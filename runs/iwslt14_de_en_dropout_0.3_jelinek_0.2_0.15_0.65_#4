Sender: LSF System <lsfadmin@eu-g3-056>
Subject: Job 210595737: <iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:39:16 2022
Job was executed on host(s) <eu-g3-056>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:39:30 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:39:30 2022
Terminated at Wed Mar 23 12:55:46 2022
Results reported at Wed Mar 23 12:55:46 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.2,0.15,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4569.30 sec.
    Max Memory :                                 5102 MB
    Average Memory :                             3916.85 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14898.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4576 sec.
    Turnaround time :                            4590 sec.

The output (if any) follows:

2022-03-23 11:39:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.2,0.15,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.2,0.15,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:39:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:39:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:39:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:39:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:39:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1128/160239 [00:00<00:14, 11264.94it/s]  2%|▏         | 2491/160239 [00:00<00:12, 12653.91it/s]  2%|▏         | 3882/160239 [00:00<00:11, 13226.86it/s]  3%|▎         | 5205/160239 [00:00<00:11, 13126.53it/s]  4%|▍         | 6518/160239 [00:00<00:11, 12970.86it/s]  5%|▍         | 7816/160239 [00:00<00:11, 12792.33it/s]  6%|▌         | 9096/160239 [00:00<00:11, 12708.64it/s]  7%|▋         | 10434/160239 [00:00<00:11, 12917.39it/s]  7%|▋         | 11748/160239 [00:00<00:11, 12984.59it/s]  8%|▊         | 13055/160239 [00:01<00:11, 13010.60it/s]  9%|▉         | 14357/160239 [00:01<00:11, 12881.35it/s] 10%|▉         | 15649/160239 [00:01<00:11, 12892.24it/s] 11%|█         | 16939/160239 [00:01<00:11, 12693.71it/s] 11%|█▏        | 18225/160239 [00:01<00:11, 12742.40it/s] 12%|█▏        | 19504/160239 [00:01<00:11, 12756.16it/s] 13%|█▎        | 20889/160239 [00:01<00:10, 13082.53it/s] 14%|█▍        | 22198/160239 [00:01<00:10, 12680.08it/s] 15%|█▍        | 23473/160239 [00:01<00:10, 12699.38it/s] 15%|█▌        | 24767/160239 [00:01<00:10, 12769.45it/s] 16%|█▋        | 26046/160239 [00:02<00:10, 12723.72it/s] 17%|█▋        | 27320/160239 [00:02<00:10, 12680.30it/s] 18%|█▊        | 28638/160239 [00:02<00:10, 12828.29it/s] 19%|█▊        | 29922/160239 [00:02<00:10, 12638.55it/s] 19%|█▉        | 31187/160239 [00:02<00:10, 12619.87it/s] 20%|██        | 32559/160239 [00:02<00:09, 12944.62it/s] 21%|██        | 33855/160239 [00:02<00:10, 12566.73it/s] 22%|██▏       | 35115/160239 [00:02<00:10, 12438.57it/s] 23%|██▎       | 36433/160239 [00:02<00:09, 12654.38it/s] 24%|██▎       | 37701/160239 [00:02<00:09, 12570.59it/s] 24%|██▍       | 39005/160239 [00:03<00:09, 12706.65it/s] 25%|██▌       | 40303/160239 [00:03<00:09, 12785.84it/s] 26%|██▌       | 41603/160239 [00:03<00:09, 12848.19it/s] 27%|██▋       | 42889/160239 [00:03<00:09, 12524.95it/s] 28%|██▊       | 44144/160239 [00:03<00:09, 12351.03it/s] 28%|██▊       | 45402/160239 [00:03<00:09, 12417.36it/s] 29%|██▉       | 46732/160239 [00:03<00:08, 12675.40it/s] 30%|██▉       | 48049/160239 [00:03<00:08, 12820.42it/s] 31%|███       | 49346/160239 [00:03<00:08, 12861.11it/s] 32%|███▏      | 50633/160239 [00:03<00:08, 12699.07it/s] 32%|███▏      | 51915/160239 [00:04<00:08, 12731.77it/s] 33%|███▎      | 53235/160239 [00:04<00:08, 12868.23it/s] 34%|███▍      | 54523/160239 [00:04<00:08, 12844.15it/s] 35%|███▍      | 55809/160239 [00:04<00:08, 12846.76it/s] 36%|███▌      | 57168/160239 [00:04<00:07, 13065.00it/s] 37%|███▋      | 58541/160239 [00:04<00:07, 13262.62it/s] 37%|███▋      | 59868/160239 [00:04<00:07, 13216.94it/s] 38%|███▊      | 61190/160239 [00:04<00:07, 12741.90it/s] 39%|███▉      | 62536/160239 [00:04<00:07, 12950.63it/s] 40%|███▉      | 63838/160239 [00:04<00:07, 12969.82it/s] 41%|████      | 65374/160239 [00:05<00:06, 13673.73it/s] 42%|████▏     | 66744/160239 [00:05<00:06, 13504.27it/s] 42%|████▏     | 68097/160239 [00:05<00:06, 13321.97it/s] 43%|████▎     | 69431/160239 [00:05<00:07, 12813.87it/s] 44%|████▍     | 70750/160239 [00:05<00:06, 12920.37it/s] 45%|████▍     | 72085/160239 [00:05<00:06, 13042.81it/s] 46%|████▌     | 73393/160239 [00:05<00:06, 12797.01it/s] 47%|████▋     | 74676/160239 [00:05<00:06, 12746.18it/s] 47%|████▋     | 75967/160239 [00:05<00:06, 12790.48it/s] 48%|████▊     | 77334/160239 [00:06<00:06, 13048.80it/s] 49%|████▉     | 78657/160239 [00:06<00:06, 13099.46it/s] 50%|████▉     | 79986/160239 [00:06<00:06, 13155.80it/s] 51%|█████     | 81447/160239 [00:06<00:05, 13589.23it/s] 52%|█████▏    | 82807/160239 [00:06<00:05, 13359.91it/s] 53%|█████▎    | 84145/160239 [00:06<00:05, 13184.55it/s] 53%|█████▎    | 85491/160239 [00:06<00:05, 13264.84it/s] 54%|█████▍    | 86910/160239 [00:06<00:05, 13537.03it/s] 55%|█████▌    | 88265/160239 [00:06<00:05, 13262.96it/s] 56%|█████▌    | 89662/160239 [00:06<00:05, 13469.35it/s] 57%|█████▋    | 91011/160239 [00:07<00:05, 13259.44it/s] 58%|█████▊    | 92339/160239 [00:07<00:05, 13246.32it/s] 58%|█████▊    | 93665/160239 [00:07<00:05, 13116.59it/s] 59%|█████▉    | 94978/160239 [00:07<00:05, 12902.75it/s] 60%|██████    | 96311/160239 [00:07<00:04, 13026.06it/s] 61%|██████    | 97618/160239 [00:07<00:04, 13036.16it/s] 62%|██████▏   | 98960/160239 [00:07<00:04, 13148.69it/s] 63%|██████▎   | 100320/160239 [00:07<00:04, 13281.27it/s] 63%|██████▎   | 101649/160239 [00:07<00:04, 13042.75it/s] 64%|██████▍   | 102955/160239 [00:07<00:04, 12824.11it/s] 65%|██████▌   | 104307/160239 [00:08<00:04, 13021.84it/s] 66%|██████▌   | 105620/160239 [00:08<00:04, 13051.11it/s] 67%|██████▋   | 106927/160239 [00:08<00:04, 12999.87it/s] 68%|██████▊   | 108228/160239 [00:08<00:04, 12656.04it/s] 68%|██████▊   | 109496/160239 [00:08<00:04, 12603.25it/s] 69%|██████▉   | 110791/160239 [00:08<00:03, 12701.89it/s] 70%|██████▉   | 112144/160239 [00:08<00:03, 12945.39it/s] 71%|███████   | 113447/160239 [00:08<00:03, 12970.15it/s] 72%|███████▏  | 114754/160239 [00:08<00:03, 12998.22it/s] 72%|███████▏  | 116073/160239 [00:08<00:03, 13053.83it/s] 73%|███████▎  | 117379/160239 [00:09<00:03, 12843.95it/s] 74%|███████▍  | 118697/160239 [00:09<00:03, 12941.06it/s] 75%|███████▍  | 120038/160239 [00:09<00:03, 13075.21it/s] 76%|███████▌  | 121357/160239 [00:09<00:02, 13104.02it/s] 77%|███████▋  | 122745/160239 [00:09<00:02, 13335.03it/s] 77%|███████▋  | 124079/160239 [00:09<00:02, 13137.84it/s] 78%|███████▊  | 125394/160239 [00:09<00:02, 12819.59it/s] 79%|███████▉  | 126713/160239 [00:09<00:02, 12925.21it/s] 80%|███████▉  | 128067/160239 [00:09<00:02, 13104.71it/s] 81%|████████  | 129379/160239 [00:10<00:02, 13032.90it/s] 82%|████████▏ | 130684/160239 [00:10<00:02, 12598.95it/s] 82%|████████▏ | 131968/160239 [00:10<00:02, 12668.51it/s] 83%|████████▎ | 133242/160239 [00:10<00:02, 12687.69it/s] 84%|████████▍ | 134513/160239 [00:10<00:02, 12558.48it/s] 85%|████████▍ | 135818/160239 [00:10<00:01, 12701.65it/s] 86%|████████▌ | 137148/160239 [00:10<00:01, 12877.63it/s] 86%|████████▋ | 138482/160239 [00:10<00:01, 13013.56it/s] 87%|████████▋ | 139849/160239 [00:10<00:01, 13207.06it/s] 88%|████████▊ | 141206/160239 [00:10<00:01, 13312.24it/s] 89%|████████▉ | 142538/160239 [00:11<00:01, 12983.20it/s] 90%|████████▉ | 143839/160239 [00:11<00:01, 12953.30it/s] 91%|█████████ | 145136/160239 [00:11<00:01, 12853.46it/s] 91%|█████████▏| 146423/160239 [00:11<00:01, 12687.61it/s] 92%|█████████▏| 147693/160239 [00:11<00:00, 12686.19it/s] 93%|█████████▎| 148963/160239 [00:11<00:00, 12386.51it/s] 94%|█████████▍| 150271/160239 [00:11<00:00, 12587.95it/s] 95%|█████████▍| 151569/160239 [00:11<00:00, 12703.12it/s] 95%|█████████▌| 152883/160239 [00:11<00:00, 12829.17it/s] 96%|█████████▌| 154175/160239 [00:11<00:00, 12853.99it/s] 97%|█████████▋| 155560/160239 [00:12<00:00, 13149.09it/s] 98%|█████████▊| 156877/160239 [00:12<00:00, 13154.13it/s] 99%|█████████▊| 158193/160239 [00:12<00:00, 12877.14it/s]100%|█████████▉| 159565/160239 [00:12<00:00, 13123.06it/s]100%|██████████| 160239/160239 [00:12<00:00, 12921.45it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3874/160239 [00:00<00:04, 38731.26it/s]  5%|▍         | 7779/160239 [00:00<00:03, 38917.61it/s]  7%|▋         | 11763/160239 [00:00<00:03, 39337.71it/s] 10%|▉         | 15718/160239 [00:00<00:03, 39417.19it/s] 12%|█▏        | 19660/160239 [00:00<00:03, 39417.07it/s] 15%|█▍        | 23613/160239 [00:00<00:03, 39453.65it/s] 17%|█▋        | 27559/160239 [00:00<00:03, 39287.76it/s] 20%|█▉        | 31575/160239 [00:00<00:03, 39561.27it/s] 22%|██▏       | 35532/160239 [00:00<00:03, 39035.48it/s] 25%|██▍       | 39502/160239 [00:01<00:03, 39238.05it/s] 27%|██▋       | 43428/160239 [00:01<00:03, 38922.86it/s] 30%|██▉       | 47380/160239 [00:01<00:02, 39102.29it/s] 32%|███▏      | 51298/160239 [00:01<00:02, 39123.95it/s] 34%|███▍      | 55236/160239 [00:01<00:02, 39199.23it/s] 37%|███▋      | 59337/160239 [00:01<00:02, 39742.57it/s] 40%|███▉      | 63359/160239 [00:01<00:02, 39884.85it/s] 42%|████▏     | 67449/160239 [00:01<00:02, 40188.36it/s] 45%|████▍     | 71469/160239 [00:01<00:02, 40024.32it/s] 47%|████▋     | 75472/160239 [00:01<00:02, 39711.57it/s] 50%|████▉     | 79585/160239 [00:02<00:02, 40131.28it/s] 52%|█████▏    | 83717/160239 [00:02<00:01, 40482.06it/s] 55%|█████▍    | 87841/160239 [00:02<00:01, 40707.59it/s] 57%|█████▋    | 91913/160239 [00:02<00:01, 40468.24it/s] 60%|█████▉    | 95961/160239 [00:02<00:01, 40348.84it/s] 62%|██████▏   | 100026/160239 [00:02<00:01, 40434.92it/s] 65%|██████▍   | 104070/160239 [00:02<00:01, 39977.93it/s] 67%|██████▋   | 108070/160239 [00:02<00:01, 39813.05it/s] 70%|██████▉   | 112053/160239 [00:02<00:01, 39739.65it/s] 72%|███████▏  | 116086/160239 [00:02<00:01, 39913.71it/s] 75%|███████▍  | 120078/160239 [00:03<00:01, 39863.57it/s] 77%|███████▋  | 124160/160239 [00:03<00:00, 40147.33it/s] 80%|███████▉  | 128176/160239 [00:03<00:00, 40006.48it/s] 82%|████████▏ | 132177/160239 [00:03<00:00, 39644.12it/s] 85%|████████▍ | 136143/160239 [00:03<00:00, 39527.87it/s] 88%|████████▊ | 140279/160239 [00:03<00:00, 40071.71it/s] 90%|█████████ | 144288/160239 [00:03<00:00, 39854.81it/s] 93%|█████████▎| 148275/160239 [00:03<00:00, 39617.04it/s] 95%|█████████▌| 152238/160239 [00:03<00:00, 39420.23it/s] 98%|█████████▊| 156284/160239 [00:03<00:00, 39727.02it/s]100%|██████████| 160239/160239 [00:04<00:00, 39746.65it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2107.69it/s]2022-03-23 11:39:56 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:39:56 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:39:56 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:39:56 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:39:56 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:39:56 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:39:56 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:39:56 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:39:56 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:39:56 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:39:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:39:56 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:39:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:39:56 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:39:56 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:39:56 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 11:39:56 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 11:39:56 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:39:57 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:39:57 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:39:57 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:39:57 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:39:57 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:39:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:40:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:40:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:40:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:40:40 | INFO | train_inner | epoch 001:    104 / 157 loss=13.468, ppl=11329.9, wps=65321.4, ups=2.6, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=3.003, loss_scale=8, train_wall=42, gb_free=11.8, wall=43
2022-03-23 11:40:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:41:03 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 11:41:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:41:06 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 11:41:06 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:41:09 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 11:41:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:41:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:41:12 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:41:16 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:41:22 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:41:27 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:41:33 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:41:40 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:41:42 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:41:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:41:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.239 | ppl 9671.1 | bleu 0.01 | wps 4156 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:41:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:41:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:41:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:41:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.659855523146689 seconds)
2022-03-23 11:41:44 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:41:44 | INFO | train | epoch 001 | loss 13.035 | ppl 8390.67 | wps 37385.8 | ups 1.49 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.292 | loss_scale 8 | train_wall 61 | gb_free 12.1 | wall 107
KL Stats: Epoch 1 Divergences: Uniform: 0.5374774154235699 Unigram: 1.4589843600711985
2022-03-23 11:41:44 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:41:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:42:02 | INFO | train_inner | epoch 002:     47 / 157 loss=12.04, ppl=4210.87, wps=30475.7, ups=1.22, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=0.956, loss_scale=8, train_wall=36, gb_free=22.3, wall=125
2022-03-23 11:42:40 | INFO | train_inner | epoch 002:    147 / 157 loss=11.539, ppl=2975.99, wps=66295.2, ups=2.65, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=0.848, loss_scale=8, train_wall=37, gb_free=12.1, wall=163
2022-03-23 11:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example hypothesis: you.
2022-03-23 11:42:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:42:50 | INFO | fairseq.tasks.translation | example hypothesis: the the.
2022-03-23 11:42:50 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:42:53 | INFO | fairseq.tasks.translation | example hypothesis: i i i i.
2022-03-23 11:42:53 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:42:56 | INFO | fairseq.tasks.translation | example hypothesis: you you,,,,,,,,,,,,,,,,,.
2022-03-23 11:42:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:42:59 | INFO | fairseq.tasks.translation | example hypothesis: and we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we.
2022-03-23 11:42:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:43:03 | INFO | fairseq.tasks.translation | example hypothesis: and and and and we we we we we we we we we we we we we.
2022-03-23 11:43:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:43:08 | INFO | fairseq.tasks.translation | example hypothesis: and and the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:43:13 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and the the the the the the the the the the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:43:20 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:43:22 | INFO | fairseq.tasks.translation | example hypothesis: we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:43:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:43:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.579 | ppl 6119.06 | bleu 0.02 | wps 4577.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:43:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.7797708669677377 seconds)
2022-03-23 11:43:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:43:24 | INFO | train | epoch 002 | loss 11.589 | ppl 3079.62 | wps 39367.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.887 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 208
KL Stats: Epoch 2 Divergences: Uniform: 0.624368059301356 Unigram: 0.37454871143105883
2022-03-23 11:43:24 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:58 | INFO | train_inner | epoch 003:     90 / 157 loss=11.319, ppl=2555.54, wps=31613, ups=1.27, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=0.864, loss_scale=8, train_wall=37, gb_free=12, wall=242
2022-03-23 11:44:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:44:27 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:44:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:44:30 | INFO | fairseq.tasks.translation | example hypothesis: and he he, he the.
2022-03-23 11:44:30 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:44:35 | INFO | fairseq.tasks.translation | example hypothesis: and i, i, i, i, i, i, i, i, i to to to to to to to to to to to to to to to to to to
2022-03-23 11:44:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:44:40 | INFO | fairseq.tasks.translation | example hypothesis: and he, he was, he was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was,
2022-03-23 11:44:40 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:44:45 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we
2022-03-23 11:44:45 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:44:51 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, we, we to the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to the
2022-03-23 11:44:51 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:44:57 | INFO | fairseq.tasks.translation | example hypothesis: and it's, the, but the, but the, but the, but the, but but the, but the, but the, but the, but the, but but but but but the, but the, but the, but the, but the, but the, but the, but the, but but but but but but but but but the
2022-03-23 11:44:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:45:03 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, we, we, and we the, and we, we the the, and we the the the the, and we the, and we, and we the the, and we the the the the, we, and the, and we the the the, and we the the, and we the the the the, and we we we we the the the the, we the the the the, and the the the the, and we we
2022-03-23 11:45:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:45:11 | INFO | fairseq.tasks.translation | example hypothesis: and and the, "the," "" "the," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:45:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:45:13 | INFO | fairseq.tasks.translation | example hypothesis: and we, the, the, the, the, the, the, the, the, the, the, the, the, the, we the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, we we we we we the, the, we we we we we the, the, the, the, the, the, the, we we we the, the, the, the, the, the, we we the, the, the, the, the, the, the, the, the, the, the, the, we we we we we we we we the, the, the, the, the, and the, we we we we we the the the the, we we we we the the the the the, the, the, the, the, the, we we we we we we we we the the the the, the the, the, the, the, the, the, the, the, the the
2022-03-23 11:45:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:45:13 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.393 | ppl 5379.18 | bleu 0.23 | wps 3543.2 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.23
2022-03-23 11:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:45:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.23) (writing took 1.7503072530962527 seconds)
2022-03-23 11:45:15 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:45:15 | INFO | train | epoch 003 | loss 11.217 | ppl 2379.63 | wps 35665.9 | ups 1.42 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.914 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 318
KL Stats: Epoch 3 Divergences: Uniform: 0.7790103579071187 Unigram: 0.29558754196339243
2022-03-23 11:45:15 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:45:28 | INFO | train_inner | epoch 004:     33 / 157 loss=11.083, ppl=2168.7, wps=28636.2, ups=1.12, wpb=25598.5, bsz=1067.8, num_updates=500, lr=6.25e-05, gnorm=1.02, loss_scale=8, train_wall=37, gb_free=12, wall=331
2022-03-23 11:46:05 | INFO | train_inner | epoch 004:    133 / 157 loss=10.933, ppl=1955.4, wps=67051.9, ups=2.66, wpb=25215.5, bsz=1096.9, num_updates=600, lr=7.5e-05, gnorm=0.942, loss_scale=8, train_wall=37, gb_free=12.4, wall=369
2022-03-23 11:46:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:46:18 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can can can can can can can have.
2022-03-23 11:46:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:46:23 | INFO | fairseq.tasks.translation | example hypothesis: he's a of the world of the world.
2022-03-23 11:46:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:46:28 | INFO | fairseq.tasks.translation | example hypothesis: so i think i'm to have a lot of the world of a lot of a lot of the world of the world of the world of the world.
2022-03-23 11:46:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:46:33 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was he was he was he was he was was he was was was he was was was he was was was he was was was he he was was was was was was was he was a
2022-03-23 11:46:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:46:39 | INFO | fairseq.tasks.translation | example hypothesis: and we know, we know, and we know, and we know, what we know, we know, and we know, we're're're're're're to do we can can can can can can can can can can can have a
2022-03-23 11:46:39 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:46:44 | INFO | fairseq.tasks.translation | example hypothesis: and we can can see the world, and we can can can can can can can can can can can can can can can can can can can see or or or or or or or or or or or or or or or or or or or or or or or or or or or.
2022-03-23 11:46:44 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:46:50 | INFO | fairseq.tasks.translation | example hypothesis: but we're the world, but but they're're the world, but but they're're're the world, but but they're're're the world, but they're're're're're the world, and they're're're're're're're're're're're're're're're're're're're the world.
2022-03-23 11:46:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:46:56 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world, and we can can can can can can can see the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see the the the
2022-03-23 11:46:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:04 | INFO | fairseq.tasks.translation | example hypothesis: and it's the, "" "" "we've've've've've've've've've've've've've've've said," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 11:47:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:06 | INFO | fairseq.tasks.translation | example hypothesis: and we're the world, and we've've've've've've've've've've've have to be to be to be to be to be that that that that we're to be be be to be to be be be to be to be be be be to be to be be be to be be to be be the the world, and it's the world, and it's the world to be be be be be be be be be be be be be be be be be to be, and the world, and the world, and the world, and it's the world, and the world, and it's the world, and we can can can be be be be be be be be be be be be be to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be the
2022-03-23 11:47:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:06 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.153 | ppl 4555.44 | bleu 0.99 | wps 3414.1 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.99
2022-03-23 11:47:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:47:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:47:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:47:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.99) (writing took 1.7908568819984794 seconds)
2022-03-23 11:47:08 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:47:08 | INFO | train | epoch 004 | loss 11.01 | ppl 2062.09 | wps 34924.8 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.963 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 431
KL Stats: Epoch 4 Divergences: Uniform: 0.7939962792040213 Unigram: 0.4283478248988639
2022-03-23 11:47:08 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:47:37 | INFO | train_inner | epoch 005:     76 / 157 loss=10.835, ppl=1826.9, wps=27396.3, ups=1.09, wpb=25097.7, bsz=1058.7, num_updates=700, lr=8.75e-05, gnorm=1.149, loss_scale=8, train_wall=37, gb_free=11.9, wall=461
2022-03-23 11:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:48:11 | INFO | fairseq.tasks.translation | example hypothesis: so, you can can can can see.
2022-03-23 11:48:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:48:15 | INFO | fairseq.tasks.translation | example hypothesis: and he was a lot of the time, he can can can be.
2022-03-23 11:48:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:48:19 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to be a lot of a lot of a lot of a lot of the world, i can can can can can be a lot of the world.
2022-03-23 11:48:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:48:24 | INFO | fairseq.tasks.translation | example hypothesis: and he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was he was a
2022-03-23 11:48:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:48:29 | INFO | fairseq.tasks.translation | example hypothesis: so, what we're going to do, and we have a lot of a lot of a lot of a lot of a lot of what we have a lot of the world, and we have a lot of what we have a lot of the
2022-03-23 11:48:29 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:48:34 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do the world, and we're going to do we're going to do the world of the world of the world of the world of the world of the world, and we're going to do we're going to do we're going to do or or or or or
2022-03-23 11:48:34 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:48:40 | INFO | fairseq.tasks.translation | example hypothesis: and they're a lot of the way, but they're not not not not a lot of the world, but they're a lot of the world, but they're not not not not not not not not a lot of the world, but they're a lot of the world of the world of the world.
2022-03-23 11:48:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:48:46 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world of the world of the world, and we can see the world, and we can see the world of the world of the world of the world of the world of the world, and we can see the world of the world of the world, and we can see the world of the world of the world, and we can see the world, and we can see the world of the world of the world, and we can see the world
2022-03-23 11:48:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:48:54 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" i said, "" "" "" "" "" "" i said, "" "" "" "i said," "" "i said," the first first first first first first first first first first, "" "" "" "" "" "" "" "" "" "" "" "" "" "" i said, "i said," "" "" "" "" "" "" "" "the first first first first first first first first first first first first first first first first first first first first first" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "i said," "" "" "" "" "" "" "" i said, "" ""
2022-03-23 11:48:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example hypothesis: and we have the world of the world of the world, and the world of the world of the world, the world of the world of the world of the world of the world of the world of the world of the world, and we've've've've've have to see the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and the world of the world of the world of the world of the world of the world, and the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, and the world, and the world, and the world of the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:48:56 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.908 | ppl 3843.23 | bleu 1.5 | wps 3627.9 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.5
2022-03-23 11:48:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:48:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:48:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:48:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.5) (writing took 1.824597213882953 seconds)
2022-03-23 11:48:58 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:48:58 | INFO | train | epoch 005 | loss 10.777 | ppl 1754.63 | wps 35862.6 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.023 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 541
KL Stats: Epoch 5 Divergences: Uniform: 0.8330873358719777 Unigram: 0.5618765558094844
2022-03-23 11:48:58 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:48:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:49:06 | INFO | train_inner | epoch 006:     19 / 157 loss=10.788, ppl=1768.03, wps=28192.7, ups=1.13, wpb=25039.8, bsz=950.1, num_updates=800, lr=0.0001, gnorm=0.895, loss_scale=8, train_wall=37, gb_free=12, wall=549
2022-03-23 11:49:43 | INFO | train_inner | epoch 006:    119 / 157 loss=10.608, ppl=1560.44, wps=67057.2, ups=2.67, wpb=25126.8, bsz=945, num_updates=900, lr=0.0001125, gnorm=1.006, loss_scale=8, train_wall=37, gb_free=11.5, wall=587
2022-03-23 11:49:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:01 | INFO | fairseq.tasks.translation | example hypothesis: they can't have.
2022-03-23 11:50:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:50:05 | INFO | fairseq.tasks.translation | example hypothesis: he can be a lot of course.
2022-03-23 11:50:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:50:09 | INFO | fairseq.tasks.translation | example hypothesis: now, i can't have a lot of this.
2022-03-23 11:50:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:50:14 | INFO | fairseq.tasks.translation | example hypothesis: he was he was a lot of he was, and he was been been going to me.
2022-03-23 11:50:14 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:50:19 | INFO | fairseq.tasks.translation | example hypothesis: so, what we have a lot of what we have a lot of what we're going to do, and we're going to do, and we're going to do, and we're going to do, and we're going to have a
2022-03-23 11:50:19 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:50:24 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do that we're going to do the world, and we have to do the world, and we're going to do the world, and we're going to do that we're going to do the world.
2022-03-23 11:50:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to have a lot of the way, they're going to have a lot of the way, but they're not been been been been, and they're going to be a lot of the way, but they're going to be, but they're going to be a lot of the way.
2022-03-23 11:50:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:50:36 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to see the world, and we're going to do, and we're going to see the world, and we're going to get the world, and we're going to get the world, and we're going to get the world.
2022-03-23 11:50:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "" "" "" "" "" "" "" "" "you have to be," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" i said, "i said," i said, "" "" "" "" "" "" "" "" "" you, "i said," i said, "i said," "" "" i said, "" "" "" "" "" "" "" "" "" "" we said, "i said," i said, "i said," we said, "" i said, "" "" "" "" "" "" "" "" ""
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:50:46 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be the world, and we have to be the world, and we have to be the world, and we have to be the world, and we're going to get the world, and we have to be the world, and we have to be the world, and we have to have to have to be the world, and we have to be the world, and we have to be the world, and we're going to see the world, and we have the world, and we have the world, and we have to be the world, and we have to be the world, and we're going to have to have to have to have to be the world, and we're going to be the world, and we're going to be the world, and we have to be the world, and we have to have to have to have to be the world, and we have to be the world, and the
2022-03-23 11:50:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:50:46 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.717 | ppl 3365.44 | bleu 1.86 | wps 3702.5 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.86
2022-03-23 11:50:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:50:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:50:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.86) (writing took 1.7651521568186581 seconds)
2022-03-23 11:50:47 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:50:47 | INFO | train | epoch 006 | loss 10.586 | ppl 1536.7 | wps 36129.1 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.006 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 651
KL Stats: Epoch 6 Divergences: Uniform: 0.8689722970132184 Unigram: 0.661422736720628
2022-03-23 11:50:48 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:50:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:51:11 | INFO | train_inner | epoch 007:     62 / 157 loss=10.562, ppl=1511.47, wps=28364.6, ups=1.14, wpb=24967.7, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=0.89, loss_scale=8, train_wall=37, gb_free=12.4, wall=675
2022-03-23 11:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:51:50 | INFO | fairseq.tasks.translation | example hypothesis: these can't have a lot of this.
2022-03-23 11:51:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:51:55 | INFO | fairseq.tasks.translation | example hypothesis: he can have a year.
2022-03-23 11:51:55 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:51:59 | INFO | fairseq.tasks.translation | example hypothesis: now, i can see this, i can't have a lot of this.
2022-03-23 11:51:59 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:52:03 | INFO | fairseq.tasks.translation | example hypothesis: he was a lot of me, because he had been been been been been been been been been been been been been been because he was been been been been been been been been been been.
2022-03-23 11:52:03 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:52:08 | INFO | fairseq.tasks.translation | example hypothesis: so what we're going to do is what we're going to do is what we're going to do?
2022-03-23 11:52:08 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:52:12 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to talk about our world, or our world, and we're going to talk about our world.
2022-03-23 11:52:12 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:52:17 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to have a lot of, you're going to see, but they're going to have a lot of these are not not, but they're going to have a lot of the same, but they're going to have a lot of the way, but they're going to have a lot of the way.
2022-03-23 11:52:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:52:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see, we can see, we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see, we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, we can see the
2022-03-23 11:52:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:52:31 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:52:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:52:33 | INFO | fairseq.tasks.translation | example hypothesis: so, if we have a lot of the world, it's a lot of the world, which is that we're going to have a lot of the world, which is that we're going to have a lot of the world, which is that we're going to have a lot of the world, which is that we're going to have a lot of the world, which is that we're going to have a lot of the world, which is that we're going to have a lot of the world, which is a lot of the world, which is a lot of the world, which is that we're going to have a lot of the world, which is that we have a lot of the world, which is that we're going to have a lot of the world, which is that we're going to have a lot of the world, which is a lot of the world, and the world, which is that we're going to have a lot of the world, which is that we're going to have a lot of the world, which is
2022-03-23 11:52:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:52:33 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.579 | ppl 3060.08 | bleu 2.28 | wps 3825.7 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.28
2022-03-23 11:52:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:52:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.28) (writing took 1.7874905429780483 seconds)
2022-03-23 11:52:35 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:52:35 | INFO | train | epoch 007 | loss 10.408 | ppl 1358.73 | wps 36645.5 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.88 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 759
KL Stats: Epoch 7 Divergences: Uniform: 0.8990062314795567 Unigram: 0.734338394532573
2022-03-23 11:52:35 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:38 | INFO | train_inner | epoch 008:      5 / 157 loss=10.271, ppl=1235.63, wps=29461, ups=1.16, wpb=25396.2, bsz=1052.4, num_updates=1100, lr=0.0001375, gnorm=0.886, loss_scale=8, train_wall=37, gb_free=12.1, wall=761
2022-03-23 11:53:15 | INFO | train_inner | epoch 008:    105 / 157 loss=10.273, ppl=1237.65, wps=66770.5, ups=2.65, wpb=25204.4, bsz=1027.4, num_updates=1200, lr=0.00015, gnorm=0.801, loss_scale=8, train_wall=37, gb_free=12.3, wall=799
2022-03-23 11:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:53:38 | INFO | fairseq.tasks.translation | example hypothesis: these can't be.
2022-03-23 11:53:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:53:42 | INFO | fairseq.tasks.translation | example hypothesis: it's a year.
2022-03-23 11:53:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:53:46 | INFO | fairseq.tasks.translation | example hypothesis: this is that i can see that i can make a lot of course.
2022-03-23 11:53:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:53:49 | INFO | fairseq.tasks.translation | example hypothesis: he was his father.
2022-03-23 11:53:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:53:53 | INFO | fairseq.tasks.translation | example hypothesis: so, one of what's a little bit of what we're going to do with what we're going to do with what we're going to do?
2022-03-23 11:53:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:53:57 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to be going to talk about the world.
2022-03-23 11:53:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:54:01 | INFO | fairseq.tasks.translation | example hypothesis: some of them, but if you're going to look at it, but you're going to look at the way.
2022-03-23 11:54:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:54:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to go to get a little bit of the world, and we can see that we can see that we can see the world.
2022-03-23 11:54:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:09 | INFO | fairseq.tasks.translation | example hypothesis: one: if you're going to say, "we're going to say," if we're going to be going to say, "if we're going to be going to be going to say, and we're going to be going to do it.
2022-03-23 11:54:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:54:11 | INFO | fairseq.tasks.translation | example hypothesis: and it's a little bit that we're going to get to be a lot of the way that we're going to get to be going to be going to be a little bit of the way that we're going to be going to be going to be going to be going to be going to be going to be going to be going to be going to be going to be going to be going to be going to be a little bit that we're going to be a little bit that we're going to get to get to get to get to get to be a little bit that we're going to be going to be going to be a little bit that we're going to be going to be going to be going to be going to be going to be going to be going to be going to be going to be a little bit.
2022-03-23 11:54:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:54:11 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.455 | ppl 2807.6 | bleu 2.56 | wps 5061.8 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 2.56
2022-03-23 11:54:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:54:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:54:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 8 @ 1252 updates, score 2.56) (writing took 1.823097491171211 seconds)
2022-03-23 11:54:13 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:54:13 | INFO | train | epoch 008 | loss 10.265 | ppl 1230.17 | wps 40474.2 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.884 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 856
KL Stats: Epoch 8 Divergences: Uniform: 0.9292742826288247 Unigram: 0.7829832893732238
2022-03-23 11:54:13 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:54:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:54:31 | INFO | train_inner | epoch 009:     48 / 157 loss=10.207, ppl=1182.24, wps=32952.4, ups=1.32, wpb=24959.6, bsz=1001.8, num_updates=1300, lr=0.0001625, gnorm=0.888, loss_scale=8, train_wall=37, gb_free=11.8, wall=875
2022-03-23 11:55:09 | INFO | train_inner | epoch 009:    148 / 157 loss=10.087, ppl=1087.66, wps=67015.9, ups=2.64, wpb=25342.7, bsz=1020.9, num_updates=1400, lr=0.000175, gnorm=0.817, loss_scale=8, train_wall=37, gb_free=11.8, wall=912
2022-03-23 11:55:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:55:16 | INFO | fairseq.tasks.translation | example hypothesis: this is not no.
2022-03-23 11:55:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:55:20 | INFO | fairseq.tasks.translation | example hypothesis: and then, he's a year in the last year.
2022-03-23 11:55:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:55:24 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of course of course, i can make a lot of course.
2022-03-23 11:55:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:55:29 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he was his father, because he was his father, because she was his father was his father, because she was going to his father was his father, because she was his father
2022-03-23 11:55:29 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is, and i'm going to say, and what we're going to do, and what we're going to do?
2022-03-23 11:55:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:55:39 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to talk about our time, and we're going to talk about things about things, or not about the world, or or the other other things, or, or the other other or or or or or or or or the other other other other or or or or or
2022-03-23 11:55:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:55:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them, and some of the.
2022-03-23 11:55:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to look at the information, we're going to make this, and we can see this, and then we can see the kind of the world, and then we can see the kind of the world, and we can see, and then we can see that we can see the kind of the world, and then we can see the world.
2022-03-23 11:55:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:57 | INFO | fairseq.tasks.translation | example hypothesis: one: the one of the reason, and it's a little bit, and it's called "and it's going to say," and it's going to say, "if you're going to say," if you're going to say, "if you're going to say," and then it's going to say, "and then we're going to say," and then it's going to say, "if you're going to say," and then it's going to say, "and then it's going to say," if you're going to say, "and then it's going to say," if you're going to say, "if you're going to say," and then it's going to say, "if you're going to say," you're going to say, "you're going to say," if you're going to say,
2022-03-23 11:55:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:59 | INFO | fairseq.tasks.translation | example hypothesis: and.
2022-03-23 11:55:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:59 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.248 | ppl 2432.19 | bleu 4.47 | wps 3736.7 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4.47
2022-03-23 11:55:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:55:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:56:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.47) (writing took 1.766494412906468 seconds)
2022-03-23 11:56:01 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:56:01 | INFO | train | epoch 009 | loss 10.118 | ppl 1111.17 | wps 36353.7 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.792 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 965
KL Stats: Epoch 9 Divergences: Uniform: 0.9571290740741311 Unigram: 0.8280505833773797
2022-03-23 11:56:02 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:56:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:36 | INFO | train_inner | epoch 010:     91 / 157 loss=9.885, ppl=945.26, wps=29172.1, ups=1.15, wpb=25471.1, bsz=1099.8, num_updates=1500, lr=0.0001875, gnorm=0.878, loss_scale=8, train_wall=37, gb_free=11.8, wall=1000
2022-03-23 11:57:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:05 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able to use them.
2022-03-23 11:57:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:57:09 | INFO | fairseq.tasks.translation | example hypothesis: and then he can be about about about about about about about 30,000 years.
2022-03-23 11:57:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:57:13 | INFO | fairseq.tasks.translation | example hypothesis: that's what i can do, of course, of course, of course, of course, of course.
2022-03-23 11:57:13 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:57:17 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because his father was his father, because she was his father was his mother.
2022-03-23 11:57:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:57:21 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a child, and we've got a child, so what we did?
2022-03-23 11:57:21 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:57:25 | INFO | fairseq.tasks.translation | example hypothesis: so, so we have our time to talk about how to talk about things, or they don't talk about the world.
2022-03-23 11:57:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:57:30 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are, but if you don't know, you don't know, you don't know, it's so if you don't need to get the energy, and you don't need to do it.
2022-03-23 11:57:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information, we can take this information, and we can take a little bit of these kinds of information, and then we can take a little bit of it, and then we can see the
2022-03-23 11:57:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:40 | INFO | fairseq.tasks.translation | example hypothesis: one: one of one of the things, and it's interesting interesting thing, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's a long long long long long long, "you have to have to have to have to have to have to have to be a long long long time," you know, "you know," you know, "for the
2022-03-23 11:57:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:43 | INFO | fairseq.tasks.translation | example hypothesis: and so,, it's always always always always the mother, and the way that we've got to get a lot of the way that we've got a lot of a lot of things that we've got to get a lot of things that we had a lot of things that we had a lot of the
2022-03-23 11:57:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:43 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.064 | ppl 2140.66 | bleu 7.73 | wps 4322.8 | wpb 17862.2 | bsz 728.3 | num_updates 1566 | best_bleu 7.73
2022-03-23 11:57:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1566 updates
2022-03-23 11:57:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 10 @ 1566 updates, score 7.73) (writing took 1.8272691001184285 seconds)
2022-03-23 11:57:44 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:57:44 | INFO | train | epoch 010 | loss 9.96 | ppl 996.23 | wps 38283.2 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1566 | lr 0.00019575 | gnorm 0.834 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 1068
KL Stats: Epoch 10 Divergences: Uniform: 0.9854019786051884 Unigram: 0.8760153094504858
2022-03-23 11:57:45 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:57:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:58 | INFO | train_inner | epoch 011:     34 / 157 loss=9.983, ppl=1012.35, wps=30665.6, ups=1.22, wpb=25082.5, bsz=937.7, num_updates=1600, lr=0.0002, gnorm=0.766, loss_scale=8, train_wall=37, gb_free=12.4, wall=1081
2022-03-23 11:58:35 | INFO | train_inner | epoch 011:    134 / 157 loss=9.755, ppl=863.94, wps=66837.1, ups=2.67, wpb=25054.1, bsz=1010.5, num_updates=1700, lr=0.0002125, gnorm=0.77, loss_scale=8, train_wall=37, gb_free=12.3, wall=1119
2022-03-23 11:58:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:48 | INFO | fairseq.tasks.translation | example hypothesis: this can't use these materials.
2022-03-23 11:58:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:58:52 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about about 30,000 miles.
2022-03-23 11:58:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 11:58:56 | INFO | fairseq.tasks.translation | example hypothesis: that's what i can also use of course, of course, of course, of course, of course, of course.
2022-03-23 11:58:56 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 11:59:01 | INFO | fairseq.tasks.translation | example hypothesis: he never never never never never never seen his father because his father had his father, because his father had his father was his father with him.
2022-03-23 11:59:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 11:59:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is, and i had a lot of people who had a child, and so we got a child, so we asked us to do what do?
2022-03-23 11:59:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 11:59:10 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time about our time about things about things about how much things are not going to talk to talk about the world, or each other, or each other.
2022-03-23 11:59:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're some of the.
2022-03-23 11:59:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:59:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the information of these information that we can start with a little bit of these information, we can start with a little bit of the information, and then we can start with the structure of the information.
2022-03-23 11:59:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:59:23 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons that it's interesting, and it's interesting for me for me for me, and i'm going to do it for me to be able to be able to tell you, "and then then," if you know, "you know," you know, "and then you know," in this is, "and then you know," and then, "the most important to say," and then, "and then," and then you know, "the next to say," the next to say, "the next to say," and then, "and then," the best, "the best," the next to say, "and then," and then, "the best people who's the best people who's the best of the best," the best people who said, "and then we've got to say," the
2022-03-23 11:59:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:59:26 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still always always always always the mother, and the work of the work that we have a lot of work on our work, and when we're going to see a lot of the world, and then we're going to see that we're going to see that's going to see that we're going to see a lot of the world.
2022-03-23 11:59:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:26 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.897 | ppl 1906.82 | bleu 9.36 | wps 4337 | wpb 17862.2 | bsz 728.3 | num_updates 1723 | best_bleu 9.36
2022-03-23 11:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1723 updates
2022-03-23 11:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:59:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 11:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 11 @ 1723 updates, score 9.36) (writing took 1.8060792172327638 seconds)
2022-03-23 11:59:27 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:59:27 | INFO | train | epoch 011 | loss 9.767 | ppl 871.11 | wps 38329.8 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1723 | lr 0.000215375 | gnorm 0.746 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1171
KL Stats: Epoch 11 Divergences: Uniform: 1.016770918726692 Unigram: 0.9170799372344066
2022-03-23 11:59:28 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:57 | INFO | train_inner | epoch 012:     77 / 157 loss=9.507, ppl=727.62, wps=31375.1, ups=1.22, wpb=25654, bsz=1101.4, num_updates=1800, lr=0.000225, gnorm=0.739, loss_scale=8, train_wall=37, gb_free=12.1, wall=1201
2022-03-23 12:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:31 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use it.
2022-03-23 12:00:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:00:35 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 80s.
2022-03-23 12:00:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example hypothesis: and this pattern can also be able to be a sense of course.
2022-03-23 12:00:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example hypothesis: he never had his father, because his father had his father had his father, she had his father with him.
2022-03-23 12:00:43 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example hypothesis: one of my mom is at aids, and a child has got a child, so we asked us to do what do?
2022-03-23 12:00:47 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:00:51 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about things like this and not talk to talk about, or not about poverty or other.
2022-03-23 12:00:51 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you are some of the things, but if you don't know, but if you don't need it, if you don't need the energy, you need the energy, and you need the energy.
2022-03-23 12:00:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can start up with a little bit, we can start to start with a little bit of the structure, and the structure of the structure, which is all the structure of the information, and all the information.
2022-03-23 12:00:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:04 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons, and it's interesting to be interesting for me to be in tedson, you know, you've got to tell you that the best revolution, "if you've got the best revolution, you've got the best revolution," and then we've got to tell you know, "if you're going to say," the best for the best revolution, "the best revolution," the best revolution, "the best time," the best revolution, "the best revolution," the best revolution, "the best time," the best time, you've got the best time, "the best time, you've got the best time, you've got to give you know," the best revolution, "the best for you've got to give you know," the best time, you've got the best time, "you've got the best,"
2022-03-23 12:01:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:01:06 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, there's still still the mother, and the part of the design of our work that we had to see that when we had to use a little bit that we had to use, if we had to use a little bit that we had to use the system, we had to use it in a little bit of the system, we had to use to use, we had to use, we had to use to use to use to use it, to use to use to use, to use, to use to use to use to use to use to use, to use, and to make a little bit that if we had to make a little bit that we had to make a little bit that we had to make a little bit that we had to make a little bit that we had to make a little bit that we had to use the reget a little bit that we had to be a huge system, to use that we had to make a huge system, to use, to use it was a little bit of the
2022-03-23 12:01:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:01:06 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.649 | ppl 1606.22 | bleu 11.97 | wps 4639.1 | wpb 17862.2 | bsz 728.3 | num_updates 1880 | best_bleu 11.97
2022-03-23 12:01:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1880 updates
2022-03-23 12:01:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:01:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:01:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 12 @ 1880 updates, score 11.97) (writing took 1.8067446881905198 seconds)
2022-03-23 12:01:08 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:01:08 | INFO | train | epoch 012 | loss 9.586 | ppl 768.46 | wps 39271.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1880 | lr 0.000235 | gnorm 0.768 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1272
KL Stats: Epoch 12 Divergences: Uniform: 1.044002289048035 Unigram: 0.9447626877837338
2022-03-23 12:01:08 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:16 | INFO | train_inner | epoch 013:     20 / 157 loss=9.634, ppl=794.81, wps=31250.7, ups=1.27, wpb=24602.9, bsz=954.1, num_updates=1900, lr=0.0002375, gnorm=0.782, loss_scale=8, train_wall=37, gb_free=11.8, wall=1279
2022-03-23 12:01:54 | INFO | train_inner | epoch 013:    120 / 157 loss=9.449, ppl=699.1, wps=66385.2, ups=2.65, wpb=25062.1, bsz=1044.2, num_updates=2000, lr=0.00025, gnorm=0.795, loss_scale=8, train_wall=37, gb_free=12.7, wall=1317
2022-03-23 12:02:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:11 | INFO | fairseq.tasks.translation | example hypothesis: it can't use these chemical chemical.
2022-03-23 12:02:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 miles.
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:02:19 | INFO | fairseq.tasks.translation | example hypothesis: and this pattern can also be able to be a sense of course.
2022-03-23 12:02:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had had his father.
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example hypothesis: so one of my friends is a child, and we found a child, so we asked us to do what do?
2022-03-23 12:02:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example hypothesis: and so we spend our time to talk about how to talk about things and not talk about poverty or not about poverty.
2022-03-23 12:02:30 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are going to get out of the lines, but if they don't like it, they don't need their own energy, and if they don't need the energy.
2022-03-23 12:02:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this, we can start to start with a traditional traditional, and then we can start able to start the form of the form of the structure, and the structure of information, and all of the information.
2022-03-23 12:02:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:42 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons, and it's interesting for me to be here for me, "yes, yes," yes, it's the best thing that we've got to say, "if you're going to say," the best revolution. "
2022-03-23 12:02:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, the mother is still the invention, and we have a big design on our work that we had to use the airplane, and if we had to use it, it was a little bit that we had to be able to be able to be able to use, and if we had to use it.
2022-03-23 12:02:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:43 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.556 | ppl 1505.74 | bleu 11.49 | wps 5194.9 | wpb 17862.2 | bsz 728.3 | num_updates 2037 | best_bleu 11.97
2022-03-23 12:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2037 updates
2022-03-23 12:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:02:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:02:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 13 @ 2037 updates, score 11.49) (writing took 0.8390989331528544 seconds)
2022-03-23 12:02:44 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:02:44 | INFO | train | epoch 013 | loss 9.412 | ppl 681.11 | wps 41317.2 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 2037 | lr 0.000254625 | gnorm 0.782 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 1367
KL Stats: Epoch 13 Divergences: Uniform: 1.0730222676411731 Unigram: 0.974356118793528
2022-03-23 12:02:44 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:02:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:08 | INFO | train_inner | epoch 014:     63 / 157 loss=9.246, ppl=607.02, wps=34420.4, ups=1.35, wpb=25541.3, bsz=1062.3, num_updates=2100, lr=0.0002625, gnorm=0.769, loss_scale=8, train_wall=37, gb_free=12.3, wall=1391
2022-03-23 12:03:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:47 | INFO | fairseq.tasks.translation | example hypothesis: this is no chemical chemical chemical chemical chemical chemical chemical chemical chemical use.
2022-03-23 12:03:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 888,000 restaurant in the restaurant.
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:03:57 | INFO | fairseq.tasks.translation | example hypothesis: so, i can also, of course, of course, of course, i can also, of course, of course, of course, of course, of course, of course
2022-03-23 12:03:57 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother, because she had his mother with him.
2022-03-23 12:04:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is died, and aids died a child, so we asked us to do what are we doing?
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example hypothesis: so, we spend our time to talk about how things are, and how to talk about how to talk about things that are not about poverty, or other, or other, or other, or other, or other people, or each other, or we're going to talk about poverty.
2022-03-23 12:04:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:04:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic field, but in the field of the field, if they don't want to move their own energy, and if you don't need to move the power of the energy, and so you need to move, and so you need to the power of the power of the power, you're so you're so
2022-03-23 12:04:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:04:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that can use the information of this reflection, we can start able to start with a traditional traditional, and we can start to start using the form of the structure of the structure, and all of the information, which is all the information that we can start all the information, and so, and so if we can start all the information, the information, and so if we're all the information, the information, the information, the information
2022-03-23 12:04:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:27 | INFO | fairseq.tasks.translation | example hypothesis: 19th: one of the reasons that it's interesting, and it's interesting to be interesting for me, "yes," you know, "if you're going to say," the best revolution, you're going to say, "you know," you're going to say, "you know," in this time, "you're going to have a long time," the most important revolution, "and then we're going to have a long time," and then we're going to do it's going to say, "the first time," and then we're going to do it's a lot of you're going to have a lot of the most important revolution, "
2022-03-23 12:04:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:29 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the mother, and a big design of design that we have to use a great design that we've had to be able to be able to be able to be able to be able to use, and that if we had to use it in a scale, and if you have to use it's all of the, it's all of us, it's all of us to use to use to use, to use, it is that it, to use, and if you know, it's a little bit of the
2022-03-23 12:04:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:29 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.42 | ppl 1369.83 | bleu 11.71 | wps 3949.7 | wpb 17862.2 | bsz 728.3 | num_updates 2194 | best_bleu 11.97
2022-03-23 12:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2194 updates
2022-03-23 12:04:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:04:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:04:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 14 @ 2194 updates, score 11.71) (writing took 0.8529337961226702 seconds)
2022-03-23 12:04:30 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:04:30 | INFO | train | epoch 014 | loss 9.262 | ppl 613.84 | wps 37207.3 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 2194 | lr 0.00027425 | gnorm 0.761 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1473
KL Stats: Epoch 14 Divergences: Uniform: 1.1038138937070552 Unigram: 0.9940527002406463
2022-03-23 12:04:30 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:04:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:32 | INFO | train_inner | epoch 015:      6 / 157 loss=9.295, ppl=628, wps=29298.2, ups=1.18, wpb=24782.3, bsz=960.7, num_updates=2200, lr=0.000275, gnorm=0.736, loss_scale=8, train_wall=37, gb_free=11.9, wall=1476
2022-03-23 12:04:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 12:05:10 | INFO | train_inner | epoch 015:    107 / 157 loss=9.155, ppl=569.99, wps=66026.7, ups=2.64, wpb=24972, bsz=1022.6, num_updates=2300, lr=0.0002875, gnorm=0.713, loss_scale=4, train_wall=37, gb_free=11.9, wall=1514
2022-03-23 12:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:33 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical rays.
2022-03-23 12:05:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:05:37 | INFO | fairseq.tasks.translation | example hypothesis: and then it can be about 8,000 places in the restaurant.
2022-03-23 12:05:37 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:05:41 | INFO | fairseq.tasks.translation | example hypothesis: i can also have this magnetic magnetic, of course, i can also get a bible bible.
2022-03-23 12:05:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:05:45 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his father had learned with his mother, when she was pregnant with him.
2022-03-23 12:05:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:05:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is died in aids and died a child, so we said, what do we do with their child?
2022-03-23 12:05:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:05:54 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like the equation, and not talk about the nuclear weapons of poverty or other weapons.
2022-03-23 12:05:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:05:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magnetic magnetic magnetic field in the field, but if you don't want to move it, if you don't need your movements, and you don't need to move your movements.
2022-03-23 12:05:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:06:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional reflection of traditional face, and we can start to start with a big form of the form of the form of the form of the shape, and the information, and the information that's the information of the information, and the information that's what's going to start through it's going on.
2022-03-23 12:06:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we have interesting, and it's interesting for me to be here to be here for tedson, "yes, that it was the best time."
2022-03-23 12:06:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still to use the mother of the mother, and a big design of design that we had to solve our plane, that we had to solve a unique way that we had to solve a unique way that we had to solve a unique source of it, and we had to solve it, to solve it, to solve, and if you had to solve a unique source of the
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:06:09 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.205 | ppl 1180.17 | bleu 16.42 | wps 4483.9 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.42
2022-03-23 12:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:06:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.42) (writing took 1.7853663987480104 seconds)
2022-03-23 12:06:11 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:06:11 | INFO | train | epoch 015 | loss 9.107 | ppl 551.29 | wps 38644.5 | ups 1.54 | wpb 25119 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.687 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1575
KL Stats: Epoch 15 Divergences: Uniform: 1.1334246391167087 Unigram: 1.0082094779198438
2022-03-23 12:06:11 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:06:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:06:31 | INFO | train_inner | epoch 016:     50 / 157 loss=9.09, ppl=544.92, wps=31464.5, ups=1.24, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=0.639, loss_scale=4, train_wall=37, gb_free=12.5, wall=1594
2022-03-23 12:07:08 | INFO | train_inner | epoch 016:    150 / 157 loss=8.864, ppl=465.95, wps=67259.4, ups=2.68, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=0.688, loss_scale=4, train_wall=37, gb_free=11.9, wall=1632
2022-03-23 12:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical chemical chemical rays.
2022-03-23 12:07:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example hypothesis: and then it can be about 8,000 places in the restaurant in the restaurant.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example hypothesis: these magnetic magnetic magnetic magnetic magnetic, of course, i can also make a popular bible.
2022-03-23 12:07:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:07:26 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had learned his mother when she was pregnant with him.
2022-03-23 12:07:26 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and one of aids, so we asked us good, what do we do with her?
2022-03-23 12:07:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:07:35 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talk about nuclear weapons or nuclear weapons or nuclear weapons.
2022-03-23 12:07:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:07:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic magnetic magnetic magnetic magnetic lines in the field, but the susususus don't move their movements, and if you don't need your movements, you need energy and so forth.
2022-03-23 12:07:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face of traditional face, the big face of the face of the face of the face, and there's a real shape of the structure of the structure, and the whole structure of the structure, and the whole structure, which is all the structure of the information, and the information, which is a whole structure, and the structure, and the information that we can
2022-03-23 12:07:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measure it for me to be here for tedtedwomen, yes, yes, yes, the best time she said, "well, somebody said," well, if we're going to support them and then we're going to support them, we're going to support them in this time. "
2022-03-23 12:07:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a great design of design that we're working on our plane, and we had to solve the aircraft, a unique result that we had to solve all the problems that we had to solve the air system, and we had to be connected to the air.
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:50 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.085 | ppl 1086.35 | bleu 18.25 | wps 4623.4 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 18.25
2022-03-23 12:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 18.25) (writing took 1.8113956307061017 seconds)
2022-03-23 12:07:52 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:07:52 | INFO | train | epoch 016 | loss 8.934 | ppl 489.19 | wps 39174.5 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.672 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1675
KL Stats: Epoch 16 Divergences: Uniform: 1.1610719264936424 Unigram: 1.032786993508347
2022-03-23 12:07:52 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:28 | INFO | train_inner | epoch 017:     93 / 157 loss=8.711, ppl=419.14, wps=32374.7, ups=1.25, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=0.587, loss_scale=4, train_wall=38, gb_free=12, wall=1711
2022-03-23 12:08:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:55 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical chemical.
2022-03-23 12:08:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:08:59 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 8,000 places in the restaurant.
2022-03-23 12:08:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can also, of course, of course, of course, i can also make a popular bible.
2022-03-23 12:09:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:09:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother, because his mother had learned when she was pregnant with him.
2022-03-23 12:09:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin has died and died in aids, and a waisy child, so we asked us good, what do we do with them?
2022-03-23 12:09:12 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:09:17 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to spend things about things like gender times, and not talking about nuclear weapons or nuclear weapons, or every other topic.
2022-03-23 12:09:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:09:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic field of magnetic magnetic lines in the field of magnetic lines, but the sususus don't like it, if you need your movements, and so you need your movements.
2022-03-23 12:09:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:09:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection of reflection, we can start with a traditional facial facial facial factors, and we can start using it through the shape of the information, and the whole structure, and the whole structure of all the structure.
2022-03-23 12:09:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting to measure it for me here for tedwomen in tedwomen, is that... yes, the best one said, "if we're going to help them to support them," and then we're going to support them to support them, "and then we're going to support them to support them to support them."
2022-03-23 12:09:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:32 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big part of design design design work on our plane, we had to solve a result that we had to solve all the problems that we had to solve the problems that it was to be connected to the ground -- all the way to us to the soil, and it's all the way to the way that it's a recoordinated with the way that we have to the way to the way to the way that it is that it is to the way that it was to the way that it is to the air, or to the way that it's a remove on the way that it is to the way that it is to the way that it's a coordination of the air, or to the air.
2022-03-23 12:09:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:32 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.035 | ppl 1049.5 | bleu 19.48 | wps 4428.1 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.48
2022-03-23 12:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:09:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.48) (writing took 1.7680619610473514 seconds)
2022-03-23 12:09:34 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:09:34 | INFO | train | epoch 017 | loss 8.77 | ppl 436.54 | wps 38662.9 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.604 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1778
KL Stats: Epoch 17 Divergences: Uniform: 1.1863656779249103 Unigram: 1.0545821386997096
2022-03-23 12:09:34 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:09:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:48 | INFO | train_inner | epoch 018:     36 / 157 loss=8.777, ppl=438.57, wps=30475.8, ups=1.25, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=0.639, loss_scale=4, train_wall=36, gb_free=12.2, wall=1792
2022-03-23 12:10:26 | INFO | train_inner | epoch 018:    136 / 157 loss=8.642, ppl=399.57, wps=67264.2, ups=2.63, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=0.6, loss_scale=4, train_wall=38, gb_free=11.8, wall=1830
2022-03-23 12:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:38 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:10:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:10:42 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:10:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:10:46 | INFO | fairseq.tasks.translation | example hypothesis: and i can also make these magnetic magnetic magnetic magnets, of course, of course, i can also make a popular bible.
2022-03-23 12:10:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:10:50 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had never learned his mother had been pregnant.
2022-03-23 12:10:50 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:10:54 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and a wavela child, so we said, well, what do we do with her?
2022-03-23 12:10:54 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:10:58 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times, and not about nuclear times or nuclear weapons.
2022-03-23 12:10:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:11:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic magnetic field in the field of magnetic lines, but the susuck doesn't like it, if you don't need your movements, you need your energy, and so you need your energy disorders.
2022-03-23 12:11:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:11:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can start with a traditional face that can start with a traditional face, and the real shape of the information, which is all the structure, and the structure of the structure and all the structure.
2022-03-23 12:11:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:11:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure, for me, for me, for tedwomen, is that... "
2022-03-23 12:11:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:11:13 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big part of the design work that we're working on on our plane was a result that we had to solve all the kinds of problems that we had to be connected to the ground of the ground, and it's all of us.
2022-03-23 12:11:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:11:13 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.857 | ppl 927.15 | bleu 21.2 | wps 4672.7 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.2
2022-03-23 12:11:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:11:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:11:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:11:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.2) (writing took 1.7881236360408366 seconds)
2022-03-23 12:11:14 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:11:14 | INFO | train | epoch 018 | loss 8.664 | ppl 405.59 | wps 39336.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.622 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 1878
KL Stats: Epoch 18 Divergences: Uniform: 1.203851448719926 Unigram: 1.06072895742572
2022-03-23 12:11:15 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:11:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:45 | INFO | train_inner | epoch 019:     79 / 157 loss=8.704, ppl=417.03, wps=31170, ups=1.27, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=0.592, loss_scale=4, train_wall=36, gb_free=11.8, wall=1908
2022-03-23 12:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:18 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:12:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:12:22 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:12:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:12:25 | INFO | fairseq.tasks.translation | example hypothesis: i can also, of course, of course, to make a popular form.
2022-03-23 12:12:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:12:29 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother, when she was pregnant.
2022-03-23 12:12:29 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:12:33 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and we asked us, so what do we do with her?
2022-03-23 12:12:33 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:12:37 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time to talk about things like gender times and not talking about nuclear weapons or weapons.
2022-03-23 12:12:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:12:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magic lines in the inside of the inside, but the sususualalegon doesn't like it, if they need their movements, and they need their movements.
2022-03-23 12:12:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big face of the face, and the shape of the face of the face.
2022-03-23 12:12:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here is that... "
2022-03-23 12:12:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design that we're using in the aircraft, or if we had to solve a result of it, we had to solve the unique problems that we had to solve the unique problems.
2022-03-23 12:12:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:51 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.813 | ppl 899.72 | bleu 20.5 | wps 4966.7 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.2
2022-03-23 12:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:12:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:12:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 19 @ 2978 updates, score 20.5) (writing took 0.7855384689755738 seconds)
2022-03-23 12:12:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:12:52 | INFO | train | epoch 019 | loss 8.546 | ppl 373.7 | wps 40646.8 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.57 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 1975
KL Stats: Epoch 19 Divergences: Uniform: 1.2205596612199465 Unigram: 1.0726302592281538
2022-03-23 12:12:52 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:00 | INFO | train_inner | epoch 020:     22 / 157 loss=8.547, ppl=374, wps=33174.2, ups=1.32, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.551, loss_scale=4, train_wall=37, gb_free=12.7, wall=1984
2022-03-23 12:13:38 | INFO | train_inner | epoch 020:    122 / 157 loss=8.244, ppl=303.2, wps=68218, ups=2.63, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.518, loss_scale=4, train_wall=38, gb_free=22.3, wall=2022
2022-03-23 12:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:13:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:13:59 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in restaurant.
2022-03-23 12:13:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:14:03 | INFO | fairseq.tasks.translation | example hypothesis: i can also expanding a popular bike.
2022-03-23 12:14:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:14:06 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother when she was pregnant.
2022-03-23 12:14:06 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:14:10 | INFO | fairseq.tasks.translation | example hypothesis: so one of my cousins is died and a wash child, so we asked what do we do with her?
2022-03-23 12:14:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:14:14 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times, and not about nuclear weapons or poverty or any other issue.
2022-03-23 12:14:14 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:14:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are starting in the inside the inside, but the superconductor doesn't like it, if they need energy, and so they need their energy movements, and so they need their movements.
2022-03-23 12:14:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:14:23 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial, the big factors of the face, and the real shape of the face, and the real shape of the face, and the whole information, and the whole information that can fold the whole structure and fold all the structure of this structure.
2022-03-23 12:14:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here at tedwomen, is that... yes, when it was the best. "
2022-03-23 12:14:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we had to solve the mother of invention, and a big part of the design work that we use on the plane was a result that we had to solve the unique problems that we had to solve all the problems that were connected to the ground -- to the ground -- all of the way -- and a continued to use it to use all the way to use it was to use it from the refrifrigergeration of the refrigeration of the refrigeration of the refrigeration of design system, either.
2022-03-23 12:14:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:30 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.723 | ppl 845.16 | bleu 22.37 | wps 4763.6 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.37
2022-03-23 12:14:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:14:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:14:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.37) (writing took 1.8851648708805442 seconds)
2022-03-23 12:14:31 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:14:31 | INFO | train | epoch 020 | loss 8.43 | ppl 344.94 | wps 39573.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.532 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2075
KL Stats: Epoch 20 Divergences: Uniform: 1.2285858111432684 Unigram: 1.0844650161566862
2022-03-23 12:14:32 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:57 | INFO | train_inner | epoch 021:     65 / 157 loss=8.545, ppl=373.6, wps=31530, ups=1.28, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.544, loss_scale=4, train_wall=37, gb_free=12.8, wall=2100
2022-03-23 12:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:35 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:15:35 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:15:39 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:15:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:15:43 | INFO | fairseq.tasks.translation | example hypothesis: i can also expanding that rough magnets, of course, to form a popular bike.
2022-03-23 12:15:43 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:15:46 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 12:15:46 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:15:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousinis died in aids, and has a wais-child, so we asked us what do we do with her?
2022-03-23 12:15:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:15:54 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or poverty or any other topic.
2022-03-23 12:15:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:15:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bold field of magnetic field in the inside, but the superconductor doesn't like it when you move, your movements, and so the suck disorder.
2022-03-23 12:15:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:16:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big configuration of the face and the basic form of the face, and the basic form of the face, and the information, and by the one, and the whole structure.
2022-03-23 12:16:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:16:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen, is that... well, when i was deployed, it was the best, when someone said, "stop the men in a table and say," if we're going to support you. "
2022-03-23 12:16:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:16:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our plane was a result that we had to solve the unique problems so that it was connected to the ground -- to use everything from a continuing and refrigering system to use it.
2022-03-23 12:16:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:16:07 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.6 | ppl 776.17 | bleu 24.77 | wps 5063.5 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 24.77
2022-03-23 12:16:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:16:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:16:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 24.77) (writing took 1.8043952519074082 seconds)
2022-03-23 12:16:09 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:16:09 | INFO | train | epoch 021 | loss 8.341 | ppl 324.29 | wps 40556.3 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.499 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2172
KL Stats: Epoch 21 Divergences: Uniform: 1.2384521946764988 Unigram: 1.0937014828452742
2022-03-23 12:16:09 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:12 | INFO | train_inner | epoch 022:      8 / 157 loss=8.227, ppl=299.72, wps=33459.3, ups=1.32, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.476, loss_scale=4, train_wall=37, gb_free=12.4, wall=2176
2022-03-23 12:16:50 | INFO | train_inner | epoch 022:    108 / 157 loss=8.257, ppl=305.87, wps=67145.2, ups=2.66, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.509, loss_scale=4, train_wall=37, gb_free=12, wall=2213
2022-03-23 12:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:17:12 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:17:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:17:16 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can protect about 8,000 places in the restaurant.
2022-03-23 12:17:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:17:19 | INFO | fairseq.tasks.translation | example hypothesis: i can also expanding these smooth magnetic magnetic magnetic magnetic magnets.
2022-03-23 12:17:19 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:17:23 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 12:17:23 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:17:27 | INFO | fairseq.tasks.translation | example hypothesis: one of my couples died in aids and have an orphanage child, so we asked us what do we do with her?
2022-03-23 12:17:27 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:17:31 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not talking about nuclear weapons or poverty.
2022-03-23 12:17:31 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are starting in the inside, but the superconductor doesn't like if you move your energy, because your movements need your energy, and the superconductor disorders.
2022-03-23 12:17:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face of the face of the real face and the basic shape of the face, and rerepeat it by the one of the information that makes the ports and fold.
2022-03-23 12:17:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen is that... yes, when he said it was the best dinner, when someone said, "turn you to the men."
2022-03-23 12:17:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're on our plane was a result that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground.
2022-03-23 12:17:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:42 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.671 | ppl 815.19 | bleu 20.32 | wps 5439.3 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.77
2022-03-23 12:17:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:17:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:17:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:17:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 22 @ 3449 updates, score 20.32) (writing took 0.7875719778239727 seconds)
2022-03-23 12:17:43 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:17:43 | INFO | train | epoch 022 | loss 8.269 | ppl 308.47 | wps 42056 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.508 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2266
KL Stats: Epoch 22 Divergences: Uniform: 1.2408792198174483 Unigram: 1.1011097860384107
2022-03-23 12:17:43 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:17:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:18:02 | INFO | train_inner | epoch 023:     51 / 157 loss=8.169, ppl=287.82, wps=34760.9, ups=1.38, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.494, loss_scale=4, train_wall=37, gb_free=12.9, wall=2286
2022-03-23 12:18:40 | INFO | train_inner | epoch 023:    151 / 157 loss=8.322, ppl=320.13, wps=66233.2, ups=2.67, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.483, loss_scale=4, train_wall=37, gb_free=12, wall=2323
2022-03-23 12:18:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:46 | INFO | fairseq.tasks.translation | example hypothesis: it can't use chemical rockets.
2022-03-23 12:18:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:18:50 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:18:50 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:18:54 | INFO | fairseq.tasks.translation | example hypothesis: so i can also expand this round magnetic magnetic, of course, to shape a popular equation.
2022-03-23 12:18:54 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:18:58 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:18:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:19:02 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died in aids, and has a wash child left, so we asked us, well, what do we do with them?
2022-03-23 12:19:02 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:19:06 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equally gender times, and not about the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:19:06 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:19:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic field of magnetic field are caught in the inside, but the superconductor doesn't like it when you move, because your movements need energy, and the superconductor disorders.
2022-03-23 12:19:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:19:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big configuration of the face and the basic shape, and by the themes of the information that the ports and fold all the structure.
2022-03-23 12:19:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to be here at tedwomen, is that... well, when it became striking dinner, when someone said, "turn you to the men on your table and say," if the revolution starts to support you, "and then the truth is," we've already been supporting you, "
2022-03-23 12:19:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:22 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of invention is still the mother of invention, and a big part of the design work that we're on the plane of our toys, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and the continuity of a refrigeration system, and it allows us to see that when we're either in the
2022-03-23 12:19:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:22 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.459 | ppl 703.65 | bleu 27.39 | wps 4630.2 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.39
2022-03-23 12:19:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:19:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:19:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.39) (writing took 1.8349419957958162 seconds)
2022-03-23 12:19:24 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:19:24 | INFO | train | epoch 023 | loss 8.198 | ppl 293.61 | wps 39135.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.471 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2367
KL Stats: Epoch 23 Divergences: Uniform: 1.2463303359838238 Unigram: 1.1048794323016473
2022-03-23 12:19:24 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:59 | INFO | train_inner | epoch 024:     94 / 157 loss=8.079, ppl=270.47, wps=31543.8, ups=1.25, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.422, loss_scale=4, train_wall=37, gb_free=12.1, wall=2403
2022-03-23 12:20:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example hypothesis: these sonic rockets can't use chemical rockets.
2022-03-23 12:20:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 12:20:31 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these round magnets to form a popular equation.
2022-03-23 12:20:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died in aids, and we asked a waisine child, so what do we do with her?
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like equally gender times, and not about genocid or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:20:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:20:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field may be caught in the inside, but the superconductor doesn't like when they're moving, because their movements need, and so the superconductor disorder.
2022-03-23 12:20:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big contexture of the face, and the basic shape of the face, and the whole portion of the structure and all a fold.
2022-03-23 12:20:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measure the revolution, for me to be here at tedwomen, is that... tyes, it was the best combined when someone said, "turn you to the men in a spring and tell you," if we're supporting the truth. "
2022-03-23 12:20:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:59 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on at our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuing system that allows us to see that it's a fluid system, and it allows us to use it into a special machine.
2022-03-23 12:20:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:59 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.452 | ppl 700.27 | bleu 27.08 | wps 5052.4 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.39
2022-03-23 12:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:20:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 24 @ 3763 updates, score 27.08) (writing took 0.8375776801258326 seconds)
2022-03-23 12:21:00 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:21:00 | INFO | train | epoch 024 | loss 8.12 | ppl 278.17 | wps 40896.1 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.449 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2464
KL Stats: Epoch 24 Divergences: Uniform: 1.2490414678550243 Unigram: 1.1117671608414008
2022-03-23 12:21:01 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:21:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:14 | INFO | train_inner | epoch 025:     37 / 157 loss=8.209, ppl=295.85, wps=33182.6, ups=1.34, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.477, loss_scale=4, train_wall=37, gb_free=12.8, wall=2478
2022-03-23 12:21:52 | INFO | train_inner | epoch 025:    137 / 157 loss=8.02, ppl=259.59, wps=67224, ups=2.65, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.437, loss_scale=4, train_wall=37, gb_free=11.9, wall=2516
2022-03-23 12:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:22:03 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:22:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:22:07 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can take about 8,000 places in the restaurant.
2022-03-23 12:22:07 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:22:11 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can also expand to form a popular comparison.
2022-03-23 12:22:11 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:22:15 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:22:15 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:22:19 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died on aids, and we asked a waisena child, so what do we do with her?
2022-03-23 12:22:19 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:22:23 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equally gender times, and not about genocid or the spread of nuclear weapons or poverty or every other topic.
2022-03-23 12:22:23 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:22:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are caught by magnetic field lines in the inside, but the superconductor doesn't like it when they move, because their movements need energy, and so the superconductor disorders.
2022-03-23 12:22:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can start the big constructions of the face, and the basic form of information that comes from the whole porter structure, which is a fold.
2022-03-23 12:22:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen, is that... t.d., it was already supported to you.
2022-03-23 12:22:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane on the stones, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation to surgery -- everything from a continuous variation, all of a continuing system, and it allows us to see that if you use the energy system, you use it to use the system, you can use it in the solar system, or you can use it in the solar system.
2022-03-23 12:22:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:38 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.386 | ppl 669.28 | bleu 28.55 | wps 4681.3 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.55
2022-03-23 12:22:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:22:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:22:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:22:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.55) (writing took 1.8343397323042154 seconds)
2022-03-23 12:22:40 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:22:40 | INFO | train | epoch 025 | loss 8.066 | ppl 268.05 | wps 39567.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.44 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2563
KL Stats: Epoch 25 Divergences: Uniform: 1.25219982412462 Unigram: 1.1131203148144453
2022-03-23 12:22:40 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:22:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:23:10 | INFO | train_inner | epoch 026:     80 / 157 loss=7.939, ppl=245.4, wps=32347.2, ups=1.28, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.433, loss_scale=4, train_wall=37, gb_free=12.2, wall=2594
2022-03-23 12:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:43 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:23:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:23:47 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 12:23:47 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:23:51 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that smoke, of course, to shape a popular equation.
2022-03-23 12:23:51 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:23:55 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:23:55 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:23:59 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousines has died of aids, and we've left a waisena child, so we asked us, well, what do we do with her?
2022-03-23 12:23:59 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:24:03 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equality, and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:24:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:24:07 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnet lines are captured in the inner, but the superconductor doesn't like it when they move, they need their movements, and so the superconductive disorder.
2022-03-23 12:24:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:24:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the facial and the basic shape, and by the theast, which is the whole portion structure and all fold a fold.
2022-03-23 12:24:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen is that... well, when strikes dinner, it was the best summarized when somebody said, "turn you to men at a table and tell you," if the revolution starts. "
2022-03-23 12:24:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:16 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of the design work that we're on our airplane is the most proud of it that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and refrigeration system that allows us to use.
2022-03-23 12:24:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:16 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.34 | ppl 648.05 | bleu 28.84 | wps 5030.2 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.84
2022-03-23 12:24:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:24:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:24:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.84) (writing took 1.8205946320667863 seconds)
2022-03-23 12:24:18 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:24:18 | INFO | train | epoch 026 | loss 8.011 | ppl 258.03 | wps 40290.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.422 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2661
KL Stats: Epoch 26 Divergences: Uniform: 1.2515774284032892 Unigram: 1.1173660366569442
2022-03-23 12:24:18 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:24:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:27 | INFO | train_inner | epoch 027:     23 / 157 loss=8.014, ppl=258.44, wps=32872, ups=1.3, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.426, loss_scale=4, train_wall=37, gb_free=11.8, wall=2671
2022-03-23 12:25:05 | INFO | train_inner | epoch 027:    123 / 157 loss=8, ppl=256.01, wps=66389.5, ups=2.66, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.372, loss_scale=4, train_wall=37, gb_free=12.3, wall=2708
2022-03-23 12:25:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:21 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:25:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:25:25 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 12:25:25 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this rough magnets, of course, to shape a popular equilibrium.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:25:33 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:25:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:25:37 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousinen has died on aids, and let's leave an orphanage, so we asked us, well, what do we do with her?
2022-03-23 12:25:37 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like the gender high times, and not genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:25:41 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field are caught in the inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting disorder.
2022-03-23 12:25:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big constructions of the face and the basic form of the facial and the basic form of information that the whole portion structure and all fold a fold.
2022-03-23 12:25:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measured to me here at tedwomen is that... well, when dinner was put together best, when someone said, "take you to the men at a table and say," if the revolution starts to help you. "
2022-03-23 12:25:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a cooling system that allows us to stop using an aircraft, if you're either going to be able to use the
2022-03-23 12:25:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:56 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.279 | ppl 621.44 | bleu 29.6 | wps 4733.9 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.6
2022-03-23 12:25:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:25:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:25:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:25:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.6) (writing took 1.841951169539243 seconds)
2022-03-23 12:25:58 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:25:58 | INFO | train | epoch 027 | loss 7.946 | ppl 246.65 | wps 39638.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.39 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 2761
KL Stats: Epoch 27 Divergences: Uniform: 1.2536436635457886 Unigram: 1.1222124646173637
2022-03-23 12:25:58 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:25:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:23 | INFO | train_inner | epoch 028:     66 / 157 loss=7.899, ppl=238.72, wps=32448.5, ups=1.28, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.425, loss_scale=4, train_wall=37, gb_free=12.1, wall=2787
2022-03-23 12:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:27:01 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:27:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:27:05 | INFO | fairseq.tasks.translation | example hypothesis: it can occur about 8,000 places in the restaurant.
2022-03-23 12:27:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:27:09 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnets, of course, to shape a popular equilibrium.
2022-03-23 12:27:09 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:27:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:27:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousinen has died of aids and left a orphanage, so we asked us, well, what do we do with her?
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:27:21 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-23 12:27:21 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:27:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field are caught in the inside, but the superconductor doesn't like it when you move, because your movements use, and so the superconductor disorder disorder.
2022-03-23 12:27:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that can recover the big constructions of the face and the basic shape, and by theft this information that refits the whole portion structure and all an fold.
2022-03-23 12:27:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that... tyes, when the striking dinner was summared to be the best, when someone said, "turn you to the men at your table and tell you," if the revolution starts to support you. "the truth is that women, we've already been supporting you for that long time."
2022-03-23 12:27:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:35 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we are on our airplane on the stones was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft, or either if you look at the propellment, or a mechanism, you're going to see the truck, or you're going to see the truck, or you're either going to have to have to have a mechanism, or you're either, you're going to have to have to have to have to have a mechanism.
2022-03-23 12:27:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:35 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.256 | ppl 611.24 | bleu 30.28 | wps 4774.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.28
2022-03-23 12:27:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:27:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:27:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.28) (writing took 1.8082954711280763 seconds)
2022-03-23 12:27:37 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:27:37 | INFO | train | epoch 028 | loss 7.915 | ppl 241.31 | wps 39766 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.403 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2860
KL Stats: Epoch 28 Divergences: Uniform: 1.251708053321933 Unigram: 1.1242226008112681
2022-03-23 12:27:37 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:27:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:27:41 | INFO | train_inner | epoch 029:      9 / 157 loss=7.892, ppl=237.48, wps=32279.7, ups=1.28, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.362, loss_scale=4, train_wall=37, gb_free=12.3, wall=2864
2022-03-23 12:28:19 | INFO | train_inner | epoch 029:    109 / 157 loss=7.854, ppl=231.4, wps=67161.3, ups=2.66, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.394, loss_scale=4, train_wall=37, gb_free=12.7, wall=2902
2022-03-23 12:28:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:41 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:28:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:28:44 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:28:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:28:48 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets to form a popular equation.
2022-03-23 12:28:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:28:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 12:28:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender high times, and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:29:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:29:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 12:29:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:29:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial constructions of the face and the basic shape, and refuse it by theft information that includes the whole portion structure and all the ffits.
2022-03-23 12:29:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measuring it for me here at tedwomen is that... well, when dinner turned it out to be the best together when someone said, "turn you to the men at your table, and then we support the revolution, and then the truth is that women, for me, we've already started, and then we've been supporting you."
2022-03-23 12:29:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:15 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we're on our plane on our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variation and a system that allows us to use it, that it allows us to use it in the aircraft, and it allows us to use it to use it in the aircraft, in the aircraft, in the stairs, or the staircase, and it's either, and it's a mechanism, to get the most fluid traffic, or a mechanism, and it's either, and it's a mechanism.
2022-03-23 12:29:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.26 | ppl 613.3 | bleu 30.05 | wps 4787 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.28
2022-03-23 12:29:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:29:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:29:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:29:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 29 @ 4548 updates, score 30.05) (writing took 0.7797439657151699 seconds)
2022-03-23 12:29:16 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:29:16 | INFO | train | epoch 029 | loss 7.861 | ppl 232.49 | wps 40007.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.38 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 2959
KL Stats: Epoch 29 Divergences: Uniform: 1.2550668096682531 Unigram: 1.1318634953540143
2022-03-23 12:29:16 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:29:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:36 | INFO | train_inner | epoch 030:     52 / 157 loss=7.85, ppl=230.64, wps=32296.7, ups=1.3, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.381, loss_scale=4, train_wall=37, gb_free=12.5, wall=2979
2022-03-23 12:30:13 | INFO | train_inner | epoch 030:    152 / 157 loss=7.845, ppl=229.92, wps=67168.8, ups=2.67, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.358, loss_scale=4, train_wall=37, gb_free=12.1, wall=3017
2022-03-23 12:30:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:30:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:30:23 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:30:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:30:27 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to expand any glider.
2022-03-23 12:30:27 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:30:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:30:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a waisena child, so we asked ourselves, well, what do we do with her?
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like equal high times, not about genocide or the prevalence of nuclear weapons or poverty or any other topic.
2022-03-23 12:30:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught in the inside, but the superconductor doesn't like it when you move your movements, and so the superconducting disorders.
2022-03-23 12:30:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can recover the big constructions of the face and the basic form of information that refuse the whole porter structure and all the fers.
2022-03-23 12:30:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and measured for me to be here at tedwomen, is that... tyes, when the dinner dinner was put it up to the top, "turn you to the men on your table and then we're going to support you."
2022-03-23 12:30:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on on our airplane was the most stumbling, a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system, that allows us to use an airplane in the air, to either be able to solve the same way, or if you're going to see the mechanism, or if you're going to solve the wheel, or if you're going to have to have to get the wheel, you're going to have to have to have the wheel, you're going to have to see the wheel, or you're going to have to have to have to have to have to have to have a mechanism, or you're going to have to have to have to have to have to have to have to have the wheel, you're going to do it, you're going to get it, you're going to get it, or
2022-03-23 12:30:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:55 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.173 | ppl 577.37 | bleu 31.38 | wps 4601.2 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.38
2022-03-23 12:30:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:30:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:30:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.38) (writing took 1.8058653357438743 seconds)
2022-03-23 12:30:56 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:30:56 | INFO | train | epoch 030 | loss 7.825 | ppl 226.72 | wps 39209.8 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.37 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3060
KL Stats: Epoch 30 Divergences: Uniform: 1.2527558132562602 Unigram: 1.1306701231583391
2022-03-23 12:30:57 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:30:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:33 | INFO | train_inner | epoch 031:     95 / 157 loss=7.816, ppl=225.37, wps=31509.5, ups=1.26, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.366, loss_scale=4, train_wall=37, gb_free=12.6, wall=3096
2022-03-23 12:31:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:32:04 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:32:04 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:32:08 | INFO | fairseq.tasks.translation | example hypothesis: this round magnet, of course, can expand to form a popular equilibrium.
2022-03-23 12:32:08 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:32:12 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:32:12 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or poverty or any other topic.
2022-03-23 12:32:20 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnet field lines are captured inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 12:32:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which gives the big contextures of the face and the basic shape, and by theft, which includes the whole portion of this reflection and all of the ffits.
2022-03-23 12:32:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when a strictly dinner, it was the best summarized when someone said, "turn you to the men at your table and tell you, if the revolution begins, then we support you.
2022-03-23 12:32:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are most proud of at our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration and a cooling system that allows us to use an aircraft at the same time when you can see the most of the propelled, and either the most efficient, to the most sophisticated, if you can see the most sophisticated, or the most sophisticated, or the most of a mechanism, or the most of a mechanism, if you can see the.
2022-03-23 12:32:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:35 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.188 | ppl 583.15 | bleu 31.5 | wps 4674.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.5
2022-03-23 12:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:32:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:32:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:32:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.5) (writing took 1.7877611787989736 seconds)
2022-03-23 12:32:36 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:32:36 | INFO | train | epoch 031 | loss 7.786 | ppl 220.64 | wps 39436.1 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.371 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 3160
KL Stats: Epoch 31 Divergences: Uniform: 1.253198603317166 Unigram: 1.1341433088490662
2022-03-23 12:32:37 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:32:51 | INFO | train_inner | epoch 032:     38 / 157 loss=7.722, ppl=211.16, wps=32255.7, ups=1.28, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.386, loss_scale=4, train_wall=37, gb_free=13.1, wall=3175
2022-03-23 12:33:29 | INFO | train_inner | epoch 032:    138 / 157 loss=7.721, ppl=211.02, wps=67117.3, ups=2.65, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.328, loss_scale=4, train_wall=37, gb_free=12.3, wall=3212
2022-03-23 12:33:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:40 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:33:40 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:33:44 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:33:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:33:48 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnet, of course, to shape a popular glimpse.
2022-03-23 12:33:48 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:33:52 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 12:33:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage child, so we asked us, well, what do we do with her?
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 12:34:00 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field are captured in the inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:34:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection of reflection, we can start with a traditional facial, which gives the big conscores of facial and the basic form, and refers it through the theft of the information that refers the whole porter structure and all the wrinkles.
2022-03-23 12:34:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate for me to be here at tedwomen here at tedwomen, is that... tyes, the dinner dinner was really summarized best when somebody said, "turn you to the men at your table and say to them," if the revolution begins, then we support you. "'" the truth, women love is that we've already started with you at this long time. "
2022-03-23 12:34:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our plane was the most stumbling result that we had to solve the unique problems that were connected to it -- everything, from a continuous variation and a refrigeration system of liquid, that allows us to use an aircraft in the aircraft to either be able to get rid of the propelled or a mechanical transportation, or a mechanical device, or a mechanical device that's either to operate in the same way that's been connected to a mechanism.
2022-03-23 12:34:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:14 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.142 | ppl 564.77 | bleu 31.43 | wps 4773.5 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.5
2022-03-23 12:34:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:34:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:34:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:34:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.43) (writing took 0.8149282289668918 seconds)
2022-03-23 12:34:15 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:34:15 | INFO | train | epoch 032 | loss 7.75 | ppl 215.27 | wps 40175.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.349 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3258
KL Stats: Epoch 32 Divergences: Uniform: 1.2529800062629566 Unigram: 1.1368658316145397
2022-03-23 12:34:15 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:34:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:46 | INFO | train_inner | epoch 033:     81 / 157 loss=7.768, ppl=217.92, wps=32573, ups=1.3, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.345, loss_scale=4, train_wall=37, gb_free=11.6, wall=3289
2022-03-23 12:35:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:18 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:35:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:35:22 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:35:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:35:26 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand that round magnets, of course, to shape any glimpse.
2022-03-23 12:35:26 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:35:30 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 12:35:30 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:35:34 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and we left an orphanage, so we said, well, what do we do with it?
2022-03-23 12:35:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:35:38 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs, not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:35:38 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:35:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are captured in the inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 12:35:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial confront of the face and the basic shape, and the basic form of information that comes from the entire portion structure, and we can start to fold all the wrinkles.
2022-03-23 12:35:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:35:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate for me to be here at tedwomen, is that... tyes, when strikes dinner, it's the best summarized when someone said, "turn you to the men at your table and tell you, 'when the revolution begins, then we support you.' 'if the truth is that women, we already have a long time to support you.'
2022-03-23 12:35:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're stumbling at our airplane, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuously varied variation and a refrigerator system that allows us to use a steady machine to the wheel.
2022-03-23 12:35:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:35:52 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.149 | ppl 567.64 | bleu 31.81 | wps 4803.2 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.81
2022-03-23 12:35:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:35:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:35:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:35:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.81) (writing took 1.806028868071735 seconds)
2022-03-23 12:35:54 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:35:54 | INFO | train | epoch 033 | loss 7.719 | ppl 210.76 | wps 39695.1 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.349 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3358
KL Stats: Epoch 33 Divergences: Uniform: 1.2553112375777233 Unigram: 1.139586848228534
2022-03-23 12:35:55 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:04 | INFO | train_inner | epoch 034:     24 / 157 loss=7.656, ppl=201.67, wps=32334.3, ups=1.29, wpb=25158.1, bsz=1109.5, num_updates=5200, lr=0.000438529, gnorm=0.352, loss_scale=4, train_wall=37, gb_free=12.1, wall=3367
2022-03-23 12:36:41 | INFO | train_inner | epoch 034:    124 / 157 loss=7.705, ppl=208.61, wps=66983.5, ups=2.66, wpb=25147.3, bsz=995.5, num_updates=5300, lr=0.000434372, gnorm=0.366, loss_scale=4, train_wall=37, gb_free=12.1, wall=3405
2022-03-23 12:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:58 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:36:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:37:02 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can talk about 8,000 places in the restaurant.
2022-03-23 12:37:02 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:37:06 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets, i can expand, of course, to form any glimpse.
2022-03-23 12:37:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:37:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:37:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:37:14 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:37:14 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:37:18 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:37:18 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:37:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use, and so the superconductor disorders.
2022-03-23 12:37:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial sscan, which gives the big contextures of the face and the basic shape, and through the theft of the information that refers all the por-structure and all of the wrinkles.
2022-03-23 12:37:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate to be here for me at tedwomen, is that... well, in the strict dinner dinner dinner, it's best summarized when someone said, "turn to the men at your table and say to them," if the revolution starts, we support you. "the truth, women love is that we've already supported you at this topic for a long time."
2022-03-23 12:37:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on our plane, was a result that we had to solve the unique problems that were connected to this -- all, from a continuous variation, and a refrigeration system, that allows us to use an aircraft in the world, to use an aircraft in the go-go-gosh, or a particular result that we're going to be used to be able to be able to operate it at the same time.
2022-03-23 12:37:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:33 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.116 | ppl 554.85 | bleu 32.43 | wps 4696.3 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.43
2022-03-23 12:37:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:37:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:37:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.43) (writing took 1.8117547826841474 seconds)
2022-03-23 12:37:35 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:37:35 | INFO | train | epoch 034 | loss 7.701 | ppl 208.03 | wps 39378.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.352 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3458
KL Stats: Epoch 34 Divergences: Uniform: 1.2549817105730627 Unigram: 1.1410258341547446
2022-03-23 12:37:35 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:38:00 | INFO | train_inner | epoch 035:     67 / 157 loss=7.854, ppl=231.36, wps=31262.3, ups=1.26, wpb=24737.3, bsz=977.8, num_updates=5400, lr=0.000430331, gnorm=0.334, loss_scale=4, train_wall=37, gb_free=12.9, wall=3484
2022-03-23 12:38:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:38:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:38:42 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:38:42 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:38:45 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand that round magnets, of course, to form any glimpse.
2022-03-23 12:38:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:38:49 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:38:49 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:38:53 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:38:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:38:57 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or poverty or any other topic.
2022-03-23 12:38:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:39:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:39:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:39:06 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can restore the big contextures of the face and the basic form of information that includes the whole portion structure and all of the fine folds.
2022-03-23 12:39:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:39:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when strict dinner dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins to support you. "
2022-03-23 12:39:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most proud of at our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously varied variation and a cooling system that allows us to use an aircraft in the aircraft in the gosh traffic until a passenger transportation, or an aircraft, to a particular result that allows us to use.
2022-03-23 12:39:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:12 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.099 | ppl 548.24 | bleu 31.92 | wps 4725.3 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.43
2022-03-23 12:39:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:39:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:39:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:39:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.92) (writing took 0.8028653766959906 seconds)
2022-03-23 12:39:13 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:39:13 | INFO | train | epoch 035 | loss 7.675 | ppl 204.31 | wps 40059.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.342 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3557
KL Stats: Epoch 35 Divergences: Uniform: 1.2536586870767363 Unigram: 1.1434263940987355
2022-03-23 12:39:13 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:39:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:18 | INFO | train_inner | epoch 036:     10 / 157 loss=7.546, ppl=186.89, wps=33126.2, ups=1.3, wpb=25566.1, bsz=1051.8, num_updates=5500, lr=0.000426401, gnorm=0.332, loss_scale=4, train_wall=37, gb_free=12.3, wall=3561
2022-03-23 12:39:55 | INFO | train_inner | epoch 036:    110 / 157 loss=7.532, ppl=185.03, wps=68064, ups=2.65, wpb=25691.2, bsz=1093.6, num_updates=5600, lr=0.000422577, gnorm=0.331, loss_scale=4, train_wall=37, gb_free=11.6, wall=3599
2022-03-23 12:40:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:40:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:40:20 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:40:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:40:24 | INFO | fairseq.tasks.translation | example hypothesis: and i can also expand these round magnets to shape any glider.
2022-03-23 12:40:24 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:40:28 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:40:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:40:32 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:40:32 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:40:37 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:40:37 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:40:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use, and so the superconductor disorders.
2022-03-23 12:40:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:45 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection, we can start with a traditional facial can, which gives the big contextures of the face and the basic form of information that refers the whole porter structure and all the fine wrongs.
2022-03-23 12:40:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:40:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate for me to be here at tedwomen, is that -- well, when it was stripped dinner, it was best summarized when someone said, "turn to the men at your table and tell you," if the revolution begins, then we support you. "'" the truth, women love, we've been supporting you in this topic for a long time. "
2022-03-23 12:40:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:40:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on our airplane is the stumbling, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuously variable variation and refrigeration system with refrigeration that allows us to use an aircraft in the garbage, until a specific manual, to fit the propelled, or a mechanism of the propelled when you look at the same as a mechanism of a mechanism of a mechanism, if you look at the same as a mechanism, if you look at the same as a mechanism of a mechanism of a mechanism, and you look at the same as a mechanized, or a mechanism, and you look at the same time, if you can see the same as a mechanism, if you can either, or a mechanism, and use it's going on the same as a mechanized by a
2022-03-23 12:40:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:40:52 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.088 | ppl 544.17 | bleu 32.8 | wps 4638 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.8
2022-03-23 12:40:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:40:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:40:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:40:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.8) (writing took 1.8363023339770734 seconds)
2022-03-23 12:40:53 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:40:53 | INFO | train | epoch 036 | loss 7.647 | ppl 200.4 | wps 39388.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.334 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3657
KL Stats: Epoch 36 Divergences: Uniform: 1.2539271771870983 Unigram: 1.1450498674495169
2022-03-23 12:40:54 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:40:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:41:14 | INFO | train_inner | epoch 037:     53 / 157 loss=7.772, ppl=218.61, wps=31304.8, ups=1.27, wpb=24594.8, bsz=930.9, num_updates=5700, lr=0.000418854, gnorm=0.327, loss_scale=4, train_wall=36, gb_free=11.8, wall=3677
2022-03-23 12:41:51 | INFO | train_inner | epoch 037:    153 / 157 loss=7.618, ppl=196.5, wps=67247.5, ups=2.68, wpb=25108.7, bsz=1017.4, num_updates=5800, lr=0.000415227, gnorm=0.337, loss_scale=4, train_wall=37, gb_free=12.8, wall=3715
2022-03-23 12:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:57 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:41:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:42:00 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occupy about 8,000 places in the restaurant.
2022-03-23 12:42:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these roles to shape any glider.
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:42:08 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 12:42:08 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:42:13 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids, and left an orphanage child, so we asked, well, what do we do with her?
2022-03-23 12:42:13 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:42:17 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:42:17 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:42:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial sscan, which gives the big contextures of the face and the basic form of information that comes from the whole por-structure and all folds.
2022-03-23 12:42:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in the striking dinner dinner, it was best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins, then we support you. "
2022-03-23 12:42:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:30 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we are most stumbling on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuously varied variables and refrigeration system, that allows us to use an aircraft in the go-transportation to a particular vehicle, either when you're going to be able to get the propelled, or you're going to be able to see the same as you're going to the floor.
2022-03-23 12:42:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:30 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.089 | ppl 544.71 | bleu 32.68 | wps 4896.7 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.8
2022-03-23 12:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:42:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:42:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.68) (writing took 0.7893809671513736 seconds)
2022-03-23 12:42:31 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:42:31 | INFO | train | epoch 037 | loss 7.623 | ppl 197.09 | wps 40529.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.324 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 3754
KL Stats: Epoch 37 Divergences: Uniform: 1.2558994077956722 Unigram: 1.1496626153627985
2022-03-23 12:42:31 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:43:08 | INFO | train_inner | epoch 038:     96 / 157 loss=7.648, ppl=200.53, wps=32573.6, ups=1.31, wpb=24888.9, bsz=988.9, num_updates=5900, lr=0.000411693, gnorm=0.345, loss_scale=4, train_wall=37, gb_free=11.8, wall=3791
2022-03-23 12:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:43:34 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:43:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:43:38 | INFO | fairseq.tasks.translation | example hypothesis: over the year, it can occur about 8,000 places in the restaurant.
2022-03-23 12:43:38 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:43:42 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these round magnets, of course, to shape any same glider.
2022-03-23 12:43:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:43:47 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:43:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:43:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:43:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:43:55 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:43:55 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:43:59 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundings of magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:43:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:44:03 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can start to restore the big contextures of the face and the basic form of information that includes the whole porch structure and all the fine wrinkles.
2022-03-23 12:44:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:44:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was stripped, it was best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins, then we support you. '"the truth is that we've been supporting you for a long time."
2022-03-23 12:44:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously varied variation and a cooling system with liquid coolness that allows us to use an aircraft in the traffic and a particular passenger, which is either when you're going to get rid of a mechanism, or when you're going to see it's going to get rid of a mechanism, you're going on the same way, and you're going to get rid of a mechanism.
2022-03-23 12:44:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:44:09 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.049 | ppl 529.8 | bleu 32.99 | wps 4670.9 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.99
2022-03-23 12:44:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:44:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:44:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 38 @ 5961 updates, score 32.99) (writing took 1.7519888863898814 seconds)
2022-03-23 12:44:11 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:44:11 | INFO | train | epoch 038 | loss 7.608 | ppl 195.09 | wps 39331.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.333 | loss_scale 4 | train_wall 59 | gb_free 11.8 | wall 3855
KL Stats: Epoch 38 Divergences: Uniform: 1.2532862117977157 Unigram: 1.147749508667059
2022-03-23 12:44:12 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:27 | INFO | train_inner | epoch 039:     39 / 157 loss=7.537, ppl=185.7, wps=32338.4, ups=1.27, wpb=25502.7, bsz=1028.5, num_updates=6000, lr=0.000408248, gnorm=0.311, loss_scale=4, train_wall=37, gb_free=11.3, wall=3870
2022-03-23 12:45:04 | INFO | train_inner | epoch 039:    139 / 157 loss=7.586, ppl=192.2, wps=66671.1, ups=2.65, wpb=25165.5, bsz=1001.3, num_updates=6100, lr=0.000404888, gnorm=0.327, loss_scale=4, train_wall=37, gb_free=12, wall=3908
2022-03-23 12:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:15 | INFO | fairseq.tasks.translation | example hypothesis: these probe can't use chemical rockets.
2022-03-23 12:45:15 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:45:18 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:45:18 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:45:22 | INFO | fairseq.tasks.translation | example hypothesis: i can expand these round magnets, of course, to form any same glider.
2022-03-23 12:45:22 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:45:27 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:45:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:45:31 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:45:31 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:45:39 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconduction disturbs.
2022-03-23 12:45:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that will restore the large contextures of the face and the basic form of information that includes the whole porter structure and all the fine folds.
2022-03-23 12:45:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was devoted, it was best summarized when someone said, "turn you to the men at your table and tell them, 'when the revolution begins, we support you.'" the truth, women love you is that we have already been supporting you for a long time. "
2022-03-23 12:45:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continually varied gear and a cooling system of liquid, that allows us to use an aircraft in the stop-transportation to a particular passenger, that either when you're going to get rid of it, or when you're going to be able to see it in the floor, or a mechanism, or if you're going to get rid of a mechanism that's going to get rid of a mechanism, or a mechanism, to get rid of the same way.
2022-03-23 12:45:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:49 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.063 | ppl 534.75 | bleu 32.82 | wps 4770.3 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 32.99
2022-03-23 12:45:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:45:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:45:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:45:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 39 @ 6118 updates, score 32.82) (writing took 0.7771764378994703 seconds)
2022-03-23 12:45:50 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:45:50 | INFO | train | epoch 039 | loss 7.584 | ppl 191.92 | wps 40124.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.32 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 3953
KL Stats: Epoch 39 Divergences: Uniform: 1.2552672855630316 Unigram: 1.153725516247046
2022-03-23 12:45:50 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:45:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:46:21 | INFO | train_inner | epoch 040:     82 / 157 loss=7.585, ppl=191.94, wps=32754.4, ups=1.3, wpb=25232.8, bsz=982.4, num_updates=6200, lr=0.00040161, gnorm=0.33, loss_scale=4, train_wall=37, gb_free=12.8, wall=3985
2022-03-23 12:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:46:53 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:46:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:46:57 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:46:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:47:01 | INFO | fairseq.tasks.translation | example hypothesis: of course, these round magnets, i can expand, of course, to form any glider.
2022-03-23 12:47:01 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:47:05 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father closer, because his father had left his mother when she was pregnant with him.
2022-03-23 12:47:05 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:47:10 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:47:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not talking about genocide or prevalence of nuclear weapons or poverty or any other topic.
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconduction disturbs.
2022-03-23 12:47:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big contextures of the face and the basic form of information that includes the whole porch structure and all the fine wrinkles.
2022-03-23 12:47:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in the striking dinner dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins, then we support you. '"the truth, women love is that we've been supporting you for a long time."
2022-03-23 12:47:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to it on the ground -- everything from a continuously varied variation and a cooling system that allows us to use an aircraft in the stop go-traffic until a particular passenger, or a propelled system that's going to be connected to a mechanism that is either when we're going to be able to be able to operate at the same time.
2022-03-23 12:47:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:29 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.051 | ppl 530.26 | bleu 33.22 | wps 4611.3 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.22
2022-03-23 12:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:47:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:47:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 40 @ 6275 updates, score 33.22) (writing took 1.788168461062014 seconds)
2022-03-23 12:47:30 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:47:30 | INFO | train | epoch 040 | loss 7.567 | ppl 189.56 | wps 39211.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.321 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4054
KL Stats: Epoch 40 Divergences: Uniform: 1.2549061016606138 Unigram: 1.153630852566822
2022-03-23 12:47:31 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:47:40 | INFO | train_inner | epoch 041:     25 / 157 loss=7.665, ppl=202.99, wps=30976.2, ups=1.27, wpb=24410.6, bsz=1075.8, num_updates=6300, lr=0.00039841, gnorm=0.337, loss_scale=4, train_wall=36, gb_free=11.8, wall=4064
2022-03-23 12:48:18 | INFO | train_inner | epoch 041:    125 / 157 loss=7.48, ppl=178.53, wps=67382.9, ups=2.63, wpb=25606.7, bsz=1039.7, num_updates=6400, lr=0.000395285, gnorm=0.353, loss_scale=4, train_wall=38, gb_free=12, wall=4102
2022-03-23 12:48:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:48:34 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:48:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:48:38 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:48:38 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:48:41 | INFO | fairseq.tasks.translation | example hypothesis: and of course, these round magnets can expand to form any glider.
2022-03-23 12:48:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:48:45 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:48:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:48:50 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:48:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:48:54 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:48:54 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:48:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:48:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:49:02 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can restore the big contextures of the face and the basic form of information that comes from themes that include the whole por-structure and all the fine wrinkles.
2022-03-23 12:49:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:49:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate for me here at tedwomen is that... well, the truth is, we've been supporting you for a long time.
2022-03-23 12:49:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:49:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention and a large part of the design work that we are most proud of on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously varied variation and cooling system with coolness that allows us to use an aircraft in the stop-go-transportation, or a mechanism, or a mechanism.
2022-03-23 12:49:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:49:08 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.058 | ppl 533.01 | bleu 32.93 | wps 4738 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.22
2022-03-23 12:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:49:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:49:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:49:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 41 @ 6432 updates, score 32.93) (writing took 0.8231800091452897 seconds)
2022-03-23 12:49:09 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:49:09 | INFO | train | epoch 041 | loss 7.565 | ppl 189.35 | wps 39989.5 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.36 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4153
KL Stats: Epoch 41 Divergences: Uniform: 1.2563192971670916 Unigram: 1.1551166299266429
2022-03-23 12:49:09 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:49:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:49:35 | INFO | train_inner | epoch 042:     68 / 157 loss=7.399, ppl=168.74, wps=33344, ups=1.29, wpb=25777.1, bsz=1074.2, num_updates=6500, lr=0.000392232, gnorm=0.313, loss_scale=4, train_wall=37, gb_free=11.8, wall=4179
2022-03-23 12:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:50:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:50:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:50:16 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:50:16 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:50:20 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets to make any glider.
2022-03-23 12:50:20 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:50:24 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant.
2022-03-23 12:50:24 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:50:29 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked, well, what do we do with her?
2022-03-23 12:50:29 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding, not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:50:37 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a few bundles of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, so the superconductor disorders.
2022-03-23 12:50:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:50:42 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial face that will restore the size of the face and the basic form of information that includes the entire portion structure and all the fine wrinkles.
2022-03-23 12:50:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:50:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in the striking dinner, it was the best summarized when someone said, "turn you to the men at your table and tell you," if the revolution begins, then we support you. '"'" the truth, women love is that we've been supporting you for a long time.
2022-03-23 12:50:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:50:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still a big part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a cooling system that allows us to use an aircraft in the stop-go-traffic, to a particular passage, or if you're going to use the propellment, or if you're going to use it on the ground, from a continuously varied mechanism.
2022-03-23 12:50:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:50:47 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.018 | ppl 518.47 | bleu 33.54 | wps 4713.4 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.54
2022-03-23 12:50:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 12:50:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:50:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt
2022-03-23 12:50:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_best.pt (epoch 42 @ 6589 updates, score 33.54) (writing took 1.7936749355867505 seconds)
2022-03-23 12:50:49 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:50:49 | INFO | train | epoch 042 | loss 7.538 | ppl 185.9 | wps 39502.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.324 | loss_scale 4 | train_wall 58 | gb_free 13.2 | wall 4253
KL Stats: Epoch 42 Divergences: Uniform: 1.2540028776175898 Unigram: 1.1547290594998638
2022-03-23 12:50:49 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:50:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:50:54 | INFO | train_inner | epoch 043:     11 / 157 loss=7.709, ppl=209.27, wps=31409.7, ups=1.28, wpb=24614, bsz=951.5, num_updates=6600, lr=0.000389249, gnorm=0.329, loss_scale=4, train_wall=37, gb_free=12.4, wall=4257
2022-03-23 12:51:31 | INFO | train_inner | epoch 043:    111 / 157 loss=7.536, ppl=185.62, wps=66507.8, ups=2.68, wpb=24831.9, bsz=987.7, num_updates=6700, lr=0.000386334, gnorm=0.307, loss_scale=4, train_wall=37, gb_free=12.1, wall=4295
2022-03-23 12:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:51:52 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:51:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:51:56 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:51:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:52:00 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can also expand these round magnets to form any glider.
2022-03-23 12:52:00 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:52:04 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:52:04 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:52:08 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked, well, what do we do with her?
2022-03-23 12:52:08 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:52:13 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:52:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:52:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconduction disorders.
2022-03-23 12:52:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:21 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big contextures of the face and the basic form, and admitts it by theft that information that includes the whole portion structure and all the fine.
2022-03-23 12:52:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in the striking dinner, it was best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins to support you. '"'" the truth, women, love is that we've already been supporting you for a long time. at this point.
2022-03-23 12:52:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously varied variation and a cooling system that allows us to use an aircraft in the stop traffic, to fit it to a mechanism, or to a mechanism, if you're in the ground.
2022-03-23 12:52:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:26 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.022 | ppl 519.86 | bleu 33.3 | wps 4845.5 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.54
2022-03-23 12:52:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 12:52:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:52:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 43 @ 6746 updates, score 33.3) (writing took 0.7546678041107953 seconds)
2022-03-23 12:52:27 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:52:27 | INFO | train | epoch 043 | loss 7.516 | ppl 183.01 | wps 40346.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.31 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4351
KL Stats: Epoch 43 Divergences: Uniform: 1.2548101832704448 Unigram: 1.1585193382301036
2022-03-23 12:52:27 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:52:48 | INFO | train_inner | epoch 044:     54 / 157 loss=7.527, ppl=184.39, wps=32679.2, ups=1.3, wpb=25094.8, bsz=1059.9, num_updates=6800, lr=0.000383482, gnorm=0.321, loss_scale=4, train_wall=37, gb_free=12.8, wall=4371
2022-03-23 12:53:25 | INFO | train_inner | epoch 044:    154 / 157 loss=7.445, ppl=174.27, wps=68309.7, ups=2.67, wpb=25554.9, bsz=1021.8, num_updates=6900, lr=0.000380693, gnorm=0.297, loss_scale=4, train_wall=37, gb_free=11.7, wall=4409
2022-03-23 12:53:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:30 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:53:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:53:34 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:53:34 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:53:38 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these round magnets to shape any glimpse.
2022-03-23 12:53:38 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:53:42 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:53:42 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:53:46 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:53:46 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:53:50 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other subject.
2022-03-23 12:53:50 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:53:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundles of magnetic field are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 12:53:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:53:59 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face that will restore the grows of the face and the basic form of information that refers the whole portion structure and all the fine folds.
2022-03-23 12:53:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:54:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn you to the men at your table and say to them," if the revolution begins, we support you. '"the truth, women, love is that we've been supporting you for this topic for a long time.
2022-03-23 12:54:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:54:04 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we have stumbled on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable operations and a cooling system that allows us to use an aircraft in the stop traffic to a specific passage, to a mechanism, to the propelled.
2022-03-23 12:54:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:54:04 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.007 | ppl 514.41 | bleu 33.49 | wps 4836.1 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.54
2022-03-23 12:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 12:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:54:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:54:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.49) (writing took 0.8129684338346124 seconds)
2022-03-23 12:54:05 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:54:05 | INFO | train | epoch 044 | loss 7.499 | ppl 180.93 | wps 40287.2 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.304 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 4449
KL Stats: Epoch 44 Divergences: Uniform: 1.2540246211005066 Unigram: 1.159851701953561
2022-03-23 12:54:05 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:54:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:54:42 | INFO | train_inner | epoch 045:     97 / 157 loss=7.452, ppl=175.11, wps=32938.9, ups=1.3, wpb=25370.2, bsz=970.1, num_updates=7000, lr=0.000377964, gnorm=0.306, loss_scale=4, train_wall=37, gb_free=11.8, wall=4486
2022-03-23 12:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:55:08 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:55:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:55:12 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can occupy about 8,000 places in the restaurant.
2022-03-23 12:55:12 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 12:55:16 | INFO | fairseq.tasks.translation | example hypothesis: and of course, i can expand these magnet to shape any glide.
2022-03-23 12:55:16 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 12:55:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father closer because his father had left his mother when she was pregnant with him.
2022-03-23 12:55:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 12:55:24 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 12:55:24 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 12:55:28 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not talking about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 12:55:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 12:55:32 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when you move around, because your movements use energy, and so the superconducting.
2022-03-23 12:55:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:55:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can begin to restore the big contextures of the face and the basic form of information that comes from thief that includes the whole por-structure and all the fine wrinkles.
2022-03-23 12:55:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:55:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and appropriate for me to be here at tedwomen is that -- well, we've been supporting you for a long time.
2022-03-23 12:55:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:55:43 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're most proud of at our airplane to fit the unique problems that were connected to it on the ground -- everything, from a continuous variation and a refrigerator system that allows us to use an aircraft in the steady traffic, to fit an aircraft at a particular time, to an airplane.
2022-03-23 12:55:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:55:43 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.013 | ppl 516.66 | bleu 33.48 | wps 4790.3 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.54
2022-03-23 12:55:43 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 12:55:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 12:55:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:55:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt
2022-03-23 12:55:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.2_0.15_0.65_#4/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.48) (writing took 0.8195532937534153 seconds)
2022-03-23 12:55:44 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:55:44 | INFO | train | epoch 045 | loss 7.494 | ppl 180.31 | wps 40094.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.334 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 4547
2022-03-23 12:55:44 | INFO | fairseq_cli.train | done training in 4546.6 seconds
