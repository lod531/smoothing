Sender: LSF System <lsfadmin@eu-g3-059>
Subject: Job 210581107: <iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:23:51 2022
Job was executed on host(s) <eu-g3-059>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:24:23 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:24:23 2022
Terminated at Wed Mar 23 10:17:53 2022
Results reported at Wed Mar 23 10:17:53 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575612 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3193.00 sec.
    Max Memory :                                 5248 MB
    Average Memory :                             4083.22 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14752.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3209 sec.
    Turnaround time :                            3242 sec.

The output (if any) follows:

2022-03-23 09:24:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575612, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:24:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:24:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:24:37 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:24:37 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:24:37 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:24:37 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:24:37 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:24:37 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:24:37 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:24:37 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:24:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:24:42 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:24:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:24:42 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:24:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:24:42 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:24:42 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:24:42 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:24:42 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:24:42 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:24:42 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:24:42 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:24:42 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:24:42 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:24:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:24:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:24:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:24:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:25:19 | INFO | train_inner | epoch 001:    104 / 157 loss=12.189, nll_loss=11.868, ppl=3737.67, wps=80079.3, ups=3.16, wpb=25305.7, bsz=1024.9, num_updates=100, lr=1.25e-05, gnorm=2.971, loss_scale=8, train_wall=36, gb_free=14, wall=37
2022-03-23 09:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:25:39 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-23 09:25:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:25:41 | INFO | fairseq.tasks.translation | example hypothesis: ..
2022-03-23 09:25:41 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:25:43 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:25:43 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:25:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the,,,,,,,,,,,,,,,,,
2022-03-23 09:25:46 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:25:49 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 09:25:49 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:25:52 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:52 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:25:56 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:56 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:26:02 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:09 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:26:11 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:26:11 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.718 | nll_loss 9.999 | ppl 1023.11 | bleu 0.01 | wps 5004.4 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:26:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:26:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:26:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6235592029988766 seconds)
2022-03-23 09:26:13 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:26:13 | INFO | train | epoch 001 | loss 11.804 | nll_loss 11.384 | ppl 2672.05 | wps 45191 | ups 1.79 | wpb 25225.5 | bsz 1001.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.334 | loss_scale 8 | train_wall 52 | gb_free 14 | wall 91
2022-03-23 09:26:13 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:28 | INFO | train_inner | epoch 002:     47 / 157 loss=10.896, nll_loss=10.242, ppl=1210.86, wps=36505.3, ups=1.45, wpb=25181.6, bsz=982.6, num_updates=200, lr=2.5e-05, gnorm=0.975, loss_scale=8, train_wall=31, gb_free=13.8, wall=106
2022-03-23 09:26:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:26:59 | INFO | train_inner | epoch 002:    148 / 157 loss=10.263, nll_loss=9.402, ppl=676.64, wps=80563.9, ups=3.21, wpb=25113.2, bsz=1008.6, num_updates=300, lr=3.75e-05, gnorm=1.398, loss_scale=4, train_wall=31, gb_free=13.4, wall=137
2022-03-23 09:27:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:06 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the.
2022-03-23 09:27:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:27:10 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:10 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:27:15 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and
2022-03-23 09:27:15 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:27:20 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:20 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:27:25 | INFO | fairseq.tasks.translation | example hypothesis: so i i i i i i i i i i i i i i i,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:25 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:27:30 | INFO | fairseq.tasks.translation | example hypothesis: we we,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:30 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:27:36 | INFO | fairseq.tasks.translation | example hypothesis: and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:36 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:27:42 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:27:49 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:52 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:52 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.987 | nll_loss 8.965 | ppl 499.87 | bleu 0.01 | wps 3568.4 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.01
2022-03-23 09:27:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-23 09:27:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:27:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:27:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.01) (writing took 1.8545897300355136 seconds)
2022-03-23 09:27:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:27:53 | INFO | train | epoch 002 | loss 10.381 | nll_loss 9.561 | ppl 755.44 | wps 39011.9 | ups 1.55 | wpb 25157 | bsz 1018.6 | num_updates 309 | lr 3.8625e-05 | gnorm 1.203 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 191
2022-03-23 09:27:54 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:27:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:23 | INFO | train_inner | epoch 003:     91 / 157 loss=9.936, nll_loss=8.93, ppl=487.77, wps=30433.7, ups=1.2, wpb=25354.8, bsz=1116.3, num_updates=400, lr=5e-05, gnorm=1.072, loss_scale=4, train_wall=31, gb_free=13.5, wall=221
2022-03-23 09:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:46 | INFO | fairseq.tasks.translation | example hypothesis: it's a.
2022-03-23 09:28:46 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:28:50 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's's the the the the the the the the.
2022-03-23 09:28:50 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:28:54 | INFO | fairseq.tasks.translation | example hypothesis: and and and it's's a a a a, but but but but but but but but but but but but but but but but but but but but but but but but but
2022-03-23 09:28:54 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:28:58 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's's's the the the the the the the the the the the the the the, and the, and the the the the the.
2022-03-23 09:28:58 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:29:02 | INFO | fairseq.tasks.translation | example hypothesis: and i, i, i, i i i to to to to to to to to to to to to to to to to to to to to to to to.
2022-03-23 09:29:02 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:29:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's's the the the the the the, we to to to to to to to to to to to to to to to.
2022-03-23 09:29:06 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:29:11 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's's, and the the the the the the the the the the the the the, and we, and we, and we, and we, we, and we, and we, and we is is is is is is is is is, we to to to to to to to to to to to to to to to to to
2022-03-23 09:29:11 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example hypothesis: and and and we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and we, and we of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:24 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:29:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to, and and and and and and and and and and to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:26 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.763 | nll_loss 8.616 | ppl 392.33 | bleu 0.17 | wps 4085.1 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.17
2022-03-23 09:29:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 09:29:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:29:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:29:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.17) (writing took 1.7523938622325659 seconds)
2022-03-23 09:29:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:29:28 | INFO | train | epoch 003 | loss 9.934 | nll_loss 8.924 | ppl 485.69 | wps 41694.5 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.064 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 286
2022-03-23 09:29:28 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:29:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:29:39 | INFO | train_inner | epoch 004:     34 / 157 loss=9.908, nll_loss=8.886, ppl=472.98, wps=32727.2, ups=1.3, wpb=25104.3, bsz=908.9, num_updates=500, lr=6.25e-05, gnorm=1.129, loss_scale=4, train_wall=30, gb_free=13.9, wall=297
2022-03-23 09:30:10 | INFO | train_inner | epoch 004:    134 / 157 loss=9.615, nll_loss=8.499, ppl=361.82, wps=79873.8, ups=3.22, wpb=24779.4, bsz=1026.4, num_updates=600, lr=7.5e-05, gnorm=1.454, loss_scale=4, train_wall=31, gb_free=14.3, wall=329
2022-03-23 09:30:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:21 | INFO | fairseq.tasks.translation | example hypothesis: this is this.
2022-03-23 09:30:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:30:25 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world of the world, and they're see the world.
2022-03-23 09:30:25 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:30:30 | INFO | fairseq.tasks.translation | example hypothesis: and but it's a very, but it's a very very of a very and they've've've've've've've've've've've've've've've've've have
2022-03-23 09:30:30 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:30:35 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world of the world, and are are are are are are are are are the world, and are are are are are are are are are are are are are the world.
2022-03-23 09:30:35 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:30:40 | INFO | fairseq.tasks.translation | example hypothesis: so i've've've've've've've've've've've've've've had to think to think to think to think in the world, and i think in the world, and i think in the world.
2022-03-23 09:30:40 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:30:46 | INFO | fairseq.tasks.translation | example hypothesis: so we can can have to have to have to have to have to have to be the world, and we've've've've've've've've've've've've've've've've've've've've've've've've've've have to have to have to have to have to be
2022-03-23 09:30:46 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:30:52 | INFO | fairseq.tasks.translation | example hypothesis: and we've've've've've've have to have to have to have to do to have to be the world, and we've've've've've've've've've've've've've've've've've've've've've've have to have to have to have to have to do to do to do to do to do to do to do to
2022-03-23 09:30:52 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:30:58 | INFO | fairseq.tasks.translation | example hypothesis: and we've've've've've've've've've've have to have to have to have to have to do we've've've've've've've've've've've've've've've've've've've've've've've have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to have to to to to to to the the the world
2022-03-23 09:30:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:06 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" we said, "" we had had had had to had had had had to had to had had had had to had to had had had to had to had a "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "we've've've've've've've've've've've've've've've've was a a a a a", "," "" "," "" "" "" "" "" "", "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:31:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:08 | INFO | fairseq.tasks.translation | example hypothesis: and we have to have to have a that we've've have to have to have to have to have to have to have to have to have to have to have to have to have to be a a that we've've've've've've've have to have to have to have to have to be to be to be a a that that we have to be the world, and we have to have to be to be to be to be to be to be to be to be a a a that that we have to be the world, and we've've've've've've've've've've've've've've've have to have to have to have to be the world, and we have to have to have to be the world, and we have to have to have to have to be to be the world, and we've've've've've've've've've've have to be the world, and that we have to be the world, and that we have to be the world, and we have to have to have to have to have a
2022-03-23 09:31:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:08 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.35 | nll_loss 8.085 | ppl 271.45 | bleu 1 | wps 3486 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 1
2022-03-23 09:31:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 09:31:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:31:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:31:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 4 @ 623 updates, score 1.0) (writing took 1.7509724460542202 seconds)
2022-03-23 09:31:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:31:10 | INFO | train | epoch 004 | loss 9.638 | nll_loss 8.529 | ppl 369.43 | wps 38799.4 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.407 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 388
2022-03-23 09:31:10 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:34 | INFO | train_inner | epoch 005:     77 / 157 loss=9.429, nll_loss=8.249, ppl=304.3, wps=29866.6, ups=1.19, wpb=25067.7, bsz=977.2, num_updates=700, lr=8.75e-05, gnorm=1.377, loss_scale=4, train_wall=30, gb_free=14.2, wall=412
2022-03-23 09:31:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:03 | INFO | fairseq.tasks.translation | example hypothesis: these can't be this.
2022-03-23 09:32:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:32:07 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and it's the world.
2022-03-23 09:32:07 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:32:11 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot of a lot, but it's a lot of a lot of a lot of a lot of a lot.
2022-03-23 09:32:11 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:32:15 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world, and it's the world, and it's the world, and it's the world, and it's going to see, and it's going to the world.
2022-03-23 09:32:15 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:32:20 | INFO | fairseq.tasks.translation | example hypothesis: so i'm going to see it, and i'm going to see that i'm going to see it.
2022-03-23 09:32:20 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:32:25 | INFO | fairseq.tasks.translation | example hypothesis: so we can see that we can see that we can see that we can see it.
2022-03-23 09:32:25 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:32:31 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to do it, and we're going to do it's going to do it?
2022-03-23 09:32:31 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example hypothesis: and so we can see that we can see that we can see, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see, and we can see that we can see that we can see
2022-03-23 09:32:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:32:44 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" "" "" "we said," "" "" "" we said, "we said," we said, "we said," it's going to say, "it's going to say," it's going to say, "" "" it's going to say, "" "" "" "" "" "" "" "" "" "" it's the first, "it's going to do it's going to say," it's going to say, "" "" "" "" "it's going to say," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" it's a little little little little little little little little little little "" "" ""
2022-03-23 09:32:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:32:46 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the time, and it's a lot of it's a lot of the time, it's a lot of the time, but we can't have a lot of that we don't do it's a lot of the time, and it's going to be a lot of that we can see it's a lot of it's a lot of the time, and it's a lot of the way, and we have a lot of it's a lot of the way, it's a lot of that we can't have a lot of the way, and it's a lot of it's a lot of the time, and it's a lot of the time, and we're going to do it's a lot of the time, and we're going to be a lot of the way that we're going to be a lot of the way that we're going to be a lot of the way that we're going to do it's a lot of the time, and it's going to see that we're going to be a lot
2022-03-23 09:32:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:32:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.998 | nll_loss 7.583 | ppl 191.71 | bleu 1.62 | wps 3818.1 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.62
2022-03-23 09:32:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 09:32:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:32:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.62) (writing took 1.8007147070020437 seconds)
2022-03-23 09:32:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:32:48 | INFO | train | epoch 005 | loss 9.292 | nll_loss 8.064 | ppl 267.7 | wps 40413 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.411 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 486
2022-03-23 09:32:48 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:32:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:54 | INFO | train_inner | epoch 006:     20 / 157 loss=9.162, nll_loss=7.889, ppl=237.03, wps=31494.3, ups=1.25, wpb=25184.2, bsz=1065.4, num_updates=800, lr=0.0001, gnorm=1.412, loss_scale=4, train_wall=30, gb_free=14.3, wall=492
2022-03-23 09:33:26 | INFO | train_inner | epoch 006:    120 / 157 loss=8.966, nll_loss=7.625, ppl=197.36, wps=81180.5, ups=3.2, wpb=25400.5, bsz=1063.6, num_updates=900, lr=0.0001125, gnorm=1.346, loss_scale=4, train_wall=31, gb_free=13.9, wall=524
2022-03-23 09:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example hypothesis: these can't have this.
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:33:44 | INFO | fairseq.tasks.translation | example hypothesis: and you can see the world, and you can see the world.
2022-03-23 09:33:44 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:33:48 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot of a lot, but it's a lot, but it's a lot.
2022-03-23 09:33:48 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:33:53 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world, and it's going to get the world, and it's going to the world.
2022-03-23 09:33:53 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:33:58 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to see it, and i'm going to do it's going to do it's going to be a lot of the same way of the same way, i'm going to do it.
2022-03-23 09:33:58 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:34:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we can be a lot of this, we can be a lot of the time, we can be a lot of the way, we can be a lot of the way.
2022-03-23 09:34:03 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:34:08 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to do, and we're going to do, we're going to do it, and we're going to do it?
2022-03-23 09:34:08 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that we can see that we can see a lot of the way, and we can see that we can see the way, and we can see that we can see that we can see the world, and we can see that we can see the world, and we can see that we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the way
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:22 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" "we said," "the first first first time," he said, "we said," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "we've said," it's going to say, "it's going to say," and then then we've said, "the first first first first first first first first first," "we've said," we've said, "it's going to say," we said, "we've said," we said, "we've said," it's going to say, "it's going to say," we've said, "we've said," it's going to say, "we've said," we've said, "we've said," "
2022-03-23 09:34:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:25 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of course, if we're going to be a lot of course, and we're going to see that we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to make the same same way, and we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to be a lot of the way, and we're going to be going to see the way that we're going to see the way that we're going to see the way that we're going to see the way that we're going to see the way, and we're going to be going to be a
2022-03-23 09:34:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:25 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.749 | nll_loss 7.237 | ppl 150.87 | bleu 1.82 | wps 3724 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.82
2022-03-23 09:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:34:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:34:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.82) (writing took 1.7782414881512523 seconds)
2022-03-23 09:34:26 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:34:26 | INFO | train | epoch 006 | loss 8.976 | nll_loss 7.638 | ppl 199.13 | wps 40038.3 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.284 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 584
2022-03-23 09:34:27 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:34:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:46 | INFO | train_inner | epoch 007:     63 / 157 loss=8.832, nll_loss=7.442, ppl=173.94, wps=31077.6, ups=1.24, wpb=25057.9, bsz=1034.6, num_updates=1000, lr=0.000125, gnorm=1.287, loss_scale=4, train_wall=30, gb_free=13.9, wall=604
2022-03-23 09:35:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:19 | INFO | fairseq.tasks.translation | example hypothesis: these can't can be.
2022-03-23 09:35:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:35:23 | INFO | fairseq.tasks.translation | example hypothesis: and that's the world, you can see the world.
2022-03-23 09:35:23 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:35:28 | INFO | fairseq.tasks.translation | example hypothesis: but but it's a lot of the world, and it's a lot, and it's a lot, and it's a lot, and it's a lot.
2022-03-23 09:35:28 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:35:32 | INFO | fairseq.tasks.translation | example hypothesis: now, it's very very, and it's very, and it's the way, and it's the way, and it's the way.
2022-03-23 09:35:32 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:35:37 | INFO | fairseq.tasks.translation | example hypothesis: it's like me, i can see that i can be able to be able to me, and i can be able to see the world.
2022-03-23 09:35:37 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:35:42 | INFO | fairseq.tasks.translation | example hypothesis: so how we can be able to be able to be as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as we can be as as as as as as as as as as as as we can
2022-03-23 09:35:42 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:35:47 | INFO | fairseq.tasks.translation | example hypothesis: it's about the world, and we're going to do, and we're going to do that we're going to be going to do, and we're going to do the world?
2022-03-23 09:35:47 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example hypothesis: so so if we can see that we can see that, and we can make a lot of the world, and we can see that we can see that we can see that we can do that we can do that we can see the world, and we can see the world, and we can see the way, and we can see the way, and we can see the way, and we can see the world, and we can see the way of the way,
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example hypothesis: well, "when we said," "we said," the first time, "" "" "the first time," "the first time," the first time, "" "we've said," we've said, "is," the first time, "we've said," we've got to say, "is," the first first time, "" "and the first time," the first time, "the first time," the first time, "is," we've got to say, "the first time," is, "the first time," the first time, "is," we've said, "the first time," is, "the first time," and we're going to say, "is," and we've got to say, "is," the first time, "" the first time, "
2022-03-23 09:36:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:02 | INFO | fairseq.tasks.translation | example hypothesis: and that's the way that we're going to be able to make the way that we're going to be able to be able to be able to be able to be able to be able to make the way, and we can be able to be able to make the way, and we can be able to make the way, and we can be able to be able to be able to make the way, but we can be able to be able to be able to make the way, but we can be able to be able to be able to make the way that we can be able to be able to make the way, and that we're going to make the way, and that we can be able to be able to make the way, and that we're going to be able to make the way that we can see that we can see that we're going to make the way that we can see the way that we're going to make the way that we're going to make the way that we can be able to be able to be able to be able
2022-03-23 09:36:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:02 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 8.522 | nll_loss 6.919 | ppl 121.02 | bleu 2.71 | wps 3843.1 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.71
2022-03-23 09:36:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:36:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:36:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:36:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.71) (writing took 1.806660617236048 seconds)
2022-03-23 09:36:04 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:36:04 | INFO | train | epoch 007 | loss 8.764 | nll_loss 7.351 | ppl 163.22 | wps 40566.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.218 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 682
2022-03-23 09:36:04 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:36:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:06 | INFO | train_inner | epoch 008:      6 / 157 loss=8.753, nll_loss=7.336, ppl=161.59, wps=31636, ups=1.25, wpb=25248.9, bsz=977.9, num_updates=1100, lr=0.0001375, gnorm=1.106, loss_scale=4, train_wall=31, gb_free=14.1, wall=684
2022-03-23 09:36:38 | INFO | train_inner | epoch 008:    106 / 157 loss=8.594, nll_loss=7.121, ppl=139.23, wps=80408.4, ups=3.18, wpb=25265.2, bsz=1009.1, num_updates=1200, lr=0.00015, gnorm=1.225, loss_scale=4, train_wall=31, gb_free=14.2, wall=716
2022-03-23 09:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:57 | INFO | fairseq.tasks.translation | example hypothesis: these can't use these data.
2022-03-23 09:36:57 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:37:01 | INFO | fairseq.tasks.translation | example hypothesis: and so, that's that they're going to see the world.
2022-03-23 09:37:01 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:37:06 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, there's a lot of the world, and there's a lot of other and there's a lot of other and then there's a lot.
2022-03-23 09:37:06 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:37:11 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of people, and it's in the world, and it's a lot of the world, and there are the world.
2022-03-23 09:37:11 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:37:16 | INFO | fairseq.tasks.translation | example hypothesis: and it also also also also also also also also also like how i could i can see how i can see that i can see it in the same way that i can be in the world.
2022-03-23 09:37:16 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:37:22 | INFO | fairseq.tasks.translation | example hypothesis: so as as we can see how we can see this as as as as as as as as we can see this as as a little bit of the way that can be able to be able to be able to be able to be able.
2022-03-23 09:37:22 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example hypothesis: and it's about the world, we have to do that we have to do the world, and we're going to go from the world, and we're going to go from the world, and we're going to go from the world, and we're going to go out of the world, and we're going to do that we're going to go
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:37:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we can look at the way that we can see the way that we can see the way, and we can see that we can see the same way of the way, and we can see that we can see the same way that we can do that we can make a little bit of the brain and make a little bit of the world, and we can do that we can do that we can see the same way of the way that we can do that and
2022-03-23 09:37:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:41 | INFO | fairseq.tasks.translation | example hypothesis: one of the first one of the first one of the first time, "the first one of the first time," the first time, and it's going to say, "the first time," we said, "the first time," we said, "the first time," we said, "the first time," the first time, "the first time," we said, "the first time," the first time, "we said," the first time, "the first time," the first time, "the first time," the first time, "the first time," the first time, "the first time," the first time, "the first time," the first time, "we said," the first time, "the first time," the first time, "the first time," the first time, "the first time,
2022-03-23 09:37:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:37:43 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's a few years, when we're going to be a lot of the way that we're going to take the way, and we're going to go to be a little bit of the way that we're going to get to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the way, and when we're going to be able to the way that we're going to be able to be a few years, because we're going to the way that we're going to be able to be able to make the way that we're going to be able to be able to be able to be able
2022-03-23 09:37:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:37:43 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 8.302 | nll_loss 6.61 | ppl 97.71 | bleu 3.3 | wps 3534.1 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.3
2022-03-23 09:37:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:37:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:37:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:37:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.3) (writing took 1.830032390076667 seconds)
2022-03-23 09:37:45 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:37:45 | INFO | train | epoch 008 | loss 8.546 | nll_loss 7.059 | ppl 133.3 | wps 38863.2 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.142 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 783
2022-03-23 09:37:46 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:01 | INFO | train_inner | epoch 009:     49 / 157 loss=8.442, nll_loss=6.919, ppl=121.04, wps=29492.2, ups=1.19, wpb=24737.8, bsz=1006.3, num_updates=1300, lr=0.0001625, gnorm=1.011, loss_scale=4, train_wall=30, gb_free=13.6, wall=799
2022-03-23 09:38:33 | INFO | train_inner | epoch 009:    149 / 157 loss=8.251, nll_loss=6.664, ppl=101.4, wps=82453.7, ups=3.2, wpb=25771.8, bsz=1055, num_updates=1400, lr=0.000175, gnorm=1.059, loss_scale=4, train_wall=31, gb_free=13.4, wall=831
2022-03-23 09:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:38:39 | INFO | fairseq.tasks.translation | example hypothesis: these can't have no data.
2022-03-23 09:38:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:38:43 | INFO | fairseq.tasks.translation | example hypothesis: and all of course, they're going to see it.
2022-03-23 09:38:43 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:38:46 | INFO | fairseq.tasks.translation | example hypothesis: but everybody's a lot of between between between between between between between between between between between between between between between between between between between between between between between between between between between.
2022-03-23 09:38:46 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:38:50 | INFO | fairseq.tasks.translation | example hypothesis: now, in fact, it turns out, and there are the united states, the united states, and the united states are the united states.
2022-03-23 09:38:50 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example hypothesis: it also also also also also also also also also, as i can see it in the same time.
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:38:59 | INFO | fairseq.tasks.translation | example hypothesis: so how we can take our brain, as we can be able to create a new system, if it would be a new way that it would be able to be a new system.
2022-03-23 09:38:59 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:39:04 | INFO | fairseq.tasks.translation | example hypothesis: so it's about the brain, we've got to have a lot of the world, and we've got to get from a lot of children, and many of our children, and then we're going to go out of our children, the kids who are going to go out of their children, from the kids, and then they're going to go out
2022-03-23 09:39:04 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:39:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information, we can use this, we can do this, we can make a kind of the brain, and we can use the brain, and we can use the brain, and we can make a kind of the brain, and we can get the brain, and the brain, and we can get a kind of the brain, which we can get the brain, and then we can get the brain, which is a kind of the brain
2022-03-23 09:39:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:17 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the idea of course, and it's going to be very important, and it's going to do that, and then we're going to have a little bit of what we're going to be going to be going to be going to give you, and then we're going to be going to be going to have to have to be a little bit of the same time, and then we're going to have to have to have a little bit of that we're going to have to have to have to have to be going to have to have to have a little bit of the same time, and then we're going to have to have to have to have to have to have to have to be a little bit of the same time, and then we're going to have to have to have to be very good for the time, and then, and then we're going to have a little bit
2022-03-23 09:39:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:20 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still still still the way that we're going to have a way, and if we're going to have a little bit of the way that we're going to have to have to have a little bit of the way that we're going to have to have to have to have to have to have to have to be able to get the way that we're going to have to be able to have a little bit of the way that we're going to get the way that we're going to have to be able to have to have to be able to get the way that we're going to have a little bit of the way that we're going to have to be able to get the same way that we're going to be able to have a way that we're going to have a way that we're going to get the same way that we're going to be able to have a way that we're going to have a way that we're going to have to be able to have to be able to have to be able to have a
2022-03-23 09:39:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:20 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.018 | nll_loss 6.218 | ppl 74.45 | bleu 5.25 | wps 4004.1 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 5.25
2022-03-23 09:39:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:39:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:39:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 9 @ 1408 updates, score 5.25) (writing took 1.7923512617126107 seconds)
2022-03-23 09:39:21 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:39:21 | INFO | train | epoch 009 | loss 8.309 | nll_loss 6.741 | ppl 106.99 | wps 41091.6 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.062 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 879
2022-03-23 09:39:22 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:39:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:39:51 | INFO | train_inner | epoch 010:     92 / 157 loss=8.096, nll_loss=6.459, ppl=87.96, wps=31797.5, ups=1.28, wpb=24869.8, bsz=1053.8, num_updates=1500, lr=0.0001875, gnorm=1.089, loss_scale=4, train_wall=31, gb_free=14.7, wall=909
2022-03-23 09:40:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:14 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 09:40:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:40:18 | INFO | fairseq.tasks.translation | example hypothesis: and all of that you can see it, you see the world.
2022-03-23 09:40:18 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:40:22 | INFO | fairseq.tasks.translation | example hypothesis: but everybody has a lot between between between between between between between between between between between between and other.
2022-03-23 09:40:22 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:40:27 | INFO | fairseq.tasks.translation | example hypothesis: now, it's going on on the united states, and in the united states, the united states, the united states are the united states.
2022-03-23 09:40:27 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:40:31 | INFO | fairseq.tasks.translation | example hypothesis: it could be able to see how i'm going to be so so i'm going to be able to be able to the other other other other other other other.
2022-03-23 09:40:31 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:40:35 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can make our computer that can be able to be able to be a new new new york, if it would be a new new new new york.
2022-03-23 09:40:35 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:40:39 | INFO | fairseq.tasks.translation | example hypothesis: it's going to do that we've got from from from from from from the university, from the kids who are going to go from our children, and many children are going to go from the children.
2022-03-23 09:40:39 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:40:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information that we can make this information, we can make a kind of information, and we can make a lot of the brain, which is going to make a little bit of the brain.
2022-03-23 09:40:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:48 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons, it's interesting, and it's really interesting for me for me for me, "if you know, we're going to say," if you're going to say, "if you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "you're going to say," well, "well," we're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you know," you know, "you know," well, "you know," well, "you're going to say," you're going to say, "you're going to say
2022-03-23 09:40:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:50 | INFO | fairseq.tasks.translation | example hypothesis: so, it's still still still the mother, and the reason we're going to see that we're going to look at the same time, if we're going to see a little bit of the same time that we're going to see that we're going to see a very important thing that we're going to be able to be able to see the same time.
2022-03-23 09:40:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:50 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.758 | nll_loss 5.849 | ppl 57.63 | bleu 8.4 | wps 4615.2 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 8.4
2022-03-23 09:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:40:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 10 @ 1565 updates, score 8.4) (writing took 1.8201009859330952 seconds)
2022-03-23 09:40:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:40:52 | INFO | train | epoch 010 | loss 8.074 | nll_loss 6.428 | ppl 86.09 | wps 43601.1 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.105 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 970
2022-03-23 09:40:52 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:03 | INFO | train_inner | epoch 011:     35 / 157 loss=7.99, nll_loss=6.313, ppl=79.51, wps=34857.9, ups=1.38, wpb=25206.7, bsz=992.5, num_updates=1600, lr=0.0002, gnorm=1.152, loss_scale=4, train_wall=30, gb_free=13.8, wall=981
2022-03-23 09:41:34 | INFO | train_inner | epoch 011:    135 / 157 loss=7.897, nll_loss=6.19, ppl=73.02, wps=79290, ups=3.2, wpb=24785.7, bsz=1016.1, num_updates=1700, lr=0.0002125, gnorm=1.163, loss_scale=4, train_wall=31, gb_free=14.4, wall=1013
2022-03-23 09:41:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:45 | INFO | fairseq.tasks.translation | example hypothesis: this can't use.
2022-03-23 09:41:45 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example hypothesis: and all of them without them, they see it.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:41:52 | INFO | fairseq.tasks.translation | example hypothesis: but everybody's a different difference between between between between between the power, and language.
2022-03-23 09:41:52 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:41:56 | INFO | fairseq.tasks.translation | example hypothesis: it's very difficult to be working on the countries, and the countries are the united states, the united states are the united states.
2022-03-23 09:41:56 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:42:00 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm going to be so so i'm going to get the other side on the other side of the other side.
2022-03-23 09:42:00 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:42:04 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can do our computer, we can make this new way to create a new new way when it would be able to be a new way.
2022-03-23 09:42:04 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:42:08 | INFO | fairseq.tasks.translation | example hypothesis: is it?
2022-03-23 09:42:08 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:42:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information of this information that we can start to do with a simple system, and we can actually start to create a different structure, which is going to do a different structure of information.
2022-03-23 09:42:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:17 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that it's interesting for me, and it's interesting for me to say, "well," well, "if you've been going to say," if you've been going to say, "if you're going to say," if you're going to say, "if you're going to say," well, "well," if you're going to tell you're going to tell you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "if you're going to tell you're going to tell you know," well, "well," well, "well," well, "well," well, "well," well, "well,
2022-03-23 09:42:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:19 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still the mother, and if we're going to look at the way we're going to see that it was going to be able to look at one of the problems that we had to be able to be able to be able to be able to be able to be able to look at one of the problems that we had to look at the problems that we had to be able to be able to look at one of the problems that we had to look at one of the problems that we had to look at the same time that we had to look at one of the same time, and the same time that we had to look at the same thing that we had to see it is that we had to see it was that we had to look at the same thing that we had to look at the same thing that we had to look at the same thing that we had to look at the same time that we had to see that we had to see that we had to see it was going to see that we had to see that it is that
2022-03-23 09:42:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:19 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 7.577 | nll_loss 5.565 | ppl 47.36 | bleu 8.59 | wps 4745.9 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.59
2022-03-23 09:42:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:42:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:42:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:42:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.59) (writing took 1.8232810418121517 seconds)
2022-03-23 09:42:21 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:42:21 | INFO | train | epoch 011 | loss 7.875 | nll_loss 6.162 | ppl 71.59 | wps 44227.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.136 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1059
2022-03-23 09:42:22 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:42:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:46 | INFO | train_inner | epoch 012:     78 / 157 loss=7.66, nll_loss=5.875, ppl=58.69, wps=35868.1, ups=1.4, wpb=25690.2, bsz=1080.7, num_updates=1800, lr=0.000225, gnorm=1.13, loss_scale=4, train_wall=30, gb_free=13.9, wall=1084
2022-03-23 09:43:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:14 | INFO | fairseq.tasks.translation | example hypothesis: these rop can't use chemical.
2022-03-23 09:43:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example hypothesis: and all of them without them, they see the world.
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:43:22 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else else else else else else between power and intelligence.
2022-03-23 09:43:22 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:43:26 | INFO | fairseq.tasks.translation | example hypothesis: very important, it turns out in japan, and the countries, the united states are used.
2022-03-23 09:43:26 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:43:30 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i am so much i'm going to get my head in the other side of other side.
2022-03-23 09:43:30 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:43:33 | INFO | fairseq.tasks.translation | example hypothesis: so as we can imagine our computer that can be able to use this new new brain, if it would be able to be a new part of the body.
2022-03-23 09:43:33 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:43:37 | INFO | fairseq.tasks.translation | example hypothesis: and it's the impact? we've got to come from from the mimiy, from the science, and many kids come from our children, and many children.
2022-03-23 09:43:37 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:43:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information that we can start able to start with a sense of traditional systems, and we can start able to do it through the structure of the structure of information.
2022-03-23 09:43:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting for me for me, "yes, that's the best thing to say," if you're going to say, "if you're going to say," if you're going to say, "if you're going to say," if you're going to say, "the best thing."
2022-03-23 09:43:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:46 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and the big work of our work that we had to use the internet of our problems that we had to be able to do it, and if we had to use it to be able to be able to do it.
2022-03-23 09:43:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:46 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 7.364 | nll_loss 5.267 | ppl 38.51 | bleu 11.73 | wps 5094.5 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.73
2022-03-23 09:43:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:43:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:43:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:43:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.73) (writing took 1.8459562887437642 seconds)
2022-03-23 09:43:48 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:43:48 | INFO | train | epoch 012 | loss 7.647 | nll_loss 5.856 | ppl 57.93 | wps 45369.8 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.081 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1146
2022-03-23 09:43:49 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:43:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:56 | INFO | train_inner | epoch 013:     21 / 157 loss=7.634, nll_loss=5.838, ppl=57.2, wps=36075.6, ups=1.44, wpb=25090.3, bsz=964, num_updates=1900, lr=0.0002375, gnorm=1.031, loss_scale=4, train_wall=31, gb_free=13.6, wall=1154
2022-03-23 09:44:27 | INFO | train_inner | epoch 013:    121 / 157 loss=7.379, nll_loss=5.499, ppl=45.21, wps=81008.4, ups=3.24, wpb=24993.5, bsz=1065.4, num_updates=2000, lr=0.00025, gnorm=1.011, loss_scale=4, train_wall=30, gb_free=13.5, wall=1185
2022-03-23 09:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:41 | INFO | fairseq.tasks.translation | example hypothesis: these rocks can't use chemical materials.
2022-03-23 09:44:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:44:46 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, no without you can see it, you see the world.
2022-03-23 09:44:46 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:44:50 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else else else else else else else between the weight between the intelligence, and intelligence and intelligence.
2022-03-23 09:44:50 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:44:54 | INFO | fairseq.tasks.translation | example hypothesis: very quickly, it's going on in japan, japan, in japan, and countries, the united states, the united states are the united states.
2022-03-23 09:44:54 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:44:58 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, how i am so so much, so i'm going to do the other side of the other side.
2022-03-23 09:44:58 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:45:02 | INFO | fairseq.tasks.translation | example hypothesis: so as we can imagine our computer, as we can imagine the brain of the brain, the new brain, when it would be part of the body.
2022-03-23 09:45:02 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:45:06 | INFO | fairseq.tasks.translation | example hypothesis: so it's the impact? we've got to do with gy, from the university, from the university of science, and many of our children are going to make a lot of kids.
2022-03-23 09:45:06 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information of this kind of reflection, we can see with some of the traditional traditional traditional objects that are going to make it through the whole structure and all the information.
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:13 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons, it's interesting, and it's interesting for me, "i'm going to tell you," well, you know, if you're going to tell you the best thing. "
2022-03-23 09:45:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:14 | INFO | fairseq.tasks.translation | example hypothesis: well, unfortunately, it's still the mother of mother, and the great great design of the work, and if you're going to see that it was a little bit of the problems that we had to have to do with the surface.
2022-03-23 09:45:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:14 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 7.154 | nll_loss 4.959 | ppl 31.11 | bleu 13.66 | wps 5088.1 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.66
2022-03-23 09:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:45:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:45:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:45:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.66) (writing took 1.8281846530735493 seconds)
2022-03-23 09:45:16 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:45:16 | INFO | train | epoch 013 | loss 7.404 | nll_loss 5.532 | ppl 46.27 | wps 45268.3 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.994 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1234
2022-03-23 09:45:16 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:45:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:36 | INFO | train_inner | epoch 014:     64 / 157 loss=7.225, nll_loss=5.292, ppl=39.18, wps=36928.5, ups=1.43, wpb=25789, bsz=1069.9, num_updates=2100, lr=0.0002625, gnorm=0.942, loss_scale=4, train_wall=31, gb_free=13.9, wall=1254
2022-03-23 09:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example hypothesis: these rocks can't use chemical chemical.
2022-03-23 09:46:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:46:13 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, you see that it's going to see the world.
2022-03-23 09:46:13 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:46:17 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different amount between the weight between the weight and intelligence, and intelligence.
2022-03-23 09:46:17 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:46:21 | INFO | fairseq.tasks.translation | example hypothesis: especially very focus on japan, japan, japan and australia, australia, the united states, the united states, are the united states.
2022-03-23 09:46:21 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:46:25 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, as i'm so, so i'm going to do my attention in the other side.
2022-03-23 09:46:25 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:46:29 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer, we can imagine the brains to use this new tool to use this new tool when it would be part of the body, it would be part of the body.
2022-03-23 09:46:29 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:46:33 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact?
2022-03-23 09:46:33 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:46:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that can use from this kind of reflection, we can start with a traditional face, and we start able to start able to start with the face of the information, and there's a real structure of information.
2022-03-23 09:46:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons it's interesting, and it's interesting for me to be here at tedtedtedtedtedtalks, "yes, it's the best thing that we said," hey, "well," if we're working with you're working with the best revolution. "
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the key mother is still the invention of the invention, and a big design that we're going to solve on on our plane, is that we had to solve a unique way to solve that we had to be able to be able to be able to be able to use the surface of the surface of the ground, and if we had to see that it is to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that
2022-03-23 09:46:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:44 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.886 | nll_loss 4.613 | ppl 24.48 | bleu 15.31 | wps 4663.7 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.31
2022-03-23 09:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:46:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.31) (writing took 1.9094913420267403 seconds)
2022-03-23 09:46:46 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:46:46 | INFO | train | epoch 014 | loss 7.216 | nll_loss 5.277 | ppl 38.77 | wps 43623.2 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.98 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1324
2022-03-23 09:46:46 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:49 | INFO | train_inner | epoch 015:      7 / 157 loss=7.271, nll_loss=5.347, ppl=40.69, wps=33708.8, ups=1.38, wpb=24372, bsz=907.3, num_updates=2200, lr=0.000275, gnorm=1.003, loss_scale=4, train_wall=30, gb_free=14.3, wall=1327
2022-03-23 09:47:20 | INFO | train_inner | epoch 015:    107 / 157 loss=6.999, nll_loss=4.986, ppl=31.69, wps=80284.7, ups=3.2, wpb=25109.4, bsz=1095.3, num_updates=2300, lr=0.0002875, gnorm=0.961, loss_scale=4, train_wall=31, gb_free=14.7, wall=1358
2022-03-23 09:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:39 | INFO | fairseq.tasks.translation | example hypothesis: these little chemical chemical can't use.
2022-03-23 09:47:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:47:43 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, you can see it, you see the world.
2022-03-23 09:47:43 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:47:46 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between balance and intelligence.
2022-03-23 09:47:46 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:47:50 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, japan and australia, australia, australia, australia, the united states are the united states.
2022-03-23 09:47:50 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:47:53 | INFO | fairseq.tasks.translation | example hypothesis: it's also interested in me, as i'm focused on my attention.
2022-03-23 09:47:53 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:47:57 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computers can make the brains to build this new tool as a new tool.
2022-03-23 09:47:57 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:48:01 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we've come from berbery, from berbery university, from the science institute of science, and the kids come to get a lot of scientific experiments.
2022-03-23 09:48:01 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:48:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from the reflection, we can start with traditional face, we can start able to start able to start with a traditional face of the face of the face, and the real shape of the information, and there's all the information.
2022-03-23 09:48:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are interesting and measure for me to be here for tedtedson, "yes, that it was the best thing when someone said," well, "well," somebody said, "well," if we're working with you know, "if we're working with a long time."
2022-03-23 09:48:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:11 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and the invention of design is a big design that we're able to use on our plane, which was a result that we had to solve that we had to solve the result of a unique way that we had to be able to be able to solve the surface of the ground, and if we had to do it.
2022-03-23 09:48:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:11 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.791 | nll_loss 4.486 | ppl 22.41 | bleu 14.05 | wps 5119.1 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.31
2022-03-23 09:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:48:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 15 @ 2350 updates, score 14.05) (writing took 0.7421863740310073 seconds)
2022-03-23 09:48:12 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:48:12 | INFO | train | epoch 015 | loss 7.007 | nll_loss 4.995 | ppl 31.88 | wps 46019.5 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.94 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1410
2022-03-23 09:48:12 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:28 | INFO | train_inner | epoch 016:     50 / 157 loss=6.858, nll_loss=4.796, ppl=27.79, wps=37986.2, ups=1.46, wpb=25944, bsz=1069.2, num_updates=2400, lr=0.0003, gnorm=0.851, loss_scale=4, train_wall=31, gb_free=14, wall=1426
2022-03-23 09:48:59 | INFO | train_inner | epoch 016:    150 / 157 loss=6.888, nll_loss=4.828, ppl=28.41, wps=79529.8, ups=3.25, wpb=24484.4, bsz=910, num_updates=2500, lr=0.0003125, gnorm=0.9, loss_scale=4, train_wall=30, gb_free=14.8, wall=1457
2022-03-23 09:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:05 | INFO | fairseq.tasks.translation | example hypothesis: and these sunlight can't use chemical chemical chemical rations.
2022-03-23 09:49:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without that, you see it, the world's different to see the world.
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between the weight and uncertainty intelligence and intelligence.
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, australia, australia and australia, the united states, the united states are the united states.
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:49:22 | INFO | fairseq.tasks.translation | example hypothesis: it could be interested in me, as i'm focused on my attention, so i can carry my attention on the other side of the other side.
2022-03-23 09:49:22 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:49:26 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can reconstruct our computer, the brains to create this new tool when it would be part of the physical body.
2022-03-23 09:49:26 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact?
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:49:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this reflection, we can start with traditional face with a traditional face of the face of the face, and the real shape of the face of the information, and there's a whole structure that's all of the information that we're using the information, and the whole structure of the information, and all the information that we can begin to use of the information, and the information that's all the information that we can begin to use
2022-03-23 09:49:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting to be here for tedtedwomen, "yeah, when someone said," well, if you have the best thing to say, "'"' "'"' "'"' "'"' "'"' "'"' "'"' "'" and we've been working on, "and then we've been working with you know, if we've been working with you've been working on the truth,"' "'"' "'"' "'" and then we've been working on the truth, "and then we've been working with you've been working with you know," and then, "and then,"' "'"' "'"' "'"' "'"' "'"' "'"' "and then we've been working on this
2022-03-23 09:49:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother, and a big design of design, we had to see the design of the airport, that we had to solve a unique problem, so we had to solve the unique problems, and if we had to solve it, it's still connected to the surface of a level, if you have to see that it's still to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you have to see the ground, if you have to see the ground, and see that it's a big, and to see that if you have to see that if you have to see that if you have to see that it's a big, if you have to see that you have to see that it's a big, if you have to see that if you have to see the surface of a big, if you're going to see that,
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:44 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.687 | nll_loss 4.309 | ppl 19.82 | bleu 16.13 | wps 4246.7 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.13
2022-03-23 09:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:49:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 16 @ 2507 updates, score 16.13) (writing took 1.7633991069160402 seconds)
2022-03-23 09:49:46 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:49:46 | INFO | train | epoch 016 | loss 6.828 | nll_loss 4.752 | ppl 26.95 | wps 42125.8 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.907 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1504
2022-03-23 09:49:46 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:15 | INFO | train_inner | epoch 017:     93 / 157 loss=6.691, nll_loss=4.569, ppl=23.74, wps=32941, ups=1.31, wpb=25136.7, bsz=1023.9, num_updates=2600, lr=0.000325, gnorm=0.872, loss_scale=4, train_wall=31, gb_free=14.4, wall=1533
2022-03-23 09:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:39 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rocket.
2022-03-23 09:50:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:50:43 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize that you can see the world.
2022-03-23 09:50:43 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:50:47 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between balance and uncertainty, instinct intelligence.
2022-03-23 09:50:47 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:50:50 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, japan and australia, australia, the countries of the united states.
2022-03-23 09:50:50 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:50:55 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, so i'm focused on my attention in the other side.
2022-03-23 09:50:55 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:50:59 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can imagine our computers can restore, the brain has been able to create this new tool when it was part of the body.
2022-03-23 09:50:59 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:51:03 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact that we have?
2022-03-23 09:51:03 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:51:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional face of traditional face that can start with a traditional face, and the real face of the face of the face, and the information is to reconstruct it.
2022-03-23 09:51:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we're doing interesting, and then, for me, is to be here at tedtedwomen, that's... yeah, that......... yeah, it was the best thing that's when you say, "if you're working on a table," we're working with this time, "and then we're working with you're working with this time."
2022-03-23 09:51:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:13 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still able to use the invention of the invention, and a great part of the design that we're using on our plane was a plane that was a result of it was able to solve.
2022-03-23 09:51:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:13 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.428 | nll_loss 3.963 | ppl 15.59 | bleu 19.05 | wps 4773.9 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.05
2022-03-23 09:51:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:51:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.05) (writing took 1.7120204959064722 seconds)
2022-03-23 09:51:15 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:51:15 | INFO | train | epoch 017 | loss 6.647 | nll_loss 4.51 | ppl 22.79 | wps 44127.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.827 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1593
2022-03-23 09:51:15 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:51:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:27 | INFO | train_inner | epoch 018:     36 / 157 loss=6.6, nll_loss=4.446, ppl=21.8, wps=35054.9, ups=1.4, wpb=25105.8, bsz=998.2, num_updates=2700, lr=0.0003375, gnorm=0.821, loss_scale=4, train_wall=31, gb_free=13.8, wall=1605
2022-03-23 09:51:58 | INFO | train_inner | epoch 018:    136 / 157 loss=6.44, nll_loss=4.236, ppl=18.84, wps=80754.8, ups=3.19, wpb=25301.2, bsz=1070.7, num_updates=2800, lr=0.00035, gnorm=0.773, loss_scale=4, train_wall=31, gb_free=14.9, wall=1636
2022-03-23 09:52:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rocket.
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:52:12 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-23 09:52:12 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe and wrong, instinct and intelligence.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:52:20 | INFO | fairseq.tasks.translation | example hypothesis: especially focus on japan, korea and australia, countries, who were connected to the united states.
2022-03-23 09:52:20 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:52:24 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i'm my attention to the circuits of the circuits on the other side.
2022-03-23 09:52:24 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:52:28 | INFO | fairseq.tasks.translation | example hypothesis: so fast as we can restore our computers, the brains of this new tool to form this new tool as a part of the primate.
2022-03-23 09:52:28 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:52:32 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from bery, at stanford, at the indian science institute, who come out and bring our scientific experiments.
2022-03-23 09:52:32 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:52:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big face of the face and reform information through this whole structure, which is all the structure of this structure, and all the structure.
2022-03-23 09:52:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:40 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and measure it for me to be here at tedwomen, is that...
2022-03-23 09:52:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:42 | INFO | fairseq.tasks.translation | example hypothesis: luluckily, the mother's mother's invention, and a big part of design work that we use on the plane, was a result that we had to solve the unique problems on the ground -- all over the ground, and if you use it to see the ground, you're going to use the ground, you're going to see it, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to use a big part of a big part of the aircraft, you're going to see, you're going to see, or you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see, you're going to see
2022-03-23 09:52:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:42 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.325 | nll_loss 3.802 | ppl 13.95 | bleu 20.85 | wps 4820.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.85
2022-03-23 09:52:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:52:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:52:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:52:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.85) (writing took 1.8220173493027687 seconds)
2022-03-23 09:52:44 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:52:44 | INFO | train | epoch 018 | loss 6.477 | nll_loss 4.284 | ppl 19.49 | wps 44276.9 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.786 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1682
2022-03-23 09:52:45 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:10 | INFO | train_inner | epoch 019:     79 / 157 loss=6.36, nll_loss=4.129, ppl=17.5, wps=35676.8, ups=1.4, wpb=25544.4, bsz=989.9, num_updates=2900, lr=0.0003625, gnorm=0.727, loss_scale=4, train_wall=31, gb_free=13.6, wall=1708
2022-03-23 09:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:37 | INFO | fairseq.tasks.translation | example hypothesis: these sunk can't use chemical rockets.
2022-03-23 09:53:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:53:42 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you see it, you see the world differently.
2022-03-23 09:53:42 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe between faith between faith and reason, instinct intelligence and intelligence.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:53:49 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea, korea and australia, countries that are connected to the united states.
2022-03-23 09:53:49 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:53:53 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused on my attention, so i can carry my attention in the circuit on the other side.
2022-03-23 09:53:53 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:53:58 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can reconstruct our computers, we can reform the brains of this new tool to make this new tool as it would be part of the primate.
2022-03-23 09:53:58 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:54:02 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, from the indian science institute that come from from the indian science institute, and our kids get a lot of scientific reform.
2022-03-23 09:54:02 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:54:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection, we can start with a traditional face that can start with a traditional facial face, and the shape of the face, and the information is the whole structure that all the structure of this structure, the structure of this structure, and the whole structure, and the whole structure is the whole structure, and we can make all the structure.
2022-03-23 09:54:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:11 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and measure it interesting and measure it for me to be here at tedwomen, is that... yes,......... in the best thing that someone said to you, "the men who are saying," if we're working on a table and say, "if we're going to support the truth for you know," the truth is a long time we've already starting to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be here at tedtalk to be here at tedmed with this talk to be here at tedmed with
2022-03-23 09:54:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:14 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention of invention, and a big part of design work that we're at the plane on our plane, was a result of it that we had to solve the unique problems that were connected to the ground -- everything that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, and see a huge part of a huge part of a huge part of a huge part of a huge amount of the ground, if you can see that if you can see that if you can see that if you can see that if you can see that if you can see that if you can see that if you can see that if you can see that if you can see a huge amount of a huge amount of an air-based on our aircraft,
2022-03-23 09:54:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:14 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.224 | nll_loss 3.675 | ppl 12.77 | bleu 22.53 | wps 4536.5 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 22.53
2022-03-23 09:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 19 @ 2978 updates, score 22.53) (writing took 1.7776558720506728 seconds)
2022-03-23 09:54:15 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:54:15 | INFO | train | epoch 019 | loss 6.314 | nll_loss 4.067 | ppl 16.76 | wps 43335.8 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.731 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1773
2022-03-23 09:54:16 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:23 | INFO | train_inner | epoch 020:     22 / 157 loss=6.279, nll_loss=4.022, ppl=16.24, wps=33782.5, ups=1.37, wpb=24602.2, bsz=1016.5, num_updates=3000, lr=0.000375, gnorm=0.747, loss_scale=4, train_wall=30, gb_free=13.8, wall=1781
2022-03-23 09:54:54 | INFO | train_inner | epoch 020:    122 / 157 loss=6.161, nll_loss=3.867, ppl=14.59, wps=81332.6, ups=3.16, wpb=25699.2, bsz=1067.5, num_updates=3100, lr=0.0003875, gnorm=0.689, loss_scale=4, train_wall=31, gb_free=14.3, wall=1812
2022-03-23 09:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:09 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rocket rakets.
2022-03-23 09:55:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:55:13 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 09:55:13 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:55:17 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between faith and reason, instincts and intelligence.
2022-03-23 09:55:17 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:55:20 | INFO | fairseq.tasks.translation | example hypothesis: very, particularly focus it on japan, korea and australia, countries who are connected to the united states.
2022-03-23 09:55:20 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:55:24 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention to the circuit on the other side.
2022-03-23 09:55:24 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:55:28 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can reconstruct our computer, the brain needles to form this new tool as it would be part of the primates of primates.
2022-03-23 09:55:28 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:55:33 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact that we have professors from, from berkeley, at stanford, from the indian science institute, who come and bring our kids to our scientific formal formula, the experiments that go far beyond normal education.
2022-03-23 09:55:33 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:55:36 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face and the shape of the real shape, and through that information that makes it all the structure of the porports and all the structure.
2022-03-23 09:55:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:40 | INFO | fairseq.tasks.translation | example hypothesis: th: yeah, when someone said, "stop the men and say," if we're working with you. "
2022-03-23 09:55:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the unique problems that were connected to the ground, and it's all of us to be able to use the refrigeration of the air, and if you're going to be able to see that we had to solve the unique problems that were connected to the ground.
2022-03-23 09:55:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:41 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.094 | nll_loss 3.543 | ppl 11.65 | bleu 22.52 | wps 4987.4 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.53
2022-03-23 09:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:55:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:55:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 20 @ 3135 updates, score 22.52) (writing took 0.7476900066249073 seconds)
2022-03-23 09:55:42 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:55:42 | INFO | train | epoch 020 | loss 6.189 | nll_loss 3.903 | ppl 14.95 | wps 45497.5 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.716 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 1860
2022-03-23 09:55:43 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:03 | INFO | train_inner | epoch 021:     65 / 157 loss=6.137, nll_loss=3.833, ppl=14.26, wps=35790.7, ups=1.45, wpb=24609.9, bsz=972.3, num_updates=3200, lr=0.0004, gnorm=0.709, loss_scale=4, train_wall=30, gb_free=14.3, wall=1881
2022-03-23 09:56:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:35 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 09:56:35 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:56:39 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-23 09:56:39 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:56:43 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else find a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:56:43 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:56:47 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, the endangered of the u.s..
2022-03-23 09:56:47 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:56:50 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how concentrated i'm so that i can carry my attention on the circuit.
2022-03-23 09:56:50 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:56:54 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can restore our computers, the brain activity to form this new tool.
2022-03-23 09:56:54 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:56:57 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, who come and teach our kids a lot of scientific reformers.
2022-03-23 09:56:57 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:57:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial and the basic shape of the face.
2022-03-23 09:57:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we're doing high-interesting and measured to tedwomen, is that... well, when it was the best thing that somebody said to you said, "stop the men in the table, and then if we're going to support the revolution, and then we're going to support you."
2022-03-23 09:57:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design that we use at the airport was a result of it that we had to solve the unique problems that we had to solve the problems that were connected to the ground to the ground, and if you use the refrifrigergeration, or if you use the refrigergergergeration of the refrigergeration, or if you use the refrigergergergeration of the refrigeration.
2022-03-23 09:57:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:06 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.069 | nll_loss 3.479 | ppl 11.15 | bleu 21.9 | wps 5321.6 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 22.53
2022-03-23 09:57:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:57:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 09:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 21 @ 3292 updates, score 21.9) (writing took 0.802446361631155 seconds)
2022-03-23 09:57:07 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:57:07 | INFO | train | epoch 021 | loss 6.09 | nll_loss 3.772 | ppl 13.67 | wps 46519.3 | ups 1.85 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.701 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1945
2022-03-23 09:57:08 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:10 | INFO | train_inner | epoch 022:      8 / 157 loss=6.097, nll_loss=3.781, ppl=13.74, wps=37454.7, ups=1.48, wpb=25247.4, bsz=1007.4, num_updates=3300, lr=0.0004125, gnorm=0.708, loss_scale=4, train_wall=31, gb_free=14.3, wall=1949
2022-03-23 09:57:42 | INFO | train_inner | epoch 022:    108 / 157 loss=5.931, nll_loss=3.566, ppl=11.84, wps=81791.5, ups=3.16, wpb=25856.5, bsz=1029.7, num_updates=3400, lr=0.000425, gnorm=0.577, loss_scale=4, train_wall=31, gb_free=14.2, wall=1980
2022-03-23 09:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:00 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 09:58:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:58:04 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-23 09:58:04 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:58:08 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:58:08 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:58:12 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries who are connected to the united states.
2022-03-23 09:58:12 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:58:16 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention degrees in the circuit on the other side.
2022-03-23 09:58:16 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:58:20 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can reconstruct our computer, the brain activity of the new tool to form this new tool as if it was part of the body of primates.
2022-03-23 09:58:20 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:58:24 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professor from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers that go to normal education that go far beyond normal education.
2022-03-23 09:58:24 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:58:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, the big constructions of the face and the basic shape of the face, and the basic shape of the face is restored, and through that information, and through that information that's all the porting the porting the portion, we can fold it.
2022-03-23 09:58:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we're doing high and measured for me here at tedwomen is that... well, when it was put on the best, when somebody said, "well, when somebody said," well, "turn it up to the men and say," well, when we say, "well, when we say," well, "well, we're going to support you know," well, "well, we're working on," well, "well, we're going to support you know," well, we're working on, we're going to support you know, we're working on, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 09:58:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, we still need to solve the mother of invention, and a big part of the design work that we use on our plane on the stest, was a result of it was that we had to solve the unique problems that we had to solve the unique problems that were connected to the ground -- all of us from a variation of refrigeration, and a continuous refriction of the refrigeration of the refrigeration, and the refrigeration of the refrightening system, and the refrigeration, which allows us to refriction to see that if you to see that if you to refrightening the refrightening the refrightening the refrightening the refrightening the refrigeration, if you can't have to the refrigeration, if you can't see that if you can't use the refrightening the refrightening the refrigeration, if you can
2022-03-23 09:58:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:36 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 5.958 | nll_loss 3.338 | ppl 10.11 | bleu 25.37 | wps 4610.1 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 25.37
2022-03-23 09:58:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:58:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:58:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 09:58:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 22 @ 3449 updates, score 25.37) (writing took 1.8041381277143955 seconds)
2022-03-23 09:58:38 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:58:38 | INFO | train | epoch 022 | loss 5.958 | nll_loss 3.603 | ppl 12.15 | wps 43541.8 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.631 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2036
2022-03-23 09:58:38 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:58:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:54 | INFO | train_inner | epoch 023:     51 / 157 loss=5.947, nll_loss=3.589, ppl=12.04, wps=33707.4, ups=1.39, wpb=24328.4, bsz=1036.3, num_updates=3500, lr=0.0004375, gnorm=0.682, loss_scale=4, train_wall=30, gb_free=14, wall=2052
2022-03-23 09:59:25 | INFO | train_inner | epoch 023:    151 / 157 loss=5.855, nll_loss=3.469, ppl=11.07, wps=80790.6, ups=3.21, wpb=25147.8, bsz=992, num_updates=3600, lr=0.00045, gnorm=0.58, loss_scale=4, train_wall=31, gb_free=14, wall=2083
2022-03-23 09:59:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:31 | INFO | fairseq.tasks.translation | example hypothesis: these sunk can't use chemical rakets.
2022-03-23 09:59:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 09:59:35 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 09:59:35 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 09:59:39 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between belief and reason, instinct and intelligence.
2022-03-23 09:59:39 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 09:59:42 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 09:59:42 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 09:59:46 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how concentrated i'm so that i can carry my attention degree in the circuit on the other side.
2022-03-23 09:59:46 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 09:59:50 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can restore our computer, the brain activity to form this new tool as if it would be a body part of primates.
2022-03-23 09:59:50 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 09:59:54 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from, from berkeley, stanford, from indian science institute that come and teach our children a lot of scientific formers that go far beyond normal education.
2022-03-23 09:59:54 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 09:59:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, the big constructions of the face and the basic shape, and through that one information, the whole portion, the whole portion and all folds.
2022-03-23 09:59:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are highly interesting and measured to me here at tedwomen is that... tyes, when it was stripped in the best than someone said, "stop the men in a table, and then we're going to support them, and then we're going to support them."
2022-03-23 10:00:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of design work that we're at our plane, was a result of that we had to solve the unique problems so it was connected to the ground -- all of the continued to a continuous variation of design, and that allows us to refrightened to refrigerate, and to see that if you could see the refrightening system, or the refrightened by the refrightening system, and if you could either the refrightened to see the refrightened to the refrightened to see the refrightened to the refrightened to the refrightening, and to see if you could see the refrightening, and to the refrightening, and to the refrightened to the refrightening, and to the refrightened to the refrightened to the refriction
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:05 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.819 | nll_loss 3.159 | ppl 8.93 | bleu 26.91 | wps 4873.5 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.91
2022-03-23 10:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:00:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:00:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.91) (writing took 1.9573237407021224 seconds)
2022-03-23 10:00:07 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:00:07 | INFO | train | epoch 023 | loss 5.863 | nll_loss 3.479 | ppl 11.15 | wps 44309.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.592 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2125
2022-03-23 10:00:07 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:37 | INFO | train_inner | epoch 024:     94 / 157 loss=5.785, nll_loss=3.381, ppl=10.42, wps=35504.6, ups=1.4, wpb=25359.4, bsz=1073.3, num_updates=3700, lr=0.0004625, gnorm=0.61, loss_scale=4, train_wall=31, gb_free=14, wall=2155
2022-03-23 10:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:00 | INFO | fairseq.tasks.translation | example hypothesis: these sunk can't use chemical rockets.
2022-03-23 10:01:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:01:04 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you notice it, you see the world differently.
2022-03-23 10:01:04 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:01:08 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find another balance between faith and reason, instinct and intelligence.
2022-03-23 10:01:08 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 10:01:11 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:01:15 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused i can carry my attention degrees in the circuit on the other side.
2022-03-23 10:01:15 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:01:19 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity to form this new tool as if it was a body part of primates.
2022-03-23 10:01:19 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:01:23 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berkeley, stanford, from indian science institute that come and teach our children a lot of scientific formers that go far beyond normal class.
2022-03-23 10:01:23 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:01:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, the grows of the face and the basic shape of the face of the face of the face and fold it through that information that folds all the porting structure.
2022-03-23 10:01:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:01:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be highly interesting to me here at tedwomen is that... tyes, when someone said, "turn you up to the men in the table and say," well, if the revolution begins to support you. "
2022-03-23 10:01:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:01:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a huge part of design work that we're at the stumber, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous refrigeration and a refrigeration system that allows us to use a refrightening system, or if you can either use the propelled by a mechanism for a mechanism.
2022-03-23 10:01:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:01:32 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.844 | nll_loss 3.198 | ppl 9.18 | bleu 25.96 | wps 5193.3 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.91
2022-03-23 10:01:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:01:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:01:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 24 @ 3763 updates, score 25.96) (writing took 0.7903272639960051 seconds)
2022-03-23 10:01:32 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:01:32 | INFO | train | epoch 024 | loss 5.792 | nll_loss 3.389 | ppl 10.47 | wps 46204.6 | ups 1.84 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.599 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2210
2022-03-23 10:01:33 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:45 | INFO | train_inner | epoch 025:     37 / 157 loss=5.747, nll_loss=3.329, ppl=10.05, wps=37264.1, ups=1.48, wpb=25260, bsz=1026.2, num_updates=3800, lr=0.000475, gnorm=0.583, loss_scale=4, train_wall=31, gb_free=14.8, wall=2223
2022-03-23 10:02:16 | INFO | train_inner | epoch 025:    137 / 157 loss=5.727, nll_loss=3.305, ppl=9.88, wps=80272.3, ups=3.17, wpb=25303.9, bsz=1010.7, num_updates=3900, lr=0.0004875, gnorm=0.58, loss_scale=4, train_wall=31, gb_free=14, wall=2254
2022-03-23 10:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example hypothesis: these sunk can't use chemical rockets.
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:02:30 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world differently.
2022-03-23 10:02:30 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:02:34 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 10:02:34 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:02:37 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 10:02:37 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention degrees in the circuit on the other side.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, we can restore the brain activity to form this new tool, as if it was a body part of primates.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:02:50 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formal experiments that go far beyond normal education.
2022-03-23 10:02:50 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:02:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection reflection, we can start with a traditional face, the grows of the face, and the basic shape of the right and the basic shape of the information that folds the whole portion and all the fits.
2022-03-23 10:02:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured for me to be here at tedwomen is that... well, when they were the best summarized when somebody said, "turn to the men in your table and say," if the revolution starts to support you, "the truth is that we have been supporting women is already," we have been supporting for you for a long time, "we're going to have a" we're going to be very long time, "we're going to be supporting," we're going to be supported by a "we're going to be supporting," we're going to help you know, "we're going to be very long."
2022-03-23 10:02:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we are at our plane at the stest, was a result of that we had to solve the unique problems that were connected to the ground -- all of a continuous variation and refrigeration system that allows us to be refrightened to use with a refrigeration, or if you can use the refueled motor motor motor motor motor motor remotism, it's a particular mechanism, or the remotism that allows us to be connected to be connected to move the refueled by the refrigergergergeration of the remotism that we can either be able to the remotism.
2022-03-23 10:03:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:00 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.687 | nll_loss 2.99 | ppl 7.95 | bleu 28.85 | wps 4787.3 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.85
2022-03-23 10:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:03:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.85) (writing took 1.8236946938559413 seconds)
2022-03-23 10:03:02 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:03:02 | INFO | train | epoch 025 | loss 5.713 | nll_loss 3.286 | ppl 9.76 | wps 44023.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.58 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2300
2022-03-23 10:03:02 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:03:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:28 | INFO | train_inner | epoch 026:     80 / 157 loss=5.63, nll_loss=3.18, ppl=9.07, wps=34507.3, ups=1.4, wpb=24652.2, bsz=1026.6, num_updates=4000, lr=0.0005, gnorm=0.536, loss_scale=4, train_wall=30, gb_free=20.1, wall=2326
2022-03-23 10:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:03:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly without realizing it, you can see the world differently.
2022-03-23 10:03:59 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:04:03 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example hypothesis: in particular, it's focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:04:07 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:04:11 | INFO | fairseq.tasks.translation | example hypothesis: it could be interested in how focused i am so that i can wear my attention level in the circuit board on the other side.
2022-03-23 10:04:11 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:04:15 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, we can recover the brain activity to create this new tool as if it was a body part of the primate.
2022-03-23 10:04:15 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from indian science institute that come and teach our children a lot of scientific formal experiments that go far beyond normal class.
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:04:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face that gives the grows constructions of the face and the basic shape, and refits it through that information that folds all the porting structure and fold it through the whole portion structure.
2022-03-23 10:04:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:04:27 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen is that... tyes, when he was stripped down, when somebody said, "turn to men in your table and tell them," when the revolution starts to support you. "
2022-03-23 10:04:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:04:28 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a huge part of the design work that we're at our aircraft was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigerator system that allows us to use a refrigerator, or to see that it's a refrigerator in the aircraft.
2022-03-23 10:04:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:04:28 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.679 | nll_loss 2.973 | ppl 7.85 | bleu 27.95 | wps 4997.9 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.85
2022-03-23 10:04:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:04:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:04:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:04:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 26 @ 4077 updates, score 27.95) (writing took 0.8278898242861032 seconds)
2022-03-23 10:04:29 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:04:29 | INFO | train | epoch 026 | loss 5.656 | nll_loss 3.214 | ppl 9.28 | wps 45443.4 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.566 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2387
2022-03-23 10:04:29 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:37 | INFO | train_inner | epoch 027:     23 / 157 loss=5.66, nll_loss=3.219, ppl=9.31, wps=36195.2, ups=1.45, wpb=25007.4, bsz=1000.1, num_updates=4100, lr=0.000493865, gnorm=0.573, loss_scale=4, train_wall=31, gb_free=13.8, wall=2395
2022-03-23 10:05:08 | INFO | train_inner | epoch 027:    123 / 157 loss=5.607, nll_loss=3.153, ppl=8.89, wps=79801.1, ups=3.2, wpb=24952.8, bsz=975.6, num_updates=4200, lr=0.00048795, gnorm=0.539, loss_scale=4, train_wall=31, gb_free=14.1, wall=2426
2022-03-23 10:05:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:05:22 | INFO | fairseq.tasks.translation | example hypothesis: this sonde can't use chemical rockets.
2022-03-23 10:05:22 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:05:26 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 10:05:26 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:05:30 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find another balance between faith and reason, instinct and intelligence.
2022-03-23 10:05:30 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:05:34 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 10:05:34 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:05:38 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused i am so that i can carry my attention degrees in the circuit on the other side.
2022-03-23 10:05:38 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:05:42 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, we can restore the brain activity to form this new tool as if it was a part of the primate.
2022-03-23 10:05:42 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:05:46 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers that go far beyond normal class.
2022-03-23 10:05:46 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:05:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big configurations of the face and the basic shape, and emphasize it through that one information that makes all the entire porting structure and all the fuses.
2022-03-23 10:05:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, when dinner was put it in the best place, as someone said, "turn on the men in your table and say," if the revolution starts to be here, we're actually supporting you that women have already been supported in this topic for you. "
2022-03-23 10:05:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our plane at the stest was a result of solving the unique problems that were connected to the ground -- everything, from a continuous variation, and a refrigeration system that allows us to be refrigerated by a refrigering machine, to a refrigeration, to the most refrigeration, to a searching machine, either if you can see that, or if you can see the most trigger, or if you can either, if you can solve the most trigger, if you can see the most triggergergergergergergering the most, or if you can see the ground, or if you can see the most triggergergergergergergergergergergergergergergergergergergergergering, if you can see the most trigger, or if you can see the most trigger, if you can
2022-03-23 10:05:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:57 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.614 | nll_loss 2.894 | ppl 7.43 | bleu 29.53 | wps 4759.2 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.53
2022-03-23 10:05:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:05:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:05:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.53) (writing took 1.8592604110017419 seconds)
2022-03-23 10:05:59 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:05:59 | INFO | train | epoch 027 | loss 5.593 | nll_loss 3.134 | ppl 8.78 | wps 44111 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.553 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2477
2022-03-23 10:05:59 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:19 | INFO | train_inner | epoch 028:     66 / 157 loss=5.531, nll_loss=3.054, ppl=8.31, wps=35583.1, ups=1.4, wpb=25425.4, bsz=1071.8, num_updates=4300, lr=0.000482243, gnorm=0.566, loss_scale=4, train_wall=30, gb_free=14.5, wall=2497
2022-03-23 10:06:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:52 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:06:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:06:55 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden without realizing it, you can see the world differently.
2022-03-23 10:06:55 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:06:59 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:06:59 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:07:03 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 10:07:03 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:07:07 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can put my attention degrees in the circuit on the other side.
2022-03-23 10:07:07 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:07:11 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, we can restore the brain activity to form this new tool, as if it was a body part of primates.
2022-03-23 10:07:11 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:07:15 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formers that are far beyond normal education.
2022-03-23 10:07:15 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:07:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the grows of the face and the basic shape, and embedded it through the thief information that folds all the porting structure and all the ffunga.
2022-03-23 10:07:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:07:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's been highly interesting and measured for me here at tedwomen is that -- well, in strictly dinner, it's the best thing that somebody said, "turn to the men at dtable and tell them," if the revolution starts. '' '' '' '' '' '' '' '' '' 'the truth that we have been supported for you. "
2022-03-23 10:07:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:07:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we are at our plane on the stumber was a result of that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variation and a refrigerator system that allows us to use a rivers and a refrigerator that allows us to keep a right-hand machine that allows us to the trucks, and if you can see it in the trucks, or if you can see the trucks.
2022-03-23 10:07:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:07:25 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.577 | nll_loss 2.852 | ppl 7.22 | bleu 29.54 | wps 4960.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.54
2022-03-23 10:07:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:07:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.54) (writing took 1.8003750308416784 seconds)
2022-03-23 10:07:27 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:07:27 | INFO | train | epoch 028 | loss 5.515 | nll_loss 3.036 | ppl 8.2 | wps 44873.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.509 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2565
2022-03-23 10:07:27 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:30 | INFO | train_inner | epoch 029:      9 / 157 loss=5.529, nll_loss=3.054, ppl=8.3, wps=35963.9, ups=1.42, wpb=25343.1, bsz=984.4, num_updates=4400, lr=0.000476731, gnorm=0.502, loss_scale=4, train_wall=31, gb_free=13.7, wall=2568
2022-03-23 10:08:01 | INFO | train_inner | epoch 029:    109 / 157 loss=5.439, nll_loss=2.938, ppl=7.66, wps=79936.8, ups=3.2, wpb=24969.6, bsz=1032.4, num_updates=4500, lr=0.000471405, gnorm=0.456, loss_scale=4, train_wall=31, gb_free=14.8, wall=2599
2022-03-23 10:08:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:08:20 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:08:20 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:08:24 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly without you notice it, you see the world differently.
2022-03-23 10:08:24 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:08:28 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:08:28 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:08:32 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are the united states.
2022-03-23 10:08:32 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:08:36 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i'm so that i can carry my attention degree in the circuit on the other side.
2022-03-23 10:08:36 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:08:39 | INFO | fairseq.tasks.translation | example hypothesis: as soon as we can restore our computers, the brain activity locks up to form this new tool, as if it was a body part of the primate.
2022-03-23 10:08:39 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:08:44 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:08:44 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:08:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the grows of the face and the basic shape, and put it through that information that pulls all the porting structure and all the fffits.
2022-03-23 10:08:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be highly interesting and measured to me here at tedwomen is that... well, when dinner became the best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts to support you, the truth is that we've already been supporting you. "
2022-03-23 10:08:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane was a result of that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous, refrigerator, that allows us to use aircraft in the aircraft to move the ground to the ground, if you can see it in the ground, or if you can see it, you're either the most trigger, you're going to the crawling up to the ground, if you're going to the ground, you're going to the car truck up until you're going to the ground, you're going to the vehicle, you're going to the ground, you can see it, you can see it in a special, you can see it, you can see that you're going to the ground, you can see it, you can see it, or if you're either use it, you can see it, you can see it, you can see it,
2022-03-23 10:08:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:54 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.532 | nll_loss 2.805 | ppl 6.99 | bleu 30.29 | wps 4804.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.29
2022-03-23 10:08:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:08:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:08:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:08:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.29) (writing took 2.0035628490149975 seconds)
2022-03-23 10:08:56 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:08:56 | INFO | train | epoch 029 | loss 5.44 | nll_loss 2.94 | ppl 7.67 | wps 44163.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.457 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2654
2022-03-23 10:08:56 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:08:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:09:13 | INFO | train_inner | epoch 030:     52 / 157 loss=5.432, nll_loss=2.932, ppl=7.63, wps=35553.2, ups=1.4, wpb=25459.7, bsz=1003, num_updates=4600, lr=0.000466252, gnorm=0.477, loss_scale=4, train_wall=31, gb_free=14.7, wall=2671
2022-03-23 10:09:44 | INFO | train_inner | epoch 030:    152 / 157 loss=5.403, nll_loss=2.894, ppl=7.43, wps=80829.1, ups=3.22, wpb=25116.1, bsz=1053.4, num_updates=4700, lr=0.000461266, gnorm=0.473, loss_scale=4, train_wall=31, gb_free=13.8, wall=2702
2022-03-23 10:09:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:50 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:09:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:09:53 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world differently.
2022-03-23 10:09:53 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:09:57 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 10:09:57 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:10:01 | INFO | fairseq.tasks.translation | example hypothesis: it's especially focused on japan, korea and australia, countries that are end-connected in the united states.
2022-03-23 10:10:01 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:10:05 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i am so that i can put my attention degree on the board on the other side.
2022-03-23 10:10:05 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:10:09 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, the brain activity is restoring to form this new tool as if it was a body of primate.
2022-03-23 10:10:09 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:10:13 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute that comes and teach our kids a lot of scientific format, experiments that go far beyond normal class.
2022-03-23 10:10:13 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:10:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big configurations of the face and the basic shape, and deploys it through the thief information that pulls the entire portion structure and all the fences.
2022-03-23 10:10:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:10:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to the men at dtable and say," if the revolution begins to support you. "] 'the truth is that we've already been supporting you,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:10:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:10:24 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a big part of the design work that we're at our plane at the stumest was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a refrigerator system that allows us to use a right-hand flight machine machine, or to see that you can either get rid of a propelled trajectory, or if you're going to see the propelled, if you're going to be able to see it, if you're going to be able to see that you're going to see it, if you're going to the most reliable to see that you're going to see the most reliable to the most reliable to the most reliable to see it, if you're going to the most reliable, if you're going to see it, if you're going to get rid of the most reliable to get rid of the most reliable to see
2022-03-23 10:10:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:10:24 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 5.477 | nll_loss 2.744 | ppl 6.7 | bleu 31.02 | wps 4820.4 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.02
2022-03-23 10:10:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:10:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:10:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:10:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.02) (writing took 2.2611904172226787 seconds)
2022-03-23 10:10:26 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:10:26 | INFO | train | epoch 030 | loss 5.414 | nll_loss 2.908 | ppl 7.5 | wps 43949.7 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.487 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2744
2022-03-23 10:10:26 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:10:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:56 | INFO | train_inner | epoch 031:     95 / 157 loss=5.359, nll_loss=2.837, ppl=7.14, wps=34916, ups=1.38, wpb=25253.7, bsz=993, num_updates=4800, lr=0.000456435, gnorm=0.477, loss_scale=4, train_wall=31, gb_free=13.5, wall=2774
2022-03-23 10:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:11:19 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:11:19 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:11:23 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world differently.
2022-03-23 10:11:23 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:11:26 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:11:26 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:11:30 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:11:30 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:11:34 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i am, so i can carry my attention level on the board.
2022-03-23 10:11:34 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:11:38 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can reconfront our computers, the brain activity shifts to form this new tool as if it was a body part of primates.
2022-03-23 10:11:38 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:11:42 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:11:42 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:11:46 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can, which restores the face and the basic shape, and exposes it through the one that refits the entire portion structure and all the fits.
2022-03-23 10:11:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me here at tedwomen is that... well, when dinner was stripped, it was best summarized, when somebody said, "turn to the men on your table and say," if the revolution begins, we support you. 'the truth is that we've already supported you in this topic. "
2022-03-23 10:11:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:53 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we are at our plane on the stumber plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a refrigeration system that allows us to use an aircraft machine to stop until you move the ground, or if you're specialized, you're in the ground, and if you're in the most vulnerable, you're in the ground, you can see the deployed, or if you're in the deployed to the deployed, the deployed to the deployed to the deployed by the deployed, the ground, the deployed by the ground, the deployed by the deployed, the deployed by the deployed by the deployed by the deployed by the deployed by the deployed by the deployed, the ground,
2022-03-23 10:11:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:53 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 5.445 | nll_loss 2.716 | ppl 6.57 | bleu 30.88 | wps 4892 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.02
2022-03-23 10:11:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:11:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:11:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:11:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 31 @ 4862 updates, score 30.88) (writing took 0.7784775220789015 seconds)
2022-03-23 10:11:53 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:11:53 | INFO | train | epoch 031 | loss 5.356 | nll_loss 2.834 | ppl 7.13 | wps 45147.2 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.474 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2831
2022-03-23 10:11:54 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:12:06 | INFO | train_inner | epoch 032:     38 / 157 loss=5.323, nll_loss=2.793, ppl=6.93, wps=35790.5, ups=1.44, wpb=24898.9, bsz=1067.6, num_updates=4900, lr=0.000451754, gnorm=0.464, loss_scale=4, train_wall=30, gb_free=13.7, wall=2844
2022-03-23 10:12:37 | INFO | train_inner | epoch 032:    138 / 157 loss=5.332, nll_loss=2.804, ppl=6.98, wps=80682.3, ups=3.18, wpb=25391.9, bsz=991.7, num_updates=5000, lr=0.000447214, gnorm=0.452, loss_scale=4, train_wall=31, gb_free=13.6, wall=2875
2022-03-23 10:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:47 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:12:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:12:51 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without knowing it, you see the world differently.
2022-03-23 10:12:51 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:12:54 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-23 10:12:54 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:12:59 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries, who are close to the united states.
2022-03-23 10:12:59 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:13:03 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am so that i can carry my attention degree in the circuit board on the other side.
2022-03-23 10:13:03 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:13:07 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computer, the brain activity shifts to form this new tool, as if it was a part of the primate.
2022-03-23 10:13:07 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:13:11 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:13:11 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:13:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big configurations of the face and the basic shape, and recovers it through that kind of information that refers the whole portion structure and all the fits.
2022-03-23 10:13:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:13:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when he was checked dinner, it was best summarized, when someone said, "turn to the men on your table and say," if the revolution starts to support you. '' '"the truth is that we've been supporting you for a long time."
2022-03-23 10:13:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:13:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our airplane on the stumber, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a cooling system that allows us to use an aircraft in the aircraft to a particular passenger, to see the ground, or if you're going to see it, if you're in the ground, if you're going to operate on the ground, you're in the ground, or if you're going to see, you're going to the ground, you're going to see it's a continuously, you're going to see it's a continuously, you're not going to see it, you're going to see it, you're going to see it, you're going to see it, you're going to see it, you're going to see it, you're going to go on,
2022-03-23 10:13:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:13:21 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 5.416 | nll_loss 2.661 | ppl 6.33 | bleu 32.38 | wps 4766.1 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 32.38
2022-03-23 10:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:13:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:13:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:13:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 32 @ 5019 updates, score 32.38) (writing took 1.7757288981229067 seconds)
2022-03-23 10:13:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:13:23 | INFO | train | epoch 032 | loss 5.309 | nll_loss 2.774 | ppl 6.84 | wps 44121.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.449 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2921
2022-03-23 10:13:23 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:13:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:49 | INFO | train_inner | epoch 033:     81 / 157 loss=5.268, nll_loss=2.722, ppl=6.6, wps=34729.6, ups=1.4, wpb=24880.4, bsz=1026.3, num_updates=5100, lr=0.000442807, gnorm=0.473, loss_scale=4, train_wall=30, gb_free=14.8, wall=2947
2022-03-23 10:14:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:14:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:14:20 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without realizing it, you see the world differently.
2022-03-23 10:14:20 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:14:24 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-23 10:14:24 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:14:28 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries, the enlies of the united states.
2022-03-23 10:14:28 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:14:32 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i am, so i can put my attention degree in the board on the other side.
2022-03-23 10:14:32 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:14:36 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity is shifting to this new tool as if it was a body of primate.
2022-03-23 10:14:36 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:14:40 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, coming and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:14:40 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:14:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face can, the grows contexture of the face and the basic shape, and reject it by the one information that comes from the entire porting structure and all the fits.
2022-03-23 10:14:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been very interesting and appropriate for me to be here at tedwomen is that, well, when i was stripped dinner, it was best summarized, when someone said, "turn to the men at your desk and say, 'if the revolution begins to support you.' '' if the truth, we've been supporting you at tedwomen, we've already started this topic for a long time. '"] ["] ["] ["] ["] [unclear] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:14:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:51 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we are at our plane at the stumest was a result of the fact that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a refrigerator and a refrigeration system that allows us to use on our plane at the aircraft on the aircraft, to move a staircase, to the crawling machine, to the crawling, to the crawling, to the craftsman, to the ground, to move it, to move it, to move it, to the ground, to the floor, to the floor, to the floor, to move it, to the vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle vehicle, to the floor, to the floor, to the floor, to move it, to the floor, to the floor, to the floor, to the floor, to the floor, to the floor,
2022-03-23 10:14:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:51 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 5.453 | nll_loss 2.696 | ppl 6.48 | bleu 32.11 | wps 4642.5 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.38
2022-03-23 10:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:14:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 33 @ 5176 updates, score 32.11) (writing took 0.843204824719578 seconds)
2022-03-23 10:14:52 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:14:52 | INFO | train | epoch 033 | loss 5.28 | nll_loss 2.738 | ppl 6.67 | wps 44126.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.484 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3010
2022-03-23 10:14:53 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:00 | INFO | train_inner | epoch 034:     24 / 157 loss=5.292, nll_loss=2.755, ppl=6.75, wps=35644.3, ups=1.4, wpb=25446.9, bsz=1002.9, num_updates=5200, lr=0.000438529, gnorm=0.501, loss_scale=4, train_wall=31, gb_free=13.7, wall=3018
2022-03-23 10:15:31 | INFO | train_inner | epoch 034:    124 / 157 loss=5.223, nll_loss=2.665, ppl=6.34, wps=80593.8, ups=3.22, wpb=25063.4, bsz=1053.4, num_updates=5300, lr=0.000434372, gnorm=0.422, loss_scale=4, train_wall=31, gb_free=14.1, wall=3049
2022-03-23 10:15:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:45 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:15:45 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:15:50 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden without realizing it, you see the world differently.
2022-03-23 10:15:50 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:15:53 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:15:53 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:15:57 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:15:57 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:16:01 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i'm so that i can put my attention degree in the board on the other side.
2022-03-23 10:16:01 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:16:05 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity is shifting to form this new tool as if it was a body of primates.
2022-03-23 10:16:05 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:16:09 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 10:16:09 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:16:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big contexts of the face and the basic shape, and put it through that one piece of information that pulls the entire porous structure and all the fones.
2022-03-23 10:16:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:16:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that -- well, when dinner was summed, it was best summed up when somebody said, "turn to the men on your table and say to you," when the revolution begins, we support you. "the truth, women is that we've already been supporting you for a long time."
2022-03-23 10:16:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:16:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane at the stumber was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigerator system with refrigeration that allows us to use an aircraft in the go-go-and-traffic machine either to a specific way, or if you had to use the most triggering mechanism.
2022-03-23 10:16:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:16:19 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.38 | nll_loss 2.633 | ppl 6.2 | bleu 32.05 | wps 4897.7 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.38
2022-03-23 10:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:16:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt
2022-03-23 10:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.05) (writing took 1.5260013118386269 seconds)
2022-03-23 10:16:20 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:16:20 | INFO | train | epoch 034 | loss 5.237 | nll_loss 2.682 | ppl 6.42 | wps 44924.6 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.445 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3098
2022-03-23 10:16:21 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:16:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:42 | INFO | train_inner | epoch 035:     67 / 157 loss=5.226, nll_loss=2.667, ppl=6.35, wps=35277.6, ups=1.42, wpb=24815.7, bsz=930.4, num_updates=5400, lr=0.000430331, gnorm=0.439, loss_scale=4, train_wall=31, gb_free=13.8, wall=3120
2022-03-23 10:17:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:17:13 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 10:17:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without knowing it, you see the world differently.
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 10:17:21 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:17:21 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 10:17:25 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 10:17:25 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 10:17:29 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the circuit board on the other side.
2022-03-23 10:17:29 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 10:17:33 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computer, the brain activity shifts to form this new tool as if it was a part of the primate.
2022-03-23 10:17:33 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 10:17:37 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-23 10:17:37 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 10:17:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big contextures of the face and the basic shape, and defects it through the information that refers the entire porte structure and all the fits folds.
2022-03-23 10:17:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that we do it very interesting and measured it for me to be here at tedwomen is that... well, when i was dinner, it was best summarized when someone said, "turn to the men at your desk and tell you," 'when the revolution begins, we support you.' '' '' '' '' the truth, we love is that we've been supporting you for a long time. "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 10:17:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our plane at the stumest was a result of that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuous variation and a refrigerator of the refrigeration and a refrigeration system that allows us to use an aircraft in the ridge to go to a go-go-go-goodbbye, to a searchy, to a searchy, to a searchy, to move the ridge, to the ridge, to a searchy, to the ridge, to the ridge, to the ridge, to a searchy when you see the ridge, to move the ridge, to the ridge, to the ridge, to the ridge, to the ridge when you get the ridge, to the ridge, to the ridge, to the ridge,
2022-03-23 10:17:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:48 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.389 | nll_loss 2.635 | ppl 6.21 | bleu 32.38 | wps 4705 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.38
2022-03-23 10:17:48 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:17:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:17:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:17:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt
2022-03-23 10:17:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#2/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.38) (writing took 1.7735651559196413 seconds)
2022-03-23 10:17:50 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:17:50 | INFO | train | epoch 035 | loss 5.2 | nll_loss 2.636 | ppl 6.22 | wps 43864 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.444 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3188
2022-03-23 10:17:50 | INFO | fairseq_cli.train | done training in 3187.8 seconds
