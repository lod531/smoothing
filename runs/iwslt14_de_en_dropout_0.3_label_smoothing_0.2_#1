Sender: LSF System <lsfadmin@eu-g3-058>
Subject: Job 210581077: <iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:23:46 2022
Job was executed on host(s) <eu-g3-058>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:23:56 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:23:56 2022
Terminated at Wed Mar 23 10:48:45 2022
Results reported at Wed Mar 23 10:48:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5083.63 sec.
    Max Memory :                                 5159 MB
    Average Memory :                             3894.16 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14841.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   5088 sec.
    Turnaround time :                            5099 sec.

The output (if any) follows:

2022-03-23 09:24:01 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.2, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:24:01 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:24:01 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:24:01 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:24:01 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:24:01 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:24:01 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:24:01 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:24:01 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:24:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:24:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:24:01 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:24:04 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:24:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:24:04 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:24:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:24:04 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:24:04 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:24:04 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 09:24:04 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 09:24:04 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:24:04 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:24:04 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:24:04 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:24:04 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:24:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:24:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:24:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:24:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:24:38 | INFO | train_inner | epoch 001:    104 / 157 loss=12.18, nll_loss=11.858, ppl=3712.58, wps=80545.3, ups=3.2, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.924, loss_scale=8, train_wall=33, gb_free=14, wall=34
2022-03-23 09:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:24:58 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:24:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:25:00 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:25:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:25:03 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,....
2022-03-23 09:25:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:25:06 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:25:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:25:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:25:15 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:25:20 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:25:26 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:25:33 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:25:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:25:35 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.724 | nll_loss 10.011 | ppl 1031.67 | bleu 0.01 | wps 4320.5 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:25:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:25:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6716366428881884 seconds)
2022-03-23 09:25:37 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:25:37 | INFO | train | epoch 001 | loss 11.795 | nll_loss 11.373 | ppl 2652.6 | wps 42404.7 | ups 1.69 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.331 | loss_scale 8 | train_wall 49 | gb_free 22.4 | wall 93
2022-03-23 09:25:37 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:25:52 | INFO | train_inner | epoch 002:     47 / 157 loss=10.855, nll_loss=10.191, ppl=1169.22, wps=34159.9, ups=1.35, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.148, loss_scale=8, train_wall=30, gb_free=14.7, wall=108
2022-03-23 09:26:24 | INFO | train_inner | epoch 002:    147 / 157 loss=10.264, nll_loss=9.401, ppl=676.03, wps=80378.7, ups=3.19, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.246, loss_scale=8, train_wall=31, gb_free=14, wall=140
2022-03-23 09:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:26:30 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:26:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:26:33 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the.
2022-03-23 09:26:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:26:38 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the.
2022-03-23 09:26:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:26:43 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:26:48 | INFO | fairseq.tasks.translation | example hypothesis: and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:26:54 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:26:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:26:59 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:27:05 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:27:12 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:27:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:27:15 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:27:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:27:15 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.985 | nll_loss 8.955 | ppl 496.12 | bleu 0.01 | wps 3644.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:27:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:27:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:27:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.9750592629425228 seconds)
2022-03-23 09:27:17 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:27:17 | INFO | train | epoch 002 | loss 10.365 | nll_loss 9.54 | ppl 744.45 | wps 39699.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.185 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 193
2022-03-23 09:27:17 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:27:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:27:45 | INFO | train_inner | epoch 003:     90 / 157 loss=10.019, nll_loss=9.039, ppl=526.2, wps=30278.6, ups=1.23, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.158, loss_scale=8, train_wall=30, gb_free=13.7, wall=221
2022-03-23 09:28:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:28:09 | INFO | fairseq.tasks.translation | example hypothesis: we the the the.
2022-03-23 09:28:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:28:12 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the.
2022-03-23 09:28:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:28:16 | INFO | fairseq.tasks.translation | example hypothesis: and the the the of the of the of the of the of the.
2022-03-23 09:28:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:28:21 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and it's's, it's, and it's, and it's's's.
2022-03-23 09:28:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:28:26 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's's's, and it's's's's's, and it's's's, and it's's's's's's's's's.
2022-03-23 09:28:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:28:31 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:28:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:28:37 | INFO | fairseq.tasks.translation | example hypothesis: and it's, and it's, it's, it's, it's, and it's's, and it's, and it's's's, and the the the the the the the the the the, and it's, and it's's's's's's's's, and it's, and it's, and it's's's
2022-03-23 09:28:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:28:43 | INFO | fairseq.tasks.translation | example hypothesis: and we, and the the, and the the the, and the the, and the the, and the the the the the the the the the the, and the the, and the the the, and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:28:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:51 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:28:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:53 | INFO | fairseq.tasks.translation | example hypothesis: and we a, the, the a a a a a a a, and the a, and the a a, and the the, and the the the the a a a a a, and the, and the, and the the, and the a a a a a a a a a a, and the, and the the the the a a a a a a a a a a a a a a a a a a a a a, and the the the the, and the, and the the the the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a, and the, and the, and the, and the, and the, and the, and the, and the a a a a a a a a a a, and the, and the, and the, and the, and the, and the, and the the the the the the the the the the the the the the the the the the a a a a
2022-03-23 09:28:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:53 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.783 | nll_loss 8.652 | ppl 402.29 | bleu 0.12 | wps 3714.2 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.12
2022-03-23 09:28:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:28:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:28:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.12) (writing took 1.7908482057973742 seconds)
2022-03-23 09:28:55 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:28:55 | INFO | train | epoch 003 | loss 9.952 | nll_loss 8.947 | ppl 493.68 | wps 40195.2 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.24 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 291
2022-03-23 09:28:55 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:28:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:29:06 | INFO | train_inner | epoch 004:     33 / 157 loss=9.831, nll_loss=8.784, ppl=440.93, wps=31462.1, ups=1.24, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.265, loss_scale=8, train_wall=31, gb_free=13.9, wall=302
2022-03-23 09:29:37 | INFO | train_inner | epoch 004:    133 / 157 loss=9.641, nll_loss=8.533, ppl=370.38, wps=80745.9, ups=3.2, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.344, loss_scale=8, train_wall=31, gb_free=12.6, wall=333
2022-03-23 09:29:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:48 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 09:29:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:29:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world of the world.
2022-03-23 09:29:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:29:56 | INFO | fairseq.tasks.translation | example hypothesis: so we have to're the world of the world.
2022-03-23 09:29:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example hypothesis: and it's a world, and it's a world.
2022-03-23 09:30:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:30:05 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not not not not not not not not not not not not not not not not not not it.
2022-03-23 09:30:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:30:10 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and this is the world, and the world of the world of the world, and the world of the world.
2022-03-23 09:30:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:30:16 | INFO | fairseq.tasks.translation | example hypothesis: but you're are the world, but you're the world, but you can're the world, but you're're the world, but it's the world, but you can can can are are are are are the world, but you can can are are are are are the world.
2022-03-23 09:30:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:30:22 | INFO | fairseq.tasks.translation | example hypothesis: so we can can can can can can can can can can can can can can can can can can can can can can can see the the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be the world of the world of the world.
2022-03-23 09:30:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:30:29 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:30:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have the world of the world of the world of the world of the world of the world, which is the world of the world of the world, which is the world of the world, which is the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, which is the world of the world of the world of the world of the world of the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see
2022-03-23 09:30:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:30:31 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.337 | nll_loss 8.06 | ppl 266.92 | bleu 1 | wps 3739.1 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1
2022-03-23 09:30:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:30:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:30:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.0) (writing took 1.803468246012926 seconds)
2022-03-23 09:30:33 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:30:33 | INFO | train | epoch 004 | loss 9.647 | nll_loss 8.542 | ppl 372.71 | wps 40125.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.309 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 389
2022-03-23 09:30:34 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:30:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:57 | INFO | train_inner | epoch 005:     76 / 157 loss=9.432, nll_loss=8.255, ppl=305.57, wps=30546.1, ups=1.24, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.457, loss_scale=8, train_wall=30, gb_free=13.4, wall=414
2022-03-23 09:31:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world in the world.
2022-03-23 09:31:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:31:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world is the world.
2022-03-23 09:31:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example hypothesis: we're going to have to be a lot of the world.
2022-03-23 09:31:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, there's a lot of the world.
2022-03-23 09:31:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:31:45 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not that we're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not
2022-03-23 09:31:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:50 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world in the world in the world, and the world in the world in the world in the world in the world, and the world in the world in the world in the world in the world in the world in the world in the world,
2022-03-23 09:31:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:56 | INFO | fairseq.tasks.translation | example hypothesis: but if you're not not not not not not not not not not to be a lot of the lot of the lot of the world, but they're going to be a lot of the world, but they're going to be not not not not not not not not not not not not not not not not not not not not not not not not not not
2022-03-23 09:31:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:32:02 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to see the world, and we're going to be a lot of the world, and we're going to see the world of the world, and we're going to see the world of the world of the world, and we can see the world, and we can see the world of the world of the world of the world, and we can see the world, and we're going to see the world of the world, and we can see
2022-03-23 09:32:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:32:10 | INFO | fairseq.tasks.translation | example hypothesis: so, "we're a lot," it's a lot, "" it's a lot, "it's a lot," it's a lot, "it's a lot," "" "" "" it's a lot, "" it's a lot, "" "it's a lot of the world," it's a lot, "" "it's a lot," "" it's a lot, "" "" "" "" "" it's a lot of the world, "it's a lot," "" it's a lot of the world, "" "" it's a lot, "" "" it's a lot, "" "it's a lot," "" it's a lot, "" "" "" it's a lot of the world, "" "" "" "" ""
2022-03-23 09:32:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:32:12 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be a lot of the way that we're a lot of the world that we have to be a lot of the world that we're a lot of the world that we have to be a lot of the world that we have to be a lot of the world that we have to be a lot of the world that we have to be a lot of the way that we have to be a lot of the way to be a lot of the world of the world that we have to be a lot of the world that we have to be a lot of the world, which is that we have to be a lot of the world that we have to go to be a lot of the world that we have to be a lot of the way to be a lot of the world of the world, and we have to be be be the world, and the world, which is that we have to have to be the world that we have to be a lot of the way that we have to go to be a lot of the way that we have
2022-03-23 09:32:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:32:12 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.034 | nll_loss 7.664 | ppl 202.85 | bleu 1.29 | wps 3576.4 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.29
2022-03-23 09:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:32:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:32:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:32:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.29) (writing took 1.8428356507793069 seconds)
2022-03-23 09:32:14 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:32:14 | INFO | train | epoch 005 | loss 9.287 | nll_loss 8.058 | ppl 266.59 | wps 39086.1 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.384 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 490
2022-03-23 09:32:15 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:32:20 | INFO | train_inner | epoch 006:     19 / 157 loss=9.19, nll_loss=7.928, ppl=243.53, wps=30529.6, ups=1.2, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.389, loss_scale=8, train_wall=30, gb_free=14.6, wall=497
2022-03-23 09:32:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:32:52 | INFO | train_inner | epoch 006:    120 / 157 loss=9.028, nll_loss=7.706, ppl=208.84, wps=79915.6, ups=3.17, wpb=25234.2, bsz=1007, num_updates=900, lr=0.0001125, gnorm=1.313, loss_scale=4, train_wall=31, gb_free=14.1, wall=528
2022-03-23 09:33:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:33:07 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 09:33:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:33:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the idea.
2022-03-23 09:33:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:33:16 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be two.
2022-03-23 09:33:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:33:20 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world.
2022-03-23 09:33:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:33:25 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do that we're going to do it's going to do that we're going to do that we're going to do that we're going to do it.
2022-03-23 09:33:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:33:30 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, and people in the world, in the world, in the world, in the world, in the world, and the world, in the world, and in the world, and in the world, and people is the world.
2022-03-23 09:33:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example hypothesis: but they're not going to see, but they're not going to be a lot of the way.
2022-03-23 09:33:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see that we can see that we can see the world.
2022-03-23 09:33:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:33:48 | INFO | fairseq.tasks.translation | example hypothesis: and if you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "it's going to say," "" "it's going to say," it's going to say, "" "" "" "" it's going to say, "" "" "" "" "" "" "" "" "" "" "it's going to say," it's a "" "" "" it's a "it's going to say," it's going to say, "you know," it's a "" it's a "it's a" it's a first first first first first first first first first first first first first, "
2022-03-23 09:33:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:51 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of fact, if we're going to be a lot of fact, we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to see that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to see that we're going to be a lot of the world, and we're going to see that we're going to
2022-03-23 09:33:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:51 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.75 | nll_loss 7.247 | ppl 151.87 | bleu 1.95 | wps 3785.9 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.95
2022-03-23 09:33:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:33:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:33:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:33:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.95) (writing took 1.8062182920984924 seconds)
2022-03-23 09:33:52 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:33:52 | INFO | train | epoch 006 | loss 9.019 | nll_loss 7.693 | ppl 206.86 | wps 39908.7 | ups 1.59 | wpb 25122.4 | bsz 1014.9 | num_updates 937 | lr 0.000117125 | gnorm 1.358 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 589
2022-03-23 09:33:53 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:12 | INFO | train_inner | epoch 007:     63 / 157 loss=8.849, nll_loss=7.466, ppl=176.81, wps=31278, ups=1.24, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.185, loss_scale=4, train_wall=30, gb_free=14.9, wall=609
2022-03-23 09:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:45 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see this.
2022-03-23 09:34:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most of the most.
2022-03-23 09:34:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a new new new new new new new new new new new way.
2022-03-23 09:34:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a lot, and it's going to be a lot of the world.
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:35:01 | INFO | fairseq.tasks.translation | example hypothesis: it's it's just just just just just to do that we're going to do it, and we're going to do it, and we're going to do it, and we're going to do that we're going to do it.
2022-03-23 09:35:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:35:06 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the world, and it's the people in the world, and the world, and it's the world.
2022-03-23 09:35:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:35:12 | INFO | fairseq.tasks.translation | example hypothesis: well, some of course, but they're not going to be a lot of the world, but they're not going to be able to be a lot, but it, but they're going to be a lot of them, but they're going to be able to be a lot, but they're going to be able to be able to be able to
2022-03-23 09:35:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:35:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the brain, and we're going to see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the
2022-03-23 09:35:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:35:25 | INFO | fairseq.tasks.translation | example hypothesis: so, if you know, we're going to say, "we're going to say," well, "we're going to say," well, "we're going to say," well, "we're going to say," we're going to go to say, "well," we're going to say, "well," and then we're going to go to say, "and then we're going to say," well, "and then we're going to say," and we're going to say, "and then we're going to go to say," well, "we're going to say," well, "we're going to say," and we're going to be a "and we're going to say," well, "you know," we're going to say, "well," we're going to say, ""
2022-03-23 09:35:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:35:28 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to get a lot of the world, and we're going to be a lot of the world, and we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:35:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:35:28 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 8.531 | nll_loss 6.919 | ppl 121.02 | bleu 2.5 | wps 3836.2 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.5
2022-03-23 09:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:35:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:35:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.5) (writing took 1.7687256489880383 seconds)
2022-03-23 09:35:30 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:35:30 | INFO | train | epoch 007 | loss 8.743 | nll_loss 7.326 | ppl 160.41 | wps 40675.6 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.136 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 686
2022-03-23 09:35:30 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:35:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:32 | INFO | train_inner | epoch 008:      6 / 157 loss=8.686, nll_loss=7.249, ppl=152.16, wps=31483.6, ups=1.26, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.179, loss_scale=4, train_wall=30, gb_free=14.4, wall=688
2022-03-23 09:36:03 | INFO | train_inner | epoch 008:    106 / 157 loss=8.495, nll_loss=6.994, ppl=127.48, wps=81414.8, ups=3.23, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.132, loss_scale=4, train_wall=31, gb_free=14.7, wall=719
2022-03-23 09:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example hypothesis: we saw this idea in the middle of the brain in the middle of the world.
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most most of the most most of the most of the most most of the most of the most of the most most of
2022-03-23 09:36:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:36:33 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be able to be able to be able to be two two new new new new new new york.
2022-03-23 09:36:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:36:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an example, and there's a lot of example, where we're going to see where where are going to see where are going to see where are going to see where where are going
2022-03-23 09:36:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just just just just just just a little bit of what we're going to do is what we're going to do is what we're going to do is that we're going to do.
2022-03-23 09:36:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:49 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the people in the people who have been been a lot of people in the people in the world, and the people who are a lot of people in the people in the world.
2022-03-23 09:36:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of the things, but it's not a lot, but if it's the same way, but it's not a lot of the brain, but it's not the same way, but it's not the same way, but it's not the same way, but it's the same way, but
2022-03-23 09:36:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:37:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the brain, and we can see that we can see that we can see that we can see the brain, and see that we can see the brain, and see that we can see the brain, and then we can see the brain, and then we can see the brain can see that we can see that we can see that we can see that we can see the brain can see that we can see the brain can see the brain
2022-03-23 09:37:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:09 | INFO | fairseq.tasks.translation | example hypothesis: one: it's one of the world, "and it's a lot of the world," and it's a lot of the world, "and if we're going to say," and then we're going to say, "and then it's going to say," and then it's going to say, "and then it's going to say," that we're going to say, "and then we're going to say," that we're going to say, "and then it's going to say," and then it's going to say, "and then it's going to say," "" and then it's going to say, "and then it's going to say," that we're going to say, "and then it's going to say," and then it's a lot of the world, "that we're going to say," "
2022-03-23 09:37:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:37:11 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, if we're going to be a lot of the world that we're going to see that we're going to make a lot of the world that we're going to see the world that we're going to be able to make a lot of the world, and then we're going to make a lot of the world that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see the world that we're going to see that we're going to make a lot of the world that we're going to make a lot of the world that we're going to see that we're going to see that we're going to make a lot of the world that we're going to be able to make a lot of the world that we're going to be able to be able to see the world that we're going to see that we're going to see that we're going to be able to be able to make a lot of the world, when we're going to see
2022-03-23 09:37:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:37:11 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 8.333 | nll_loss 6.647 | ppl 100.19 | bleu 2.91 | wps 3388 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.91
2022-03-23 09:37:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:37:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.91) (writing took 1.8528466988354921 seconds)
2022-03-23 09:37:13 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:37:13 | INFO | train | epoch 008 | loss 8.535 | nll_loss 7.045 | ppl 132.03 | wps 38114.1 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.166 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 789
2022-03-23 09:37:13 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:37:29 | INFO | train_inner | epoch 009:     49 / 157 loss=8.454, nll_loss=6.935, ppl=122.35, wps=29804.4, ups=1.16, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.142, loss_scale=4, train_wall=31, gb_free=14.9, wall=805
2022-03-23 09:38:00 | INFO | train_inner | epoch 009:    149 / 157 loss=8.348, nll_loss=6.791, ppl=110.74, wps=80255.9, ups=3.23, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.163, loss_scale=4, train_wall=31, gb_free=14.3, wall=836
2022-03-23 09:38:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:38:06 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the middle of the end.
2022-03-23 09:38:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:38:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most most of the most most most most of the most most most of the most most most most most of
2022-03-23 09:38:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:38:15 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new york are two two two two two two two.
2022-03-23 09:38:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:38:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a ssssssswhere where you're going to go, and where you're going to go with a day.
2022-03-23 09:38:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:38:25 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to do a few few of his life, and what's going to do, and what's all of his life are all of his life.
2022-03-23 09:38:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:38:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like people like people for the people for the people, and the most people who have been been a lot of people for a few people for a few people in the people, and that is a lot of people in the most people in the united states.
2022-03-23 09:38:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:38:37 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of those of the water, but if you don't have to see, but if you don't know, if it's not, but if it's a lot of course, and if you don't have to look at the way, it's not, and if you're not, but it's the same way, it's
2022-03-23 09:38:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see that we can be able to be able to be able to be able to be able to be able to be able to be able, and we can see that we can see the brain, and then we can be able to create a kind of the brain, and then we can be able to create a kind of the brain, and then we can see that we can see that we can see the brain
2022-03-23 09:38:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:50 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the other people, and it's going to say, and then it's going to say, "and then we're going to say," and then you know, "you know," well, "you know," well, "well," well, "well," you know, "well," you know, "you know," you know, "you know," well, "well," well, "well," you know, "well," you know, "well," well, "well," well, "you know," well, "you know," well, "well," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know,
2022-03-23 09:38:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:53 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, it's still still still still more than the world, and if we're going to be a lot of the world, and if we're going to do that we're going to do that we're going to be a lot of the world, we're going to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, and then we're going to do that we're going to do that we're going to do that we're going to be a lot of the system that we're going to be able to be able to be a lot of the system that we're going to be able to be a lot of the system that we're going to be able to be able to be a lot of the system that we're going to be able to be a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-23 09:38:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:53 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.059 | nll_loss 6.259 | ppl 76.6 | bleu 4.45 | wps 3524 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 4.45
2022-03-23 09:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:38:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:38:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:38:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 4.45) (writing took 1.881724536884576 seconds)
2022-03-23 09:38:55 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:38:55 | INFO | train | epoch 009 | loss 8.331 | nll_loss 6.77 | ppl 109.15 | wps 38904.5 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.138 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 891
2022-03-23 09:38:55 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:38:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:39:24 | INFO | train_inner | epoch 010:     92 / 157 loss=8.145, nll_loss=6.522, ppl=91.89, wps=29789.7, ups=1.19, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.991, loss_scale=4, train_wall=31, gb_free=14.3, wall=920
2022-03-23 09:39:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example hypothesis: we've got these pppon the top.
2022-03-23 09:39:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most, where most of most of most most most of most of most most.
2022-03-23 09:39:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:56 | INFO | fairseq.tasks.translation | example hypothesis: these new new new new new new new new new new new new new new new new two two.
2022-03-23 09:39:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:40:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese, where the chinese, where are going to go.
2022-03-23 09:40:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:40:04 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just a couple of his head, and what's going on on.
2022-03-23 09:40:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:40:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamay of people like the most people for the number of people, and this is a number of the number of people in the number of the number.
2022-03-23 09:40:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:40:13 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of them are going to go through the surface, but if you don't need to use it, but if you need it, if you need to have the energy, and if you need to have the energy, if you need to have the energy, and you need to have the energy, and if you need it's not need
2022-03-23 09:40:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information, we can use this information, we can use this information, and we can use a kind of information, and we can use the brain, and we can use the brain, and the brain, and that's all the structure, and that's all the structure, and all of the brain, and that's all the structure, and all of the structure, and we can use of the brain, and all of the brain,
2022-03-23 09:40:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:27 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the reasons, and it's interesting, and it's very interesting for me, "and it's going to say," well, "well," you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "well," well, "well," we've got to do we've got to do you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "it's a very good for this is that we've got a very good for you've got to do you know,"
2022-03-23 09:40:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:29 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still a lot of the mother, and the first thing that we're going to do that we've got to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:40:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:29 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.751 | nll_loss 5.844 | ppl 57.45 | bleu 7.07 | wps 3965.8 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.07
2022-03-23 09:40:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:40:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:40:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.07) (writing took 1.8125962940976024 seconds)
2022-03-23 09:40:31 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:40:31 | INFO | train | epoch 010 | loss 8.073 | nll_loss 6.427 | ppl 86.02 | wps 41066.2 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.014 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 987
2022-03-23 09:40:31 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:40:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:42 | INFO | train_inner | epoch 011:     35 / 157 loss=8.002, nll_loss=6.332, ppl=80.58, wps=31889, ups=1.28, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.072, loss_scale=4, train_wall=30, gb_free=13.4, wall=998
2022-03-23 09:41:13 | INFO | train_inner | epoch 011:    135 / 157 loss=7.803, nll_loss=6.066, ppl=67, wps=81831.7, ups=3.2, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.026, loss_scale=4, train_wall=31, gb_free=13.3, wall=1030
2022-03-23 09:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example hypothesis: we had this ppppon the center.
2022-03-23 09:41:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the ha, most of most of most of the most here.
2022-03-23 09:41:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:41:32 | INFO | fairseq.tasks.translation | example hypothesis: so, these new new new new new new new new york are going to be going to be able.
2022-03-23 09:41:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are the chinese chinese, where they're going to go with the pppppppppppa.
2022-03-23 09:41:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:40 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few months on his head, and what's going on on your head.
2022-03-23 09:41:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:44 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of people for the number, and the number of the number of the number of the number.
2022-03-23 09:41:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some kind of mats in the air, but if you don't need the energy, and if you need your energy, you need your energy, and you need the energy.
2022-03-23 09:41:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can see this structure, we can create a structure of the structure, and the structure of the information that are all the structure of the information that are going to be able.
2022-03-23 09:41:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:57 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons, and it's interesting for me that i'm going to say, "you know," well, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you're going to say that if you're going to say," you're going to say, "you're going to say," you know, "you know," you're going to say, "you know," you know, "you're going to say," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know
2022-03-23 09:41:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:59 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still still the mother, and a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:41:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:59 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 7.57 | nll_loss 5.586 | ppl 48.03 | bleu 10.05 | wps 4676.3 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 10.05
2022-03-23 09:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:41:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:42:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 10.05) (writing took 1.8230858789756894 seconds)
2022-03-23 09:42:01 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:42:01 | INFO | train | epoch 011 | loss 7.854 | nll_loss 6.134 | ppl 70.21 | wps 43927.2 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.042 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1077
2022-03-23 09:42:01 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:42:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:25 | INFO | train_inner | epoch 012:     78 / 157 loss=7.724, nll_loss=5.959, ppl=62.22, wps=34693.3, ups=1.39, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.028, loss_scale=4, train_wall=30, gb_free=14, wall=1102
2022-03-23 09:42:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example hypothesis: we did this pat the clinics.
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:57 | INFO | fairseq.tasks.translation | example hypothesis: and that's the right line of ha, most of most of most of the most.
2022-03-23 09:42:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:43:01 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to be able to create two new ways.
2022-03-23 09:43:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:43:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese food, where they're going to go and get it.
2022-03-23 09:43:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:43:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're not just just a few few of his head on his head, and what's going on on.
2022-03-23 09:43:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:43:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of people who went to the number of animals, and this is a number of animals that has been used to be used to be a viiiiiiiiiiiiiiiiiiiiiii
2022-03-23 09:43:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the brain, but in fact, it doesn't want to be able to be able to use the energy, if you need to use your energy, and you need your energy, and you need to need your energy.
2022-03-23 09:43:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information is going to be able to be able to be able to be able to start with a structure of the structure of the structure, and the structure of the information, which is all the structure of the structure, and all the information.
2022-03-23 09:43:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:26 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons that it's interesting, and it's interesting for me to be here for me, "oh," oh, "you know," you've got to say, "you know," you know, "you know," you know, "you know," well, "you're going to say," you're going to say, "you know," you're going to say, "you're going to say," you've got to say, "well," you've got to say, "well," you know, "you've got to say," well, "you know," you know, "well," well, "you know," well, "well," you know, "you know," you know, "you know," you're going to say, "you know," you know, "
2022-03-23 09:43:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:29 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and the great part of the work that we've got to be a lot of the world that we had to be able to see that if we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that
2022-03-23 09:43:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:29 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 7.316 | nll_loss 5.209 | ppl 36.99 | bleu 10.75 | wps 4655.1 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.75
2022-03-23 09:43:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:43:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:43:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.75) (writing took 1.8297988148406148 seconds)
2022-03-23 09:43:31 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:43:31 | INFO | train | epoch 012 | loss 7.628 | nll_loss 5.831 | ppl 56.93 | wps 43953.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.051 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1167
2022-03-23 09:43:31 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:38 | INFO | train_inner | epoch 013:     21 / 157 loss=7.53, nll_loss=5.701, ppl=52.04, wps=34837, ups=1.39, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.125, loss_scale=4, train_wall=30, gb_free=13.9, wall=1174
2022-03-23 09:44:09 | INFO | train_inner | epoch 013:    121 / 157 loss=7.433, nll_loss=5.568, ppl=47.43, wps=80756.5, ups=3.19, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.983, loss_scale=4, train_wall=31, gb_free=13.6, wall=1205
2022-03-23 09:44:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:24 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppin the clinic.
2022-03-23 09:44:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:44:28 | INFO | fairseq.tasks.translation | example hypothesis: that's the car of doha, most of most of the most of here.
2022-03-23 09:44:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:44:31 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ores.
2022-03-23 09:44:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese food, where they're going to do with ssmile.
2022-03-23 09:44:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just going to understand a couple of electrodes on his head, and what's going on on.
2022-03-23 09:44:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamace of people like the responsibility for the number of animals, the number of animals, and that has become become a viiiiiibia.
2022-03-23 09:44:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:44:47 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magic, but it doesn't need to be able to move the energy, if you don't need your energy energy and the energy.
2022-03-23 09:44:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this reflection, we can start with a big form of the shape of the shape, and the shape of the structure of the structure and the information.
2022-03-23 09:44:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's going to be here for me, "oh," oh, "well," if you say, "the best time," and then you've been working with you've been working with you. "
2022-03-23 09:44:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:57 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, it's still the mother of the mother, and a big job that we've got to solve it on the bottom of the problems that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:44:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:57 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 7.152 | nll_loss 4.971 | ppl 31.36 | bleu 13.15 | wps 4959.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.15
2022-03-23 09:44:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:44:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:44:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.15) (writing took 1.8482925109565258 seconds)
2022-03-23 09:44:59 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:44:59 | INFO | train | epoch 013 | loss 7.41 | nll_loss 5.538 | ppl 46.45 | wps 44901 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.009 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1255
2022-03-23 09:44:59 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:19 | INFO | train_inner | epoch 014:     64 / 157 loss=7.283, nll_loss=5.369, ppl=41.32, wps=35645.3, ups=1.43, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.95, loss_scale=4, train_wall=30, gb_free=14, wall=1275
2022-03-23 09:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinics.
2022-03-23 09:45:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:45:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which most of most of the most of the most of here.
2022-03-23 09:45:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new orts that are going to create two new ways.
2022-03-23 09:46:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:46:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where food are happy, and they're going to be able to be able.
2022-03-23 09:46:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:46:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a few electrodes on his head on his head on his head, and all of his mind.
2022-03-23 09:46:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:46:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamaze people like the responsibility of the responsibility, the number of animals, and that has become become a convition.
2022-03-23 09:46:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:46:16 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic of the lines in the lines, but it doesn't be able to move, if you need your energy and the energy.
2022-03-23 09:46:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can actually start with a traditional traditional face of the shape of the information, and the whole structure of information.
2022-03-23 09:46:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting to make me here for tedwomen, "oh," you know, "you know," you know, "you know," and if you're working with the truth. "
2022-03-23 09:46:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:25 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the best invention of the invention, and one part of the great design that we have to see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:46:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:25 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.995 | nll_loss 4.724 | ppl 26.43 | bleu 15.66 | wps 4853.3 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.66
2022-03-23 09:46:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:46:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:46:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:46:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.66) (writing took 1.8097804449498653 seconds)
2022-03-23 09:46:27 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:46:27 | INFO | train | epoch 014 | loss 7.163 | nll_loss 5.208 | ppl 36.96 | wps 44585.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.921 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1343
2022-03-23 09:46:27 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:46:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:30 | INFO | train_inner | epoch 015:      7 / 157 loss=7.074, nll_loss=5.088, ppl=34.01, wps=35936.2, ups=1.41, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.87, loss_scale=4, train_wall=30, gb_free=13.9, wall=1346
2022-03-23 09:47:01 | INFO | train_inner | epoch 015:    107 / 157 loss=6.966, nll_loss=4.942, ppl=30.75, wps=80630.6, ups=3.21, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.954, loss_scale=4, train_wall=31, gb_free=13.9, wall=1377
2022-03-23 09:47:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinics.
2022-03-23 09:47:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha, most of the most know here.
2022-03-23 09:47:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that will create two new clients.
2022-03-23 09:47:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:47:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food food food, where the legs will be happy with salt and salt.
2022-03-23 09:47:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just not just a few electrodes on his head and understand what all his thoughts are on your mind.
2022-03-23 09:47:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:47:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamating people like the responsibility of responsibility, and the number of animals grew up, and this is a number of the animals that has become become become a priiiiiiibia.
2022-03-23 09:47:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:47:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic magnetic magnetic lines in the lines, but it doesn't like, if you don't want to move your energy energy, you need your energy, and so you need to move your energy.
2022-03-23 09:47:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information information, the reflection of this reflection comes from a traditional face, we can actually start able to start with a traditional face, and we can start able to start with the shape of the information, and the whole structure of the structure.
2022-03-23 09:47:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting to make me here for tedwomen, is that the best thing that the best thing is that if someone said, "oh," the best thing that we've been working with a cash revolution, and then, "if we've been working with you've been working with a long time."
2022-03-23 09:47:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:57 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a great design part of the work that we're able to use a plane that we had to use a unique system, or if we had to use it, it's a unique system, it's a unique system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see,
2022-03-23 09:47:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:57 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.717 | nll_loss 4.354 | ppl 20.45 | bleu 16.98 | wps 4425.4 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.98
2022-03-23 09:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:47:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:47:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.98) (writing took 1.824955599848181 seconds)
2022-03-23 09:47:59 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:47:59 | INFO | train | epoch 015 | loss 6.98 | nll_loss 4.959 | ppl 31.1 | wps 42962.7 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.922 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1435
2022-03-23 09:47:59 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:15 | INFO | train_inner | epoch 016:     50 / 157 loss=6.961, nll_loss=4.927, ppl=30.43, wps=34258.1, ups=1.35, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.883, loss_scale=4, train_wall=31, gb_free=14.3, wall=1452
2022-03-23 09:48:46 | INFO | train_inner | epoch 016:    150 / 157 loss=6.713, nll_loss=4.6, ppl=24.24, wps=80343.5, ups=3.26, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.812, loss_scale=4, train_wall=30, gb_free=14.5, wall=1482
2022-03-23 09:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:48:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-23 09:48:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new logic.
2022-03-23 09:49:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are going to be defeeding.
2022-03-23 09:49:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:49:07 | INFO | fairseq.tasks.translation | example hypothesis: it's not just a few electrodes on his head and understand what all its thoughts are on the mind.
2022-03-23 09:49:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals of responsibility, the number of animals grew up, and this is a number of animals.
2022-03-23 09:49:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic lines in the field, but it doesn't be able to move if they don't need their energy, and they don't need their energy, and they need their energy, and they need their energy.
2022-03-23 09:49:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start able to start able to start able to start able to start able to start with the very big face of the face of the shape of the shape of the shape of the shape of the shape of the shape of the shape of the shape of the shape of the shape of the shape, and then we can start of the shape of the shape of the shape
2022-03-23 09:49:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for tedwomen. "
2022-03-23 09:49:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:49:25 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and a large part of the work that we're able to see is that we had to solve in our airplane was a result of the plane that we had to solve a unique result that we had to solve is that we had to solve a unique result of it.
2022-03-23 09:49:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:49:25 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.701 | nll_loss 4.346 | ppl 20.33 | bleu 14.2 | wps 5018.3 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.98
2022-03-23 09:49:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:49:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 09:49:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 09:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 14.2) (writing took 0.7672261032275856 seconds)
2022-03-23 09:49:26 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:49:26 | INFO | train | epoch 016 | loss 6.773 | nll_loss 4.679 | ppl 25.62 | wps 45594.1 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.864 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1522
2022-03-23 09:49:26 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:55 | INFO | train_inner | epoch 017:     93 / 157 loss=6.663, nll_loss=4.533, ppl=23.15, wps=36541.9, ups=1.44, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.888, loss_scale=4, train_wall=31, gb_free=14.9, wall=1552
2022-03-23 09:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:19 | INFO | fairseq.tasks.translation | example hypothesis: we made these pink in the clinic clinics.
2022-03-23 09:50:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:50:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 09:50:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:50:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks of dining the two new pigs that are going to be transmitted.
2022-03-23 09:50:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:50:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food food, where happy legs are shadow with salsalsalsalz and feeding.
2022-03-23 09:50:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:50:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all its thoughts is on the top.
2022-03-23 09:50:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:50:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people like the responsibility for life, the number of animals grew up, and that's a basis of natural protection in namibia.
2022-03-23 09:50:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:50:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic field, but the sucks like the sucks, if you don't need your energy, and you need to move your energy.
2022-03-23 09:50:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:49 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start able to start with a traditional facial face, and we can start able to start able to start using the information, and we have the whole structure that all the structure of the structure, and the structure of the structure, and the structure, and the structure of the structure that all the structure, and the structure is going to be able to be able to be able to be able
2022-03-23 09:50:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting, for me to be in tedtedwomen, is that when you've been working on the best time, "you know, you know, you know, the men who said," and if you've been working with you've been working with you've been working on a table and you've been working with you've been working with you've been working with you've been working with this truth, "and then we've been working with you've been working with you've been working with you've been working with you've been working with you've been working with you know, you've been working on the truth, you've been working on a long time, you've been working with you've been working with you know, you've been working with you've been working with you've been working with you've been working with you've got
2022-03-23 09:50:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:58 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and a big part of the design design work on our plane, we have to solve a unique result of it was to solve the problems that we had to solve the problems that we had to solve it on the ground -- and if you can be able to see it, it's all the power of us can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:50:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:58 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.442 | nll_loss 3.991 | ppl 15.91 | bleu 18.54 | wps 4252.7 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 18.54
2022-03-23 09:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:50:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:50:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 18.54) (writing took 1.7833136143162847 seconds)
2022-03-23 09:50:59 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:50:59 | INFO | train | epoch 017 | loss 6.642 | nll_loss 4.503 | ppl 22.67 | wps 42130.1 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.865 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1616
2022-03-23 09:51:00 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:11 | INFO | train_inner | epoch 018:     36 / 157 loss=6.575, nll_loss=4.411, ppl=21.28, wps=33220, ups=1.32, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.854, loss_scale=4, train_wall=30, gb_free=14.3, wall=1627
2022-03-23 09:51:42 | INFO | train_inner | epoch 018:    136 / 157 loss=6.469, nll_loss=4.271, ppl=19.31, wps=80085.3, ups=3.23, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.803, loss_scale=4, train_wall=31, gb_free=14.1, wall=1658
2022-03-23 09:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:51:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them.
2022-03-23 09:51:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:52:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks of the two new pigs.
2022-03-23 09:52:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:52:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are going to be salt with salsalz.
2022-03-23 09:52:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all its thoughts are on the top.
2022-03-23 09:52:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:52:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, as the people responsibility for the wild, grew up the number of animals, and this is a foundation for the natural protection of conservation.
2022-03-23 09:52:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bols of magnetic field lines in the interior lines, but the susuicide doesn't like it, if you're moving your energy, you need energy, and so that's how the superconductor is.
2022-03-23 09:52:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial facial face, which can start with the big constructions of the face of the face, and the fundamental shape of the information that gives you the whole structure.
2022-03-23 09:52:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:52:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure it interesting, for me in tedwomen, is that... "well," you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, it's a long time to support for women. "
2022-03-23 09:52:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:52:27 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother's invention of the invention, and a big part of design work on our plane, was a result that we've had to solve a result of it, that we had to solve the unique problems that were connected to the ground -- all the way that we're able to use the power of a degray system, and if you can use it in the air, it's a legal system, if you can use it in the power to be able to see that if you can use it in the same time, you can use the power of a deployment of the power of a degray.
2022-03-23 09:52:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:52:27 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.24 | nll_loss 3.699 | ppl 12.99 | bleu 21.63 | wps 4762.5 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 21.63
2022-03-23 09:52:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:52:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:52:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 21.63) (writing took 1.7661345680244267 seconds)
2022-03-23 09:52:29 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:52:29 | INFO | train | epoch 018 | loss 6.465 | nll_loss 4.267 | ppl 19.25 | wps 44155.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.778 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1705
2022-03-23 09:52:29 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:54 | INFO | train_inner | epoch 019:     79 / 157 loss=6.358, nll_loss=4.124, ppl=17.44, wps=35589.2, ups=1.39, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.713, loss_scale=4, train_wall=31, gb_free=14, wall=1731
2022-03-23 09:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example hypothesis: we made these bupts in the clinic.
2022-03-23 09:53:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:53:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:53:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:53:30 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to become the two new pigs.
2022-03-23 09:53:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:53:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are being served with salz and fat.
2022-03-23 09:53:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:53:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts on the front.
2022-03-23 09:53:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wild animals, the number of wild animals, and this is a basis of conservation in namibia.
2022-03-23 09:53:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bbbloodl of magnetic lines, but the sususuians don't like to move the energy, and so the suicide disorder.
2022-03-23 09:53:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face and the basic shape of the information that comes through the whole structure of this reflection, which is the whole structure of this reflection of reflection, and we can fold the structure.
2022-03-23 09:53:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's interesting and measure me to be here at tedwomen, is that -- when the best thing was said, "you know, the men who said," and when you say, "if we've been talking about a table table, and then we've been talking to you, you know, you know, you know, you know, you know, you know, you know, there's a silence, the fact, the fact, the fact, the fact, you know, the fact, there's a lot of course, you know, there's a silence of you know, there's a game game game that there's a silence of you know, you know, there's a silence of you know, there's a silence of the women's a game that there's a game that there's a game.
2022-03-23 09:53:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a big part of the design work that we're going to be a result that we had to solve the unique problems that were connected to the ground -- all the way that we had to be a continents of a continents, and a big part of the design of the design of the design system, and that we're using the power of a plane, and that allows us to see that if we're using the power to use the power of the power of a refrigergergerms, or the power of a plane, or the power of the power of a plane.
2022-03-23 09:53:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:55 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.189 | nll_loss 3.633 | ppl 12.41 | bleu 22.31 | wps 4882.8 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 22.31
2022-03-23 09:53:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:53:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:53:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:53:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 22.31) (writing took 1.8255972508341074 seconds)
2022-03-23 09:53:57 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:53:57 | INFO | train | epoch 019 | loss 6.303 | nll_loss 4.053 | ppl 16.6 | wps 44614.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.741 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1794
2022-03-23 09:53:58 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:05 | INFO | train_inner | epoch 020:     22 / 157 loss=6.237, nll_loss=3.966, ppl=15.62, wps=35205.7, ups=1.42, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.719, loss_scale=4, train_wall=30, gb_free=14.7, wall=1801
2022-03-23 09:54:36 | INFO | train_inner | epoch 020:    122 / 157 loss=6.174, nll_loss=3.883, ppl=14.75, wps=81678, ups=3.16, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.678, loss_scale=4, train_wall=31, gb_free=13.6, wall=1833
2022-03-23 09:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:51 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 09:54:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:55 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most of you here.
2022-03-23 09:54:55 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:59 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of the two new pigs of the two new pigments.
2022-03-23 09:54:59 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:55:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are going to be served with salz and puppeer.
2022-03-23 09:55:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:55:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all his thoughts on the road.
2022-03-23 09:55:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:55:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, the people of the responsibility of the wild, the number of animals grew up, and this is a foundation of conservation in namibia.
2022-03-23 09:55:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:55:15 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of magnetic field lines in the inside the inner lines, but the sulalers may not be able to move if they need to move, because their energy needs energy, and so the susulant disorders.
2022-03-23 09:55:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, the big constructions of the face, and the basic shape of the face, and the basic shape of the information, which is the whole portion of these reflection, and we can start with a traditional facial facial facial face.
2022-03-23 09:55:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:55:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and measure it to me in tedwomen is to be here at tedwomen is that... yes, in the best swiss, when someone said, "shut you on a table and say," if you're going to be able to be able to be able to be here at a table revolution, and then we've got the love of you, "the truth is that there's a long time," in this is a game that we've got a long time, in the piano with the piano, in the piano, in the piano, the piano, and then we've got a long time, we've got a long time, we've been working with the harbage of course of course of course of the piano, the piano, the piano, the piano, the piano, and we've been working with the piano, the piano
2022-03-23 09:55:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:55:27 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're working on on our plane, a result of it was that we had to solve the unique problems that were interconnected to the ground -- everything from a continent, and a big part of the design work of the design work, and a big part of the design work that we're going to be able to use in the aircraft with the aircraft, or a constraigightforward, if it was a constraigigightforward, it was an aircraft, or a constraigigightforward, it was a constraigigightforward, it was a constraightforward to be an aircraft, or a constraigigightforward to an aircraft with a constraigigightforward to an aircraft, or an aircraft, it was an aircraft that we had to an aircraft, or a constraigigightforward to be an aircraft,
2022-03-23 09:55:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:55:27 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.089 | nll_loss 3.505 | ppl 11.35 | bleu 24.1 | wps 4491.5 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 24.1
2022-03-23 09:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:55:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:55:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 24.1) (writing took 1.8132836050353944 seconds)
2022-03-23 09:55:29 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:55:29 | INFO | train | epoch 020 | loss 6.16 | nll_loss 3.865 | ppl 14.57 | wps 43122.6 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.696 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1885
2022-03-23 09:55:29 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:50 | INFO | train_inner | epoch 021:     65 / 157 loss=6.081, nll_loss=3.763, ppl=13.58, wps=33959.5, ups=1.36, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.747, loss_scale=4, train_wall=30, gb_free=13.9, wall=1906
2022-03-23 09:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:22 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:56:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:56:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:56:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create the two new pigments.
2022-03-23 09:56:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:56:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs will be served with salz and fat.
2022-03-23 09:56:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:56:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all his thoughts on the road.
2022-03-23 09:56:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:56:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew back again, and this is a foundation for the natural protection in namibia.
2022-03-23 09:56:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some belt of the magnet lines in the inner, but the superconductor may not like it, if they're moving, because they need their energy, and so the suicide disorder.
2022-03-23 09:56:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that can begin to start with the big constructions of the face and the basic shape of the face, and through that one of the whole ports.
2022-03-23 09:56:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting, and then i'm going to be here at tedwomen, is that... yes, when he was on the best, when someone said, "you know, you know, you know, you know, if you're in this table, you know, you know, you know, the truth is that you have a long time to thank you."
2022-03-23 09:56:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:57 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of the invention, and a big part of the design work that we're going to be able to see in our plane, was a result of it that we had to solve the unique problems that were connected to the ground -- everything to a variable system that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:56:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:57 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 5.959 | nll_loss 3.346 | ppl 10.17 | bleu 25.45 | wps 4654.7 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 25.45
2022-03-23 09:56:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:56:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:56:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:56:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 25.45) (writing took 1.8245948227122426 seconds)
2022-03-23 09:56:59 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:56:59 | INFO | train | epoch 021 | loss 6.073 | nll_loss 3.751 | ppl 13.46 | wps 43891.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.703 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1975
2022-03-23 09:56:59 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:02 | INFO | train_inner | epoch 022:      8 / 157 loss=6.081, nll_loss=3.76, ppl=13.55, wps=34278.4, ups=1.38, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.684, loss_scale=4, train_wall=30, gb_free=13.9, wall=1978
2022-03-23 09:57:33 | INFO | train_inner | epoch 022:    108 / 157 loss=6.008, nll_loss=3.667, ppl=12.7, wps=79668.9, ups=3.23, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.694, loss_scale=4, train_wall=31, gb_free=13.8, wall=2009
2022-03-23 09:57:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:57:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:57:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:00 | INFO | fairseq.tasks.translation | example hypothesis: stars become new golf locks that are going to be restored two new pigs.
2022-03-23 09:58:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:03 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pippets.
2022-03-23 09:58:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:58:07 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all its thoughts are on the road.
2022-03-23 09:58:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:58:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people's responsibility for the wild, the number of wild animals, and that's a foundation for conservation in namibia.
2022-03-23 09:58:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:58:15 | INFO | fairseq.tasks.translation | example hypothesis: first, some blooddy rocks in the inner, but the suouter may not be, if they're moving, because their movements need energy.
2022-03-23 09:58:15 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:58:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big constructions of the face and the basic shape of the shape of the face and the basic shape of the shape of the face.
2022-03-23 09:58:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:58:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and measured for me at tedwomen is that... "yes, we've already been supporting the world."
2022-03-23 09:58:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:58:25 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're going to see in our aircraft, or if you had to solve a result of it.
2022-03-23 09:58:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:58:25 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 5.938 | nll_loss 3.301 | ppl 9.85 | bleu 24.9 | wps 4945.1 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 25.45
2022-03-23 09:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 09:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 09:58:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 24.9) (writing took 0.7826320119202137 seconds)
2022-03-23 09:58:26 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:58:26 | INFO | train | epoch 022 | loss 5.988 | nll_loss 3.64 | ppl 12.47 | wps 45491.7 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.671 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2062
2022-03-23 09:58:26 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:58:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:58:42 | INFO | train_inner | epoch 023:     51 / 157 loss=5.94, nll_loss=3.576, ppl=11.92, wps=36782.9, ups=1.44, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.582, loss_scale=4, train_wall=31, gb_free=13.8, wall=2078
2022-03-23 09:59:13 | INFO | train_inner | epoch 023:    151 / 157 loss=5.824, nll_loss=3.43, ppl=10.78, wps=82125.9, ups=3.23, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.614, loss_scale=4, train_wall=31, gb_free=13.8, wall=2109
2022-03-23 09:59:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:59:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:59:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably knows most here.
2022-03-23 09:59:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:59:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new golden locks that create the two new pigs.
2022-03-23 09:59:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:59:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pit.
2022-03-23 09:59:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:59:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 09:59:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:59:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people's responsibility for the wild, the number of wild animals grew back again. and this is a basis for conservation protection in namibia.
2022-03-23 09:59:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:59:43 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodle of magnet lines in the inside, but the superconductor may not like that if they're moving, because they need their energy, and so the suide disorder.
2022-03-23 09:59:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:48 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial reflection, which is the big constructions of the face and the basic shape of the face and the basic shape of the basic shape of the face.
2022-03-23 09:59:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that has been very interesting and measured for me here at tedwomen is that -- well, in the long time, we've been supported with silent, when someone said, "turn it up on the best part of us on a table and say," if the revolution. "
2022-03-23 09:59:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:55 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and a great part of design work that we're in our aircraft, that was a result that we had to solve the unique problems that had to be connected to the ground, if we're able to use the security system, or a large part of a transportation, and a large part of the refrightened to refrightened to the power of a car system, or an aircraft, or a refrightened by a market, that is that allows us to be able to be able to use, or a market, if we're able to use the power, or a market, it's a market, that's a market, that's a market, or a car system that is a market, or a market, that's a market, that's a market, that's a market, that's a market, that is either, that's a system that's a market, or a market system that's a market, or a system that allows us to be able to
2022-03-23 09:59:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:55 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.903 | nll_loss 3.265 | ppl 9.61 | bleu 25.8 | wps 4572.7 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.8
2022-03-23 09:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 09:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:59:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 09:59:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.8) (writing took 1.7477073320187628 seconds)
2022-03-23 09:59:57 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 09:59:57 | INFO | train | epoch 023 | loss 5.86 | nll_loss 3.475 | ppl 11.12 | wps 43374.2 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.595 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2153
2022-03-23 09:59:57 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 09:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:26 | INFO | train_inner | epoch 024:     94 / 157 loss=5.819, nll_loss=3.423, ppl=10.73, wps=34032.5, ups=1.37, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.622, loss_scale=4, train_wall=30, gb_free=13.8, wall=2183
2022-03-23 10:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:49 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:00:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:00:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:57 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new gold locks.
2022-03-23 10:00:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:01:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and ppeg.
2022-03-23 10:01:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:01:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:01:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:01:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people responsibility for the wild, the number of wild animals grew back. and that's a basis for conservation in namibia.
2022-03-23 10:01:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:01:13 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are caught in the inside, but the superconductor doesn't like if they move, because their movements need their energy, and so the supersuperconducting disorders.
2022-03-23 10:01:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:01:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that gives the big constructions of the face, and the basic information that fits all the ports.
2022-03-23 10:01:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:01:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, in the striking dinner, when someone said, "turn you to a table and say, if the revolution starts to support you. ''"
2022-03-23 10:01:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:01:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to operations -- everything from a continuous variable system and a refrigeration system that allows us to use it to the power of the air, and that it would be a refrightening system that it's either possible to be able to be able to be able to use the power to the power in the power in the air, or to be able to be able to move the power to the power to the power to the market, and that if you can't be connected to the power to the power that it would be able to the power of the power to the power that it would be able to the air, that it's either be able to the power that it's either be able to the power that it's a system.
2022-03-23 10:01:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:01:24 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.763 | nll_loss 3.075 | ppl 8.43 | bleu 27.32 | wps 4779.2 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.32
2022-03-23 10:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:01:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.32) (writing took 1.7671865718439221 seconds)
2022-03-23 10:01:26 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:01:26 | INFO | train | epoch 024 | loss 5.788 | nll_loss 3.382 | ppl 10.43 | wps 44475.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.577 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2242
2022-03-23 10:01:26 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:01:38 | INFO | train_inner | epoch 025:     37 / 157 loss=5.705, nll_loss=3.277, ppl=9.69, wps=35771.1, ups=1.4, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.521, loss_scale=4, train_wall=30, gb_free=14, wall=2254
2022-03-23 10:02:09 | INFO | train_inner | epoch 025:    137 / 157 loss=5.775, nll_loss=3.367, ppl=10.32, wps=80337.3, ups=3.21, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.623, loss_scale=4, train_wall=31, gb_free=13.9, wall=2285
2022-03-23 10:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:02:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:02:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:02:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:02:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 10:02:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:02:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and psuitcase.
2022-03-23 10:02:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:02:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:02:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:02:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for wildlife, the number of wild animals grew back. and this is a foundation for conservation in namibia.
2022-03-23 10:02:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines start inside inside, but the supersupersuperconductor may not be if you move your energy, and so the superconductor disorders.
2022-03-23 10:02:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face and the basic form of information that refits the whole portion structure and refits it through the theft structure.
2022-03-23 10:02:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that was highly interesting and measured for me here at tedwomen is that... tyes, when someone said, "turn you to your desk."
2022-03-23 10:02:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:50 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to operating it -- everything from a continuous variable system and a refrigeration system that allows us to refrigeration, or if we're going to be able to get a specific device, or if we're either going to be able to be able to be able to go to the air, if we're going to the air, if we're going to the united states.
2022-03-23 10:02:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:50 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.799 | nll_loss 3.132 | ppl 8.77 | bleu 25.28 | wps 5134.6 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.32
2022-03-23 10:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:02:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:02:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:02:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 25.28) (writing took 0.8174281767569482 seconds)
2022-03-23 10:02:51 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:02:51 | INFO | train | epoch 025 | loss 5.734 | nll_loss 3.314 | ppl 9.95 | wps 46117 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.592 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2327
2022-03-23 10:02:51 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:02:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:17 | INFO | train_inner | epoch 026:     80 / 157 loss=5.647, nll_loss=3.202, ppl=9.2, wps=37499.7, ups=1.47, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.532, loss_scale=4, train_wall=30, gb_free=14, wall=2353
2022-03-23 10:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep sheep in the clinic.
2022-03-23 10:03:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here.
2022-03-23 10:03:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:52 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 10:03:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:03:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:04:00 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:04:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:04:04 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people of responsibility for the wildlife, the number of wildanimals grew up again, and this is a foundation for conservation in namibia.
2022-03-23 10:04:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:04:08 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are caught in the inner, but the superconductor doesn't like it, if they're moving, because their movements need energy, and so the superconducting disorders.
2022-03-23 10:04:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:04:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can start with the big constructions of the face and the basic shape, and restoring it through the theft of information that fits the whole portion structure and all the fits.
2022-03-23 10:04:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:04:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was put together the best when someone said, "turn on the men on your table and say," if the revolution starts to support you. "
2022-03-23 10:04:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we're at the stagent of our airplane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigering system that allows us to be able to refrigerated to be able to use our aircraft, or to be able to be able to see, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 10:04:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:04:19 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.636 | nll_loss 2.923 | ppl 7.58 | bleu 29.29 | wps 4684.9 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.29
2022-03-23 10:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:04:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:04:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:04:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.29) (writing took 1.8017469989135861 seconds)
2022-03-23 10:04:21 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:04:21 | INFO | train | epoch 026 | loss 5.645 | nll_loss 3.201 | ppl 9.19 | wps 44048.2 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.547 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 2417
2022-03-23 10:04:21 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:04:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:04:29 | INFO | train_inner | epoch 027:     23 / 157 loss=5.6, nll_loss=3.144, ppl=8.84, wps=34595.5, ups=1.39, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.541, loss_scale=4, train_wall=30, gb_free=14.8, wall=2425
2022-03-23 10:05:00 | INFO | train_inner | epoch 027:    123 / 157 loss=5.591, nll_loss=3.132, ppl=8.77, wps=80804.5, ups=3.23, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.515, loss_scale=4, train_wall=31, gb_free=13.6, wall=2456
2022-03-23 10:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:05:14 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:05:18 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:05:21 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:05:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:05:25 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:05:25 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:05:30 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:05:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:05:34 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew back. and this is a basis for conservation in namibia.
2022-03-23 10:05:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:05:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if they're moving, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:05:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that refers the groben constructions of the face and the basic shape, and refuses it through the theft structure and all the folds.
2022-03-23 10:05:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate to be here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn you to your table and tell you," if the revolution starts to support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 10:05:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane at the stumber toes, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable operating system and a refrigerator system that allows us to use a refrigerator machine to be able to use, or if we're going to see the propellism, or if we're going to be able to look at the united states, or if you're either going to see the trajectory of a mechanism, or if you're going to be able to be able to see the trajectory.
2022-03-23 10:05:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:48 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.605 | nll_loss 2.895 | ppl 7.44 | bleu 29.52 | wps 4861.4 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.52
2022-03-23 10:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:05:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:05:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:05:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.52) (writing took 1.9479982629418373 seconds)
2022-03-23 10:05:49 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:05:49 | INFO | train | epoch 027 | loss 5.56 | nll_loss 3.093 | ppl 8.53 | wps 44531.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.496 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2506
2022-03-23 10:05:50 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:10 | INFO | train_inner | epoch 028:     66 / 157 loss=5.532, nll_loss=3.055, ppl=8.31, wps=35198.5, ups=1.41, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.521, loss_scale=4, train_wall=30, gb_free=14.7, wall=2527
2022-03-23 10:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:06:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-23 10:06:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will write two new pigs.
2022-03-23 10:06:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pit.
2022-03-23 10:06:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all your minds are on the track.
2022-03-23 10:06:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:07:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the case like people's responsibility for wildlife, the number of wild animals grew back, and this is a basis for conservation in namibia.
2022-03-23 10:07:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:07:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 10:07:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:07:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the big contures of facial and the basic form, and restoring it through the theast of information that refers the whole porter structure and all the fold.
2022-03-23 10:07:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:07:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here at tedwomen is that -- well, when you were striking dinner, it was the best thing when someone said, "turn you to the men on your table and say," if the revolution starts to help you support you. "the truth is that we're already supporting you."
2022-03-23 10:07:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we are at our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous varied variation and a system of refrigeration, that allows us to see a refrigerator of the aircraft in the aircraft, or if you can see a refrigerator of a trajectory of a trajectory of the air, if you can see the propellism, if you can see the racy of a mechanism, if you can see the current current system, or the racy, if you can't see the air, if you can't see the air, if you can see the current current problems that's flying, it's going to the racy of a mechanism, if you can't see the air, if you can see it's going to the air, if you can't see the air, if you can see the
2022-03-23 10:07:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:07:17 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.58 | nll_loss 2.843 | ppl 7.17 | bleu 29.99 | wps 4763.2 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.99
2022-03-23 10:07:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:07:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.99) (writing took 2.0365066742524505 seconds)
2022-03-23 10:07:19 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:07:19 | INFO | train | epoch 028 | loss 5.532 | nll_loss 3.056 | ppl 8.32 | wps 44274.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.556 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2595
2022-03-23 10:07:19 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:07:22 | INFO | train_inner | epoch 029:      9 / 157 loss=5.55, nll_loss=3.081, ppl=8.46, wps=35265, ups=1.4, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.578, loss_scale=4, train_wall=30, gb_free=13.6, wall=2598
2022-03-23 10:07:53 | INFO | train_inner | epoch 029:    109 / 157 loss=5.466, nll_loss=2.973, ppl=7.85, wps=80995.4, ups=3.22, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.496, loss_scale=4, train_wall=31, gb_free=13.6, wall=2629
2022-03-23 10:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:08:12 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:08:12 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:08:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 10:08:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:08:20 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that generate two new pigs.
2022-03-23 10:08:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and psuitcase.
2022-03-23 10:08:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:08:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:08:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew up, and that's become a basis for conservation in namibia.
2022-03-23 10:08:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:08:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught in the inside, but the superconductor doesn't like it when they move, they use their energy, and so the superconducting disorder.
2022-03-23 10:08:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refuse the grows of the face and the basic form, and refuse it through the themes that refuse the whole porter structure and all the fits.
2022-03-23 10:08:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured to me here at tedwomen is that... well, when dinner was the best summaries when someone said, "turn you to your men to your table and say," if the revolution starts to support you. "
2022-03-23 10:08:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:46 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a large part of the design work that we're at our airplane at the stest toes, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a system that allows us to refrigerate in traffic, or if you can see the propelled to a proliferation, if you can use a mechanism, or if you can either use a mechanism, or if you can use a mechanism, or if you can use a mechanism, or if you can use a mechanism, or if you can use it, or if you can use a mechanism, or if you can use it, or if you can use a mechanism, or if you can use a mechanism, or if you can use a mechanism, or if you can use it, or if you can use it, or if you can use a mechanism, or if you can use a mechanism
2022-03-23 10:08:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:46 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.525 | nll_loss 2.79 | ppl 6.92 | bleu 30.34 | wps 4847.4 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.34
2022-03-23 10:08:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:08:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:08:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:08:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.34) (writing took 1.934900816064328 seconds)
2022-03-23 10:08:48 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:08:48 | INFO | train | epoch 029 | loss 5.463 | nll_loss 2.969 | ppl 7.83 | wps 44390.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.505 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2684
2022-03-23 10:08:48 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:09:04 | INFO | train_inner | epoch 030:     52 / 157 loss=5.44, nll_loss=2.94, ppl=7.67, wps=35083.6, ups=1.4, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.494, loss_scale=4, train_wall=30, gb_free=13.9, wall=2701
2022-03-23 10:09:35 | INFO | train_inner | epoch 030:    152 / 157 loss=5.383, nll_loss=2.87, ppl=7.31, wps=81970, ups=3.24, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.439, loss_scale=4, train_wall=31, gb_free=14.7, wall=2732
2022-03-23 10:09:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep on the clinic.
2022-03-23 10:09:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:09:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will be transcend two new pigs.
2022-03-23 10:09:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:09:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:09:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:10:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew again, and that's a basis for conservation in namibia.
2022-03-23 10:10:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:10:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught in the inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorders.
2022-03-23 10:10:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:10:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which repeats the big contures of the face and the basic shape, and restoring it through the theast information that pulls the entire portion structure and all the folds.
2022-03-23 10:10:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:10:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to the men to your table and say," if the revolution starts to support you. "
2022-03-23 10:10:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:10:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a large part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a system of refrigeration to the security system that allows us to use a special transportation to the ground, or if you can see the propellism, or if you can see the propelled to the land, if you can use it, or if you can use it, or if you can see the propeller, if you can use it to the air, or if you can use it, or if you can use it, or if you can use it to the air, or if you can use it to the air, or if you can use it to the air, or if you can use it to the air, or if you can use it to the air, to the air, to the air, to the ground, or if you can
2022-03-23 10:10:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:10:15 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 5.476 | nll_loss 2.742 | ppl 6.69 | bleu 30.83 | wps 4823.4 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.83
2022-03-23 10:10:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:10:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:10:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.83) (writing took 2.0526578458957374 seconds)
2022-03-23 10:10:17 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:10:17 | INFO | train | epoch 030 | loss 5.395 | nll_loss 2.883 | ppl 7.37 | wps 44366.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.456 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2773
2022-03-23 10:10:17 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:10:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:47 | INFO | train_inner | epoch 031:     95 / 157 loss=5.359, nll_loss=2.837, ppl=7.15, wps=35649.1, ups=1.4, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.456, loss_scale=4, train_wall=31, gb_free=13.6, wall=2803
2022-03-23 10:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:11:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:11:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:11:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 10:11:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:11:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:11:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:11:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:11:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:11:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:11:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:11:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildanimals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:11:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:11:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 10:11:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic shape, and recover it through the thief information that pulls the whole porter structure and all the fits.
2022-03-23 10:11:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn you to your men on your table and say," if the revolution begins, we support you. "the truth is that we've already started to support you for a long time."
2022-03-23 10:11:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variable and refrigerating system with a refrigerator that allows us to use a refrigerator in the aircraft, or to be able to use the car traffic, or when you can use it to use it, if you can use it, or when you can use it, if you can use it, or when you can use it, you can use it, you can use it, you can use it, you can use it, you can use it, you can use it to see the steer, or when you can use it, you can use it, you can use it, you can use it, you can use it to see the current current, or when you can see it, if you can use it, you can use it, you can see
2022-03-23 10:11:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:43 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 5.45 | nll_loss 2.711 | ppl 6.55 | bleu 31.45 | wps 4869.9 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.45
2022-03-23 10:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:11:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.45) (writing took 1.8675728747621179 seconds)
2022-03-23 10:11:45 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:11:45 | INFO | train | epoch 031 | loss 5.352 | nll_loss 2.83 | ppl 7.11 | wps 44779.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.454 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2861
2022-03-23 10:11:45 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:11:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:57 | INFO | train_inner | epoch 032:     38 / 157 loss=5.304, nll_loss=2.768, ppl=6.81, wps=35367.8, ups=1.42, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.434, loss_scale=4, train_wall=30, gb_free=14.3, wall=2874
2022-03-23 10:12:28 | INFO | train_inner | epoch 032:    138 / 157 loss=5.33, nll_loss=2.802, ppl=6.98, wps=81321.4, ups=3.22, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.494, loss_scale=4, train_wall=31, gb_free=14.4, wall=2905
2022-03-23 10:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:12:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:12:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:12:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-23 10:12:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wild animals grew back. and that's become a basis for conservation in namibia.
2022-03-23 10:12:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:13:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it, if they move, they use their movements, and so the superconductor disorder.
2022-03-23 10:13:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:06 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that refers the big constraints of the face and the basic form, and restoring it through the one that refuses the whole porter structure and all the fits.
2022-03-23 10:13:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:13:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, in the strict dinner, it was best summarized when someone said, "turn you to your table and tell them," 'if the revolution begins, we support you, "the truth is that we've already started to support you for a long time."
2022-03-23 10:13:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:13:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and a refrigeration system that allows us to use in the aircraft, to go to traffic, or if you look at the aircraft, or if you're in particular, you're going to go, you're going to be able to use it, or if you look at the ground, you're either, you're going to be able to be able to use it, you're going to use it, you're going to be able to be able to use it, or if you're going to use it, you're driving, you're driving, you're going to have to have to be a legal, or if you're going to go, or if you're going to have to see the aircraft, you're going to go, you're going, you're driving, you're going
2022-03-23 10:13:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:13:12 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 5.431 | nll_loss 2.68 | ppl 6.41 | bleu 31.24 | wps 4762.5 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.45
2022-03-23 10:13:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:13:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:13:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:13:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.24) (writing took 0.810830180067569 seconds)
2022-03-23 10:13:13 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:13:13 | INFO | train | epoch 032 | loss 5.313 | nll_loss 2.78 | ppl 6.87 | wps 44794.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.472 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2949
2022-03-23 10:13:13 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:13:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:39 | INFO | train_inner | epoch 033:     81 / 157 loss=5.237, nll_loss=2.684, ppl=6.42, wps=35527.9, ups=1.42, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.443, loss_scale=4, train_wall=30, gb_free=14, wall=2975
2022-03-23 10:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:14:07 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep beep on the clinic.
2022-03-23 10:14:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:14:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:14:15 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 10:14:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:14:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:14:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:14:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all its thoughts are on the track.
2022-03-23 10:14:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:14:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wild, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:14:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:14:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:14:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:14:35 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflective reflection, we can start with a traditional facial can that refers the big constructures of the face and the basic form, and recongestion it through this one information that refers the whole porter structure and all the fits.
2022-03-23 10:14:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that, well, when dinner was summarized the best thing, when someone said, "turn you to the men on your table and say," if the revolution starts to support you. '"the truth is that we've already been supporting you for this topic for a long period of time."
2022-03-23 10:14:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigerator system, that allows us to use an aircraft on the stumber traffic until a particular cycle, or if you can see the propelled to the ground, or if you can see the propelled, or if you can see the promoting system.
2022-03-23 10:14:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:42 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 5.4 | nll_loss 2.644 | ppl 6.25 | bleu 32.51 | wps 4696.7 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.51
2022-03-23 10:14:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:14:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:14:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:14:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.51) (writing took 1.8842617250047624 seconds)
2022-03-23 10:14:44 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:14:44 | INFO | train | epoch 033 | loss 5.266 | nll_loss 2.72 | ppl 6.59 | wps 43549.9 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.439 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3040
2022-03-23 10:14:44 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:14:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:52 | INFO | train_inner | epoch 034:     24 / 157 loss=5.293, nll_loss=2.754, ppl=6.75, wps=34484.9, ups=1.37, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.449, loss_scale=4, train_wall=31, gb_free=13.8, wall=3048
2022-03-23 10:15:23 | INFO | train_inner | epoch 034:    124 / 157 loss=5.218, nll_loss=2.66, ppl=6.32, wps=80772.2, ups=3.21, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.457, loss_scale=4, train_wall=31, gb_free=13.7, wall=3079
2022-03-23 10:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:15:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:15:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:45 | INFO | fairseq.tasks.translation | example hypothesis: stars will generate new goldilocks in india that will generate two new pigs.
2022-03-23 10:15:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:15:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of its thoughts are on the track.
2022-03-23 10:15:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wild animals grew back again, and that's become a basis for conservation in namibia.
2022-03-23 10:15:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught inside, but the superconductor doesn't like it, if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:16:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:16:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the big constraints of the face and the basic form of information that refers the entire porter structure and all the folds through the one that refers the entire porter structure and the fold.
2022-03-23 10:16:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:16:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that... well, when dinner was the best summarized when someone said, "turn you to your table and tell you, 'if the revolution begins to be here, we support you to you.'" the truth, women, we've already been supporting you for you for a long time. "
2022-03-23 10:16:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:16:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're most proud of at our airplane, was a result that we had to solve the unique problems that were connected to it -- everything, from a continuous variation of the design work that allows us to operate in the ground and a cooling system of fluid that allows us to use in the air-goand the aircraft to a specialist to a state, if you're either in the aircraft, if you're in the aircraft, or if you're in particular, or if you can see the aircraft, or if you're in the aircraft, or if you're in the same for the aircraft, or if you're in the same way.
2022-03-23 10:16:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:16:12 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.399 | nll_loss 2.662 | ppl 6.33 | bleu 32.27 | wps 4680.2 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.51
2022-03-23 10:16:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:16:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.27) (writing took 1.4438535990193486 seconds)
2022-03-23 10:16:13 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:16:13 | INFO | train | epoch 034 | loss 5.237 | nll_loss 2.683 | ppl 6.42 | wps 44073.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.474 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3130
2022-03-23 10:16:14 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:16:35 | INFO | train_inner | epoch 035:     67 / 157 loss=5.243, nll_loss=2.69, ppl=6.46, wps=35150, ups=1.4, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.478, loss_scale=4, train_wall=30, gb_free=14.7, wall=3151
2022-03-23 10:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:17:06 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:17:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:17:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:17:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:17:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks prayers that will transcend two new pigs.
2022-03-23 10:17:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:17:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:17:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all its thoughts are on the track.
2022-03-23 10:17:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:17:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the sauce of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 10:17:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:17:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:17:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:17:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form of information that draws the whole porter structure and all the fits.
2022-03-23 10:17:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that -- well, when dinner was summarized, it was the best thing when someone said, "turn you to your table and say," if the revolution starts, we support you, "the truth, women's love is that we've already started you for a long time."
2022-03-23 10:17:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the most staggering mother, and a large part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a cooling system of liquid, that allows us to use an aircraft in the aircraft to a special transportation, or if you go to the propeller, if you look at the ground.
2022-03-23 10:17:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:40 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.375 | nll_loss 2.615 | ppl 6.13 | bleu 32.17 | wps 4827.9 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.51
2022-03-23 10:17:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:17:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.17) (writing took 0.8963969494216144 seconds)
2022-03-23 10:17:41 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:17:41 | INFO | train | epoch 035 | loss 5.196 | nll_loss 2.631 | ppl 6.19 | wps 45037.4 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.435 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 3217
2022-03-23 10:17:41 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:45 | INFO | train_inner | epoch 036:     10 / 157 loss=5.178, nll_loss=2.609, ppl=6.1, wps=35540, ups=1.43, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.42, loss_scale=4, train_wall=30, gb_free=14.7, wall=3221
2022-03-23 10:18:16 | INFO | train_inner | epoch 036:    110 / 157 loss=5.164, nll_loss=2.59, ppl=6.02, wps=80339.6, ups=3.18, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.447, loss_scale=4, train_wall=31, gb_free=14.7, wall=3252
2022-03-23 10:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:34 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieps in the clinic.
2022-03-23 10:18:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:18:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:42 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:18:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:18:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the sauce of how people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis of conservation in namibia.
2022-03-23 10:18:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements are using energy, and so the superconductor.
2022-03-23 10:18:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face can that restores the big conscores of the face and the basic shape, and then then restore it through the theft structure and all the fits.
2022-03-23 10:19:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:19:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and measured to me here at tedwomen is that -- well, we've been supporting you for this long, "turn to the men on your table and say to them," if the revolution begins, "we're supporting you." the truth, "we've already been supporting you for a long time."
2022-03-23 10:19:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:19:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a great part of the design work that we're most proud of on our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerating system of fluid, that allows us to use a steady machine in the steady traffic, or in the aircraft, or to a specificent way, or to be, or to a trajectory, or to a trajectory, or to a constituency, or, or to be, or to the road, or to the constituency, or to which is, or to the constituency, or to which is, or to be, or to operate, if you can't be, or to the constituency, or to operate it, or to the ground, or to the constituency, or to the constant, or to the constant,
2022-03-23 10:19:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:19:10 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 5.361 | nll_loss 2.611 | ppl 6.11 | bleu 32.52 | wps 4652.1 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.52
2022-03-23 10:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.52) (writing took 2.4892601729370654 seconds)
2022-03-23 10:19:12 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:19:12 | INFO | train | epoch 036 | loss 5.188 | nll_loss 2.621 | ppl 6.15 | wps 43388.7 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.483 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3308
2022-03-23 10:19:12 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:19:29 | INFO | train_inner | epoch 037:     53 / 157 loss=5.151, nll_loss=2.576, ppl=5.96, wps=35081.4, ups=1.37, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.481, loss_scale=4, train_wall=30, gb_free=14.7, wall=3325
2022-03-23 10:20:00 | INFO | train_inner | epoch 037:    153 / 157 loss=5.184, nll_loss=2.615, ppl=6.13, wps=80133, ups=3.23, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.435, loss_scale=4, train_wall=31, gb_free=13.5, wall=3356
2022-03-23 10:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:20:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:20:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of you here.
2022-03-23 10:20:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks prayers that will transcend two new pigs.
2022-03-23 10:20:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:20:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:20:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:20:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:20:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the sauce of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis of conservation in namibia.
2022-03-23 10:20:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:20:29 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are captured inside, but the superconductor doesn't like it, if they move, because their movements are using their energy, and so the superconductor disorder.
2022-03-23 10:20:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:20:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that restores the grows of the face and the basic form of information that refers the entire porter structure and all the fine folds.
2022-03-23 10:20:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when dinner was put it best together when someone said, "turn you to your desk and say, 'if the revolution starts, we support you.'"
2022-03-23 10:20:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're most proud of on our airplane, was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuous variation and a refrigerator system of liquid, that allows us to use a machine to use on our aircraft on the stumber traffic, and be able to use it to use an aircraft, to become a special amount of aircraft, to become a special amount of aircraft in the ground, to be connected to be able to the ground, to be able to be able to be able to be able to be able to use of aircraft, if you can see it's all the wrong mechanism, if you can see it's all the wrong, or if you can see it's all the way.
2022-03-23 10:20:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:40 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 5.335 | nll_loss 2.572 | ppl 5.95 | bleu 32.96 | wps 4614.6 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.96
2022-03-23 10:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:20:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.96) (writing took 2.109400579240173 seconds)
2022-03-23 10:20:42 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:20:42 | INFO | train | epoch 037 | loss 5.139 | nll_loss 2.558 | ppl 5.89 | wps 43641.1 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.421 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3399
2022-03-23 10:20:43 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:20:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:21:13 | INFO | train_inner | epoch 038:     96 / 157 loss=5.117, nll_loss=2.53, ppl=5.78, wps=33784.1, ups=1.37, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.416, loss_scale=4, train_wall=30, gb_free=14.3, wall=3429
2022-03-23 10:21:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:21:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 10:21:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:21:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:21:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:21:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:21:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are captured inside, but the superconductor doesn't like it, if they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:21:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:22:03 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form of information that refers the whole porter structure and all the fine.
2022-03-23 10:22:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:22:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that -- well, when dinner was first summarized, when someone said, "turn to your desk and say, 'when the revolution begins, we support you.' the truth is that we've already been supporting you about this topic for a long time."
2022-03-23 10:22:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:22:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the great part of the design work that we're on our airplane to be the most proud of our aircraft, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable and a cooling system of fluid, that allows us to use an aircraft in our aircraft to be a very stumber traffic, to a specialized way of using an aircraft, to a particular cycle where you can't solve it's either passing machine, or to a specifiction of passing machine, to an aircraft that will be used to an aircraft that will be used to an aircraft that will be a specifiction that will be a specifiction of a specific vehicle that will be used to an aircraft that will be used to an aircraft that will be able to an aircraft that will be used to a specific way of an aircraft that will look at the ground, all the ground, if you can
2022-03-23 10:22:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:22:10 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 5.329 | nll_loss 2.558 | ppl 5.89 | bleu 32.61 | wps 4723.1 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.96
2022-03-23 10:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:22:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.61) (writing took 0.9089198526926339 seconds)
2022-03-23 10:22:11 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:22:11 | INFO | train | epoch 038 | loss 5.114 | nll_loss 2.527 | ppl 5.76 | wps 44716.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.422 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3487
2022-03-23 10:22:11 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:22:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:22:24 | INFO | train_inner | epoch 039:     39 / 157 loss=5.055, nll_loss=2.454, ppl=5.48, wps=36741.9, ups=1.41, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.405, loss_scale=4, train_wall=30, gb_free=13.6, wall=3500
2022-03-23 10:22:55 | INFO | train_inner | epoch 039:    139 / 157 loss=5.13, nll_loss=2.548, ppl=5.85, wps=80110.2, ups=3.23, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.49, loss_scale=4, train_wall=31, gb_free=14.7, wall=3531
2022-03-23 10:23:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:23:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:23:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:23:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:23:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:23:12 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:23:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:23:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:23:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:23:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:23:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:23:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:23:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:23:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field types of magnetic field lines are captured inside, but the superconductor doesn't like it, if they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:23:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:23:32 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can, which restores the large constraints of the face and the basic shape, and then restore it through the one that refuses the entire porch structure and all the fits.
2022-03-23 10:23:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that -- well, when dinner was stripped, it was best summarized, when someone said, "turn you to the men on your table and say," if the revolution begins, we support you. "the truth, women, is that we've already been supporting you for a long period of time." at this time, racel spring, we've already started with silks. "
2022-03-23 10:23:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a large part of the design work that we're the most proud of on our airplane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable drive and a cooling system of liquid, that allows us to use an aircraft in the stop-and go-traffic, to be special to a rider, or if you can see the ground of one that's in the same way.
2022-03-23 10:23:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:39 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.3 | nll_loss 2.533 | ppl 5.79 | bleu 33.23 | wps 4682.5 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.23
2022-03-23 10:23:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:23:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:23:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:23:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.23) (writing took 1.9599131341092288 seconds)
2022-03-23 10:23:41 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:23:41 | INFO | train | epoch 039 | loss 5.093 | nll_loss 2.501 | ppl 5.66 | wps 43862.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.449 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3577
2022-03-23 10:23:41 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:07 | INFO | train_inner | epoch 040:     82 / 157 loss=5.063, nll_loss=2.461, ppl=5.51, wps=34368.6, ups=1.39, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.39, loss_scale=4, train_wall=30, gb_free=14.1, wall=3603
2022-03-23 10:24:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:24:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:24:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:41 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:24:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:24:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the sauce of people taking responsibility for wildlife, the number of wildlife grew up again, and that's a basis for conservation in namibia.
2022-03-23 10:24:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:58 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are captured inside, but the superconductor doesn't like it, if they move, because their movements use energy, and the superconductor disturbs.
2022-03-23 10:24:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:02 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that restores the big constraints of the face and the basic shape, and then ensus it through that information that refers the entire porn structure and all the fine wrinkles.
2022-03-23 10:25:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:25:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to be here for me at tedwomen is that... well, when dinner has been the best summarized when someone said, "turn you to your table and say," if the revolution begins, then we support you. '"the truth is that we've already been supporting you for a long time. rachel spring's"
2022-03-23 10:25:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:25:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're the most proud of on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variables and a refrigerator system that allows us to use an aircraft in the stop traffic to a specially appropriate vehicle, or if you're going to see the trajectory, if you're on the ground, you're going to see the aircraft, or if you're going to see the aircraft, you're on the aircraft, you're going to the road, you're going to see the road, or if you're going to see the aircraft, you're going to the aircraft, you're on the road, you're going to the road, you're going to the road, or if you're going to see the aircraft, you're going to the road, you're on the road, you're going to see the road,
2022-03-23 10:25:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:25:08 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.32 | nll_loss 2.549 | ppl 5.85 | bleu 33.02 | wps 4791.4 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.23
2022-03-23 10:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:25:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:25:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.02) (writing took 0.867511582095176 seconds)
2022-03-23 10:25:09 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:25:09 | INFO | train | epoch 040 | loss 5.056 | nll_loss 2.453 | ppl 5.47 | wps 44855.6 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.409 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3665
2022-03-23 10:25:09 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:25:17 | INFO | train_inner | epoch 041:     25 / 157 loss=5.071, nll_loss=2.472, ppl=5.55, wps=36287.2, ups=1.42, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.429, loss_scale=4, train_wall=30, gb_free=14.4, wall=3673
2022-03-23 10:25:48 | INFO | train_inner | epoch 041:    125 / 157 loss=5.038, nll_loss=2.43, ppl=5.39, wps=80155.5, ups=3.21, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.439, loss_scale=4, train_wall=31, gb_free=13.8, wall=3704
2022-03-23 10:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:26:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:26:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:26:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of beds that will transcend two new pigs.
2022-03-23 10:26:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:26:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:26:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:26:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:26:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:26:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent that people took responsibility for wildlife, the number of wildlife grew up again, and that's become a foundation for conservation in namibia.
2022-03-23 10:26:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:26:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your energy uses, and the superconductor disorder.
2022-03-23 10:26:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:26:30 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can, which resembles the big constraints of the face and the basic shape, and ending it through the one of the information that refers the whole porter structure and all the fine.
2022-03-23 10:26:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, when dinner was stripped, it was best summarized when someone said, "turn to the men on your table and say to them," if the revolution begins, then we support you. '"the truth is that we've been supporting you for a long time." at carroel spring, "] ["] ["] ["] ["] ["] ["
2022-03-23 10:26:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable and a refrigerator system with liquid, that allows us to use an aircraft in the stop-go-traffic to a special driver, or if you fly the ground, or when you get to the wheel.
2022-03-23 10:26:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:36 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.264 | nll_loss 2.502 | ppl 5.67 | bleu 33.64 | wps 4810.8 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.64
2022-03-23 10:26:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:26:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:26:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:26:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.64) (writing took 2.0151423630304635 seconds)
2022-03-23 10:26:38 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:26:38 | INFO | train | epoch 041 | loss 5.04 | nll_loss 2.433 | ppl 5.4 | wps 44346.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.425 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3754
2022-03-23 10:26:38 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:59 | INFO | train_inner | epoch 042:     68 / 157 loss=5.011, nll_loss=2.397, ppl=5.27, wps=35276.1, ups=1.41, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.406, loss_scale=4, train_wall=30, gb_free=22.4, wall=3776
2022-03-23 10:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:27:31 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepans in the clinic.
2022-03-23 10:27:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:27:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two pigs.
2022-03-23 10:27:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:27:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the corn of how people took responsibility for wildlife, the number of wild animals grew back. and this has become a foundation for conservation in namibia.
2022-03-23 10:27:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:55 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use their energy, and the superconducting disorder.
2022-03-23 10:27:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:59 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face bar that refers the big contures of the face and the basic shape, and then deploy it through that information that refers the entire porn structure and all the fine folds.
2022-03-23 10:27:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:28:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, when dinner was stripped, it was best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, we support you.'" the truth, women are love you for a long time. "
2022-03-23 10:28:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:28:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variable and a cooling system of liquid, that allows us to use an aircraft in the gait to stop and traffic to a particular bite, either if you're flying the ground, or if you're going to be able to be able to see the degraded, to the point where you're going.
2022-03-23 10:28:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:28:04 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 5.297 | nll_loss 2.517 | ppl 5.73 | bleu 33.15 | wps 4884.6 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.64
2022-03-23 10:28:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:28:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:28:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.15) (writing took 0.8397010061889887 seconds)
2022-03-23 10:28:05 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:28:05 | INFO | train | epoch 042 | loss 5.009 | nll_loss 2.394 | ppl 5.26 | wps 45246.3 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.404 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3841
2022-03-23 10:28:06 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:28:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:28:09 | INFO | train_inner | epoch 043:     11 / 157 loss=4.991, nll_loss=2.373, ppl=5.18, wps=36544.4, ups=1.43, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.392, loss_scale=4, train_wall=31, gb_free=13.9, wall=3846
2022-03-23 10:28:40 | INFO | train_inner | epoch 043:    111 / 157 loss=5.024, nll_loss=2.411, ppl=5.32, wps=80322.8, ups=3.23, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.429, loss_scale=4, train_wall=31, gb_free=13.8, wall=3877
2022-03-23 10:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:29:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:29:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in india that will transcend two new pigs.
2022-03-23 10:29:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:29:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:29:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:29:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:29:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:29:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:29:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconducting disorder.
2022-03-23 10:29:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:29:27 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big conscores of the face and the basic shape, and letting it go through the thief information that refuses the whole por-structure and all the fine.
2022-03-23 10:29:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in strict dinner, it's been the best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, we support you. '"'" 'the truth, love is that we've been supporting you with this topic for a long time. in carel spring, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["'
2022-03-23 10:29:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're most stumbling on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variables and a refrigerator system with refrigerators that allows us to use an aircraft in the stop go-traffic to a particular passenger drive, either when you fly the propeller, or when you get to the ground, to see the mechanism, until the trajectory of a constituency, until you get rid of an aircraft system that's going to the road, until you see the road, until you get rid of an aircraft system, until you get rid of an aircraft, until you get rid of an aircraft, until you get rid of an aircraft system, until you get rid of an aircraft, until you see it's going to the propeller, until you get rid of an aircraft,
2022-03-23 10:29:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:33 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 5.267 | nll_loss 2.487 | ppl 5.61 | bleu 33.79 | wps 4664.2 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.79
2022-03-23 10:29:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:29:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:29:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.79) (writing took 1.9698162181302905 seconds)
2022-03-23 10:29:35 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:29:35 | INFO | train | epoch 043 | loss 4.992 | nll_loss 2.371 | ppl 5.17 | wps 43814 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.415 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3932
2022-03-23 10:29:36 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:53 | INFO | train_inner | epoch 044:     54 / 157 loss=4.964, nll_loss=2.337, ppl=5.05, wps=34339.8, ups=1.38, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.436, loss_scale=4, train_wall=30, gb_free=14.2, wall=3949
2022-03-23 10:30:23 | INFO | train_inner | epoch 044:    154 / 157 loss=4.97, nll_loss=2.344, ppl=5.08, wps=83175.8, ups=3.25, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.391, loss_scale=4, train_wall=30, gb_free=13.8, wall=3980
2022-03-23 10:30:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:30:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 10:30:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:30:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:30:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:30:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:30:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they're moving, because their movements are using energy, and the superconductor is disturbing.
2022-03-23 10:30:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:56 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that refers the big constraints of the face and the basic form, and then go through that information that refers the whole porn structure and all the fine folds.
2022-03-23 10:30:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:31:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it highly interesting and appropriate to me here at tedwomen is that -- well, when dinner was strictly summarized, it was the best summarized when someone said, "turn to the men on your table and say to you," if the revolution begins, then we support you. '"the truth, women have already supported you for a long time.
2022-03-23 10:31:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:31:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're the most stumbling on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously variable and a refrigerator system, that allows us to use an aircraft in stopand go-traffic to a special drive, either when you fly or when you get propelled to the ground -- all the propelled to a mechanism.
2022-03-23 10:31:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:31:02 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 5.276 | nll_loss 2.5 | ppl 5.66 | bleu 33.41 | wps 4808.5 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.79
2022-03-23 10:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:31:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.41) (writing took 0.9509964748285711 seconds)
2022-03-23 10:31:03 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:31:03 | INFO | train | epoch 044 | loss 4.974 | nll_loss 2.348 | ppl 5.09 | wps 44909.1 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.422 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 4020
2022-03-23 10:31:04 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:34 | INFO | train_inner | epoch 045:     97 / 157 loss=4.949, nll_loss=2.317, ppl=4.98, wps=36206.8, ups=1.41, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.431, loss_scale=4, train_wall=31, gb_free=14.6, wall=4050
2022-03-23 10:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleeps in the clinic.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline that i think most of you know about.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:32:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of dinments that will transcend two new pigs.
2022-03-23 10:32:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:32:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:32:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:32:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all its thoughts are on the track.
2022-03-23 10:32:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:32:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people were taking responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:32:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:32:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use their energy, and the superconductor disorder.
2022-03-23 10:32:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:32:25 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that restores the big constraints of the face and the basic form, and then restore it by the one that refers the whole porter structure and all the fine wrinkles.
2022-03-23 10:32:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate, to me here at tedwomen is that -- well, when argued dinner, it was best summarized when someone said, "turn to the men to your table and say to them, 'when the revolution begins, we support you.'" the truth is that we love you for a long time. "
2022-03-23 10:32:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a refrigerating system of fluid, that allows us to use an aircraft at the same time, to fly the ground, to the wheel.
2022-03-23 10:32:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:30 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 5.257 | nll_loss 2.485 | ppl 5.6 | bleu 33.83 | wps 4814.7 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.83
2022-03-23 10:32:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:32:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:32:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:32:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 45 @ 7060 updates, score 33.83) (writing took 1.9579131212085485 seconds)
2022-03-23 10:32:32 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:32:32 | INFO | train | epoch 045 | loss 4.965 | nll_loss 2.337 | ppl 5.05 | wps 44359 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.441 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 4109
2022-03-23 10:32:33 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:32:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:45 | INFO | train_inner | epoch 046:     40 / 157 loss=4.973, nll_loss=2.347, ppl=5.09, wps=34299.5, ups=1.41, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.441, loss_scale=4, train_wall=30, gb_free=14.3, wall=4121
2022-03-23 10:33:16 | INFO | train_inner | epoch 046:    140 / 157 loss=4.93, nll_loss=2.294, ppl=4.9, wps=81542.5, ups=3.21, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.4, loss_scale=4, train_wall=31, gb_free=13.6, wall=4153
2022-03-23 10:33:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:33:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:33:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:33:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:33:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:49 | INFO | fairseq.tasks.translation | example hypothesis: first, a few strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use their energy and disturb the superconductor.
2022-03-23 10:33:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:53 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form, and enhance it through the information that refers the entire porn structure and all the fine.
2022-03-23 10:33:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in the strictly dinner, it was best summarized when someone said, "turn to the men at your table and say," if the revolution begins, we support you. '"'" the truth, love is that we've already supported you for a long time. at rachel carel spring, "the future of sandra borrowing."
2022-03-23 10:33:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention, and a big part of the design work that we're most proud about on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable and a refrigeration system with fluid, that allows us to use an aircraft at the stopand go-go-traffic, to a special passenger vehicle that can be propelled, or if you fly the ground, to the security system.
2022-03-23 10:33:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:58 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 5.257 | nll_loss 2.479 | ppl 5.58 | bleu 33.72 | wps 4987.9 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.83
2022-03-23 10:33:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:33:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:33:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:33:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.72) (writing took 0.902223042678088 seconds)
2022-03-23 10:33:59 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:33:59 | INFO | train | epoch 046 | loss 4.934 | nll_loss 2.298 | ppl 4.92 | wps 45579.3 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.41 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 4195
2022-03-23 10:33:59 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 10:33:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:34:26 | INFO | train_inner | epoch 047:     83 / 157 loss=4.908, nll_loss=2.264, ppl=4.8, wps=36056.4, ups=1.43, wpb=25147.5, bsz=1057.7, num_updates=7300, lr=0.000370117, gnorm=0.413, loss_scale=4, train_wall=30, gb_free=13.8, wall=4222
2022-03-23 10:34:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers in the clinic.
2022-03-23 10:34:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:34:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:34:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:35:01 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:35:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:35:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:35:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:35:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:35:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:35:13 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 10:35:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:35:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy and the superconductor disorder.
2022-03-23 10:35:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:35:21 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can, which restores the big constraints of the face and the basic form, and then add it through that information that refers the entire porn structure and all the fine.
2022-03-23 10:35:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:35:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, at strict dinner, it was best summarized when someone said, "turn to the men on your table and say to you. 'when the revolution begins, we support you.'" the truth, women, is that we've already supported you at this topic for a long time. at rachel spring. "
2022-03-23 10:35:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:35:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're on our plane at the stumbling toast, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable and a cooling system with fluid, that allows us to use an aircraft in the gait in the stop go-traffic, to a specially appropriate vehicle.
2022-03-23 10:35:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:35:26 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 5.25 | nll_loss 2.479 | ppl 5.57 | bleu 33.81 | wps 5028.2 | wpb 17862.2 | bsz 728.3 | num_updates 7374 | best_bleu 33.83
2022-03-23 10:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7374 updates
2022-03-23 10:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:35:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 47 @ 7374 updates, score 33.81) (writing took 0.9797002887353301 seconds)
2022-03-23 10:35:27 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 10:35:27 | INFO | train | epoch 047 | loss 4.916 | nll_loss 2.273 | ppl 4.83 | wps 45012.2 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7374 | lr 0.000368255 | gnorm 0.404 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 4283
2022-03-23 10:35:27 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 10:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:35:35 | INFO | train_inner | epoch 048:     26 / 157 loss=4.91, nll_loss=2.268, ppl=4.82, wps=36315.1, ups=1.45, wpb=25089, bsz=1043, num_updates=7400, lr=0.000367607, gnorm=0.419, loss_scale=4, train_wall=30, gb_free=13.6, wall=4291
2022-03-23 10:36:07 | INFO | train_inner | epoch 048:    126 / 157 loss=4.912, nll_loss=2.268, ppl=4.82, wps=81406.2, ups=3.17, wpb=25678, bsz=966, num_updates=7500, lr=0.000365148, gnorm=0.382, loss_scale=4, train_wall=31, gb_free=14, wall=4323
2022-03-23 10:36:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:36:20 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep beep at the clinic.
2022-03-23 10:36:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:36:24 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here know.
2022-03-23 10:36:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:36:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks prayers that will transcend two new pigs.
2022-03-23 10:36:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:36:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:36:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:36:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:36:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:36:40 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:36:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:36:44 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconductor disorder.
2022-03-23 10:36:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:36:48 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that refers the big constructures of the face and the basic shape, and then add it through that information that refers the entire por-structure and all the fine wrinkles.
2022-03-23 10:36:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:36:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate to me here at tedwomen is that -- well, when dinner was stripped, it was best summarized when someone said, "turn to the men to your desk and say to them, 'when the revolution starts to support you.'" '"the truth is that we've been supporting you with this topic for a long time. at rachel spring, we've already started with silspring," the future of sandra: "and then we've been doing our gains borrow row row row row," and then we're going to downstream, "
2022-03-23 10:36:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:36:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the need to be the mother of invention, and a large part of the design work that we're on our airplane to the most stagnant, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variables and a cooling system with liquid that it allows us to use a machine in the stop-go-traffic, to a special vehicle vehicle vehicle vehicle that is either when you have to run the unique problems that when you're propeller or when you're flying, if you're going to the propeller or when you're going to operate on the wheel or when you're flying space where you're flying, if you're going to the plotter or when you're going to the plotter or when you're going to the wheels that you're going to do it's going to do it's going to do it's going to operate on the ground, if you're going to do it's going to do it's going to the
2022-03-23 10:36:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:36:55 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 5.242 | nll_loss 2.471 | ppl 5.54 | bleu 33.92 | wps 4756.4 | wpb 17862.2 | bsz 728.3 | num_updates 7531 | best_bleu 33.92
2022-03-23 10:36:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7531 updates
2022-03-23 10:36:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:36:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:36:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 48 @ 7531 updates, score 33.92) (writing took 2.116327908821404 seconds)
2022-03-23 10:36:57 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 10:36:57 | INFO | train | epoch 048 | loss 4.898 | nll_loss 2.251 | ppl 4.76 | wps 43818 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 7531 | lr 0.000364396 | gnorm 0.409 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 4373
2022-03-23 10:36:57 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 10:36:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:37:19 | INFO | train_inner | epoch 049:     69 / 157 loss=4.885, nll_loss=2.235, ppl=4.71, wps=33838.4, ups=1.39, wpb=24399, bsz=1004.6, num_updates=7600, lr=0.000362738, gnorm=0.422, loss_scale=4, train_wall=30, gb_free=14.1, wall=4395
2022-03-23 10:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:37:50 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:37:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:37:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of us here know.
2022-03-23 10:37:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:37:58 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:37:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:38:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:38:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:38:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:38:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:38:10 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:38:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:38:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because they use their movements to disturb the superconductor.
2022-03-23 10:38:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:38:18 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the size of the face and the basic form, and then add it through the thief information that refers the whole porn structure and all the fine.
2022-03-23 10:38:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:38:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn to the men on your desk and say, 'when the revolution starts, we support you.'" the truth, women, is that we've been supporting you with this topic for a long time. at rachel spring, "future borra: yeah." & lt; em & gt; & lt; / em & gt;
2022-03-23 10:38:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:38:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a huge part of the design work that we're on our airplane at the most staggering toast was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variable and a refrigerator system, that it allows us to use a machine in stop-go-traffic until a particular vehicle that was either drives the soil until the wheel, or when you see the wheel, the ground of a mechanism.
2022-03-23 10:38:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:38:24 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 5.239 | nll_loss 2.474 | ppl 5.55 | bleu 33.8 | wps 4797.8 | wpb 17862.2 | bsz 728.3 | num_updates 7688 | best_bleu 33.92
2022-03-23 10:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7688 updates
2022-03-23 10:38:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:38:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:38:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 49 @ 7688 updates, score 33.8) (writing took 0.9275084282271564 seconds)
2022-03-23 10:38:25 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 10:38:25 | INFO | train | epoch 049 | loss 4.881 | nll_loss 2.23 | ppl 4.69 | wps 44903.3 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 7688 | lr 0.000360656 | gnorm 0.4 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4461
2022-03-23 10:38:25 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 10:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:38:29 | INFO | train_inner | epoch 050:     12 / 157 loss=4.879, nll_loss=2.228, ppl=4.69, wps=36391.3, ups=1.42, wpb=25586.8, bsz=1069, num_updates=7700, lr=0.000360375, gnorm=0.401, loss_scale=4, train_wall=30, gb_free=14.7, wall=4465
2022-03-23 10:39:00 | INFO | train_inner | epoch 050:    112 / 157 loss=4.857, nll_loss=2.199, ppl=4.59, wps=81498.5, ups=3.21, wpb=25420, bsz=1059.8, num_updates=7800, lr=0.000358057, gnorm=0.402, loss_scale=4, train_wall=31, gb_free=13.7, wall=4497
2022-03-23 10:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:39:18 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:39:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:39:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:39:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:39:25 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of india that will transcend two new pigs.
2022-03-23 10:39:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:39:29 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:39:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:39:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:39:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:39:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife regrew. and that's become a basis for conservation in namibia.
2022-03-23 10:39:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:39:42 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are used, and the superconductor is disturbing.
2022-03-23 10:39:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:39:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the big contures of the face and the basic form, and then we'll add it through the thief information that refers all the pores structure and all the fine.
2022-03-23 10:39:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:39:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, at the strictly dinner, it's been best summarized when someone said, "turn to the men to your desk and say, 'when the revolution begins, we'll support you.'" the truth, women, is that we've already been supporting you in this topic for a long time. at chel carbonson spring, "in the future, borra borrow, we're going to download our borrows."
2022-03-23 10:39:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:39:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're most proud of on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a refrigerator system, that it allows us to use a aircraft machine in stop-go-traffic to a special passenger vehicle that can be propelled to either drive, if you fly in the ground, or when you go to the deployment of a mechanism, to the deployment of an aircraft system of an aircraft in the aircraft, to the aircraft system of an aircraft, to the aircraft, to the aircraft, to the aircraft, to the aircraft, to the rail, to the rail, to the aircraft system, to the aircraft, to the aircraft system, to the aircraft, to the aircraft, to the aircraft, to the aircraft
2022-03-23 10:39:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:39:52 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 5.221 | nll_loss 2.456 | ppl 5.49 | bleu 34.09 | wps 4737.2 | wpb 17862.2 | bsz 728.3 | num_updates 7845 | best_bleu 34.09
2022-03-23 10:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7845 updates
2022-03-23 10:39:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:39:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 50 @ 7845 updates, score 34.09) (writing took 2.086033334955573 seconds)
2022-03-23 10:39:54 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 10:39:54 | INFO | train | epoch 050 | loss 4.863 | nll_loss 2.207 | ppl 4.62 | wps 44070.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 7845 | lr 0.000357029 | gnorm 0.401 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 4551
2022-03-23 10:39:55 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 10:39:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:40:12 | INFO | train_inner | epoch 051:     55 / 157 loss=4.856, nll_loss=2.196, ppl=4.58, wps=34700.1, ups=1.39, wpb=24912.1, bsz=989.4, num_updates=7900, lr=0.000355784, gnorm=0.395, loss_scale=4, train_wall=30, gb_free=14.8, wall=4568
2022-03-23 10:40:43 | INFO | train_inner | epoch 051:    155 / 157 loss=4.852, nll_loss=2.192, ppl=4.57, wps=81958.2, ups=3.26, wpb=25169.7, bsz=1006.8, num_updates=8000, lr=0.000353553, gnorm=0.408, loss_scale=4, train_wall=30, gb_free=13.5, wall=4599
2022-03-23 10:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:40:47 | INFO | fairseq.tasks.translation | example hypothesis: we put up these pieppers in the clinic.
2022-03-23 10:40:47 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:40:51 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which i think most of you know here.
2022-03-23 10:40:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:40:55 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:40:55 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:40:59 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:40:59 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:41:03 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:41:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:41:07 | INFO | fairseq.tasks.translation | example hypothesis: and in the measurement of people's responsibility for wildlife, the number of wildlife regrew. and this has become a basis for conservation in namibia.
2022-03-23 10:41:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:41:11 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like it, if they move, because their movements use their energy, and the superconducting disorder.
2022-03-23 10:41:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:41:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the size of the face and the basic shape, and then go through the information that refers the entire porter structure and all the fine.
2022-03-23 10:41:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:41:19 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, in the strictly dinner, it was best summarized when someone said, "turn to the men on your desk and tell them, 'when the revolution begins, then we support you.' the truth, women, is that we've already supported you in this topic for a long period of time. in chrael carel spring, we've started our future."
2022-03-23 10:41:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:41:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drive and a refrigerator system with a refrigerator system, that it allows us to use an aircraft in the stop and go-traffic to a special driver that either drives the propelled or when you're flying, or if you're in the ground, or if you're the trajectory of a mechanism, the aircraft system, to the aircraft, to the ground, to the aircraft.
2022-03-23 10:41:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:41:21 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 5.238 | nll_loss 2.45 | ppl 5.46 | bleu 34.02 | wps 4823.4 | wpb 17862.2 | bsz 728.3 | num_updates 8002 | best_bleu 34.09
2022-03-23 10:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8002 updates
2022-03-23 10:41:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 51 @ 8002 updates, score 34.02) (writing took 0.9846022939309478 seconds)
2022-03-23 10:41:22 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 10:41:22 | INFO | train | epoch 051 | loss 4.846 | nll_loss 2.184 | ppl 4.54 | wps 44908.7 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 8002 | lr 0.000353509 | gnorm 0.403 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 4639
2022-03-23 10:41:23 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 10:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:41:53 | INFO | train_inner | epoch 052:     98 / 157 loss=4.818, nll_loss=2.149, ppl=4.43, wps=35607.1, ups=1.42, wpb=25057.5, bsz=1065.7, num_updates=8100, lr=0.000351364, gnorm=0.415, loss_scale=4, train_wall=30, gb_free=13.6, wall=4669
2022-03-23 10:42:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:42:15 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep at the clinic.
2022-03-23 10:42:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:42:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 10:42:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:42:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:42:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:42:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:42:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:42:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:42:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:42:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the magnitude of people's responsibility for wildlife, the number of wildlife regrew, and this has become a basis of conservation in namibia.
2022-03-23 10:42:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:42:39 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when they move around, because they use their movements to disrupt the superconductor.
2022-03-23 10:42:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:42:43 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the gross contours of the face and restores the basic shape, and then add it through that information that refers all the pores structure and all the fine.
2022-03-23 10:42:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:42:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in the strictly dinner, it's been put together best when someone said, "turn to the men on your desk and say to them, 'when the revolution starts, we'll support you.'" '"the truth is that we love you for a long time."
2022-03-23 10:42:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:42:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuously variable and a cooling system of liquid that allows us to use an aircraft in the stop-go-to a particular vehicle that would either drive the propeller or if you're going to the ground.
2022-03-23 10:42:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:42:49 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 5.217 | nll_loss 2.452 | ppl 5.47 | bleu 34.28 | wps 4895.7 | wpb 17862.2 | bsz 728.3 | num_updates 8159 | best_bleu 34.28
2022-03-23 10:42:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8159 updates
2022-03-23 10:42:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:42:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:42:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 52 @ 8159 updates, score 34.28) (writing took 2.0709973541088402 seconds)
2022-03-23 10:42:51 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 10:42:51 | INFO | train | epoch 052 | loss 4.839 | nll_loss 2.175 | ppl 4.52 | wps 44631.3 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 8159 | lr 0.000350091 | gnorm 0.411 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 4727
2022-03-23 10:42:51 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 10:42:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:43:04 | INFO | train_inner | epoch 053:     41 / 157 loss=4.844, nll_loss=2.181, ppl=4.53, wps=35487.8, ups=1.41, wpb=25151.3, bsz=978.2, num_updates=8200, lr=0.000349215, gnorm=0.415, loss_scale=4, train_wall=30, gb_free=13.9, wall=4740
2022-03-23 10:43:35 | INFO | train_inner | epoch 053:    141 / 157 loss=4.841, nll_loss=2.179, ppl=4.53, wps=80062.3, ups=3.22, wpb=24894.4, bsz=1025.6, num_updates=8300, lr=0.000347105, gnorm=0.43, loss_scale=4, train_wall=31, gb_free=14.1, wall=4771
2022-03-23 10:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:43:44 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep at the clinic.
2022-03-23 10:43:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:43:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:43:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:43:52 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in india that will transcend two new pigs.
2022-03-23 10:43:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:43:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:43:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:44:00 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:44:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:44:04 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife regrew. and this has become a basis for conservation in namibia.
2022-03-23 10:44:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:44:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when you move around, because your movements are using your energy, and the superconductor is disturbing.
2022-03-23 10:44:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:44:12 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional face can that restores the big contours of the face and the basic form, and then go through that information that refers all the pores structure and all the fine.
2022-03-23 10:44:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:44:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate, to me here at tedwomen, is that... well, in the strictly dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution begins, then we support you. "the truth, women love you, is that we've been supporting you for a long time. at rachel carly spring," and then our future borrows. "
2022-03-23 10:44:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:44:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable drive and a cooling system of liquid that allows us to use a aircraft machine in stop-go-traffic to a particular passenger passage that either drives the propelled to the ground, or when you get to see the trajectory, to the ground, to see the security facility, to see the deforesting mechanism in the aircraft system.
2022-03-23 10:44:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:44:17 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 5.212 | nll_loss 2.433 | ppl 5.4 | bleu 34.5 | wps 4965 | wpb 17862.2 | bsz 728.3 | num_updates 8316 | best_bleu 34.5
2022-03-23 10:44:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8316 updates
2022-03-23 10:44:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt
2022-03-23 10:44:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_best.pt (epoch 53 @ 8316 updates, score 34.5) (writing took 2.1118562216870487 seconds)
2022-03-23 10:44:20 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 10:44:20 | INFO | train | epoch 053 | loss 4.83 | nll_loss 2.164 | ppl 4.48 | wps 44475.6 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 8316 | lr 0.000346771 | gnorm 0.424 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 4816
2022-03-23 10:44:20 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 10:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:44:46 | INFO | train_inner | epoch 054:     84 / 157 loss=4.821, nll_loss=2.151, ppl=4.44, wps=35823.4, ups=1.41, wpb=25481.9, bsz=991, num_updates=8400, lr=0.000345033, gnorm=0.43, loss_scale=4, train_wall=30, gb_free=13.8, wall=4843
2022-03-23 10:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:45:13 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:45:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:45:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, probably most of you here.
2022-03-23 10:45:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:45:20 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:45:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:45:25 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:45:25 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:45:29 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:45:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:45:33 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife regrew, and that's become a basis for conservation in namibia.
2022-03-23 10:45:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:45:37 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and the superconductor is disturbing.
2022-03-23 10:45:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:45:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that restores the large constructures of the face and the basic shape, and go through that information that refers the entire porter structure and all the fine.
2022-03-23 10:45:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:45:45 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn you to your desk and say to the men," when the revolution starts, we support you. '"the truth, love is that we've already supported you for a long time. at rachel carel spring," the future of sandstone. "
2022-03-23 10:45:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:45:46 | INFO | fairseq.tasks.translation | example hypothesis: luckily, still the mother of invention, and a large part of the design work that we're most proud of on our airplane, was a result that we had to solve the unique problems that were connected to doing it on the ground -- everything from a continuous variables and a cooling system of liquid that allows us to use an aircraft in stop-go-traffic to a particular passenger drive that either drives the propels or when you fly on the ground to the wheel or when you get rid of a car storm.
2022-03-23 10:45:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:45:46 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 5.227 | nll_loss 2.443 | ppl 5.44 | bleu 34.22 | wps 4937.2 | wpb 17862.2 | bsz 728.3 | num_updates 8473 | best_bleu 34.5
2022-03-23 10:45:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8473 updates
2022-03-23 10:45:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 54 @ 8473 updates, score 34.22) (writing took 0.9471146818250418 seconds)
2022-03-23 10:45:47 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 10:45:47 | INFO | train | epoch 054 | loss 4.812 | nll_loss 2.14 | ppl 4.41 | wps 45263.5 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 8473 | lr 0.000343543 | gnorm 0.419 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 4903
2022-03-23 10:45:47 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 10:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:45:56 | INFO | train_inner | epoch 055:     27 / 157 loss=4.795, nll_loss=2.118, ppl=4.34, wps=36269.8, ups=1.43, wpb=25284.2, bsz=1058, num_updates=8500, lr=0.000342997, gnorm=0.396, loss_scale=4, train_wall=31, gb_free=13.4, wall=4912
2022-03-23 10:46:27 | INFO | train_inner | epoch 055:    127 / 157 loss=4.816, nll_loss=2.145, ppl=4.42, wps=81274.1, ups=3.24, wpb=25067.6, bsz=963.8, num_updates=8600, lr=0.000340997, gnorm=0.43, loss_scale=4, train_wall=30, gb_free=14.7, wall=4943
2022-03-23 10:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:46:40 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 10:46:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:46:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:46:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:46:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:46:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:46:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:46:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:46:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:46:59 | INFO | fairseq.tasks.translation | example hypothesis: and at the rate of how people took responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-23 10:46:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:47:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field bundles are trapped inside, but the superconductor doesn't like it when they move because their movements use energy, and that's how the superconductor boils.
2022-03-23 10:47:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:47:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use information that comes from this mirror reflection, we can start with a traditional facial can that restores the gross contours of the face and the basic shape, and then add it through that information that refers the whole porch structure and all the fine.
2022-03-23 10:47:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:47:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate, to me here at tedwomen, is that... well, when constricted dinner, it was best summarized when someone said, "turn to the men at your table and say, 'when the revolution starts, we'll support you.'" the truth, women, is that we've already been supporting you for a long time. rachel carel spring, "in our future," and we're going to crumb our pride to sandra foods. "
2022-03-23 10:47:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:47:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, there's still the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables and a cooling system of fluid that allows us to use an aircraft machine in stop-go-traffic to a particular vehicle that either drives the propelled to the ground, or when you're flying, or if you're on the ground, or when you're on a mechanical storm, to see the air conditioning device to the ground, to the ground, to see an aircraft system, to the air conditioning system, to the aircraft system, to the ground, to the aircraft, to the air conditioning, to the air conditioning, to the ground, to the aircraft facilities, to the air conditioning, to the air conditioning, to the air conditioning, to the
2022-03-23 10:47:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:47:14 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 5.217 | nll_loss 2.436 | ppl 5.41 | bleu 34.2 | wps 4772.9 | wpb 17862.2 | bsz 728.3 | num_updates 8630 | best_bleu 34.5
2022-03-23 10:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8630 updates
2022-03-23 10:47:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 55 @ 8630 updates, score 34.2) (writing took 0.9873558622784913 seconds)
2022-03-23 10:47:15 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 10:47:15 | INFO | train | epoch 055 | loss 4.798 | nll_loss 2.122 | ppl 4.35 | wps 44691.1 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 8630 | lr 0.000340404 | gnorm 0.416 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 4991
2022-03-23 10:47:16 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 10:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:47:38 | INFO | train_inner | epoch 056:     70 / 157 loss=4.787, nll_loss=2.107, ppl=4.31, wps=34631.4, ups=1.41, wpb=24477.2, bsz=993.4, num_updates=8700, lr=0.000339032, gnorm=0.41, loss_scale=4, train_wall=30, gb_free=13.7, wall=5014
2022-03-23 10:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:48:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:48:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:48:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:48:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:48:16 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two pigs.
2022-03-23 10:48:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:48:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:48:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:48:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of his thoughts are on the track.
2022-03-23 10:48:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:48:28 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:48:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:48:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and the superconductor is disturbing.
2022-03-23 10:48:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:48:36 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that refers the large constructures of the face and the basic shape, and then add it through that information that refers the whole pore structure and all the fine wrinkles.
2022-03-23 10:48:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:48:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me here at tedwomen is that... well, at strict dinner, it was best summarized when someone said, "turn to the men on your table and say, 'when the revolution starts, we'll support you.' '" the truth, women, is that we've been supporting you for this for a long time. at rachel carent, "with silspring," future borra's borrows. "
2022-03-23 10:48:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:48:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're most proud of on our airplane, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variables and a cooling system of fluid that allows us to use a machine in stop and traffic to a special passenger that either drives the propeller, or when you run the ground to see the cycles.
2022-03-23 10:48:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:48:41 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 5.224 | nll_loss 2.429 | ppl 5.38 | bleu 34.21 | wps 5034.7 | wpb 17862.2 | bsz 728.3 | num_updates 8787 | best_bleu 34.5
2022-03-23 10:48:41 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 8787 updates
2022-03-23 10:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:48:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt
2022-03-23 10:48:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.2_#1/checkpoint_last.pt (epoch 56 @ 8787 updates, score 34.21) (writing took 0.9424871141090989 seconds)
2022-03-23 10:48:42 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 10:48:42 | INFO | train | epoch 056 | loss 4.784 | nll_loss 2.104 | ppl 4.3 | wps 45581.7 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 8787 | lr 0.000337349 | gnorm 0.407 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 5078
2022-03-23 10:48:42 | INFO | fairseq_cli.train | done training in 5077.7 seconds
