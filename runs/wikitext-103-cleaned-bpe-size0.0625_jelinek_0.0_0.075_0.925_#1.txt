Sender: LSF System <lsfadmin@eu-g3-071>
Subject: Job 208123773: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.0_0.075_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.0_0.075_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:25:17 2022
Job was executed on host(s) <eu-g3-071>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 16:39:06 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 16:39:06 2022
Terminated at Tue Mar 15 06:20:18 2022
Results reported at Tue Mar 15 06:20:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.0, 0.075, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   49238.54 sec.
    Max Memory :                                 5102 MB
    Average Memory :                             3489.67 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14898.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   49272 sec.
    Turnaround time :                            71701 sec.

The output (if any) follows:

2022-03-14 16:39:15 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.0, 0.075, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 16:39:15 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-14 16:39:16 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
Calculating frequency stats:
  0%|          | 0/112584 [00:00<?, ?it/s]  1%|          | 632/112584 [00:00<00:17, 6316.06it/s]  1%|          | 1264/112584 [00:00<00:19, 5575.01it/s]  2%|▏         | 1828/112584 [00:00<00:20, 5457.65it/s]  2%|▏         | 2377/112584 [00:00<00:20, 5310.83it/s]  3%|▎         | 3130/112584 [00:00<00:18, 6065.92it/s]  3%|▎         | 3742/112584 [00:00<00:18, 5853.68it/s]  4%|▍         | 4401/112584 [00:00<00:17, 6079.93it/s]  5%|▍         | 5112/112584 [00:00<00:16, 6393.88it/s]  5%|▌         | 5756/112584 [00:00<00:16, 6333.48it/s]  6%|▌         | 6393/112584 [00:01<00:17, 6192.78it/s]  6%|▌         | 7015/112584 [00:01<00:18, 5795.96it/s]  7%|▋         | 7613/112584 [00:01<00:17, 5847.23it/s]  7%|▋         | 8203/112584 [00:01<00:18, 5734.43it/s]  8%|▊         | 8780/112584 [00:01<00:18, 5722.93it/s]  8%|▊         | 9405/112584 [00:01<00:17, 5875.54it/s]  9%|▉         | 9997/112584 [00:01<00:17, 5887.47it/s]  9%|▉         | 10588/112584 [00:01<00:17, 5766.78it/s] 10%|▉         | 11185/112584 [00:01<00:17, 5825.42it/s] 10%|█         | 11769/112584 [00:02<00:17, 5653.51it/s] 11%|█         | 12395/112584 [00:02<00:17, 5827.98it/s] 12%|█▏        | 12994/112584 [00:02<00:16, 5873.62it/s] 12%|█▏        | 13659/112584 [00:02<00:16, 6085.10it/s] 13%|█▎        | 14269/112584 [00:02<00:16, 6014.13it/s] 13%|█▎        | 14872/112584 [00:02<00:16, 6015.51it/s] 14%|█▎        | 15475/112584 [00:02<00:16, 5849.85it/s] 14%|█▍        | 16062/112584 [00:02<00:16, 5721.54it/s] 15%|█▍        | 16636/112584 [00:02<00:16, 5686.41it/s] 15%|█▌        | 17269/112584 [00:02<00:16, 5868.22it/s] 16%|█▌        | 17879/112584 [00:03<00:15, 5932.16it/s] 16%|█▋        | 18474/112584 [00:03<00:16, 5756.76it/s] 17%|█▋        | 19197/112584 [00:03<00:15, 6173.56it/s] 18%|█▊        | 19826/112584 [00:03<00:14, 6207.27it/s] 18%|█▊        | 20449/112584 [00:03<00:15, 5938.58it/s] 19%|█▊        | 21047/112584 [00:03<00:15, 5919.59it/s] 19%|█▉        | 21642/112584 [00:03<00:15, 5685.34it/s] 20%|█▉        | 22272/112584 [00:03<00:15, 5855.54it/s] 20%|██        | 22943/112584 [00:03<00:14, 6101.78it/s] 21%|██        | 23557/112584 [00:03<00:14, 6076.98it/s] 22%|██▏       | 24269/112584 [00:04<00:13, 6375.54it/s] 22%|██▏       | 24946/112584 [00:04<00:13, 6491.63it/s] 23%|██▎       | 25597/112584 [00:04<00:13, 6452.02it/s] 23%|██▎       | 26244/112584 [00:04<00:14, 6124.90it/s] 24%|██▍       | 26861/112584 [00:04<00:14, 5836.75it/s] 24%|██▍       | 27450/112584 [00:04<00:15, 5634.57it/s] 25%|██▍       | 28041/112584 [00:04<00:14, 5704.51it/s] 26%|██▌       | 28755/112584 [00:04<00:13, 6111.92it/s] 26%|██▌       | 29371/112584 [00:04<00:14, 5815.14it/s] 27%|██▋       | 30026/112584 [00:05<00:13, 6014.92it/s] 27%|██▋       | 30633/112584 [00:05<00:14, 5675.08it/s] 28%|██▊       | 31207/112584 [00:05<00:14, 5515.01it/s] 28%|██▊       | 31825/112584 [00:05<00:14, 5694.71it/s] 29%|██▉       | 32400/112584 [00:05<00:14, 5529.50it/s] 29%|██▉       | 32957/112584 [00:05<00:14, 5539.94it/s] 30%|██▉       | 33514/112584 [00:05<00:14, 5494.79it/s] 30%|███       | 34104/112584 [00:05<00:13, 5610.33it/s] 31%|███       | 34784/112584 [00:05<00:13, 5955.61it/s] 31%|███▏      | 35382/112584 [00:06<00:13, 5721.44it/s] 32%|███▏      | 35958/112584 [00:06<00:13, 5669.09it/s] 32%|███▏      | 36581/112584 [00:06<00:13, 5823.12it/s] 33%|███▎      | 37166/112584 [00:06<00:13, 5637.01it/s] 34%|███▎      | 37733/112584 [00:06<00:13, 5485.46it/s] 34%|███▍      | 38298/112584 [00:06<00:13, 5528.50it/s] 35%|███▍      | 38877/112584 [00:06<00:13, 5600.69it/s] 35%|███▌      | 39439/112584 [00:06<00:13, 5520.29it/s] 36%|███▌      | 40059/112584 [00:06<00:12, 5715.93it/s] 36%|███▌      | 40746/112584 [00:06<00:11, 6053.45it/s] 37%|███▋      | 41353/112584 [00:07<00:12, 5895.84it/s] 37%|███▋      | 41945/112584 [00:07<00:12, 5549.34it/s] 38%|███▊      | 42505/112584 [00:07<00:12, 5429.45it/s] 38%|███▊      | 43077/112584 [00:07<00:12, 5511.13it/s] 39%|███▉      | 43690/112584 [00:07<00:12, 5688.44it/s] 39%|███▉      | 44262/112584 [00:07<00:12, 5607.14it/s] 40%|███▉      | 44911/112584 [00:07<00:11, 5858.68it/s] 40%|████      | 45519/112584 [00:07<00:11, 5918.47it/s] 41%|████      | 46156/112584 [00:07<00:10, 6051.24it/s] 42%|████▏     | 46766/112584 [00:07<00:10, 6058.44it/s] 42%|████▏     | 47733/112584 [00:08<00:09, 7129.26it/s] 43%|████▎     | 48448/112584 [00:08<00:09, 6872.83it/s] 44%|████▎     | 49139/112584 [00:08<00:09, 6848.11it/s] 44%|████▍     | 49826/112584 [00:08<00:09, 6692.44it/s] 45%|████▍     | 50498/112584 [00:08<00:10, 6155.48it/s] 45%|████▌     | 51123/112584 [00:08<00:10, 6067.90it/s] 46%|████▌     | 51736/112584 [00:08<00:10, 6050.36it/s] 47%|████▋     | 52517/112584 [00:08<00:09, 6541.21it/s] 47%|████▋     | 53177/112584 [00:08<00:09, 6344.00it/s] 48%|████▊     | 53816/112584 [00:09<00:09, 6225.05it/s] 48%|████▊     | 54442/112584 [00:09<00:10, 5814.11it/s] 49%|████▉     | 55030/112584 [00:09<00:09, 5777.40it/s] 49%|████▉     | 55725/112584 [00:09<00:09, 6098.92it/s] 50%|█████     | 56340/112584 [00:09<00:09, 5979.55it/s] 51%|█████     | 56942/112584 [00:09<00:09, 5652.99it/s] 51%|█████     | 57513/112584 [00:09<00:09, 5571.57it/s] 52%|█████▏    | 58124/112584 [00:09<00:09, 5716.23it/s] 52%|█████▏    | 58855/112584 [00:09<00:08, 6167.39it/s] 53%|█████▎    | 59477/112584 [00:10<00:09, 5810.98it/s] 53%|█████▎    | 60065/112584 [00:10<00:09, 5795.35it/s] 54%|█████▍    | 60673/112584 [00:10<00:08, 5873.76it/s] 55%|█████▍    | 61435/112584 [00:10<00:08, 6375.72it/s] 55%|█████▌    | 62077/112584 [00:10<00:08, 6050.45it/s] 56%|█████▌    | 62689/112584 [00:10<00:08, 6024.81it/s] 56%|█████▌    | 63296/112584 [00:10<00:08, 5869.31it/s] 57%|█████▋    | 63931/112584 [00:10<00:08, 6005.44it/s] 57%|█████▋    | 64535/112584 [00:10<00:08, 5792.17it/s] 58%|█████▊    | 65125/112584 [00:11<00:08, 5814.36it/s] 58%|█████▊    | 65709/112584 [00:11<00:08, 5785.75it/s] 59%|█████▉    | 66310/112584 [00:11<00:07, 5849.63it/s] 59%|█████▉    | 66984/112584 [00:11<00:07, 6108.67it/s] 60%|██████    | 67597/112584 [00:11<00:07, 5777.62it/s] 61%|██████    | 68180/112584 [00:11<00:07, 5645.49it/s] 61%|██████    | 68922/112584 [00:11<00:07, 6143.93it/s] 62%|██████▏   | 69542/112584 [00:11<00:07, 6056.81it/s] 62%|██████▏   | 70168/112584 [00:11<00:06, 6115.26it/s] 63%|██████▎   | 70783/112584 [00:11<00:07, 5881.02it/s] 63%|██████▎   | 71388/112584 [00:12<00:06, 5928.81it/s] 64%|██████▍   | 72009/112584 [00:12<00:06, 6008.28it/s] 64%|██████▍   | 72612/112584 [00:12<00:06, 6008.75it/s] 65%|██████▌   | 73363/112584 [00:12<00:06, 6451.13it/s] 66%|██████▌   | 74161/112584 [00:12<00:05, 6903.69it/s] 66%|██████▋   | 74854/112584 [00:12<00:05, 6552.62it/s] 67%|██████▋   | 75515/112584 [00:12<00:05, 6248.93it/s] 68%|██████▊   | 76168/112584 [00:12<00:05, 6324.92it/s] 68%|██████▊   | 76805/112584 [00:12<00:05, 6223.99it/s] 69%|██████▉   | 77445/112584 [00:13<00:05, 6274.20it/s] 69%|██████▉   | 78075/112584 [00:13<00:05, 6160.65it/s] 70%|██████▉   | 78693/112584 [00:13<00:05, 5816.53it/s] 70%|███████   | 79279/112584 [00:13<00:06, 5408.09it/s] 71%|███████   | 79843/112584 [00:13<00:05, 5466.45it/s] 71%|███████▏  | 80426/112584 [00:13<00:05, 5565.62it/s] 72%|███████▏  | 81048/112584 [00:13<00:05, 5749.10it/s] 73%|███████▎  | 81678/112584 [00:13<00:05, 5902.62it/s] 73%|███████▎  | 82285/112584 [00:13<00:05, 5944.31it/s] 74%|███████▎  | 82894/112584 [00:13<00:04, 5981.50it/s] 74%|███████▍  | 83558/112584 [00:14<00:04, 6170.63it/s] 75%|███████▍  | 84177/112584 [00:14<00:04, 6011.26it/s] 75%|███████▌  | 84839/112584 [00:14<00:04, 6184.40it/s] 76%|███████▌  | 85460/112584 [00:14<00:04, 5858.92it/s] 76%|███████▋  | 86067/112584 [00:14<00:04, 5918.61it/s] 77%|███████▋  | 86679/112584 [00:14<00:04, 5976.68it/s] 78%|███████▊  | 87354/112584 [00:14<00:04, 6198.70it/s] 78%|███████▊  | 87977/112584 [00:14<00:03, 6151.80it/s] 79%|███████▊  | 88594/112584 [00:14<00:04, 5811.38it/s] 79%|███████▉  | 89180/112584 [00:15<00:04, 5730.74it/s] 80%|███████▉  | 89790/112584 [00:15<00:03, 5835.37it/s] 80%|████████  | 90377/112584 [00:15<00:03, 5618.26it/s] 81%|████████  | 90942/112584 [00:15<00:03, 5466.81it/s] 81%|████████▏ | 91621/112584 [00:15<00:03, 5832.32it/s] 82%|████████▏ | 92209/112584 [00:15<00:03, 5836.90it/s] 82%|████████▏ | 92857/112584 [00:15<00:03, 6017.70it/s] 83%|████████▎ | 93462/112584 [00:15<00:03, 5828.81it/s] 84%|████████▎ | 94048/112584 [00:15<00:03, 5737.02it/s] 84%|████████▍ | 94737/112584 [00:15<00:02, 6064.24it/s] 85%|████████▍ | 95347/112584 [00:16<00:02, 5939.73it/s] 85%|████████▌ | 95944/112584 [00:16<00:02, 5899.34it/s] 86%|████████▌ | 96771/112584 [00:16<00:02, 6587.74it/s] 87%|████████▋ | 97433/112584 [00:16<00:02, 6401.54it/s] 87%|████████▋ | 98077/112584 [00:16<00:02, 6138.41it/s] 88%|████████▊ | 98695/112584 [00:16<00:02, 5875.94it/s] 88%|████████▊ | 99291/112584 [00:16<00:02, 5898.45it/s] 89%|████████▊ | 99884/112584 [00:16<00:02, 5655.91it/s] 89%|████████▉ | 100453/112584 [00:16<00:02, 5512.31it/s] 90%|████████▉ | 101100/112584 [00:17<00:01, 5776.69it/s] 90%|█████████ | 101694/112584 [00:17<00:01, 5820.57it/s] 91%|█████████ | 102327/112584 [00:17<00:01, 5964.40it/s] 91%|█████████▏| 102926/112584 [00:17<00:01, 5912.71it/s] 92%|█████████▏| 103519/112584 [00:17<00:01, 5756.23it/s] 92%|█████████▏| 104097/112584 [00:17<00:01, 5547.88it/s] 93%|█████████▎| 104757/112584 [00:17<00:01, 5840.70it/s] 94%|█████████▎| 105345/112584 [00:17<00:01, 5691.92it/s] 94%|█████████▍| 105991/112584 [00:17<00:01, 5908.64it/s] 95%|█████████▍| 106585/112584 [00:17<00:01, 5820.16it/s] 95%|█████████▌| 107170/112584 [00:18<00:00, 5654.38it/s] 96%|█████████▌| 107783/112584 [00:18<00:00, 5781.78it/s] 96%|█████████▋| 108364/112584 [00:18<00:00, 5763.16it/s] 97%|█████████▋| 108942/112584 [00:18<00:00, 5500.91it/s] 97%|█████████▋| 109532/112584 [00:18<00:00, 5613.08it/s] 98%|█████████▊| 110101/112584 [00:18<00:00, 5630.40it/s] 98%|█████████▊| 110779/112584 [00:18<00:00, 5963.11it/s] 99%|█████████▉| 111422/112584 [00:18<00:00, 6098.03it/s]100%|█████████▉| 112034/112584 [00:18<00:00, 6027.10it/s]100%|██████████| 112584/112584 [00:19<00:00, 5920.68it/s]

gathering stats for n=1
  0%|          | 0/112584 [00:00<?, ?it/s]  2%|▏         | 1828/112584 [00:00<00:06, 18270.56it/s]  3%|▎         | 3775/112584 [00:00<00:05, 18963.45it/s]  5%|▌         | 5960/112584 [00:00<00:05, 20275.29it/s]  7%|▋         | 7988/112584 [00:00<00:05, 19297.10it/s]  9%|▉         | 9968/112584 [00:00<00:05, 19458.35it/s] 11%|█         | 11919/112584 [00:00<00:05, 19388.97it/s] 12%|█▏        | 13946/112584 [00:00<00:05, 19666.26it/s] 14%|█▍        | 15916/112584 [00:00<00:04, 19499.29it/s] 16%|█▌        | 17868/112584 [00:00<00:04, 19483.37it/s] 18%|█▊        | 19921/112584 [00:01<00:04, 19797.70it/s] 19%|█▉        | 21902/112584 [00:01<00:04, 19473.89it/s] 21%|██▏       | 24037/112584 [00:01<00:04, 20023.34it/s] 23%|██▎       | 26093/112584 [00:01<00:04, 20180.16it/s] 25%|██▍       | 28113/112584 [00:01<00:04, 19544.82it/s] 27%|██▋       | 30125/112584 [00:01<00:04, 19711.36it/s] 29%|██▊       | 32101/112584 [00:01<00:04, 19156.90it/s] 30%|███       | 34022/112584 [00:01<00:04, 19109.80it/s] 32%|███▏      | 35973/112584 [00:01<00:03, 19225.73it/s] 34%|███▎      | 37899/112584 [00:01<00:03, 19014.90it/s] 35%|███▌      | 39829/112584 [00:02<00:03, 19093.53it/s] 37%|███▋      | 41751/112584 [00:02<00:03, 19128.48it/s] 39%|███▉      | 43666/112584 [00:02<00:03, 19007.82it/s] 41%|████      | 45642/112584 [00:02<00:03, 19230.48it/s] 43%|████▎     | 48007/112584 [00:02<00:03, 20539.40it/s] 45%|████▍     | 50104/112584 [00:02<00:03, 20662.95it/s] 46%|████▋     | 52172/112584 [00:02<00:02, 20372.41it/s] 48%|████▊     | 54211/112584 [00:02<00:02, 20260.34it/s] 50%|████▉     | 56239/112584 [00:02<00:02, 20166.21it/s] 52%|█████▏    | 58257/112584 [00:02<00:02, 19667.97it/s] 53%|█████▎    | 60227/112584 [00:03<00:02, 19668.73it/s] 55%|█████▌    | 62296/112584 [00:03<00:02, 19968.89it/s] 57%|█████▋    | 64295/112584 [00:03<00:02, 19828.26it/s] 59%|█████▉    | 66280/112584 [00:03<00:02, 19739.95it/s] 61%|██████    | 68255/112584 [00:03<00:02, 19513.02it/s] 63%|██████▎   | 70412/112584 [00:03<00:02, 20117.27it/s] 64%|██████▍   | 72426/112584 [00:03<00:02, 19843.56it/s] 66%|██████▋   | 74754/112584 [00:03<00:01, 20854.16it/s] 68%|██████▊   | 76843/112584 [00:03<00:01, 20632.42it/s] 70%|███████   | 78909/112584 [00:03<00:01, 19952.75it/s] 72%|███████▏  | 80910/112584 [00:04<00:01, 19607.99it/s] 74%|███████▎  | 82922/112584 [00:04<00:01, 19751.42it/s] 75%|███████▌  | 84941/112584 [00:04<00:01, 19865.41it/s] 77%|███████▋  | 86956/112584 [00:04<00:01, 19948.37it/s] 79%|███████▉  | 88953/112584 [00:04<00:01, 19657.40it/s] 81%|████████  | 90921/112584 [00:04<00:01, 19271.04it/s] 83%|████████▎ | 92996/112584 [00:04<00:00, 19701.93it/s] 84%|████████▍ | 95005/112584 [00:04<00:00, 19813.58it/s] 86%|████████▋ | 97150/112584 [00:04<00:00, 20295.11it/s] 88%|████████▊ | 99182/112584 [00:05<00:00, 19919.50it/s] 90%|████████▉ | 101177/112584 [00:05<00:00, 19583.56it/s] 92%|█████████▏| 103176/112584 [00:05<00:00, 19700.23it/s] 93%|█████████▎| 105149/112584 [00:05<00:00, 19432.69it/s] 95%|█████████▌| 107100/112584 [00:05<00:00, 19451.55it/s] 97%|█████████▋| 109047/112584 [00:05<00:00, 19215.65it/s] 99%|█████████▊| 111127/112584 [00:05<00:00, 19680.23it/s]100%|██████████| 112584/112584 [00:05<00:00, 19706.46it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 600.99it/s]2022-03-14 16:39:43 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-14 16:39:43 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-14 16:39:43 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-14 16:39:43 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-14 16:39:43 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-14 16:39:43 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 16:39:43 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-14 16:39:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 16:39:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:39:44 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-14 16:39:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:39:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 16:39:44 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-14 16:39:44 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:44 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 16:39:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 16:39:44 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-14 16:39:44 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 16:39:44 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-14 16:39:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 16:39:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 16:39:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:39:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 16:40:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-14 16:42:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:42:35 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.913 | ppl 7713.39 | wps 66366.1 | wpb 2040.3 | bsz 4 | num_updates 98
2022-03-14 16:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 98 updates
2022-03-14 16:42:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:42:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:42:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 1 @ 98 updates, score 12.913) (writing took 1.8529357463121414 seconds)
2022-03-14 16:42:36 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 16:42:36 | INFO | train | epoch 001 | loss 14.274 | ppl 19804.5 | wps 39679 | ups 0.61 | wpb 65306.1 | bsz 127.6 | num_updates 98 | lr 1.23476e-05 | gnorm 3.057 | loss_scale 4 | train_wall 162 | gb_free 20.8 | wall 173
KL Stats: Epoch 1 Divergences: Uniform: 0.5688806548194001 Unigram: 2.500715359312158
2022-03-14 16:42:36 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 16:42:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:42:40 | INFO | train_inner | epoch 002:      2 / 103 loss=14.248, ppl=19452.4, wps=39693.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=3.023, loss_scale=4, train_wall=165, gb_free=20.8, wall=176
2022-03-14 16:45:18 | INFO | train_inner | epoch 002:    102 / 103 loss=12.345, ppl=5201.98, wps=41474.9, ups=0.63, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.148, loss_scale=4, train_wall=153, gb_free=20.8, wall=334
2022-03-14 16:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:45:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.563 | ppl 3024.93 | wps 66516.5 | wpb 2040.3 | bsz 4 | num_updates 201 | best_loss 11.563
2022-03-14 16:45:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 201 updates
2022-03-14 16:45:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:45:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:45:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 2 @ 201 updates, score 11.563) (writing took 1.9571570977568626 seconds)
2022-03-14 16:45:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 16:45:24 | INFO | train | epoch 002 | loss 12.353 | ppl 5230.28 | wps 40092.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 201 | lr 2.522e-05 | gnorm 1.15 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 341
KL Stats: Epoch 2 Divergences: Uniform: 0.5521545777210377 Unigram: 1.1893481525878513
2022-03-14 16:45:24 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 16:45:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:48:01 | INFO | train_inner | epoch 003:     99 / 103 loss=11.081, ppl=2166.22, wps=40033.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.681, loss_scale=4, train_wall=153, gb_free=20.8, wall=497
2022-03-14 16:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:48:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.582 | ppl 1533.22 | wps 66568.2 | wpb 2040.3 | bsz 4 | num_updates 304 | best_loss 10.582
2022-03-14 16:48:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 304 updates
2022-03-14 16:48:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 3 @ 304 updates, score 10.582) (writing took 2.1445466922596097 seconds)
2022-03-14 16:48:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 16:48:12 | INFO | train | epoch 003 | loss 11.062 | ppl 2137.78 | wps 40027.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 304 | lr 3.80924e-05 | gnorm 0.671 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 509
KL Stats: Epoch 3 Divergences: Uniform: 0.7908058668419297 Unigram: 0.53995903420422
2022-03-14 16:48:12 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 16:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:50:44 | INFO | train_inner | epoch 004:     96 / 103 loss=10.422, ppl=1372.18, wps=40001.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.419, loss_scale=4, train_wall=153, gb_free=20.8, wall=660
2022-03-14 16:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:50:58 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.213 | ppl 1186.73 | wps 66481.2 | wpb 2040.3 | bsz 4 | num_updates 407 | best_loss 10.213
2022-03-14 16:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 407 updates
2022-03-14 16:50:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:50:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 4 @ 407 updates, score 10.213) (writing took 2.0448490334674716 seconds)
2022-03-14 16:51:00 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 16:51:00 | INFO | train | epoch 004 | loss 10.403 | ppl 1353.73 | wps 40064.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 407 | lr 5.09648e-05 | gnorm 0.415 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 677
KL Stats: Epoch 4 Divergences: Uniform: 1.2727416497637745 Unigram: 0.36665283038625823
2022-03-14 16:51:00 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 16:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:53:27 | INFO | train_inner | epoch 005:     93 / 103 loss=10.115, ppl=1109.31, wps=40032.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.463, loss_scale=4, train_wall=153, gb_free=20.8, wall=824
2022-03-14 16:53:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:53:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.924 | ppl 971.2 | wps 66950.9 | wpb 2040.3 | bsz 4 | num_updates 510 | best_loss 9.924
2022-03-14 16:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 510 updates
2022-03-14 16:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:53:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 5 @ 510 updates, score 9.924) (writing took 2.1119989175349474 seconds)
2022-03-14 16:53:48 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 16:53:48 | INFO | train | epoch 005 | loss 10.091 | ppl 1090.42 | wps 40060.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 510 | lr 6.38373e-05 | gnorm 0.463 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 845
KL Stats: Epoch 5 Divergences: Uniform: 1.5725798221404346 Unigram: 0.49737084631798856
2022-03-14 16:53:48 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 16:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:56:10 | INFO | train_inner | epoch 006:     90 / 103 loss=9.841, ppl=917.21, wps=40006.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.513, loss_scale=8, train_wall=153, gb_free=20.8, wall=987
2022-03-14 16:56:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:56:34 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.652 | ppl 804.78 | wps 66785.6 | wpb 2040.3 | bsz 4 | num_updates 613 | best_loss 9.652
2022-03-14 16:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 613 updates
2022-03-14 16:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:56:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 6 @ 613 updates, score 9.652) (writing took 2.0207831785082817 seconds)
2022-03-14 16:56:36 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 16:56:36 | INFO | train | epoch 006 | loss 9.815 | ppl 900.78 | wps 40067.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 613 | lr 7.67097e-05 | gnorm 0.523 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1012
KL Stats: Epoch 6 Divergences: Uniform: 1.7210620619523784 Unigram: 0.6631768828851855
2022-03-14 16:56:36 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 16:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:58:54 | INFO | train_inner | epoch 007:     87 / 103 loss=9.581, ppl=765.78, wps=40042.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.609, loss_scale=8, train_wall=153, gb_free=20.8, wall=1150
2022-03-14 16:59:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:59:22 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.395 | ppl 673.4 | wps 66759.2 | wpb 2040.3 | bsz 4 | num_updates 716 | best_loss 9.395
2022-03-14 16:59:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 716 updates
2022-03-14 16:59:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:59:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 16:59:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 7 @ 716 updates, score 9.395) (writing took 2.0519261052832007 seconds)
2022-03-14 16:59:24 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 16:59:24 | INFO | train | epoch 007 | loss 9.545 | ppl 747.25 | wps 40076.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 716 | lr 8.95821e-05 | gnorm 0.639 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1180
KL Stats: Epoch 7 Divergences: Uniform: 1.8788267228216666 Unigram: 0.8172836580448354
2022-03-14 16:59:24 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 16:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:01:37 | INFO | train_inner | epoch 008:     84 / 103 loss=9.326, ppl=642.01, wps=40006.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.736, loss_scale=8, train_wall=153, gb_free=20.8, wall=1313
2022-03-14 17:02:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:02:10 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.152 | ppl 569.02 | wps 66948.7 | wpb 2040.3 | bsz 4 | num_updates 819 | best_loss 9.152
2022-03-14 17:02:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 819 updates
2022-03-14 17:02:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:02:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 8 @ 819 updates, score 9.152) (writing took 2.0309540620073676 seconds)
2022-03-14 17:02:12 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 17:02:12 | INFO | train | epoch 008 | loss 9.286 | ppl 624.2 | wps 40050.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 819 | lr 0.000102455 | gnorm 0.742 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1348
KL Stats: Epoch 8 Divergences: Uniform: 2.064263413679341 Unigram: 0.9646564496444753
2022-03-14 17:02:12 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 17:02:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:04:20 | INFO | train_inner | epoch 009:     81 / 103 loss=9.104, ppl=550.13, wps=40022.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.725, loss_scale=8, train_wall=153, gb_free=20.8, wall=1476
2022-03-14 17:04:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:04:58 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.956 | ppl 496.75 | wps 66640.4 | wpb 2040.3 | bsz 4 | num_updates 922 | best_loss 8.956
2022-03-14 17:04:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 922 updates
2022-03-14 17:04:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:05:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 9 @ 922 updates, score 8.956) (writing took 2.0469410941004753 seconds)
2022-03-14 17:05:00 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 17:05:00 | INFO | train | epoch 009 | loss 9.06 | ppl 533.76 | wps 40056.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 922 | lr 0.000115327 | gnorm 0.744 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1516
KL Stats: Epoch 9 Divergences: Uniform: 2.217079629754266 Unigram: 1.0961150713026546
2022-03-14 17:05:00 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 17:05:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:07:03 | INFO | train_inner | epoch 010:     78 / 103 loss=8.904, ppl=478.92, wps=40012.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.752, loss_scale=8, train_wall=153, gb_free=20.8, wall=1640
2022-03-14 17:07:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:07:46 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.784 | ppl 440.65 | wps 66592.3 | wpb 2040.3 | bsz 4 | num_updates 1025 | best_loss 8.784
2022-03-14 17:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1025 updates
2022-03-14 17:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:07:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 10 @ 1025 updates, score 8.784) (writing took 2.01776803471148 seconds)
2022-03-14 17:07:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 17:07:48 | INFO | train | epoch 010 | loss 8.865 | ppl 466.13 | wps 40061.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1025 | lr 0.000128199 | gnorm 0.742 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1684
KL Stats: Epoch 10 Divergences: Uniform: 2.352676327941434 Unigram: 1.2101795725105176
2022-03-14 17:07:48 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 17:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:09:46 | INFO | train_inner | epoch 011:     75 / 103 loss=8.731, ppl=424.95, wps=40027.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.802, loss_scale=16, train_wall=153, gb_free=20.8, wall=1803
2022-03-14 17:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:10:34 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.634 | ppl 397.35 | wps 66788.6 | wpb 2040.3 | bsz 4 | num_updates 1128 | best_loss 8.634
2022-03-14 17:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1128 updates
2022-03-14 17:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:10:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:10:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 11 @ 1128 updates, score 8.634) (writing took 2.0238766223192215 seconds)
2022-03-14 17:10:36 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 17:10:36 | INFO | train | epoch 011 | loss 8.692 | ppl 413.44 | wps 40059.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1128 | lr 0.000141072 | gnorm 0.789 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1852
KL Stats: Epoch 11 Divergences: Uniform: 2.4829400874885317 Unigram: 1.3072834614665687
2022-03-14 17:10:36 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 17:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:12:30 | INFO | train_inner | epoch 012:     72 / 103 loss=8.581, ppl=382.82, wps=39994.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.78, loss_scale=16, train_wall=153, gb_free=20.8, wall=1966
2022-03-14 17:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:13:22 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.499 | ppl 361.87 | wps 66591.4 | wpb 2040.3 | bsz 4 | num_updates 1231 | best_loss 8.499
2022-03-14 17:13:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1231 updates
2022-03-14 17:13:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:13:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:13:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 12 @ 1231 updates, score 8.499) (writing took 2.0503236707299948 seconds)
2022-03-14 17:13:24 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 17:13:24 | INFO | train | epoch 012 | loss 8.532 | ppl 370.2 | wps 40040.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1231 | lr 0.000153944 | gnorm 0.8 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 2020
KL Stats: Epoch 12 Divergences: Uniform: 2.6085504530457375 Unigram: 1.3934855867282745
2022-03-14 17:13:24 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 17:13:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:15:13 | INFO | train_inner | epoch 013:     69 / 103 loss=8.424, ppl=343.41, wps=40009.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.809, loss_scale=16, train_wall=153, gb_free=20.8, wall=2129
2022-03-14 17:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:16:10 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.374 | ppl 331.7 | wps 66573.1 | wpb 2040.3 | bsz 4 | num_updates 1334 | best_loss 8.374
2022-03-14 17:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1334 updates
2022-03-14 17:16:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:16:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:16:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 13 @ 1334 updates, score 8.374) (writing took 2.008791757747531 seconds)
2022-03-14 17:16:12 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 17:16:12 | INFO | train | epoch 013 | loss 8.381 | ppl 333.33 | wps 40042.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1334 | lr 0.000166817 | gnorm 0.819 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 2188
KL Stats: Epoch 13 Divergences: Uniform: 2.73199102970641 Unigram: 1.4737078004832125
2022-03-14 17:16:12 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 17:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:17:56 | INFO | train_inner | epoch 014:     66 / 103 loss=8.282, ppl=311.23, wps=40019.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.824, loss_scale=16, train_wall=153, gb_free=20.8, wall=2292
2022-03-14 17:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:18:57 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.273 | ppl 309.29 | wps 66771.8 | wpb 2040.3 | bsz 4 | num_updates 1437 | best_loss 8.273
2022-03-14 17:18:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1437 updates
2022-03-14 17:18:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:18:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:19:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 14 @ 1437 updates, score 8.273) (writing took 2.2007080167531967 seconds)
2022-03-14 17:19:00 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 17:19:00 | INFO | train | epoch 014 | loss 8.233 | ppl 300.97 | wps 40030.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1437 | lr 0.000179689 | gnorm 0.839 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 2356
KL Stats: Epoch 14 Divergences: Uniform: 2.8527226237963124 Unigram: 1.5500197704507395
2022-03-14 17:19:00 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 17:19:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:20:39 | INFO | train_inner | epoch 015:     63 / 103 loss=8.143, ppl=282.61, wps=39981.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.858, loss_scale=16, train_wall=153, gb_free=20.8, wall=2456
2022-03-14 17:21:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:21:46 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.147 | ppl 283.56 | wps 66860.3 | wpb 2040.3 | bsz 4 | num_updates 1540 | best_loss 8.147
2022-03-14 17:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1540 updates
2022-03-14 17:21:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:21:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 15 @ 1540 updates, score 8.147) (writing took 2.098056750372052 seconds)
2022-03-14 17:21:48 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 17:21:48 | INFO | train | epoch 015 | loss 8.088 | ppl 272.01 | wps 40049.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1540 | lr 0.000192562 | gnorm 0.839 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2524
KL Stats: Epoch 15 Divergences: Uniform: 2.9658950927723153 Unigram: 1.6204355435232856
2022-03-14 17:21:48 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 17:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:23:23 | INFO | train_inner | epoch 016:     60 / 103 loss=8, ppl=255.94, wps=40017.5, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.83, loss_scale=32, train_wall=153, gb_free=20.8, wall=2619
2022-03-14 17:24:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:24:34 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.037 | ppl 262.72 | wps 66597 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 8.037
2022-03-14 17:24:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-14 17:24:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:24:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:24:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 16 @ 1643 updates, score 8.037) (writing took 2.1035812264308333 seconds)
2022-03-14 17:24:36 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 17:24:36 | INFO | train | epoch 016 | loss 7.942 | ppl 245.94 | wps 40050.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.841 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2692
KL Stats: Epoch 16 Divergences: Uniform: 3.0798157368919874 Unigram: 1.6859369388087877
2022-03-14 17:24:36 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 17:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:26:06 | INFO | train_inner | epoch 017:     57 / 103 loss=7.86, ppl=232.27, wps=39999.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.847, loss_scale=32, train_wall=153, gb_free=20.8, wall=2782
2022-03-14 17:27:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:27:21 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.938 | ppl 245.24 | wps 66589.3 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 7.938
2022-03-14 17:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-14 17:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:27:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 17 @ 1746 updates, score 7.938) (writing took 2.0655257692560554 seconds)
2022-03-14 17:27:24 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 17:27:24 | INFO | train | epoch 017 | loss 7.798 | ppl 222.58 | wps 40052.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.865 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2860
KL Stats: Epoch 17 Divergences: Uniform: 3.1969357357607384 Unigram: 1.7509160480239716
2022-03-14 17:27:24 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 17:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:28:49 | INFO | train_inner | epoch 018:     54 / 103 loss=7.72, ppl=210.84, wps=40010.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.876, loss_scale=32, train_wall=153, gb_free=20.8, wall=2945
2022-03-14 17:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:30:09 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.845 | ppl 229.91 | wps 66589.7 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 7.845
2022-03-14 17:30:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-14 17:30:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:30:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 18 @ 1849 updates, score 7.845) (writing took 2.0533136390149593 seconds)
2022-03-14 17:30:12 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 17:30:12 | INFO | train | epoch 018 | loss 7.658 | ppl 201.97 | wps 40052.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.87 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3028
KL Stats: Epoch 18 Divergences: Uniform: 3.308649243112433 Unigram: 1.8119555040859658
2022-03-14 17:30:12 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 17:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:31:32 | INFO | train_inner | epoch 019:     51 / 103 loss=7.588, ppl=192.35, wps=40020.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.867, loss_scale=32, train_wall=153, gb_free=20.8, wall=3109
2022-03-14 17:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:32:57 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.75 | ppl 215.2 | wps 66596.1 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 7.75
2022-03-14 17:32:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-14 17:32:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:32:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 19 @ 1952 updates, score 7.75) (writing took 2.0461144987493753 seconds)
2022-03-14 17:32:59 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 17:32:59 | INFO | train | epoch 019 | loss 7.521 | ppl 183.62 | wps 40060.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.857 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3196
KL Stats: Epoch 19 Divergences: Uniform: 3.4234794898697802 Unigram: 1.8707911139948046
2022-03-14 17:32:59 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 17:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:34:15 | INFO | train_inner | epoch 020:     48 / 103 loss=7.46, ppl=176.02, wps=40018.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.854, loss_scale=32, train_wall=153, gb_free=20.8, wall=3272
2022-03-14 17:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:35:45 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.674 | ppl 204.27 | wps 66576.4 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 7.674
2022-03-14 17:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-14 17:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:35:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 20 @ 2055 updates, score 7.674) (writing took 2.034372736699879 seconds)
2022-03-14 17:35:47 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 17:35:47 | INFO | train | epoch 020 | loss 7.388 | ppl 167.53 | wps 40060.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.836 | loss_scale 64 | train_wall 157 | gb_free 20.8 | wall 3364
KL Stats: Epoch 20 Divergences: Uniform: 3.5364885687258103 Unigram: 1.9263687927874629
2022-03-14 17:35:47 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 17:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:36:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:37:00 | INFO | train_inner | epoch 021:     46 / 103 loss=7.327, ppl=160.55, wps=39636, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.852, loss_scale=32, train_wall=154, gb_free=20.8, wall=3437
2022-03-14 17:38:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:38:33 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.607 | ppl 194.96 | wps 65182.6 | wpb 2040.3 | bsz 4 | num_updates 2157 | best_loss 7.607
2022-03-14 17:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2157 updates
2022-03-14 17:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 21 @ 2157 updates, score 7.607) (writing took 2.082198889926076 seconds)
2022-03-14 17:38:35 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 17:38:35 | INFO | train | epoch 021 | loss 7.268 | ppl 154.11 | wps 39643.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2157 | lr 0.000269671 | gnorm 0.862 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3532
KL Stats: Epoch 21 Divergences: Uniform: 3.6533543145143623 Unigram: 1.980579215053602
2022-03-14 17:38:35 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 17:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:39:43 | INFO | train_inner | epoch 022:     43 / 103 loss=7.216, ppl=148.63, wps=39989.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.849, loss_scale=32, train_wall=153, gb_free=20.8, wall=3600
2022-03-14 17:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:41:21 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.543 | ppl 186.5 | wps 66180.7 | wpb 2040.3 | bsz 4 | num_updates 2260 | best_loss 7.543
2022-03-14 17:41:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2260 updates
2022-03-14 17:41:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:41:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 22 @ 2260 updates, score 7.543) (writing took 1.9727409249171615 seconds)
2022-03-14 17:41:23 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 17:41:23 | INFO | train | epoch 022 | loss 7.152 | ppl 142.25 | wps 40067 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2260 | lr 0.000282544 | gnorm 0.862 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3700
KL Stats: Epoch 22 Divergences: Uniform: 3.765096970628666 Unigram: 2.0299122839826307
2022-03-14 17:41:23 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 17:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:42:27 | INFO | train_inner | epoch 023:     40 / 103 loss=7.105, ppl=137.68, wps=40021.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.849, loss_scale=32, train_wall=153, gb_free=20.8, wall=3763
2022-03-14 17:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:44:09 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.477 | ppl 178.18 | wps 66761.5 | wpb 2040.3 | bsz 4 | num_updates 2363 | best_loss 7.477
2022-03-14 17:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2363 updates
2022-03-14 17:44:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:44:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 23 @ 2363 updates, score 7.477) (writing took 2.116373049095273 seconds)
2022-03-14 17:44:11 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 17:44:11 | INFO | train | epoch 023 | loss 7.043 | ppl 131.87 | wps 40034.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2363 | lr 0.000295416 | gnorm 0.848 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3868
KL Stats: Epoch 23 Divergences: Uniform: 3.873110474028452 Unigram: 2.0774902467913554
2022-03-14 17:44:11 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 17:44:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:45:10 | INFO | train_inner | epoch 024:     37 / 103 loss=7.004, ppl=128.36, wps=40006.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.866, loss_scale=32, train_wall=153, gb_free=20.8, wall=3926
2022-03-14 17:46:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:46:57 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.442 | ppl 173.94 | wps 66419 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.442
2022-03-14 17:46:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-14 17:46:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:46:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:46:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.442) (writing took 2.0056757871061563 seconds)
2022-03-14 17:46:59 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 17:46:59 | INFO | train | epoch 024 | loss 6.941 | ppl 122.83 | wps 40064.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.845 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4036
KL Stats: Epoch 24 Divergences: Uniform: 3.981660870043133 Unigram: 2.121290097511968
2022-03-14 17:46:59 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 17:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:47:53 | INFO | train_inner | epoch 025:     34 / 103 loss=6.901, ppl=119.51, wps=40008.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.851, loss_scale=32, train_wall=153, gb_free=20.8, wall=4090
2022-03-14 17:49:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:49:45 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.395 | ppl 168.31 | wps 66415.3 | wpb 2040.3 | bsz 4 | num_updates 2569 | best_loss 7.395
2022-03-14 17:49:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2569 updates
2022-03-14 17:49:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:49:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 25 @ 2569 updates, score 7.395) (writing took 2.3703517662361264 seconds)
2022-03-14 17:49:48 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 17:49:48 | INFO | train | epoch 025 | loss 6.842 | ppl 114.74 | wps 39968.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2569 | lr 0.000321161 | gnorm 0.828 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4204
KL Stats: Epoch 25 Divergences: Uniform: 4.079984309262062 Unigram: 2.1648852890578647
2022-03-14 17:49:48 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 17:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:50:37 | INFO | train_inner | epoch 026:     31 / 103 loss=6.82, ppl=113, wps=39936.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.824, loss_scale=32, train_wall=153, gb_free=20.8, wall=4253
2022-03-14 17:50:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:52:33 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.352 | ppl 163.37 | wps 66376.9 | wpb 2040.3 | bsz 4 | num_updates 2671 | best_loss 7.352
2022-03-14 17:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2671 updates
2022-03-14 17:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:52:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 26 @ 2671 updates, score 7.352) (writing took 2.1309055872261524 seconds)
2022-03-14 17:52:36 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 17:52:36 | INFO | train | epoch 026 | loss 6.749 | ppl 107.59 | wps 39640.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2671 | lr 0.000333908 | gnorm 0.835 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4372
KL Stats: Epoch 26 Divergences: Uniform: 4.179275456155298 Unigram: 2.205432633908192
2022-03-14 17:52:36 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 17:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:53:22 | INFO | train_inner | epoch 027:     29 / 103 loss=6.72, ppl=105.4, wps=39601.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.824, loss_scale=32, train_wall=154, gb_free=20.8, wall=4418
2022-03-14 17:55:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:55:21 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.327 | ppl 160.52 | wps 66703 | wpb 2040.3 | bsz 4 | num_updates 2774 | best_loss 7.327
2022-03-14 17:55:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2774 updates
2022-03-14 17:55:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:55:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 27 @ 2774 updates, score 7.327) (writing took 2.2713008588179946 seconds)
2022-03-14 17:55:24 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 17:55:24 | INFO | train | epoch 027 | loss 6.663 | ppl 101.33 | wps 40034 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2774 | lr 0.000346781 | gnorm 0.845 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4540
KL Stats: Epoch 27 Divergences: Uniform: 4.274891223395383 Unigram: 2.2448083356707884
2022-03-14 17:55:24 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 17:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:56:05 | INFO | train_inner | epoch 028:     26 / 103 loss=6.639, ppl=99.64, wps=39997.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.826, loss_scale=32, train_wall=153, gb_free=20.8, wall=4581
2022-03-14 17:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:58:09 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.285 | ppl 155.96 | wps 66602.9 | wpb 2040.3 | bsz 4 | num_updates 2877 | best_loss 7.285
2022-03-14 17:58:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2877 updates
2022-03-14 17:58:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:58:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 17:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 28 @ 2877 updates, score 7.285) (writing took 2.1096995677798986 seconds)
2022-03-14 17:58:12 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 17:58:12 | INFO | train | epoch 028 | loss 6.578 | ppl 95.51 | wps 40059.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2877 | lr 0.000359653 | gnorm 0.823 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4708
KL Stats: Epoch 28 Divergences: Uniform: 4.36415648171024 Unigram: 2.2831908757391113
2022-03-14 17:58:12 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 17:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:58:48 | INFO | train_inner | epoch 029:     23 / 103 loss=6.561, ppl=94.44, wps=40010.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.826, loss_scale=32, train_wall=153, gb_free=20.8, wall=4744
2022-03-14 17:58:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:00:57 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.271 | ppl 154.42 | wps 66855.8 | wpb 2040.3 | bsz 4 | num_updates 2979 | best_loss 7.271
2022-03-14 18:00:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2979 updates
2022-03-14 18:00:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 29 @ 2979 updates, score 7.271) (writing took 2.1995263546705246 seconds)
2022-03-14 18:01:00 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 18:01:00 | INFO | train | epoch 029 | loss 6.495 | ppl 90.22 | wps 39641.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2979 | lr 0.000372401 | gnorm 0.81 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4876
KL Stats: Epoch 29 Divergences: Uniform: 4.457258486002409 Unigram: 2.3224741702134137
2022-03-14 18:01:00 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 18:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:01:33 | INFO | train_inner | epoch 030:     21 / 103 loss=6.481, ppl=89.33, wps=39612.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.865, loss_scale=16, train_wall=154, gb_free=20.8, wall=4909
2022-03-14 18:03:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:03:45 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.246 | ppl 151.77 | wps 66114.4 | wpb 2040.3 | bsz 4 | num_updates 3082 | best_loss 7.246
2022-03-14 18:03:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3082 updates
2022-03-14 18:03:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:03:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:03:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 30 @ 3082 updates, score 7.246) (writing took 2.153601100668311 seconds)
2022-03-14 18:03:48 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 18:03:48 | INFO | train | epoch 030 | loss 6.42 | ppl 85.6 | wps 40048.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3082 | lr 0.000385273 | gnorm 0.847 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5044
KL Stats: Epoch 30 Divergences: Uniform: 4.540757361717547 Unigram: 2.3573573600022657
2022-03-14 18:03:48 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 18:03:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:04:16 | INFO | train_inner | epoch 031:     18 / 103 loss=6.404, ppl=84.66, wps=39992.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.813, loss_scale=16, train_wall=153, gb_free=20.8, wall=5073
2022-03-14 18:06:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:06:33 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.233 | ppl 150.42 | wps 66542.6 | wpb 2040.3 | bsz 4 | num_updates 3185 | best_loss 7.233
2022-03-14 18:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3185 updates
2022-03-14 18:06:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:06:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 31 @ 3185 updates, score 7.233) (writing took 2.087113847024739 seconds)
2022-03-14 18:06:36 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 18:06:36 | INFO | train | epoch 031 | loss 6.341 | ppl 81.04 | wps 40066.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3185 | lr 0.000398145 | gnorm 0.821 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5212
KL Stats: Epoch 31 Divergences: Uniform: 4.63185941156722 Unigram: 2.3939487885534434
2022-03-14 18:06:36 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 18:06:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:06:59 | INFO | train_inner | epoch 032:     15 / 103 loss=6.327, ppl=80.29, wps=40046.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.805, loss_scale=16, train_wall=153, gb_free=20.8, wall=5236
2022-03-14 18:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:09:21 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.224 | ppl 149.5 | wps 66697.6 | wpb 2040.3 | bsz 4 | num_updates 3288 | best_loss 7.224
2022-03-14 18:09:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3288 updates
2022-03-14 18:09:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:09:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 32 @ 3288 updates, score 7.224) (writing took 2.109536570496857 seconds)
2022-03-14 18:09:23 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 18:09:23 | INFO | train | epoch 032 | loss 6.268 | ppl 77.09 | wps 40080.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3288 | lr 0.000411018 | gnorm 0.832 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5380
KL Stats: Epoch 32 Divergences: Uniform: 4.713381590217121 Unigram: 2.431301779955702
2022-03-14 18:09:23 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 18:09:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:09:42 | INFO | train_inner | epoch 033:     12 / 103 loss=6.263, ppl=76.79, wps=40028.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.83, loss_scale=16, train_wall=153, gb_free=20.8, wall=5399
2022-03-14 18:12:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:12:09 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.225 | ppl 149.62 | wps 66782.3 | wpb 2040.3 | bsz 4 | num_updates 3391 | best_loss 7.224
2022-03-14 18:12:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3391 updates
2022-03-14 18:12:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:12:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 33 @ 3391 updates, score 7.225) (writing took 0.8627675585448742 seconds)
2022-03-14 18:12:10 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 18:12:10 | INFO | train | epoch 033 | loss 6.195 | ppl 73.26 | wps 40355.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3391 | lr 0.00042389 | gnorm 0.825 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5546
KL Stats: Epoch 33 Divergences: Uniform: 4.798147466700934 Unigram: 2.466954491935525
2022-03-14 18:12:10 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 18:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:12:24 | INFO | train_inner | epoch 034:      9 / 103 loss=6.188, ppl=72.92, wps=40325.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.84, loss_scale=16, train_wall=153, gb_free=20.8, wall=5561
2022-03-14 18:14:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:14:56 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.217 | ppl 148.75 | wps 66702.4 | wpb 2040.3 | bsz 4 | num_updates 3494 | best_loss 7.217
2022-03-14 18:14:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3494 updates
2022-03-14 18:14:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:14:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt
2022-03-14 18:14:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_best.pt (epoch 34 @ 3494 updates, score 7.217) (writing took 2.128889807499945 seconds)
2022-03-14 18:14:58 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 18:14:58 | INFO | train | epoch 034 | loss 6.125 | ppl 69.81 | wps 40046.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3494 | lr 0.000436763 | gnorm 0.833 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 5714
KL Stats: Epoch 34 Divergences: Uniform: 4.880982563205395 Unigram: 2.503543786486969
2022-03-14 18:14:58 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 18:14:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:15:08 | INFO | train_inner | epoch 035:      6 / 103 loss=6.124, ppl=69.77, wps=39997.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.823, loss_scale=32, train_wall=153, gb_free=20.8, wall=5724
2022-03-14 18:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:17:44 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.222 | ppl 149.26 | wps 66129.1 | wpb 2040.3 | bsz 4 | num_updates 3597 | best_loss 7.217
2022-03-14 18:17:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3597 updates
2022-03-14 18:17:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 35 @ 3597 updates, score 7.222) (writing took 0.9060324262827635 seconds)
2022-03-14 18:17:45 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 18:17:45 | INFO | train | epoch 035 | loss 6.057 | ppl 66.59 | wps 40325.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3597 | lr 0.000449635 | gnorm 0.834 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 5881
KL Stats: Epoch 35 Divergences: Uniform: 4.9592668281490635 Unigram: 2.5401243822940267
2022-03-14 18:17:45 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 18:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:17:50 | INFO | train_inner | epoch 036:      3 / 103 loss=6.056, ppl=66.51, wps=40296.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.842, loss_scale=32, train_wall=153, gb_free=20.8, wall=5886
2022-03-14 18:18:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:20:31 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.229 | ppl 149.99 | wps 66175 | wpb 2040.3 | bsz 4 | num_updates 3699 | best_loss 7.217
2022-03-14 18:20:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3699 updates
2022-03-14 18:20:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:20:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 36 @ 3699 updates, score 7.229) (writing took 1.0516989193856716 seconds)
2022-03-14 18:20:32 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 18:20:32 | INFO | train | epoch 036 | loss 5.99 | ppl 63.56 | wps 39919 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 3699 | lr 0.000462383 | gnorm 0.84 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6048
KL Stats: Epoch 36 Divergences: Uniform: 5.046597312907604 Unigram: 2.57785647021536
2022-03-14 18:20:32 | INFO | fairseq.trainer | begin training epoch 37
2022-03-14 18:20:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:20:33 | INFO | train_inner | epoch 037:      1 / 103 loss=5.991, ppl=63.58, wps=39891.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.839, loss_scale=16, train_wall=154, gb_free=20.8, wall=6050
2022-03-14 18:23:11 | INFO | train_inner | epoch 037:    101 / 103 loss=5.926, ppl=60.81, wps=41472.9, ups=0.63, wpb=65530.9, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.81, loss_scale=16, train_wall=153, gb_free=20.8, wall=6208
2022-03-14 18:23:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:23:18 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.232 | ppl 150.29 | wps 66151.8 | wpb 2040.3 | bsz 4 | num_updates 3802 | best_loss 7.217
2022-03-14 18:23:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3802 updates
2022-03-14 18:23:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:23:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 37 @ 3802 updates, score 7.232) (writing took 0.9732997268438339 seconds)
2022-03-14 18:23:19 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-14 18:23:19 | INFO | train | epoch 037 | loss 5.926 | ppl 60.78 | wps 40321.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3802 | lr 0.000475255 | gnorm 0.807 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6215
KL Stats: Epoch 37 Divergences: Uniform: 5.126248706426196 Unigram: 2.612317525240024
2022-03-14 18:23:19 | INFO | fairseq.trainer | begin training epoch 38
2022-03-14 18:23:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:25:54 | INFO | train_inner | epoch 038:     98 / 103 loss=5.871, ppl=58.51, wps=40273.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3900, lr=0.000487503, gnorm=0.866, loss_scale=16, train_wall=153, gb_free=20.8, wall=6370
2022-03-14 18:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:26:05 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.237 | ppl 150.85 | wps 66541.5 | wpb 2040.3 | bsz 4 | num_updates 3905 | best_loss 7.217
2022-03-14 18:26:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3905 updates
2022-03-14 18:26:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:26:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 38 @ 3905 updates, score 7.237) (writing took 0.9962200839072466 seconds)
2022-03-14 18:26:06 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-14 18:26:06 | INFO | train | epoch 038 | loss 5.871 | ppl 58.52 | wps 40301.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3905 | lr 0.000488127 | gnorm 0.864 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6382
KL Stats: Epoch 38 Divergences: Uniform: 5.210784174563824 Unigram: 2.646416255997226
2022-03-14 18:26:06 | INFO | fairseq.trainer | begin training epoch 39
2022-03-14 18:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:28:36 | INFO | train_inner | epoch 039:     95 / 103 loss=5.805, ppl=55.9, wps=40279, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.855, loss_scale=16, train_wall=153, gb_free=20.8, wall=6532
2022-03-14 18:28:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:28:51 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.263 | ppl 153.56 | wps 66248.1 | wpb 2040.3 | bsz 4 | num_updates 4008 | best_loss 7.217
2022-03-14 18:28:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4008 updates
2022-03-14 18:28:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 39 @ 4008 updates, score 7.263) (writing took 1.0116843432188034 seconds)
2022-03-14 18:28:52 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-14 18:28:52 | INFO | train | epoch 039 | loss 5.804 | ppl 55.88 | wps 40307.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4008 | lr 0.000499501 | gnorm 0.854 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6549
KL Stats: Epoch 39 Divergences: Uniform: 5.28805196663175 Unigram: 2.6849579356882054
2022-03-14 18:28:52 | INFO | fairseq.trainer | begin training epoch 40
2022-03-14 18:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:31:18 | INFO | train_inner | epoch 040:     92 / 103 loss=5.745, ppl=53.63, wps=40266.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.84, loss_scale=16, train_wall=153, gb_free=20.8, wall=6694
2022-03-14 18:31:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:31:38 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.267 | ppl 153.99 | wps 66871.7 | wpb 2040.3 | bsz 4 | num_updates 4111 | best_loss 7.217
2022-03-14 18:31:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4111 updates
2022-03-14 18:31:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:31:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:31:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 40 @ 4111 updates, score 7.267) (writing took 1.0016704369336367 seconds)
2022-03-14 18:31:39 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-14 18:31:39 | INFO | train | epoch 040 | loss 5.743 | ppl 53.55 | wps 40306.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4111 | lr 0.000493204 | gnorm 0.848 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6716
KL Stats: Epoch 40 Divergences: Uniform: 5.377065642575387 Unigram: 2.7195550767758965
2022-03-14 18:31:39 | INFO | fairseq.trainer | begin training epoch 41
2022-03-14 18:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:32:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:34:02 | INFO | train_inner | epoch 041:     90 / 103 loss=5.68, ppl=51.27, wps=39899, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.843, loss_scale=16, train_wall=154, gb_free=20.8, wall=6858
2022-03-14 18:34:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:34:25 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.272 | ppl 154.6 | wps 66515.8 | wpb 2040.3 | bsz 4 | num_updates 4213 | best_loss 7.217
2022-03-14 18:34:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4213 updates
2022-03-14 18:34:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 41 @ 4213 updates, score 7.272) (writing took 0.9613338094204664 seconds)
2022-03-14 18:34:26 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-14 18:34:26 | INFO | train | epoch 041 | loss 5.673 | ppl 51.02 | wps 39938.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4213 | lr 0.000487197 | gnorm 0.82 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6883
KL Stats: Epoch 41 Divergences: Uniform: 5.458571370115346 Unigram: 2.7571571884632284
2022-03-14 18:34:26 | INFO | fairseq.trainer | begin training epoch 42
2022-03-14 18:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:36:44 | INFO | train_inner | epoch 042:     87 / 103 loss=5.617, ppl=49.07, wps=40298.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.804, loss_scale=16, train_wall=153, gb_free=20.8, wall=7020
2022-03-14 18:37:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:37:12 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.297 | ppl 157.3 | wps 66402.1 | wpb 2040.3 | bsz 4 | num_updates 4316 | best_loss 7.217
2022-03-14 18:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4316 updates
2022-03-14 18:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:37:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 42 @ 4316 updates, score 7.297) (writing took 0.978152934461832 seconds)
2022-03-14 18:37:13 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-14 18:37:13 | INFO | train | epoch 042 | loss 5.612 | ppl 48.92 | wps 40323.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4316 | lr 0.000481348 | gnorm 0.83 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7049
KL Stats: Epoch 42 Divergences: Uniform: 5.542863778622547 Unigram: 2.796073389772371
2022-03-14 18:37:13 | INFO | fairseq.trainer | begin training epoch 43
2022-03-14 18:37:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:39:26 | INFO | train_inner | epoch 043:     84 / 103 loss=5.565, ppl=47.34, wps=40270.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.831, loss_scale=16, train_wall=153, gb_free=20.8, wall=7182
2022-03-14 18:39:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:39:59 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.305 | ppl 158.1 | wps 66793.9 | wpb 2040.3 | bsz 4 | num_updates 4419 | best_loss 7.217
2022-03-14 18:39:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4419 updates
2022-03-14 18:39:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:40:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 43 @ 4419 updates, score 7.305) (writing took 0.9874869287014008 seconds)
2022-03-14 18:40:00 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-14 18:40:00 | INFO | train | epoch 043 | loss 5.553 | ppl 46.95 | wps 40305.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4419 | lr 0.000475705 | gnorm 0.812 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7216
KL Stats: Epoch 43 Divergences: Uniform: 5.623815280174937 Unigram: 2.831498250158099
2022-03-14 18:40:00 | INFO | fairseq.trainer | begin training epoch 44
2022-03-14 18:40:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:42:08 | INFO | train_inner | epoch 044:     81 / 103 loss=5.5, ppl=45.27, wps=40286.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.8, loss_scale=16, train_wall=153, gb_free=20.8, wall=7344
2022-03-14 18:42:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:42:46 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.329 | ppl 160.8 | wps 66327.5 | wpb 2040.3 | bsz 4 | num_updates 4522 | best_loss 7.217
2022-03-14 18:42:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4522 updates
2022-03-14 18:42:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:42:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:42:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 44 @ 4522 updates, score 7.329) (writing took 0.9735293015837669 seconds)
2022-03-14 18:42:47 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-14 18:42:47 | INFO | train | epoch 044 | loss 5.496 | ppl 45.13 | wps 40323.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4522 | lr 0.000470256 | gnorm 0.824 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7383
KL Stats: Epoch 44 Divergences: Uniform: 5.708715350876051 Unigram: 2.871053159250061
2022-03-14 18:42:47 | INFO | fairseq.trainer | begin training epoch 45
2022-03-14 18:42:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:44:50 | INFO | train_inner | epoch 045:     78 / 103 loss=5.453, ppl=43.82, wps=40287.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.828, loss_scale=16, train_wall=153, gb_free=20.8, wall=7506
2022-03-14 18:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:45:33 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.362 | ppl 164.56 | wps 66284.9 | wpb 2040.3 | bsz 4 | num_updates 4625 | best_loss 7.217
2022-03-14 18:45:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4625 updates
2022-03-14 18:45:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:45:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 45 @ 4625 updates, score 7.362) (writing took 0.9771828018128872 seconds)
2022-03-14 18:45:34 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-14 18:45:34 | INFO | train | epoch 045 | loss 5.441 | ppl 43.43 | wps 40318.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4625 | lr 0.000464991 | gnorm 0.813 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7550
KL Stats: Epoch 45 Divergences: Uniform: 5.790824419297292 Unigram: 2.905186676637089
2022-03-14 18:45:34 | INFO | fairseq.trainer | begin training epoch 46
2022-03-14 18:45:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:46:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:47:34 | INFO | train_inner | epoch 046:     76 / 103 loss=5.397, ppl=42.14, wps=39890, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.801, loss_scale=16, train_wall=154, gb_free=20.8, wall=7670
2022-03-14 18:48:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:48:19 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.371 | ppl 165.55 | wps 66519.1 | wpb 2040.3 | bsz 4 | num_updates 4727 | best_loss 7.217
2022-03-14 18:48:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4727 updates
2022-03-14 18:48:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 46 @ 4727 updates, score 7.371) (writing took 1.060077209956944 seconds)
2022-03-14 18:48:20 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 18:48:20 | INFO | train | epoch 046 | loss 5.385 | ppl 41.77 | wps 39907.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4727 | lr 0.000459946 | gnorm 0.812 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7717
KL Stats: Epoch 46 Divergences: Uniform: 5.8714292752826065 Unigram: 2.942710192372756
2022-03-14 18:48:20 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 18:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:50:16 | INFO | train_inner | epoch 047:     73 / 103 loss=5.345, ppl=40.64, wps=40275.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.833, loss_scale=16, train_wall=153, gb_free=20.8, wall=7832
2022-03-14 18:51:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:51:06 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.401 | ppl 169.03 | wps 66311.2 | wpb 2040.3 | bsz 4 | num_updates 4830 | best_loss 7.217
2022-03-14 18:51:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4830 updates
2022-03-14 18:51:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 47 @ 4830 updates, score 7.401) (writing took 0.9965025102719665 seconds)
2022-03-14 18:51:07 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 18:51:07 | INFO | train | epoch 047 | loss 5.335 | ppl 40.35 | wps 40324.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4830 | lr 0.000455016 | gnorm 0.807 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7884
KL Stats: Epoch 47 Divergences: Uniform: 5.9460965165323785 Unigram: 2.9769468300480226
2022-03-14 18:51:07 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 18:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:52:58 | INFO | train_inner | epoch 048:     70 / 103 loss=5.301, ppl=39.42, wps=40291.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.813, loss_scale=16, train_wall=153, gb_free=20.8, wall=7994
2022-03-14 18:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:53:53 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.409 | ppl 169.99 | wps 66313.3 | wpb 2040.3 | bsz 4 | num_updates 4933 | best_loss 7.217
2022-03-14 18:53:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4933 updates
2022-03-14 18:53:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:53:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:53:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 48 @ 4933 updates, score 7.409) (writing took 1.030844614841044 seconds)
2022-03-14 18:53:54 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 18:53:54 | INFO | train | epoch 048 | loss 5.284 | ppl 38.97 | wps 40312.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4933 | lr 0.00045024 | gnorm 0.823 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8051
KL Stats: Epoch 48 Divergences: Uniform: 6.025623489750269 Unigram: 3.0130481938835274
2022-03-14 18:53:54 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 18:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:55:40 | INFO | train_inner | epoch 049:     67 / 103 loss=5.251, ppl=38.08, wps=40275.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.803, loss_scale=16, train_wall=153, gb_free=20.8, wall=8157
2022-03-14 18:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:56:40 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.442 | ppl 173.9 | wps 66154.3 | wpb 2040.3 | bsz 4 | num_updates 5036 | best_loss 7.217
2022-03-14 18:56:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5036 updates
2022-03-14 18:56:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:56:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:56:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 49 @ 5036 updates, score 7.442) (writing took 0.974894248880446 seconds)
2022-03-14 18:56:41 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 18:56:41 | INFO | train | epoch 049 | loss 5.239 | ppl 37.76 | wps 40311 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5036 | lr 0.000445612 | gnorm 0.804 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8217
KL Stats: Epoch 49 Divergences: Uniform: 6.102995838054448 Unigram: 3.045816733601252
2022-03-14 18:56:41 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 18:56:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:58:22 | INFO | train_inner | epoch 050:     64 / 103 loss=5.209, ppl=37, wps=40281.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.814, loss_scale=16, train_wall=153, gb_free=20.8, wall=8319
2022-03-14 18:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:59:27 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.481 | ppl 178.59 | wps 66185.6 | wpb 2040.3 | bsz 4 | num_updates 5139 | best_loss 7.217
2022-03-14 18:59:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5139 updates
2022-03-14 18:59:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 18:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 50 @ 5139 updates, score 7.481) (writing took 0.9746713954955339 seconds)
2022-03-14 18:59:28 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 18:59:28 | INFO | train | epoch 050 | loss 5.193 | ppl 36.59 | wps 40318.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5139 | lr 0.000441124 | gnorm 0.826 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8384
KL Stats: Epoch 50 Divergences: Uniform: 6.184236957484109 Unigram: 3.07989298044298
2022-03-14 18:59:28 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 18:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:00:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:01:06 | INFO | train_inner | epoch 051:     62 / 103 loss=5.162, ppl=35.8, wps=39899.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.82, loss_scale=16, train_wall=154, gb_free=20.8, wall=8482
2022-03-14 19:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:02:14 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.499 | ppl 180.91 | wps 66561.1 | wpb 2040.3 | bsz 4 | num_updates 5241 | best_loss 7.217
2022-03-14 19:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5241 updates
2022-03-14 19:02:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:02:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 51 @ 5241 updates, score 7.499) (writing took 0.9794578859582543 seconds)
2022-03-14 19:02:15 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 19:02:15 | INFO | train | epoch 051 | loss 5.147 | ppl 35.43 | wps 39942.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5241 | lr 0.00043681 | gnorm 0.81 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8551
KL Stats: Epoch 51 Divergences: Uniform: 6.258707772970814 Unigram: 3.1134049862787627
2022-03-14 19:02:15 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 19:02:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:03:48 | INFO | train_inner | epoch 052:     59 / 103 loss=5.125, ppl=34.89, wps=40293.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.812, loss_scale=16, train_wall=153, gb_free=20.8, wall=8644
2022-03-14 19:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:05:01 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.523 | ppl 183.92 | wps 66297.4 | wpb 2040.3 | bsz 4 | num_updates 5344 | best_loss 7.217
2022-03-14 19:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5344 updates
2022-03-14 19:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:05:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 52 @ 5344 updates, score 7.523) (writing took 0.9619581233710051 seconds)
2022-03-14 19:05:02 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 19:05:02 | INFO | train | epoch 052 | loss 5.108 | ppl 34.49 | wps 40323.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5344 | lr 0.00043258 | gnorm 0.822 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8718
KL Stats: Epoch 52 Divergences: Uniform: 6.332471373888796 Unigram: 3.1447818477612377
2022-03-14 19:05:02 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 19:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:06:30 | INFO | train_inner | epoch 053:     56 / 103 loss=5.082, ppl=33.88, wps=40288.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.822, loss_scale=16, train_wall=153, gb_free=20.8, wall=8806
2022-03-14 19:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:07:47 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.539 | ppl 186.04 | wps 66607.7 | wpb 2040.3 | bsz 4 | num_updates 5447 | best_loss 7.217
2022-03-14 19:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5447 updates
2022-03-14 19:07:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 53 @ 5447 updates, score 7.539) (writing took 1.0044507291167974 seconds)
2022-03-14 19:07:48 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 19:07:48 | INFO | train | epoch 053 | loss 5.068 | ppl 33.54 | wps 40315 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5447 | lr 0.000428471 | gnorm 0.823 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8885
KL Stats: Epoch 53 Divergences: Uniform: 6.399506093930479 Unigram: 3.1752727804573286
2022-03-14 19:07:48 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 19:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:09:12 | INFO | train_inner | epoch 054:     53 / 103 loss=5.047, ppl=33.05, wps=40285.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.82, loss_scale=16, train_wall=153, gb_free=20.8, wall=8969
2022-03-14 19:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:10:34 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.569 | ppl 189.95 | wps 66296.3 | wpb 2040.3 | bsz 4 | num_updates 5550 | best_loss 7.217
2022-03-14 19:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5550 updates
2022-03-14 19:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:10:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:10:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 54 @ 5550 updates, score 7.569) (writing took 1.0438725696876645 seconds)
2022-03-14 19:10:35 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 19:10:35 | INFO | train | epoch 054 | loss 5.028 | ppl 32.64 | wps 40300.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5550 | lr 0.000424476 | gnorm 0.824 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 9052
KL Stats: Epoch 54 Divergences: Uniform: 6.47387407617825 Unigram: 3.2056015044812467
2022-03-14 19:10:35 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 19:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:11:54 | INFO | train_inner | epoch 055:     50 / 103 loss=5.013, ppl=32.29, wps=40270.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.838, loss_scale=16, train_wall=153, gb_free=20.8, wall=9131
2022-03-14 19:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:13:21 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.589 | ppl 192.56 | wps 66646.9 | wpb 2040.3 | bsz 4 | num_updates 5653 | best_loss 7.217
2022-03-14 19:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5653 updates
2022-03-14 19:13:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:13:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 55 @ 5653 updates, score 7.589) (writing took 0.9685209263116121 seconds)
2022-03-14 19:13:22 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 19:13:22 | INFO | train | epoch 055 | loss 4.99 | ppl 31.79 | wps 40331.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5653 | lr 0.000420592 | gnorm 0.829 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 9219
KL Stats: Epoch 55 Divergences: Uniform: 6.543495760037645 Unigram: 3.2357359309896205
2022-03-14 19:13:22 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 19:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:14:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:14:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:14:40 | INFO | train_inner | epoch 056:     49 / 103 loss=4.968, ppl=31.3, wps=39527.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.831, loss_scale=8, train_wall=156, gb_free=20.8, wall=9296
2022-03-14 19:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:16:08 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.617 | ppl 196.26 | wps 66775.3 | wpb 2040.3 | bsz 4 | num_updates 5754 | best_loss 7.217
2022-03-14 19:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5754 updates
2022-03-14 19:16:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 56 @ 5754 updates, score 7.617) (writing took 0.9876907709985971 seconds)
2022-03-14 19:16:09 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 19:16:09 | INFO | train | epoch 056 | loss 4.951 | ppl 30.93 | wps 39549.8 | ups 0.61 | wpb 65307.9 | bsz 127.6 | num_updates 5754 | lr 0.000416884 | gnorm 0.821 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9385
KL Stats: Epoch 56 Divergences: Uniform: 6.607879153522072 Unigram: 3.265450048990309
2022-03-14 19:16:09 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 19:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:17:22 | INFO | train_inner | epoch 057:     46 / 103 loss=4.938, ppl=30.65, wps=40298, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.823, loss_scale=8, train_wall=153, gb_free=20.8, wall=9458
2022-03-14 19:18:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:18:55 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.638 | ppl 199.24 | wps 66441.9 | wpb 2040.3 | bsz 4 | num_updates 5857 | best_loss 7.217
2022-03-14 19:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5857 updates
2022-03-14 19:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 57 @ 5857 updates, score 7.638) (writing took 0.9761974709108472 seconds)
2022-03-14 19:18:56 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 19:18:56 | INFO | train | epoch 057 | loss 4.92 | ppl 30.26 | wps 40328.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5857 | lr 0.000413202 | gnorm 0.828 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9552
KL Stats: Epoch 57 Divergences: Uniform: 6.6741900982423585 Unigram: 3.2944159361491003
2022-03-14 19:18:56 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 19:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:20:04 | INFO | train_inner | epoch 058:     43 / 103 loss=4.905, ppl=29.97, wps=40298.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.831, loss_scale=8, train_wall=153, gb_free=20.8, wall=9620
2022-03-14 19:21:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:21:42 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.672 | ppl 203.98 | wps 66702.6 | wpb 2040.3 | bsz 4 | num_updates 5960 | best_loss 7.217
2022-03-14 19:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5960 updates
2022-03-14 19:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:21:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:21:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 58 @ 5960 updates, score 7.672) (writing took 0.9679370727390051 seconds)
2022-03-14 19:21:42 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 19:21:42 | INFO | train | epoch 058 | loss 4.886 | ppl 29.56 | wps 40331.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5960 | lr 0.000409616 | gnorm 0.836 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9719
KL Stats: Epoch 58 Divergences: Uniform: 6.743178821267692 Unigram: 3.3224080636072526
2022-03-14 19:21:42 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 19:21:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:22:46 | INFO | train_inner | epoch 059:     40 / 103 loss=4.872, ppl=29.28, wps=40295.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.844, loss_scale=8, train_wall=153, gb_free=20.8, wall=9782
2022-03-14 19:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:24:28 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.696 | ppl 207.36 | wps 66349.7 | wpb 2040.3 | bsz 4 | num_updates 6063 | best_loss 7.217
2022-03-14 19:24:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6063 updates
2022-03-14 19:24:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:24:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:24:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 59 @ 6063 updates, score 7.696) (writing took 0.9928258312866092 seconds)
2022-03-14 19:24:29 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 19:24:29 | INFO | train | epoch 059 | loss 4.853 | ppl 28.9 | wps 40333.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6063 | lr 0.000406122 | gnorm 0.841 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9886
KL Stats: Epoch 59 Divergences: Uniform: 6.80696967455691 Unigram: 3.3493749850723136
2022-03-14 19:24:29 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 19:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:25:28 | INFO | train_inner | epoch 060:     37 / 103 loss=4.844, ppl=28.72, wps=40304.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.828, loss_scale=8, train_wall=153, gb_free=20.8, wall=9944
2022-03-14 19:27:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:27:15 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.711 | ppl 209.56 | wps 66371.4 | wpb 2040.3 | bsz 4 | num_updates 6166 | best_loss 7.217
2022-03-14 19:27:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6166 updates
2022-03-14 19:27:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:27:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:27:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 60 @ 6166 updates, score 7.711) (writing took 0.9915673118084669 seconds)
2022-03-14 19:27:16 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 19:27:16 | INFO | train | epoch 060 | loss 4.82 | ppl 28.25 | wps 40340.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6166 | lr 0.000402715 | gnorm 0.836 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10052
KL Stats: Epoch 60 Divergences: Uniform: 6.866288407561796 Unigram: 3.3732713651639568
2022-03-14 19:27:16 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 19:27:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:28:10 | INFO | train_inner | epoch 061:     34 / 103 loss=4.811, ppl=28.07, wps=40311.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6200, lr=0.00040161, gnorm=0.835, loss_scale=8, train_wall=153, gb_free=20.8, wall=10106
2022-03-14 19:28:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:29:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:30:02 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 7.736 | ppl 213.23 | wps 67016.1 | wpb 2040.3 | bsz 4 | num_updates 6268 | best_loss 7.217
2022-03-14 19:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6268 updates
2022-03-14 19:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:30:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 61 @ 6268 updates, score 7.736) (writing took 0.9790322193875909 seconds)
2022-03-14 19:30:03 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 19:30:03 | INFO | train | epoch 061 | loss 4.789 | ppl 27.66 | wps 39975.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6268 | lr 0.000399425 | gnorm 0.846 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10219
KL Stats: Epoch 61 Divergences: Uniform: 6.929560011386346 Unigram: 3.4005311074349844
2022-03-14 19:30:03 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 19:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:30:53 | INFO | train_inner | epoch 062:     32 / 103 loss=4.775, ppl=27.38, wps=39943.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6300, lr=0.00039841, gnorm=0.836, loss_scale=8, train_wall=154, gb_free=20.8, wall=10270
2022-03-14 19:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:32:48 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 7.766 | ppl 217.65 | wps 66291.7 | wpb 2040.3 | bsz 4 | num_updates 6371 | best_loss 7.217
2022-03-14 19:32:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6371 updates
2022-03-14 19:32:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 62 @ 6371 updates, score 7.766) (writing took 1.0402970854192972 seconds)
2022-03-14 19:32:49 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 19:32:49 | INFO | train | epoch 062 | loss 4.76 | ppl 27.1 | wps 40338.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6371 | lr 0.000396183 | gnorm 0.836 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10386
KL Stats: Epoch 62 Divergences: Uniform: 6.98161900230259 Unigram: 3.425025299762531
2022-03-14 19:32:49 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 19:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:33:35 | INFO | train_inner | epoch 063:     29 / 103 loss=4.755, ppl=27, wps=40318.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=6400, lr=0.000395285, gnorm=0.851, loss_scale=8, train_wall=153, gb_free=20.8, wall=10432
2022-03-14 19:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:35:35 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 7.787 | ppl 220.83 | wps 66300.2 | wpb 2040.3 | bsz 4 | num_updates 6474 | best_loss 7.217
2022-03-14 19:35:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6474 updates
2022-03-14 19:35:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 63 @ 6474 updates, score 7.787) (writing took 1.0037323739379644 seconds)
2022-03-14 19:35:36 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 19:35:36 | INFO | train | epoch 063 | loss 4.733 | ppl 26.59 | wps 40374.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6474 | lr 0.000393019 | gnorm 0.842 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10552
KL Stats: Epoch 63 Divergences: Uniform: 7.045239866845263 Unigram: 3.4503810096900662
2022-03-14 19:35:36 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 19:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:36:17 | INFO | train_inner | epoch 064:     26 / 103 loss=4.728, ppl=26.51, wps=40336.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6500, lr=0.000392232, gnorm=0.842, loss_scale=8, train_wall=152, gb_free=20.8, wall=10594
2022-03-14 19:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:38:22 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 7.799 | ppl 222.73 | wps 66664 | wpb 2040.3 | bsz 4 | num_updates 6577 | best_loss 7.217
2022-03-14 19:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6577 updates
2022-03-14 19:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:38:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:38:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 64 @ 6577 updates, score 7.799) (writing took 0.9937400603666902 seconds)
2022-03-14 19:38:23 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 19:38:23 | INFO | train | epoch 064 | loss 4.704 | ppl 26.06 | wps 40385.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6577 | lr 0.000389929 | gnorm 0.833 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10719
KL Stats: Epoch 64 Divergences: Uniform: 7.10262814473036 Unigram: 3.4738492410118944
2022-03-14 19:38:23 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 19:38:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:38:59 | INFO | train_inner | epoch 065:     23 / 103 loss=4.7, ppl=25.99, wps=40341.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6600, lr=0.000389249, gnorm=0.832, loss_scale=8, train_wall=153, gb_free=20.8, wall=10755
2022-03-14 19:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:41:08 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 7.836 | ppl 228.46 | wps 66527.4 | wpb 2040.3 | bsz 4 | num_updates 6680 | best_loss 7.217
2022-03-14 19:41:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6680 updates
2022-03-14 19:41:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:41:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:41:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 65 @ 6680 updates, score 7.836) (writing took 1.098694364540279 seconds)
2022-03-14 19:41:09 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 19:41:09 | INFO | train | epoch 065 | loss 4.677 | ppl 25.59 | wps 40334.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6680 | lr 0.000386912 | gnorm 0.834 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10886
KL Stats: Epoch 65 Divergences: Uniform: 7.158207000867108 Unigram: 3.4973558626529178
2022-03-14 19:41:09 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 19:41:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:41:41 | INFO | train_inner | epoch 066:     20 / 103 loss=4.674, ppl=25.53, wps=40308.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6700, lr=0.000386334, gnorm=0.846, loss_scale=8, train_wall=152, gb_free=20.8, wall=10917
2022-03-14 19:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:43:55 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 7.85 | ppl 230.71 | wps 66510.6 | wpb 2040.3 | bsz 4 | num_updates 6783 | best_loss 7.217
2022-03-14 19:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6783 updates
2022-03-14 19:43:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:43:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:43:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 66 @ 6783 updates, score 7.85) (writing took 1.0485313553363085 seconds)
2022-03-14 19:43:56 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 19:43:56 | INFO | train | epoch 066 | loss 4.651 | ppl 25.12 | wps 40341.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6783 | lr 0.000383963 | gnorm 0.847 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 11053
KL Stats: Epoch 66 Divergences: Uniform: 7.21302661762469 Unigram: 3.5198874272595173
2022-03-14 19:43:56 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 19:43:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:44:23 | INFO | train_inner | epoch 067:     17 / 103 loss=4.647, ppl=25.05, wps=40315.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=6800, lr=0.000383482, gnorm=0.836, loss_scale=16, train_wall=153, gb_free=20.8, wall=11079
2022-03-14 19:44:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:46:42 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 7.871 | ppl 234.05 | wps 66533.6 | wpb 2040.3 | bsz 4 | num_updates 6885 | best_loss 7.217
2022-03-14 19:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6885 updates
2022-03-14 19:46:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:46:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:46:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 67 @ 6885 updates, score 7.871) (writing took 0.9962059138342738 seconds)
2022-03-14 19:46:43 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 19:46:43 | INFO | train | epoch 067 | loss 4.626 | ppl 24.69 | wps 39976.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6885 | lr 0.000381108 | gnorm 0.851 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11219
KL Stats: Epoch 67 Divergences: Uniform: 7.259658882923975 Unigram: 3.543011111027618
2022-03-14 19:46:43 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 19:46:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:47:07 | INFO | train_inner | epoch 068:     15 / 103 loss=4.626, ppl=24.69, wps=39935.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=6900, lr=0.000380693, gnorm=0.852, loss_scale=8, train_wall=154, gb_free=20.8, wall=11243
2022-03-14 19:49:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:49:28 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 7.881 | ppl 235.68 | wps 66321.5 | wpb 2040.3 | bsz 4 | num_updates 6988 | best_loss 7.217
2022-03-14 19:49:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6988 updates
2022-03-14 19:49:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:49:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 68 @ 6988 updates, score 7.881) (writing took 1.0280277822166681 seconds)
2022-03-14 19:49:30 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 19:49:30 | INFO | train | epoch 068 | loss 4.602 | ppl 24.29 | wps 40356 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6988 | lr 0.000378289 | gnorm 0.852 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11386
KL Stats: Epoch 68 Divergences: Uniform: 7.314325698117378 Unigram: 3.5637910444449745
2022-03-14 19:49:30 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 19:49:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:49:49 | INFO | train_inner | epoch 069:     12 / 103 loss=4.599, ppl=24.24, wps=40327.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=7000, lr=0.000377964, gnorm=0.85, loss_scale=8, train_wall=152, gb_free=20.8, wall=11405
2022-03-14 19:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:52:15 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 7.917 | ppl 241.68 | wps 66623.8 | wpb 2040.3 | bsz 4 | num_updates 7091 | best_loss 7.217
2022-03-14 19:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 7091 updates
2022-03-14 19:52:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:52:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 69 @ 7091 updates, score 7.917) (writing took 1.0110743083059788 seconds)
2022-03-14 19:52:16 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 19:52:16 | INFO | train | epoch 069 | loss 4.579 | ppl 23.9 | wps 40363.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7091 | lr 0.000375531 | gnorm 0.845 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11553
KL Stats: Epoch 69 Divergences: Uniform: 7.367711359790776 Unigram: 3.586067892427434
2022-03-14 19:52:16 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 19:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:52:30 | INFO | train_inner | epoch 070:      9 / 103 loss=4.579, ppl=23.9, wps=40332, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7100, lr=0.000375293, gnorm=0.849, loss_scale=8, train_wall=153, gb_free=20.8, wall=11567
2022-03-14 19:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:55:02 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 7.937 | ppl 245.11 | wps 66483.8 | wpb 2040.3 | bsz 4 | num_updates 7194 | best_loss 7.217
2022-03-14 19:55:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 7194 updates
2022-03-14 19:55:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:55:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:55:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 70 @ 7194 updates, score 7.937) (writing took 1.0515768053010106 seconds)
2022-03-14 19:55:03 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 19:55:03 | INFO | train | epoch 070 | loss 4.555 | ppl 23.51 | wps 40360.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7194 | lr 0.000372833 | gnorm 0.844 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11719
KL Stats: Epoch 70 Divergences: Uniform: 7.417104605884839 Unigram: 3.6058762360601224
2022-03-14 19:55:03 | INFO | fairseq.trainer | begin training epoch 71
2022-03-14 19:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:55:12 | INFO | train_inner | epoch 071:      6 / 103 loss=4.559, ppl=23.57, wps=40314.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=7200, lr=0.000372678, gnorm=0.842, loss_scale=8, train_wall=153, gb_free=20.8, wall=11729
2022-03-14 19:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:57:48 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 7.956 | ppl 248.39 | wps 66463.7 | wpb 2040.3 | bsz 4 | num_updates 7297 | best_loss 7.217
2022-03-14 19:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 7297 updates
2022-03-14 19:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 19:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 71 @ 7297 updates, score 7.956) (writing took 1.051512487232685 seconds)
2022-03-14 19:57:50 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-14 19:57:50 | INFO | train | epoch 071 | loss 4.532 | ppl 23.14 | wps 40354.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7297 | lr 0.000370193 | gnorm 0.86 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11886
KL Stats: Epoch 71 Divergences: Uniform: 7.460709714310798 Unigram: 3.6264003957795414
2022-03-14 19:57:50 | INFO | fairseq.trainer | begin training epoch 72
2022-03-14 19:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:57:54 | INFO | train_inner | epoch 072:      3 / 103 loss=4.533, ppl=23.16, wps=40327.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=0.86, loss_scale=8, train_wall=152, gb_free=20.8, wall=11891
2022-03-14 20:00:32 | INFO | train_inner | epoch 072:    103 / 103 loss=4.513, ppl=22.83, wps=41529.8, ups=0.64, wpb=65305.6, bsz=127.6, num_updates=7400, lr=0.000367607, gnorm=0.857, loss_scale=16, train_wall=152, gb_free=20.8, wall=12048
2022-03-14 20:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:00:35 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 7.978 | ppl 252.17 | wps 66572.9 | wpb 2040.3 | bsz 4 | num_updates 7400 | best_loss 7.217
2022-03-14 20:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 7400 updates
2022-03-14 20:00:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:00:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:00:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 72 @ 7400 updates, score 7.978) (writing took 1.041322834789753 seconds)
2022-03-14 20:00:36 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-14 20:00:36 | INFO | train | epoch 072 | loss 4.51 | ppl 22.79 | wps 40356.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7400 | lr 0.000367607 | gnorm 0.856 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 12053
KL Stats: Epoch 72 Divergences: Uniform: 7.513324249172175 Unigram: 3.6460216317382006
2022-03-14 20:00:36 | INFO | fairseq.trainer | begin training epoch 73
2022-03-14 20:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:03:14 | INFO | train_inner | epoch 073:    100 / 103 loss=4.486, ppl=22.4, wps=40324.1, ups=0.62, wpb=65530.9, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.851, loss_scale=16, train_wall=153, gb_free=20.8, wall=12211
2022-03-14 20:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:03:22 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 8.005 | ppl 256.83 | wps 66677.8 | wpb 2040.3 | bsz 4 | num_updates 7503 | best_loss 7.217
2022-03-14 20:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7503 updates
2022-03-14 20:03:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:03:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:03:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 73 @ 7503 updates, score 8.005) (writing took 1.0190481804311275 seconds)
2022-03-14 20:03:23 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-14 20:03:23 | INFO | train | epoch 073 | loss 4.489 | ppl 22.45 | wps 40359.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7503 | lr 0.000365075 | gnorm 0.852 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 12219
KL Stats: Epoch 73 Divergences: Uniform: 7.553208546640242 Unigram: 3.6659494625903877
2022-03-14 20:03:23 | INFO | fairseq.trainer | begin training epoch 74
2022-03-14 20:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:05:56 | INFO | train_inner | epoch 074:     97 / 103 loss=4.468, ppl=22.14, wps=40322.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7600, lr=0.000362738, gnorm=0.859, loss_scale=16, train_wall=153, gb_free=20.8, wall=12373
2022-03-14 20:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:06:09 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 8.029 | ppl 261.21 | wps 66540.6 | wpb 2040.3 | bsz 4 | num_updates 7606 | best_loss 7.217
2022-03-14 20:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7606 updates
2022-03-14 20:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 74 @ 7606 updates, score 8.029) (writing took 1.0286326259374619 seconds)
2022-03-14 20:06:10 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-14 20:06:10 | INFO | train | epoch 074 | loss 4.47 | ppl 22.16 | wps 40353 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7606 | lr 0.000362595 | gnorm 0.86 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 12386
KL Stats: Epoch 74 Divergences: Uniform: 7.594209880204533 Unigram: 3.6854976181950625
2022-03-14 20:06:10 | INFO | fairseq.trainer | begin training epoch 75
2022-03-14 20:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:08:38 | INFO | train_inner | epoch 075:     94 / 103 loss=4.447, ppl=21.81, wps=40335.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7700, lr=0.000360375, gnorm=0.868, loss_scale=16, train_wall=152, gb_free=20.8, wall=12534
2022-03-14 20:08:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:08:55 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 8.028 | ppl 261.05 | wps 66757.2 | wpb 2040.3 | bsz 4 | num_updates 7709 | best_loss 7.217
2022-03-14 20:08:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7709 updates
2022-03-14 20:08:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:08:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:08:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 75 @ 7709 updates, score 8.028) (writing took 1.1295434702187777 seconds)
2022-03-14 20:08:56 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-14 20:08:56 | INFO | train | epoch 075 | loss 4.448 | ppl 21.83 | wps 40344.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7709 | lr 0.000360165 | gnorm 0.871 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 12553
KL Stats: Epoch 75 Divergences: Uniform: 7.63936898616273 Unigram: 3.702987038015048
2022-03-14 20:08:56 | INFO | fairseq.trainer | begin training epoch 76
2022-03-14 20:08:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:10:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:11:22 | INFO | train_inner | epoch 076:     92 / 103 loss=4.427, ppl=21.52, wps=39901.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7800, lr=0.000358057, gnorm=0.871, loss_scale=8, train_wall=154, gb_free=20.8, wall=12698
2022-03-14 20:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:11:42 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 8.048 | ppl 264.61 | wps 66395.9 | wpb 2040.3 | bsz 4 | num_updates 7811 | best_loss 7.217
2022-03-14 20:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7811 updates
2022-03-14 20:11:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 76 @ 7811 updates, score 8.048) (writing took 1.025546532124281 seconds)
2022-03-14 20:11:43 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-14 20:11:43 | INFO | train | epoch 076 | loss 4.428 | ppl 21.52 | wps 39952.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7811 | lr 0.000357805 | gnorm 0.864 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12720
KL Stats: Epoch 76 Divergences: Uniform: 7.683706475637028 Unigram: 3.7205167549416704
2022-03-14 20:11:43 | INFO | fairseq.trainer | begin training epoch 77
2022-03-14 20:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:14:04 | INFO | train_inner | epoch 077:     89 / 103 loss=4.412, ppl=21.29, wps=40314.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7900, lr=0.000355784, gnorm=0.861, loss_scale=8, train_wall=153, gb_free=20.8, wall=12860
2022-03-14 20:14:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:14:29 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 8.064 | ppl 267.59 | wps 66720 | wpb 2040.3 | bsz 4 | num_updates 7914 | best_loss 7.217
2022-03-14 20:14:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7914 updates
2022-03-14 20:14:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 77 @ 7914 updates, score 8.064) (writing took 1.0526160225272179 seconds)
2022-03-14 20:14:30 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-14 20:14:30 | INFO | train | epoch 077 | loss 4.41 | ppl 21.25 | wps 40348.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7914 | lr 0.000355469 | gnorm 0.865 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12886
KL Stats: Epoch 77 Divergences: Uniform: 7.723806385715116 Unigram: 3.73690977170214
2022-03-14 20:14:30 | INFO | fairseq.trainer | begin training epoch 78
2022-03-14 20:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:16:46 | INFO | train_inner | epoch 078:     86 / 103 loss=4.391, ppl=20.98, wps=40316.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8000, lr=0.000353553, gnorm=0.863, loss_scale=8, train_wall=153, gb_free=20.8, wall=13022
2022-03-14 20:17:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:17:16 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 8.09 | ppl 272.47 | wps 66345 | wpb 2040.3 | bsz 4 | num_updates 8017 | best_loss 7.217
2022-03-14 20:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 8017 updates
2022-03-14 20:17:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:17:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:17:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 78 @ 8017 updates, score 8.09) (writing took 1.0488199731335044 seconds)
2022-03-14 20:17:17 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-14 20:17:17 | INFO | train | epoch 078 | loss 4.393 | ppl 21.01 | wps 40342.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8017 | lr 0.000353178 | gnorm 0.864 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 13053
KL Stats: Epoch 78 Divergences: Uniform: 7.766234986086723 Unigram: 3.7544839987381278
2022-03-14 20:17:17 | INFO | fairseq.trainer | begin training epoch 79
2022-03-14 20:17:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:19:28 | INFO | train_inner | epoch 079:     83 / 103 loss=4.376, ppl=20.77, wps=40327.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8100, lr=0.000351364, gnorm=0.867, loss_scale=8, train_wall=152, gb_free=20.8, wall=13184
2022-03-14 20:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:20:02 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 8.098 | ppl 274.09 | wps 66541.4 | wpb 2040.3 | bsz 4 | num_updates 8120 | best_loss 7.217
2022-03-14 20:20:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 8120 updates
2022-03-14 20:20:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 79 @ 8120 updates, score 8.098) (writing took 1.1292230868712068 seconds)
2022-03-14 20:20:03 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-14 20:20:03 | INFO | train | epoch 079 | loss 4.374 | ppl 20.73 | wps 40355 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8120 | lr 0.000350931 | gnorm 0.862 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 13220
KL Stats: Epoch 79 Divergences: Uniform: 7.802719650044078 Unigram: 3.770275266155595
2022-03-14 20:20:03 | INFO | fairseq.trainer | begin training epoch 80
2022-03-14 20:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:22:10 | INFO | train_inner | epoch 080:     80 / 103 loss=4.357, ppl=20.49, wps=40305.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8200, lr=0.000349215, gnorm=0.872, loss_scale=8, train_wall=152, gb_free=20.8, wall=13346
2022-03-14 20:22:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:22:49 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 8.106 | ppl 275.44 | wps 66693.3 | wpb 2040.3 | bsz 4 | num_updates 8223 | best_loss 7.217
2022-03-14 20:22:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 8223 updates
2022-03-14 20:22:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:22:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 80 @ 8223 updates, score 8.106) (writing took 1.0697157196700573 seconds)
2022-03-14 20:22:50 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-14 20:22:50 | INFO | train | epoch 080 | loss 4.357 | ppl 20.49 | wps 40346.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8223 | lr 0.000348726 | gnorm 0.877 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 13386
KL Stats: Epoch 80 Divergences: Uniform: 7.838890191569579 Unigram: 3.786705664494056
2022-03-14 20:22:50 | INFO | fairseq.trainer | begin training epoch 81
2022-03-14 20:22:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:24:52 | INFO | train_inner | epoch 081:     77 / 103 loss=4.344, ppl=20.31, wps=40317.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8300, lr=0.000347105, gnorm=0.873, loss_scale=16, train_wall=152, gb_free=20.8, wall=13508
2022-03-14 20:25:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:25:36 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 8.136 | ppl 281.4 | wps 66469.3 | wpb 2040.3 | bsz 4 | num_updates 8326 | best_loss 7.217
2022-03-14 20:25:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 8326 updates
2022-03-14 20:25:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:25:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 81 @ 8326 updates, score 8.136) (writing took 1.0502196988090873 seconds)
2022-03-14 20:25:37 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-14 20:25:37 | INFO | train | epoch 081 | loss 4.339 | ppl 20.24 | wps 40354.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8326 | lr 0.000346563 | gnorm 0.875 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13553
KL Stats: Epoch 81 Divergences: Uniform: 7.881885964610025 Unigram: 3.802059695351514
2022-03-14 20:25:37 | INFO | fairseq.trainer | begin training epoch 82
2022-03-14 20:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:27:34 | INFO | train_inner | epoch 082:     74 / 103 loss=4.325, ppl=20.04, wps=40336.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8400, lr=0.000345033, gnorm=0.876, loss_scale=16, train_wall=152, gb_free=20.8, wall=13670
2022-03-14 20:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:28:22 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 8.153 | ppl 284.67 | wps 66785.2 | wpb 2040.3 | bsz 4 | num_updates 8429 | best_loss 7.217
2022-03-14 20:28:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 8429 updates
2022-03-14 20:28:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:28:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 82 @ 8429 updates, score 8.153) (writing took 1.0784421721473336 seconds)
2022-03-14 20:28:23 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-14 20:28:23 | INFO | train | epoch 082 | loss 4.321 | ppl 19.99 | wps 40361.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8429 | lr 0.000344439 | gnorm 0.87 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13720
KL Stats: Epoch 82 Divergences: Uniform: 7.9177205565923625 Unigram: 3.820112739147707
2022-03-14 20:28:23 | INFO | fairseq.trainer | begin training epoch 83
2022-03-14 20:28:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:30:16 | INFO | train_inner | epoch 083:     71 / 103 loss=4.307, ppl=19.8, wps=40287.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8500, lr=0.000342997, gnorm=0.866, loss_scale=16, train_wall=153, gb_free=20.8, wall=13832
2022-03-14 20:31:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:31:09 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 8.174 | ppl 288.84 | wps 66773 | wpb 2040.3 | bsz 4 | num_updates 8532 | best_loss 7.217
2022-03-14 20:31:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 8532 updates
2022-03-14 20:31:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:31:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:31:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 83 @ 8532 updates, score 8.174) (writing took 0.9490080513060093 seconds)
2022-03-14 20:31:10 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-14 20:31:10 | INFO | train | epoch 083 | loss 4.307 | ppl 19.79 | wps 40361.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8532 | lr 0.000342353 | gnorm 0.872 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13886
KL Stats: Epoch 83 Divergences: Uniform: 7.951535709853907 Unigram: 3.8349115461494696
2022-03-14 20:31:10 | INFO | fairseq.trainer | begin training epoch 84
2022-03-14 20:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:32:58 | INFO | train_inner | epoch 084:     68 / 103 loss=4.295, ppl=19.63, wps=40304.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8600, lr=0.000340997, gnorm=0.884, loss_scale=16, train_wall=153, gb_free=20.8, wall=13994
2022-03-14 20:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:33:56 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 8.194 | ppl 292.88 | wps 66195 | wpb 2040.3 | bsz 4 | num_updates 8635 | best_loss 7.217
2022-03-14 20:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8635 updates
2022-03-14 20:33:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 84 @ 8635 updates, score 8.194) (writing took 1.0587692502886057 seconds)
2022-03-14 20:33:57 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-14 20:33:57 | INFO | train | epoch 084 | loss 4.289 | ppl 19.55 | wps 40285.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8635 | lr 0.000340305 | gnorm 0.883 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 14053
KL Stats: Epoch 84 Divergences: Uniform: 7.985125240257182 Unigram: 3.849018132419172
2022-03-14 20:33:57 | INFO | fairseq.trainer | begin training epoch 85
2022-03-14 20:33:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:35:40 | INFO | train_inner | epoch 085:     65 / 103 loss=4.279, ppl=19.42, wps=40250.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=8700, lr=0.000339032, gnorm=0.883, loss_scale=16, train_wall=153, gb_free=20.8, wall=14156
2022-03-14 20:36:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:36:43 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 8.195 | ppl 293.15 | wps 66444 | wpb 2040.3 | bsz 4 | num_updates 8738 | best_loss 7.217
2022-03-14 20:36:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8738 updates
2022-03-14 20:36:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:36:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:36:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 85 @ 8738 updates, score 8.195) (writing took 0.9986522477120161 seconds)
2022-03-14 20:36:44 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-14 20:36:44 | INFO | train | epoch 085 | loss 4.274 | ppl 19.35 | wps 40297.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8738 | lr 0.000338294 | gnorm 0.887 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 14220
KL Stats: Epoch 85 Divergences: Uniform: 8.017873504627447 Unigram: 3.8626705852928036
2022-03-14 20:36:44 | INFO | fairseq.trainer | begin training epoch 86
2022-03-14 20:36:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:38:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 20:38:24 | INFO | train_inner | epoch 086:     63 / 103 loss=4.265, ppl=19.23, wps=39885.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8800, lr=0.0003371, gnorm=0.883, loss_scale=16, train_wall=154, gb_free=20.8, wall=14320
2022-03-14 20:38:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:39:30 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 8.227 | ppl 299.72 | wps 66614.2 | wpb 2040.3 | bsz 4 | num_updates 8839 | best_loss 7.217
2022-03-14 20:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8839 updates
2022-03-14 20:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:39:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:39:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 86 @ 8839 updates, score 8.227) (writing took 1.0143722277134657 seconds)
2022-03-14 20:39:31 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-14 20:39:31 | INFO | train | epoch 086 | loss 4.258 | ppl 19.14 | wps 39521.9 | ups 0.61 | wpb 65307.9 | bsz 127.6 | num_updates 8839 | lr 0.000336355 | gnorm 0.886 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14387
KL Stats: Epoch 86 Divergences: Uniform: 8.057685669102446 Unigram: 3.878268255631509
2022-03-14 20:39:31 | INFO | fairseq.trainer | begin training epoch 87
2022-03-14 20:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:41:07 | INFO | train_inner | epoch 087:     61 / 103 loss=4.246, ppl=18.98, wps=39887, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=8900, lr=0.000335201, gnorm=0.89, loss_scale=8, train_wall=154, gb_free=20.8, wall=14484
2022-03-14 20:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:42:17 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 8.237 | ppl 301.76 | wps 66366.8 | wpb 2040.3 | bsz 4 | num_updates 8942 | best_loss 7.217
2022-03-14 20:42:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8942 updates
2022-03-14 20:42:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:42:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:42:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 87 @ 8942 updates, score 8.237) (writing took 0.9822092596441507 seconds)
2022-03-14 20:42:18 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-14 20:42:18 | INFO | train | epoch 087 | loss 4.245 | ppl 18.96 | wps 40320.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8942 | lr 0.000334413 | gnorm 0.892 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14554
KL Stats: Epoch 87 Divergences: Uniform: 8.086342822176956 Unigram: 3.8912692374804303
2022-03-14 20:42:18 | INFO | fairseq.trainer | begin training epoch 88
2022-03-14 20:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:43:49 | INFO | train_inner | epoch 088:     58 / 103 loss=4.236, ppl=18.84, wps=40279.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9000, lr=0.000333333, gnorm=0.877, loss_scale=8, train_wall=153, gb_free=20.8, wall=14646
2022-03-14 20:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:45:04 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 8.257 | ppl 305.88 | wps 66466.3 | wpb 2040.3 | bsz 4 | num_updates 9045 | best_loss 7.217
2022-03-14 20:45:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 9045 updates
2022-03-14 20:45:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:45:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:45:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 88 @ 9045 updates, score 8.257) (writing took 1.000650255009532 seconds)
2022-03-14 20:45:05 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-14 20:45:05 | INFO | train | epoch 088 | loss 4.231 | ppl 18.78 | wps 40298.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9045 | lr 0.000332503 | gnorm 0.875 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14721
KL Stats: Epoch 88 Divergences: Uniform: 8.114248283332918 Unigram: 3.9054160326094522
2022-03-14 20:45:05 | INFO | fairseq.trainer | begin training epoch 89
2022-03-14 20:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:46:32 | INFO | train_inner | epoch 089:     55 / 103 loss=4.226, ppl=18.71, wps=40254.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9100, lr=0.000331497, gnorm=0.89, loss_scale=8, train_wall=153, gb_free=20.8, wall=14808
2022-03-14 20:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:47:51 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 8.265 | ppl 307.72 | wps 66682.1 | wpb 2040.3 | bsz 4 | num_updates 9148 | best_loss 7.217
2022-03-14 20:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 9148 updates
2022-03-14 20:47:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:47:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:47:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 89 @ 9148 updates, score 8.265) (writing took 1.0496908752247691 seconds)
2022-03-14 20:47:52 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-14 20:47:52 | INFO | train | epoch 089 | loss 4.217 | ppl 18.6 | wps 40290.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9148 | lr 0.000330626 | gnorm 0.898 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14888
KL Stats: Epoch 89 Divergences: Uniform: 8.14760732857696 Unigram: 3.917235385604359
2022-03-14 20:47:52 | INFO | fairseq.trainer | begin training epoch 90
2022-03-14 20:47:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:49:14 | INFO | train_inner | epoch 090:     52 / 103 loss=4.21, ppl=18.51, wps=40261.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9200, lr=0.00032969, gnorm=0.904, loss_scale=8, train_wall=153, gb_free=20.8, wall=14970
2022-03-14 20:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:50:38 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 8.279 | ppl 310.58 | wps 65794.9 | wpb 2040.3 | bsz 4 | num_updates 9251 | best_loss 7.217
2022-03-14 20:50:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 9251 updates
2022-03-14 20:50:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:50:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:50:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 90 @ 9251 updates, score 8.279) (writing took 1.0388828348368406 seconds)
2022-03-14 20:50:39 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-14 20:50:39 | INFO | train | epoch 090 | loss 4.202 | ppl 18.41 | wps 40275 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9251 | lr 0.00032878 | gnorm 0.892 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15055
KL Stats: Epoch 90 Divergences: Uniform: 8.177807208780596 Unigram: 3.931131048227067
2022-03-14 20:50:39 | INFO | fairseq.trainer | begin training epoch 91
2022-03-14 20:50:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:51:56 | INFO | train_inner | epoch 091:     49 / 103 loss=4.195, ppl=18.31, wps=40242.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9300, lr=0.000327913, gnorm=0.88, loss_scale=8, train_wall=153, gb_free=20.8, wall=15133
2022-03-14 20:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:53:25 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 8.292 | ppl 313.38 | wps 66586.9 | wpb 2040.3 | bsz 4 | num_updates 9354 | best_loss 7.217
2022-03-14 20:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 9354 updates
2022-03-14 20:53:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:53:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:53:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 91 @ 9354 updates, score 8.292) (writing took 1.043839931488037 seconds)
2022-03-14 20:53:26 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-14 20:53:26 | INFO | train | epoch 091 | loss 4.189 | ppl 18.24 | wps 40288.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9354 | lr 0.000326965 | gnorm 0.88 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 15222
KL Stats: Epoch 91 Divergences: Uniform: 8.208313131244712 Unigram: 3.9427417903141135
2022-03-14 20:53:26 | INFO | fairseq.trainer | begin training epoch 92
2022-03-14 20:53:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:53:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:54:40 | INFO | train_inner | epoch 092:     47 / 103 loss=4.184, ppl=18.18, wps=39874.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9400, lr=0.000326164, gnorm=0.888, loss_scale=8, train_wall=154, gb_free=20.8, wall=15296
2022-03-14 20:56:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:56:12 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 8.312 | ppl 317.82 | wps 66595.4 | wpb 2040.3 | bsz 4 | num_updates 9456 | best_loss 7.217
2022-03-14 20:56:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 9456 updates
2022-03-14 20:56:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:56:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:56:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 92 @ 9456 updates, score 8.312) (writing took 1.0037720575928688 seconds)
2022-03-14 20:56:13 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-14 20:56:13 | INFO | train | epoch 092 | loss 4.175 | ppl 18.06 | wps 39917.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 9456 | lr 0.000325197 | gnorm 0.897 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15389
KL Stats: Epoch 92 Divergences: Uniform: 8.23220503941403 Unigram: 3.956894019597942
2022-03-14 20:56:13 | INFO | fairseq.trainer | begin training epoch 93
2022-03-14 20:56:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:57:22 | INFO | train_inner | epoch 093:     44 / 103 loss=4.166, ppl=17.96, wps=40268.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9500, lr=0.000324443, gnorm=0.905, loss_scale=8, train_wall=153, gb_free=20.8, wall=15459
2022-03-14 20:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:58:58 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 8.313 | ppl 318.06 | wps 66418.8 | wpb 2040.3 | bsz 4 | num_updates 9559 | best_loss 7.217
2022-03-14 20:58:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 9559 updates
2022-03-14 20:58:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:59:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 20:59:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 93 @ 9559 updates, score 8.313) (writing took 1.1179412119090557 seconds)
2022-03-14 20:59:00 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-14 20:59:00 | INFO | train | epoch 093 | loss 4.162 | ppl 17.9 | wps 40273.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9559 | lr 0.00032344 | gnorm 0.899 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15556
KL Stats: Epoch 93 Divergences: Uniform: 8.261234579335332 Unigram: 3.968090430074161
2022-03-14 20:59:00 | INFO | fairseq.trainer | begin training epoch 94
2022-03-14 20:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:00:04 | INFO | train_inner | epoch 094:     41 / 103 loss=4.154, ppl=17.8, wps=40235.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9600, lr=0.000322749, gnorm=0.885, loss_scale=8, train_wall=153, gb_free=20.8, wall=15621
2022-03-14 21:01:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:01:45 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 8.333 | ppl 322.47 | wps 66493.9 | wpb 2040.3 | bsz 4 | num_updates 9662 | best_loss 7.217
2022-03-14 21:01:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9662 updates
2022-03-14 21:01:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:01:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:01:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 94 @ 9662 updates, score 8.333) (writing took 1.007132031954825 seconds)
2022-03-14 21:01:46 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-14 21:01:46 | INFO | train | epoch 094 | loss 4.15 | ppl 17.75 | wps 40305.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9662 | lr 0.000321711 | gnorm 0.896 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15723
KL Stats: Epoch 94 Divergences: Uniform: 8.288020004407146 Unigram: 3.9815830548487416
2022-03-14 21:01:46 | INFO | fairseq.trainer | begin training epoch 95
2022-03-14 21:01:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:02:47 | INFO | train_inner | epoch 095:     38 / 103 loss=4.15, ppl=17.75, wps=40280.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9700, lr=0.000321081, gnorm=0.903, loss_scale=8, train_wall=153, gb_free=20.8, wall=15783
2022-03-14 21:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:04:32 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 8.337 | ppl 323.44 | wps 66518.2 | wpb 2040.3 | bsz 4 | num_updates 9765 | best_loss 7.217
2022-03-14 21:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9765 updates
2022-03-14 21:04:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:04:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:04:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 95 @ 9765 updates, score 8.337) (writing took 1.0449509313330054 seconds)
2022-03-14 21:04:33 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-14 21:04:33 | INFO | train | epoch 095 | loss 4.137 | ppl 17.6 | wps 40288.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9765 | lr 0.00032001 | gnorm 0.908 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15890
KL Stats: Epoch 95 Divergences: Uniform: 8.31144464513141 Unigram: 3.9910028569879845
2022-03-14 21:04:33 | INFO | fairseq.trainer | begin training epoch 96
2022-03-14 21:04:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:05:29 | INFO | train_inner | epoch 096:     35 / 103 loss=4.135, ppl=17.56, wps=40252.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9800, lr=0.000319438, gnorm=0.916, loss_scale=8, train_wall=153, gb_free=20.8, wall=15945
2022-03-14 21:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:07:19 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 8.368 | ppl 330.37 | wps 66536.3 | wpb 2040.3 | bsz 4 | num_updates 9868 | best_loss 7.217
2022-03-14 21:07:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9868 updates
2022-03-14 21:07:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:07:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 96 @ 9868 updates, score 8.368) (writing took 1.0144778275862336 seconds)
2022-03-14 21:07:20 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-14 21:07:20 | INFO | train | epoch 096 | loss 4.125 | ppl 17.45 | wps 40295.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9868 | lr 0.000318336 | gnorm 0.905 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 16057
KL Stats: Epoch 96 Divergences: Uniform: 8.342587054534272 Unigram: 4.003091438169995
2022-03-14 21:07:20 | INFO | fairseq.trainer | begin training epoch 97
2022-03-14 21:07:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:08:11 | INFO | train_inner | epoch 097:     32 / 103 loss=4.122, ppl=17.42, wps=40263.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9900, lr=0.000317821, gnorm=0.903, loss_scale=16, train_wall=153, gb_free=20.8, wall=16107
2022-03-14 21:10:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:10:06 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 8.369 | ppl 330.69 | wps 66296.2 | wpb 2040.3 | bsz 4 | num_updates 9971 | best_loss 7.217
2022-03-14 21:10:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9971 updates
2022-03-14 21:10:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:10:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:10:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 97 @ 9971 updates, score 8.369) (writing took 1.0665172319859266 seconds)
2022-03-14 21:10:07 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-14 21:10:07 | INFO | train | epoch 097 | loss 4.113 | ppl 17.3 | wps 40309.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9971 | lr 0.000316687 | gnorm 0.906 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16224
KL Stats: Epoch 97 Divergences: Uniform: 8.367009586672346 Unigram: 4.0147314514996335
2022-03-14 21:10:07 | INFO | fairseq.trainer | begin training epoch 98
2022-03-14 21:10:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:10:53 | INFO | train_inner | epoch 098:     29 / 103 loss=4.111, ppl=17.28, wps=40267.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10000, lr=0.000316228, gnorm=0.903, loss_scale=16, train_wall=153, gb_free=20.8, wall=16270
2022-03-14 21:12:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:12:53 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 8.381 | ppl 333.37 | wps 66550.7 | wpb 2040.3 | bsz 4 | num_updates 10074 | best_loss 7.217
2022-03-14 21:12:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 10074 updates
2022-03-14 21:12:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:12:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:12:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 98 @ 10074 updates, score 8.381) (writing took 1.0290832268074155 seconds)
2022-03-14 21:12:54 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-14 21:12:54 | INFO | train | epoch 098 | loss 4.102 | ppl 17.17 | wps 40283.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10074 | lr 0.000315064 | gnorm 0.905 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16391
KL Stats: Epoch 98 Divergences: Uniform: 8.386537404988083 Unigram: 4.024509788322378
2022-03-14 21:12:54 | INFO | fairseq.trainer | begin training epoch 99
2022-03-14 21:12:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:13:35 | INFO | train_inner | epoch 099:     26 / 103 loss=4.1, ppl=17.15, wps=40255.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10100, lr=0.000314658, gnorm=0.916, loss_scale=16, train_wall=153, gb_free=20.8, wall=16432
2022-03-14 21:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:15:40 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 8.406 | ppl 339.15 | wps 66468.9 | wpb 2040.3 | bsz 4 | num_updates 10177 | best_loss 7.217
2022-03-14 21:15:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 10177 updates
2022-03-14 21:15:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 99 @ 10177 updates, score 8.406) (writing took 1.0357592897489667 seconds)
2022-03-14 21:15:41 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-14 21:15:41 | INFO | train | epoch 099 | loss 4.09 | ppl 17.03 | wps 40306 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10177 | lr 0.000313466 | gnorm 0.902 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16558
KL Stats: Epoch 99 Divergences: Uniform: 8.416317061143308 Unigram: 4.035965574712778
2022-03-14 21:15:41 | INFO | fairseq.trainer | begin training epoch 100
2022-03-14 21:15:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:16:18 | INFO | train_inner | epoch 100:     23 / 103 loss=4.088, ppl=17.01, wps=40274.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10200, lr=0.000313112, gnorm=0.896, loss_scale=16, train_wall=153, gb_free=20.8, wall=16594
2022-03-14 21:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:18:27 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 8.402 | ppl 338.16 | wps 66792.1 | wpb 2040.3 | bsz 4 | num_updates 10280 | best_loss 7.217
2022-03-14 21:18:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 10280 updates
2022-03-14 21:18:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:18:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 100 @ 10280 updates, score 8.402) (writing took 1.1541733434423804 seconds)
2022-03-14 21:18:28 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-14 21:18:28 | INFO | train | epoch 100 | loss 4.08 | ppl 16.92 | wps 40283.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10280 | lr 0.000311891 | gnorm 0.9 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16725
KL Stats: Epoch 100 Divergences: Uniform: 8.437412602746255 Unigram: 4.044712705566586
2022-03-14 21:18:28 | INFO | fairseq.trainer | begin training epoch 101
2022-03-14 21:18:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:19:00 | INFO | train_inner | epoch 101:     20 / 103 loss=4.08, ppl=16.92, wps=40243.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10300, lr=0.000311588, gnorm=0.9, loss_scale=16, train_wall=153, gb_free=20.8, wall=16756
2022-03-14 21:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:21:14 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 8.419 | ppl 342.31 | wps 66484.1 | wpb 2040.3 | bsz 4 | num_updates 10383 | best_loss 7.217
2022-03-14 21:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 10383 updates
2022-03-14 21:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:21:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:21:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 101 @ 10383 updates, score 8.419) (writing took 1.0088336924090981 seconds)
2022-03-14 21:21:15 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-14 21:21:15 | INFO | train | epoch 101 | loss 4.069 | ppl 16.78 | wps 40292.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10383 | lr 0.000310341 | gnorm 0.896 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16892
KL Stats: Epoch 101 Divergences: Uniform: 8.459390827416058 Unigram: 4.055882306746062
2022-03-14 21:21:15 | INFO | fairseq.trainer | begin training epoch 102
2022-03-14 21:21:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:21:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:21:44 | INFO | train_inner | epoch 102:     18 / 103 loss=4.07, ppl=16.79, wps=39875.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10400, lr=0.000310087, gnorm=0.889, loss_scale=16, train_wall=154, gb_free=20.8, wall=16920
2022-03-14 21:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:24:01 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 8.442 | ppl 347.75 | wps 66555 | wpb 2040.3 | bsz 4 | num_updates 10485 | best_loss 7.217
2022-03-14 21:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10485 updates
2022-03-14 21:24:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:24:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:24:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 102 @ 10485 updates, score 8.442) (writing took 1.0726141715422273 seconds)
2022-03-14 21:24:02 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-14 21:24:02 | INFO | train | epoch 102 | loss 4.058 | ppl 16.66 | wps 39904.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10485 | lr 0.000308827 | gnorm 0.906 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 17058
KL Stats: Epoch 102 Divergences: Uniform: 8.48296318320765 Unigram: 4.067002224966023
2022-03-14 21:24:02 | INFO | fairseq.trainer | begin training epoch 103
2022-03-14 21:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:24:26 | INFO | train_inner | epoch 103:     15 / 103 loss=4.058, ppl=16.65, wps=40250.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10500, lr=0.000308607, gnorm=0.907, loss_scale=16, train_wall=153, gb_free=20.8, wall=17082
2022-03-14 21:25:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:26:48 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 8.444 | ppl 348.33 | wps 66079.2 | wpb 2040.3 | bsz 4 | num_updates 10587 | best_loss 7.217
2022-03-14 21:26:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 10587 updates
2022-03-14 21:26:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:26:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:26:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 103 @ 10587 updates, score 8.444) (writing took 1.03515172470361 seconds)
2022-03-14 21:26:49 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-14 21:26:49 | INFO | train | epoch 103 | loss 4.048 | ppl 16.54 | wps 39900 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10587 | lr 0.000307336 | gnorm 0.912 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17225
KL Stats: Epoch 103 Divergences: Uniform: 8.501494002123009 Unigram: 4.076531155015581
2022-03-14 21:26:49 | INFO | fairseq.trainer | begin training epoch 104
2022-03-14 21:26:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:27:10 | INFO | train_inner | epoch 104:     13 / 103 loss=4.047, ppl=16.53, wps=39876.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10600, lr=0.000307148, gnorm=0.916, loss_scale=8, train_wall=154, gb_free=20.8, wall=17246
2022-03-14 21:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:29:35 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 8.446 | ppl 348.74 | wps 66357 | wpb 2040.3 | bsz 4 | num_updates 10690 | best_loss 7.217
2022-03-14 21:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10690 updates
2022-03-14 21:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:29:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:29:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 104 @ 10690 updates, score 8.446) (writing took 1.0554864695295691 seconds)
2022-03-14 21:29:36 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-14 21:29:36 | INFO | train | epoch 104 | loss 4.036 | ppl 16.4 | wps 40290.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10690 | lr 0.000305852 | gnorm 0.91 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17392
KL Stats: Epoch 104 Divergences: Uniform: 8.524889545223212 Unigram: 4.086935049017022
2022-03-14 21:29:36 | INFO | fairseq.trainer | begin training epoch 105
2022-03-14 21:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:29:52 | INFO | train_inner | epoch 105:     10 / 103 loss=4.034, ppl=16.39, wps=40255.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10700, lr=0.000305709, gnorm=0.905, loss_scale=8, train_wall=153, gb_free=20.8, wall=17408
2022-03-14 21:32:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:32:22 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 8.481 | ppl 357.32 | wps 66268.1 | wpb 2040.3 | bsz 4 | num_updates 10793 | best_loss 7.217
2022-03-14 21:32:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10793 updates
2022-03-14 21:32:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:32:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:32:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 105 @ 10793 updates, score 8.481) (writing took 1.017809446901083 seconds)
2022-03-14 21:32:23 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-14 21:32:23 | INFO | train | epoch 105 | loss 4.027 | ppl 16.3 | wps 40299 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10793 | lr 0.000304389 | gnorm 0.906 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17559
KL Stats: Epoch 105 Divergences: Uniform: 8.546283343400356 Unigram: 4.095081083263357
2022-03-14 21:32:23 | INFO | fairseq.trainer | begin training epoch 106
2022-03-14 21:32:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:32:34 | INFO | train_inner | epoch 106:      7 / 103 loss=4.029, ppl=16.33, wps=40269, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10800, lr=0.00030429, gnorm=0.909, loss_scale=8, train_wall=153, gb_free=20.8, wall=17570
2022-03-14 21:35:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:35:09 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 8.47 | ppl 354.67 | wps 66505.4 | wpb 2040.3 | bsz 4 | num_updates 10896 | best_loss 7.217
2022-03-14 21:35:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10896 updates
2022-03-14 21:35:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:35:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:35:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 106 @ 10896 updates, score 8.47) (writing took 1.0582329574972391 seconds)
2022-03-14 21:35:10 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-14 21:35:10 | INFO | train | epoch 106 | loss 4.017 | ppl 16.19 | wps 40306.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10896 | lr 0.000302947 | gnorm 0.909 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17726
KL Stats: Epoch 106 Divergences: Uniform: 8.569899796895921 Unigram: 4.105096098551552
2022-03-14 21:35:10 | INFO | fairseq.trainer | begin training epoch 107
2022-03-14 21:35:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:35:16 | INFO | train_inner | epoch 107:      4 / 103 loss=4.019, ppl=16.21, wps=40266.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10900, lr=0.000302891, gnorm=0.91, loss_scale=8, train_wall=153, gb_free=20.8, wall=17733
2022-03-14 21:37:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:37:56 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 8.496 | ppl 361.04 | wps 66212.1 | wpb 2040.3 | bsz 4 | num_updates 10999 | best_loss 7.217
2022-03-14 21:37:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 10999 updates
2022-03-14 21:37:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:37:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:37:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 107 @ 10999 updates, score 8.496) (writing took 1.0248718215152621 seconds)
2022-03-14 21:37:57 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-14 21:37:57 | INFO | train | epoch 107 | loss 4.006 | ppl 16.07 | wps 40293.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10999 | lr 0.000301525 | gnorm 0.92 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 17893
KL Stats: Epoch 107 Divergences: Uniform: 8.591401196332836 Unigram: 4.115965868173692
2022-03-14 21:37:57 | INFO | fairseq.trainer | begin training epoch 108
2022-03-14 21:37:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:37:58 | INFO | train_inner | epoch 108:      1 / 103 loss=4.009, ppl=16.1, wps=40260.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11000, lr=0.000301511, gnorm=0.92, loss_scale=8, train_wall=153, gb_free=20.8, wall=17895
2022-03-14 21:40:37 | INFO | train_inner | epoch 108:    101 / 103 loss=3.997, ppl=15.97, wps=41462.1, ups=0.63, wpb=65530.9, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.913, loss_scale=16, train_wall=153, gb_free=20.8, wall=18053
2022-03-14 21:40:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:40:43 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 8.507 | ppl 363.68 | wps 66163.4 | wpb 2040.3 | bsz 4 | num_updates 11102 | best_loss 7.217
2022-03-14 21:40:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 11102 updates
2022-03-14 21:40:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:40:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:40:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 108 @ 11102 updates, score 8.507) (writing took 1.0743188001215458 seconds)
2022-03-14 21:40:44 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-14 21:40:44 | INFO | train | epoch 108 | loss 3.997 | ppl 15.97 | wps 40271.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11102 | lr 0.000300123 | gnorm 0.915 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18060
KL Stats: Epoch 108 Divergences: Uniform: 8.606296099893921 Unigram: 4.122823187620073
2022-03-14 21:40:44 | INFO | fairseq.trainer | begin training epoch 109
2022-03-14 21:40:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:43:19 | INFO | train_inner | epoch 109:     98 / 103 loss=3.985, ppl=15.84, wps=40239.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11200, lr=0.000298807, gnorm=0.921, loss_scale=16, train_wall=153, gb_free=20.8, wall=18215
2022-03-14 21:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:43:30 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 8.514 | ppl 365.5 | wps 66530.2 | wpb 2040.3 | bsz 4 | num_updates 11205 | best_loss 7.217
2022-03-14 21:43:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 11205 updates
2022-03-14 21:43:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:43:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:43:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 109 @ 11205 updates, score 8.514) (writing took 1.028887839987874 seconds)
2022-03-14 21:43:31 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-14 21:43:31 | INFO | train | epoch 109 | loss 3.988 | ppl 15.87 | wps 40295 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11205 | lr 0.00029874 | gnorm 0.92 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18227
KL Stats: Epoch 109 Divergences: Uniform: 8.627691572385046 Unigram: 4.131778555067202
2022-03-14 21:43:31 | INFO | fairseq.trainer | begin training epoch 110
2022-03-14 21:43:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:43:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:46:03 | INFO | train_inner | epoch 110:     96 / 103 loss=3.974, ppl=15.72, wps=39880.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11300, lr=0.000297482, gnorm=0.925, loss_scale=8, train_wall=154, gb_free=20.8, wall=18379
2022-03-14 21:46:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:46:17 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 8.517 | ppl 366.33 | wps 66168.3 | wpb 2040.3 | bsz 4 | num_updates 11307 | best_loss 7.217
2022-03-14 21:46:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 11307 updates
2022-03-14 21:46:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:46:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:46:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 110 @ 11307 updates, score 8.517) (writing took 1.1721609635278583 seconds)
2022-03-14 21:46:18 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-14 21:46:18 | INFO | train | epoch 110 | loss 3.976 | ppl 15.74 | wps 39879.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11307 | lr 0.00029739 | gnorm 0.925 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 18394
KL Stats: Epoch 110 Divergences: Uniform: 8.646367898781802 Unigram: 4.141931091945546
2022-03-14 21:46:18 | INFO | fairseq.trainer | begin training epoch 111
2022-03-14 21:46:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:48:45 | INFO | train_inner | epoch 111:     93 / 103 loss=3.968, ppl=15.65, wps=40216.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11400, lr=0.000296174, gnorm=0.934, loss_scale=8, train_wall=153, gb_free=20.8, wall=18541
2022-03-14 21:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:49:04 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 8.525 | ppl 368.47 | wps 66244 | wpb 2040.3 | bsz 4 | num_updates 11410 | best_loss 7.217
2022-03-14 21:49:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 11410 updates
2022-03-14 21:49:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:49:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:49:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 111 @ 11410 updates, score 8.525) (writing took 1.117044711485505 seconds)
2022-03-14 21:49:05 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-14 21:49:05 | INFO | train | epoch 111 | loss 3.969 | ppl 15.66 | wps 40255 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11410 | lr 0.000296045 | gnorm 0.935 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 18561
KL Stats: Epoch 111 Divergences: Uniform: 8.661998087976645 Unigram: 4.149045885499237
2022-03-14 21:49:05 | INFO | fairseq.trainer | begin training epoch 112
2022-03-14 21:49:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:51:27 | INFO | train_inner | epoch 112:     90 / 103 loss=3.959, ppl=15.55, wps=40227.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11500, lr=0.000294884, gnorm=0.908, loss_scale=8, train_wall=153, gb_free=20.8, wall=18704
2022-03-14 21:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:51:51 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 8.538 | ppl 371.81 | wps 66195.8 | wpb 2040.3 | bsz 4 | num_updates 11513 | best_loss 7.217
2022-03-14 21:51:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 11513 updates
2022-03-14 21:51:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:51:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:51:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 112 @ 11513 updates, score 8.538) (writing took 1.0674249595031142 seconds)
2022-03-14 21:51:52 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-14 21:51:52 | INFO | train | epoch 112 | loss 3.959 | ppl 15.55 | wps 40272.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11513 | lr 0.000294717 | gnorm 0.91 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 18728
KL Stats: Epoch 112 Divergences: Uniform: 8.676914625038071 Unigram: 4.157247003048122
2022-03-14 21:51:52 | INFO | fairseq.trainer | begin training epoch 113
2022-03-14 21:51:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:54:10 | INFO | train_inner | epoch 113:     87 / 103 loss=3.948, ppl=15.43, wps=40251.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11600, lr=0.00029361, gnorm=0.917, loss_scale=8, train_wall=153, gb_free=20.8, wall=18866
2022-03-14 21:54:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:54:38 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 8.559 | ppl 377.1 | wps 65899.7 | wpb 2040.3 | bsz 4 | num_updates 11616 | best_loss 7.217
2022-03-14 21:54:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 11616 updates
2022-03-14 21:54:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:54:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 113 @ 11616 updates, score 8.559) (writing took 1.0351713607087731 seconds)
2022-03-14 21:54:39 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-14 21:54:39 | INFO | train | epoch 113 | loss 3.951 | ppl 15.46 | wps 40276.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11616 | lr 0.000293408 | gnorm 0.916 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 18895
KL Stats: Epoch 113 Divergences: Uniform: 8.702081589946067 Unigram: 4.167948090867902
2022-03-14 21:54:39 | INFO | fairseq.trainer | begin training epoch 114
2022-03-14 21:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:56:52 | INFO | train_inner | epoch 114:     84 / 103 loss=3.943, ppl=15.38, wps=40235.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11700, lr=0.000292353, gnorm=0.919, loss_scale=8, train_wall=153, gb_free=20.8, wall=19028
2022-03-14 21:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:57:25 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 8.561 | ppl 377.72 | wps 66208 | wpb 2040.3 | bsz 4 | num_updates 11719 | best_loss 7.217
2022-03-14 21:57:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 11719 updates
2022-03-14 21:57:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:57:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 21:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 114 @ 11719 updates, score 8.561) (writing took 1.0256957886740565 seconds)
2022-03-14 21:57:26 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-14 21:57:26 | INFO | train | epoch 114 | loss 3.943 | ppl 15.38 | wps 40299.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11719 | lr 0.000292116 | gnorm 0.92 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 19062
KL Stats: Epoch 114 Divergences: Uniform: 8.713549410731268 Unigram: 4.173597656325761
2022-03-14 21:57:26 | INFO | fairseq.trainer | begin training epoch 115
2022-03-14 21:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:59:34 | INFO | train_inner | epoch 115:     81 / 103 loss=3.933, ppl=15.28, wps=40251.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=11800, lr=0.000291111, gnorm=0.918, loss_scale=16, train_wall=153, gb_free=20.8, wall=19191
2022-03-14 21:59:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:00:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:00:12 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 8.577 | ppl 381.97 | wps 66204.6 | wpb 2040.3 | bsz 4 | num_updates 11821 | best_loss 7.217
2022-03-14 22:00:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11821 updates
2022-03-14 22:00:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:00:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:00:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 115 @ 11821 updates, score 8.577) (writing took 1.0458557773381472 seconds)
2022-03-14 22:00:13 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-14 22:00:13 | INFO | train | epoch 115 | loss 3.933 | ppl 15.27 | wps 39878.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11821 | lr 0.000290853 | gnorm 0.92 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 19229
KL Stats: Epoch 115 Divergences: Uniform: 8.736574743143905 Unigram: 4.182847793525789
2022-03-14 22:00:13 | INFO | fairseq.trainer | begin training epoch 116
2022-03-14 22:00:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:02:18 | INFO | train_inner | epoch 116:     79 / 103 loss=3.927, ppl=15.21, wps=39851.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=11900, lr=0.000289886, gnorm=0.928, loss_scale=8, train_wall=154, gb_free=20.8, wall=19354
2022-03-14 22:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:02:59 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 8.585 | ppl 384.12 | wps 65867.3 | wpb 2040.3 | bsz 4 | num_updates 11924 | best_loss 7.217
2022-03-14 22:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11924 updates
2022-03-14 22:02:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:03:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 116 @ 11924 updates, score 8.585) (writing took 1.100285285152495 seconds)
2022-03-14 22:03:00 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-14 22:03:00 | INFO | train | epoch 116 | loss 3.924 | ppl 15.18 | wps 40265 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11924 | lr 0.000289594 | gnorm 0.921 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 19396
KL Stats: Epoch 116 Divergences: Uniform: 8.753703525005871 Unigram: 4.19138301801664
2022-03-14 22:03:00 | INFO | fairseq.trainer | begin training epoch 117
2022-03-14 22:03:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:05:00 | INFO | train_inner | epoch 117:     76 / 103 loss=3.916, ppl=15.09, wps=40236, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12000, lr=0.000288675, gnorm=0.905, loss_scale=8, train_wall=153, gb_free=20.8, wall=19517
2022-03-14 22:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:05:46 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 8.598 | ppl 387.42 | wps 66060.7 | wpb 2040.3 | bsz 4 | num_updates 12027 | best_loss 7.217
2022-03-14 22:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 12027 updates
2022-03-14 22:05:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 117 @ 12027 updates, score 8.598) (writing took 1.0789097463712096 seconds)
2022-03-14 22:05:47 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-14 22:05:47 | INFO | train | epoch 117 | loss 3.918 | ppl 15.11 | wps 40279.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12027 | lr 0.000288351 | gnorm 0.914 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 19563
KL Stats: Epoch 117 Divergences: Uniform: 8.767726159385129 Unigram: 4.197723454541694
2022-03-14 22:05:47 | INFO | fairseq.trainer | begin training epoch 118
2022-03-14 22:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:07:42 | INFO | train_inner | epoch 118:     73 / 103 loss=3.908, ppl=15.01, wps=40256.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12100, lr=0.00028748, gnorm=0.922, loss_scale=8, train_wall=153, gb_free=20.8, wall=19679
2022-03-14 22:08:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:08:33 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 8.63 | ppl 396.05 | wps 66725 | wpb 2040.3 | bsz 4 | num_updates 12130 | best_loss 7.217
2022-03-14 22:08:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 12130 updates
2022-03-14 22:08:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:08:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:08:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 118 @ 12130 updates, score 8.63) (writing took 1.0453391829505563 seconds)
2022-03-14 22:08:34 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-14 22:08:34 | INFO | train | epoch 118 | loss 3.909 | ppl 15.02 | wps 40299.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12130 | lr 0.000287124 | gnorm 0.921 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 19730
KL Stats: Epoch 118 Divergences: Uniform: 8.7833428272389 Unigram: 4.2066968258447
2022-03-14 22:08:34 | INFO | fairseq.trainer | begin training epoch 119
2022-03-14 22:08:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:10:25 | INFO | train_inner | epoch 119:     70 / 103 loss=3.904, ppl=14.97, wps=40248.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12200, lr=0.000286299, gnorm=0.92, loss_scale=8, train_wall=153, gb_free=20.8, wall=19841
2022-03-14 22:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:11:20 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 8.613 | ppl 391.57 | wps 66640.9 | wpb 2040.3 | bsz 4 | num_updates 12233 | best_loss 7.217
2022-03-14 22:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 12233 updates
2022-03-14 22:11:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:11:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 119 @ 12233 updates, score 8.613) (writing took 1.0617639748379588 seconds)
2022-03-14 22:11:21 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-14 22:11:21 | INFO | train | epoch 119 | loss 3.9 | ppl 14.93 | wps 40277.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12233 | lr 0.000285913 | gnorm 0.92 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 19897
KL Stats: Epoch 119 Divergences: Uniform: 8.801290364912566 Unigram: 4.214427839267249
2022-03-14 22:11:21 | INFO | fairseq.trainer | begin training epoch 120
2022-03-14 22:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:13:07 | INFO | train_inner | epoch 120:     67 / 103 loss=3.894, ppl=14.86, wps=40262, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12300, lr=0.000285133, gnorm=0.936, loss_scale=8, train_wall=153, gb_free=20.8, wall=20003
2022-03-14 22:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:14:07 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 8.63 | ppl 396.05 | wps 66149.8 | wpb 2040.3 | bsz 4 | num_updates 12336 | best_loss 7.217
2022-03-14 22:14:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 12336 updates
2022-03-14 22:14:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:14:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:14:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 120 @ 12336 updates, score 8.63) (writing took 1.0381477707996964 seconds)
2022-03-14 22:14:08 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-14 22:14:08 | INFO | train | epoch 120 | loss 3.892 | ppl 14.85 | wps 40303.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12336 | lr 0.000284717 | gnorm 0.931 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20064
KL Stats: Epoch 120 Divergences: Uniform: 8.813472840960475 Unigram: 4.22167304019009
2022-03-14 22:14:08 | INFO | fairseq.trainer | begin training epoch 121
2022-03-14 22:14:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:15:49 | INFO | train_inner | epoch 121:     64 / 103 loss=3.889, ppl=14.82, wps=40248, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12400, lr=0.000283981, gnorm=0.925, loss_scale=16, train_wall=153, gb_free=20.8, wall=20166
2022-03-14 22:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:16:54 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 8.612 | ppl 391.21 | wps 66344.3 | wpb 2040.3 | bsz 4 | num_updates 12439 | best_loss 7.217
2022-03-14 22:16:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 12439 updates
2022-03-14 22:16:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 121 @ 12439 updates, score 8.612) (writing took 1.041581954807043 seconds)
2022-03-14 22:16:55 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-14 22:16:55 | INFO | train | epoch 121 | loss 3.885 | ppl 14.78 | wps 40280 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12439 | lr 0.000283535 | gnorm 0.928 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20231
KL Stats: Epoch 121 Divergences: Uniform: 8.826046882564858 Unigram: 4.228420274824989
2022-03-14 22:16:55 | INFO | fairseq.trainer | begin training epoch 122
2022-03-14 22:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:18:31 | INFO | train_inner | epoch 122:     61 / 103 loss=3.882, ppl=14.74, wps=40252.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12500, lr=0.000282843, gnorm=0.923, loss_scale=16, train_wall=153, gb_free=20.8, wall=20328
2022-03-14 22:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:19:41 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 8.63 | ppl 396.14 | wps 66674.2 | wpb 2040.3 | bsz 4 | num_updates 12542 | best_loss 7.217
2022-03-14 22:19:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 12542 updates
2022-03-14 22:19:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:19:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 122 @ 12542 updates, score 8.63) (writing took 1.064478024840355 seconds)
2022-03-14 22:19:42 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-14 22:19:42 | INFO | train | epoch 122 | loss 3.878 | ppl 14.7 | wps 40264.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12542 | lr 0.000282369 | gnorm 0.933 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20398
KL Stats: Epoch 122 Divergences: Uniform: 8.839204174124523 Unigram: 4.234710970657983
2022-03-14 22:19:42 | INFO | fairseq.trainer | begin training epoch 123
2022-03-14 22:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:21:14 | INFO | train_inner | epoch 123:     58 / 103 loss=3.869, ppl=14.61, wps=40232.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12600, lr=0.000281718, gnorm=0.927, loss_scale=16, train_wall=153, gb_free=20.8, wall=20490
2022-03-14 22:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:22:28 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 8.655 | ppl 403.22 | wps 66341.9 | wpb 2040.3 | bsz 4 | num_updates 12645 | best_loss 7.217
2022-03-14 22:22:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 12645 updates
2022-03-14 22:22:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:22:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:22:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 123 @ 12645 updates, score 8.655) (writing took 1.0193721363320947 seconds)
2022-03-14 22:22:29 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-14 22:22:29 | INFO | train | epoch 123 | loss 3.87 | ppl 14.62 | wps 40281.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12645 | lr 0.000281216 | gnorm 0.92 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20565
KL Stats: Epoch 123 Divergences: Uniform: 8.856378535656159 Unigram: 4.24126467268096
2022-03-14 22:22:29 | INFO | fairseq.trainer | begin training epoch 124
2022-03-14 22:22:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:23:56 | INFO | train_inner | epoch 124:     55 / 103 loss=3.866, ppl=14.58, wps=40237.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12700, lr=0.000280607, gnorm=0.934, loss_scale=16, train_wall=153, gb_free=20.8, wall=20652
2022-03-14 22:25:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:25:15 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 8.648 | ppl 401.08 | wps 66220.1 | wpb 2040.3 | bsz 4 | num_updates 12748 | best_loss 7.217
2022-03-14 22:25:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 12748 updates
2022-03-14 22:25:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:25:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 124 @ 12748 updates, score 8.648) (writing took 1.051102208904922 seconds)
2022-03-14 22:25:16 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-14 22:25:16 | INFO | train | epoch 124 | loss 3.863 | ppl 14.55 | wps 40265.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12748 | lr 0.000280078 | gnorm 0.934 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20733
KL Stats: Epoch 124 Divergences: Uniform: 8.867632166170468 Unigram: 4.248690720067475
2022-03-14 22:25:16 | INFO | fairseq.trainer | begin training epoch 125
2022-03-14 22:25:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:26:38 | INFO | train_inner | epoch 125:     52 / 103 loss=3.861, ppl=14.53, wps=40247.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12800, lr=0.000279508, gnorm=0.933, loss_scale=16, train_wall=153, gb_free=20.8, wall=20815
2022-03-14 22:27:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:28:02 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 8.654 | ppl 402.96 | wps 66529.8 | wpb 2040.3 | bsz 4 | num_updates 12850 | best_loss 7.217
2022-03-14 22:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12850 updates
2022-03-14 22:28:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:28:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 125 @ 12850 updates, score 8.654) (writing took 1.0101746572181582 seconds)
2022-03-14 22:28:03 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-14 22:28:03 | INFO | train | epoch 125 | loss 3.855 | ppl 14.47 | wps 39910.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12850 | lr 0.000278964 | gnorm 0.93 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20899
KL Stats: Epoch 125 Divergences: Uniform: 8.88121027916659 Unigram: 4.253884515906134
2022-03-14 22:28:03 | INFO | fairseq.trainer | begin training epoch 126
2022-03-14 22:28:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:29:22 | INFO | train_inner | epoch 126:     50 / 103 loss=3.851, ppl=14.43, wps=39862.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12900, lr=0.000278423, gnorm=0.931, loss_scale=16, train_wall=154, gb_free=20.8, wall=20979
2022-03-14 22:30:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:30:49 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 8.676 | ppl 408.91 | wps 66946.9 | wpb 2040.3 | bsz 4 | num_updates 12953 | best_loss 7.217
2022-03-14 22:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12953 updates
2022-03-14 22:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:30:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:30:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 126 @ 12953 updates, score 8.676) (writing took 1.0187517227604985 seconds)
2022-03-14 22:30:50 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-14 22:30:50 | INFO | train | epoch 126 | loss 3.847 | ppl 14.39 | wps 40298.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12953 | lr 0.000277853 | gnorm 0.932 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21066
KL Stats: Epoch 126 Divergences: Uniform: 8.898806849399355 Unigram: 4.264719733406227
2022-03-14 22:30:50 | INFO | fairseq.trainer | begin training epoch 127
2022-03-14 22:30:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:32:04 | INFO | train_inner | epoch 127:     47 / 103 loss=3.839, ppl=14.31, wps=40272.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13000, lr=0.00027735, gnorm=0.923, loss_scale=16, train_wall=153, gb_free=20.8, wall=21141
2022-03-14 22:33:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:33:36 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 8.687 | ppl 412.14 | wps 66582.7 | wpb 2040.3 | bsz 4 | num_updates 13056 | best_loss 7.217
2022-03-14 22:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 13056 updates
2022-03-14 22:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:33:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 127 @ 13056 updates, score 8.687) (writing took 0.990157388150692 seconds)
2022-03-14 22:33:37 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-14 22:33:37 | INFO | train | epoch 127 | loss 3.841 | ppl 14.33 | wps 40311.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13056 | lr 0.000276755 | gnorm 0.924 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21233
KL Stats: Epoch 127 Divergences: Uniform: 8.905549901195553 Unigram: 4.269943937671321
2022-03-14 22:33:37 | INFO | fairseq.trainer | begin training epoch 128
2022-03-14 22:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:34:46 | INFO | train_inner | epoch 128:     44 / 103 loss=3.843, ppl=14.35, wps=40280.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13100, lr=0.000276289, gnorm=0.944, loss_scale=16, train_wall=153, gb_free=20.8, wall=21303
2022-03-14 22:36:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:36:23 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 8.692 | ppl 413.66 | wps 66372.4 | wpb 2040.3 | bsz 4 | num_updates 13158 | best_loss 7.217
2022-03-14 22:36:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 13158 updates
2022-03-14 22:36:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:36:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:36:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 128 @ 13158 updates, score 8.692) (writing took 1.0109476698562503 seconds)
2022-03-14 22:36:24 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-14 22:36:24 | INFO | train | epoch 128 | loss 3.834 | ppl 14.26 | wps 39915.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13158 | lr 0.00027568 | gnorm 0.947 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 21400
KL Stats: Epoch 128 Divergences: Uniform: 8.919852648135624 Unigram: 4.274235503451708
2022-03-14 22:36:24 | INFO | fairseq.trainer | begin training epoch 129
2022-03-14 22:36:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:37:30 | INFO | train_inner | epoch 129:     42 / 103 loss=3.828, ppl=14.2, wps=39888.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=13200, lr=0.000275241, gnorm=0.941, loss_scale=8, train_wall=154, gb_free=20.8, wall=21467
2022-03-14 22:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:39:10 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 8.701 | ppl 416.17 | wps 66372.7 | wpb 2040.3 | bsz 4 | num_updates 13261 | best_loss 7.217
2022-03-14 22:39:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 13261 updates
2022-03-14 22:39:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:39:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:39:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 129 @ 13261 updates, score 8.701) (writing took 1.037963628768921 seconds)
2022-03-14 22:39:11 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-14 22:39:11 | INFO | train | epoch 129 | loss 3.827 | ppl 14.19 | wps 40296.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13261 | lr 0.000274607 | gnorm 0.942 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 21567
KL Stats: Epoch 129 Divergences: Uniform: 8.934296004760787 Unigram: 4.282038271203555
2022-03-14 22:39:11 | INFO | fairseq.trainer | begin training epoch 130
2022-03-14 22:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:40:12 | INFO | train_inner | epoch 130:     39 / 103 loss=3.823, ppl=14.15, wps=40260, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13300, lr=0.000274204, gnorm=0.931, loss_scale=8, train_wall=153, gb_free=20.8, wall=21629
2022-03-14 22:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:41:57 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 8.687 | ppl 412.1 | wps 66402.9 | wpb 2040.3 | bsz 4 | num_updates 13364 | best_loss 7.217
2022-03-14 22:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 13364 updates
2022-03-14 22:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:41:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 130 @ 13364 updates, score 8.687) (writing took 0.9713799208402634 seconds)
2022-03-14 22:41:58 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-14 22:41:58 | INFO | train | epoch 130 | loss 3.821 | ppl 14.13 | wps 40315.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13364 | lr 0.000273547 | gnorm 0.936 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 21734
KL Stats: Epoch 130 Divergences: Uniform: 8.943920423810033 Unigram: 4.286573341498703
2022-03-14 22:41:58 | INFO | fairseq.trainer | begin training epoch 131
2022-03-14 22:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:42:55 | INFO | train_inner | epoch 131:     36 / 103 loss=3.821, ppl=14.13, wps=40274.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=0.945, loss_scale=8, train_wall=153, gb_free=20.8, wall=21791
2022-03-14 22:44:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:44:43 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 8.717 | ppl 420.8 | wps 66757.4 | wpb 2040.3 | bsz 4 | num_updates 13467 | best_loss 7.217
2022-03-14 22:44:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 13467 updates
2022-03-14 22:44:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:44:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 131 @ 13467 updates, score 8.717) (writing took 1.0452668499201536 seconds)
2022-03-14 22:44:44 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-14 22:44:44 | INFO | train | epoch 131 | loss 3.814 | ppl 14.06 | wps 40290.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13467 | lr 0.000272499 | gnorm 0.947 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 21901
KL Stats: Epoch 131 Divergences: Uniform: 8.9597106215269 Unigram: 4.29316152275902
2022-03-14 22:44:45 | INFO | fairseq.trainer | begin training epoch 132
2022-03-14 22:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:45:37 | INFO | train_inner | epoch 132:     33 / 103 loss=3.812, ppl=14.04, wps=40243.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13500, lr=0.000272166, gnorm=0.946, loss_scale=8, train_wall=153, gb_free=20.8, wall=21953
2022-03-14 22:47:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:47:30 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 8.716 | ppl 420.51 | wps 66509.9 | wpb 2040.3 | bsz 4 | num_updates 13570 | best_loss 7.217
2022-03-14 22:47:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 13570 updates
2022-03-14 22:47:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 132 @ 13570 updates, score 8.716) (writing took 1.024443170055747 seconds)
2022-03-14 22:47:31 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-14 22:47:31 | INFO | train | epoch 132 | loss 3.807 | ppl 13.99 | wps 40282.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13570 | lr 0.000271463 | gnorm 0.93 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 22068
KL Stats: Epoch 132 Divergences: Uniform: 8.971990211994694 Unigram: 4.300009193294142
2022-03-14 22:47:32 | INFO | fairseq.trainer | begin training epoch 133
2022-03-14 22:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:48:19 | INFO | train_inner | epoch 133:     30 / 103 loss=3.806, ppl=13.99, wps=40269.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13600, lr=0.000271163, gnorm=0.923, loss_scale=8, train_wall=153, gb_free=20.8, wall=22115
2022-03-14 22:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:50:17 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 8.736 | ppl 426.47 | wps 66555.2 | wpb 2040.3 | bsz 4 | num_updates 13673 | best_loss 7.217
2022-03-14 22:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 13673 updates
2022-03-14 22:50:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:50:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 133 @ 13673 updates, score 8.736) (writing took 0.9821472344920039 seconds)
2022-03-14 22:50:18 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-14 22:50:18 | INFO | train | epoch 133 | loss 3.8 | ppl 13.93 | wps 40305.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13673 | lr 0.000270438 | gnorm 0.93 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22235
KL Stats: Epoch 133 Divergences: Uniform: 8.984995354374966 Unigram: 4.3063021507277215
2022-03-14 22:50:18 | INFO | fairseq.trainer | begin training epoch 134
2022-03-14 22:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:51:01 | INFO | train_inner | epoch 134:     27 / 103 loss=3.8, ppl=13.93, wps=40273.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13700, lr=0.000270172, gnorm=0.935, loss_scale=16, train_wall=153, gb_free=20.8, wall=22278
2022-03-14 22:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:53:04 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 8.732 | ppl 425.31 | wps 66393.4 | wpb 2040.3 | bsz 4 | num_updates 13776 | best_loss 7.217
2022-03-14 22:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 13776 updates
2022-03-14 22:53:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 134 @ 13776 updates, score 8.732) (writing took 1.0297715244814754 seconds)
2022-03-14 22:53:05 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-14 22:53:05 | INFO | train | epoch 134 | loss 3.793 | ppl 13.86 | wps 40296.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13776 | lr 0.000269425 | gnorm 0.946 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22402
KL Stats: Epoch 134 Divergences: Uniform: 8.992254672764242 Unigram: 4.312066910292305
2022-03-14 22:53:05 | INFO | fairseq.trainer | begin training epoch 135
2022-03-14 22:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:53:43 | INFO | train_inner | epoch 135:     24 / 103 loss=3.792, ppl=13.86, wps=40260.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13800, lr=0.000269191, gnorm=0.94, loss_scale=16, train_wall=153, gb_free=20.8, wall=22440
2022-03-14 22:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:55:51 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 8.724 | ppl 422.76 | wps 66975.6 | wpb 2040.3 | bsz 4 | num_updates 13879 | best_loss 7.217
2022-03-14 22:55:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13879 updates
2022-03-14 22:55:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:55:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 135 @ 13879 updates, score 8.724) (writing took 0.99850201793015 seconds)
2022-03-14 22:55:52 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-14 22:55:52 | INFO | train | epoch 135 | loss 3.787 | ppl 13.81 | wps 40296.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13879 | lr 0.000268424 | gnorm 0.927 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22569
KL Stats: Epoch 135 Divergences: Uniform: 9.00452833031854 Unigram: 4.317402911633417
2022-03-14 22:55:52 | INFO | fairseq.trainer | begin training epoch 136
2022-03-14 22:55:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:56:26 | INFO | train_inner | epoch 136:     21 / 103 loss=3.787, ppl=13.81, wps=40260.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13900, lr=0.000268221, gnorm=0.929, loss_scale=16, train_wall=153, gb_free=20.8, wall=22602
2022-03-14 22:56:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 22:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:58:38 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 8.758 | ppl 432.79 | wps 66723 | wpb 2040.3 | bsz 4 | num_updates 13981 | best_loss 7.217
2022-03-14 22:58:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13981 updates
2022-03-14 22:58:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 22:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 136 @ 13981 updates, score 8.758) (writing took 0.988891338929534 seconds)
2022-03-14 22:58:39 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-14 22:58:39 | INFO | train | epoch 136 | loss 3.78 | ppl 13.74 | wps 39913 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13981 | lr 0.000267443 | gnorm 0.942 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 22736
KL Stats: Epoch 136 Divergences: Uniform: 9.018330589117658 Unigram: 4.323856239697652
2022-03-14 22:58:39 | INFO | fairseq.trainer | begin training epoch 137
2022-03-14 22:58:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:59:09 | INFO | train_inner | epoch 137:     19 / 103 loss=3.781, ppl=13.75, wps=39883.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14000, lr=0.000267261, gnorm=0.945, loss_scale=8, train_wall=154, gb_free=20.8, wall=22766
2022-03-14 23:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:01:25 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 8.745 | ppl 429.09 | wps 66518.3 | wpb 2040.3 | bsz 4 | num_updates 14084 | best_loss 7.217
2022-03-14 23:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 14084 updates
2022-03-14 23:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 137 @ 14084 updates, score 8.745) (writing took 0.9899058993905783 seconds)
2022-03-14 23:01:26 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-14 23:01:26 | INFO | train | epoch 137 | loss 3.776 | ppl 13.7 | wps 40298.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14084 | lr 0.000266463 | gnorm 0.941 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 22903
KL Stats: Epoch 137 Divergences: Uniform: 9.030060536565918 Unigram: 4.327675468862911
2022-03-14 23:01:26 | INFO | fairseq.trainer | begin training epoch 138
2022-03-14 23:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:01:51 | INFO | train_inner | epoch 138:     16 / 103 loss=3.777, ppl=13.71, wps=40265.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14100, lr=0.000266312, gnorm=0.939, loss_scale=8, train_wall=153, gb_free=20.8, wall=22928
2022-03-14 23:04:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:04:12 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 8.77 | ppl 436.49 | wps 66575.4 | wpb 2040.3 | bsz 4 | num_updates 14187 | best_loss 7.217
2022-03-14 23:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 14187 updates
2022-03-14 23:04:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:04:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:04:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 138 @ 14187 updates, score 8.77) (writing took 0.9864754807204008 seconds)
2022-03-14 23:04:13 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-14 23:04:13 | INFO | train | epoch 138 | loss 3.769 | ppl 13.63 | wps 40308.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14187 | lr 0.000265494 | gnorm 0.938 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 23069
KL Stats: Epoch 138 Divergences: Uniform: 9.040834055651896 Unigram: 4.334353945859437
2022-03-14 23:04:13 | INFO | fairseq.trainer | begin training epoch 139
2022-03-14 23:04:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:04:34 | INFO | train_inner | epoch 139:     13 / 103 loss=3.771, ppl=13.65, wps=40270.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14200, lr=0.000265372, gnorm=0.939, loss_scale=8, train_wall=153, gb_free=20.8, wall=23090
2022-03-14 23:06:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:06:59 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 8.769 | ppl 436.13 | wps 66179.3 | wpb 2040.3 | bsz 4 | num_updates 14290 | best_loss 7.217
2022-03-14 23:06:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 14290 updates
2022-03-14 23:06:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:07:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 139 @ 14290 updates, score 8.769) (writing took 1.0227816263213754 seconds)
2022-03-14 23:07:00 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-14 23:07:00 | INFO | train | epoch 139 | loss 3.763 | ppl 13.58 | wps 40278.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14290 | lr 0.000264535 | gnorm 0.94 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 23236
KL Stats: Epoch 139 Divergences: Uniform: 9.050480680756817 Unigram: 4.339326228513223
2022-03-14 23:07:00 | INFO | fairseq.trainer | begin training epoch 140
2022-03-14 23:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:07:16 | INFO | train_inner | epoch 140:     10 / 103 loss=3.765, ppl=13.6, wps=40248.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14300, lr=0.000264443, gnorm=0.94, loss_scale=8, train_wall=153, gb_free=20.8, wall=23252
2022-03-14 23:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:09:46 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 8.776 | ppl 438.48 | wps 67059 | wpb 2040.3 | bsz 4 | num_updates 14393 | best_loss 7.217
2022-03-14 23:09:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 14393 updates
2022-03-14 23:09:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 140 @ 14393 updates, score 8.776) (writing took 1.0313967568799853 seconds)
2022-03-14 23:09:47 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-14 23:09:47 | INFO | train | epoch 140 | loss 3.758 | ppl 13.52 | wps 40303.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14393 | lr 0.000263587 | gnorm 0.934 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 23403
KL Stats: Epoch 140 Divergences: Uniform: 9.063308132462048 Unigram: 4.344427547966921
2022-03-14 23:09:47 | INFO | fairseq.trainer | begin training epoch 141
2022-03-14 23:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:09:58 | INFO | train_inner | epoch 141:      7 / 103 loss=3.756, ppl=13.51, wps=40269.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14400, lr=0.000263523, gnorm=0.932, loss_scale=8, train_wall=153, gb_free=20.8, wall=23415
2022-03-14 23:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:12:33 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 8.795 | ppl 444.18 | wps 66833 | wpb 2040.3 | bsz 4 | num_updates 14496 | best_loss 7.217
2022-03-14 23:12:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 14496 updates
2022-03-14 23:12:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:12:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 141 @ 14496 updates, score 8.795) (writing took 0.9821861749514937 seconds)
2022-03-14 23:12:34 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-14 23:12:34 | INFO | train | epoch 141 | loss 3.75 | ppl 13.46 | wps 40286.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14496 | lr 0.000262649 | gnorm 0.942 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23570
KL Stats: Epoch 141 Divergences: Uniform: 9.069247722029466 Unigram: 4.35004715563489
2022-03-14 23:12:34 | INFO | fairseq.trainer | begin training epoch 142
2022-03-14 23:12:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:12:40 | INFO | train_inner | epoch 142:      4 / 103 loss=3.754, ppl=13.5, wps=40257.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14500, lr=0.000262613, gnorm=0.945, loss_scale=16, train_wall=153, gb_free=20.8, wall=23577
2022-03-14 23:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:15:20 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 8.779 | ppl 439.37 | wps 66556.8 | wpb 2040.3 | bsz 4 | num_updates 14599 | best_loss 7.217
2022-03-14 23:15:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 14599 updates
2022-03-14 23:15:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:15:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 142 @ 14599 updates, score 8.779) (writing took 1.0001031337305903 seconds)
2022-03-14 23:15:21 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-14 23:15:21 | INFO | train | epoch 142 | loss 3.746 | ppl 13.41 | wps 40308.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14599 | lr 0.000261721 | gnorm 0.952 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23737
KL Stats: Epoch 142 Divergences: Uniform: 9.07948589654651 Unigram: 4.356115072095337
2022-03-14 23:15:21 | INFO | fairseq.trainer | begin training epoch 143
2022-03-14 23:15:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:15:22 | INFO | train_inner | epoch 143:      1 / 103 loss=3.747, ppl=13.43, wps=40273.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14600, lr=0.000261712, gnorm=0.954, loss_scale=16, train_wall=153, gb_free=20.8, wall=23739
2022-03-14 23:18:01 | INFO | train_inner | epoch 143:    101 / 103 loss=3.739, ppl=13.36, wps=41446.6, ups=0.63, wpb=65530.9, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.941, loss_scale=16, train_wall=153, gb_free=20.8, wall=23897
2022-03-14 23:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:18:07 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 8.783 | ppl 440.41 | wps 66785.2 | wpb 2040.3 | bsz 4 | num_updates 14702 | best_loss 7.217
2022-03-14 23:18:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 14702 updates
2022-03-14 23:18:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:18:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 143 @ 14702 updates, score 8.783) (writing took 0.9721893528476357 seconds)
2022-03-14 23:18:08 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-14 23:18:08 | INFO | train | epoch 143 | loss 3.739 | ppl 13.36 | wps 40309.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14702 | lr 0.000260803 | gnorm 0.944 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23904
KL Stats: Epoch 143 Divergences: Uniform: 9.088726913828147 Unigram: 4.359380338050811
2022-03-14 23:18:08 | INFO | fairseq.trainer | begin training epoch 144
2022-03-14 23:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:20:43 | INFO | train_inner | epoch 144:     98 / 103 loss=3.731, ppl=13.28, wps=40261.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14800, lr=0.000259938, gnorm=0.949, loss_scale=16, train_wall=153, gb_free=20.8, wall=24059
2022-03-14 23:20:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:20:54 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 8.808 | ppl 448.29 | wps 66562.7 | wpb 2040.3 | bsz 4 | num_updates 14805 | best_loss 7.217
2022-03-14 23:20:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 14805 updates
2022-03-14 23:20:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:20:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:20:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 144 @ 14805 updates, score 8.808) (writing took 0.9674841454252601 seconds)
2022-03-14 23:20:55 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-14 23:20:55 | INFO | train | epoch 144 | loss 3.734 | ppl 13.31 | wps 40292.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14805 | lr 0.000259894 | gnorm 0.948 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24071
KL Stats: Epoch 144 Divergences: Uniform: 9.097821376585882 Unigram: 4.36450537098993
2022-03-14 23:20:55 | INFO | fairseq.trainer | begin training epoch 145
2022-03-14 23:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:23:25 | INFO | train_inner | epoch 145:     95 / 103 loss=3.73, ppl=13.27, wps=40276.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14900, lr=0.000259064, gnorm=0.948, loss_scale=16, train_wall=153, gb_free=20.8, wall=24221
2022-03-14 23:23:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:23:41 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 8.826 | ppl 453.71 | wps 66562.4 | wpb 2040.3 | bsz 4 | num_updates 14908 | best_loss 7.217
2022-03-14 23:23:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 14908 updates
2022-03-14 23:23:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 145 @ 14908 updates, score 8.826) (writing took 0.9497203920036554 seconds)
2022-03-14 23:23:42 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-14 23:23:42 | INFO | train | epoch 145 | loss 3.73 | ppl 13.27 | wps 40314.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14908 | lr 0.000258994 | gnorm 0.949 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24238
KL Stats: Epoch 145 Divergences: Uniform: 9.104515772963675 Unigram: 4.36895009377898
2022-03-14 23:23:42 | INFO | fairseq.trainer | begin training epoch 146
2022-03-14 23:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:24:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:26:09 | INFO | train_inner | epoch 146:     93 / 103 loss=3.72, ppl=13.17, wps=39893.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15000, lr=0.000258199, gnorm=0.947, loss_scale=16, train_wall=154, gb_free=20.8, wall=24385
2022-03-14 23:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:26:27 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 8.826 | ppl 453.69 | wps 66746.5 | wpb 2040.3 | bsz 4 | num_updates 15010 | best_loss 7.217
2022-03-14 23:26:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 15010 updates
2022-03-14 23:26:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 146 @ 15010 updates, score 8.826) (writing took 0.9788395324721932 seconds)
2022-03-14 23:26:28 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-14 23:26:28 | INFO | train | epoch 146 | loss 3.721 | ppl 13.19 | wps 39916.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15010 | lr 0.000258113 | gnorm 0.949 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24405
KL Stats: Epoch 146 Divergences: Uniform: 9.119098749893823 Unigram: 4.37669212184175
2022-03-14 23:26:28 | INFO | fairseq.trainer | begin training epoch 147
2022-03-14 23:26:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:28:51 | INFO | train_inner | epoch 147:     90 / 103 loss=3.715, ppl=13.13, wps=40259.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15100, lr=0.000257343, gnorm=0.945, loss_scale=16, train_wall=153, gb_free=20.8, wall=24547
2022-03-14 23:29:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:29:14 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 8.829 | ppl 454.63 | wps 66688.5 | wpb 2040.3 | bsz 4 | num_updates 15113 | best_loss 7.217
2022-03-14 23:29:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 15113 updates
2022-03-14 23:29:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 147 @ 15113 updates, score 8.829) (writing took 0.9809000054374337 seconds)
2022-03-14 23:29:15 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-14 23:29:15 | INFO | train | epoch 147 | loss 3.717 | ppl 13.15 | wps 40290.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15113 | lr 0.000257232 | gnorm 0.948 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24572
KL Stats: Epoch 147 Divergences: Uniform: 9.125075474886739 Unigram: 4.38072971226144
2022-03-14 23:29:15 | INFO | fairseq.trainer | begin training epoch 148
2022-03-14 23:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:31:33 | INFO | train_inner | epoch 148:     87 / 103 loss=3.711, ppl=13.09, wps=40261.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15200, lr=0.000256495, gnorm=0.948, loss_scale=16, train_wall=153, gb_free=20.8, wall=24709
2022-03-14 23:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:32:01 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 8.825 | ppl 453.41 | wps 66295.1 | wpb 2040.3 | bsz 4 | num_updates 15216 | best_loss 7.217
2022-03-14 23:32:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 15216 updates
2022-03-14 23:32:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:32:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:32:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 148 @ 15216 updates, score 8.825) (writing took 0.9746761899441481 seconds)
2022-03-14 23:32:02 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-14 23:32:02 | INFO | train | epoch 148 | loss 3.712 | ppl 13.11 | wps 40293.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15216 | lr 0.00025636 | gnorm 0.946 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24739
KL Stats: Epoch 148 Divergences: Uniform: 9.134796320756335 Unigram: 4.3847241761185485
2022-03-14 23:32:02 | INFO | fairseq.trainer | begin training epoch 149
2022-03-14 23:32:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:34:15 | INFO | train_inner | epoch 149:     84 / 103 loss=3.707, ppl=13.06, wps=40276.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15300, lr=0.000255655, gnorm=0.949, loss_scale=16, train_wall=153, gb_free=20.8, wall=24872
2022-03-14 23:34:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:34:48 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 8.832 | ppl 455.87 | wps 66552.7 | wpb 2040.3 | bsz 4 | num_updates 15319 | best_loss 7.217
2022-03-14 23:34:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 15319 updates
2022-03-14 23:34:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:34:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:34:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 149 @ 15319 updates, score 8.832) (writing took 0.9837719080969691 seconds)
2022-03-14 23:34:49 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-14 23:34:49 | INFO | train | epoch 149 | loss 3.706 | ppl 13.05 | wps 40308.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15319 | lr 0.000255496 | gnorm 0.948 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24906
KL Stats: Epoch 149 Divergences: Uniform: 9.146602416801382 Unigram: 4.391740507621807
2022-03-14 23:34:49 | INFO | fairseq.trainer | begin training epoch 150
2022-03-14 23:34:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:36:57 | INFO | train_inner | epoch 150:     81 / 103 loss=3.701, ppl=13.01, wps=40256.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15400, lr=0.000254824, gnorm=0.946, loss_scale=16, train_wall=153, gb_free=20.8, wall=25034
2022-03-14 23:37:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:37:35 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 8.837 | ppl 457.32 | wps 66466 | wpb 2040.3 | bsz 4 | num_updates 15422 | best_loss 7.217
2022-03-14 23:37:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 15422 updates
2022-03-14 23:37:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:37:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 150 @ 15422 updates, score 8.837) (writing took 0.978460299782455 seconds)
2022-03-14 23:37:36 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-14 23:37:36 | INFO | train | epoch 150 | loss 3.703 | ppl 13.02 | wps 40298 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15422 | lr 0.000254642 | gnorm 0.945 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25073
KL Stats: Epoch 150 Divergences: Uniform: 9.152174167555893 Unigram: 4.393445553907624
2022-03-14 23:37:36 | INFO | fairseq.trainer | begin training epoch 151
2022-03-14 23:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:38:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:39:41 | INFO | train_inner | epoch 151:     79 / 103 loss=3.701, ppl=13, wps=39885.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=15500, lr=0.000254, gnorm=0.948, loss_scale=16, train_wall=154, gb_free=20.8, wall=25198
2022-03-14 23:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:40:22 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 8.856 | ppl 463.26 | wps 66565.2 | wpb 2040.3 | bsz 4 | num_updates 15524 | best_loss 7.217
2022-03-14 23:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 15524 updates
2022-03-14 23:40:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 151 @ 15524 updates, score 8.856) (writing took 0.9433211628347635 seconds)
2022-03-14 23:40:23 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-14 23:40:23 | INFO | train | epoch 151 | loss 3.696 | ppl 12.96 | wps 39920.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15524 | lr 0.000253804 | gnorm 0.953 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25239
KL Stats: Epoch 151 Divergences: Uniform: 9.164584961302275 Unigram: 4.4000041460806765
2022-03-14 23:40:23 | INFO | fairseq.trainer | begin training epoch 152
2022-03-14 23:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:42:23 | INFO | train_inner | epoch 152:     76 / 103 loss=3.688, ppl=12.89, wps=40292.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15600, lr=0.000253185, gnorm=0.955, loss_scale=16, train_wall=153, gb_free=20.8, wall=25360
2022-03-14 23:43:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:43:09 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 8.851 | ppl 461.81 | wps 66771.5 | wpb 2040.3 | bsz 4 | num_updates 15627 | best_loss 7.217
2022-03-14 23:43:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 15627 updates
2022-03-14 23:43:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:43:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 152 @ 15627 updates, score 8.851) (writing took 1.0205792840570211 seconds)
2022-03-14 23:43:10 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-14 23:43:10 | INFO | train | epoch 152 | loss 3.691 | ppl 12.91 | wps 40309.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15627 | lr 0.000252966 | gnorm 0.952 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25406
KL Stats: Epoch 152 Divergences: Uniform: 9.170761870636401 Unigram: 4.4045807093809355
2022-03-14 23:43:10 | INFO | fairseq.trainer | begin training epoch 153
2022-03-14 23:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:45:05 | INFO | train_inner | epoch 153:     73 / 103 loss=3.688, ppl=12.89, wps=40271.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15700, lr=0.000252377, gnorm=0.946, loss_scale=16, train_wall=153, gb_free=20.8, wall=25522
2022-03-14 23:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:45:56 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 8.853 | ppl 462.38 | wps 66727 | wpb 2040.3 | bsz 4 | num_updates 15730 | best_loss 7.217
2022-03-14 23:45:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 15730 updates
2022-03-14 23:45:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 153 @ 15730 updates, score 8.853) (writing took 0.9376666462048888 seconds)
2022-03-14 23:45:57 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-14 23:45:57 | INFO | train | epoch 153 | loss 3.686 | ppl 12.87 | wps 40319 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15730 | lr 0.000252136 | gnorm 0.94 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25573
KL Stats: Epoch 153 Divergences: Uniform: 9.17627505715957 Unigram: 4.406711255123002
2022-03-14 23:45:57 | INFO | fairseq.trainer | begin training epoch 154
2022-03-14 23:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:47:47 | INFO | train_inner | epoch 154:     70 / 103 loss=3.679, ppl=12.81, wps=40283.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15800, lr=0.000251577, gnorm=0.949, loss_scale=16, train_wall=153, gb_free=20.8, wall=25684
2022-03-14 23:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:48:43 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 8.871 | ppl 468.12 | wps 66674 | wpb 2040.3 | bsz 4 | num_updates 15833 | best_loss 7.217
2022-03-14 23:48:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 15833 updates
2022-03-14 23:48:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:48:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 154 @ 15833 updates, score 8.871) (writing took 0.9678639313206077 seconds)
2022-03-14 23:48:44 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-14 23:48:44 | INFO | train | epoch 154 | loss 3.681 | ppl 12.83 | wps 40312.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15833 | lr 0.000251315 | gnorm 0.953 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25740
KL Stats: Epoch 154 Divergences: Uniform: 9.18652395996902 Unigram: 4.413013003266178
2022-03-14 23:48:44 | INFO | fairseq.trainer | begin training epoch 155
2022-03-14 23:48:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:50:30 | INFO | train_inner | epoch 155:     67 / 103 loss=3.678, ppl=12.8, wps=40279.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15900, lr=0.000250785, gnorm=0.951, loss_scale=16, train_wall=153, gb_free=20.8, wall=25846
2022-03-14 23:51:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:51:30 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 8.862 | ppl 465.16 | wps 66569.4 | wpb 2040.3 | bsz 4 | num_updates 15936 | best_loss 7.217
2022-03-14 23:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 15936 updates
2022-03-14 23:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:51:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 155 @ 15936 updates, score 8.862) (writing took 1.0151576222851872 seconds)
2022-03-14 23:51:31 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-14 23:51:31 | INFO | train | epoch 155 | loss 3.676 | ppl 12.78 | wps 40275.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15936 | lr 0.000250502 | gnorm 0.954 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25907
KL Stats: Epoch 155 Divergences: Uniform: 9.193853258621873 Unigram: 4.418355623927788
2022-03-14 23:51:31 | INFO | fairseq.trainer | begin training epoch 156
2022-03-14 23:51:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:52:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:53:14 | INFO | train_inner | epoch 156:     65 / 103 loss=3.671, ppl=12.74, wps=39839.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=16000, lr=0.00025, gnorm=0.955, loss_scale=16, train_wall=154, gb_free=20.8, wall=26010
2022-03-14 23:54:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:54:17 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 8.878 | ppl 470.64 | wps 66170.2 | wpb 2040.3 | bsz 4 | num_updates 16038 | best_loss 7.217
2022-03-14 23:54:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 16038 updates
2022-03-14 23:54:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:54:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 156 @ 16038 updates, score 8.878) (writing took 0.9817298678681254 seconds)
2022-03-14 23:54:18 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-14 23:54:18 | INFO | train | epoch 156 | loss 3.67 | ppl 12.72 | wps 39902.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16038 | lr 0.000249704 | gnorm 0.951 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26074
KL Stats: Epoch 156 Divergences: Uniform: 9.199872508860985 Unigram: 4.421942732412178
2022-03-14 23:54:18 | INFO | fairseq.trainer | begin training epoch 157
2022-03-14 23:54:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:55:56 | INFO | train_inner | epoch 157:     62 / 103 loss=3.668, ppl=12.71, wps=40273.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16100, lr=0.000249222, gnorm=0.949, loss_scale=16, train_wall=153, gb_free=20.8, wall=26172
2022-03-14 23:57:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:57:04 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 8.893 | ppl 475.39 | wps 66521.1 | wpb 2040.3 | bsz 4 | num_updates 16141 | best_loss 7.217
2022-03-14 23:57:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 16141 updates
2022-03-14 23:57:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:57:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 157 @ 16141 updates, score 8.893) (writing took 1.012930071912706 seconds)
2022-03-14 23:57:05 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-14 23:57:05 | INFO | train | epoch 157 | loss 3.668 | ppl 12.71 | wps 40301.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16141 | lr 0.000248906 | gnorm 0.957 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26241
KL Stats: Epoch 157 Divergences: Uniform: 9.20730768830165 Unigram: 4.425383140883844
2022-03-14 23:57:05 | INFO | fairseq.trainer | begin training epoch 158
2022-03-14 23:57:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:58:38 | INFO | train_inner | epoch 158:     59 / 103 loss=3.664, ppl=12.68, wps=40262.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16200, lr=0.000248452, gnorm=0.961, loss_scale=16, train_wall=153, gb_free=20.8, wall=26334
2022-03-14 23:59:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:59:50 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 8.88 | ppl 471.01 | wps 66724.5 | wpb 2040.3 | bsz 4 | num_updates 16244 | best_loss 7.217
2022-03-14 23:59:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 16244 updates
2022-03-14 23:59:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:59:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-14 23:59:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 158 @ 16244 updates, score 8.88) (writing took 0.9962475849315524 seconds)
2022-03-14 23:59:52 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-14 23:59:52 | INFO | train | epoch 158 | loss 3.662 | ppl 12.66 | wps 40280.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16244 | lr 0.000248115 | gnorm 0.961 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26408
KL Stats: Epoch 158 Divergences: Uniform: 9.216980142372416 Unigram: 4.429375835866251
2022-03-14 23:59:52 | INFO | fairseq.trainer | begin training epoch 159
2022-03-14 23:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:01:20 | INFO | train_inner | epoch 159:     56 / 103 loss=3.659, ppl=12.63, wps=40248.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16300, lr=0.000247689, gnorm=0.96, loss_scale=16, train_wall=153, gb_free=20.8, wall=26497
2022-03-15 00:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:02:37 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 8.893 | ppl 475.37 | wps 66256.5 | wpb 2040.3 | bsz 4 | num_updates 16347 | best_loss 7.217
2022-03-15 00:02:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 16347 updates
2022-03-15 00:02:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:02:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 159 @ 16347 updates, score 8.893) (writing took 1.001793789677322 seconds)
2022-03-15 00:02:39 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-15 00:02:39 | INFO | train | epoch 159 | loss 3.657 | ppl 12.62 | wps 40290.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16347 | lr 0.000247332 | gnorm 0.964 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26575
KL Stats: Epoch 159 Divergences: Uniform: 9.22607311334361 Unigram: 4.434601875717651
2022-03-15 00:02:39 | INFO | fairseq.trainer | begin training epoch 160
2022-03-15 00:02:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:04:02 | INFO | train_inner | epoch 160:     53 / 103 loss=3.655, ppl=12.6, wps=40249.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16400, lr=0.000246932, gnorm=0.956, loss_scale=16, train_wall=153, gb_free=20.8, wall=26659
2022-03-15 00:05:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:05:24 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 8.911 | ppl 481.28 | wps 66292.6 | wpb 2040.3 | bsz 4 | num_updates 16450 | best_loss 7.217
2022-03-15 00:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 16450 updates
2022-03-15 00:05:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:05:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 160 @ 16450 updates, score 8.911) (writing took 0.8970813984051347 seconds)
2022-03-15 00:05:25 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-15 00:05:25 | INFO | train | epoch 160 | loss 3.652 | ppl 12.57 | wps 40316.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16450 | lr 0.000246557 | gnorm 0.953 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26742
KL Stats: Epoch 160 Divergences: Uniform: 9.234083152369744 Unigram: 4.439638004324023
2022-03-15 00:05:25 | INFO | fairseq.trainer | begin training epoch 161
2022-03-15 00:05:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:06:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:06:46 | INFO | train_inner | epoch 161:     51 / 103 loss=3.648, ppl=12.54, wps=39868.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16500, lr=0.000246183, gnorm=0.96, loss_scale=16, train_wall=154, gb_free=20.8, wall=26823
2022-03-15 00:08:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:08:12 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 8.909 | ppl 480.69 | wps 66165.5 | wpb 2040.3 | bsz 4 | num_updates 16552 | best_loss 7.217
2022-03-15 00:08:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 16552 updates
2022-03-15 00:08:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:08:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 161 @ 16552 updates, score 8.909) (writing took 0.8772232346236706 seconds)
2022-03-15 00:08:12 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-15 00:08:12 | INFO | train | epoch 161 | loss 3.646 | ppl 12.52 | wps 39870.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16552 | lr 0.000245796 | gnorm 0.951 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26909
KL Stats: Epoch 161 Divergences: Uniform: 9.239888207988733 Unigram: 4.4427706391200195
2022-03-15 00:08:12 | INFO | fairseq.trainer | begin training epoch 162
2022-03-15 00:08:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:09:29 | INFO | train_inner | epoch 162:     48 / 103 loss=3.646, ppl=12.52, wps=40217.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16600, lr=0.00024544, gnorm=0.949, loss_scale=16, train_wall=153, gb_free=20.8, wall=26985
2022-03-15 00:10:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:10:59 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 8.914 | ppl 482.52 | wps 66288.8 | wpb 2040.3 | bsz 4 | num_updates 16655 | best_loss 7.217
2022-03-15 00:10:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 16655 updates
2022-03-15 00:10:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:11:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 162 @ 16655 updates, score 8.914) (writing took 0.8535329764708877 seconds)
2022-03-15 00:11:00 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-15 00:11:00 | INFO | train | epoch 162 | loss 3.644 | ppl 12.5 | wps 40238.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16655 | lr 0.000245035 | gnorm 0.953 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27076
KL Stats: Epoch 162 Divergences: Uniform: 9.247862100829181 Unigram: 4.447048090450375
2022-03-15 00:11:00 | INFO | fairseq.trainer | begin training epoch 163
2022-03-15 00:11:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:12:11 | INFO | train_inner | epoch 163:     45 / 103 loss=3.641, ppl=12.47, wps=40221.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16700, lr=0.000244704, gnorm=0.956, loss_scale=16, train_wall=153, gb_free=20.8, wall=27147
2022-03-15 00:13:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:13:46 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 8.927 | ppl 486.58 | wps 66059.4 | wpb 2040.3 | bsz 4 | num_updates 16758 | best_loss 7.217
2022-03-15 00:13:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 16758 updates
2022-03-15 00:13:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:13:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:13:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 163 @ 16758 updates, score 8.927) (writing took 0.8460754547268152 seconds)
2022-03-15 00:13:47 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-15 00:13:47 | INFO | train | epoch 163 | loss 3.639 | ppl 12.46 | wps 40249.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16758 | lr 0.000244281 | gnorm 0.953 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27243
KL Stats: Epoch 163 Divergences: Uniform: 9.253288847631108 Unigram: 4.451270840298651
2022-03-15 00:13:47 | INFO | fairseq.trainer | begin training epoch 164
2022-03-15 00:13:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:14:53 | INFO | train_inner | epoch 164:     42 / 103 loss=3.638, ppl=12.45, wps=40198.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16800, lr=0.000243975, gnorm=0.955, loss_scale=16, train_wall=153, gb_free=20.8, wall=27310
2022-03-15 00:16:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:16:33 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 8.942 | ppl 491.85 | wps 66685.8 | wpb 2040.3 | bsz 4 | num_updates 16861 | best_loss 7.217
2022-03-15 00:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 16861 updates
2022-03-15 00:16:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:16:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 164 @ 16861 updates, score 8.942) (writing took 0.9142510741949081 seconds)
2022-03-15 00:16:34 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-15 00:16:34 | INFO | train | epoch 164 | loss 3.634 | ppl 12.42 | wps 40245.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16861 | lr 0.000243533 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27410
KL Stats: Epoch 164 Divergences: Uniform: 9.259959939281131 Unigram: 4.455237606282881
2022-03-15 00:16:34 | INFO | fairseq.trainer | begin training epoch 165
2022-03-15 00:16:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:17:36 | INFO | train_inner | epoch 165:     39 / 103 loss=3.633, ppl=12.41, wps=40207.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16900, lr=0.000243252, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=27472
2022-03-15 00:19:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:19:20 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 8.916 | ppl 483.17 | wps 66060.4 | wpb 2040.3 | bsz 4 | num_updates 16964 | best_loss 7.217
2022-03-15 00:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 16964 updates
2022-03-15 00:19:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 165 @ 16964 updates, score 8.916) (writing took 0.8651645099744201 seconds)
2022-03-15 00:19:21 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-15 00:19:21 | INFO | train | epoch 165 | loss 3.63 | ppl 12.38 | wps 40220.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16964 | lr 0.000242793 | gnorm 0.965 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27578
KL Stats: Epoch 165 Divergences: Uniform: 9.266791855144605 Unigram: 4.458606187259945
2022-03-15 00:19:21 | INFO | fairseq.trainer | begin training epoch 166
2022-03-15 00:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:20:18 | INFO | train_inner | epoch 166:     36 / 103 loss=3.629, ppl=12.38, wps=40214.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17000, lr=0.000242536, gnorm=0.955, loss_scale=16, train_wall=153, gb_free=20.8, wall=27635
2022-03-15 00:20:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:22:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:22:07 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 8.932 | ppl 488.41 | wps 66393.8 | wpb 2040.3 | bsz 4 | num_updates 17066 | best_loss 7.217
2022-03-15 00:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 17066 updates
2022-03-15 00:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 166 @ 17066 updates, score 8.932) (writing took 0.838834029622376 seconds)
2022-03-15 00:22:08 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-15 00:22:08 | INFO | train | epoch 166 | loss 3.626 | ppl 12.34 | wps 39921.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17066 | lr 0.000242066 | gnorm 0.957 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27745
KL Stats: Epoch 166 Divergences: Uniform: 9.275867282857611 Unigram: 4.463020208330003
2022-03-15 00:22:08 | INFO | fairseq.trainer | begin training epoch 167
2022-03-15 00:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:23:02 | INFO | train_inner | epoch 167:     34 / 103 loss=3.625, ppl=12.34, wps=39866.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=17100, lr=0.000241825, gnorm=0.971, loss_scale=16, train_wall=154, gb_free=20.8, wall=27798
2022-03-15 00:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:24:54 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 8.954 | ppl 495.81 | wps 66475.9 | wpb 2040.3 | bsz 4 | num_updates 17169 | best_loss 7.217
2022-03-15 00:24:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 17169 updates
2022-03-15 00:24:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:24:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:24:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 167 @ 17169 updates, score 8.954) (writing took 0.8635394349694252 seconds)
2022-03-15 00:24:55 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-15 00:24:55 | INFO | train | epoch 167 | loss 3.622 | ppl 12.31 | wps 40250.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17169 | lr 0.000241339 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27912
KL Stats: Epoch 167 Divergences: Uniform: 9.280232079812121 Unigram: 4.466447128149989
2022-03-15 00:24:55 | INFO | fairseq.trainer | begin training epoch 168
2022-03-15 00:24:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:25:44 | INFO | train_inner | epoch 168:     31 / 103 loss=3.621, ppl=12.3, wps=40234.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17200, lr=0.000241121, gnorm=0.961, loss_scale=16, train_wall=153, gb_free=20.8, wall=27961
2022-03-15 00:27:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:27:41 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 8.957 | ppl 497.07 | wps 66071.4 | wpb 2040.3 | bsz 4 | num_updates 17272 | best_loss 7.217
2022-03-15 00:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 17272 updates
2022-03-15 00:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 168 @ 17272 updates, score 8.957) (writing took 0.8720313217490911 seconds)
2022-03-15 00:27:42 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-15 00:27:42 | INFO | train | epoch 168 | loss 3.616 | ppl 12.26 | wps 40246.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17272 | lr 0.000240618 | gnorm 0.962 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28079
KL Stats: Epoch 168 Divergences: Uniform: 9.287915471039435 Unigram: 4.46984918902314
2022-03-15 00:27:42 | INFO | fairseq.trainer | begin training epoch 169
2022-03-15 00:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:28:27 | INFO | train_inner | epoch 169:     28 / 103 loss=3.617, ppl=12.27, wps=40206, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17300, lr=0.000240424, gnorm=0.959, loss_scale=16, train_wall=153, gb_free=20.8, wall=28123
2022-03-15 00:29:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 00:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:30:29 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 8.95 | ppl 494.53 | wps 66299.4 | wpb 2040.3 | bsz 4 | num_updates 17374 | best_loss 7.217
2022-03-15 00:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 17374 updates
2022-03-15 00:30:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:30:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 169 @ 17374 updates, score 8.95) (writing took 0.8918569013476372 seconds)
2022-03-15 00:30:30 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-15 00:30:30 | INFO | train | epoch 169 | loss 3.612 | ppl 12.23 | wps 39823.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17374 | lr 0.000239911 | gnorm 0.955 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 28246
KL Stats: Epoch 169 Divergences: Uniform: 9.292438624088446 Unigram: 4.47237616711217
2022-03-15 00:30:30 | INFO | fairseq.trainer | begin training epoch 170
2022-03-15 00:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:31:11 | INFO | train_inner | epoch 170:     26 / 103 loss=3.612, ppl=12.23, wps=39802.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=17400, lr=0.000239732, gnorm=0.962, loss_scale=8, train_wall=155, gb_free=20.8, wall=28287
2022-03-15 00:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:33:16 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 8.956 | ppl 496.48 | wps 66485.3 | wpb 2040.3 | bsz 4 | num_updates 17477 | best_loss 7.217
2022-03-15 00:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 17477 updates
2022-03-15 00:33:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 170 @ 17477 updates, score 8.956) (writing took 0.8557241698727012 seconds)
2022-03-15 00:33:17 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-15 00:33:17 | INFO | train | epoch 170 | loss 3.609 | ppl 12.2 | wps 40280.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17477 | lr 0.000239203 | gnorm 0.973 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 28413
KL Stats: Epoch 170 Divergences: Uniform: 9.301185648877114 Unigram: 4.47735141902866
2022-03-15 00:33:17 | INFO | fairseq.trainer | begin training epoch 171
2022-03-15 00:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:33:53 | INFO | train_inner | epoch 171:     23 / 103 loss=3.611, ppl=12.22, wps=40248.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17500, lr=0.000239046, gnorm=0.974, loss_scale=8, train_wall=153, gb_free=20.8, wall=28450
2022-03-15 00:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:36:03 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 8.966 | ppl 500.16 | wps 66289.7 | wpb 2040.3 | bsz 4 | num_updates 17580 | best_loss 7.217
2022-03-15 00:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 17580 updates
2022-03-15 00:36:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:36:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 171 @ 17580 updates, score 8.966) (writing took 0.8591759903356433 seconds)
2022-03-15 00:36:04 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-15 00:36:04 | INFO | train | epoch 171 | loss 3.604 | ppl 12.16 | wps 40276.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17580 | lr 0.000238501 | gnorm 0.975 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 28580
KL Stats: Epoch 171 Divergences: Uniform: 9.305117363208968 Unigram: 4.481487624633834
2022-03-15 00:36:04 | INFO | fairseq.trainer | begin training epoch 172
2022-03-15 00:36:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:36:35 | INFO | train_inner | epoch 172:     20 / 103 loss=3.601, ppl=12.14, wps=40233.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17600, lr=0.000238366, gnorm=0.971, loss_scale=8, train_wall=153, gb_free=20.8, wall=28612
2022-03-15 00:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:38:50 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 8.961 | ppl 498.32 | wps 66095.5 | wpb 2040.3 | bsz 4 | num_updates 17683 | best_loss 7.217
2022-03-15 00:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 17683 updates
2022-03-15 00:38:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:38:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:38:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 172 @ 17683 updates, score 8.961) (writing took 0.8508788663893938 seconds)
2022-03-15 00:38:51 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-15 00:38:51 | INFO | train | epoch 172 | loss 3.6 | ppl 12.12 | wps 40236.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17683 | lr 0.000237806 | gnorm 0.971 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 28747
KL Stats: Epoch 172 Divergences: Uniform: 9.313559504035817 Unigram: 4.484578190502238
2022-03-15 00:38:51 | INFO | fairseq.trainer | begin training epoch 173
2022-03-15 00:38:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:39:18 | INFO | train_inner | epoch 173:     17 / 103 loss=3.603, ppl=12.15, wps=40204.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17700, lr=0.000237691, gnorm=0.972, loss_scale=8, train_wall=153, gb_free=20.8, wall=28774
2022-03-15 00:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:41:37 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 8.968 | ppl 500.64 | wps 66473.3 | wpb 2040.3 | bsz 4 | num_updates 17786 | best_loss 7.217
2022-03-15 00:41:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 17786 updates
2022-03-15 00:41:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:41:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 173 @ 17786 updates, score 8.968) (writing took 0.8819237239658833 seconds)
2022-03-15 00:41:38 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-15 00:41:38 | INFO | train | epoch 173 | loss 3.596 | ppl 12.09 | wps 40239.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17786 | lr 0.000237116 | gnorm 0.956 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 28914
KL Stats: Epoch 173 Divergences: Uniform: 9.32165295655958 Unigram: 4.488245418361988
2022-03-15 00:41:38 | INFO | fairseq.trainer | begin training epoch 174
2022-03-15 00:41:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:42:00 | INFO | train_inner | epoch 174:     14 / 103 loss=3.595, ppl=12.08, wps=40203, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17800, lr=0.000237023, gnorm=0.958, loss_scale=8, train_wall=153, gb_free=20.8, wall=28937
2022-03-15 00:44:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:44:24 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 8.977 | ppl 503.81 | wps 66250.6 | wpb 2040.3 | bsz 4 | num_updates 17889 | best_loss 7.217
2022-03-15 00:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 17889 updates
2022-03-15 00:44:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:44:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 174 @ 17889 updates, score 8.977) (writing took 0.8603530135005713 seconds)
2022-03-15 00:44:25 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-15 00:44:25 | INFO | train | epoch 174 | loss 3.592 | ppl 12.06 | wps 40248 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17889 | lr 0.000236432 | gnorm 0.955 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29082
KL Stats: Epoch 174 Divergences: Uniform: 9.32666767340629 Unigram: 4.491753203941645
2022-03-15 00:44:25 | INFO | fairseq.trainer | begin training epoch 175
2022-03-15 00:44:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:44:43 | INFO | train_inner | epoch 175:     11 / 103 loss=3.594, ppl=12.07, wps=40220.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17900, lr=0.00023636, gnorm=0.954, loss_scale=16, train_wall=153, gb_free=20.8, wall=29099
2022-03-15 00:47:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:47:11 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 8.98 | ppl 504.84 | wps 65937.2 | wpb 2040.3 | bsz 4 | num_updates 17992 | best_loss 7.217
2022-03-15 00:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 17992 updates
2022-03-15 00:47:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:47:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 175 @ 17992 updates, score 8.98) (writing took 0.8571527898311615 seconds)
2022-03-15 00:47:12 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-15 00:47:12 | INFO | train | epoch 175 | loss 3.589 | ppl 12.03 | wps 40277 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17992 | lr 0.000235755 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29249
KL Stats: Epoch 175 Divergences: Uniform: 9.331800072892005 Unigram: 4.492751177920713
2022-03-15 00:47:12 | INFO | fairseq.trainer | begin training epoch 176
2022-03-15 00:47:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:47:25 | INFO | train_inner | epoch 176:      8 / 103 loss=3.591, ppl=12.05, wps=40244.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18000, lr=0.000235702, gnorm=0.972, loss_scale=16, train_wall=153, gb_free=20.8, wall=29261
2022-03-15 00:49:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:49:58 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 8.986 | ppl 507 | wps 66271.8 | wpb 2040.3 | bsz 4 | num_updates 18095 | best_loss 7.217
2022-03-15 00:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 18095 updates
2022-03-15 00:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:49:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:49:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 176 @ 18095 updates, score 8.986) (writing took 0.85967100225389 seconds)
2022-03-15 00:49:59 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-15 00:49:59 | INFO | train | epoch 176 | loss 3.585 | ppl 12 | wps 40255.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18095 | lr 0.000235083 | gnorm 0.986 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29416
KL Stats: Epoch 176 Divergences: Uniform: 9.339810497877394 Unigram: 4.498779384490978
2022-03-15 00:49:59 | INFO | fairseq.trainer | begin training epoch 177
2022-03-15 00:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:50:07 | INFO | train_inner | epoch 177:      5 / 103 loss=3.586, ppl=12.01, wps=40221.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18100, lr=0.00023505, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=29424
2022-03-15 00:52:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:52:46 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 8.985 | ppl 506.58 | wps 66279.9 | wpb 2040.3 | bsz 4 | num_updates 18198 | best_loss 7.217
2022-03-15 00:52:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 18198 updates
2022-03-15 00:52:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:52:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 177 @ 18198 updates, score 8.985) (writing took 0.8585386881604791 seconds)
2022-03-15 00:52:47 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-15 00:52:47 | INFO | train | epoch 177 | loss 3.579 | ppl 11.95 | wps 40217.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18198 | lr 0.000234416 | gnorm 0.966 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29583
KL Stats: Epoch 177 Divergences: Uniform: 9.342884115771188 Unigram: 4.502290790174849
2022-03-15 00:52:47 | INFO | fairseq.trainer | begin training epoch 178
2022-03-15 00:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:52:50 | INFO | train_inner | epoch 178:      2 / 103 loss=3.58, ppl=11.96, wps=40183.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18200, lr=0.000234404, gnorm=0.967, loss_scale=16, train_wall=153, gb_free=20.8, wall=29586
2022-03-15 00:55:28 | INFO | train_inner | epoch 178:    102 / 103 loss=3.579, ppl=11.95, wps=41379.4, ups=0.63, wpb=65530.9, bsz=128, num_updates=18300, lr=0.000233762, gnorm=0.971, loss_scale=16, train_wall=154, gb_free=20.8, wall=29745
2022-03-15 00:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:55:33 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 8.991 | ppl 508.85 | wps 65288.6 | wpb 2040.3 | bsz 4 | num_updates 18301 | best_loss 7.217
2022-03-15 00:55:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 18301 updates
2022-03-15 00:55:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 178 @ 18301 updates, score 8.991) (writing took 0.8765676962211728 seconds)
2022-03-15 00:55:34 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-15 00:55:34 | INFO | train | epoch 178 | loss 3.577 | ppl 11.93 | wps 40241.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18301 | lr 0.000233756 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29750
KL Stats: Epoch 178 Divergences: Uniform: 9.349582884249418 Unigram: 4.50522786435418
2022-03-15 00:55:34 | INFO | fairseq.trainer | begin training epoch 179
2022-03-15 00:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:57:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:58:12 | INFO | train_inner | epoch 179:    100 / 103 loss=3.571, ppl=11.89, wps=39775.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18400, lr=0.000233126, gnorm=0.972, loss_scale=16, train_wall=155, gb_free=20.8, wall=29909
2022-03-15 00:58:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:58:20 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.015 | ppl 517.4 | wps 66235 | wpb 2040.3 | bsz 4 | num_updates 18403 | best_loss 7.217
2022-03-15 00:58:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 18403 updates
2022-03-15 00:58:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 00:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 179 @ 18403 updates, score 9.015) (writing took 0.8952219011262059 seconds)
2022-03-15 00:58:21 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-15 00:58:21 | INFO | train | epoch 179 | loss 3.572 | ppl 11.89 | wps 39813.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18403 | lr 0.000233107 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29918
KL Stats: Epoch 179 Divergences: Uniform: 9.354762989056816 Unigram: 4.509169274526907
2022-03-15 00:58:21 | INFO | fairseq.trainer | begin training epoch 180
2022-03-15 00:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:00:55 | INFO | train_inner | epoch 180:     97 / 103 loss=3.567, ppl=11.85, wps=40218.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18500, lr=0.000232495, gnorm=0.969, loss_scale=16, train_wall=153, gb_free=20.8, wall=30071
2022-03-15 01:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:01:07 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.018 | ppl 518.37 | wps 66472.6 | wpb 2040.3 | bsz 4 | num_updates 18506 | best_loss 7.217
2022-03-15 01:01:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 18506 updates
2022-03-15 01:01:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:01:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 180 @ 18506 updates, score 9.018) (writing took 0.8746058372780681 seconds)
2022-03-15 01:01:08 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-15 01:01:08 | INFO | train | epoch 180 | loss 3.568 | ppl 11.86 | wps 40259.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18506 | lr 0.000232458 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30085
KL Stats: Epoch 180 Divergences: Uniform: 9.359745733016288 Unigram: 4.511740840660732
2022-03-15 01:01:08 | INFO | fairseq.trainer | begin training epoch 181
2022-03-15 01:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:03:37 | INFO | train_inner | epoch 181:     94 / 103 loss=3.562, ppl=11.81, wps=40219.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18600, lr=0.000231869, gnorm=0.951, loss_scale=16, train_wall=153, gb_free=20.8, wall=30234
2022-03-15 01:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:03:54 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.006 | ppl 514 | wps 66306.9 | wpb 2040.3 | bsz 4 | num_updates 18609 | best_loss 7.217
2022-03-15 01:03:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 18609 updates
2022-03-15 01:03:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 181 @ 18609 updates, score 9.006) (writing took 0.9869379634037614 seconds)
2022-03-15 01:03:55 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-15 01:03:55 | INFO | train | epoch 181 | loss 3.563 | ppl 11.82 | wps 40220.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18609 | lr 0.000231813 | gnorm 0.953 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30252
KL Stats: Epoch 181 Divergences: Uniform: 9.364334408787078 Unigram: 4.514987278089842
2022-03-15 01:03:55 | INFO | fairseq.trainer | begin training epoch 182
2022-03-15 01:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:06:20 | INFO | train_inner | epoch 182:     91 / 103 loss=3.559, ppl=11.78, wps=40180.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18700, lr=0.000231249, gnorm=0.972, loss_scale=16, train_wall=153, gb_free=20.8, wall=30396
2022-03-15 01:06:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:06:42 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.009 | ppl 515.08 | wps 65887.5 | wpb 2040.3 | bsz 4 | num_updates 18712 | best_loss 7.217
2022-03-15 01:06:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 18712 updates
2022-03-15 01:06:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 182 @ 18712 updates, score 9.009) (writing took 0.8706641616299748 seconds)
2022-03-15 01:06:43 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-15 01:06:43 | INFO | train | epoch 182 | loss 3.561 | ppl 11.8 | wps 40235.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18712 | lr 0.000231174 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30419
KL Stats: Epoch 182 Divergences: Uniform: 9.37059302924529 Unigram: 4.518690955529278
2022-03-15 01:06:43 | INFO | fairseq.trainer | begin training epoch 183
2022-03-15 01:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:09:02 | INFO | train_inner | epoch 183:     88 / 103 loss=3.558, ppl=11.78, wps=40216.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18800, lr=0.000230633, gnorm=0.969, loss_scale=16, train_wall=153, gb_free=20.8, wall=30558
2022-03-15 01:09:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:09:29 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.007 | ppl 514.48 | wps 66124.9 | wpb 2040.3 | bsz 4 | num_updates 18815 | best_loss 7.217
2022-03-15 01:09:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 18815 updates
2022-03-15 01:09:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:09:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:09:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 183 @ 18815 updates, score 9.007) (writing took 0.9781012088060379 seconds)
2022-03-15 01:09:30 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-15 01:09:30 | INFO | train | epoch 183 | loss 3.558 | ppl 11.78 | wps 40231.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18815 | lr 0.000230541 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30586
KL Stats: Epoch 183 Divergences: Uniform: 9.374062044368856 Unigram: 4.520056858181997
2022-03-15 01:09:30 | INFO | fairseq.trainer | begin training epoch 184
2022-03-15 01:09:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:11:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:11:46 | INFO | train_inner | epoch 184:     86 / 103 loss=3.553, ppl=11.74, wps=39808.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18900, lr=0.000230022, gnorm=0.981, loss_scale=16, train_wall=155, gb_free=20.8, wall=30723
2022-03-15 01:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:12:16 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.021 | ppl 519.35 | wps 65984.2 | wpb 2040.3 | bsz 4 | num_updates 18917 | best_loss 7.217
2022-03-15 01:12:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 18917 updates
2022-03-15 01:12:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:12:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 184 @ 18917 updates, score 9.021) (writing took 0.9282935559749603 seconds)
2022-03-15 01:12:17 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-15 01:12:17 | INFO | train | epoch 184 | loss 3.554 | ppl 11.74 | wps 39837.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18917 | lr 0.000229918 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30753
KL Stats: Epoch 184 Divergences: Uniform: 9.38219377686759 Unigram: 4.5251081820926755
2022-03-15 01:12:17 | INFO | fairseq.trainer | begin training epoch 185
2022-03-15 01:12:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:14:29 | INFO | train_inner | epoch 185:     83 / 103 loss=3.549, ppl=11.7, wps=40208.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19000, lr=0.000229416, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=30885
2022-03-15 01:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:15:03 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.016 | ppl 517.72 | wps 65832.2 | wpb 2040.3 | bsz 4 | num_updates 19020 | best_loss 7.217
2022-03-15 01:15:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 19020 updates
2022-03-15 01:15:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:15:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 185 @ 19020 updates, score 9.016) (writing took 0.8606945564970374 seconds)
2022-03-15 01:15:04 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-15 01:15:04 | INFO | train | epoch 185 | loss 3.55 | ppl 11.71 | wps 40273.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19020 | lr 0.000229295 | gnorm 0.97 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 30921
KL Stats: Epoch 185 Divergences: Uniform: 9.38431040787355 Unigram: 4.527294375064312
2022-03-15 01:15:04 | INFO | fairseq.trainer | begin training epoch 186
2022-03-15 01:15:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:17:11 | INFO | train_inner | epoch 186:     80 / 103 loss=3.546, ppl=11.68, wps=40211.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19100, lr=0.000228814, gnorm=0.968, loss_scale=16, train_wall=153, gb_free=20.8, wall=31047
2022-03-15 01:17:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:17:50 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.027 | ppl 521.67 | wps 66476.6 | wpb 2040.3 | bsz 4 | num_updates 19123 | best_loss 7.217
2022-03-15 01:17:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 19123 updates
2022-03-15 01:17:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:17:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:17:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 186 @ 19123 updates, score 9.027) (writing took 0.8854626249521971 seconds)
2022-03-15 01:17:51 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-15 01:17:51 | INFO | train | epoch 186 | loss 3.546 | ppl 11.68 | wps 40235.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19123 | lr 0.000228677 | gnorm 0.969 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31088
KL Stats: Epoch 186 Divergences: Uniform: 9.387238322570509 Unigram: 4.530393070278469
2022-03-15 01:17:51 | INFO | fairseq.trainer | begin training epoch 187
2022-03-15 01:17:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:19:53 | INFO | train_inner | epoch 187:     77 / 103 loss=3.542, ppl=11.65, wps=40221, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19200, lr=0.000228218, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=31210
2022-03-15 01:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:20:38 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.035 | ppl 524.59 | wps 66485.3 | wpb 2040.3 | bsz 4 | num_updates 19226 | best_loss 7.217
2022-03-15 01:20:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 19226 updates
2022-03-15 01:20:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 187 @ 19226 updates, score 9.035) (writing took 0.8894707150757313 seconds)
2022-03-15 01:20:38 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-15 01:20:38 | INFO | train | epoch 187 | loss 3.544 | ppl 11.66 | wps 40248.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19226 | lr 0.000228063 | gnorm 0.969 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31255
KL Stats: Epoch 187 Divergences: Uniform: 9.399932994611039 Unigram: 4.535006383325563
2022-03-15 01:20:38 | INFO | fairseq.trainer | begin training epoch 188
2022-03-15 01:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:22:36 | INFO | train_inner | epoch 188:     74 / 103 loss=3.542, ppl=11.65, wps=40198, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19300, lr=0.000227626, gnorm=0.964, loss_scale=16, train_wall=153, gb_free=20.8, wall=31372
2022-03-15 01:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:23:25 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.028 | ppl 522.02 | wps 66102.3 | wpb 2040.3 | bsz 4 | num_updates 19329 | best_loss 7.217
2022-03-15 01:23:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 19329 updates
2022-03-15 01:23:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 188 @ 19329 updates, score 9.028) (writing took 0.8763934820890427 seconds)
2022-03-15 01:23:26 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-15 01:23:26 | INFO | train | epoch 188 | loss 3.54 | ppl 11.64 | wps 40217.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19329 | lr 0.000227455 | gnorm 0.965 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31422
KL Stats: Epoch 188 Divergences: Uniform: 9.399681158090347 Unigram: 4.536279038095702
2022-03-15 01:23:26 | INFO | fairseq.trainer | begin training epoch 189
2022-03-15 01:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:25:18 | INFO | train_inner | epoch 189:     71 / 103 loss=3.535, ppl=11.59, wps=40172, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19400, lr=0.000227038, gnorm=0.966, loss_scale=16, train_wall=153, gb_free=20.8, wall=31535
2022-03-15 01:25:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:26:12 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.038 | ppl 525.62 | wps 66672.6 | wpb 2040.3 | bsz 4 | num_updates 19431 | best_loss 7.217
2022-03-15 01:26:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 19431 updates
2022-03-15 01:26:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 189 @ 19431 updates, score 9.038) (writing took 0.9331238614395261 seconds)
2022-03-15 01:26:13 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-15 01:26:13 | INFO | train | epoch 189 | loss 3.536 | ppl 11.6 | wps 39824.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19431 | lr 0.000226857 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31589
KL Stats: Epoch 189 Divergences: Uniform: 9.405036590115994 Unigram: 4.538585936282215
2022-03-15 01:26:13 | INFO | fairseq.trainer | begin training epoch 190
2022-03-15 01:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:28:02 | INFO | train_inner | epoch 190:     69 / 103 loss=3.534, ppl=11.59, wps=39825.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=19500, lr=0.000226455, gnorm=0.972, loss_scale=16, train_wall=155, gb_free=20.8, wall=31699
2022-03-15 01:28:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:28:59 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.051 | ppl 530.39 | wps 66134.8 | wpb 2040.3 | bsz 4 | num_updates 19534 | best_loss 7.217
2022-03-15 01:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 19534 updates
2022-03-15 01:28:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:29:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 190 @ 19534 updates, score 9.051) (writing took 0.8689487706869841 seconds)
2022-03-15 01:29:00 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-15 01:29:00 | INFO | train | epoch 190 | loss 3.533 | ppl 11.58 | wps 40271.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19534 | lr 0.000226258 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31756
KL Stats: Epoch 190 Divergences: Uniform: 9.410595451991933 Unigram: 4.541274314998221
2022-03-15 01:29:00 | INFO | fairseq.trainer | begin training epoch 191
2022-03-15 01:29:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:30:45 | INFO | train_inner | epoch 191:     66 / 103 loss=3.529, ppl=11.55, wps=40246.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19600, lr=0.000225877, gnorm=0.965, loss_scale=16, train_wall=153, gb_free=20.8, wall=31861
2022-03-15 01:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:31:46 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.044 | ppl 527.72 | wps 66683.2 | wpb 2040.3 | bsz 4 | num_updates 19637 | best_loss 7.217
2022-03-15 01:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 19637 updates
2022-03-15 01:31:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:31:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:31:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 191 @ 19637 updates, score 9.044) (writing took 0.9081788500770926 seconds)
2022-03-15 01:31:47 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-15 01:31:47 | INFO | train | epoch 191 | loss 3.529 | ppl 11.54 | wps 40253.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19637 | lr 0.000225664 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31924
KL Stats: Epoch 191 Divergences: Uniform: 9.417082673690476 Unigram: 4.545729656507093
2022-03-15 01:31:47 | INFO | fairseq.trainer | begin training epoch 192
2022-03-15 01:31:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:33:27 | INFO | train_inner | epoch 192:     63 / 103 loss=3.525, ppl=11.51, wps=40251, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19700, lr=0.000225303, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=32023
2022-03-15 01:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:34:33 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.05 | ppl 529.98 | wps 66264.7 | wpb 2040.3 | bsz 4 | num_updates 19740 | best_loss 7.217
2022-03-15 01:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 19740 updates
2022-03-15 01:34:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:34:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:34:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 192 @ 19740 updates, score 9.05) (writing took 0.8599862204864621 seconds)
2022-03-15 01:34:34 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-15 01:34:34 | INFO | train | epoch 192 | loss 3.525 | ppl 11.51 | wps 40298.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19740 | lr 0.000225075 | gnorm 0.972 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32091
KL Stats: Epoch 192 Divergences: Uniform: 9.422359517621135 Unigram: 4.548881546264626
2022-03-15 01:34:34 | INFO | fairseq.trainer | begin training epoch 193
2022-03-15 01:34:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:36:09 | INFO | train_inner | epoch 193:     60 / 103 loss=3.524, ppl=11.5, wps=40227.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19800, lr=0.000224733, gnorm=0.972, loss_scale=16, train_wall=153, gb_free=20.8, wall=32186
2022-03-15 01:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:37:20 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.061 | ppl 534.04 | wps 66678.6 | wpb 2040.3 | bsz 4 | num_updates 19843 | best_loss 7.217
2022-03-15 01:37:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 19843 updates
2022-03-15 01:37:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:37:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 193 @ 19843 updates, score 9.061) (writing took 0.8513141479343176 seconds)
2022-03-15 01:37:21 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-15 01:37:21 | INFO | train | epoch 193 | loss 3.523 | ppl 11.49 | wps 40279.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19843 | lr 0.00022449 | gnorm 0.97 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32258
KL Stats: Epoch 193 Divergences: Uniform: 9.426065059407927 Unigram: 4.55100306356247
2022-03-15 01:37:21 | INFO | fairseq.trainer | begin training epoch 194
2022-03-15 01:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:38:52 | INFO | train_inner | epoch 194:     57 / 103 loss=3.521, ppl=11.48, wps=40230.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19900, lr=0.000224168, gnorm=0.976, loss_scale=16, train_wall=153, gb_free=20.8, wall=32348
2022-03-15 01:39:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:40:07 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.059 | ppl 533.23 | wps 66288.1 | wpb 2040.3 | bsz 4 | num_updates 19945 | best_loss 7.217
2022-03-15 01:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 19945 updates
2022-03-15 01:40:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:40:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 194 @ 19945 updates, score 9.059) (writing took 0.8645256366580725 seconds)
2022-03-15 01:40:08 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-15 01:40:08 | INFO | train | epoch 194 | loss 3.519 | ppl 11.46 | wps 39849.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19945 | lr 0.000223915 | gnorm 0.981 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32425
KL Stats: Epoch 194 Divergences: Uniform: 9.430068797300562 Unigram: 4.554771552975014
2022-03-15 01:40:08 | INFO | fairseq.trainer | begin training epoch 195
2022-03-15 01:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:41:35 | INFO | train_inner | epoch 195:     55 / 103 loss=3.515, ppl=11.43, wps=39822.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20000, lr=0.000223607, gnorm=0.973, loss_scale=16, train_wall=155, gb_free=20.8, wall=32512
2022-03-15 01:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:42:54 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.067 | ppl 536.31 | wps 66637.2 | wpb 2040.3 | bsz 4 | num_updates 20048 | best_loss 7.217
2022-03-15 01:42:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 20048 updates
2022-03-15 01:42:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:42:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:42:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 195 @ 20048 updates, score 9.067) (writing took 0.8597721019759774 seconds)
2022-03-15 01:42:55 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-15 01:42:55 | INFO | train | epoch 195 | loss 3.515 | ppl 11.43 | wps 40281.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20048 | lr 0.000223339 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32592
KL Stats: Epoch 195 Divergences: Uniform: 9.435861101673122 Unigram: 4.557680358620153
2022-03-15 01:42:55 | INFO | fairseq.trainer | begin training epoch 196
2022-03-15 01:42:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:44:18 | INFO | train_inner | epoch 196:     52 / 103 loss=3.515, ppl=11.43, wps=40267.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20100, lr=0.00022305, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=32674
2022-03-15 01:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:45:42 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.076 | ppl 539.59 | wps 66102.7 | wpb 2040.3 | bsz 4 | num_updates 20151 | best_loss 7.217
2022-03-15 01:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 20151 updates
2022-03-15 01:45:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:45:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:45:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 196 @ 20151 updates, score 9.076) (writing took 0.9019925836473703 seconds)
2022-03-15 01:45:42 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-15 01:45:42 | INFO | train | epoch 196 | loss 3.512 | ppl 11.41 | wps 40246.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20151 | lr 0.000222767 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32759
KL Stats: Epoch 196 Divergences: Uniform: 9.438674047371183 Unigram: 4.559989067139368
2022-03-15 01:45:42 | INFO | fairseq.trainer | begin training epoch 197
2022-03-15 01:45:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:47:00 | INFO | train_inner | epoch 197:     49 / 103 loss=3.509, ppl=11.38, wps=40187.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=20200, lr=0.000222497, gnorm=0.976, loss_scale=16, train_wall=153, gb_free=20.8, wall=32837
2022-03-15 01:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:48:29 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.081 | ppl 541.46 | wps 66272.1 | wpb 2040.3 | bsz 4 | num_updates 20254 | best_loss 7.217
2022-03-15 01:48:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 20254 updates
2022-03-15 01:48:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:48:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:48:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 197 @ 20254 updates, score 9.081) (writing took 0.9313600398600101 seconds)
2022-03-15 01:48:30 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-15 01:48:30 | INFO | train | epoch 197 | loss 3.508 | ppl 11.38 | wps 40217.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20254 | lr 0.0002222 | gnorm 0.961 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32926
KL Stats: Epoch 197 Divergences: Uniform: 9.445041168257786 Unigram: 4.563680852656419
2022-03-15 01:48:30 | INFO | fairseq.trainer | begin training epoch 198
2022-03-15 01:48:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:49:43 | INFO | train_inner | epoch 198:     46 / 103 loss=3.509, ppl=11.38, wps=40195.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20300, lr=0.000221948, gnorm=0.965, loss_scale=16, train_wall=153, gb_free=20.8, wall=32999
2022-03-15 01:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:51:16 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.087 | ppl 543.79 | wps 66121.7 | wpb 2040.3 | bsz 4 | num_updates 20357 | best_loss 7.217
2022-03-15 01:51:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 20357 updates
2022-03-15 01:51:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:51:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:51:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 198 @ 20357 updates, score 9.087) (writing took 0.9000473888590932 seconds)
2022-03-15 01:51:17 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-15 01:51:17 | INFO | train | epoch 198 | loss 3.507 | ppl 11.37 | wps 40227.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20357 | lr 0.000221637 | gnorm 0.967 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33093
KL Stats: Epoch 198 Divergences: Uniform: 9.447581068475968 Unigram: 4.5650682280281965
2022-03-15 01:51:17 | INFO | fairseq.trainer | begin training epoch 199
2022-03-15 01:51:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:52:25 | INFO | train_inner | epoch 199:     43 / 103 loss=3.508, ppl=11.38, wps=40191.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20400, lr=0.000221404, gnorm=0.965, loss_scale=16, train_wall=153, gb_free=20.8, wall=33162
2022-03-15 01:53:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:54:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:54:03 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.073 | ppl 538.56 | wps 66072.9 | wpb 2040.3 | bsz 4 | num_updates 20459 | best_loss 7.217
2022-03-15 01:54:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 20459 updates
2022-03-15 01:54:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:54:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 199 @ 20459 updates, score 9.073) (writing took 0.8745580771937966 seconds)
2022-03-15 01:54:04 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-15 01:54:04 | INFO | train | epoch 199 | loss 3.504 | ppl 11.35 | wps 39832.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20459 | lr 0.000221084 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33261
KL Stats: Epoch 199 Divergences: Uniform: 9.451474136234689 Unigram: 4.56688029340805
2022-03-15 01:54:04 | INFO | fairseq.trainer | begin training epoch 200
2022-03-15 01:54:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:55:09 | INFO | train_inner | epoch 200:     41 / 103 loss=3.502, ppl=11.33, wps=39816, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=20500, lr=0.000220863, gnorm=0.983, loss_scale=16, train_wall=155, gb_free=20.8, wall=33326
2022-03-15 01:56:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:56:50 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.085 | ppl 543.13 | wps 66087.5 | wpb 2040.3 | bsz 4 | num_updates 20562 | best_loss 7.217
2022-03-15 01:56:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 20562 updates
2022-03-15 01:56:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:56:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:56:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 200 @ 20562 updates, score 9.085) (writing took 0.9087231308221817 seconds)
2022-03-15 01:56:51 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-15 01:56:51 | INFO | train | epoch 200 | loss 3.499 | ppl 11.31 | wps 40238.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20562 | lr 0.00022053 | gnorm 0.982 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33428
KL Stats: Epoch 200 Divergences: Uniform: 9.454602830275844 Unigram: 4.57004782679152
2022-03-15 01:56:51 | INFO | fairseq.trainer | begin training epoch 201
2022-03-15 01:56:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:57:52 | INFO | train_inner | epoch 201:     38 / 103 loss=3.496, ppl=11.28, wps=40187.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=20600, lr=0.000220326, gnorm=0.98, loss_scale=16, train_wall=153, gb_free=20.8, wall=33488
2022-03-15 01:59:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:59:38 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.093 | ppl 545.95 | wps 66544.2 | wpb 2040.3 | bsz 4 | num_updates 20665 | best_loss 7.217
2022-03-15 01:59:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 20665 updates
2022-03-15 01:59:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:59:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 01:59:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 201 @ 20665 updates, score 9.093) (writing took 0.8760952232405543 seconds)
2022-03-15 01:59:39 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-15 01:59:39 | INFO | train | epoch 201 | loss 3.497 | ppl 11.29 | wps 40229.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20665 | lr 0.00021998 | gnorm 0.985 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33595
KL Stats: Epoch 201 Divergences: Uniform: 9.461607167088578 Unigram: 4.573248935824328
2022-03-15 01:59:39 | INFO | fairseq.trainer | begin training epoch 202
2022-03-15 01:59:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:00:34 | INFO | train_inner | epoch 202:     35 / 103 loss=3.498, ppl=11.3, wps=40218.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20700, lr=0.000219793, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=33650
2022-03-15 02:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:02:25 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.092 | ppl 545.74 | wps 66300.8 | wpb 2040.3 | bsz 4 | num_updates 20768 | best_loss 7.217
2022-03-15 02:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 20768 updates
2022-03-15 02:02:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:02:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:02:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 202 @ 20768 updates, score 9.092) (writing took 0.8503798674792051 seconds)
2022-03-15 02:02:26 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-15 02:02:26 | INFO | train | epoch 202 | loss 3.492 | ppl 11.25 | wps 40238.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20768 | lr 0.000219433 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33762
KL Stats: Epoch 202 Divergences: Uniform: 9.466266537098466 Unigram: 4.576685314592345
2022-03-15 02:02:26 | INFO | fairseq.trainer | begin training epoch 203
2022-03-15 02:02:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:03:17 | INFO | train_inner | epoch 203:     32 / 103 loss=3.491, ppl=11.24, wps=40179.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20800, lr=0.000219265, gnorm=0.969, loss_scale=16, train_wall=153, gb_free=20.8, wall=33813
2022-03-15 02:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:05:12 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.105 | ppl 550.68 | wps 66262.3 | wpb 2040.3 | bsz 4 | num_updates 20871 | best_loss 7.217
2022-03-15 02:05:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 20871 updates
2022-03-15 02:05:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:05:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 203 @ 20871 updates, score 9.105) (writing took 0.8551072273403406 seconds)
2022-03-15 02:05:13 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-15 02:05:13 | INFO | train | epoch 203 | loss 3.491 | ppl 11.24 | wps 40239.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20871 | lr 0.000218891 | gnorm 0.969 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33929
KL Stats: Epoch 203 Divergences: Uniform: 9.46642788167647 Unigram: 4.578122814861717
2022-03-15 02:05:13 | INFO | fairseq.trainer | begin training epoch 204
2022-03-15 02:05:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:05:59 | INFO | train_inner | epoch 204:     29 / 103 loss=3.494, ppl=11.26, wps=40220.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20900, lr=0.000218739, gnorm=0.972, loss_scale=16, train_wall=153, gb_free=20.8, wall=33975
2022-03-15 02:07:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:07:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:07:59 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.107 | ppl 551.5 | wps 66761.1 | wpb 2040.3 | bsz 4 | num_updates 20973 | best_loss 7.217
2022-03-15 02:07:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 20973 updates
2022-03-15 02:07:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:08:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 204 @ 20973 updates, score 9.107) (writing took 0.9160657254979014 seconds)
2022-03-15 02:08:00 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-15 02:08:00 | INFO | train | epoch 204 | loss 3.487 | ppl 11.22 | wps 39874.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20973 | lr 0.000218358 | gnorm 0.973 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34096
KL Stats: Epoch 204 Divergences: Uniform: 9.475008957734131 Unigram: 4.581964766729312
2022-03-15 02:08:00 | INFO | fairseq.trainer | begin training epoch 205
2022-03-15 02:08:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:08:43 | INFO | train_inner | epoch 205:     27 / 103 loss=3.484, ppl=11.19, wps=39859, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=21000, lr=0.000218218, gnorm=0.97, loss_scale=16, train_wall=154, gb_free=20.8, wall=34139
2022-03-15 02:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:10:46 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.108 | ppl 551.79 | wps 66715.6 | wpb 2040.3 | bsz 4 | num_updates 21076 | best_loss 7.217
2022-03-15 02:10:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 21076 updates
2022-03-15 02:10:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:10:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 205 @ 21076 updates, score 9.108) (writing took 0.9729105066508055 seconds)
2022-03-15 02:10:47 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-15 02:10:47 | INFO | train | epoch 205 | loss 3.484 | ppl 11.19 | wps 40237.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21076 | lr 0.000217824 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34264
KL Stats: Epoch 205 Divergences: Uniform: 9.475377222631467 Unigram: 4.5825083353450164
2022-03-15 02:10:47 | INFO | fairseq.trainer | begin training epoch 206
2022-03-15 02:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:11:25 | INFO | train_inner | epoch 206:     24 / 103 loss=3.486, ppl=11.2, wps=40194.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=21100, lr=0.0002177, gnorm=0.983, loss_scale=16, train_wall=153, gb_free=20.8, wall=34302
2022-03-15 02:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:13:33 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.099 | ppl 548.32 | wps 66536.7 | wpb 2040.3 | bsz 4 | num_updates 21179 | best_loss 7.217
2022-03-15 02:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 21179 updates
2022-03-15 02:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 206 @ 21179 updates, score 9.099) (writing took 0.8870878787711263 seconds)
2022-03-15 02:13:34 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-15 02:13:34 | INFO | train | epoch 206 | loss 3.481 | ppl 11.17 | wps 40271.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21179 | lr 0.000217294 | gnorm 0.981 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34431
KL Stats: Epoch 206 Divergences: Uniform: 9.480878110929813 Unigram: 4.586091697457171
2022-03-15 02:13:34 | INFO | fairseq.trainer | begin training epoch 207
2022-03-15 02:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:14:08 | INFO | train_inner | epoch 207:     21 / 103 loss=3.482, ppl=11.17, wps=40231.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21200, lr=0.000217186, gnorm=0.979, loss_scale=16, train_wall=153, gb_free=20.8, wall=34464
2022-03-15 02:16:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:16:21 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.125 | ppl 558.35 | wps 66459.5 | wpb 2040.3 | bsz 4 | num_updates 21282 | best_loss 7.217
2022-03-15 02:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 21282 updates
2022-03-15 02:16:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:16:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:16:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 207 @ 21282 updates, score 9.125) (writing took 0.8849948076531291 seconds)
2022-03-15 02:16:21 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-15 02:16:21 | INFO | train | epoch 207 | loss 3.478 | ppl 11.14 | wps 40227.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21282 | lr 0.000216767 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34598
KL Stats: Epoch 207 Divergences: Uniform: 9.484249350409948 Unigram: 4.588316891043447
2022-03-15 02:16:21 | INFO | fairseq.trainer | begin training epoch 208
2022-03-15 02:16:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:16:50 | INFO | train_inner | epoch 208:     18 / 103 loss=3.479, ppl=11.15, wps=40200.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21300, lr=0.000216676, gnorm=0.98, loss_scale=16, train_wall=153, gb_free=20.8, wall=34626
2022-03-15 02:19:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:19:08 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.12 | ppl 556.4 | wps 66444.6 | wpb 2040.3 | bsz 4 | num_updates 21385 | best_loss 7.217
2022-03-15 02:19:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 21385 updates
2022-03-15 02:19:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:19:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:19:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 208 @ 21385 updates, score 9.12) (writing took 0.9500644905492663 seconds)
2022-03-15 02:19:09 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-15 02:19:09 | INFO | train | epoch 208 | loss 3.476 | ppl 11.12 | wps 40249.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21385 | lr 0.000216245 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34765
KL Stats: Epoch 208 Divergences: Uniform: 9.487503354239877 Unigram: 4.591260243339019
2022-03-15 02:19:09 | INFO | fairseq.trainer | begin training epoch 209
2022-03-15 02:19:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:19:32 | INFO | train_inner | epoch 209:     15 / 103 loss=3.478, ppl=11.14, wps=40225.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21400, lr=0.000216169, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=34789
2022-03-15 02:21:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:21:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:21:55 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 9.125 | ppl 558.15 | wps 66272.5 | wpb 2040.3 | bsz 4 | num_updates 21487 | best_loss 7.217
2022-03-15 02:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 21487 updates
2022-03-15 02:21:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:21:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:21:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 209 @ 21487 updates, score 9.125) (writing took 0.8966672765091062 seconds)
2022-03-15 02:21:56 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-15 02:21:56 | INFO | train | epoch 209 | loss 3.472 | ppl 11.1 | wps 39860.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21487 | lr 0.000215731 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34932
KL Stats: Epoch 209 Divergences: Uniform: 9.491665474322405 Unigram: 4.594428968482177
2022-03-15 02:21:56 | INFO | fairseq.trainer | begin training epoch 210
2022-03-15 02:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:22:16 | INFO | train_inner | epoch 210:     13 / 103 loss=3.472, ppl=11.1, wps=39826.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21500, lr=0.000215666, gnorm=0.987, loss_scale=16, train_wall=155, gb_free=20.8, wall=34953
2022-03-15 02:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:24:42 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 9.11 | ppl 552.71 | wps 65783.2 | wpb 2040.3 | bsz 4 | num_updates 21590 | best_loss 7.217
2022-03-15 02:24:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 21590 updates
2022-03-15 02:24:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:24:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:24:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 210 @ 21590 updates, score 9.11) (writing took 0.8642207188531756 seconds)
2022-03-15 02:24:43 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-15 02:24:43 | INFO | train | epoch 210 | loss 3.469 | ppl 11.07 | wps 40225.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21590 | lr 0.000215216 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35099
KL Stats: Epoch 210 Divergences: Uniform: 9.497351987557447 Unigram: 4.5960404397109365
2022-03-15 02:24:43 | INFO | fairseq.trainer | begin training epoch 211
2022-03-15 02:24:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:24:59 | INFO | train_inner | epoch 211:     10 / 103 loss=3.469, ppl=11.08, wps=40186.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21600, lr=0.000215166, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=35115
2022-03-15 02:27:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:27:29 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 9.14 | ppl 564 | wps 66369.9 | wpb 2040.3 | bsz 4 | num_updates 21693 | best_loss 7.217
2022-03-15 02:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 21693 updates
2022-03-15 02:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 211 @ 21693 updates, score 9.14) (writing took 0.8818671982735395 seconds)
2022-03-15 02:27:30 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-15 02:27:30 | INFO | train | epoch 211 | loss 3.465 | ppl 11.05 | wps 40260.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21693 | lr 0.000214704 | gnorm 0.981 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35266
KL Stats: Epoch 211 Divergences: Uniform: 9.498552192191333 Unigram: 4.598805130961714
2022-03-15 02:27:30 | INFO | fairseq.trainer | begin training epoch 212
2022-03-15 02:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:27:41 | INFO | train_inner | epoch 212:      7 / 103 loss=3.468, ppl=11.07, wps=40229.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21700, lr=0.000214669, gnorm=0.983, loss_scale=16, train_wall=153, gb_free=20.8, wall=35278
2022-03-15 02:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:30:16 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 9.127 | ppl 559.13 | wps 66494.3 | wpb 2040.3 | bsz 4 | num_updates 21796 | best_loss 7.217
2022-03-15 02:30:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 21796 updates
2022-03-15 02:30:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:30:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 212 @ 21796 updates, score 9.127) (writing took 0.9152764622122049 seconds)
2022-03-15 02:30:17 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-15 02:30:17 | INFO | train | epoch 212 | loss 3.464 | ppl 11.04 | wps 40237.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21796 | lr 0.000214196 | gnorm 0.973 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35434
KL Stats: Epoch 212 Divergences: Uniform: 9.50054558111754 Unigram: 4.599403392711778
2022-03-15 02:30:17 | INFO | fairseq.trainer | begin training epoch 213
2022-03-15 02:30:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:30:24 | INFO | train_inner | epoch 213:      4 / 103 loss=3.466, ppl=11.05, wps=40206.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21800, lr=0.000214176, gnorm=0.972, loss_scale=16, train_wall=153, gb_free=20.8, wall=35440
2022-03-15 02:33:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:33:03 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 9.129 | ppl 560.02 | wps 66277.1 | wpb 2040.3 | bsz 4 | num_updates 21899 | best_loss 7.217
2022-03-15 02:33:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 21899 updates
2022-03-15 02:33:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 213 @ 21899 updates, score 9.129) (writing took 0.9190360987558961 seconds)
2022-03-15 02:33:04 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-15 02:33:04 | INFO | train | epoch 213 | loss 3.462 | ppl 11.02 | wps 40240.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21899 | lr 0.000213692 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35601
KL Stats: Epoch 213 Divergences: Uniform: 9.509748271003547 Unigram: 4.6044722194748795
2022-03-15 02:33:04 | INFO | fairseq.trainer | begin training epoch 214
2022-03-15 02:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:33:06 | INFO | train_inner | epoch 214:      1 / 103 loss=3.464, ppl=11.03, wps=40206.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21900, lr=0.000213687, gnorm=0.981, loss_scale=16, train_wall=153, gb_free=20.8, wall=35602
2022-03-15 02:35:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:35:46 | INFO | train_inner | epoch 214:    102 / 103 loss=3.458, ppl=10.99, wps=40945.9, ups=0.62, wpb=65530.9, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.986, loss_scale=16, train_wall=155, gb_free=20.8, wall=35763
2022-03-15 02:35:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:35:51 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 9.142 | ppl 565.14 | wps 66274.5 | wpb 2040.3 | bsz 4 | num_updates 22001 | best_loss 7.217
2022-03-15 02:35:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 22001 updates
2022-03-15 02:35:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:35:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 214 @ 22001 updates, score 9.142) (writing took 0.8690446401014924 seconds)
2022-03-15 02:35:52 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-15 02:35:52 | INFO | train | epoch 214 | loss 3.458 | ppl 10.99 | wps 39844.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22001 | lr 0.000213196 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35768
KL Stats: Epoch 214 Divergences: Uniform: 9.512092105883717 Unigram: 4.605072015311272
2022-03-15 02:35:52 | INFO | fairseq.trainer | begin training epoch 215
2022-03-15 02:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:38:29 | INFO | train_inner | epoch 215:     99 / 103 loss=3.454, ppl=10.96, wps=40213, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22100, lr=0.000212718, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=35925
2022-03-15 02:38:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:38:38 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 9.153 | ppl 569.11 | wps 66418.3 | wpb 2040.3 | bsz 4 | num_updates 22104 | best_loss 7.217
2022-03-15 02:38:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 22104 updates
2022-03-15 02:38:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:38:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:38:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 215 @ 22104 updates, score 9.153) (writing took 0.8886194722726941 seconds)
2022-03-15 02:38:39 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-15 02:38:39 | INFO | train | epoch 215 | loss 3.455 | ppl 10.97 | wps 40245.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22104 | lr 0.000212699 | gnorm 0.985 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35935
KL Stats: Epoch 215 Divergences: Uniform: 9.51594495264736 Unigram: 4.608528712498173
2022-03-15 02:38:39 | INFO | fairseq.trainer | begin training epoch 216
2022-03-15 02:38:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:41:11 | INFO | train_inner | epoch 216:     96 / 103 loss=3.45, ppl=10.93, wps=40207, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22200, lr=0.000212238, gnorm=0.968, loss_scale=16, train_wall=153, gb_free=20.8, wall=36087
2022-03-15 02:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:41:25 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 9.148 | ppl 567.44 | wps 66282.7 | wpb 2040.3 | bsz 4 | num_updates 22207 | best_loss 7.217
2022-03-15 02:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 22207 updates
2022-03-15 02:41:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 216 @ 22207 updates, score 9.148) (writing took 0.8926560189574957 seconds)
2022-03-15 02:41:26 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-15 02:41:26 | INFO | train | epoch 216 | loss 3.451 | ppl 10.94 | wps 40236.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22207 | lr 0.000212205 | gnorm 0.97 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36102
KL Stats: Epoch 216 Divergences: Uniform: 9.51289109443645 Unigram: 4.609430020799879
2022-03-15 02:41:26 | INFO | fairseq.trainer | begin training epoch 217
2022-03-15 02:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:43:53 | INFO | train_inner | epoch 217:     93 / 103 loss=3.448, ppl=10.91, wps=40216.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22300, lr=0.000211762, gnorm=0.968, loss_scale=16, train_wall=153, gb_free=20.8, wall=36250
2022-03-15 02:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:44:12 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 9.147 | ppl 566.92 | wps 66392.9 | wpb 2040.3 | bsz 4 | num_updates 22310 | best_loss 7.217
2022-03-15 02:44:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 22310 updates
2022-03-15 02:44:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 217 @ 22310 updates, score 9.147) (writing took 0.8871689289808273 seconds)
2022-03-15 02:44:13 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-15 02:44:13 | INFO | train | epoch 217 | loss 3.45 | ppl 10.93 | wps 40246.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22310 | lr 0.000211714 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36270
KL Stats: Epoch 217 Divergences: Uniform: 9.521559135490325 Unigram: 4.6128388695613385
2022-03-15 02:44:13 | INFO | fairseq.trainer | begin training epoch 218
2022-03-15 02:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:46:36 | INFO | train_inner | epoch 218:     90 / 103 loss=3.444, ppl=10.88, wps=40208.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22400, lr=0.000211289, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=36412
2022-03-15 02:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:46:59 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 9.143 | ppl 565.28 | wps 66090.3 | wpb 2040.3 | bsz 4 | num_updates 22413 | best_loss 7.217
2022-03-15 02:46:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 22413 updates
2022-03-15 02:46:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:47:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:47:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 218 @ 22413 updates, score 9.143) (writing took 0.8647253029048443 seconds)
2022-03-15 02:47:00 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-15 02:47:00 | INFO | train | epoch 218 | loss 3.446 | ppl 10.9 | wps 40238.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22413 | lr 0.000211227 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36437
KL Stats: Epoch 218 Divergences: Uniform: 9.52789331922289 Unigram: 4.616282424982877
2022-03-15 02:47:00 | INFO | fairseq.trainer | begin training epoch 219
2022-03-15 02:47:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:49:18 | INFO | train_inner | epoch 219:     87 / 103 loss=3.446, ppl=10.9, wps=40190, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22500, lr=0.000210819, gnorm=0.961, loss_scale=32, train_wall=153, gb_free=20.8, wall=36575
2022-03-15 02:49:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:49:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:49:47 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 9.151 | ppl 568.59 | wps 66470.2 | wpb 2040.3 | bsz 4 | num_updates 22515 | best_loss 7.217
2022-03-15 02:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 22515 updates
2022-03-15 02:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 219 @ 22515 updates, score 9.151) (writing took 0.8742498811334372 seconds)
2022-03-15 02:49:47 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-15 02:49:47 | INFO | train | epoch 219 | loss 3.444 | ppl 10.88 | wps 39842.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22515 | lr 0.000210748 | gnorm 0.962 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36604
KL Stats: Epoch 219 Divergences: Uniform: 9.528826886338756 Unigram: 4.61731291087334
2022-03-15 02:49:47 | INFO | fairseq.trainer | begin training epoch 220
2022-03-15 02:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:52:02 | INFO | train_inner | epoch 220:     85 / 103 loss=3.439, ppl=10.85, wps=39835.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=22600, lr=0.000210352, gnorm=0.988, loss_scale=16, train_wall=155, gb_free=20.8, wall=36739
2022-03-15 02:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:52:34 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 9.162 | ppl 572.92 | wps 66475.6 | wpb 2040.3 | bsz 4 | num_updates 22618 | best_loss 7.217
2022-03-15 02:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 22618 updates
2022-03-15 02:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:52:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 220 @ 22618 updates, score 9.162) (writing took 0.8929755985736847 seconds)
2022-03-15 02:52:35 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-15 02:52:35 | INFO | train | epoch 220 | loss 3.442 | ppl 10.86 | wps 40246.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22618 | lr 0.000210268 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36771
KL Stats: Epoch 220 Divergences: Uniform: 9.534208131476596 Unigram: 4.620140793657601
2022-03-15 02:52:35 | INFO | fairseq.trainer | begin training epoch 221
2022-03-15 02:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:54:45 | INFO | train_inner | epoch 221:     82 / 103 loss=3.439, ppl=10.85, wps=40187.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22700, lr=0.000209888, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=36901
2022-03-15 02:55:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:55:21 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 9.165 | ppl 574.15 | wps 66493.2 | wpb 2040.3 | bsz 4 | num_updates 22721 | best_loss 7.217
2022-03-15 02:55:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 22721 updates
2022-03-15 02:55:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:55:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 221 @ 22721 updates, score 9.165) (writing took 0.8978282241150737 seconds)
2022-03-15 02:55:22 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-15 02:55:22 | INFO | train | epoch 221 | loss 3.438 | ppl 10.84 | wps 40223.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22721 | lr 0.000209791 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36938
KL Stats: Epoch 221 Divergences: Uniform: 9.536387932550474 Unigram: 4.6224911942645095
2022-03-15 02:55:22 | INFO | fairseq.trainer | begin training epoch 222
2022-03-15 02:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:57:27 | INFO | train_inner | epoch 222:     79 / 103 loss=3.434, ppl=10.81, wps=40204, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22800, lr=0.000209427, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=37064
2022-03-15 02:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:58:08 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 9.163 | ppl 573.08 | wps 66234.9 | wpb 2040.3 | bsz 4 | num_updates 22824 | best_loss 7.217
2022-03-15 02:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 22824 updates
2022-03-15 02:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 02:58:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 222 @ 22824 updates, score 9.163) (writing took 0.9093315619975328 seconds)
2022-03-15 02:58:09 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-15 02:58:09 | INFO | train | epoch 222 | loss 3.436 | ppl 10.82 | wps 40231.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22824 | lr 0.000209317 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37105
KL Stats: Epoch 222 Divergences: Uniform: 9.541117592601488 Unigram: 4.6237026033615445
2022-03-15 02:58:09 | INFO | fairseq.trainer | begin training epoch 223
2022-03-15 02:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:00:10 | INFO | train_inner | epoch 223:     76 / 103 loss=3.433, ppl=10.8, wps=40197.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22900, lr=0.000208969, gnorm=0.975, loss_scale=16, train_wall=153, gb_free=20.8, wall=37226
2022-03-15 03:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:00:55 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 9.172 | ppl 576.79 | wps 66290.1 | wpb 2040.3 | bsz 4 | num_updates 22927 | best_loss 7.217
2022-03-15 03:00:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 22927 updates
2022-03-15 03:00:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 223 @ 22927 updates, score 9.172) (writing took 0.8905696766451001 seconds)
2022-03-15 03:00:56 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-15 03:00:56 | INFO | train | epoch 223 | loss 3.434 | ppl 10.81 | wps 40231.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22927 | lr 0.000208846 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37273
KL Stats: Epoch 223 Divergences: Uniform: 9.541073114550171 Unigram: 4.625272969298171
2022-03-15 03:00:56 | INFO | fairseq.trainer | begin training epoch 224
2022-03-15 03:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:02:52 | INFO | train_inner | epoch 224:     73 / 103 loss=3.432, ppl=10.79, wps=40207.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23000, lr=0.000208514, gnorm=0.986, loss_scale=16, train_wall=153, gb_free=20.8, wall=37388
2022-03-15 03:03:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:03:43 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 9.182 | ppl 581.03 | wps 66642.2 | wpb 2040.3 | bsz 4 | num_updates 23029 | best_loss 7.217
2022-03-15 03:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 23029 updates
2022-03-15 03:03:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:03:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 224 @ 23029 updates, score 9.182) (writing took 0.8981660278514028 seconds)
2022-03-15 03:03:44 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-15 03:03:44 | INFO | train | epoch 224 | loss 3.431 | ppl 10.78 | wps 39837.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23029 | lr 0.000208383 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37440
KL Stats: Epoch 224 Divergences: Uniform: 9.547474622428307 Unigram: 4.628373396067814
2022-03-15 03:03:44 | INFO | fairseq.trainer | begin training epoch 225
2022-03-15 03:03:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:05:36 | INFO | train_inner | epoch 225:     71 / 103 loss=3.429, ppl=10.77, wps=39808.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23100, lr=0.000208063, gnorm=0.983, loss_scale=16, train_wall=155, gb_free=20.8, wall=37552
2022-03-15 03:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:06:30 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 9.188 | ppl 583.18 | wps 66211.7 | wpb 2040.3 | bsz 4 | num_updates 23132 | best_loss 7.217
2022-03-15 03:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 23132 updates
2022-03-15 03:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:06:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 225 @ 23132 updates, score 9.188) (writing took 0.9019251558929682 seconds)
2022-03-15 03:06:31 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-15 03:06:31 | INFO | train | epoch 225 | loss 3.428 | ppl 10.77 | wps 40239.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23132 | lr 0.000207919 | gnorm 0.984 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37607
KL Stats: Epoch 225 Divergences: Uniform: 9.549593972686285 Unigram: 4.630922235500817
2022-03-15 03:06:31 | INFO | fairseq.trainer | begin training epoch 226
2022-03-15 03:06:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:08:18 | INFO | train_inner | epoch 226:     68 / 103 loss=3.423, ppl=10.73, wps=40208.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23200, lr=0.000207614, gnorm=0.979, loss_scale=16, train_wall=153, gb_free=20.8, wall=37715
2022-03-15 03:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:09:17 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 9.185 | ppl 582.23 | wps 66483.4 | wpb 2040.3 | bsz 4 | num_updates 23235 | best_loss 7.217
2022-03-15 03:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 23235 updates
2022-03-15 03:09:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:09:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:09:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 226 @ 23235 updates, score 9.185) (writing took 0.8676617061719298 seconds)
2022-03-15 03:09:18 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-15 03:09:18 | INFO | train | epoch 226 | loss 3.425 | ppl 10.74 | wps 40257.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23235 | lr 0.000207457 | gnorm 0.974 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37774
KL Stats: Epoch 226 Divergences: Uniform: 9.554538025878816 Unigram: 4.633564465709713
2022-03-15 03:09:18 | INFO | fairseq.trainer | begin training epoch 227
2022-03-15 03:09:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:11:01 | INFO | train_inner | epoch 227:     65 / 103 loss=3.425, ppl=10.74, wps=40202.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23300, lr=0.000207168, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=37877
2022-03-15 03:12:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:12:04 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 9.181 | ppl 580.32 | wps 66076.4 | wpb 2040.3 | bsz 4 | num_updates 23338 | best_loss 7.217
2022-03-15 03:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 23338 updates
2022-03-15 03:12:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:12:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 227 @ 23338 updates, score 9.181) (writing took 0.8680372778326273 seconds)
2022-03-15 03:12:05 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-15 03:12:05 | INFO | train | epoch 227 | loss 3.424 | ppl 10.74 | wps 40229.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23338 | lr 0.000206999 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37941
KL Stats: Epoch 227 Divergences: Uniform: 9.552201211360414 Unigram: 4.633538443974688
2022-03-15 03:12:05 | INFO | fairseq.trainer | begin training epoch 228
2022-03-15 03:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:13:43 | INFO | train_inner | epoch 228:     62 / 103 loss=3.42, ppl=10.7, wps=40240.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23400, lr=0.000206725, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=38040
2022-03-15 03:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:14:51 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 9.197 | ppl 586.75 | wps 66281.9 | wpb 2040.3 | bsz 4 | num_updates 23441 | best_loss 7.217
2022-03-15 03:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 23441 updates
2022-03-15 03:14:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 228 @ 23441 updates, score 9.197) (writing took 0.8624485321342945 seconds)
2022-03-15 03:14:52 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-15 03:14:52 | INFO | train | epoch 228 | loss 3.421 | ppl 10.71 | wps 40279.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23441 | lr 0.000206544 | gnorm 0.981 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38108
KL Stats: Epoch 228 Divergences: Uniform: 9.558913291715093 Unigram: 4.6370215752318575
2022-03-15 03:14:52 | INFO | fairseq.trainer | begin training epoch 229
2022-03-15 03:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:16:25 | INFO | train_inner | epoch 229:     59 / 103 loss=3.419, ppl=10.7, wps=40238.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23500, lr=0.000206284, gnorm=0.987, loss_scale=16, train_wall=153, gb_free=20.8, wall=38202
2022-03-15 03:17:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:17:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:17:38 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 9.186 | ppl 582.56 | wps 65753.1 | wpb 2040.3 | bsz 4 | num_updates 23543 | best_loss 7.217
2022-03-15 03:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 23543 updates
2022-03-15 03:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 229 @ 23543 updates, score 9.186) (writing took 0.9174085445702076 seconds)
2022-03-15 03:17:39 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-15 03:17:39 | INFO | train | epoch 229 | loss 3.417 | ppl 10.68 | wps 39855.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23543 | lr 0.000206096 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38276
KL Stats: Epoch 229 Divergences: Uniform: 9.559171681967058 Unigram: 4.6384331853655425
2022-03-15 03:17:39 | INFO | fairseq.trainer | begin training epoch 230
2022-03-15 03:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:19:09 | INFO | train_inner | epoch 230:     57 / 103 loss=3.417, ppl=10.68, wps=39837.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=23600, lr=0.000205847, gnorm=0.99, loss_scale=16, train_wall=154, gb_free=20.8, wall=38366
2022-03-15 03:20:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:20:25 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 9.187 | ppl 583.04 | wps 66458.2 | wpb 2040.3 | bsz 4 | num_updates 23646 | best_loss 7.217
2022-03-15 03:20:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 23646 updates
2022-03-15 03:20:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:20:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:20:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 230 @ 23646 updates, score 9.187) (writing took 0.8948220126330853 seconds)
2022-03-15 03:20:26 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-15 03:20:26 | INFO | train | epoch 230 | loss 3.415 | ppl 10.67 | wps 40285.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23646 | lr 0.000205646 | gnorm 0.981 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38443
KL Stats: Epoch 230 Divergences: Uniform: 9.564001098105292 Unigram: 4.641225912466607
2022-03-15 03:20:26 | INFO | fairseq.trainer | begin training epoch 231
2022-03-15 03:20:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:21:52 | INFO | train_inner | epoch 231:     54 / 103 loss=3.413, ppl=10.65, wps=40231.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23700, lr=0.000205412, gnorm=0.982, loss_scale=16, train_wall=153, gb_free=20.8, wall=38528
2022-03-15 03:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:23:12 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 9.191 | ppl 584.31 | wps 66646.8 | wpb 2040.3 | bsz 4 | num_updates 23749 | best_loss 7.217
2022-03-15 03:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 23749 updates
2022-03-15 03:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:23:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 231 @ 23749 updates, score 9.191) (writing took 0.9068000614643097 seconds)
2022-03-15 03:23:13 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-15 03:23:13 | INFO | train | epoch 231 | loss 3.414 | ppl 10.66 | wps 40246 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23749 | lr 0.0002052 | gnorm 0.984 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38610
KL Stats: Epoch 231 Divergences: Uniform: 9.56388327544908 Unigram: 4.640978356010995
2022-03-15 03:23:13 | INFO | fairseq.trainer | begin training epoch 232
2022-03-15 03:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:24:34 | INFO | train_inner | epoch 232:     51 / 103 loss=3.414, ppl=10.66, wps=40212.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=23800, lr=0.00020498, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=38691
2022-03-15 03:25:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:26:00 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 9.201 | ppl 588.56 | wps 66202.5 | wpb 2040.3 | bsz 4 | num_updates 23852 | best_loss 7.217
2022-03-15 03:26:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 23852 updates
2022-03-15 03:26:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:26:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:26:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 232 @ 23852 updates, score 9.201) (writing took 0.8963422123342752 seconds)
2022-03-15 03:26:00 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-15 03:26:01 | INFO | train | epoch 232 | loss 3.411 | ppl 10.64 | wps 40235.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23852 | lr 0.000204756 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38777
KL Stats: Epoch 232 Divergences: Uniform: 9.571578323179065 Unigram: 4.646660626359878
2022-03-15 03:26:01 | INFO | fairseq.trainer | begin training epoch 233
2022-03-15 03:26:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:27:17 | INFO | train_inner | epoch 233:     48 / 103 loss=3.41, ppl=10.63, wps=40203.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23900, lr=0.000204551, gnorm=0.981, loss_scale=16, train_wall=153, gb_free=20.8, wall=38853
2022-03-15 03:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:28:47 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 9.184 | ppl 581.58 | wps 66283.9 | wpb 2040.3 | bsz 4 | num_updates 23955 | best_loss 7.217
2022-03-15 03:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 23955 updates
2022-03-15 03:28:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:28:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 233 @ 23955 updates, score 9.184) (writing took 0.8891307078301907 seconds)
2022-03-15 03:28:48 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-15 03:28:48 | INFO | train | epoch 233 | loss 3.408 | ppl 10.62 | wps 40259 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23955 | lr 0.000204316 | gnorm 0.984 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38944
KL Stats: Epoch 233 Divergences: Uniform: 9.572908182063493 Unigram: 4.64608672402632
2022-03-15 03:28:48 | INFO | fairseq.trainer | begin training epoch 234
2022-03-15 03:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:29:59 | INFO | train_inner | epoch 234:     45 / 103 loss=3.404, ppl=10.59, wps=40229.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24000, lr=0.000204124, gnorm=0.98, loss_scale=16, train_wall=153, gb_free=20.8, wall=39015
2022-03-15 03:31:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:31:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:31:34 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 9.205 | ppl 590.17 | wps 66360.9 | wpb 2040.3 | bsz 4 | num_updates 24057 | best_loss 7.217
2022-03-15 03:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 24057 updates
2022-03-15 03:31:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:31:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 234 @ 24057 updates, score 9.205) (writing took 0.9150407798588276 seconds)
2022-03-15 03:31:35 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-15 03:31:35 | INFO | train | epoch 234 | loss 3.405 | ppl 10.59 | wps 39869.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24057 | lr 0.000203882 | gnorm 0.978 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39111
KL Stats: Epoch 234 Divergences: Uniform: 9.575538397589428 Unigram: 4.647803864052911
2022-03-15 03:31:35 | INFO | fairseq.trainer | begin training epoch 235
2022-03-15 03:31:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:32:43 | INFO | train_inner | epoch 235:     43 / 103 loss=3.406, ppl=10.6, wps=39829.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=24100, lr=0.0002037, gnorm=0.985, loss_scale=16, train_wall=155, gb_free=20.8, wall=39179
2022-03-15 03:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:34:21 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 9.209 | ppl 591.8 | wps 66473.4 | wpb 2040.3 | bsz 4 | num_updates 24160 | best_loss 7.217
2022-03-15 03:34:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 24160 updates
2022-03-15 03:34:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:34:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:34:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 235 @ 24160 updates, score 9.209) (writing took 0.8660353142768145 seconds)
2022-03-15 03:34:22 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-15 03:34:22 | INFO | train | epoch 235 | loss 3.404 | ppl 10.59 | wps 40234.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24160 | lr 0.000203447 | gnorm 0.988 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39278
KL Stats: Epoch 235 Divergences: Uniform: 9.577419892704281 Unigram: 4.650281725284062
2022-03-15 03:34:22 | INFO | fairseq.trainer | begin training epoch 236
2022-03-15 03:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:35:25 | INFO | train_inner | epoch 236:     40 / 103 loss=3.402, ppl=10.57, wps=40223.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24200, lr=0.000203279, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=39342
2022-03-15 03:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:37:08 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 9.207 | ppl 591.09 | wps 66376.1 | wpb 2040.3 | bsz 4 | num_updates 24263 | best_loss 7.217
2022-03-15 03:37:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 24263 updates
2022-03-15 03:37:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:37:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:37:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 236 @ 24263 updates, score 9.207) (writing took 0.9088572841137648 seconds)
2022-03-15 03:37:09 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-15 03:37:09 | INFO | train | epoch 236 | loss 3.401 | ppl 10.57 | wps 40266.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24263 | lr 0.000203015 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39445
KL Stats: Epoch 236 Divergences: Uniform: 9.579346649854575 Unigram: 4.651088345476089
2022-03-15 03:37:09 | INFO | fairseq.trainer | begin training epoch 237
2022-03-15 03:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:38:08 | INFO | train_inner | epoch 237:     37 / 103 loss=3.4, ppl=10.56, wps=40218.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24300, lr=0.00020286, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=39504
2022-03-15 03:39:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:39:55 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 9.2 | ppl 588 | wps 66463.5 | wpb 2040.3 | bsz 4 | num_updates 24366 | best_loss 7.217
2022-03-15 03:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 24366 updates
2022-03-15 03:39:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:39:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 237 @ 24366 updates, score 9.2) (writing took 0.9244328700006008 seconds)
2022-03-15 03:39:56 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-15 03:39:56 | INFO | train | epoch 237 | loss 3.399 | ppl 10.55 | wps 40260.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24366 | lr 0.000202585 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39612
KL Stats: Epoch 237 Divergences: Uniform: 9.58460623182414 Unigram: 4.655105814244564
2022-03-15 03:39:56 | INFO | fairseq.trainer | begin training epoch 238
2022-03-15 03:39:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:40:50 | INFO | train_inner | epoch 238:     34 / 103 loss=3.4, ppl=10.56, wps=40232.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24400, lr=0.000202444, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=39666
2022-03-15 03:42:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:42:42 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 9.198 | ppl 587.32 | wps 66262.4 | wpb 2040.3 | bsz 4 | num_updates 24469 | best_loss 7.217
2022-03-15 03:42:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 24469 updates
2022-03-15 03:42:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:42:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:42:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 238 @ 24469 updates, score 9.198) (writing took 0.9030513921752572 seconds)
2022-03-15 03:42:43 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-15 03:42:43 | INFO | train | epoch 238 | loss 3.396 | ppl 10.52 | wps 40280.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24469 | lr 0.000202158 | gnorm 0.982 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39779
KL Stats: Epoch 238 Divergences: Uniform: 9.58726669275046 Unigram: 4.656635108139638
2022-03-15 03:42:43 | INFO | fairseq.trainer | begin training epoch 239
2022-03-15 03:42:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:43:32 | INFO | train_inner | epoch 239:     31 / 103 loss=3.394, ppl=10.51, wps=40243.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24500, lr=0.000202031, gnorm=0.975, loss_scale=16, train_wall=153, gb_free=20.8, wall=39829
2022-03-15 03:45:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:45:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:45:29 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 9.193 | ppl 585.33 | wps 65959 | wpb 2040.3 | bsz 4 | num_updates 24571 | best_loss 7.217
2022-03-15 03:45:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 24571 updates
2022-03-15 03:45:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:45:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:45:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 239 @ 24571 updates, score 9.193) (writing took 0.9236102346330881 seconds)
2022-03-15 03:45:30 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-15 03:45:30 | INFO | train | epoch 239 | loss 3.394 | ppl 10.51 | wps 39832.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24571 | lr 0.000201738 | gnorm 0.984 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39947
KL Stats: Epoch 239 Divergences: Uniform: 9.592594278468153 Unigram: 4.657562115842167
2022-03-15 03:45:30 | INFO | fairseq.trainer | begin training epoch 240
2022-03-15 03:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:46:16 | INFO | train_inner | epoch 240:     29 / 103 loss=3.394, ppl=10.51, wps=39811, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24600, lr=0.000201619, gnorm=0.982, loss_scale=16, train_wall=155, gb_free=20.8, wall=39993
2022-03-15 03:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:48:17 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 9.222 | ppl 597.27 | wps 66087.1 | wpb 2040.3 | bsz 4 | num_updates 24674 | best_loss 7.217
2022-03-15 03:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 24674 updates
2022-03-15 03:48:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:48:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:48:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 240 @ 24674 updates, score 9.222) (writing took 0.9106613621115685 seconds)
2022-03-15 03:48:17 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-15 03:48:17 | INFO | train | epoch 240 | loss 3.39 | ppl 10.49 | wps 40233.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24674 | lr 0.000201317 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40114
KL Stats: Epoch 240 Divergences: Uniform: 9.597314595386973 Unigram: 4.662074777140868
2022-03-15 03:48:18 | INFO | fairseq.trainer | begin training epoch 241
2022-03-15 03:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:48:59 | INFO | train_inner | epoch 241:     26 / 103 loss=3.392, ppl=10.49, wps=40206.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24700, lr=0.000201211, gnorm=0.98, loss_scale=16, train_wall=153, gb_free=20.8, wall=40155
2022-03-15 03:51:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:51:04 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 9.216 | ppl 594.8 | wps 66423.2 | wpb 2040.3 | bsz 4 | num_updates 24777 | best_loss 7.217
2022-03-15 03:51:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 24777 updates
2022-03-15 03:51:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:51:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:51:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 241 @ 24777 updates, score 9.216) (writing took 0.9107633279636502 seconds)
2022-03-15 03:51:05 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-15 03:51:05 | INFO | train | epoch 241 | loss 3.39 | ppl 10.48 | wps 40274.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24777 | lr 0.000200898 | gnorm 0.98 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40281
KL Stats: Epoch 241 Divergences: Uniform: 9.595987795415544 Unigram: 4.66193635890746
2022-03-15 03:51:05 | INFO | fairseq.trainer | begin training epoch 242
2022-03-15 03:51:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:51:41 | INFO | train_inner | epoch 242:     23 / 103 loss=3.389, ppl=10.48, wps=40226.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24800, lr=0.000200805, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=40317
2022-03-15 03:53:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:53:51 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 9.218 | ppl 595.69 | wps 66064.2 | wpb 2040.3 | bsz 4 | num_updates 24880 | best_loss 7.217
2022-03-15 03:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 24880 updates
2022-03-15 03:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 242 @ 24880 updates, score 9.218) (writing took 0.9320063572376966 seconds)
2022-03-15 03:53:52 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-15 03:53:52 | INFO | train | epoch 242 | loss 3.387 | ppl 10.46 | wps 40246.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24880 | lr 0.000200482 | gnorm 0.985 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40448
KL Stats: Epoch 242 Divergences: Uniform: 9.59998965191464 Unigram: 4.665231125352136
2022-03-15 03:53:52 | INFO | fairseq.trainer | begin training epoch 243
2022-03-15 03:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:54:23 | INFO | train_inner | epoch 243:     20 / 103 loss=3.389, ppl=10.47, wps=40213.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24900, lr=0.000200401, gnorm=0.982, loss_scale=16, train_wall=153, gb_free=20.8, wall=40480
2022-03-15 03:56:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:56:38 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 9.216 | ppl 594.83 | wps 65948.2 | wpb 2040.3 | bsz 4 | num_updates 24983 | best_loss 7.217
2022-03-15 03:56:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 24983 updates
2022-03-15 03:56:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:56:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:56:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 243 @ 24983 updates, score 9.216) (writing took 0.8886640015989542 seconds)
2022-03-15 03:56:39 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-15 03:56:39 | INFO | train | epoch 243 | loss 3.384 | ppl 10.44 | wps 40239.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24983 | lr 0.000200068 | gnorm 0.986 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40615
KL Stats: Epoch 243 Divergences: Uniform: 9.601644805706174 Unigram: 4.665394987153323
2022-03-15 03:56:39 | INFO | fairseq.trainer | begin training epoch 244
2022-03-15 03:56:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:57:06 | INFO | train_inner | epoch 244:     17 / 103 loss=3.384, ppl=10.44, wps=40205.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=25000, lr=0.0002, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=40642
2022-03-15 03:59:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:59:25 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 9.22 | ppl 596.41 | wps 66648.2 | wpb 2040.3 | bsz 4 | num_updates 25085 | best_loss 7.217
2022-03-15 03:59:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 25085 updates
2022-03-15 03:59:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:59:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 03:59:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 244 @ 25085 updates, score 9.22) (writing took 0.918181817047298 seconds)
2022-03-15 03:59:26 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-15 03:59:26 | INFO | train | epoch 244 | loss 3.38 | ppl 10.41 | wps 39864.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25085 | lr 0.000199661 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40782
KL Stats: Epoch 244 Divergences: Uniform: 9.606298073182522 Unigram: 4.669206904067235
2022-03-15 03:59:26 | INFO | fairseq.trainer | begin training epoch 245
2022-03-15 03:59:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:59:50 | INFO | train_inner | epoch 245:     15 / 103 loss=3.38, ppl=10.41, wps=39838.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25100, lr=0.000199601, gnorm=0.985, loss_scale=16, train_wall=154, gb_free=20.8, wall=40806
2022-03-15 04:02:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:02:12 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 9.224 | ppl 598.05 | wps 66471.8 | wpb 2040.3 | bsz 4 | num_updates 25188 | best_loss 7.217
2022-03-15 04:02:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 25188 updates
2022-03-15 04:02:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:02:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 245 @ 25188 updates, score 9.224) (writing took 0.9206061502918601 seconds)
2022-03-15 04:02:13 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-15 04:02:13 | INFO | train | epoch 245 | loss 3.38 | ppl 10.41 | wps 40260.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25188 | lr 0.000199252 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40949
KL Stats: Epoch 245 Divergences: Uniform: 9.605989534042038 Unigram: 4.6689266778652
2022-03-15 04:02:13 | INFO | fairseq.trainer | begin training epoch 246
2022-03-15 04:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:02:32 | INFO | train_inner | epoch 246:     12 / 103 loss=3.383, ppl=10.44, wps=40226.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=25200, lr=0.000199205, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=40969
2022-03-15 04:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:04:59 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 9.236 | ppl 603.01 | wps 66257 | wpb 2040.3 | bsz 4 | num_updates 25291 | best_loss 7.217
2022-03-15 04:04:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 25291 updates
2022-03-15 04:04:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:05:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:05:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 246 @ 25291 updates, score 9.236) (writing took 0.9548965794965625 seconds)
2022-03-15 04:05:00 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-15 04:05:00 | INFO | train | epoch 246 | loss 3.378 | ppl 10.39 | wps 40198.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25291 | lr 0.000198846 | gnorm 0.995 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41117
KL Stats: Epoch 246 Divergences: Uniform: 9.60755878601411 Unigram: 4.670709774344228
2022-03-15 04:05:00 | INFO | fairseq.trainer | begin training epoch 247
2022-03-15 04:05:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:05:15 | INFO | train_inner | epoch 247:      9 / 103 loss=3.38, ppl=10.41, wps=40164.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25300, lr=0.000198811, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=41131
2022-03-15 04:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:07:47 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 9.24 | ppl 604.67 | wps 66460.8 | wpb 2040.3 | bsz 4 | num_updates 25394 | best_loss 7.217
2022-03-15 04:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 25394 updates
2022-03-15 04:07:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 247 @ 25394 updates, score 9.24) (writing took 0.9260591184720397 seconds)
2022-03-15 04:07:48 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-15 04:07:48 | INFO | train | epoch 247 | loss 3.375 | ppl 10.37 | wps 40244.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25394 | lr 0.000198442 | gnorm 0.981 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41284
KL Stats: Epoch 247 Divergences: Uniform: 9.613603476173258 Unigram: 4.674986978259407
2022-03-15 04:07:48 | INFO | fairseq.trainer | begin training epoch 248
2022-03-15 04:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:07:57 | INFO | train_inner | epoch 248:      6 / 103 loss=3.374, ppl=10.37, wps=40216.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25400, lr=0.000198419, gnorm=0.98, loss_scale=16, train_wall=153, gb_free=20.8, wall=41294
2022-03-15 04:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:10:34 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 9.246 | ppl 607 | wps 66282.1 | wpb 2040.3 | bsz 4 | num_updates 25497 | best_loss 7.217
2022-03-15 04:10:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 25497 updates
2022-03-15 04:10:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:10:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:10:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 248 @ 25497 updates, score 9.246) (writing took 0.9131668778136373 seconds)
2022-03-15 04:10:35 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-15 04:10:35 | INFO | train | epoch 248 | loss 3.373 | ppl 10.36 | wps 40266.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25497 | lr 0.000198041 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41451
KL Stats: Epoch 248 Divergences: Uniform: 9.615114059813017 Unigram: 4.675337520457664
2022-03-15 04:10:35 | INFO | fairseq.trainer | begin training epoch 249
2022-03-15 04:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:10:39 | INFO | train_inner | epoch 249:      3 / 103 loss=3.376, ppl=10.38, wps=40230.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25500, lr=0.00019803, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=41456
2022-03-15 04:13:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:13:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:13:21 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 9.238 | ppl 603.71 | wps 66058.2 | wpb 2040.3 | bsz 4 | num_updates 25599 | best_loss 7.217
2022-03-15 04:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 25599 updates
2022-03-15 04:13:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:13:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:13:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 249 @ 25599 updates, score 9.238) (writing took 0.9180627195164561 seconds)
2022-03-15 04:13:22 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-15 04:13:22 | INFO | train | epoch 249 | loss 3.37 | ppl 10.34 | wps 39872.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25599 | lr 0.000197646 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41618
KL Stats: Epoch 249 Divergences: Uniform: 9.616864160703972 Unigram: 4.677899784145657
2022-03-15 04:13:22 | INFO | fairseq.trainer | begin training epoch 250
2022-03-15 04:13:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:13:23 | INFO | train_inner | epoch 250:      1 / 103 loss=3.371, ppl=10.35, wps=39842.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25600, lr=0.000197642, gnorm=0.975, loss_scale=16, train_wall=154, gb_free=20.8, wall=41620
2022-03-15 04:16:02 | INFO | train_inner | epoch 250:    101 / 103 loss=3.37, ppl=10.34, wps=41361.7, ups=0.63, wpb=65530.9, bsz=128, num_updates=25700, lr=0.000197257, gnorm=0.993, loss_scale=16, train_wall=154, gb_free=20.8, wall=41778
2022-03-15 04:16:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:16:08 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 9.235 | ppl 602.52 | wps 66639.7 | wpb 2040.3 | bsz 4 | num_updates 25702 | best_loss 7.217
2022-03-15 04:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 25702 updates
2022-03-15 04:16:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 250 @ 25702 updates, score 9.235) (writing took 0.9257098259404302 seconds)
2022-03-15 04:16:09 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-15 04:16:09 | INFO | train | epoch 250 | loss 3.37 | ppl 10.34 | wps 40232.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25702 | lr 0.00019725 | gnorm 0.993 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41785
KL Stats: Epoch 250 Divergences: Uniform: 9.617052264001362 Unigram: 4.678102056959966
2022-03-15 04:16:09 | INFO | fairseq.trainer | begin training epoch 251
2022-03-15 04:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:18:44 | INFO | train_inner | epoch 251:     98 / 103 loss=3.365, ppl=10.3, wps=40218.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25800, lr=0.000196875, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=41941
2022-03-15 04:18:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:18:55 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 9.248 | ppl 607.86 | wps 66209.4 | wpb 2040.3 | bsz 4 | num_updates 25805 | best_loss 7.217
2022-03-15 04:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 25805 updates
2022-03-15 04:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 251 @ 25805 updates, score 9.248) (writing took 0.8821248533204198 seconds)
2022-03-15 04:18:56 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-15 04:18:56 | INFO | train | epoch 251 | loss 3.366 | ppl 10.31 | wps 40256.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25805 | lr 0.000196856 | gnorm 0.985 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41952
KL Stats: Epoch 251 Divergences: Uniform: 9.622529289747872 Unigram: 4.680708207273887
2022-03-15 04:18:56 | INFO | fairseq.trainer | begin training epoch 252
2022-03-15 04:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:21:27 | INFO | train_inner | epoch 252:     95 / 103 loss=3.364, ppl=10.29, wps=40182.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25900, lr=0.000196494, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=42103
2022-03-15 04:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:21:42 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 9.246 | ppl 607.08 | wps 65597.3 | wpb 2040.3 | bsz 4 | num_updates 25908 | best_loss 7.217
2022-03-15 04:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 25908 updates
2022-03-15 04:21:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:21:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:21:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 252 @ 25908 updates, score 9.246) (writing took 0.896280306391418 seconds)
2022-03-15 04:21:43 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-15 04:21:43 | INFO | train | epoch 252 | loss 3.365 | ppl 10.3 | wps 40191.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25908 | lr 0.000196464 | gnorm 0.984 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42120
KL Stats: Epoch 252 Divergences: Uniform: 9.623400685575877 Unigram: 4.681326835284386
2022-03-15 04:21:43 | INFO | fairseq.trainer | begin training epoch 253
2022-03-15 04:21:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:24:09 | INFO | train_inner | epoch 253:     92 / 103 loss=3.36, ppl=10.27, wps=40201.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26000, lr=0.000196116, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=42266
2022-03-15 04:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:24:30 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 9.258 | ppl 612.23 | wps 66295.6 | wpb 2040.3 | bsz 4 | num_updates 26011 | best_loss 7.217
2022-03-15 04:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 26011 updates
2022-03-15 04:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:24:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 253 @ 26011 updates, score 9.258) (writing took 0.9128448646515608 seconds)
2022-03-15 04:24:31 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-15 04:24:31 | INFO | train | epoch 253 | loss 3.363 | ppl 10.29 | wps 40255.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26011 | lr 0.000196075 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42287
KL Stats: Epoch 253 Divergences: Uniform: 9.625910719618634 Unigram: 4.682857836954469
2022-03-15 04:24:31 | INFO | fairseq.trainer | begin training epoch 254
2022-03-15 04:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:26:52 | INFO | train_inner | epoch 254:     89 / 103 loss=3.358, ppl=10.25, wps=40190.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26100, lr=0.00019574, gnorm=0.998, loss_scale=32, train_wall=153, gb_free=20.8, wall=42428
2022-03-15 04:27:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:27:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:27:17 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 9.246 | ppl 607.35 | wps 66189.4 | wpb 2040.3 | bsz 4 | num_updates 26113 | best_loss 7.217
2022-03-15 04:27:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 26113 updates
2022-03-15 04:27:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:27:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:27:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 254 @ 26113 updates, score 9.246) (writing took 0.8957455828785896 seconds)
2022-03-15 04:27:18 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-15 04:27:18 | INFO | train | epoch 254 | loss 3.359 | ppl 10.26 | wps 39839.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26113 | lr 0.000195691 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42454
KL Stats: Epoch 254 Divergences: Uniform: 9.629494661792055 Unigram: 4.686236853773167
2022-03-15 04:27:18 | INFO | fairseq.trainer | begin training epoch 255
2022-03-15 04:27:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:29:36 | INFO | train_inner | epoch 255:     87 / 103 loss=3.359, ppl=10.26, wps=39819.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26200, lr=0.000195366, gnorm=0.992, loss_scale=16, train_wall=155, gb_free=20.8, wall=42592
2022-03-15 04:30:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:30:04 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 9.249 | ppl 608.41 | wps 66031.3 | wpb 2040.3 | bsz 4 | num_updates 26216 | best_loss 7.217
2022-03-15 04:30:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 26216 updates
2022-03-15 04:30:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 255 @ 26216 updates, score 9.249) (writing took 0.9206640953198075 seconds)
2022-03-15 04:30:05 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-15 04:30:05 | INFO | train | epoch 255 | loss 3.357 | ppl 10.24 | wps 40217.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26216 | lr 0.000195307 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42621
KL Stats: Epoch 255 Divergences: Uniform: 9.63308236254362 Unigram: 4.687455228445678
2022-03-15 04:30:05 | INFO | fairseq.trainer | begin training epoch 256
2022-03-15 04:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:32:18 | INFO | train_inner | epoch 256:     84 / 103 loss=3.352, ppl=10.21, wps=40197.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26300, lr=0.000194994, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=42755
2022-03-15 04:32:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:32:51 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 9.26 | ppl 613.3 | wps 66284.8 | wpb 2040.3 | bsz 4 | num_updates 26319 | best_loss 7.217
2022-03-15 04:32:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 26319 updates
2022-03-15 04:32:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 256 @ 26319 updates, score 9.26) (writing took 0.920290982350707 seconds)
2022-03-15 04:32:52 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-15 04:32:52 | INFO | train | epoch 256 | loss 3.356 | ppl 10.24 | wps 40247.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26319 | lr 0.000194924 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42789
KL Stats: Epoch 256 Divergences: Uniform: 9.63464927729459 Unigram: 4.689253911800181
2022-03-15 04:32:52 | INFO | fairseq.trainer | begin training epoch 257
2022-03-15 04:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:35:01 | INFO | train_inner | epoch 257:     81 / 103 loss=3.354, ppl=10.22, wps=40214.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=26400, lr=0.000194625, gnorm=0.986, loss_scale=16, train_wall=153, gb_free=20.8, wall=42917
2022-03-15 04:35:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:35:38 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 9.256 | ppl 611.54 | wps 65864.9 | wpb 2040.3 | bsz 4 | num_updates 26422 | best_loss 7.217
2022-03-15 04:35:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 26422 updates
2022-03-15 04:35:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:35:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:35:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 257 @ 26422 updates, score 9.256) (writing took 0.8902203505858779 seconds)
2022-03-15 04:35:39 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-15 04:35:39 | INFO | train | epoch 257 | loss 3.354 | ppl 10.22 | wps 40246.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26422 | lr 0.000194544 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42956
KL Stats: Epoch 257 Divergences: Uniform: 9.636563023086328 Unigram: 4.691256405001574
2022-03-15 04:35:39 | INFO | fairseq.trainer | begin training epoch 258
2022-03-15 04:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:37:43 | INFO | train_inner | epoch 258:     78 / 103 loss=3.351, ppl=10.21, wps=40224.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=26500, lr=0.000194257, gnorm=0.992, loss_scale=16, train_wall=153, gb_free=20.8, wall=43079
2022-03-15 04:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:38:25 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 9.255 | ppl 610.96 | wps 66152.2 | wpb 2040.3 | bsz 4 | num_updates 26525 | best_loss 7.217
2022-03-15 04:38:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 26525 updates
2022-03-15 04:38:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:38:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:38:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 258 @ 26525 updates, score 9.255) (writing took 0.9005473358556628 seconds)
2022-03-15 04:38:26 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-15 04:38:26 | INFO | train | epoch 258 | loss 3.353 | ppl 10.22 | wps 40258.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26525 | lr 0.000194166 | gnorm 0.986 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43123
KL Stats: Epoch 258 Divergences: Uniform: 9.635443354863023 Unigram: 4.691054806528656
2022-03-15 04:38:26 | INFO | fairseq.trainer | begin training epoch 259
2022-03-15 04:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:40:25 | INFO | train_inner | epoch 259:     75 / 103 loss=3.351, ppl=10.2, wps=40165.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26600, lr=0.000193892, gnorm=0.987, loss_scale=16, train_wall=153, gb_free=20.8, wall=43242
2022-03-15 04:41:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:41:13 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 9.262 | ppl 613.96 | wps 66575.6 | wpb 2040.3 | bsz 4 | num_updates 26628 | best_loss 7.217
2022-03-15 04:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 26628 updates
2022-03-15 04:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:41:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:41:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 259 @ 26628 updates, score 9.262) (writing took 0.8653102023527026 seconds)
2022-03-15 04:41:14 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-15 04:41:14 | INFO | train | epoch 259 | loss 3.35 | ppl 10.2 | wps 40198.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26628 | lr 0.00019379 | gnorm 0.988 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 43290
KL Stats: Epoch 259 Divergences: Uniform: 9.640735692441266 Unigram: 4.692613615433755
2022-03-15 04:41:14 | INFO | fairseq.trainer | begin training epoch 260
2022-03-15 04:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:41:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:43:09 | INFO | train_inner | epoch 260:     73 / 103 loss=3.346, ppl=10.17, wps=39816, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=26700, lr=0.000193528, gnorm=0.989, loss_scale=16, train_wall=155, gb_free=20.8, wall=43406
2022-03-15 04:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:44:00 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 9.279 | ppl 621.2 | wps 66105.2 | wpb 2040.3 | bsz 4 | num_updates 26730 | best_loss 7.217
2022-03-15 04:44:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 26730 updates
2022-03-15 04:44:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:44:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:44:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 260 @ 26730 updates, score 9.279) (writing took 0.8845437671989202 seconds)
2022-03-15 04:44:01 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-15 04:44:01 | INFO | train | epoch 260 | loss 3.347 | ppl 10.17 | wps 39867.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26730 | lr 0.00019342 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43457
KL Stats: Epoch 260 Divergences: Uniform: 9.644896393411516 Unigram: 4.696091697934183
2022-03-15 04:44:01 | INFO | fairseq.trainer | begin training epoch 261
2022-03-15 04:44:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:45:52 | INFO | train_inner | epoch 261:     70 / 103 loss=3.345, ppl=10.16, wps=40214.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=26800, lr=0.000193167, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=43568
2022-03-15 04:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:46:47 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 9.283 | ppl 623.07 | wps 66442.6 | wpb 2040.3 | bsz 4 | num_updates 26833 | best_loss 7.217
2022-03-15 04:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 26833 updates
2022-03-15 04:46:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 261 @ 26833 updates, score 9.283) (writing took 0.8607584768906236 seconds)
2022-03-15 04:46:48 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-15 04:46:48 | INFO | train | epoch 261 | loss 3.345 | ppl 10.16 | wps 40232.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26833 | lr 0.000193048 | gnorm 0.998 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43624
KL Stats: Epoch 261 Divergences: Uniform: 9.649638213774614 Unigram: 4.699550447327199
2022-03-15 04:46:48 | INFO | fairseq.trainer | begin training epoch 262
2022-03-15 04:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:48:34 | INFO | train_inner | epoch 262:     67 / 103 loss=3.345, ppl=10.16, wps=40212.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26900, lr=0.000192807, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=43731
2022-03-15 04:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:49:34 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 9.264 | ppl 614.96 | wps 65795.3 | wpb 2040.3 | bsz 4 | num_updates 26936 | best_loss 7.217
2022-03-15 04:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 26936 updates
2022-03-15 04:49:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:49:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:49:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 262 @ 26936 updates, score 9.264) (writing took 0.8936268966645002 seconds)
2022-03-15 04:49:35 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-15 04:49:35 | INFO | train | epoch 262 | loss 3.344 | ppl 10.15 | wps 40233.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26936 | lr 0.000192679 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43792
KL Stats: Epoch 262 Divergences: Uniform: 9.648290936216444 Unigram: 4.699247352442964
2022-03-15 04:49:35 | INFO | fairseq.trainer | begin training epoch 263
2022-03-15 04:49:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:51:17 | INFO | train_inner | epoch 263:     64 / 103 loss=3.342, ppl=10.14, wps=40209.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27000, lr=0.00019245, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=43893
2022-03-15 04:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:52:21 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 9.271 | ppl 617.64 | wps 66221.7 | wpb 2040.3 | bsz 4 | num_updates 27039 | best_loss 7.217
2022-03-15 04:52:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 27039 updates
2022-03-15 04:52:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:52:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:52:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 263 @ 27039 updates, score 9.271) (writing took 0.8834452051669359 seconds)
2022-03-15 04:52:22 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-15 04:52:22 | INFO | train | epoch 263 | loss 3.342 | ppl 10.14 | wps 40260.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27039 | lr 0.000192311 | gnorm 0.998 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43959
KL Stats: Epoch 263 Divergences: Uniform: 9.651151119062417 Unigram: 4.700724701567492
2022-03-15 04:52:22 | INFO | fairseq.trainer | begin training epoch 264
2022-03-15 04:52:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:53:59 | INFO | train_inner | epoch 264:     61 / 103 loss=3.339, ppl=10.12, wps=40238.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=27100, lr=0.000192095, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=44055
2022-03-15 04:55:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:55:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:55:09 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 9.287 | ppl 624.81 | wps 65817.3 | wpb 2040.3 | bsz 4 | num_updates 27141 | best_loss 7.217
2022-03-15 04:55:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 27141 updates
2022-03-15 04:55:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 264 @ 27141 updates, score 9.287) (writing took 0.9038275638595223 seconds)
2022-03-15 04:55:10 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-15 04:55:10 | INFO | train | epoch 264 | loss 3.339 | ppl 10.12 | wps 39849 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27141 | lr 0.00019195 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44126
KL Stats: Epoch 264 Divergences: Uniform: 9.6530611198849 Unigram: 4.7018818415101284
2022-03-15 04:55:10 | INFO | fairseq.trainer | begin training epoch 265
2022-03-15 04:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:56:43 | INFO | train_inner | epoch 265:     59 / 103 loss=3.338, ppl=10.11, wps=39818.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=27200, lr=0.000191741, gnorm=0.989, loss_scale=16, train_wall=155, gb_free=20.8, wall=44219
2022-03-15 04:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:57:56 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 9.288 | ppl 624.92 | wps 66040.9 | wpb 2040.3 | bsz 4 | num_updates 27244 | best_loss 7.217
2022-03-15 04:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 27244 updates
2022-03-15 04:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 04:57:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 265 @ 27244 updates, score 9.288) (writing took 0.8955108793452382 seconds)
2022-03-15 04:57:57 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-15 04:57:57 | INFO | train | epoch 265 | loss 3.339 | ppl 10.12 | wps 40270.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27244 | lr 0.000191586 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44293
KL Stats: Epoch 265 Divergences: Uniform: 9.653035479479303 Unigram: 4.702155452951345
2022-03-15 04:57:57 | INFO | fairseq.trainer | begin training epoch 266
2022-03-15 04:57:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:59:25 | INFO | train_inner | epoch 266:     56 / 103 loss=3.333, ppl=10.08, wps=40215.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27300, lr=0.00019139, gnorm=0.991, loss_scale=16, train_wall=153, gb_free=20.8, wall=44382
2022-03-15 05:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:00:43 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 9.295 | ppl 628.32 | wps 66344.7 | wpb 2040.3 | bsz 4 | num_updates 27347 | best_loss 7.217
2022-03-15 05:00:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 27347 updates
2022-03-15 05:00:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:00:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 266 @ 27347 updates, score 9.295) (writing took 0.8747373577207327 seconds)
2022-03-15 05:00:44 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-15 05:00:44 | INFO | train | epoch 266 | loss 3.335 | ppl 10.09 | wps 40237.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27347 | lr 0.000191225 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44460
KL Stats: Epoch 266 Divergences: Uniform: 9.657732955635186 Unigram: 4.706334056903352
2022-03-15 05:00:44 | INFO | fairseq.trainer | begin training epoch 267
2022-03-15 05:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:02:08 | INFO | train_inner | epoch 267:     53 / 103 loss=3.339, ppl=10.12, wps=40204.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27400, lr=0.00019104, gnorm=0.992, loss_scale=16, train_wall=153, gb_free=20.8, wall=44544
2022-03-15 05:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:03:30 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 9.3 | ppl 630.2 | wps 66484.4 | wpb 2040.3 | bsz 4 | num_updates 27450 | best_loss 7.217
2022-03-15 05:03:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 27450 updates
2022-03-15 05:03:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:03:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:03:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 267 @ 27450 updates, score 9.3) (writing took 0.9011108232662082 seconds)
2022-03-15 05:03:31 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-15 05:03:31 | INFO | train | epoch 267 | loss 3.334 | ppl 10.08 | wps 40232.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27450 | lr 0.000190866 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44627
KL Stats: Epoch 267 Divergences: Uniform: 9.660369353804706 Unigram: 4.706718237043172
2022-03-15 05:03:31 | INFO | fairseq.trainer | begin training epoch 268
2022-03-15 05:03:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:04:50 | INFO | train_inner | epoch 268:     50 / 103 loss=3.33, ppl=10.05, wps=40215.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27500, lr=0.000190693, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=44707
2022-03-15 05:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:06:17 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 9.281 | ppl 622.21 | wps 66707.5 | wpb 2040.3 | bsz 4 | num_updates 27553 | best_loss 7.217
2022-03-15 05:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 27553 updates
2022-03-15 05:06:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:06:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 268 @ 27553 updates, score 9.281) (writing took 0.8561997292563319 seconds)
2022-03-15 05:06:18 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-15 05:06:18 | INFO | train | epoch 268 | loss 3.332 | ppl 10.07 | wps 40237.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27553 | lr 0.000190509 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44795
KL Stats: Epoch 268 Divergences: Uniform: 9.663867297493477 Unigram: 4.708450332394677
2022-03-15 05:06:18 | INFO | fairseq.trainer | begin training epoch 269
2022-03-15 05:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:07:33 | INFO | train_inner | epoch 269:     47 / 103 loss=3.33, ppl=10.06, wps=40209.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=27600, lr=0.000190347, gnorm=0.999, loss_scale=16, train_wall=153, gb_free=20.8, wall=44869
2022-03-15 05:08:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:09:04 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 9.298 | ppl 629.35 | wps 66506.1 | wpb 2040.3 | bsz 4 | num_updates 27655 | best_loss 7.217
2022-03-15 05:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 27655 updates
2022-03-15 05:09:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:09:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 269 @ 27655 updates, score 9.298) (writing took 0.8767244946211576 seconds)
2022-03-15 05:09:05 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-15 05:09:05 | INFO | train | epoch 269 | loss 3.328 | ppl 10.04 | wps 39863.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27655 | lr 0.000190157 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44962
KL Stats: Epoch 269 Divergences: Uniform: 9.662620815909843 Unigram: 4.709222301133813
2022-03-15 05:09:05 | INFO | fairseq.trainer | begin training epoch 270
2022-03-15 05:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:10:17 | INFO | train_inner | epoch 270:     45 / 103 loss=3.33, ppl=10.05, wps=39834.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=27700, lr=0.000190003, gnorm=0.997, loss_scale=16, train_wall=155, gb_free=20.8, wall=45033
2022-03-15 05:11:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:11:51 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 9.299 | ppl 629.98 | wps 66493.3 | wpb 2040.3 | bsz 4 | num_updates 27758 | best_loss 7.217
2022-03-15 05:11:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 27758 updates
2022-03-15 05:11:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:11:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:11:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 270 @ 27758 updates, score 9.299) (writing took 0.907484345138073 seconds)
2022-03-15 05:11:52 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-15 05:11:52 | INFO | train | epoch 270 | loss 3.327 | ppl 10.04 | wps 40268.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27758 | lr 0.000189804 | gnorm 0.986 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45129
KL Stats: Epoch 270 Divergences: Uniform: 9.670659713071688 Unigram: 4.711910738003258
2022-03-15 05:11:52 | INFO | fairseq.trainer | begin training epoch 271
2022-03-15 05:11:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:12:59 | INFO | train_inner | epoch 271:     42 / 103 loss=3.326, ppl=10.03, wps=40230.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=27800, lr=0.000189661, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=45195
2022-03-15 05:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:14:39 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 9.303 | ppl 631.67 | wps 66396.4 | wpb 2040.3 | bsz 4 | num_updates 27861 | best_loss 7.217
2022-03-15 05:14:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 27861 updates
2022-03-15 05:14:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:14:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:14:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 271 @ 27861 updates, score 9.303) (writing took 0.9045570883899927 seconds)
2022-03-15 05:14:39 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-15 05:14:39 | INFO | train | epoch 271 | loss 3.326 | ppl 10.03 | wps 40237.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27861 | lr 0.000189453 | gnorm 0.987 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45296
KL Stats: Epoch 271 Divergences: Uniform: 9.669340398970137 Unigram: 4.712765927330542
2022-03-15 05:14:40 | INFO | fairseq.trainer | begin training epoch 272
2022-03-15 05:14:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:15:41 | INFO | train_inner | epoch 272:     39 / 103 loss=3.326, ppl=10.03, wps=40207.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27900, lr=0.000189321, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=45358
2022-03-15 05:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:17:26 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 9.299 | ppl 629.71 | wps 66161.6 | wpb 2040.3 | bsz 4 | num_updates 27964 | best_loss 7.217
2022-03-15 05:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 27964 updates
2022-03-15 05:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 272 @ 27964 updates, score 9.299) (writing took 0.8895561741665006 seconds)
2022-03-15 05:17:27 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-15 05:17:27 | INFO | train | epoch 272 | loss 3.324 | ppl 10.02 | wps 40252.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27964 | lr 0.000189104 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45463
KL Stats: Epoch 272 Divergences: Uniform: 9.671452165290072 Unigram: 4.715285709615401
2022-03-15 05:17:27 | INFO | fairseq.trainer | begin training epoch 273
2022-03-15 05:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:18:24 | INFO | train_inner | epoch 273:     36 / 103 loss=3.321, ppl=10, wps=40226.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28000, lr=0.000188982, gnorm=1.008, loss_scale=16, train_wall=153, gb_free=20.8, wall=45520
2022-03-15 05:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:20:13 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 9.304 | ppl 632.2 | wps 66477.3 | wpb 2040.3 | bsz 4 | num_updates 28067 | best_loss 7.217
2022-03-15 05:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 28067 updates
2022-03-15 05:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:20:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 273 @ 28067 updates, score 9.304) (writing took 0.8967850618064404 seconds)
2022-03-15 05:20:14 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-15 05:20:14 | INFO | train | epoch 273 | loss 3.322 | ppl 10 | wps 40256.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28067 | lr 0.000188757 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45630
KL Stats: Epoch 273 Divergences: Uniform: 9.671797891485642 Unigram: 4.715727843971716
2022-03-15 05:20:14 | INFO | fairseq.trainer | begin training epoch 274
2022-03-15 05:20:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:21:06 | INFO | train_inner | epoch 274:     33 / 103 loss=3.322, ppl=10, wps=40222, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28100, lr=0.000188646, gnorm=0.995, loss_scale=16, train_wall=153, gb_free=20.8, wall=45682
2022-03-15 05:22:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:23:00 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 9.303 | ppl 631.58 | wps 65820.2 | wpb 2040.3 | bsz 4 | num_updates 28169 | best_loss 7.217
2022-03-15 05:23:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 28169 updates
2022-03-15 05:23:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:23:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:23:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 274 @ 28169 updates, score 9.303) (writing took 0.8706989185884595 seconds)
2022-03-15 05:23:01 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-15 05:23:01 | INFO | train | epoch 274 | loss 3.319 | ppl 9.98 | wps 39870 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28169 | lr 0.000188414 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45797
KL Stats: Epoch 274 Divergences: Uniform: 9.67720655418135 Unigram: 4.717042706985165
2022-03-15 05:23:01 | INFO | fairseq.trainer | begin training epoch 275
2022-03-15 05:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:23:50 | INFO | train_inner | epoch 275:     31 / 103 loss=3.321, ppl=9.99, wps=39828.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=28200, lr=0.000188311, gnorm=0.989, loss_scale=16, train_wall=155, gb_free=20.8, wall=45846
2022-03-15 05:25:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:25:47 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 9.298 | ppl 629.34 | wps 66381.6 | wpb 2040.3 | bsz 4 | num_updates 28272 | best_loss 7.217
2022-03-15 05:25:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 28272 updates
2022-03-15 05:25:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 275 @ 28272 updates, score 9.298) (writing took 0.8885630760341883 seconds)
2022-03-15 05:25:48 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-15 05:25:48 | INFO | train | epoch 275 | loss 3.319 | ppl 9.98 | wps 40249 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28272 | lr 0.000188071 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45964
KL Stats: Epoch 275 Divergences: Uniform: 9.6773374596077 Unigram: 4.718260406825244
2022-03-15 05:25:48 | INFO | fairseq.trainer | begin training epoch 276
2022-03-15 05:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:26:32 | INFO | train_inner | epoch 276:     28 / 103 loss=3.318, ppl=9.97, wps=40228.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=28300, lr=0.000187978, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=46009
2022-03-15 05:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:28:34 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 9.309 | ppl 634.33 | wps 66505.6 | wpb 2040.3 | bsz 4 | num_updates 28375 | best_loss 7.217
2022-03-15 05:28:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 28375 updates
2022-03-15 05:28:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:28:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:28:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 276 @ 28375 updates, score 9.309) (writing took 0.8736914023756981 seconds)
2022-03-15 05:28:35 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-15 05:28:35 | INFO | train | epoch 276 | loss 3.317 | ppl 9.96 | wps 40240.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28375 | lr 0.000187729 | gnorm 1.013 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46132
KL Stats: Epoch 276 Divergences: Uniform: 9.680616119092946 Unigram: 4.720756680950517
2022-03-15 05:28:35 | INFO | fairseq.trainer | begin training epoch 277
2022-03-15 05:28:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:29:15 | INFO | train_inner | epoch 277:     25 / 103 loss=3.317, ppl=9.97, wps=40203.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28400, lr=0.000187647, gnorm=1.018, loss_scale=16, train_wall=153, gb_free=20.8, wall=46171
2022-03-15 05:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:31:21 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 9.303 | ppl 631.77 | wps 66116.6 | wpb 2040.3 | bsz 4 | num_updates 28478 | best_loss 7.217
2022-03-15 05:31:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 28478 updates
2022-03-15 05:31:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:31:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 277 @ 28478 updates, score 9.303) (writing took 0.9170555863529444 seconds)
2022-03-15 05:31:22 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-15 05:31:22 | INFO | train | epoch 277 | loss 3.314 | ppl 9.95 | wps 40228.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28478 | lr 0.00018739 | gnorm 1.002 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46299
KL Stats: Epoch 277 Divergences: Uniform: 9.68221570864106 Unigram: 4.722564255678289
2022-03-15 05:31:22 | INFO | fairseq.trainer | begin training epoch 278
2022-03-15 05:31:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:31:57 | INFO | train_inner | epoch 278:     22 / 103 loss=3.315, ppl=9.95, wps=40195.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28500, lr=0.000187317, gnorm=0.99, loss_scale=16, train_wall=153, gb_free=20.8, wall=46334
2022-03-15 05:34:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:34:08 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 9.302 | ppl 631.04 | wps 66006.4 | wpb 2040.3 | bsz 4 | num_updates 28581 | best_loss 7.217
2022-03-15 05:34:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 28581 updates
2022-03-15 05:34:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:34:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:34:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 278 @ 28581 updates, score 9.302) (writing took 0.8996563777327538 seconds)
2022-03-15 05:34:09 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-15 05:34:09 | INFO | train | epoch 278 | loss 3.312 | ppl 9.93 | wps 40289.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28581 | lr 0.000187052 | gnorm 0.99 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46466
KL Stats: Epoch 278 Divergences: Uniform: 9.67996482414198 Unigram: 4.724575453797172
2022-03-15 05:34:09 | INFO | fairseq.trainer | begin training epoch 279
2022-03-15 05:34:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:34:39 | INFO | train_inner | epoch 279:     19 / 103 loss=3.312, ppl=9.93, wps=40259, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28600, lr=0.000186989, gnorm=0.995, loss_scale=16, train_wall=153, gb_free=20.8, wall=46496
2022-03-15 05:36:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:36:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:36:56 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 9.306 | ppl 632.83 | wps 66225.7 | wpb 2040.3 | bsz 4 | num_updates 28683 | best_loss 7.217
2022-03-15 05:36:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 28683 updates
2022-03-15 05:36:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:36:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:36:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 279 @ 28683 updates, score 9.306) (writing took 0.9056902108713984 seconds)
2022-03-15 05:36:56 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-15 05:36:56 | INFO | train | epoch 279 | loss 3.311 | ppl 9.92 | wps 39862.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28683 | lr 0.000186719 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46633
KL Stats: Epoch 279 Divergences: Uniform: 9.684042231288627 Unigram: 4.723832931602733
2022-03-15 05:36:56 | INFO | fairseq.trainer | begin training epoch 280
2022-03-15 05:36:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:37:23 | INFO | train_inner | epoch 280:     17 / 103 loss=3.313, ppl=9.94, wps=39820.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28700, lr=0.000186663, gnorm=0.999, loss_scale=16, train_wall=155, gb_free=20.8, wall=46660
2022-03-15 05:39:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:39:43 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 9.319 | ppl 638.78 | wps 66822.1 | wpb 2040.3 | bsz 4 | num_updates 28786 | best_loss 7.217
2022-03-15 05:39:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 28786 updates
2022-03-15 05:39:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 280 @ 28786 updates, score 9.319) (writing took 0.9129044963046908 seconds)
2022-03-15 05:39:44 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-15 05:39:44 | INFO | train | epoch 280 | loss 3.309 | ppl 9.91 | wps 40220.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28786 | lr 0.000186384 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46800
KL Stats: Epoch 280 Divergences: Uniform: 9.686790006973586 Unigram: 4.7261010420765235
2022-03-15 05:39:44 | INFO | fairseq.trainer | begin training epoch 281
2022-03-15 05:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:40:06 | INFO | train_inner | epoch 281:     14 / 103 loss=3.309, ppl=9.91, wps=40202.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28800, lr=0.000186339, gnorm=0.995, loss_scale=16, train_wall=153, gb_free=20.8, wall=46822
2022-03-15 05:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:42:30 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 9.314 | ppl 636.36 | wps 66018 | wpb 2040.3 | bsz 4 | num_updates 28889 | best_loss 7.217
2022-03-15 05:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 28889 updates
2022-03-15 05:42:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:42:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:42:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 281 @ 28889 updates, score 9.314) (writing took 0.8941314537078142 seconds)
2022-03-15 05:42:31 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-15 05:42:31 | INFO | train | epoch 281 | loss 3.308 | ppl 9.9 | wps 40250.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28889 | lr 0.000186052 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 46967
KL Stats: Epoch 281 Divergences: Uniform: 9.687210230320506 Unigram: 4.727455550864059
2022-03-15 05:42:31 | INFO | fairseq.trainer | begin training epoch 282
2022-03-15 05:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:42:48 | INFO | train_inner | epoch 282:     11 / 103 loss=3.309, ppl=9.91, wps=40215.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=28900, lr=0.000186016, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=46985
2022-03-15 05:45:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:45:17 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 9.338 | ppl 647.32 | wps 66605.8 | wpb 2040.3 | bsz 4 | num_updates 28992 | best_loss 7.217
2022-03-15 05:45:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 28992 updates
2022-03-15 05:45:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:45:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 282 @ 28992 updates, score 9.338) (writing took 0.8934033149853349 seconds)
2022-03-15 05:45:18 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-15 05:45:18 | INFO | train | epoch 282 | loss 3.306 | ppl 9.89 | wps 40273 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28992 | lr 0.000185721 | gnorm 0.994 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47134
KL Stats: Epoch 282 Divergences: Uniform: 9.693153591654063 Unigram: 4.729635183229829
2022-03-15 05:45:18 | INFO | fairseq.trainer | begin training epoch 283
2022-03-15 05:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:45:31 | INFO | train_inner | epoch 283:      8 / 103 loss=3.307, ppl=9.9, wps=40244.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29000, lr=0.000185695, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=47147
2022-03-15 05:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:48:04 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 9.327 | ppl 642.17 | wps 66194.7 | wpb 2040.3 | bsz 4 | num_updates 29095 | best_loss 7.217
2022-03-15 05:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 29095 updates
2022-03-15 05:48:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:48:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 283 @ 29095 updates, score 9.327) (writing took 0.9001528127118945 seconds)
2022-03-15 05:48:05 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-15 05:48:05 | INFO | train | epoch 283 | loss 3.303 | ppl 9.87 | wps 40254 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29095 | lr 0.000185392 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47301
KL Stats: Epoch 283 Divergences: Uniform: 9.693906894471988 Unigram: 4.7311020911814055
2022-03-15 05:48:05 | INFO | fairseq.trainer | begin training epoch 284
2022-03-15 05:48:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:48:13 | INFO | train_inner | epoch 284:      5 / 103 loss=3.306, ppl=9.89, wps=40216.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29100, lr=0.000185376, gnorm=0.987, loss_scale=16, train_wall=153, gb_free=20.8, wall=47309
2022-03-15 05:50:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:50:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:50:51 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 9.337 | ppl 646.93 | wps 66151.6 | wpb 2040.3 | bsz 4 | num_updates 29197 | best_loss 7.217
2022-03-15 05:50:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 29197 updates
2022-03-15 05:50:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 284 @ 29197 updates, score 9.337) (writing took 0.8705854509025812 seconds)
2022-03-15 05:50:52 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-15 05:50:52 | INFO | train | epoch 284 | loss 3.302 | ppl 9.86 | wps 39864.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29197 | lr 0.000185068 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47469
KL Stats: Epoch 284 Divergences: Uniform: 9.6968223720493 Unigram: 4.732604200272667
2022-03-15 05:50:52 | INFO | fairseq.trainer | begin training epoch 285
2022-03-15 05:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:50:57 | INFO | train_inner | epoch 285:      3 / 103 loss=3.301, ppl=9.86, wps=39826.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29200, lr=0.000185058, gnorm=0.99, loss_scale=16, train_wall=155, gb_free=20.8, wall=47473
2022-03-15 05:53:35 | INFO | train_inner | epoch 285:    103 / 103 loss=3.302, ppl=9.86, wps=41303.4, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=29300, lr=0.000184742, gnorm=0.99, loss_scale=16, train_wall=153, gb_free=20.8, wall=47631
2022-03-15 05:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:53:39 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 9.331 | ppl 644.24 | wps 66133.9 | wpb 2040.3 | bsz 4 | num_updates 29300 | best_loss 7.217
2022-03-15 05:53:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 29300 updates
2022-03-15 05:53:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:53:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 285 @ 29300 updates, score 9.331) (writing took 0.847479940392077 seconds)
2022-03-15 05:53:39 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-15 05:53:39 | INFO | train | epoch 285 | loss 3.3 | ppl 9.85 | wps 40185.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29300 | lr 0.000184742 | gnorm 0.989 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47636
KL Stats: Epoch 285 Divergences: Uniform: 9.69869052049385 Unigram: 4.733758053318373
2022-03-15 05:53:39 | INFO | fairseq.trainer | begin training epoch 286
2022-03-15 05:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:56:18 | INFO | train_inner | epoch 286:    100 / 103 loss=3.297, ppl=9.83, wps=40168.8, ups=0.61, wpb=65530.9, bsz=128, num_updates=29400, lr=0.000184428, gnorm=0.99, loss_scale=16, train_wall=154, gb_free=20.8, wall=47795
2022-03-15 05:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:56:26 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 9.331 | ppl 644.24 | wps 66331.3 | wpb 2040.3 | bsz 4 | num_updates 29403 | best_loss 7.217
2022-03-15 05:56:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 29403 updates
2022-03-15 05:56:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:56:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 286 @ 29403 updates, score 9.331) (writing took 0.8821752266958356 seconds)
2022-03-15 05:56:27 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-15 05:56:27 | INFO | train | epoch 286 | loss 3.299 | ppl 9.84 | wps 40192.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29403 | lr 0.000184418 | gnorm 0.991 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47803
KL Stats: Epoch 286 Divergences: Uniform: 9.698146064424392 Unigram: 4.734271336829412
2022-03-15 05:56:27 | INFO | fairseq.trainer | begin training epoch 287
2022-03-15 05:56:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:59:01 | INFO | train_inner | epoch 287:     97 / 103 loss=3.297, ppl=9.83, wps=40123, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=29500, lr=0.000184115, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=47957
2022-03-15 05:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:59:14 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 9.323 | ppl 640.67 | wps 66305.1 | wpb 2040.3 | bsz 4 | num_updates 29506 | best_loss 7.217
2022-03-15 05:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 29506 updates
2022-03-15 05:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:59:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 05:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 287 @ 29506 updates, score 9.323) (writing took 0.8677643956616521 seconds)
2022-03-15 05:59:14 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-15 05:59:14 | INFO | train | epoch 287 | loss 3.297 | ppl 9.83 | wps 40151.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 29506 | lr 0.000184096 | gnorm 1.001 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47971
KL Stats: Epoch 287 Divergences: Uniform: 9.70125358009128 Unigram: 4.736162791124115
2022-03-15 05:59:14 | INFO | fairseq.trainer | begin training epoch 288
2022-03-15 05:59:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:01:44 | INFO | train_inner | epoch 288:     94 / 103 loss=3.294, ppl=9.81, wps=40145.8, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=29600, lr=0.000183804, gnorm=0.997, loss_scale=16, train_wall=153, gb_free=20.8, wall=48120
2022-03-15 06:01:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:02:01 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 9.331 | ppl 644.11 | wps 65980.5 | wpb 2040.3 | bsz 4 | num_updates 29609 | best_loss 7.217
2022-03-15 06:02:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 29609 updates
2022-03-15 06:02:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:02:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:02:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 288 @ 29609 updates, score 9.331) (writing took 0.8574845790863037 seconds)
2022-03-15 06:02:02 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-15 06:02:02 | INFO | train | epoch 288 | loss 3.296 | ppl 9.82 | wps 40195.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29609 | lr 0.000183776 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48138
KL Stats: Epoch 288 Divergences: Uniform: 9.700934014665856 Unigram: 4.735529325288111
2022-03-15 06:02:02 | INFO | fairseq.trainer | begin training epoch 289
2022-03-15 06:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:04:26 | INFO | train_inner | epoch 289:     91 / 103 loss=3.292, ppl=9.8, wps=40155.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29700, lr=0.000183494, gnorm=0.998, loss_scale=32, train_wall=153, gb_free=20.8, wall=48283
2022-03-15 06:04:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 06:04:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:04:48 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 9.337 | ppl 646.67 | wps 65944 | wpb 2040.3 | bsz 4 | num_updates 29711 | best_loss 7.217
2022-03-15 06:04:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 29711 updates
2022-03-15 06:04:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:04:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:04:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 289 @ 29711 updates, score 9.337) (writing took 0.8522552102804184 seconds)
2022-03-15 06:04:49 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-15 06:04:49 | INFO | train | epoch 289 | loss 3.293 | ppl 9.8 | wps 39786.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29711 | lr 0.00018346 | gnorm 1.001 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48306
KL Stats: Epoch 289 Divergences: Uniform: 9.701207727402087 Unigram: 4.737782629082509
2022-03-15 06:04:49 | INFO | fairseq.trainer | begin training epoch 290
2022-03-15 06:04:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:07:10 | INFO | train_inner | epoch 290:     89 / 103 loss=3.289, ppl=9.77, wps=39767.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29800, lr=0.000183186, gnorm=1.006, loss_scale=16, train_wall=155, gb_free=20.8, wall=48447
2022-03-15 06:07:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:07:36 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 9.342 | ppl 648.81 | wps 66294.2 | wpb 2040.3 | bsz 4 | num_updates 29814 | best_loss 7.217
2022-03-15 06:07:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 29814 updates
2022-03-15 06:07:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:07:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 290 @ 29814 updates, score 9.342) (writing took 0.874665173701942 seconds)
2022-03-15 06:07:37 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-15 06:07:37 | INFO | train | epoch 290 | loss 3.292 | ppl 9.79 | wps 40188.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29814 | lr 0.000183143 | gnorm 1.002 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48473
KL Stats: Epoch 290 Divergences: Uniform: 9.707720337811969 Unigram: 4.739725975816677
2022-03-15 06:07:37 | INFO | fairseq.trainer | begin training epoch 291
2022-03-15 06:07:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:09:53 | INFO | train_inner | epoch 291:     86 / 103 loss=3.291, ppl=9.79, wps=40157.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29900, lr=0.000182879, gnorm=1.006, loss_scale=16, train_wall=153, gb_free=20.8, wall=48610
2022-03-15 06:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:10:23 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 9.333 | ppl 644.95 | wps 66268.9 | wpb 2040.3 | bsz 4 | num_updates 29917 | best_loss 7.217
2022-03-15 06:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 29917 updates
2022-03-15 06:10:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:10:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 291 @ 29917 updates, score 9.333) (writing took 0.8789962371811271 seconds)
2022-03-15 06:10:24 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-15 06:10:24 | INFO | train | epoch 291 | loss 3.29 | ppl 9.78 | wps 40205.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29917 | lr 0.000182827 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48640
KL Stats: Epoch 291 Divergences: Uniform: 9.705191519015763 Unigram: 4.740813535625069
2022-03-15 06:10:24 | INFO | fairseq.trainer | begin training epoch 292
2022-03-15 06:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:12:36 | INFO | train_inner | epoch 292:     83 / 103 loss=3.288, ppl=9.77, wps=40204.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30000, lr=0.000182574, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=48772
2022-03-15 06:13:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:13:10 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 9.342 | ppl 648.88 | wps 66070.4 | wpb 2040.3 | bsz 4 | num_updates 30020 | best_loss 7.217
2022-03-15 06:13:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 30020 updates
2022-03-15 06:13:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:13:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:13:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 292 @ 30020 updates, score 9.342) (writing took 0.8672655047848821 seconds)
2022-03-15 06:13:11 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-15 06:13:11 | INFO | train | epoch 292 | loss 3.288 | ppl 9.77 | wps 40205.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30020 | lr 0.000182513 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48808
KL Stats: Epoch 292 Divergences: Uniform: 9.708834566128258 Unigram: 4.742316247225246
2022-03-15 06:13:11 | INFO | fairseq.trainer | begin training epoch 293
2022-03-15 06:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:15:18 | INFO | train_inner | epoch 293:     80 / 103 loss=3.287, ppl=9.76, wps=40163, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30100, lr=0.000182271, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=48935
2022-03-15 06:15:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:15:58 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 9.338 | ppl 646.99 | wps 66239.9 | wpb 2040.3 | bsz 4 | num_updates 30123 | best_loss 7.217
2022-03-15 06:15:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 30123 updates
2022-03-15 06:15:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:15:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:15:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 293 @ 30123 updates, score 9.338) (writing took 0.8559374799951911 seconds)
2022-03-15 06:15:58 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-15 06:15:58 | INFO | train | epoch 293 | loss 3.286 | ppl 9.75 | wps 40226.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30123 | lr 0.000182201 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 48975
KL Stats: Epoch 293 Divergences: Uniform: 9.7104208708774 Unigram: 4.743571982431079
2022-03-15 06:15:58 | INFO | fairseq.trainer | begin training epoch 294
2022-03-15 06:15:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:18:01 | INFO | train_inner | epoch 294:     77 / 103 loss=3.281, ppl=9.72, wps=40189.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30200, lr=0.000181969, gnorm=1.008, loss_scale=16, train_wall=153, gb_free=20.8, wall=49097
2022-03-15 06:18:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 06:18:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:18:45 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 9.347 | ppl 651.2 | wps 65922.7 | wpb 2040.3 | bsz 4 | num_updates 30225 | best_loss 7.217
2022-03-15 06:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 30225 updates
2022-03-15 06:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt
2022-03-15 06:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.0_0.075_0.925_#1/checkpoint_last.pt (epoch 294 @ 30225 updates, score 9.347) (writing took 0.8716573342680931 seconds)
2022-03-15 06:18:46 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-15 06:18:46 | INFO | train | epoch 294 | loss 3.284 | ppl 9.74 | wps 39809.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 30225 | lr 0.000181893 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 49142
KL Stats: Epoch 294 Divergences: Uniform: 9.716151986046722 Unigram: 4.746888125069924
2022-03-15 06:18:46 | INFO | fairseq.trainer | begin training epoch 295
2022-03-15 06:18:46 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 496, in train_step
    optimizer.backward(loss)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
KeyboardInterrupt
