Sender: LSF System <lsfadmin@eu-g3-053>
Subject: Job 209983641: <iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1> was submitted from host <eu-login-04> by user <andriusb> in cluster <euler> at Sun Mar 20 09:01:23 2022
Job was executed on host(s) <eu-g3-053>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Sun Mar 20 09:01:38 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 20 09:01:38 2022
Terminated at Sun Mar 20 10:20:49 2022
Results reported at Sun Mar 20 10:20:49 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.4 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.19,0.01,0.80\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4738.06 sec.
    Max Memory :                                 5699 MB
    Average Memory :                             4058.62 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14301.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4750 sec.
    Turnaround time :                            4766 sec.

The output (if any) follows:

2022-03-20 09:01:44 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.19,0.01,0.80)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.4, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.19,0.01,0.80)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-20 09:01:44 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-20 09:01:44 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-20 09:01:45 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 09:01:45 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 09:01:45 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1141/160239 [00:00<00:13, 11406.75it/s]  2%|▏         | 2490/160239 [00:00<00:12, 12630.97it/s]  2%|▏         | 3868/160239 [00:00<00:11, 13151.30it/s]  3%|▎         | 5184/160239 [00:00<00:11, 13107.59it/s]  4%|▍         | 6495/160239 [00:00<00:11, 12989.54it/s]  5%|▍         | 7795/160239 [00:00<00:11, 12823.03it/s]  6%|▌         | 9078/160239 [00:00<00:11, 12716.55it/s]  6%|▋         | 10413/160239 [00:00<00:11, 12912.52it/s]  7%|▋         | 11705/160239 [00:00<00:11, 12784.68it/s]  8%|▊         | 12998/160239 [00:01<00:11, 12826.64it/s]  9%|▉         | 14282/160239 [00:01<00:11, 12730.08it/s] 10%|▉         | 15556/160239 [00:01<00:11, 12694.43it/s] 11%|█         | 16826/160239 [00:01<00:11, 12516.55it/s] 11%|█▏        | 18104/160239 [00:01<00:11, 12592.06it/s] 12%|█▏        | 19364/160239 [00:01<00:11, 12567.96it/s] 13%|█▎        | 20772/160239 [00:01<00:10, 13014.89it/s] 14%|█▍        | 22075/160239 [00:01<00:11, 12551.17it/s] 15%|█▍        | 23334/160239 [00:01<00:10, 12549.84it/s] 15%|█▌        | 24627/160239 [00:01<00:10, 12660.03it/s] 16%|█▌        | 25900/160239 [00:02<00:10, 12679.65it/s] 17%|█▋        | 27170/160239 [00:02<00:10, 12566.81it/s] 18%|█▊        | 28507/160239 [00:02<00:10, 12803.16it/s] 19%|█▊        | 29789/160239 [00:02<00:10, 12582.76it/s] 19%|█▉        | 31049/160239 [00:02<00:10, 12310.75it/s] 20%|██        | 32396/160239 [00:02<00:10, 12647.32it/s] 21%|██        | 33664/160239 [00:02<00:10, 12426.90it/s] 22%|██▏       | 34909/160239 [00:02<00:10, 12277.68it/s] 23%|██▎       | 36224/160239 [00:02<00:09, 12531.86it/s] 23%|██▎       | 37479/160239 [00:02<00:09, 12471.38it/s] 24%|██▍       | 38771/160239 [00:03<00:09, 12603.11it/s] 25%|██▍       | 40035/160239 [00:03<00:09, 12613.12it/s] 26%|██▌       | 41372/160239 [00:03<00:09, 12837.56it/s] 27%|██▋       | 42657/160239 [00:03<00:09, 12404.92it/s] 27%|██▋       | 43901/160239 [00:03<00:09, 12402.79it/s] 28%|██▊       | 45144/160239 [00:03<00:09, 12315.38it/s] 29%|██▉       | 46453/160239 [00:03<00:09, 12542.93it/s] 30%|██▉       | 47802/160239 [00:03<00:08, 12819.73it/s] 31%|███       | 49086/160239 [00:03<00:08, 12684.77it/s] 31%|███▏      | 50356/160239 [00:03<00:08, 12562.83it/s] 32%|███▏      | 51675/160239 [00:04<00:08, 12745.77it/s] 33%|███▎      | 52975/160239 [00:04<00:08, 12820.25it/s] 34%|███▍      | 54258/160239 [00:04<00:08, 12753.82it/s] 35%|███▍      | 55534/160239 [00:04<00:08, 12653.23it/s] 36%|███▌      | 56903/160239 [00:04<00:07, 12958.72it/s] 36%|███▋      | 58261/160239 [00:04<00:07, 13141.01it/s] 37%|███▋      | 59576/160239 [00:04<00:07, 13132.59it/s] 38%|███▊      | 60890/160239 [00:04<00:07, 13010.75it/s] 39%|███▉      | 62192/160239 [00:04<00:07, 12975.39it/s] 40%|███▉      | 63530/160239 [00:04<00:07, 13094.21it/s] 41%|████      | 65018/160239 [00:05<00:06, 13625.17it/s] 41%|████▏     | 66382/160239 [00:05<00:07, 13313.73it/s] 42%|████▏     | 67716/160239 [00:05<00:07, 12888.50it/s] 43%|████▎     | 69009/160239 [00:05<00:07, 12667.29it/s] 44%|████▍     | 70322/160239 [00:05<00:07, 12800.05it/s] 45%|████▍     | 71605/160239 [00:05<00:06, 12796.85it/s] 45%|████▌     | 72887/160239 [00:05<00:06, 12714.36it/s] 46%|████▋     | 74160/160239 [00:05<00:06, 12610.21it/s] 47%|████▋     | 75422/160239 [00:05<00:06, 12569.56it/s] 48%|████▊     | 76688/160239 [00:06<00:06, 12587.81it/s] 49%|████▊     | 78069/160239 [00:06<00:06, 12947.42it/s] 50%|████▉     | 79419/160239 [00:06<00:06, 13111.00it/s] 50%|█████     | 80807/160239 [00:06<00:05, 13339.57it/s] 51%|█████▏    | 82142/160239 [00:06<00:05, 13245.84it/s] 52%|█████▏    | 83482/160239 [00:06<00:05, 13291.63it/s] 53%|█████▎    | 84812/160239 [00:06<00:05, 13146.81it/s] 54%|█████▍    | 86223/160239 [00:06<00:05, 13428.78it/s] 55%|█████▍    | 87624/160239 [00:06<00:05, 13601.49it/s] 56%|█████▌    | 88985/160239 [00:06<00:05, 13298.05it/s] 56%|█████▋    | 90317/160239 [00:07<00:05, 13212.33it/s] 57%|█████▋    | 91640/160239 [00:07<00:05, 13074.58it/s] 58%|█████▊    | 92949/160239 [00:07<00:05, 13056.04it/s] 59%|█████▉    | 94256/160239 [00:07<00:05, 12692.31it/s] 60%|█████▉    | 95548/160239 [00:07<00:05, 12757.79it/s] 60%|██████    | 96838/160239 [00:07<00:04, 12797.99it/s] 61%|██████    | 98137/160239 [00:07<00:04, 12852.60it/s] 62%|██████▏   | 99460/160239 [00:07<00:04, 12963.85it/s] 63%|██████▎   | 100821/160239 [00:07<00:04, 13156.09it/s] 64%|██████▎   | 102138/160239 [00:07<00:04, 13154.23it/s] 65%|██████▍   | 103454/160239 [00:08<00:04, 12838.20it/s] 65%|██████▌   | 104853/160239 [00:08<00:04, 13175.90it/s] 66%|██████▋   | 106173/160239 [00:08<00:04, 13073.70it/s] 67%|██████▋   | 107482/160239 [00:08<00:04, 12868.52it/s] 68%|██████▊   | 108771/160239 [00:08<00:04, 12658.70it/s] 69%|██████▊   | 110039/160239 [00:08<00:04, 12538.69it/s] 69%|██████▉   | 111357/160239 [00:08<00:03, 12723.55it/s] 70%|███████   | 112691/160239 [00:08<00:03, 12901.56it/s] 71%|███████   | 113993/160239 [00:08<00:03, 12934.83it/s] 72%|███████▏  | 115288/160239 [00:08<00:03, 12846.64it/s] 73%|███████▎  | 116574/160239 [00:09<00:03, 12713.32it/s] 74%|███████▎  | 117846/160239 [00:09<00:03, 12714.32it/s] 74%|███████▍  | 119200/160239 [00:09<00:03, 12958.20it/s] 75%|███████▌  | 120497/160239 [00:09<00:03, 12531.91it/s] 76%|███████▌  | 121864/160239 [00:09<00:02, 12862.15it/s] 77%|███████▋  | 123225/160239 [00:09<00:02, 13079.86it/s] 78%|███████▊  | 124536/160239 [00:09<00:02, 12868.00it/s] 79%|███████▊  | 125826/160239 [00:09<00:02, 12726.69it/s] 79%|███████▉  | 127117/160239 [00:09<00:02, 12777.27it/s] 80%|████████  | 128483/160239 [00:10<00:02, 13035.19it/s] 81%|████████  | 129788/160239 [00:10<00:02, 12806.70it/s] 82%|████████▏ | 131071/160239 [00:10<00:02, 12562.03it/s] 83%|████████▎ | 132329/160239 [00:10<00:02, 12563.36it/s] 83%|████████▎ | 133587/160239 [00:10<00:02, 12510.88it/s] 84%|████████▍ | 134859/160239 [00:10<00:02, 12571.15it/s] 85%|████████▍ | 136134/160239 [00:10<00:01, 12621.46it/s] 86%|████████▌ | 137451/160239 [00:10<00:01, 12784.34it/s] 87%|████████▋ | 138796/160239 [00:10<00:01, 12980.64it/s] 87%|████████▋ | 140141/160239 [00:10<00:01, 13118.80it/s] 88%|████████▊ | 141478/160239 [00:11<00:01, 13193.43it/s] 89%|████████▉ | 142798/160239 [00:11<00:01, 12827.03it/s] 90%|████████▉ | 144084/160239 [00:11<00:01, 12784.60it/s] 91%|█████████ | 145367/160239 [00:11<00:01, 12796.06it/s] 92%|█████████▏| 146648/160239 [00:11<00:01, 12583.53it/s] 92%|█████████▏| 147908/160239 [00:11<00:00, 12562.21it/s] 93%|█████████▎| 149166/160239 [00:11<00:00, 12292.21it/s] 94%|█████████▍| 150459/160239 [00:11<00:00, 12477.73it/s] 95%|█████████▍| 151749/160239 [00:11<00:00, 12598.47it/s] 95%|█████████▌| 153011/160239 [00:11<00:00, 12533.24it/s] 96%|█████████▋| 154284/160239 [00:12<00:00, 12589.22it/s] 97%|█████████▋| 155649/160239 [00:12<00:00, 12901.65it/s] 98%|█████████▊| 156965/160239 [00:12<00:00, 12977.73it/s] 99%|█████████▉| 158264/160239 [00:12<00:00, 12658.66it/s]100%|█████████▉| 159624/160239 [00:12<00:00, 12932.24it/s]100%|██████████| 160239/160239 [00:12<00:00, 12805.58it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3789/160239 [00:00<00:04, 37888.05it/s]  5%|▍         | 7648/160239 [00:00<00:03, 38298.07it/s]  7%|▋         | 11550/160239 [00:00<00:03, 38622.34it/s] 10%|▉         | 15413/160239 [00:00<00:03, 38426.00it/s] 12%|█▏        | 19256/160239 [00:00<00:03, 38282.76it/s] 14%|█▍        | 23149/160239 [00:00<00:03, 38501.42it/s] 17%|█▋        | 27044/160239 [00:00<00:03, 38645.37it/s] 19%|█▉        | 30910/160239 [00:00<00:03, 38648.39it/s] 22%|██▏       | 34775/160239 [00:00<00:03, 38531.45it/s] 24%|██▍       | 38644/160239 [00:01<00:03, 38578.93it/s] 27%|██▋       | 42503/160239 [00:01<00:03, 38331.18it/s] 29%|██▉       | 46337/160239 [00:01<00:02, 38249.35it/s] 31%|███▏      | 50182/160239 [00:01<00:02, 38308.50it/s] 34%|███▍      | 54098/160239 [00:01<00:02, 38560.04it/s] 36%|███▋      | 58105/160239 [00:01<00:02, 39012.75it/s] 39%|███▊      | 62025/160239 [00:01<00:02, 39067.86it/s] 41%|████▏     | 66218/160239 [00:01<00:02, 39926.28it/s] 44%|████▍     | 70211/160239 [00:01<00:02, 39348.98it/s] 46%|████▋     | 74148/160239 [00:01<00:02, 39147.07it/s] 49%|████▊     | 78108/160239 [00:02<00:02, 39280.77it/s] 51%|█████▏    | 82142/160239 [00:02<00:01, 39593.63it/s] 54%|█████▍    | 86203/160239 [00:02<00:01, 39895.31it/s] 56%|█████▋    | 90221/160239 [00:02<00:01, 39979.50it/s] 59%|█████▉    | 94220/160239 [00:02<00:01, 39518.89it/s] 61%|██████▏   | 98186/160239 [00:02<00:01, 39555.99it/s] 64%|██████▍   | 102193/160239 [00:02<00:01, 39696.96it/s] 66%|██████▋   | 106164/160239 [00:02<00:01, 39465.04it/s] 69%|██████▊   | 110112/160239 [00:02<00:01, 38999.87it/s] 71%|███████   | 114132/160239 [00:02<00:01, 39351.32it/s] 74%|███████▎  | 118069/160239 [00:03<00:01, 39138.25it/s] 76%|███████▌  | 122052/160239 [00:03<00:00, 39342.75it/s] 79%|███████▊  | 125988/160239 [00:03<00:00, 39095.55it/s] 81%|████████  | 129899/160239 [00:03<00:00, 38872.11it/s] 83%|████████▎ | 133787/160239 [00:03<00:00, 38282.68it/s] 86%|████████▌ | 137666/160239 [00:03<00:00, 38429.86it/s] 88%|████████▊ | 141658/160239 [00:03<00:00, 38868.93it/s] 91%|█████████ | 145547/160239 [00:03<00:00, 38518.90it/s] 93%|█████████▎| 149401/160239 [00:03<00:00, 38100.03it/s] 96%|█████████▌| 153291/160239 [00:03<00:00, 38333.02it/s] 98%|█████████▊| 157208/160239 [00:04<00:00, 38577.78it/s]100%|██████████| 160239/160239 [00:04<00:00, 38898.15it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 1759.36it/s]2022-03-20 09:02:11 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-20 09:02:11 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-20 09:02:11 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-20 09:02:11 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-20 09:02:11 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-20 09:02:11 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-20 09:02:11 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-20 09:02:11 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-20 09:02:11 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-20 09:02:12 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-20 09:02:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 09:02:12 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-20 09:02:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-20 09:02:12 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-20 09:02:12 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-20 09:02:12 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:02:12 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:02:12 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-20 09:02:12 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-20 09:02:12 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-20 09:02:12 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-20 09:02:12 | INFO | fairseq.trainer | begin training epoch 1
2022-03-20 09:02:12 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-20 09:02:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-20 09:02:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-20 09:02:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-20 09:02:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-20 09:02:53 | INFO | train_inner | epoch 001:    104 / 157 loss=12.965, ppl=7996.96, wps=66024.8, ups=2.63, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.743, loss_scale=8, train_wall=41, gb_free=12.1, wall=42
2022-03-20 09:03:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:03:17 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-20 09:03:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:03:20 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-20 09:03:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:03:22 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-20 09:03:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:03:25 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-20 09:03:25 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:03:29 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:03:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:03:33 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:03:33 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:03:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:03:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:03:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:03:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:03:51 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:03:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:03:53 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:03:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:03:53 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.291 | ppl 5011.41 | bleu 0.02 | wps 4481.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-20 09:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-20 09:03:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:03:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.02) (writing took 2.082865139003843 seconds)
2022-03-20 09:03:55 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-20 09:03:55 | INFO | train | epoch 001 | loss 12.573 | ppl 6091.69 | wps 38261.1 | ups 1.53 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.204 | loss_scale 8 | train_wall 60 | gb_free 22.3 | wall 104
KL Stats: Epoch 1 Divergences: Uniform: 0.542388271711801 Unigram: 1.506096604297766
2022-03-20 09:03:56 | INFO | fairseq.trainer | begin training epoch 2
2022-03-20 09:03:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:04:14 | INFO | train_inner | epoch 002:     47 / 157 loss=11.556, ppl=3010.44, wps=31574.7, ups=1.25, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.072, loss_scale=8, train_wall=37, gb_free=12.9, wall=122
2022-03-20 09:04:52 | INFO | train_inner | epoch 002:    147 / 157 loss=11.078, ppl=2161.43, wps=66362.8, ups=2.64, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.176, loss_scale=8, train_wall=38, gb_free=12.2, wall=160
2022-03-20 09:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:04:58 | INFO | fairseq.tasks.translation | example hypothesis: we we we we.
2022-03-20 09:04:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:05:02 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the.
2022-03-20 09:05:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:05:06 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the.
2022-03-20 09:05:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:05:10 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:05:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:05:16 | INFO | fairseq.tasks.translation | example hypothesis: and and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:05:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:05:21 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-20 09:05:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:05:27 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:05:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:05:33 | INFO | fairseq.tasks.translation | example hypothesis: and and and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:05:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:05:40 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:05:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:05:42 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-20 09:05:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:05:42 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.595 | ppl 3093.25 | bleu 0.01 | wps 3712.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-20 09:05:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-20 09:05:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 2 @ 310 updates, score 0.01) (writing took 0.9772550743073225 seconds)
2022-03-20 09:05:43 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-20 09:05:43 | INFO | train | epoch 002 | loss 11.134 | ppl 2246.79 | wps 36542.7 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.087 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 212
KL Stats: Epoch 2 Divergences: Uniform: 0.6504997289117026 Unigram: 0.4449529752908588
2022-03-20 09:05:44 | INFO | fairseq.trainer | begin training epoch 3
2022-03-20 09:05:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:06:18 | INFO | train_inner | epoch 003:     90 / 157 loss=10.81, ppl=1795.02, wps=28570.2, ups=1.16, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.103, loss_scale=8, train_wall=36, gb_free=11.8, wall=246
2022-03-20 09:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:06:46 | INFO | fairseq.tasks.translation | example hypothesis: we.
2022-03-20 09:06:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:06:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the.
2022-03-20 09:06:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:06:54 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the.
2022-03-20 09:06:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:06:58 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and it's's's's's's's, and and and and and and it's's's, and and and and it's's's's, and and and and
2022-03-20 09:06:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:07:03 | INFO | fairseq.tasks.translation | example hypothesis: and and and it's's, it's's, and it's's's's's, and and and and it's's's's.
2022-03-20 09:07:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:07:08 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and
2022-03-20 09:07:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:07:14 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and the the the the the the the, and the, and the, and the, and the, and the the the the the the the the the the, and the, and and and and and and and the the the the the the the, and the the, and and and and and the the the the
2022-03-20 09:07:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:07:20 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and we we we we the the the the the the the the, and and and and and and the the the the the, and and and and and and and and and and and and and and and and and and and and and we we the the the the the the the the the the, and and and we we we we the the the the the the the the the the the the the the the the the the the the the the
2022-03-20 09:07:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:07:28 | INFO | fairseq.tasks.translation | example hypothesis: and and i, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-20 09:07:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:07:30 | INFO | fairseq.tasks.translation | example hypothesis: and and we, the, the, the, the, and the, and the, and the, and the, and the, and the, and the the the, and the, and the the, and the, and the, and the, and the the the the the, and the, and the, and the, and the, and the, and the the the the the the the the the the the, and the the the the the the the the the the the the the, and the the the the the the the the the the the the, and the, and the, and the, and the, and the the, and the the the the the the the, and the, and the, and the, and the, and the, and the, and the the, and the, and the the the the, and the, and the the the the the the the the the, and the the, and the, and the, and the the the the the the the the the the the the the the, and the,
2022-03-20 09:07:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:07:30 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.434 | ppl 2767.51 | bleu 0.1 | wps 3749 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.1
2022-03-20 09:07:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-20 09:07:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:07:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:07:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.1) (writing took 2.0349515578709543 seconds)
2022-03-20 09:07:32 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-20 09:07:32 | INFO | train | epoch 003 | loss 10.718 | ppl 1684.88 | wps 36302.3 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.186 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 321
KL Stats: Epoch 3 Divergences: Uniform: 0.8076259028008225 Unigram: 0.444235245904661
2022-03-20 09:07:33 | INFO | fairseq.trainer | begin training epoch 4
2022-03-20 09:07:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:07:45 | INFO | train_inner | epoch 004:     33 / 157 loss=10.605, ppl=1557.28, wps=28999.8, ups=1.14, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.166, loss_scale=8, train_wall=37, gb_free=12, wall=334
2022-03-20 09:08:23 | INFO | train_inner | epoch 004:    133 / 157 loss=10.455, ppl=1403.64, wps=66611.3, ups=2.64, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.266, loss_scale=8, train_wall=38, gb_free=10.8, wall=372
2022-03-20 09:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:08:36 | INFO | fairseq.tasks.translation | example hypothesis: we're're're the in the world in the world.
2022-03-20 09:08:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:08:41 | INFO | fairseq.tasks.translation | example hypothesis: this is is is is the that's the world of the world.
2022-03-20 09:08:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:08:46 | INFO | fairseq.tasks.translation | example hypothesis: and the world of the world of the world.
2022-03-20 09:08:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:08:52 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a of the world, and it's a of the world.
2022-03-20 09:08:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:08:57 | INFO | fairseq.tasks.translation | example hypothesis: and it's a that's a that's not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not that that's a.
2022-03-20 09:08:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:09:03 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and the world, and the world, and the world, and the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the
2022-03-20 09:09:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:09:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's, but it's're're're're're're're're're're're're're're're're're be be be be be be be be be be be be be be be be be be be be be be to be be be be be be be be be be be be be be be be to be to be be be be be be
2022-03-20 09:09:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:09:15 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-20 09:09:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:09:23 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-20 09:09:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:09:26 | INFO | fairseq.tasks.translation | example hypothesis: and so, we have have a a of the of the of the of the world of the of the of the world, and the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can have to to to be to be to be to be be be to be to to be be be be be be be be be be be be be be
2022-03-20 09:09:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:09:26 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.008 | ppl 2058.92 | bleu 0.48 | wps 3304.8 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.48
2022-03-20 09:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-20 09:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.48) (writing took 2.0064735910855234 seconds)
2022-03-20 09:09:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-20 09:09:28 | INFO | train | epoch 004 | loss 10.455 | ppl 1403.22 | wps 34198.8 | ups 1.36 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.192 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 436
KL Stats: Epoch 4 Divergences: Uniform: 0.8124374469230344 Unigram: 0.7761407572103873
2022-03-20 09:09:28 | INFO | fairseq.trainer | begin training epoch 5
2022-03-20 09:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:09:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-20 09:09:57 | INFO | train_inner | epoch 005:     77 / 157 loss=10.318, ppl=1276.52, wps=26161.2, ups=1.07, wpb=24523.4, bsz=945.3, num_updates=700, lr=8.75e-05, gnorm=1.411, loss_scale=4, train_wall=37, gb_free=13.2, wall=465
2022-03-20 09:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:10:31 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-20 09:10:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:10:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world.
2022-03-20 09:10:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:10:39 | INFO | fairseq.tasks.translation | example hypothesis: so we have to be the world.
2022-03-20 09:10:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:10:42 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot, there's a lot.
2022-03-20 09:10:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:10:47 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world, and we're going to do it's going to do it.
2022-03-20 09:10:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:10:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the world of the world of the world, and the world, and the world in the world in the world in the world in the world in the world in the world in the world in the world in the world.
2022-03-20 09:10:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:10:57 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to have to be the world, but they're going to be the world, but they're going to be the world, but they're going to be the world, but they're going to be the world, but they're going to be the world, but they're going to be the world, but they're going to be be
2022-03-20 09:10:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:11:03 | INFO | fairseq.tasks.translation | example hypothesis: and we have to see the world, and we're the world, and we're the world, and we're the world, and we're the world, and we're the world to see the world to be the world to be the world to be the world to be the world to be the world of the world.
2022-03-20 09:11:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:11:11 | INFO | fairseq.tasks.translation | example hypothesis: and "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-20 09:11:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:11:14 | INFO | fairseq.tasks.translation | example hypothesis: so, we've've have to be the world of the world, and we're the world, it was the world, and we're the world of the world, and we're the world, and we've've've have to be the world, and we're the world to be the world to be the world, and we're the world to be the world of the world in the world to be the world of the world of the world, and we're the world, and we've've've've've've've've've've've've've've have to be the world to be the world, and we have to be be be the world to be the world to be the world to be the world to be the world to be the world to be the world to be the world to be the world, and we've've've've've've've've've've've've've've've've've've've've've've have to be be be the world to be the world to be be be be be the world to be the world to be
2022-03-20 09:11:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:11:14 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.655 | ppl 1612.48 | bleu 1.2 | wps 3847.9 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.2
2022-03-20 09:11:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-20 09:11:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:11:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.2) (writing took 2.109181310981512 seconds)
2022-03-20 09:11:16 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-20 09:11:16 | INFO | train | epoch 005 | loss 10.113 | ppl 1107.23 | wps 36398.4 | ups 1.45 | wpb 25182.3 | bsz 1008.1 | num_updates 780 | lr 9.75e-05 | gnorm 1.314 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 544
KL Stats: Epoch 5 Divergences: Uniform: 0.8647925457922131 Unigram: 1.1731546941058923
2022-03-20 09:11:16 | INFO | fairseq.trainer | begin training epoch 6
2022-03-20 09:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:11:24 | INFO | train_inner | epoch 006:     20 / 157 loss=9.962, ppl=997.14, wps=29410.8, ups=1.16, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.256, loss_scale=4, train_wall=37, gb_free=10.8, wall=552
2022-03-20 09:12:01 | INFO | train_inner | epoch 006:    120 / 157 loss=9.821, ppl=904.79, wps=66937.7, ups=2.65, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.187, loss_scale=4, train_wall=37, gb_free=12.2, wall=590
2022-03-20 09:12:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:12:19 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-20 09:12:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:12:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the world that is the world.
2022-03-20 09:12:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:12:28 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a lot of the world.
2022-03-20 09:12:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:12:33 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of it's a lot of it's a lot of it's a lot of it's a lot of there.
2022-03-20 09:12:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:12:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not that we're not not not not not not not going to do it's not not not not going to do it.
2022-03-20 09:12:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:12:43 | INFO | fairseq.tasks.translation | example hypothesis: and this is in the world, and in the world, and in the world in the world, and the world in the world in the world, and the world, and the world in the world, and the world in the world in the world, and the world, and the world,
2022-03-20 09:12:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:12:49 | INFO | fairseq.tasks.translation | example hypothesis: but if you're not not not not going to be a lot of the world, but they're going to be not not not not not not not going to be more, but they're going to be not not not going to be a lot of the world, but they're going to be not not going to be not not not not not going to be
2022-03-20 09:12:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:12:55 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see that we can see that we can see that we can see that we can see the world, and we can see the world, and we can see the world, and we can see that we can see the world, and we can see the world, and we can see the world.
2022-03-20 09:12:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:13:03 | INFO | fairseq.tasks.translation | example hypothesis: and we said, "" "" "" "" you know, "" "" "you know," "" "you know," "" you know, "you know," you know, "it's," "" "you know," it's, "you know," "" "you know," you know, "you know," "" "" "" "" "you know," "it's," "" "" it's, "" it's, "" "" "it's," "" "" "" "" "" "" "you know," it's going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "" "
2022-03-20 09:13:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:13:05 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to be a lot of the world, we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to be a lot of the world, and we're going to be a lot of the world that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be that we're going to be a lot of that we're going to be a lot of the world, and we're going to get that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going
2022-03-20 09:13:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:13:05 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.411 | ppl 1361.2 | bleu 1.35 | wps 3556.2 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.35
2022-03-20 09:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-20 09:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:13:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.35) (writing took 1.9516250588931143 seconds)
2022-03-20 09:13:07 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-20 09:13:07 | INFO | train | epoch 006 | loss 9.824 | ppl 906.66 | wps 35453.3 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.224 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 655
KL Stats: Epoch 6 Divergences: Uniform: 0.9176025267465265 Unigram: 1.359716340290784
2022-03-20 09:13:07 | INFO | fairseq.trainer | begin training epoch 7
2022-03-20 09:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:13:31 | INFO | train_inner | epoch 007:     63 / 157 loss=9.676, ppl=817.85, wps=28000.1, ups=1.11, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.139, loss_scale=4, train_wall=37, gb_free=13, wall=680
2022-03-20 09:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:14:11 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world, we're going to see this.
2022-03-20 09:14:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:14:17 | INFO | fairseq.tasks.translation | example hypothesis: and this is the first thing of this is that the most of the most of the world is that the most of the world.
2022-03-20 09:14:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:14:22 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be two two two two two two two two two two two two two two two of two two two two two two two two two two two two two two
2022-03-20 09:14:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:14:28 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of there, there's a lot of the world, and there are a lot of the world.
2022-03-20 09:14:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:14:33 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do it, and we're going to do it's going to do it, and we're going to do it's going to do it's not going to do it
2022-03-20 09:14:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:14:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the world, in the world, and in the world, and in the world, and in the world, and in the world, and the world, in the world, and in the world, and in the world, and the world, and the world, and in the world
2022-03-20 09:14:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:14:44 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to get a lot of these things, but you're going to see, but you're going to see it, but they're going to be not not going to be a lot of the world.
2022-03-20 09:14:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:14:50 | INFO | fairseq.tasks.translation | example hypothesis: and if we can see that we're going to get a lot of the world, and then we can see that we're going to get a lot of the world.
2022-03-20 09:14:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:14:57 | INFO | fairseq.tasks.translation | example hypothesis: and if you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, and then you're going to say, "you're going to say, and then you're going to say," you're going to say, and then you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to
2022-03-20 09:14:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:14:59 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to get a lot of the world, we're going to get a lot of the world, and then we're going to get a lot of the world, and then we're going to be going to be a lot of the world, and we're going to be going to be a lot of the world, and then we're going to be a lot of the world, and then we're going to be going to be a lot of the world, and then we're going to be a lot of the world, and then we're going to get a lot of the world, and then we're going to get a lot of the world, and then we're going to get a lot of the world, and then we're going to get a lot of the world, and then we're going to be a lot of the world, and then we're going to get a lot of the world, and then we're going to get a lot of the world, and then we're going to get a lot of the world,
2022-03-20 09:14:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:14:59 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.266 | ppl 1231.02 | bleu 1.52 | wps 3414.3 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.52
2022-03-20 09:14:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-20 09:14:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:15:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:15:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 1.52) (writing took 1.9419004218652844 seconds)
2022-03-20 09:15:01 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-20 09:15:01 | INFO | train | epoch 007 | loss 9.59 | ppl 770.9 | wps 34531.9 | ups 1.37 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.152 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 770
KL Stats: Epoch 7 Divergences: Uniform: 0.9600918847518422 Unigram: 1.4731972687780734
2022-03-20 09:15:02 | INFO | fairseq.trainer | begin training epoch 8
2022-03-20 09:15:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:15:04 | INFO | train_inner | epoch 008:      6 / 157 loss=9.566, ppl=757.97, wps=26899.6, ups=1.07, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.142, loss_scale=4, train_wall=37, gb_free=12.5, wall=773
2022-03-20 09:15:42 | INFO | train_inner | epoch 008:    106 / 157 loss=9.346, ppl=650.58, wps=66953.5, ups=2.65, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.024, loss_scale=4, train_wall=37, gb_free=12.9, wall=810
2022-03-20 09:16:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:16:05 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the world.
2022-03-20 09:16:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:16:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most of the most of the most of the most of the most of the
2022-03-20 09:16:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:16:14 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be able to be new new new new new new new new new new new new new new new new new new new new new new new new new new percent
2022-03-20 09:16:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:16:19 | INFO | fairseq.tasks.translation | example hypothesis: and it's a lot of the world.
2022-03-20 09:16:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:16:24 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do it, and we're going to do it, and we're going to do it's going to do it's going to do it's going to do it's
2022-03-20 09:16:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:16:30 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the people who is a lot of people in the world, and the people who are in the people in the world, and people in the people who are the people in the world, and people in the people like the people in the world, and people in the people
2022-03-20 09:16:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:16:35 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to look at a lot of these are going to see, but they're going to get a lot of their own own own own, but they're going to get the same, but they're going to get the same, but they're going to go to get a lot of them, but they're going to be not not not
2022-03-20 09:16:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:16:41 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can see that we can see, and then we can see that we can see that we can see the brain, and then we can see that we can see the brain, and then we can see that we can see a lot of the brain, and then we can see that we can see that we can see that we can see that we can see a lot of the brain, and then then we can see that we can see that we can
2022-03-20 09:16:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:16:49 | INFO | fairseq.tasks.translation | example hypothesis: and if you say, "you know," you know, "you know," you can say, "it's a lot of the world," you know, "you know," you know, "you know," it's going to say, "it's going to say," you know, "you know," you know, "you know," you know, "it's the first first first first first," it's the first first is, "it's a" "" "" "" "" "the first first first is," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "it's going to say," ""
2022-03-20 09:16:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:16:51 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to see that we're going to see the world, it's a lot of the world, it's a lot of the world, it's a lot of the world, it's a lot of the world, it's a lot of the world, and it's a lot of the world that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, and if we're going to be able to be able to be able to be a lot of the world, which is that we can be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world.
2022-03-20 09:16:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:16:51 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.09 | ppl 1090.22 | bleu 1.92 | wps 3566.3 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 1.92
2022-03-20 09:16:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-20 09:16:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 1.92) (writing took 1.9464719612151384 seconds)
2022-03-20 09:16:53 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-20 09:16:53 | INFO | train | epoch 008 | loss 9.422 | ppl 685.78 | wps 35359.5 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.035 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 881
KL Stats: Epoch 8 Divergences: Uniform: 0.9906104298534171 Unigram: 1.5611523428646312
2022-03-20 09:16:53 | INFO | fairseq.trainer | begin training epoch 9
2022-03-20 09:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:17:12 | INFO | train_inner | epoch 009:     49 / 157 loss=9.366, ppl=660.06, wps=28366.4, ups=1.11, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.036, loss_scale=4, train_wall=38, gb_free=13.1, wall=901
2022-03-20 09:17:50 | INFO | train_inner | epoch 009:    149 / 157 loss=9.308, ppl=633.81, wps=66411.2, ups=2.68, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=0.971, loss_scale=4, train_wall=37, gb_free=12.5, wall=938
2022-03-20 09:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:17:57 | INFO | fairseq.tasks.translation | example hypothesis: we have to see this.
2022-03-20 09:17:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:18:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the most one of the most of the most of the most of the most of the most of the most of the most of the most of
2022-03-20 09:18:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:18:06 | INFO | fairseq.tasks.translation | example hypothesis: so these are two new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-20 09:18:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:18:11 | INFO | fairseq.tasks.translation | example hypothesis: there's a lot of life, and it's a lot of life, and it's a lot of life, where you're going to live in the united states.
2022-03-20 09:18:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:18:17 | INFO | fairseq.tasks.translation | example hypothesis: and it's not just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just in the
2022-03-20 09:18:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:18:22 | INFO | fairseq.tasks.translation | example hypothesis: and and in fact, in the most people who have been been in the world, for the world, in the world, for the world, for the world, for the most people who are in the people who would be in the people in the people in the world.
2022-03-20 09:18:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:18:28 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to look at the middle of the united states, there are not not a lot of the same time, but they're not a lot of the same time, but they're going to go to be a lot of the same time, but they're going to be able to be able to be able to be able to be able to
2022-03-20 09:18:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:18:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we can look at the brain, and then we can look at the brain, and then we can see the brain can see the brain, and then we can see the brain can see the brain, and then we can see the brain, and then we can see the brain, and then we can see the world, and then we can see the brain can see the brain can see the brain can see the world, and then we can see the brain,
2022-03-20 09:18:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:18:42 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-20 09:18:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:18:44 | INFO | fairseq.tasks.translation | example hypothesis: in fact, if we're going to take a few years, in the world, it's a few years, we're going to be a lot of the world, the world, the world, the world is that we're going to be a lot of the world, and the world is that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be a few of the world, and the world, and the most of the most of the world, and the world, and the world that the most of the world is the world is that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-20 09:18:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:18:44 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.872 | ppl 936.99 | bleu 2.31 | wps 3447.5 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 2.31
2022-03-20 09:18:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-20 09:18:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:18:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 2.31) (writing took 2.0048270006664097 seconds)
2022-03-20 09:18:46 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-20 09:18:46 | INFO | train | epoch 009 | loss 9.283 | ppl 623.1 | wps 34857.4 | ups 1.39 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.977 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 995
KL Stats: Epoch 9 Divergences: Uniform: 1.0178175758634282 Unigram: 1.6204253606438965
2022-03-20 09:18:47 | INFO | fairseq.trainer | begin training epoch 10
2022-03-20 09:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:19:22 | INFO | train_inner | epoch 010:     92 / 157 loss=9.221, ppl=596.87, wps=27175.6, ups=1.08, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.932, loss_scale=4, train_wall=38, gb_free=12.4, wall=1030
2022-03-20 09:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:19:50 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the united states.
2022-03-20 09:19:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:19:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most most of the most of the most of the most of the most of the most of the most of
2022-03-20 09:19:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:19:58 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be able to be able to be able.
2022-03-20 09:19:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:20:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a few years, where you're going to see where where you're going to go and where you're going to live in the united states.
2022-03-20 09:20:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:20:07 | INFO | fairseq.tasks.translation | example hypothesis: so it's not just a little bit of what we're going to do, and what we're going to do is that we're going to do is not going to do.
2022-03-20 09:20:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:20:11 | INFO | fairseq.tasks.translation | example hypothesis: and in the united states, it's like people for the people and people who are working for people for the people who who who are working for people for the people who are in the most people for the world.
2022-03-20 09:20:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:20:17 | INFO | fairseq.tasks.translation | example hypothesis: now, some of some of course, but there are a lot of water, but there are the same time, but it's the same time, but it's the same way, but it's the same time, but it's the same time, but it's the same time, but it's the same time, but it's the same time.
2022-03-20 09:20:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:20:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to look at the brain, and then we can see it, and we can see the brain, and then we can see the brain, and then we can see the brain, and then we can see the brain, and then we can see it's going to be able to be able to take the brain.
2022-03-20 09:20:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:20:30 | INFO | fairseq.tasks.translation | example hypothesis: : one:: one: one: thank you, and we're going to go back to the first time, and we're going to go back back to the first time, and then you, and then you're going to go back back to the first time, and then you're going to the first time, and then you're going to go back back back to the first time, and then you're going to go back back back back to the first time, and then you're going to the first time, and then we're going to go back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back back to the first time, and then you're going to the first time, and then you're going to
2022-03-20 09:20:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:20:32 | INFO | fairseq.tasks.translation | example hypothesis: now, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-20 09:20:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:20:32 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.684 | ppl 822.49 | bleu 3.32 | wps 3858.8 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 3.32
2022-03-20 09:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-20 09:20:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:20:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:20:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 3.32) (writing took 1.9871548088267446 seconds)
2022-03-20 09:20:34 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-20 09:20:34 | INFO | train | epoch 010 | loss 9.114 | ppl 553.98 | wps 36557.7 | ups 1.45 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.97 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1103
KL Stats: Epoch 10 Divergences: Uniform: 1.0528669838608338 Unigram: 1.6949144697435254
2022-03-20 09:20:35 | INFO | fairseq.trainer | begin training epoch 11
2022-03-20 09:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:20:48 | INFO | train_inner | epoch 011:     35 / 157 loss=9.062, ppl=534.3, wps=28905.9, ups=1.16, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.022, loss_scale=4, train_wall=37, gb_free=11.5, wall=1116
2022-03-20 09:21:26 | INFO | train_inner | epoch 011:    135 / 157 loss=8.813, ppl=449.88, wps=67670.5, ups=2.65, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.928, loss_scale=4, train_wall=37, gb_free=11.5, wall=1154
2022-03-20 09:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:21:38 | INFO | fairseq.tasks.translation | example hypothesis: we did this in this room.
2022-03-20 09:21:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:21:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of the most most most most most of the most most most most most of the most most most most most of
2022-03-20 09:21:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:21:47 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new york.
2022-03-20 09:21:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:21:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a example, where there are where where you're going to go, and where you're going to be where where you're going to go and where you're going to go.
2022-03-20 09:21:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:21:56 | INFO | fairseq.tasks.translation | example hypothesis: it's not not just just just just just just just just just just just just a little bit of what we're going to do is going to do.
2022-03-20 09:21:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:22:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of the people like the people who are used for a lot of people who who have been used for a lot of people who who had a lot of people.
2022-03-20 09:22:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:22:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of some of these are some of them, but if you're going to look at the same time, but it's not the same way, but it's not the same way, but if you can see it, but it doesn't look at the same time, but it's not the same way, but it's not the same way
2022-03-20 09:22:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:22:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can take the brain, and we can see that we can make a lot of information that can take the brain, and we can use the brain, and then we can make it out of the brain, that can make a kind of information.
2022-03-20 09:22:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:22:19 | INFO | fairseq.tasks.translation | example hypothesis: yeah: there's one of the reason that there's a good question, "" "" well, "" "" "well," "" "" "" "" well, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-20 09:22:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:22:21 | INFO | fairseq.tasks.translation | example hypothesis: now, there's no reason that if we were a few years, and we're going to do that if we were able to make a big way that we're going to make a lot of the system that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-20 09:22:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:22:21 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.48 | ppl 713.87 | bleu 4.62 | wps 3806.6 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 4.62
2022-03-20 09:22:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-20 09:22:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:22:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:22:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 4.62) (writing took 2.003302851226181 seconds)
2022-03-20 09:22:23 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-20 09:22:23 | INFO | train | epoch 011 | loss 8.932 | ppl 488.49 | wps 36337.3 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.959 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1211
KL Stats: Epoch 11 Divergences: Uniform: 1.088199134795853 Unigram: 1.7641690498331717
2022-03-20 09:22:23 | INFO | fairseq.trainer | begin training epoch 12
2022-03-20 09:22:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:22:53 | INFO | train_inner | epoch 012:     78 / 157 loss=8.859, ppl=464.29, wps=28666.2, ups=1.15, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.913, loss_scale=4, train_wall=37, gb_free=12.1, wall=1241
2022-03-20 09:23:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:23:26 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-20 09:23:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:23:30 | INFO | fairseq.tasks.translation | example hypothesis: and that's the most example of the most most of you know, "most of the most most of you know.
2022-03-20 09:23:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:23:35 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be new new new new new new new new new new new new york.
2022-03-20 09:23:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:23:39 | INFO | fairseq.tasks.translation | example hypothesis: so for example, there's an alalalalalalan, where you're going to go, and where you're going to go back and where you're going to be going to go.
2022-03-20 09:23:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:23:44 | INFO | fairseq.tasks.translation | example hypothesis: and it's not just just just just just just just just a few years, and he's going to see what he's going to do, and what's going to do.
2022-03-20 09:23:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:23:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of the people like the people for the most people who have been working for the people, and it's a few people for a few years, and that's a lot of people in order to create a few years.
2022-03-20 09:23:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:23:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some of some of you can see, but if you're going to look at the same way, but if you don't have to use it, but if you don't have the energy, if you don't have the energy, if you don't have the energy, if you don't have to get the energy, if you don't have
2022-03-20 09:23:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:24:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use this information, we can use this kind of information, and we can use it, and then we can use it into a kind of information, and then we can use the brain, and then we can use the brain, and then we can use the brain, and then we can use the brain, and then we can use the information with a kind of information, and then we can use the information, the
2022-03-20 09:24:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:24:08 | INFO | fairseq.tasks.translation | example hypothesis: bf: one of the reason it's interesting, and it's very interesting, and it's going to say, "and if you're going to say," if you're going to say, "you're going to say," if you're going to say, "you're going to say," if you're going to say, "you're going to say," you're going to say, "you're going to say," if you're going to say, "if you're going to say," you're going to say, "if you're going to say," you're going to say, "you're going to say," if you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to
2022-03-20 09:24:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:24:10 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, it's still still still a mother, and when we're going to have a new story, and if we're going to do that if we're going to create a new way that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-20 09:24:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:24:10 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.254 | ppl 610.7 | bleu 5.7 | wps 3718.1 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 5.7
2022-03-20 09:24:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-20 09:24:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 5.7) (writing took 2.083394523244351 seconds)
2022-03-20 09:24:13 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-20 09:24:13 | INFO | train | epoch 012 | loss 8.74 | ppl 427.66 | wps 36065.2 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.932 | loss_scale 4 | train_wall 59 | gb_free 12.3 | wall 1321
KL Stats: Epoch 12 Divergences: Uniform: 1.1275250817337543 Unigram: 1.825554078362447
2022-03-20 09:24:13 | INFO | fairseq.trainer | begin training epoch 13
2022-03-20 09:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:24:21 | INFO | train_inner | epoch 013:     21 / 157 loss=8.647, ppl=400.93, wps=28580.8, ups=1.14, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.045, loss_scale=4, train_wall=37, gb_free=12, wall=1329
2022-03-20 09:24:59 | INFO | train_inner | epoch 013:    121 / 157 loss=8.58, ppl=382.58, wps=66846.4, ups=2.64, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.952, loss_scale=4, train_wall=37, gb_free=11.7, wall=1367
2022-03-20 09:25:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:25:16 | INFO | fairseq.tasks.translation | example hypothesis: we went to these ppon in the middle.
2022-03-20 09:25:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:25:20 | INFO | fairseq.tasks.translation | example hypothesis: and this is the cook, "most most most of you know, most most of you know.
2022-03-20 09:25:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:25:24 | INFO | fairseq.tasks.translation | example hypothesis: these new new new new new new new new new new new new new new york will be used.
2022-03-20 09:25:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:25:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese food, where they're going to be going to be able, and they're going to be able.
2022-03-20 09:25:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:25:33 | INFO | fairseq.tasks.translation | example hypothesis: it's not sure we're not just just just a few years on his head, and what's going to do.
2022-03-20 09:25:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:25:37 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, people like the most people who have been used to be used for the number of people, and that's a very important thing for the most important thing.
2022-03-20 09:25:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:25:41 | INFO | fairseq.tasks.translation | example hypothesis: first of some of these things are going to be able to be able to be able, but if you don't need the energy, you don't need the energy, and if you need to do it.
2022-03-20 09:25:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:25:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can be able to be able to be able to be able to be able to be able to create a kind of information, and all the structure of the information.
2022-03-20 09:25:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:25:50 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons that it's interesting, and i'm going to say, "oh," you know, "you know," you know, "well," you know, "you know," you know, "well," you know, "well," well, "you know," well, "well," you know, "you know," well, "you know," you know, "well," well, "well," well, "you know," you know, "well," well, "well," well, "well," you know, "you know," you know, "well," well, "you know," well, "you know," well, "well," you know, "well," well, "well," you know, "well," well, "
2022-03-20 09:25:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:25:52 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still still still still the mother, and we're going to do that a new system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do
2022-03-20 09:25:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:25:52 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.03 | ppl 522.9 | bleu 9.14 | wps 4583.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 9.14
2022-03-20 09:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-20 09:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:25:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 9.14) (writing took 2.0165116149000823 seconds)
2022-03-20 09:25:54 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-20 09:25:54 | INFO | train | epoch 013 | loss 8.553 | ppl 375.64 | wps 39032.5 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.989 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1422
KL Stats: Epoch 13 Divergences: Uniform: 1.1675064129352375 Unigram: 1.8835192533949154
2022-03-20 09:25:54 | INFO | fairseq.trainer | begin training epoch 14
2022-03-20 09:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:26:18 | INFO | train_inner | epoch 014:     64 / 157 loss=8.462, ppl=352.7, wps=31321.1, ups=1.25, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.958, loss_scale=4, train_wall=37, gb_free=12.3, wall=1447
2022-03-20 09:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:26:58 | INFO | fairseq.tasks.translation | example hypothesis: we found this in the end of the clinics.
2022-03-20 09:26:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:27:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the point of ha ha, most most of the most most most most of you know here.
2022-03-20 09:27:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:27:06 | INFO | fairseq.tasks.translation | example hypothesis: cities are going to be a new way of the new new ideas that are going to be able.
2022-03-20 09:27:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:27:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese, where they're going to be going to be going to be.
2022-03-20 09:27:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:27:15 | INFO | fairseq.tasks.translation | example hypothesis: it's not sure that we're not just just just just just just a few of the brain, and what's going to understand.
2022-03-20 09:27:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:27:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamamace of people who found the most important way for the number of animals, and the number of years.
2022-03-20 09:27:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:27:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the rocks, but they're going to look at the top, but if they don't need to change the energy, if they don't need to change the energy.
2022-03-20 09:27:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:27:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, we can use the information of this structure, we can start going to be able to start with a structure, we can see the information of the information, and the information of the information.
2022-03-20 09:27:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:27:32 | INFO | fairseq.tasks.translation | example hypothesis: audience: one of the reasons it's interesting, and it's interesting for me, and it's going to do that for me, "you know," you know, "you're going to tell you," you know, "you know," you know, "you're going to tell you know," the best. "
2022-03-20 09:27:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:27:34 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still still still the mother, and the best part of the design of the design, and we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the system with a global system.
2022-03-20 09:27:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:27:34 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.861 | ppl 464.89 | bleu 11.11 | wps 4530.5 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 11.11
2022-03-20 09:27:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-20 09:27:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:27:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:27:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 11.11) (writing took 2.0605680770240724 seconds)
2022-03-20 09:27:36 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-20 09:27:36 | INFO | train | epoch 014 | loss 8.335 | ppl 322.83 | wps 38660.3 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.93 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1524
KL Stats: Epoch 14 Divergences: Uniform: 1.2041498665998942 Unigram: 1.9264106124992215
2022-03-20 09:27:36 | INFO | fairseq.trainer | begin training epoch 15
2022-03-20 09:27:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:27:39 | INFO | train_inner | epoch 015:      7 / 157 loss=8.198, ppl=293.75, wps=31604.8, ups=1.24, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.882, loss_scale=4, train_wall=37, gb_free=12, wall=1528
2022-03-20 09:28:17 | INFO | train_inner | epoch 015:    107 / 157 loss=8.114, ppl=277.03, wps=66890.3, ups=2.66, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.95, loss_scale=4, train_wall=37, gb_free=12, wall=1565
2022-03-20 09:28:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:28:39 | INFO | fairseq.tasks.translation | example hypothesis: we did this pm in the clinics.
2022-03-20 09:28:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:28:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha, most of you know, most of you know.
2022-03-20 09:28:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:28:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new.
2022-03-20 09:28:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:28:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese, where you're going to get with, and you're going to be able.
2022-03-20 09:28:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:28:56 | INFO | fairseq.tasks.translation | example hypothesis: it's pretty clear that we're not just just going to understand a couple of camera on his head, and all of the thought that are all the idea of the idea.
2022-03-20 09:28:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:29:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of the responsibility, people found the number of animals, and that's a number of animals.
2022-03-20 09:29:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:29:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magic, but in the field, you don't know, but if you don't need to use it, if you don't need your energy, and if you need your energy, you need to get the energy, and you need the energy.
2022-03-20 09:29:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:29:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this structure, we can start able to start with a new structure, we can start able to start able to start able to start with the structure of the structure, and create the structure of the structure of the structure, and the structure, and the structure of the structure, and the structure of the structure of the structure, and the structure, and the structure of the structure of the structure, and the structure,
2022-03-20 09:29:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:29:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for me, "oh," oh, "oh," oh, "well," you know, "well," you know, "you know," you know, "well," you know, "well," you know, "you know," well, "well," well, "you know," you know, "well," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "you know," you know, "well," well, "well," well, "well," well, "you know," well, "you know," well, "well," well, "well," well, "well,"
2022-03-20 09:29:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:29:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, the mother is still still a lot of the invention of the design, and we had to use a lot of work on our building, we had to see that if we had to use it, we were able to use a system, or we were able to use that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that we're able to see that we're able to use the entire entire entire entire entire entire entire system, and create a whole system, and see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-20 09:29:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:29:19 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.6 | ppl 388.08 | bleu 11.82 | wps 4193.5 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 11.82
2022-03-20 09:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-20 09:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:29:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 11.82) (writing took 1.968715407885611 seconds)
2022-03-20 09:29:20 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-20 09:29:20 | INFO | train | epoch 015 | loss 8.13 | ppl 280.19 | wps 37754.2 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.923 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1629
KL Stats: Epoch 15 Divergences: Uniform: 1.2417220664462696 Unigram: 1.9614359340896679
2022-03-20 09:29:21 | INFO | fairseq.trainer | begin training epoch 16
2022-03-20 09:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:29:40 | INFO | train_inner | epoch 016:     50 / 157 loss=8.069, ppl=268.62, wps=30528.2, ups=1.2, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.884, loss_scale=4, train_wall=37, gb_free=12.4, wall=1648
2022-03-20 09:30:18 | INFO | train_inner | epoch 016:    150 / 157 loss=7.958, ppl=248.68, wps=66048.1, ups=2.68, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.872, loss_scale=4, train_wall=37, gb_free=12.6, wall=1686
2022-03-20 09:30:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:30:24 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinics.
2022-03-20 09:30:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:30:28 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of dodoha, most of you know.
2022-03-20 09:30:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:30:32 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new orores.
2022-03-20 09:30:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:30:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese food, where they're going to be posted.
2022-03-20 09:30:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:30:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to understand a few cell and understand what everybody are on the mind.
2022-03-20 09:30:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:30:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamacy, people came up to the number of animals.
2022-03-20 09:30:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:30:46 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of you are in the color, but if you don't need it, if you don't need your energy, and if you need your energy.
2022-03-20 09:30:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:30:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that's going to be able to start with a traditional structure, we can start able to start able to start able to look at the form of the form of the structure and create the structure of the structure.
2022-03-20 09:30:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:30:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to do for me, "well, is that" well, "well," you know, "if you're going to say," well, "if you're going to give you the best revolution."
2022-03-20 09:30:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:30:55 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still a big design, and a lot of design that we had to use the airplanes that we had to be able to be able to be able to use the ground of a mechanical system.
2022-03-20 09:30:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:30:55 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.593 | ppl 386.04 | bleu 10.08 | wps 5268.9 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 11.82
2022-03-20 09:30:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-20 09:30:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:30:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:30:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 10.08) (writing took 0.9889787947759032 seconds)
2022-03-20 09:30:56 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-20 09:30:56 | INFO | train | epoch 016 | loss 7.932 | ppl 244.25 | wps 41177.7 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.895 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 1725
KL Stats: Epoch 16 Divergences: Uniform: 1.2793885028503031 Unigram: 2.003713396219516
2022-03-20 09:30:57 | INFO | fairseq.trainer | begin training epoch 17
2022-03-20 09:30:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:31:32 | INFO | train_inner | epoch 017:     93 / 157 loss=7.779, ppl=219.63, wps=33932.8, ups=1.34, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.891, loss_scale=4, train_wall=37, gb_free=13.1, wall=1760
2022-03-20 09:31:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:32:00 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinics.
2022-03-20 09:32:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:32:04 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha ha, most of you know, most of you know, most of them.
2022-03-20 09:32:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:32:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new orts that are going to create two new forms.
2022-03-20 09:32:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:32:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where the legs are going to be, and they're going to be posted.
2022-03-20 09:32:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:32:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just make a couple of electrodes on his head and understand what all of the things are on the mind.
2022-03-20 09:32:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:32:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of the responsibility, people came to the number of animals, the number of animals, and that has been built in the economists.
2022-03-20 09:32:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:32:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some bbbbbbbbbols in the lines, but it doesn't have the energy, and if you need your energy, and if you need to move your energy.
2022-03-20 09:32:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:32:31 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use information that reflection from this reflection, we can start able to start with a traditional face, we can start able to start able to start with the structure of the information, and the whole structure of the information, and the whole structure of the whole structure, and the whole structure of the whole structure, and the whole information that we're able to use it.
2022-03-20 09:32:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:32:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for tedtedtalks to be women, "yes, when we're talking about a long revolution," and then we have a long revolution, "if you have a long revolution," and you have a long time, "you're working with you're working with them," you're working with you're talking about, "and you know," well, "well," if you have a long time. "
2022-03-20 09:32:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:32:39 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big design of work that we have to be able to be able to be able to be able to be able to be able to see that if we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-20 09:32:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:32:39 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.32 | ppl 319.57 | bleu 14.68 | wps 4234.4 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 14.68
2022-03-20 09:32:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-20 09:32:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 14.68) (writing took 1.994823888875544 seconds)
2022-03-20 09:32:41 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-20 09:32:41 | INFO | train | epoch 017 | loss 7.776 | ppl 219.17 | wps 37822.5 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.89 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1829
KL Stats: Epoch 17 Divergences: Uniform: 1.3182561674872317 Unigram: 2.034229780109454
2022-03-20 09:32:41 | INFO | fairseq.trainer | begin training epoch 18
2022-03-20 09:32:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:32:55 | INFO | train_inner | epoch 018:     36 / 157 loss=7.685, ppl=205.73, wps=30394.6, ups=1.2, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.891, loss_scale=4, train_wall=37, gb_free=12.5, wall=1843
2022-03-20 09:33:33 | INFO | train_inner | epoch 018:    136 / 157 loss=7.642, ppl=199.74, wps=66088.5, ups=2.66, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.788, loss_scale=4, train_wall=37, gb_free=12.3, wall=1881
2022-03-20 09:33:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:33:45 | INFO | fairseq.tasks.translation | example hypothesis: we made this pill in the clinic clinic.
2022-03-20 09:33:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:33:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-20 09:33:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:33:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create the two new tracks.
2022-03-20 09:33:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:33:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese food, where happy legs are going to be posted with and salt.
2022-03-20 09:33:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:34:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrodes on his head and understand what all his thoughts are on.
2022-03-20 09:34:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:34:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamabia, the responsibility of the responsibility, the number of animals came back, and that's a number of animals.
2022-03-20 09:34:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:34:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are a little bit of magnetic lines in the field, but the alarm doesn't move if you need energy, and if you need your energy, it doesn't need your energy.
2022-03-20 09:34:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:34:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, we can start able to start able to start with a traditional face, and start able to start through the face of the whole structure, and the whole structure.
2022-03-20 09:34:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:34:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedwomen, "yeah, it's the best time to be the best thing," if we're going to support, "if you're working with this talk."
2022-03-20 09:34:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:34:20 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention of the invention, and a big design that we've got to solve in our airplane, that we had to solve a unique problem, and if you had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're able to solve the same, and see that it's a unique.
2022-03-20 09:34:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:34:20 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.144 | ppl 282.97 | bleu 16.82 | wps 4641.7 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 16.82
2022-03-20 09:34:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-20 09:34:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:34:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:34:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 16.82) (writing took 2.0941845779307187 seconds)
2022-03-20 09:34:22 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-20 09:34:22 | INFO | train | epoch 018 | loss 7.598 | ppl 193.69 | wps 39045.8 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.796 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1930
KL Stats: Epoch 18 Divergences: Uniform: 1.3562038911959116 Unigram: 2.0668334395553742
2022-03-20 09:34:22 | INFO | fairseq.trainer | begin training epoch 19
2022-03-20 09:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:34:53 | INFO | train_inner | epoch 019:     79 / 157 loss=7.466, ppl=176.85, wps=32035.5, ups=1.25, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.757, loss_scale=4, train_wall=37, gb_free=12.2, wall=1961
2022-03-20 09:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:35:25 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic.
2022-03-20 09:35:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:35:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, the most familiar here.
2022-03-20 09:35:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:35:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf of the two new trains that are going to be made.
2022-03-20 09:35:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:35:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are going to be salt with salsales and fefeminal.
2022-03-20 09:35:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:35:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just make a few electroelectrodes on his head and understand exactly what all his thoughts are on.
2022-03-20 09:35:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:35:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like people, the number of animals grew up, the number of animals, and this is a basis of conservation in the maibia.
2022-03-20 09:35:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:35:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field lines in the field, but the sulalalalarm doesn't need their energy and so forth.
2022-03-20 09:35:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:35:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of traditional face, we can start able to start the big face of the information and the whole structure.
2022-03-20 09:35:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:35:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here at tedtedwomen, is that the best thing we said, "well," well, when we're talking about them. "
2022-03-20 09:35:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:36:00 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a great part of the design that we're going to solve is that we had to solve a unique result of the substance of the ground, and if you can use it to see it in the ground.
2022-03-20 09:36:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:36:00 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.019 | ppl 259.34 | bleu 18.52 | wps 4828.2 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 18.52
2022-03-20 09:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-20 09:36:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:36:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 18.52) (writing took 2.0306424302980304 seconds)
2022-03-20 09:36:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-20 09:36:02 | INFO | train | epoch 019 | loss 7.398 | ppl 168.6 | wps 39605.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.748 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 2030
KL Stats: Epoch 19 Divergences: Uniform: 1.3904806265184035 Unigram: 2.1117354249257385
2022-03-20 09:36:02 | INFO | fairseq.trainer | begin training epoch 20
2022-03-20 09:36:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:36:11 | INFO | train_inner | epoch 020:     22 / 157 loss=7.322, ppl=160.06, wps=31817.6, ups=1.28, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.718, loss_scale=4, train_wall=37, gb_free=12.8, wall=2039
2022-03-20 09:36:49 | INFO | train_inner | epoch 020:    122 / 157 loss=7.193, ppl=146.32, wps=67517.3, ups=2.61, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.72, loss_scale=4, train_wall=38, gb_free=11.8, wall=2077
2022-03-20 09:37:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:37:05 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinics.
2022-03-20 09:37:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:37:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-20 09:37:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:37:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldits that make the two new locations.
2022-03-20 09:37:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:37:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food, where happy legs are going to be posted with salt legs with salt and pink.
2022-03-20 09:37:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:37:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to make a few electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-20 09:37:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:37:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, people like the responsibility of life, the number of animals grew up to the number of animals, and this is a foundation of conservation.
2022-03-20 09:37:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:37:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some bols of magnetic lines in the interior lines, but the susulant of the sulant alalarm doesn't have your energy, and so they need their energy, and so that's what they need.
2022-03-20 09:37:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:37:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start able to start with a traditional face with a traditional face of the face of the face and the information that are reconstructed through the information.
2022-03-20 09:37:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:37:40 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that's interesting and measure it interesting and measure it interesting for me here for tedwomen here in tedwomen, is that the best thing that someone said, "if you're working on a table revolution," and then we're working with them. "
2022-03-20 09:37:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:37:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design of design work on our airplane, is a result that we had to solve the unique problems that we had to solve, to be connected in the ground, and that it's all the way that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-20 09:37:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:37:42 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.933 | ppl 244.37 | bleu 20.33 | wps 4435.5 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 20.33
2022-03-20 09:37:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-20 09:37:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:37:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 20.33) (writing took 2.0112499319948256 seconds)
2022-03-20 09:37:44 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-20 09:37:44 | INFO | train | epoch 020 | loss 7.226 | ppl 149.72 | wps 38544.8 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.723 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 2132
KL Stats: Epoch 20 Divergences: Uniform: 1.4231729427183837 Unigram: 2.150220874144194
2022-03-20 09:37:44 | INFO | fairseq.trainer | begin training epoch 21
2022-03-20 09:37:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:38:09 | INFO | train_inner | epoch 021:     65 / 157 loss=7.106, ppl=137.77, wps=30940.6, ups=1.24, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.764, loss_scale=4, train_wall=37, gb_free=12, wall=2158
2022-03-20 09:38:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:38:48 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinics.
2022-03-20 09:38:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:38:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you.
2022-03-20 09:38:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:38:56 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf.
2022-03-20 09:38:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:39:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food food, where happy legs are going to be posted with salz and fat.
2022-03-20 09:39:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:39:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to just bring a few electrodes on his head, and understand exactly what all his thoughts are on the road.
2022-03-20 09:39:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:39:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the makea, people like the responsibility for the wild, grew up the number of the wild animals, and this is a foundation for conservation.
2022-03-20 09:39:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:39:12 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloop of the magnetic field, but the sullant like it, if you don't need your energy, and so that's what you need.
2022-03-20 09:39:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:39:16 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face that can start with with the big facial of the face, and the information that makes it all the structure.
2022-03-20 09:39:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:39:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it on me, "that's a lot of women."
2022-03-20 09:39:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:39:22 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a lot of the design work that we're going to see in our plane, is that we had to solve a result of that we had to solve the unique problems that were connected to the ground.
2022-03-20 09:39:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:39:22 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.755 | ppl 216.04 | bleu 20.83 | wps 4832.3 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 20.83
2022-03-20 09:39:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-20 09:39:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:39:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:39:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 20.83) (writing took 2.037012433167547 seconds)
2022-03-20 09:39:24 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-20 09:39:24 | INFO | train | epoch 021 | loss 7.119 | ppl 139 | wps 39642.2 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.747 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2232
KL Stats: Epoch 21 Divergences: Uniform: 1.4420734285923145 Unigram: 2.1625645908767925
2022-03-20 09:39:24 | INFO | fairseq.trainer | begin training epoch 22
2022-03-20 09:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:39:27 | INFO | train_inner | epoch 022:      8 / 157 loss=7.188, ppl=145.86, wps=31746.8, ups=1.28, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.732, loss_scale=4, train_wall=37, gb_free=12, wall=2236
2022-03-20 09:40:05 | INFO | train_inner | epoch 022:    108 / 157 loss=7.067, ppl=134.12, wps=65776.9, ups=2.67, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.726, loss_scale=4, train_wall=37, gb_free=12, wall=2273
2022-03-20 09:40:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:40:27 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-20 09:40:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:40:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 09:40:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:40:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new gold locks that are going to be written by two new pigs.
2022-03-20 09:40:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:40:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are being served with salz and fat.
2022-03-20 09:40:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:40:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-20 09:40:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:40:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility, the number of wild animals grew back to namibia. and that's a foundation for conservation.
2022-03-20 09:40:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:40:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field, but the susullers don't move when they need their movements and so they need the sullength.
2022-03-20 09:40:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:40:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of the face of the face and the fundamental shape of the universe.
2022-03-20 09:40:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:40:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me here at tedwomen, is that... "well, you know, you know, the best one said," you know, "the men who said," and then we've been working on the top of them. "
2022-03-20 09:40:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:41:00 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're going to see in our airplane, is a result that we had to solve the unique problems in the ground.
2022-03-20 09:41:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:41:00 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.686 | ppl 205.95 | bleu 20.74 | wps 4973.6 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 20.83
2022-03-20 09:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-20 09:41:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:41:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 20.74) (writing took 0.9202034762129188 seconds)
2022-03-20 09:41:01 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-20 09:41:01 | INFO | train | epoch 022 | loss 6.985 | ppl 126.66 | wps 40562.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.681 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2329
KL Stats: Epoch 22 Divergences: Uniform: 1.4638709411439923 Unigram: 2.1868909349157506
2022-03-20 09:41:01 | INFO | fairseq.trainer | begin training epoch 23
2022-03-20 09:41:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:41:21 | INFO | train_inner | epoch 023:     51 / 157 loss=6.918, ppl=120.9, wps=33475.8, ups=1.31, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.597, loss_scale=4, train_wall=37, gb_free=11.9, wall=2349
2022-03-20 09:41:58 | INFO | train_inner | epoch 023:    151 / 157 loss=6.747, ppl=107.39, wps=67732.1, ups=2.67, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.651, loss_scale=4, train_wall=37, gb_free=11.9, wall=2387
2022-03-20 09:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:42:05 | INFO | fairseq.tasks.translation | example hypothesis: we asked these pills in the clinic.
2022-03-20 09:42:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:42:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-20 09:42:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:42:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new golden locks that create two new pigs.
2022-03-20 09:42:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:42:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and ppeppet.
2022-03-20 09:42:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:42:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-20 09:42:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:42:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, the number of wild animals grew up and that's a foundation for conservation in namibia.
2022-03-20 09:42:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:42:28 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field are starting in the inner field, but the sulal doesn't move when they need their movements, and so they need their energy, and so the sulength of magnetic field.
2022-03-20 09:42:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:42:33 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial, the big constructions of the face, and the fundamental shape of the face, and the fundamental shape, and through the information that we use the whole portion of these reflection, the whole portion of this reflection, the whole structure that's going to fold the whole portion of this reflection, and the whole portion
2022-03-20 09:42:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:42:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons the high-interesting and measure it for me to be here at tedwomen, is that... well, at the front of the piano, the best one who said, "you know," put it up on a table and say, "you know, the high high school revolution," and then we've been working on, "and then we've been working on a long time," and then we've been supported to help you to help you to support the piano, "and then we've been working on the piano."
2022-03-20 09:42:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:42:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of design work that we have to see in our plane was a result that we had to solve the unique problems that we had to solve in the ground, and it's still connected to the ground -- and it's still the mother of the invention of the invention of the invention of a continuous variation, and it would be connected to a restored to a restored to a restored to a restoration of restoration, and that we're either restored to the restored to a restorm, or a restorm of the restoration of a restoration of the refugegegegestion the restoration of a refugetic system that we're able to the restores to the restores, and then we're able to the restored to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-20 09:42:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:42:40 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.632 | ppl 198.3 | bleu 22.78 | wps 4629.2 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 22.78
2022-03-20 09:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-20 09:42:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:42:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 22.78) (writing took 2.1578193083405495 seconds)
2022-03-20 09:42:42 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-20 09:42:42 | INFO | train | epoch 023 | loss 6.845 | ppl 114.99 | wps 38998 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.637 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2431
KL Stats: Epoch 23 Divergences: Uniform: 1.476355507343795 Unigram: 2.219647077624072
2022-03-20 09:42:43 | INFO | fairseq.trainer | begin training epoch 24
2022-03-20 09:42:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:43:18 | INFO | train_inner | epoch 024:     94 / 157 loss=6.818, ppl=112.83, wps=31180.5, ups=1.25, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.646, loss_scale=4, train_wall=37, gb_free=11.9, wall=2467
2022-03-20 09:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:43:46 | INFO | fairseq.tasks.translation | example hypothesis: we made these beetles in the clinic.
2022-03-20 09:43:46 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:43:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-20 09:43:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:43:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are created new goldicks that are creating two new pigs.
2022-03-20 09:43:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:43:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz and pin.
2022-03-20 09:43:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:44:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-20 09:44:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:44:06 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the wild, the number of the wild animals grew back, and that's a basis for conservation in namibia.
2022-03-20 09:44:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:44:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are starting in the inside the inner, but the susulal eggs don't have when they're moving, because their movements need energy, and so the superconductor disorders.
2022-03-20 09:44:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:44:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face and the basic form, and through the information that comes through the whole ports and fold.
2022-03-20 09:44:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:44:18 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are doing it high-interesting and measured to me here at tedwomen is that... yes, when someone said, "you know," when someone said, "you turn them up to men and say,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [don't.
2022-03-20 09:44:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:44:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable system, to a refrigeration system that allows us to use.
2022-03-20 09:44:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:44:19 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.483 | ppl 178.95 | bleu 25.08 | wps 4939 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 25.08
2022-03-20 09:44:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-20 09:44:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:44:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:44:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 25.08) (writing took 2.019190692808479 seconds)
2022-03-20 09:44:21 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-20 09:44:21 | INFO | train | epoch 024 | loss 6.755 | ppl 107.98 | wps 39997.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.625 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2529
KL Stats: Epoch 24 Divergences: Uniform: 1.4913821657891975 Unigram: 2.237043894159451
2022-03-20 09:44:21 | INFO | fairseq.trainer | begin training epoch 25
2022-03-20 09:44:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:44:36 | INFO | train_inner | epoch 025:     37 / 157 loss=6.628, ppl=98.91, wps=32948.7, ups=1.29, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.595, loss_scale=4, train_wall=37, gb_free=12.1, wall=2544
2022-03-20 09:45:13 | INFO | train_inner | epoch 025:    137 / 157 loss=6.693, ppl=103.45, wps=66450.8, ups=2.65, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.614, loss_scale=4, train_wall=37, gb_free=12, wall=2582
2022-03-20 09:45:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:45:25 | INFO | fairseq.tasks.translation | example hypothesis: we made these beetles in the clinic.
2022-03-20 09:45:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:45:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 09:45:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:45:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that make two new pigs.
2022-03-20 09:45:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:45:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where happy legs are served with salz and pitcase.
2022-03-20 09:45:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:45:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the road.
2022-03-20 09:45:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:45:44 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people took responsibility for the wild, the number of wild animals grew back. and that's a basis for conservation in namibia.
2022-03-20 09:45:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:45:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some bust of magnetic field lines are caught in the inside, but the sulouter doesn't like to move when they need energy, and so the sulalty disorder.
2022-03-20 09:45:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:45:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from these reflection reflection, we can start with a traditional facial face and the basic form of the face, and the basic form of the face.
2022-03-20 09:45:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:45:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measured for me here at tedwomen is that... well, at the summit day. "
2022-03-20 09:45:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:45:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're in our airplane, is a result that we had to solve the unique problems that were connected to the ground -- everything from a refrigering system.
2022-03-20 09:45:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:45:56 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.519 | ppl 183.43 | bleu 22.17 | wps 5377.3 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 25.08
2022-03-20 09:45:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-20 09:45:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:45:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 22.17) (writing took 0.9444129299372435 seconds)
2022-03-20 09:45:57 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-20 09:45:57 | INFO | train | epoch 025 | loss 6.661 | ppl 101.22 | wps 41283.3 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.608 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2625
KL Stats: Epoch 25 Divergences: Uniform: 1.4991090944282188 Unigram: 2.2553141227499083
2022-03-20 09:45:57 | INFO | fairseq.trainer | begin training epoch 26
2022-03-20 09:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:46:28 | INFO | train_inner | epoch 026:     80 / 157 loss=6.552, ppl=93.86, wps=34282.6, ups=1.35, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.589, loss_scale=4, train_wall=37, gb_free=12.2, wall=2656
2022-03-20 09:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:47:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beetles in the clinic.
2022-03-20 09:47:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:47:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 09:47:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:47:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that make two new pigs.
2022-03-20 09:47:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:47:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-20 09:47:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:47:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all its thoughts are on the road.
2022-03-20 09:47:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:47:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people to take responsibility for the wild, the number of wildlife animals grew back, and that's a foundation for conservation in namibia.
2022-03-20 09:47:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:47:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloodle of magnet field lines are starting in the inner, but the suprouter may not like to move when they move, because their movements need energy, and so the suprouum disorders.
2022-03-20 09:47:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:47:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial, which is the big constructions of the face and the basic shape, and through the one of these portion information that contains all the ports and fold.
2022-03-20 09:47:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:47:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's going to be interesting and measure it up to me here at tedwomen, is that... well, when you were smiling, it's best put together when someone said, "take you to the men in your table and say," if the revolution starts to support you, "we're already supporting women for this long time, we've already been working on the fact that women," well, "well," we have a lot of women in this is a lot of time to be working on a long time to be working on the millennium. "
2022-03-20 09:47:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:47:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're at our plane was a result that we had to solve the unique problems that were connected to the ground -- everything of a continuous variation and a refrigeration system that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see in the most of a security, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-20 09:47:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:47:35 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.309 | ppl 158.61 | bleu 27.58 | wps 4664.7 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 27.58
2022-03-20 09:47:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-20 09:47:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:47:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:47:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 27.58) (writing took 2.0107827582396567 seconds)
2022-03-20 09:47:37 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-20 09:47:37 | INFO | train | epoch 026 | loss 6.567 | ppl 94.79 | wps 39238.5 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.577 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2726
KL Stats: Epoch 26 Divergences: Uniform: 1.508075959530121 Unigram: 2.2765508727173054
2022-03-20 09:47:38 | INFO | fairseq.trainer | begin training epoch 27
2022-03-20 09:47:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:47:47 | INFO | train_inner | epoch 027:     23 / 157 loss=6.547, ppl=93.5, wps=31332.9, ups=1.26, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.564, loss_scale=4, train_wall=37, gb_free=12.9, wall=2736
2022-03-20 09:48:25 | INFO | train_inner | epoch 027:    123 / 157 loss=6.513, ppl=91.3, wps=66505, ups=2.66, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.559, loss_scale=4, train_wall=37, gb_free=11.7, wall=2773
2022-03-20 09:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:48:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 09:48:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:48:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 09:48:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:48:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that are going to write two new pigs.
2022-03-20 09:48:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:48:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-20 09:48:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:48:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 09:48:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:49:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-20 09:49:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:49:06 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloodlines are caught in the inside, but the suprouter doesn't like to move when they're using their movements, and so the supralty disorder.
2022-03-20 09:49:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:49:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial, which is the big constructions of the face and the basic shape, and through the theast structure, the whole portion of the portion structure and fold all the fold.
2022-03-20 09:49:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:49:14 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured for me here at tedwomen is that... tyes, when someone said, "turn you up to the men in your table and tell you," if the truth is that we've already been supporting them, "you know," you know, you know, you know, you know, you know, "well, you know, you know, you know," well, you know, you know, you know, you know, you're going to have a long time to go to go to go to the "
2022-03-20 09:49:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:49:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're at our plane was a result that we had to solve the unique problems that were connected to the ground -- all of us will use of a continuous variation and refrigeration system that we're going to use in the aircraft, or if you're able to use the aircraft, you're either going to see the refrigeration of an aircraft that we're going to be able to see the same.
2022-03-20 09:49:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:49:17 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.288 | ppl 156.27 | bleu 26.99 | wps 4768.8 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 27.58
2022-03-20 09:49:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-20 09:49:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:49:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 26.99) (writing took 0.9788572220131755 seconds)
2022-03-20 09:49:18 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-20 09:49:18 | INFO | train | epoch 027 | loss 6.491 | ppl 89.92 | wps 39388.4 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.565 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2826
KL Stats: Epoch 27 Divergences: Uniform: 1.5105011979686205 Unigram: 2.291441000999498
2022-03-20 09:49:18 | INFO | fairseq.trainer | begin training epoch 28
2022-03-20 09:49:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:49:43 | INFO | train_inner | epoch 028:     66 / 157 loss=6.501, ppl=90.59, wps=31848.1, ups=1.28, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.597, loss_scale=4, train_wall=37, gb_free=12.8, wall=2851
2022-03-20 09:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:50:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these beetles in the clinic.
2022-03-20 09:50:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:50:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 09:50:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:50:29 | INFO | fairseq.tasks.translation | example hypothesis: stars are creating new goldilocks that are going to create two new pigs.
2022-03-20 09:50:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:50:33 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pitcase.
2022-03-20 09:50:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:50:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 09:50:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:50:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility to the wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-20 09:50:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:50:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnet field lines are caught in the inside, but the superconductor doesn't like to move, because your movements use energy, and so the superconductor disorders.
2022-03-20 09:50:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:50:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that gives the big constructions of the face and the basic form, and it restores all the portudes and fold a fold.
2022-03-20 09:50:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:50:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me to be here at tedwomen, is that -- well, in the striking dinner, it's been best summarized as someone said, "turn you to men on your table and say," if the revolution starts supporting you. "
2022-03-20 09:50:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:50:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to keep a refrigeration system that allows us to be refrigered to a refrigerator or to the air, if you can either see the refrigeration of an aircraft, or to a mechanism.
2022-03-20 09:50:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:50:56 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.215 | ppl 148.6 | bleu 28.57 | wps 4732 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 28.57
2022-03-20 09:50:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-20 09:50:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:50:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:50:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 28.57) (writing took 2.0549304969608784 seconds)
2022-03-20 09:50:58 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-20 09:50:58 | INFO | train | epoch 028 | loss 6.434 | ppl 86.48 | wps 39395.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.576 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2926
KL Stats: Epoch 28 Divergences: Uniform: 1.518831549514218 Unigram: 2.3014664879301625
2022-03-20 09:50:58 | INFO | fairseq.trainer | begin training epoch 29
2022-03-20 09:50:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:51:02 | INFO | train_inner | epoch 029:      9 / 157 loss=6.406, ppl=84.78, wps=32095.7, ups=1.27, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.573, loss_scale=4, train_wall=37, gb_free=11.8, wall=2930
2022-03-20 09:51:39 | INFO | train_inner | epoch 029:    109 / 157 loss=6.389, ppl=83.79, wps=66610.1, ups=2.65, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.538, loss_scale=4, train_wall=37, gb_free=11.7, wall=2968
2022-03-20 09:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:52:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 09:52:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:52:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most here.
2022-03-20 09:52:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:52:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will write two new pigs.
2022-03-20 09:52:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:52:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-20 09:52:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:52:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 09:52:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:52:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the people have been taking responsibility for wildlife, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-20 09:52:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:52:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnet field lines are caught in the inside, but the suprouter doesn't like to move, because they use their movements, and so the superconductor disorders.
2022-03-20 09:52:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:52:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial reflection of the face and the basic form of facial and restoring the whole portion of the structure and all the folding a fold.
2022-03-20 09:52:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:52:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been highly interesting and measured to me here at tedwomen is that... tyes, when stristriking dinner, it was best summarized when somebody said, "turn you to men on your table and tell them," if the revolution starts. "
2022-03-20 09:52:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:52:36 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need is still the mother of invention, and a large part of design work that we are at our plane at the stumber, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and cooling system that allows us to stop a refrigerator machine, or if you can use a mechanism, you can either see the trajectory, or if you can use a mechanism, or a mechanism.
2022-03-20 09:52:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:52:36 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.187 | ppl 145.7 | bleu 28.63 | wps 4826.1 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 28.63
2022-03-20 09:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-20 09:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:52:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 28.63) (writing took 1.9880992248654366 seconds)
2022-03-20 09:52:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-20 09:52:38 | INFO | train | epoch 029 | loss 6.363 | ppl 82.29 | wps 39538.8 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.537 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3026
KL Stats: Epoch 29 Divergences: Uniform: 1.5196881814237078 Unigram: 2.315091946166883
2022-03-20 09:52:38 | INFO | fairseq.trainer | begin training epoch 30
2022-03-20 09:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:52:58 | INFO | train_inner | epoch 030:     52 / 157 loss=6.355, ppl=81.87, wps=31905.9, ups=1.27, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.529, loss_scale=4, train_wall=37, gb_free=12.1, wall=3046
2022-03-20 09:53:35 | INFO | train_inner | epoch 030:    152 / 157 loss=6.252, ppl=76.2, wps=67541.5, ups=2.67, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.461, loss_scale=4, train_wall=37, gb_free=12.9, wall=3084
2022-03-20 09:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:53:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep on the clinic.
2022-03-20 09:53:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:53:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 09:53:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:53:49 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldicks that will create two new pigs.
2022-03-20 09:53:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:53:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and ppepper.
2022-03-20 09:53:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:53:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-20 09:53:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:54:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for the wild, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-20 09:54:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:54:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are caught in the inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-20 09:54:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:54:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that gives the big constructions of the face and the basic shape, and through the theast information, which includes the entire portion structure and all the folds.
2022-03-20 09:54:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:54:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be interesting and measured to me here at tedwomen is that... tyes, in striking dinner, it was best summarized than someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. "
2022-03-20 09:54:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:54:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on our plane at the stest was a result of that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable system, either by a mechanism, until you can see, or if you can use it to be a specialized transportation.
2022-03-20 09:54:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:54:14 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.139 | ppl 140.92 | bleu 29.38 | wps 4960.6 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 29.38
2022-03-20 09:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-20 09:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:54:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 29.38) (writing took 1.9823624091222882 seconds)
2022-03-20 09:54:16 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-20 09:54:16 | INFO | train | epoch 030 | loss 6.284 | ppl 77.9 | wps 40116.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.486 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3125
KL Stats: Epoch 30 Divergences: Uniform: 1.5232645199649992 Unigram: 2.3384618867675404
2022-03-20 09:54:17 | INFO | fairseq.trainer | begin training epoch 31
2022-03-20 09:54:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:54:53 | INFO | train_inner | epoch 031:     95 / 157 loss=6.223, ppl=74.69, wps=33032.9, ups=1.29, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.504, loss_scale=4, train_wall=37, gb_free=11.7, wall=3161
2022-03-20 09:55:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:55:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 09:55:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:55:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 09:55:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:55:27 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that make two new pigs.
2022-03-20 09:55:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:55:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and ppepper.
2022-03-20 09:55:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:55:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 09:55:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:55:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for the wild, the number of wildlife animals grew up again, and that's a basis for conservation in namibia.
2022-03-20 09:55:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:55:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field are caught in the inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorders.
2022-03-20 09:55:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:55:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that gives the big constructions of the face and restoring the basic shape, and remixing it through that information that pulls the whole portion structure and all a fold.
2022-03-20 09:55:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:55:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to be here for me here at tedwomen is that... tyes, when the striking dinner, it was best summarized when someone said, "turn you to the men on your table and say," if the revolution begins to support you. "'"' "the truth is that we've already been supporting you for a long time."
2022-03-20 09:55:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:55:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and refrigeration system that allows us to stop a refrigeration machine, or if you're in the aircraft, or if you're going to see the propelled to a mechanism.
2022-03-20 09:55:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:55:53 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.067 | ppl 134.06 | bleu 30.19 | wps 4827 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.19
2022-03-20 09:55:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-20 09:55:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:55:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.19) (writing took 2.014024268835783 seconds)
2022-03-20 09:55:55 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-20 09:55:55 | INFO | train | epoch 031 | loss 6.246 | ppl 75.88 | wps 39829.5 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.493 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3224
KL Stats: Epoch 31 Divergences: Uniform: 1.521432418097463 Unigram: 2.3437284749472043
2022-03-20 09:55:56 | INFO | fairseq.trainer | begin training epoch 32
2022-03-20 09:55:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:56:10 | INFO | train_inner | epoch 032:     38 / 157 loss=6.221, ppl=74.59, wps=32086.8, ups=1.29, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.459, loss_scale=4, train_wall=37, gb_free=12.5, wall=3239
2022-03-20 09:56:48 | INFO | train_inner | epoch 032:    138 / 157 loss=6.173, ppl=72.14, wps=67457.1, ups=2.67, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.517, loss_scale=4, train_wall=37, gb_free=12.5, wall=3276
2022-03-20 09:56:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:56:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 09:56:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:57:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-20 09:57:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:57:07 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-20 09:57:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:57:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-20 09:57:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:57:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 09:57:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:57:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for wildlife, the number of wildlife animals grew back. and that's a basis for conservation in namibia.
2022-03-20 09:57:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:57:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught in the inside, but the suprouter doesn't like it when they move, because they're using their movements, and so the superconductor disorder.
2022-03-20 09:57:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:57:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar, which is the big constructions of the face, and the basic shape, and restores it through the one of those ports structure and all the fits.
2022-03-20 09:57:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:57:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- well, when you eat, it was best than someone said, "turn you to the men on your table and tell you," if the revolution begins, "the truth is that we've already been supporting you."
2022-03-20 09:57:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:57:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're on our plane are the stones, was a result that we had to solve the unique problems that were connected to it on the ground -- everything from a continuous variation and a refrigerator system that allows us to the aircraft to be able to stop, and to go to a particular traffic, which is a flying, or if you're going to see the propellyfish, or if you're going to be able to fly, or if you're going to see the propellyfish, or the propelled, you're going to a specific, you're going to the prophecy, you're going to the only see it's going to be able to see it's in the air, or if you're going to see it's going to be able to the same as you're going to be able to see it's in the propellyfish, you're going to see, or the
2022-03-20 09:57:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:57:33 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.034 | ppl 131.03 | bleu 29.94 | wps 4723.7 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.19
2022-03-20 09:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-20 09:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:57:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 09:57:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 29.94) (writing took 0.9904282679781318 seconds)
2022-03-20 09:57:34 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-20 09:57:34 | INFO | train | epoch 032 | loss 6.191 | ppl 73.08 | wps 39957.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.495 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3323
KL Stats: Epoch 32 Divergences: Uniform: 1.5233992254994666 Unigram: 2.3551431848368356
2022-03-20 09:57:35 | INFO | fairseq.trainer | begin training epoch 33
2022-03-20 09:57:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:58:05 | INFO | train_inner | epoch 033:     81 / 157 loss=6.139, ppl=70.45, wps=32399.1, ups=1.29, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.475, loss_scale=4, train_wall=37, gb_free=12.1, wall=3354
2022-03-20 09:58:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 09:58:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep on the clinic clinic.
2022-03-20 09:58:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 09:58:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most of you here.
2022-03-20 09:58:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 09:58:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dining two new pigs.
2022-03-20 09:58:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 09:58:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-20 09:58:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 09:58:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 09:58:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 09:58:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people adopt responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-20 09:58:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 09:59:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like to move because they use their movements, and so the superconductor disorders.
2022-03-20 09:59:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 09:59:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big constructions of the face and the basic shape, and regret it through the theast information that pulls the whole portion structure and all a fold.
2022-03-20 09:59:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 09:59:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to be highly interesting and measured to me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. "the truth is that we've already supported you for this long time."
2022-03-20 09:59:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 09:59:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're at our airplane at the stust, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and refrigeration system that allows us to use an aircraft, or if you're going to see the propelled, you're either going to see the propelled, if you're going to be able to see the same thing.
2022-03-20 09:59:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 09:59:12 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.012 | ppl 129.07 | bleu 31.18 | wps 4791.1 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.18
2022-03-20 09:59:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-20 09:59:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 09:59:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.18) (writing took 1.956864485051483 seconds)
2022-03-20 09:59:14 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-20 09:59:14 | INFO | train | epoch 033 | loss 6.149 | ppl 70.97 | wps 39462.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.472 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3423
KL Stats: Epoch 33 Divergences: Uniform: 1.5257402349490394 Unigram: 2.368284812862426
2022-03-20 09:59:15 | INFO | fairseq.trainer | begin training epoch 34
2022-03-20 09:59:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 09:59:25 | INFO | train_inner | epoch 034:     24 / 157 loss=6.18, ppl=72.48, wps=31710.5, ups=1.26, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.483, loss_scale=4, train_wall=37, gb_free=12, wall=3433
2022-03-20 10:00:03 | INFO | train_inner | epoch 034:    124 / 157 loss=6.104, ppl=68.8, wps=66003.3, ups=2.63, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.486, loss_scale=4, train_wall=38, gb_free=11.8, wall=3471
2022-03-20 10:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:00:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 10:00:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:00:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 10:00:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:00:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will generate new golden locks that will generate two new pigs.
2022-03-20 10:00:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:00:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pill suitcase.
2022-03-20 10:00:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:00:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-20 10:00:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:00:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 10:00:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:00:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured in the inside, but the supraleiter doesn't like to move, because their movements use energy, and so the superconductor disorders.
2022-03-20 10:00:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:00:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar, which gives the great constructions of the face and the basic shape, and regret it through the threshold of the entire portion structure and all the fits a fold.
2022-03-20 10:00:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:00:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, when you're striking dinner, it was best summarized when someone said, "turn you to the men on your table and tell you, 'when the revolution begins, we support you,'" the truth is that we've already been supporting you for a long time. "
2022-03-20 10:00:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:00:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on on our plane is the result that we had to solve the unique problems that were connected to it on the ground -- everything from a continuous variation and a cooler system that allows us to be able to stop in the aircraft at the top of the most staggressive, if you're going to be able to see the most progressive, if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-20 10:00:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:00:55 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.018 | ppl 129.64 | bleu 31.27 | wps 4551.9 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.27
2022-03-20 10:00:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-20 10:00:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:00:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 34 @ 5333 updates, score 31.27) (writing took 1.9408053709194064 seconds)
2022-03-20 10:00:57 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-20 10:00:57 | INFO | train | epoch 034 | loss 6.111 | ppl 69.12 | wps 38591.8 | ups 1.53 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.494 | loss_scale 4 | train_wall 59 | gb_free 11.8 | wall 3525
KL Stats: Epoch 34 Divergences: Uniform: 1.5284565612719903 Unigram: 2.377174726679827
2022-03-20 10:00:57 | INFO | fairseq.trainer | begin training epoch 35
2022-03-20 10:00:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:01:22 | INFO | train_inner | epoch 035:     67 / 157 loss=6.078, ppl=67.54, wps=31573.8, ups=1.26, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.491, loss_scale=4, train_wall=37, gb_free=12.9, wall=3551
2022-03-20 10:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:02:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-20 10:02:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:02:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-20 10:02:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:02:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dining two new pigs.
2022-03-20 10:02:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:02:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pepper suitcase.
2022-03-20 10:02:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:02:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:02:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:02:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-20 10:02:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:02:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught in the inside, but the superconductor doesn't like to move, because they use their movements, and so the superconductor disorder.
2022-03-20 10:02:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:02:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that repeat the big constructions of the face and the basic shape, and eradicate it through the dietheast information that includes all the porting structure and all the fits.
2022-03-20 10:02:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:02:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when somebody said, "turn you to the men on your table and tell you," when the revolution starts to support you, "the truth is that we've already been supporting you for this long time we've already been supporting a rubble carrot to the future."
2022-03-20 10:02:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:02:34 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of the invention, and a big part of the design work that we're stumbling on our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable operating and refrigerating system with liquid that allows us to use a machine in the go-to-fly, or if you can either see the propelled mechanism.
2022-03-20 10:02:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:02:34 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.97 | ppl 125.41 | bleu 31.5 | wps 4829.9 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.5
2022-03-20 10:02:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-20 10:02:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:02:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:02:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 31.5) (writing took 1.918168855831027 seconds)
2022-03-20 10:02:36 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-20 10:02:36 | INFO | train | epoch 035 | loss 6.069 | ppl 67.12 | wps 39895.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.458 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3624
KL Stats: Epoch 35 Divergences: Uniform: 1.529206956871557 Unigram: 2.3918153169249328
2022-03-20 10:02:36 | INFO | fairseq.trainer | begin training epoch 36
2022-03-20 10:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:02:40 | INFO | train_inner | epoch 036:     10 / 157 loss=6.113, ppl=69.22, wps=32109.5, ups=1.29, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.452, loss_scale=4, train_wall=37, gb_free=12.8, wall=3628
2022-03-20 10:03:18 | INFO | train_inner | epoch 036:    110 / 157 loss=6.016, ppl=64.72, wps=66864.4, ups=2.64, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.439, loss_scale=4, train_wall=37, gb_free=12.9, wall=3666
2022-03-20 10:03:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:03:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beetles in the clinic.
2022-03-20 10:03:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:03:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 10:03:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:03:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will generate two new pigs.
2022-03-20 10:03:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:03:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and ppepper suitcase.
2022-03-20 10:03:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:03:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:03:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:03:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 10:03:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:04:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnet rocks are caught inside, but the superconductor doesn't like moving, because they use their movements, and so the supralates disorder.
2022-03-20 10:04:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:04:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial bar that gives the big constructions of the face and restores it through the threshold of that information that refers all the ports structure and all the fits a fold.
2022-03-20 10:04:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:04:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's going to do it up and measure it to me here at tedwomen is that... well, when you're striking dinner, it was best summarized when someone said, "turn to the men on your desk and tell you," if the revolution begins, we support you, "the truth is that we've already been supporting you for a long time."
2022-03-20 10:04:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:04:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our plane are the staggering toes, was a result that we had to solve the unique problems that were connected to operating it on the ground -- all, from a continuous variable variables, and a refrigerator system with refrigerators that allows us to use an aircraft on the top of the aircraft to stop and go-go-blown up to a go-bye to one, and to a go-go-go-bye of them, and to one of them, if you were either of them, we were going to fly them, if you're going to be able to be able to be able to be able to be able to make it, if you're going to be able to be able to be able to be able to be able to fly the exclustered to see them, if you're going to be able to fly the
2022-03-20 10:04:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:04:15 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.938 | ppl 122.62 | bleu 31.79 | wps 4546.5 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.79
2022-03-20 10:04:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-20 10:04:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:04:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 31.79) (writing took 1.9253046507947147 seconds)
2022-03-20 10:04:17 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-20 10:04:17 | INFO | train | epoch 036 | loss 6.036 | ppl 65.63 | wps 39055.2 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.465 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3725
KL Stats: Epoch 36 Divergences: Uniform: 1.5283444341513621 Unigram: 2.392304367175111
2022-03-20 10:04:17 | INFO | fairseq.trainer | begin training epoch 37
2022-03-20 10:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:04:37 | INFO | train_inner | epoch 037:     53 / 157 loss=5.915, ppl=60.35, wps=32085.8, ups=1.26, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.457, loss_scale=4, train_wall=37, gb_free=12.8, wall=3745
2022-03-20 10:05:15 | INFO | train_inner | epoch 037:    153 / 157 loss=6.116, ppl=69.34, wps=66171, ups=2.67, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.469, loss_scale=4, train_wall=37, gb_free=11.7, wall=3783
2022-03-20 10:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:05:20 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-20 10:05:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:05:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know.
2022-03-20 10:05:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:05:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dining two new pigs.
2022-03-20 10:05:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:05:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and ppepper.
2022-03-20 10:05:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:05:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:05:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:05:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of how people took responsibility for wildlife, the number of wildlife animals grew up again, and this has become a basis for conservation in namibia.
2022-03-20 10:05:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:05:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines in the inner, but the superconductor doesn't like to move, because they use their movements, and so the superconductor disorder.
2022-03-20 10:05:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:05:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this mirror reflection, we can start with a traditional face that gives the large constructions of the face and restores it through the most important information that includes the whole porter structure and all the fits.
2022-03-20 10:05:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:05:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to be here at tedwomen is that -- well, in the striking dinner, it was best summarized when someone said, "turn you to the men in your desk and tell you," if the revolution begins, we support you. "the truth, love is that we've already supported you at this point is that we've already supported you in this topic for a long time.
2022-03-20 10:05:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:05:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane on the stumbling toes, was a result that we had to solve the unique problems that were connected to doing it on a continuous variables and a cooling system with fluid that allows us to use an aircraft in the aircraft at our aircraft at the top of the most stumber, to use an aircraft in the most stumber traffic, to a machine in the car station, if you're going to be able to be able to be able to be able to be able to run the most specific, if you're going to see the vehicle, or a refrigering system with fluid system with fluid system with fluid that allows us to use an aircraft that allows us to use an aircraft that allows us to use an aircraft in the aircraft in the aircraft that allows us to use an aircraft in the way, to be able
2022-03-20 10:05:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:05:55 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.921 | ppl 121.14 | bleu 32.01 | wps 4641.5 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.01
2022-03-20 10:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-20 10:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.01) (writing took 1.8528130589984357 seconds)
2022-03-20 10:05:57 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-20 10:05:57 | INFO | train | epoch 037 | loss 6.008 | ppl 64.37 | wps 39318.9 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.452 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3825
KL Stats: Epoch 37 Divergences: Uniform: 1.52987380985025 Unigram: 2.4058798707873215
2022-03-20 10:05:57 | INFO | fairseq.trainer | begin training epoch 38
2022-03-20 10:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:06:34 | INFO | train_inner | epoch 038:     96 / 157 loss=6.128, ppl=69.93, wps=31155.3, ups=1.27, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.494, loss_scale=4, train_wall=37, gb_free=12.6, wall=3862
2022-03-20 10:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:07:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-20 10:07:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:07:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 10:07:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:07:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dining two new pigs.
2022-03-20 10:07:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:07:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-20 10:07:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:07:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-20 10:07:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:07:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew back again, and this has become a basis for conservation in namibia.
2022-03-20 10:07:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:07:24 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-20 10:07:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:07:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and recommending it through the die-structure and all the traces.
2022-03-20 10:07:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:07:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that -- well, in the striking dinner, it was best summarized when someone said, "turn to the men on your table and tell you," when the revolution begins to support you. '"the truth, love is that we've already supported you for a long time."
2022-03-20 10:07:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:07:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our airplane most stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and refrigeration system with refrigeration that allows us to use an airplane to use aircraft traffic, to either use aircraft, to be able to either see the most specific problems that you can either see the most promoting or the propelled to an aircraft system, or the earth.
2022-03-20 10:07:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:07:34 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.91 | ppl 120.29 | bleu 31.71 | wps 4764.9 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.01
2022-03-20 10:07:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-20 10:07:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:07:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 31.71) (writing took 0.9111520200967789 seconds)
2022-03-20 10:07:35 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-20 10:07:35 | INFO | train | epoch 038 | loss 6.002 | ppl 64.08 | wps 40189.9 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.479 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3924
KL Stats: Epoch 38 Divergences: Uniform: 1.5301513117080678 Unigram: 2.4063478199995005
2022-03-20 10:07:36 | INFO | fairseq.trainer | begin training epoch 39
2022-03-20 10:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:07:51 | INFO | train_inner | epoch 039:     39 / 157 loss=5.782, ppl=55.03, wps=33775.4, ups=1.29, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.424, loss_scale=4, train_wall=37, gb_free=11.8, wall=3939
2022-03-20 10:08:28 | INFO | train_inner | epoch 039:    139 / 157 loss=6.022, ppl=64.96, wps=66269.2, ups=2.67, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.502, loss_scale=4, train_wall=37, gb_free=12.8, wall=3977
2022-03-20 10:08:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:08:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-20 10:08:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:08:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 10:08:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:08:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to transcend two new pigs.
2022-03-20 10:08:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:08:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and pill suitcase.
2022-03-20 10:08:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:08:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:08:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:08:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of people's responsibility for wildlife, the number of wild animals grew back again, and that's become a basis for conservation in namibia.
2022-03-20 10:08:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:09:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-20 10:09:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:09:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial able that gives the big constructions of the face and the basic shape, and recommends it through the one that pulls the entire porter structure and all the fits.
2022-03-20 10:09:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:09:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and measured to me here at tedwomen is that... well, when dinner was first summarized, it was said, "turn you to the men on your desk and say," when the revolution begins, we support you. "the truth is that we've been supporting you in this topic for a long time."
2022-03-20 10:09:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:09:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on at our airplane was the most staggering result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable and refrigeration system with liquid, that allows us to use an aircraft in the pile and the go-to-passenger traffic, or the most specific problems that we could either see when you're going to operate in the ground.
2022-03-20 10:09:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:09:14 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.876 | ppl 117.44 | bleu 32.53 | wps 4636 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 32.53
2022-03-20 10:09:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-20 10:09:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:09:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 32.53) (writing took 1.8950386350043118 seconds)
2022-03-20 10:09:16 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-20 10:09:16 | INFO | train | epoch 039 | loss 5.959 | ppl 62.21 | wps 39292.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.463 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4024
KL Stats: Epoch 39 Divergences: Uniform: 1.5307023725165783 Unigram: 2.4180612349269572
2022-03-20 10:09:16 | INFO | fairseq.trainer | begin training epoch 40
2022-03-20 10:09:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:09:47 | INFO | train_inner | epoch 040:     82 / 157 loss=5.99, ppl=63.56, wps=31407.9, ups=1.27, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.422, loss_scale=4, train_wall=37, gb_free=12.2, wall=4056
2022-03-20 10:10:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:10:19 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep on the clinic.
2022-03-20 10:10:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:10:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 10:10:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:10:27 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will generate two new pigs.
2022-03-20 10:10:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:10:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-20 10:10:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:10:35 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:10:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:10:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people adopted responsibility for wildlife, the number of wild animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-20 10:10:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:10:43 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are trapped inside, but the superconductor doesn't like moving, because they use energy, and so the superconductor disorder.
2022-03-20 10:10:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:10:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big constructures of the face and the basic shape, and recommend it through the one of these information that refers the whole por-structure and all the fits.
2022-03-20 10:10:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:10:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's really interesting and appropriate for me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men in your desk and tell you," when the revolution begins, we support you, '"the truth is that we've already been supporting you for a long time."
2022-03-20 10:10:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:10:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of the design work that we're on our airplane on the stust was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything, from a continuous variables and a refrigerator system that allows us to use an aircraft in the go-traffic to a particular vehicle, or if you're going to be able to run by the propelled to the ground, if you're going to be able to be able to operate it on the ground -- everything that you're going to see it on the wrong ground -- everything, from a continuously variable to the ground, from a continuously variable to the ground.
2022-03-20 10:10:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:10:54 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.882 | ppl 117.93 | bleu 32.44 | wps 4693.4 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 32.53
2022-03-20 10:10:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-20 10:10:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:10:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:10:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 32.44) (writing took 0.9002692489884794 seconds)
2022-03-20 10:10:55 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-20 10:10:55 | INFO | train | epoch 040 | loss 5.931 | ppl 61.01 | wps 39829 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.44 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 4123
KL Stats: Epoch 40 Divergences: Uniform: 1.5330658500772107 Unigram: 2.428370407277986
2022-03-20 10:10:55 | INFO | fairseq.trainer | begin training epoch 41
2022-03-20 10:10:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:11:05 | INFO | train_inner | epoch 041:     25 / 157 loss=5.912, ppl=60.22, wps=32822.6, ups=1.29, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.45, loss_scale=4, train_wall=37, gb_free=12.6, wall=4133
2022-03-20 10:11:43 | INFO | train_inner | epoch 041:    125 / 157 loss=5.917, ppl=60.43, wps=66352.9, ups=2.66, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.454, loss_scale=4, train_wall=37, gb_free=12, wall=4171
2022-03-20 10:11:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:11:58 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep beep in the clinic.
2022-03-20 10:11:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:12:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know.
2022-03-20 10:12:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:12:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will generate two new pigs.
2022-03-20 10:12:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:12:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-20 10:12:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:12:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-20 10:12:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:12:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for the wildlife, the number of wildlife grew up again, and that's become a foundation for conservation in namibia.
2022-03-20 10:12:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:12:23 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of bundles of magnetic field are caught inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-20 10:12:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:12:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial able that gives the big constructions of the face and the basic shape, and ending it through the one that refers the whole porter structure and all the fences.
2022-03-20 10:12:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:12:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn you to the men on your desk and tell you," when the revolution starts to support you, 'the truth is that we've already been supporting you for a long time. "
2022-03-20 10:12:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:12:32 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need is still the mother of invention, and a big part of the design work that we're on on our airplane was a result of having to solve the unique problems that were connected to operate it on the ground -- everything from a continuously variable operations and a cooling system with liquid that allows us to use a machine in the aircraft until one of the most specific vehicles is either drifted, or if you fly the propelled to the ground, you can see it in the same way.
2022-03-20 10:12:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:12:32 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.832 | ppl 113.91 | bleu 32.8 | wps 4779.8 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 32.8
2022-03-20 10:12:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-20 10:12:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:12:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:12:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 32.8) (writing took 1.8782300809398293 seconds)
2022-03-20 10:12:34 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-20 10:12:34 | INFO | train | epoch 041 | loss 5.908 | ppl 60.04 | wps 39765 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.437 | loss_scale 4 | train_wall 58 | gb_free 11.7 | wall 4223
KL Stats: Epoch 41 Divergences: Uniform: 1.531910821731359 Unigram: 2.4326644405063713
2022-03-20 10:12:35 | INFO | fairseq.trainer | begin training epoch 42
2022-03-20 10:12:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:13:00 | INFO | train_inner | epoch 042:     68 / 157 loss=5.872, ppl=58.59, wps=32299, ups=1.29, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.437, loss_scale=4, train_wall=37, gb_free=22.3, wall=4249
2022-03-20 10:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:13:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep on the clinic.
2022-03-20 10:13:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:13:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 10:13:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:13:45 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will create two new pigs.
2022-03-20 10:13:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:13:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pill suitcase.
2022-03-20 10:13:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:13:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:13:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:13:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-20 10:13:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:14:02 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-20 10:14:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:14:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the big constructions of the face and the basic shape, and deploy it through the one of those information that refers the whole porter structure and all the traces.
2022-03-20 10:14:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:14:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn to men on your table and tell them," when the revolution begins, we support you. "the truth is that we've already supported you for a long time."
2022-03-20 10:14:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:14:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane was the result that we had to solve the unique problems that were connected to operating it on the ground -- everything that a continuous variation and cooling system with liquid liquid, that allows us to use an aircraft in the stop-go-to-one to fly the ground, or if you're going to see the mechanism in the same way.
2022-03-20 10:14:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:14:11 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.865 | ppl 116.56 | bleu 32.57 | wps 4910.7 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 32.8
2022-03-20 10:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-20 10:14:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:14:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:14:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 32.57) (writing took 0.9249748019501567 seconds)
2022-03-20 10:14:12 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-20 10:14:12 | INFO | train | epoch 042 | loss 5.883 | ppl 59 | wps 40489.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.427 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4320
KL Stats: Epoch 42 Divergences: Uniform: 1.5352021919422147 Unigram: 2.4422912602720763
2022-03-20 10:14:12 | INFO | fairseq.trainer | begin training epoch 43
2022-03-20 10:14:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:14:17 | INFO | train_inner | epoch 043:     11 / 157 loss=5.838, ppl=57.22, wps=33439.7, ups=1.31, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.398, loss_scale=4, train_wall=37, gb_free=12.1, wall=4325
2022-03-20 10:14:54 | INFO | train_inner | epoch 043:    111 / 157 loss=5.913, ppl=60.24, wps=66327.7, ups=2.66, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.452, loss_scale=4, train_wall=37, gb_free=11.9, wall=4363
2022-03-20 10:15:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:15:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-20 10:15:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:15:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 10:15:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:15:23 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will generate two new pigs.
2022-03-20 10:15:23 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:15:27 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frog legs are served with salz and pill suitcase.
2022-03-20 10:15:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:15:31 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:15:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:15:35 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife animals grew up again, and that's become a basis for conservation in namibia.
2022-03-20 10:15:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:15:40 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field caps are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconductor disorder.
2022-03-20 10:15:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:15:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face that repeats the big constructures of the face and the basic shape, and deploy it through the one of those information that relates the whole porn structure and all the fine.
2022-03-20 10:15:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:15:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your desk and tell you," when the revolution begins, we support you. '"the truth, women love you for a long time, is that we've already been supporting you to support you about this topic for a long time."
2022-03-20 10:15:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:15:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane is the most stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable operations and a cooling system with liquid that allows us to use an aircraft on the stop-go-transportation to a special driver, or if you're either drifted to the most propelled, or if you're going to operate the most proper mechanism of a tragic of a mechanism in the wrong way -- all the same way.
2022-03-20 10:15:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:15:50 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.827 | ppl 113.53 | bleu 33.15 | wps 4632.6 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.15
2022-03-20 10:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-20 10:15:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:15:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt
2022-03-20 10:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.15) (writing took 1.9002669593319297 seconds)
2022-03-20 10:15:52 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-20 10:15:52 | INFO | train | epoch 043 | loss 5.863 | ppl 58.18 | wps 39313.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.435 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 4421
KL Stats: Epoch 43 Divergences: Uniform: 1.534455966623363 Unigram: 2.4469723176274876
2022-03-20 10:15:53 | INFO | fairseq.trainer | begin training epoch 44
2022-03-20 10:15:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:16:13 | INFO | train_inner | epoch 044:     54 / 157 loss=5.882, ppl=58.96, wps=31456, ups=1.27, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.437, loss_scale=4, train_wall=37, gb_free=12.3, wall=4442
2022-03-20 10:16:51 | INFO | train_inner | epoch 044:    154 / 157 loss=5.791, ppl=55.38, wps=68257.2, ups=2.67, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.414, loss_scale=4, train_wall=37, gb_free=12, wall=4479
2022-03-20 10:16:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:16:56 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beetles in the clinic.
2022-03-20 10:16:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:17:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most know here.
2022-03-20 10:17:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:17:03 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-20 10:17:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:17:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pill suitcase.
2022-03-20 10:17:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:17:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:17:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:17:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew back, and this has become a foundation for conservation in namibia.
2022-03-20 10:17:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:17:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-20 10:17:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:17:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that repeats the great constructions of the face and the basic form, and emphasize it through that information that includes the whole porn structure and all the fine structure.
2022-03-20 10:17:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:17:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... tyes, at the controversial dinner, it was best summarized when someone said, "turn you to the men on your table and tell you, 'when the revolution begins, we support you.'" the truth is that we've already been supporting you with this topic for a long time. "
2022-03-20 10:17:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:17:29 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane most stumbling, was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything from a continuously variable drill and cooling system with liquid, that allows us to use an aircraft machine in the stop-go-go-to-one traffic, either drives the propeller or the ground.
2022-03-20 10:17:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:17:29 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.825 | ppl 113.38 | bleu 32.99 | wps 4927.1 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.15
2022-03-20 10:17:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-20 10:17:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:17:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:17:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 32.99) (writing took 0.8735815957188606 seconds)
2022-03-20 10:17:30 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-20 10:17:30 | INFO | train | epoch 044 | loss 5.843 | ppl 57.4 | wps 40503.4 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.43 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 4518
KL Stats: Epoch 44 Divergences: Uniform: 1.5352332893494667 Unigram: 2.4529469987310857
2022-03-20 10:17:30 | INFO | fairseq.trainer | begin training epoch 45
2022-03-20 10:17:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:18:07 | INFO | train_inner | epoch 045:     97 / 157 loss=5.752, ppl=53.89, wps=33575.4, ups=1.31, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.431, loss_scale=4, train_wall=37, gb_free=12.7, wall=4555
2022-03-20 10:18:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:18:33 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepters in the clinic.
2022-03-20 10:18:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:18:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-20 10:18:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:18:41 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will generate two new pigs.
2022-03-20 10:18:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:18:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pills.
2022-03-20 10:18:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:18:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-20 10:18:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:18:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people adopted responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-20 10:18:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:18:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bundle of magnetic field lines captured inside, but the superconductor doesn't like moving because they use their movements, and so the superconductor disorders.
2022-03-20 10:18:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:19:01 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the big contures of the face and the basic shape, and deploy it through that information that includes all the por-structure and all the fine.
2022-03-20 10:19:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:19:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... tyes, when dinner was best summarized when somebody said, "turn you to the men on your table and tell them," when the revolution begins, we support you. '"the truth, love is that we've already started you in this topic for a long time."
2022-03-20 10:19:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:19:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable drive and refrigerator system with liquid that allows us to use an aircraft machine in the stop-go-to-one traffic, either drifting the propeller, or seeing the soil.
2022-03-20 10:19:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:19:06 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.809 | ppl 112.14 | bleu 32.87 | wps 4917.8 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.15
2022-03-20 10:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-20 10:19:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:19:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 45 @ 7060 updates, score 32.87) (writing took 0.8727873777970672 seconds)
2022-03-20 10:19:07 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-20 10:19:07 | INFO | train | epoch 045 | loss 5.827 | ppl 56.78 | wps 40611.5 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.438 | loss_scale 4 | train_wall 58 | gb_free 13.2 | wall 4615
KL Stats: Epoch 45 Divergences: Uniform: 1.5331214362208971 Unigram: 2.4566524275286388
2022-03-20 10:19:07 | INFO | fairseq.trainer | begin training epoch 46
2022-03-20 10:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-20 10:19:22 | INFO | train_inner | epoch 046:     40 / 157 loss=5.947, ppl=61.7, wps=32264.6, ups=1.33, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.446, loss_scale=4, train_wall=36, gb_free=12.4, wall=4631
2022-03-20 10:20:00 | INFO | train_inner | epoch 046:    140 / 157 loss=5.762, ppl=54.27, wps=67474.9, ups=2.65, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.41, loss_scale=4, train_wall=37, gb_free=11.7, wall=4668
2022-03-20 10:20:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-20 10:20:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-20 10:20:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-20 10:20:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-20 10:20:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-20 10:20:18 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-20 10:20:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-20 10:20:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salt and pill suitcase.
2022-03-20 10:20:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-20 10:20:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-20 10:20:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-20 10:20:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-20 10:20:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-20 10:20:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like to move because they use their movements to use energy and disturb the superconductor.
2022-03-20 10:20:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-20 10:20:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can that repeats the big constructions of the face and the basic shape, and deploy it through the one that refers the entire por-structure and all the fine.
2022-03-20 10:20:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-20 10:20:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that... well, when the strict dinner was best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, we support you. "the truth, women love you for a long time.
2022-03-20 10:20:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-20 10:20:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is the result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable drive and a refrigeration system with liquid that allows us to use an aircraft in the stop-go-traffic to a special vehicle, either drifting the propelled to the ground, or if you look at the propulsion of a mechanism, or a mechanism that's going to run at the wrong ground, or a mechanism, or a refrigeration of a mechanical system that's going to be drifted in the ground.
2022-03-20 10:20:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-20 10:20:44 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.808 | ppl 112.06 | bleu 32.85 | wps 4818.2 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.15
2022-03-20 10:20:44 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-20 10:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-20 10:20:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt
2022-03-20 10:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.4_jelinek_0.19_0.01_0.80_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 32.85) (writing took 0.8826823011040688 seconds)
2022-03-20 10:20:45 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-20 10:20:45 | INFO | train | epoch 046 | loss 5.803 | ppl 55.82 | wps 40337.7 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.422 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 4713
2022-03-20 10:20:45 | INFO | fairseq_cli.train | done training in 4712.9 seconds
