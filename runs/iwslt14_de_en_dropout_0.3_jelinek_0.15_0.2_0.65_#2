Sender: LSF System <lsfadmin@eu-g3-059>
Subject: Job 210595608: <iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:38:24 2022
Job was executed on host(s) <eu-g3-059>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:38:59 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:38:59 2022
Terminated at Wed Mar 23 12:48:15 2022
Results reported at Wed Mar 23 12:48:15 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.15,0.2,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575612 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4151.08 sec.
    Max Memory :                                 5046 MB
    Average Memory :                             3853.67 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14954.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4156 sec.
    Turnaround time :                            4191 sec.

The output (if any) follows:

2022-03-23 11:39:05 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.15,0.2,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575612, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.15,0.2,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:39:05 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:39:05 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:39:05 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:39:05 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:39:05 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1179/160239 [00:00<00:13, 11788.77it/s]  2%|▏         | 2540/160239 [00:00<00:12, 12859.02it/s]  2%|▏         | 3942/160239 [00:00<00:11, 13387.81it/s]  3%|▎         | 5281/160239 [00:00<00:11, 13031.99it/s]  4%|▍         | 6631/160239 [00:00<00:11, 13190.57it/s]  5%|▍         | 7952/160239 [00:00<00:11, 12884.48it/s]  6%|▌         | 9243/160239 [00:00<00:11, 12766.61it/s]  7%|▋         | 10591/160239 [00:00<00:11, 12988.07it/s]  7%|▋         | 11892/160239 [00:00<00:11, 12985.99it/s]  8%|▊         | 13200/160239 [00:01<00:11, 13013.05it/s]  9%|▉         | 14502/160239 [00:01<00:11, 12908.97it/s] 10%|▉         | 15794/160239 [00:01<00:11, 12802.28it/s] 11%|█         | 17075/160239 [00:01<00:11, 12623.03it/s] 11%|█▏        | 18341/160239 [00:01<00:11, 12630.34it/s] 12%|█▏        | 19661/160239 [00:01<00:10, 12799.46it/s] 13%|█▎        | 20989/160239 [00:01<00:10, 12939.40it/s] 14%|█▍        | 22284/160239 [00:01<00:10, 12704.04it/s] 15%|█▍        | 23556/160239 [00:01<00:10, 12705.61it/s] 15%|█▌        | 24829/160239 [00:01<00:10, 12710.70it/s] 16%|█▋        | 26101/160239 [00:02<00:10, 12639.34it/s] 17%|█▋        | 27366/160239 [00:02<00:10, 12544.61it/s] 18%|█▊        | 28675/160239 [00:02<00:10, 12702.85it/s] 19%|█▊        | 29946/160239 [00:02<00:10, 12517.73it/s] 19%|█▉        | 31199/160239 [00:02<00:10, 12514.02it/s] 20%|██        | 32564/160239 [00:02<00:09, 12849.79it/s] 21%|██        | 33850/160239 [00:02<00:10, 12476.31it/s] 22%|██▏       | 35101/160239 [00:02<00:10, 12340.63it/s] 23%|██▎       | 36408/160239 [00:02<00:09, 12548.04it/s] 24%|██▎       | 37665/160239 [00:02<00:09, 12494.47it/s] 24%|██▍       | 38965/160239 [00:03<00:09, 12640.56it/s] 25%|██▌       | 40245/160239 [00:03<00:09, 12686.80it/s] 26%|██▌       | 41543/160239 [00:03<00:09, 12772.75it/s] 27%|██▋       | 42821/160239 [00:03<00:09, 12431.75it/s] 28%|██▊       | 44067/160239 [00:03<00:09, 12339.88it/s] 28%|██▊       | 45303/160239 [00:03<00:09, 12333.28it/s] 29%|██▉       | 46636/160239 [00:03<00:08, 12624.23it/s] 30%|██▉       | 47960/160239 [00:03<00:08, 12804.77it/s] 31%|███       | 49242/160239 [00:03<00:08, 12806.49it/s] 32%|███▏      | 50524/160239 [00:03<00:08, 12602.05it/s] 32%|███▏      | 51799/160239 [00:04<00:08, 12644.86it/s] 33%|███▎      | 53130/160239 [00:04<00:08, 12841.95it/s] 34%|███▍      | 54416/160239 [00:04<00:08, 12764.94it/s] 35%|███▍      | 55694/160239 [00:04<00:08, 12711.51it/s] 36%|███▌      | 57061/160239 [00:04<00:07, 12990.41it/s] 36%|███▋      | 58409/160239 [00:04<00:07, 13133.43it/s] 37%|███▋      | 59734/160239 [00:04<00:07, 13156.35it/s] 38%|███▊      | 61050/160239 [00:04<00:07, 12913.65it/s] 39%|███▉      | 62343/160239 [00:04<00:07, 12871.85it/s] 40%|███▉      | 63648/160239 [00:04<00:07, 12921.20it/s] 41%|████      | 65168/160239 [00:05<00:06, 13595.09it/s] 42%|████▏     | 66529/160239 [00:05<00:06, 13454.78it/s] 42%|████▏     | 67876/160239 [00:05<00:07, 13080.92it/s] 43%|████▎     | 69187/160239 [00:05<00:07, 12705.59it/s] 44%|████▍     | 70540/160239 [00:05<00:06, 12930.97it/s] 45%|████▍     | 71837/160239 [00:05<00:06, 12827.42it/s] 46%|████▌     | 73122/160239 [00:05<00:06, 12664.35it/s] 46%|████▋     | 74391/160239 [00:05<00:06, 12649.45it/s] 47%|████▋     | 75658/160239 [00:05<00:06, 12535.03it/s] 48%|████▊     | 77006/160239 [00:06<00:06, 12810.90it/s] 49%|████▉     | 78361/160239 [00:06<00:06, 13028.73it/s] 50%|████▉     | 79674/160239 [00:06<00:06, 13057.47it/s] 51%|█████     | 81106/160239 [00:06<00:05, 13431.71it/s] 51%|█████▏    | 82451/160239 [00:06<00:05, 13345.11it/s] 52%|█████▏    | 83787/160239 [00:06<00:05, 13258.67it/s] 53%|█████▎    | 85114/160239 [00:06<00:05, 13034.48it/s] 54%|█████▍    | 86550/160239 [00:06<00:05, 13424.07it/s] 55%|█████▍    | 87901/160239 [00:06<00:05, 13448.31it/s] 56%|█████▌    | 89247/160239 [00:06<00:05, 13264.89it/s] 57%|█████▋    | 90594/160239 [00:07<00:05, 13324.49it/s] 57%|█████▋    | 91928/160239 [00:07<00:05, 12988.16it/s] 58%|█████▊    | 93252/160239 [00:07<00:05, 13059.44it/s] 59%|█████▉    | 94560/160239 [00:07<00:05, 12760.69it/s] 60%|█████▉    | 95899/160239 [00:07<00:04, 12943.58it/s] 61%|██████    | 97196/160239 [00:07<00:04, 12924.18it/s] 61%|██████▏   | 98497/160239 [00:07<00:04, 12948.20it/s] 62%|██████▏   | 99867/160239 [00:07<00:04, 13167.47it/s] 63%|██████▎   | 101204/160239 [00:07<00:04, 13226.07it/s] 64%|██████▍   | 102528/160239 [00:07<00:04, 13100.01it/s] 65%|██████▍   | 103839/160239 [00:08<00:04, 12814.40it/s] 66%|██████▌   | 105208/160239 [00:08<00:04, 13068.63it/s] 66%|██████▋   | 106517/160239 [00:08<00:04, 13011.19it/s] 67%|██████▋   | 107820/160239 [00:08<00:04, 12668.08it/s] 68%|██████▊   | 109090/160239 [00:08<00:04, 12444.38it/s] 69%|██████▉   | 110345/160239 [00:08<00:03, 12474.06it/s] 70%|██████▉   | 111721/160239 [00:08<00:03, 12847.23it/s] 71%|███████   | 113008/160239 [00:08<00:03, 12703.02it/s] 71%|███████▏  | 114346/160239 [00:08<00:03, 12899.22it/s] 72%|███████▏  | 115638/160239 [00:08<00:03, 12886.03it/s] 73%|███████▎  | 116928/160239 [00:09<00:03, 12640.76it/s] 74%|███████▍  | 118274/160239 [00:09<00:03, 12881.11it/s] 75%|███████▍  | 119625/160239 [00:09<00:03, 13065.15it/s] 75%|███████▌  | 120933/160239 [00:09<00:03, 12768.53it/s] 76%|███████▋  | 122417/160239 [00:09<00:02, 13373.96it/s] 77%|███████▋  | 123758/160239 [00:09<00:02, 13072.20it/s] 78%|███████▊  | 125069/160239 [00:09<00:02, 12771.18it/s] 79%|███████▉  | 126393/160239 [00:09<00:02, 12905.57it/s] 80%|███████▉  | 127702/160239 [00:09<00:02, 12953.72it/s] 81%|████████  | 129000/160239 [00:10<00:02, 12933.70it/s] 81%|████████▏ | 130295/160239 [00:10<00:02, 12629.52it/s] 82%|████████▏ | 131561/160239 [00:10<00:02, 12623.07it/s] 83%|████████▎ | 132828/160239 [00:10<00:02, 12636.62it/s] 84%|████████▎ | 134093/160239 [00:10<00:02, 12368.04it/s] 84%|████████▍ | 135378/160239 [00:10<00:01, 12506.74it/s] 85%|████████▌ | 136712/160239 [00:10<00:01, 12749.37it/s] 86%|████████▌ | 138044/160239 [00:10<00:01, 12916.91it/s] 87%|████████▋ | 139389/160239 [00:10<00:01, 13073.48it/s] 88%|████████▊ | 140766/160239 [00:10<00:01, 13279.29it/s] 89%|████████▊ | 142095/160239 [00:11<00:01, 13039.90it/s] 89%|████████▉ | 143401/160239 [00:11<00:01, 12943.75it/s] 90%|█████████ | 144697/160239 [00:11<00:01, 12899.36it/s] 91%|█████████ | 145988/160239 [00:11<00:01, 12680.52it/s] 92%|█████████▏| 147258/160239 [00:11<00:01, 12608.14it/s] 93%|█████████▎| 148520/160239 [00:11<00:00, 12405.57it/s] 93%|█████████▎| 149762/160239 [00:11<00:00, 12398.50it/s] 94%|█████████▍| 151048/160239 [00:11<00:00, 12531.74it/s] 95%|█████████▌| 152327/160239 [00:11<00:00, 12605.33it/s] 96%|█████████▌| 153607/160239 [00:11<00:00, 12660.18it/s] 97%|█████████▋| 154930/160239 [00:12<00:00, 12828.95it/s] 98%|█████████▊| 156275/160239 [00:12<00:00, 13011.09it/s] 98%|█████████▊| 157610/160239 [00:12<00:00, 13111.16it/s] 99%|█████████▉| 158922/160239 [00:12<00:00, 12755.85it/s]100%|██████████| 160239/160239 [00:12<00:00, 12849.65it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3942/160239 [00:00<00:03, 39412.61it/s]  5%|▍         | 7911/160239 [00:00<00:03, 39570.80it/s]  7%|▋         | 11870/160239 [00:00<00:03, 39576.74it/s] 10%|▉         | 15828/160239 [00:00<00:03, 39288.48it/s] 12%|█▏        | 19778/160239 [00:00<00:03, 39362.59it/s] 15%|█▍        | 23715/160239 [00:00<00:03, 39197.21it/s] 17%|█▋        | 27635/160239 [00:00<00:03, 38971.27it/s] 20%|█▉        | 31632/160239 [00:00<00:03, 39283.46it/s] 22%|██▏       | 35561/160239 [00:00<00:03, 38803.95it/s] 25%|██▍       | 39524/160239 [00:01<00:03, 39051.82it/s] 27%|██▋       | 43431/160239 [00:01<00:03, 38824.09it/s] 30%|██▉       | 47376/160239 [00:01<00:02, 39009.74it/s] 32%|███▏      | 51311/160239 [00:01<00:02, 39110.44it/s] 34%|███▍      | 55249/160239 [00:01<00:02, 39189.95it/s] 37%|███▋      | 59339/160239 [00:01<00:02, 39700.26it/s] 40%|███▉      | 63335/160239 [00:01<00:02, 39777.72it/s] 42%|████▏     | 67405/160239 [00:01<00:02, 40053.85it/s] 45%|████▍     | 71411/160239 [00:01<00:02, 39830.96it/s] 47%|████▋     | 75395/160239 [00:01<00:02, 39463.07it/s] 50%|████▉     | 79505/160239 [00:02<00:02, 39947.12it/s] 52%|█████▏    | 83593/160239 [00:02<00:01, 40221.77it/s] 55%|█████▍    | 87741/160239 [00:02<00:01, 40595.10it/s] 57%|█████▋    | 91802/160239 [00:02<00:01, 40389.42it/s] 60%|█████▉    | 95842/160239 [00:02<00:01, 40108.00it/s] 62%|██████▏   | 99854/160239 [00:02<00:01, 40073.77it/s] 65%|██████▍   | 103862/160239 [00:02<00:01, 39934.90it/s] 67%|██████▋   | 107856/160239 [00:02<00:01, 39888.34it/s] 70%|██████▉   | 111846/160239 [00:02<00:01, 39783.81it/s] 72%|███████▏  | 115825/160239 [00:02<00:01, 39766.47it/s] 75%|███████▍  | 119875/160239 [00:03<00:01, 39981.17it/s] 77%|███████▋  | 123927/160239 [00:03<00:00, 40137.23it/s] 80%|███████▉  | 127941/160239 [00:03<00:00, 40040.36it/s] 82%|████████▏ | 131946/160239 [00:03<00:00, 39564.32it/s] 85%|████████▍ | 135904/160239 [00:03<00:00, 39429.38it/s] 87%|████████▋ | 139967/160239 [00:03<00:00, 39784.70it/s] 90%|████████▉ | 143947/160239 [00:03<00:00, 39763.80it/s] 92%|█████████▏| 147925/160239 [00:03<00:00, 39346.90it/s] 95%|█████████▍| 151863/160239 [00:03<00:00, 39355.17it/s] 97%|█████████▋| 155869/160239 [00:03<00:00, 39564.40it/s]100%|█████████▉| 159883/160239 [00:04<00:00, 39732.17it/s]100%|██████████| 160239/160239 [00:04<00:00, 39640.87it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2347.12it/s]2022-03-23 11:39:24 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:39:24 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:39:24 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:39:24 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:39:24 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:39:24 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:39:24 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:39:24 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:39:24 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:39:24 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:39:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:39:24 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:39:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:39:24 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:39:24 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:39:24 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 11:39:24 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 11:39:24 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:39:24 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:39:24 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:39:24 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:39:25 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:39:25 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:39:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:39:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:39:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:39:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:40:06 | INFO | train_inner | epoch 001:    104 / 157 loss=13.238, ppl=9661.46, wps=67154.8, ups=2.65, wpb=25305.7, bsz=1024.9, num_updates=100, lr=1.25e-05, gnorm=3.177, loss_scale=8, train_wall=41, gb_free=12.2, wall=42
2022-03-23 11:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:40:29 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 11:40:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:40:31 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 11:40:31 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:40:33 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 11:40:33 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:40:36 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 11:40:36 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:40:39 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:40:39 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:40:42 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 11:40:42 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:40:45 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 11:40:45 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:40:48 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:40:54 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:40:56 | INFO | fairseq.tasks.translation | example hypothesis: the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:40:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:40:56 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.926 | ppl 7781.48 | bleu 0.01 | wps 5898.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:40:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:40:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:40:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.617676684167236 seconds)
2022-03-23 11:40:58 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:40:58 | INFO | train | epoch 001 | loss 12.819 | ppl 7224.76 | wps 42949 | ups 1.7 | wpb 25225.5 | bsz 1001.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.457 | loss_scale 8 | train_wall 60 | gb_free 12.1 | wall 94
KL Stats: Epoch 1 Divergences: Uniform: 0.5554213428103016 Unigram: 1.4037863105540744
2022-03-23 11:40:58 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:41:16 | INFO | train_inner | epoch 002:     47 / 157 loss=11.845, ppl=3678.13, wps=35829.5, ups=1.42, wpb=25181.6, bsz=982.6, num_updates=200, lr=2.5e-05, gnorm=0.943, loss_scale=8, train_wall=37, gb_free=11.9, wall=112
2022-03-23 11:41:53 | INFO | train_inner | epoch 002:    147 / 157 loss=11.179, ppl=2318.38, wps=67574.2, ups=2.69, wpb=25113.7, bsz=1018.9, num_updates=300, lr=3.75e-05, gnorm=0.963, loss_scale=8, train_wall=37, gb_free=12, wall=149
2022-03-23 11:41:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:42:00 | INFO | fairseq.tasks.translation | example hypothesis: and.
2022-03-23 11:42:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:42:03 | INFO | fairseq.tasks.translation | example hypothesis: and and and.
2022-03-23 11:42:03 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and.
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,.
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:42:13 | INFO | fairseq.tasks.translation | example hypothesis: and i i i i i i i i i i i i.
2022-03-23 11:42:13 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:42:17 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,.
2022-03-23 11:42:17 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:42:21 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:42:21 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:42:27 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:42:34 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:37 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:37 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 12.236 | ppl 4822.52 | bleu 0.02 | wps 4492 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:42:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:42:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:42:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.708371187094599 seconds)
2022-03-23 11:42:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:42:38 | INFO | train | epoch 002 | loss 11.32 | ppl 2556.54 | wps 39309.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.902 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 194
KL Stats: Epoch 2 Divergences: Uniform: 0.6980395023958187 Unigram: 0.33223532930259797
2022-03-23 11:42:39 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:42:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:13 | INFO | train_inner | epoch 003:     90 / 157 loss=10.977, ppl=2016.04, wps=31785.2, ups=1.26, wpb=25301.4, bsz=1112.6, num_updates=400, lr=5e-05, gnorm=0.901, loss_scale=8, train_wall=37, gb_free=11.8, wall=229
2022-03-23 11:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:41 | INFO | fairseq.tasks.translation | example hypothesis: it's.
2022-03-23 11:43:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:43:44 | INFO | fairseq.tasks.translation | example hypothesis: and and and it's's, and it's.
2022-03-23 11:43:44 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:43:48 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's a, but but but but but but but but but but but but but but but but but but but but but but but but but but but but but
2022-03-23 11:43:48 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:43:52 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and the the the, and the the the the the the the the the, and the the the the the the the the.
2022-03-23 11:43:52 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:43:56 | INFO | fairseq.tasks.translation | example hypothesis: and i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, i, and i
2022-03-23 11:43:56 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:44:01 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, we, we, we, we, we, we, we, and we, and we, we, we, we, we, we, we, and we the the the the the the the the the.
2022-03-23 11:44:01 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:44:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's, and we, and we, and the the the the the the the the, and we, and we, we, and we, and we, and we, and we, and the the the the the the the the, and we, and we, and we, and the the the the the the the the the the
2022-03-23 11:44:06 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:44:12 | INFO | fairseq.tasks.translation | example hypothesis: and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and and and and and and and and we the the the the the the the the the
2022-03-23 11:44:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:44:20 | INFO | fairseq.tasks.translation | example hypothesis: and we, "" "" "," "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:44:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:44:22 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and the the, and we, and the the the the the the the, and the, and we, and we, and we, we, and we, and we, and we, and we, and we, and we, we, and the the the the the, and the the the the the the the the the the the the the the the, and we, and we, and the the the the the the the the the the the the the the, and the the the the the the the, and the the the the the, and we, and the, and the the the the the the the the the the the the the the the the the the the the the the the the the the the, and the, and the, and the, and we, and we, and the the the the the, and we, and the the the the the the the the the the the the the the the the the the the the the the the the the the, and we, and we, and the the
2022-03-23 11:44:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:44:22 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.088 | ppl 4353.54 | bleu 0.23 | wps 3960 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.23
2022-03-23 11:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:44:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:44:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:44:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.23) (writing took 1.702381728682667 seconds)
2022-03-23 11:44:24 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:44:24 | INFO | train | epoch 003 | loss 10.949 | ppl 1976.3 | wps 37430 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.875 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 300
KL Stats: Epoch 3 Divergences: Uniform: 0.8891630354368519 Unigram: 0.23924081647093376
2022-03-23 11:44:24 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:44:37 | INFO | train_inner | epoch 004:     33 / 157 loss=10.9, ppl=1910.22, wps=29996.3, ups=1.19, wpb=25178.3, bsz=910.4, num_updates=500, lr=6.25e-05, gnorm=0.96, loss_scale=8, train_wall=37, gb_free=12.5, wall=313
2022-03-23 11:45:14 | INFO | train_inner | epoch 004:    133 / 157 loss=10.842, ppl=1835.12, wps=66574.2, ups=2.69, wpb=24784.3, bsz=1026.2, num_updates=600, lr=7.5e-05, gnorm=1.029, loss_scale=8, train_wall=37, gb_free=12.2, wall=350
2022-03-23 11:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:27 | INFO | fairseq.tasks.translation | example hypothesis: this is.
2022-03-23 11:45:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and they're're.
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:45:34 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, but it's a, but it's a, but it.
2022-03-23 11:45:34 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:45:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's the
2022-03-23 11:45:38 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:45:43 | INFO | fairseq.tasks.translation | example hypothesis: and i think you know, i've've've've've've've've've've've've've've've've've've've've have to do it.
2022-03-23 11:45:43 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:45:48 | INFO | fairseq.tasks.translation | example hypothesis: it's a, we can can can can can can have to have to have to have to have to be the the
2022-03-23 11:45:48 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:45:53 | INFO | fairseq.tasks.translation | example hypothesis: it's the, and we have have the, and we have have to have to have to be the, and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the
2022-03-23 11:45:53 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:45:59 | INFO | fairseq.tasks.translation | example hypothesis: and we have the, and we're have the the the of the
2022-03-23 11:45:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:46:06 | INFO | fairseq.tasks.translation | example hypothesis: and the, "" "" "" "" "", "" "" "" "" "" "" "" "" ",", "," "" "" "" "" "" "" "," "" "" "" "" the the the "" "" "" "" "" "" "" "", "" "" "" "" "" "" "" "" "" "
2022-03-23 11:46:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:46:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the, the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the, and the, and the of the of the of the of the of the of the of the of the, and the, and the, and that we have have have have have have have have have, and the, and the, and the, and the, and the, and the, and the that we have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have have to the
2022-03-23 11:46:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:46:08 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.844 | ppl 3676.31 | bleu 1.11 | wps 3931.1 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.11
2022-03-23 11:46:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:46:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:46:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:46:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.11) (writing took 1.699431860819459 seconds)
2022-03-23 11:46:10 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:46:10 | INFO | train | epoch 004 | loss 10.768 | ppl 1743.57 | wps 37256.2 | ups 1.48 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.083 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 406
KL Stats: Epoch 4 Divergences: Uniform: 0.9150997311812212 Unigram: 0.33636404034818157
2022-03-23 11:46:10 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:46:39 | INFO | train_inner | epoch 005:     76 / 157 loss=10.596, ppl=1548.17, wps=29631.1, ups=1.18, wpb=25085, bsz=977.3, num_updates=700, lr=8.75e-05, gnorm=1.032, loss_scale=8, train_wall=37, gb_free=12.2, wall=434
2022-03-23 11:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:47:13 | INFO | fairseq.tasks.translation | example hypothesis: these can't can can't can't can't can't can't can't can't can't can't can be.
2022-03-23 11:47:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:47:17 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world.
2022-03-23 11:47:17 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:47:21 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot, but it's a lot.
2022-03-23 11:47:21 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:47:25 | INFO | fairseq.tasks.translation | example hypothesis: and it's the world, and it's the world, and it's the world.
2022-03-23 11:47:25 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:47:30 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to see it, i'm going to do it, i'm going to do it, i'm going to do it.
2022-03-23 11:47:30 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:47:34 | INFO | fairseq.tasks.translation | example hypothesis: so we can see that we can see that we can can see that we can see the world.
2022-03-23 11:47:34 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:47:39 | INFO | fairseq.tasks.translation | example hypothesis: and we're going to do it, we're going to do it?
2022-03-23 11:47:39 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:47:44 | INFO | fairseq.tasks.translation | example hypothesis: and we can see that we can see that we can see, and we can see, and we can see that we can see that we can see, and we can see that we can see that we can see that we can see that we can see, and we can see that we can see, and we can see that we can see that we can see that we can see, and we can see that we can see that we can see, and we can
2022-03-23 11:47:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:49 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "" "" we've, "it," it's a "" "" "" we can't know, "it," it, "it's going to," it's going to, "it's a" "" "" "" "" "we're going to," it's a "it's a" "" "" "" "" "we've," it's, "it's," it's, "it's," it's, "it's," it's, "it's," it's, "it's," it's a "" "" "" "" "" "" "we've,"
2022-03-23 11:47:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:47:52 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see that we know, we're going to be a lot of the world, and it, and it's a lot of the world, and it's going to be a lot of the world.
2022-03-23 11:47:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:47:52 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.601 | ppl 3106.34 | bleu 1.96 | wps 4214.5 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.96
2022-03-23 11:47:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:47:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:47:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:47:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.96) (writing took 1.7179002780467272 seconds)
2022-03-23 11:47:53 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:47:53 | INFO | train | epoch 005 | loss 10.54 | ppl 1489.05 | wps 38158.3 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.034 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 509
KL Stats: Epoch 5 Divergences: Uniform: 0.9559942429810071 Unigram: 0.4609333143933796
2022-03-23 11:47:54 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:47:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:48:01 | INFO | train_inner | epoch 006:     19 / 157 loss=10.493, ppl=1440.7, wps=30643.1, ups=1.22, wpb=25153, bsz=1065, num_updates=800, lr=0.0001, gnorm=1.022, loss_scale=8, train_wall=37, gb_free=12, wall=517
2022-03-23 11:48:38 | INFO | train_inner | epoch 006:    119 / 157 loss=10.267, ppl=1232.52, wps=67637.6, ups=2.67, wpb=25334.9, bsz=1059.3, num_updates=900, lr=0.0001125, gnorm=1.022, loss_scale=8, train_wall=37, gb_free=12.1, wall=554
2022-03-23 11:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example hypothesis: these can't be these.
2022-03-23 11:48:56 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:49:00 | INFO | fairseq.tasks.translation | example hypothesis: and you can see the world, and you can see the world.
2022-03-23 11:49:00 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:49:04 | INFO | fairseq.tasks.translation | example hypothesis: but it's a lot of a lot of, but it's a lot of, but it's a lot.
2022-03-23 11:49:04 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:49:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's, and it's a lot of the world, and it's going to be, and they're going to see it.
2022-03-23 11:49:09 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:49:14 | INFO | fairseq.tasks.translation | example hypothesis: and i'm going to do you can see that i can see it, but i'm going to be going to see it.
2022-03-23 11:49:14 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:49:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that we can see that we can be a lot of the way.
2022-03-23 11:49:19 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:49:24 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to do, what we're going to be a lot of the world, and we're going to do, we're going to be going to do, and we're going to do it?
2022-03-23 11:49:24 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:49:30 | INFO | fairseq.tasks.translation | example hypothesis: and so we can see that we can see that we can see, and we can see that we can see that we can see that we can see that we can see, and we can see that we can see that we can see that we can see, and we can see that we can see that we can see that we can see that we can see the world.
2022-03-23 11:49:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:37 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "if we said," "we're going to be a," you're going to say, "you're going to see," you're going to be a, "we're going to see," you're going to be a, "you're going to see," you're going to see, "you're going to see the," you're going to be a little little little, "" i said, "you're going to see the," you're going to see, "i said," i said, "you're going to see," you're going to see, "you're going to see the," you're going to see, "you're going to see," we're going to see, "we're going to see," we're going to see, "we're going to say," "" "
2022-03-23 11:49:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:40 | INFO | fairseq.tasks.translation | example hypothesis: and if you can see, we're going to see that we're going to go to see the same, you're going to see the way, you're going to see that we're going to see the way, you're going to see that, you're going to see the way of the way of the way, you're going to see the way, you're going to see the way, you're going to see, and then we're going to see that we're going to see that we're going to see the first first first first first first first, and then we're going to see, and then we're going to see the same same same, and the way, you're going to see the way of the way, you're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to see that we're going to
2022-03-23 11:49:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:40 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.419 | ppl 2739.1 | bleu 1.87 | wps 3760.1 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.96
2022-03-23 11:49:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:49:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 11:49:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 11:49:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 6 @ 938 updates, score 1.87) (writing took 0.7911795410327613 seconds)
2022-03-23 11:49:41 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:49:41 | INFO | train | epoch 006 | loss 10.329 | ppl 1286.62 | wps 36871.3 | ups 1.47 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 0.96 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 616
KL Stats: Epoch 6 Divergences: Uniform: 0.9970895071404012 Unigram: 0.5586652338382629
2022-03-23 11:49:41 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:49:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:50:04 | INFO | train_inner | epoch 007:     62 / 157 loss=10.217, ppl=1190.53, wps=29342.2, ups=1.17, wpb=25123.8, bsz=1040.4, num_updates=1000, lr=0.000125, gnorm=1.005, loss_scale=8, train_wall=36, gb_free=11.6, wall=640
2022-03-23 11:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example hypothesis: these can't use this.
2022-03-23 11:50:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:50:48 | INFO | fairseq.tasks.translation | example hypothesis: and you see the world, and you see the world.
2022-03-23 11:50:48 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:50:52 | INFO | fairseq.tasks.translation | example hypothesis: but but but there's a lot of a lot of, and it's a lot of, and it's a lot of the way.
2022-03-23 11:50:52 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:50:57 | INFO | fairseq.tasks.translation | example hypothesis: and it's the way that are, because it's, and it's the way, and it's, and it's, and it's the way, and it's the way.
2022-03-23 11:50:57 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:51:02 | INFO | fairseq.tasks.translation | example hypothesis: i'm going to do it, and i'm going to do it.
2022-03-23 11:51:02 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:51:07 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see that we can be able to be able to be able to be a lot of this.
2022-03-23 11:51:07 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:51:12 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of people, and we're going to do it?
2022-03-23 11:51:12 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:51:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see that, we can see that we can see, and we can see that we can see that, and we can see that we can see that, and we can see that we can see that we can see that we can see the world, and we can see the world.
2022-03-23 11:51:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:51:25 | INFO | fairseq.tasks.translation | example hypothesis: now, "i said," "," "" "" "" "" "the first of the first first first first,", "the first first first first first," "the first first first first first first," that, "is,", "," the first first thing, "we've said," we've said, "that," that, "is," we've said, "," we've said, "we've said," we've got to say, "we've got to say," that, ",", ",", ",", ",", ",", ",", ",", "the first first first,", ",", ",", "that,", ",", "the first first first," the first first first, ""
2022-03-23 11:51:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:51:28 | INFO | fairseq.tasks.translation | example hypothesis: now, if we're going to make the world, we're going to make the world, and we're going to make the world, and that we're going to be going to make the world, that we're going to make the world, that we're going to make the world, that we're going to make the world, and the world, that we're going to get to get to make the world, and the world, that we're going to make the world, that we're going to make a, and then we're going to make the world, that we're going to make the world, that we're going to get to make the world, that we're going to make the world, and the world, and the world, that we're going to make the world, and that we're going to be going to make a, that we're going to make the world, and we're going to make a, and that we're going to be going to make the world, and that we're going to be going to the
2022-03-23 11:51:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:51:28 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.284 | ppl 2493.48 | bleu 2.21 | wps 3702.2 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2.21
2022-03-23 11:51:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:51:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:51:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.21) (writing took 1.7557244561612606 seconds)
2022-03-23 11:51:29 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:51:29 | INFO | train | epoch 007 | loss 10.18 | ppl 1159.96 | wps 36252.4 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.945 | loss_scale 8 | train_wall 58 | gb_free 11.7 | wall 725
KL Stats: Epoch 7 Divergences: Uniform: 1.0273862315450049 Unigram: 0.6204256700683433
2022-03-23 11:51:30 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:51:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:51:32 | INFO | train_inner | epoch 008:      5 / 157 loss=10.175, ppl=1156.12, wps=28755.5, ups=1.14, wpb=25268.7, bsz=978.1, num_updates=1100, lr=0.0001375, gnorm=0.845, loss_scale=8, train_wall=37, gb_free=12.8, wall=728
2022-03-23 11:52:09 | INFO | train_inner | epoch 008:    105 / 157 loss=10.061, ppl=1068.08, wps=67164.2, ups=2.66, wpb=25262.6, bsz=1008.3, num_updates=1200, lr=0.00015, gnorm=0.868, loss_scale=8, train_wall=37, gb_free=11.7, wall=765
2022-03-23 11:52:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:52:32 | INFO | fairseq.tasks.translation | example hypothesis: these can't use these things.
2022-03-23 11:52:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:52:36 | INFO | fairseq.tasks.translation | example hypothesis: and that's a lot of the world, you see the world.
2022-03-23 11:52:36 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:52:41 | INFO | fairseq.tasks.translation | example hypothesis: but in fact, there's a lot of the world, and there's a lot of, and there's a lot of the other other and the world.
2022-03-23 11:52:41 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:52:45 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's very, and it's in the world, and it's the world, and it's the world.
2022-03-23 11:52:45 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:52:50 | INFO | fairseq.tasks.translation | example hypothesis: it's also also me, i can see that i'm going to be in the world, and i can see that i can be in the world.
2022-03-23 11:52:50 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:52:56 | INFO | fairseq.tasks.translation | example hypothesis: so how we can see how we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 11:52:56 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:53:01 | INFO | fairseq.tasks.translation | example hypothesis: it's the way that we're going to do, and we're going to do that, and we're going to do that, and we're going to do it, and we're going to do it, and we're going to do, and we're going to do it.
2022-03-23 11:53:01 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to do, and we can see that we can see the, and we can see, and we can see that, and we can see, and we can see the, and we can see that we can see, and we can see that we can see the, and we can see that we can see the, and we can see that we can see that, and we can see the world, and we can see the world, and
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:53:14 | INFO | fairseq.tasks.translation | example hypothesis: : one of the one of the time, "i said," "we've said," it's a little bit, "" "" we've said, "we've said," we said, "we've said," we said, "we've got it," we've said, "we've said," we've said, "we've got to say," we've got it, ",", "," we've said, "it," we said, "we've said," we said, "it," we said, ",", "it's been been been been been been a little little bit," and we've said, "we said," we said, "we've got a little bit," and we said, "we've got a little bit," we said, "we've got a little bit
2022-03-23 11:53:14 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:53:17 | INFO | fairseq.tasks.translation | example hypothesis: so, it's a, if we're going to have to be a little bit, and we're going to have to be a little bit of the way, and we're going to see that we're going to have to be a little bit that we're going to be a, and we're going to get a lot of the way, and we're going to be a little bit of the world, and we're going to get a little bit that we're going to be a little bit that we're going to get a little bit that we're going to be a lot of the way that we're going to have to be a little bit that we're going to be a little bit that we're going to have to be a little bit that we're going to get a lot of the way that we're going to have to get a lot of the way that we're going to be a little bit that we're going to be a little bit that we're going to be a little bit of the way, and we're going to get to
2022-03-23 11:53:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:53:17 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.107 | ppl 2206.23 | bleu 3.38 | wps 3698.2 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 3.38
2022-03-23 11:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:53:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 8 @ 1252 updates, score 3.38) (writing took 1.7723943148739636 seconds)
2022-03-23 11:53:19 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:53:19 | INFO | train | epoch 008 | loss 10.019 | ppl 1037.86 | wps 36206.7 | ups 1.44 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.831 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 834
KL Stats: Epoch 8 Divergences: Uniform: 1.0614734524308642 Unigram: 0.668926261599671
2022-03-23 11:53:19 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 11:53:38 | INFO | train_inner | epoch 009:     49 / 157 loss=10.066, ppl=1071.95, wps=28026.6, ups=1.14, wpb=24670.4, bsz=1003.5, num_updates=1300, lr=0.0001625, gnorm=0.813, loss_scale=4, train_wall=37, gb_free=11.8, wall=853
2022-03-23 11:54:15 | INFO | train_inner | epoch 009:    149 / 157 loss=9.703, ppl=833.62, wps=68904.9, ups=2.67, wpb=25771.8, bsz=1055, num_updates=1400, lr=0.000175, gnorm=0.805, loss_scale=4, train_wall=37, gb_free=11.5, wall=891
2022-03-23 11:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:54:21 | INFO | fairseq.tasks.translation | example hypothesis: these can't use this.
2022-03-23 11:54:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:54:25 | INFO | fairseq.tasks.translation | example hypothesis: and now, you're going to see it, you see the world.
2022-03-23 11:54:25 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example hypothesis: but everybody's a lot of between between between between between between between between between between between between and there.
2022-03-23 11:54:29 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:54:33 | INFO | fairseq.tasks.translation | example hypothesis: now, it's going on the united states, and the united states are the united states, and the united states are the united states.
2022-03-23 11:54:33 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:54:38 | INFO | fairseq.tasks.translation | example hypothesis: it also also also also also also also also, i can be able to be able to be able to the same way.
2022-03-23 11:54:38 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example hypothesis: so as we can use our brain, as we can have a little bit of this.
2022-03-23 11:54:42 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:54:47 | INFO | fairseq.tasks.translation | example hypothesis: it's the brain that we have to do with the brain, and we have a lot of the kids, and then we're going to get the children, and our children, and our children, and then they're going to go from our children, and our children.
2022-03-23 11:54:47 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:54:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can do this, and we can do this, and we can do this, and then we can do it, and we can get a lot of the brain, and then we can do it, and we can get a lot of the brain, which is a lot of the brain, and we can get the brain, and we can do that, and we can make a lot of the brain, and we can do
2022-03-23 11:54:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:54:58 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the first, and it's a lot of what we're going to say, "and then we're going to do," and then we're going to do it, "and then we're going to do it," and then we're going to do it. ""
2022-03-23 11:54:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:00 | INFO | fairseq.tasks.translation | example hypothesis: so, it's still still still still, and if we're going to get the way, and we're going to get the way that we're going to have a, and we're going to get the way that we're going to get the way that we're going to get the way that we're going to have to get out of the same way, and we're going to get the same same way, and the way that we're going to have to get out of the way that we're going to have to get to get to get the same same way that we're going to get the same same way that we're going to have to get the same way that we're going to have to get the same same way that we're going to get out of the way that we're going to have to get a, and then, and the way that we're going to get the same same way that we're going to get a, and that we're going to get the same way that we're going to get out of the way that we
2022-03-23 11:55:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:00 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.904 | ppl 1916.47 | bleu 5.73 | wps 4202 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 5.73
2022-03-23 11:55:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 11:55:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:55:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:55:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 9 @ 1408 updates, score 5.73) (writing took 1.8164261220954359 seconds)
2022-03-23 11:55:02 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:55:02 | INFO | train | epoch 009 | loss 9.867 | ppl 933.57 | wps 37817.1 | ups 1.5 | wpb 25132.7 | bsz 1022.1 | num_updates 1408 | lr 0.000176 | gnorm 0.823 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 938
KL Stats: Epoch 9 Divergences: Uniform: 1.0940265175237773 Unigram: 0.7158350684059943
2022-03-23 11:55:03 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:55:37 | INFO | train_inner | epoch 010:     92 / 157 loss=9.753, ppl=862.72, wps=30166, ups=1.21, wpb=24869.8, bsz=1053.8, num_updates=1500, lr=0.0001875, gnorm=0.783, loss_scale=4, train_wall=37, gb_free=12.8, wall=973
2022-03-23 11:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:56:06 | INFO | fairseq.tasks.translation | example hypothesis: these can't use this, can't use it.
2022-03-23 11:56:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:56:10 | INFO | fairseq.tasks.translation | example hypothesis: and then they see that they can see the world, they see the world.
2022-03-23 11:56:10 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:56:14 | INFO | fairseq.tasks.translation | example hypothesis: but everybody has a lot between between between between between between between between between between between between between between between between between between between between between between between between between between between between between between and
2022-03-23 11:56:14 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:56:18 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's a lot of countries, and the united states are the united states, the united states are the united states.
2022-03-23 11:56:18 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:56:23 | INFO | fairseq.tasks.translation | example hypothesis: it could be also also like i'm going to show you how i can be able to be able to do it in the other other other side.
2022-03-23 11:56:23 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:56:27 | INFO | fairseq.tasks.translation | example hypothesis: so as we can imagine our computer, we can be able to be able to be able to be a new new way, if it would be a new way.
2022-03-23 11:56:27 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:56:31 | INFO | fairseq.tasks.translation | example hypothesis: it's the ability to do that we have to do from the, and they're going to go from a lot of children, and they're going to go from our children.
2022-03-23 11:56:31 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:56:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information, we can use this information, and we can make a little bit of information, and we can make a lot of information, and then we can look at it.
2022-03-23 11:56:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:56:40 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of us, and it's really interesting for me for me, "if you've got a lot of time, you're going to do it."
2022-03-23 11:56:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:56:42 | INFO | fairseq.tasks.translation | example hypothesis: so, in fact, the mother, and if we're going to see a, if we're going to do a lot of the way that we're going to be able to be able to do a, and we're going to make a lot of it.
2022-03-23 11:56:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:56:42 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.764 | ppl 1739.05 | bleu 7.66 | wps 4517.1 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 7.66
2022-03-23 11:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 11:56:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:56:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:56:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 10 @ 1565 updates, score 7.66) (writing took 1.782586361747235 seconds)
2022-03-23 11:56:44 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:56:44 | INFO | train | epoch 010 | loss 9.684 | ppl 822.71 | wps 38844.8 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.823 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1040
KL Stats: Epoch 10 Divergences: Uniform: 1.1245125627049628 Unigram: 0.7623130715230043
2022-03-23 11:56:44 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:56:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:56:57 | INFO | train_inner | epoch 011:     35 / 157 loss=9.55, ppl=749.64, wps=31515.9, ups=1.25, wpb=25206.7, bsz=992.5, num_updates=1600, lr=0.0002, gnorm=0.891, loss_scale=4, train_wall=36, gb_free=12, wall=1053
2022-03-23 11:57:35 | INFO | train_inner | epoch 011:    135 / 157 loss=9.616, ppl=784.61, wps=65935.4, ups=2.66, wpb=24785.7, bsz=1016.1, num_updates=1700, lr=0.0002125, gnorm=0.779, loss_scale=4, train_wall=37, gb_free=12.5, wall=1091
2022-03-23 11:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:57:47 | INFO | fairseq.tasks.translation | example hypothesis: these are not able to use.
2022-03-23 11:57:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:57:51 | INFO | fairseq.tasks.translation | example hypothesis: and all of course, they can see it, they see the world.
2022-03-23 11:57:51 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:57:55 | INFO | fairseq.tasks.translation | example hypothesis: but everybody's a different between between between between between between between between between between between between between between and it.
2022-03-23 11:57:55 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:57:59 | INFO | fairseq.tasks.translation | example hypothesis: it's very difficult to be in the countries, and in countries, and the united states, the united states, the united states are the united states.
2022-03-23 11:57:59 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:58:04 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested like, like i'm looking at my way, so i'm going to get the other side in the other other side.
2022-03-23 11:58:04 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:58:08 | INFO | fairseq.tasks.translation | example hypothesis: so as we can do our computer, we can imagine our computer, which is a new way to be able to be able to be able to be able to be able to be able to be able to be a new way.
2022-03-23 11:58:08 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:58:13 | INFO | fairseq.tasks.translation | example hypothesis: is it?
2022-03-23 11:58:13 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:58:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can use this kind of information, and we can start to make a different structure, and the structure of information, which is all the structure of the information, and all of the information, which is the information, and all of the information, and all of the information, and all of the information, and all the information, and all of the information, and all of the information, and all the information,
2022-03-23 11:58:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:58:23 | INFO | fairseq.tasks.translation | example hypothesis: he's one of the reasons that it's interesting for me, and it's really interesting for me to say, "well," if we've got to say, "if you've got to say," if we've got to say, "well," if you've got a very good time, "if we've got to say," well, "well," and then, "and then we've got to you've got to say," well, "well," well, "well," well, "well," and then we've got to say, "well," if we've got the most of the most of the most of you know, "and then we've got the most of you know," and then, "and then," if we've got to say, "and then," if we've got to say, "if we
2022-03-23 11:58:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:58:25 | INFO | fairseq.tasks.translation | example hypothesis: in fact, the mother is still still the mother, and the design of our work, and if we're going to see that if we had to look at the same time, if we had to see that we had to look at the same time, and we had to see that we had to see that we had to see the same way to see that if we had to see that we had to see the same way to see that if we had to see that we had to see that we had to see that we had to see that we had to see the same way to see that if we had to see that if we had to see, and to see the same time, and we had to see that we had to see that we had to see that we had to see the same time to see that if we had to see that we had to see that if we had to see that if we had to see that if we had to look at a, and we had to look at the same time to see that if we had to see that the
2022-03-23 11:58:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:58:25 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.521 | ppl 1468.91 | bleu 9.66 | wps 4262.5 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 9.66
2022-03-23 11:58:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 11:58:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:58:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 11:58:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 11 @ 1722 updates, score 9.66) (writing took 1.7760980180464685 seconds)
2022-03-23 11:58:27 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 11:58:27 | INFO | train | epoch 011 | loss 9.521 | ppl 734.83 | wps 38276.6 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.796 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1143
KL Stats: Epoch 11 Divergences: Uniform: 1.1560040908012028 Unigram: 0.7920785968593841
2022-03-23 11:58:27 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 11:58:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:58:57 | INFO | train_inner | epoch 012:     78 / 157 loss=9.259, ppl=612.53, wps=31341.7, ups=1.22, wpb=25690.2, bsz=1080.7, num_updates=1800, lr=0.000225, gnorm=0.847, loss_scale=4, train_wall=37, gb_free=12, wall=1173
2022-03-23 11:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:59:30 | INFO | fairseq.tasks.translation | example hypothesis: these animals can't use no chemical materials.
2022-03-23 11:59:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, you know, they see it without different world.
2022-03-23 11:59:34 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 11:59:38 | INFO | fairseq.tasks.translation | example hypothesis: but everybody else else else else is a lot between energy, and intelligence.
2022-03-23 11:59:38 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 11:59:42 | INFO | fairseq.tasks.translation | example hypothesis: and very difficult, it's working on japan, and the countries, countries, and the united states are working on the united states.
2022-03-23 11:59:42 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 11:59:46 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, how i'm working on my side side side in the other side of the other side.
2022-03-23 11:59:46 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can make our computer computer, can be able to be able to do this new brain.
2022-03-23 11:59:50 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 11:59:55 | INFO | fairseq.tasks.translation | example hypothesis: and it's the impact? we have to have, from the students, who have been working from the science, and many children who come out of our children, and many children are going to go from our children.
2022-03-23 11:59:55 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 11:59:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that we can start to do with this process, we can start able to start with a traditional traditional dna, and the structure of the structure of information, and all the structure of the information, and all the structure of the information.
2022-03-23 11:59:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:00:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, it's interesting for me, and it's interesting for me, "yes," yes, "yes," well, "if you've been working with you know," if you have a long time, "you've got to say," the best thing, "if you've been working with the best thing,"
2022-03-23 12:00:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:00:06 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still still a mother, and we have to see the design of our work that we had to have to have a big, and if we had to do it, it was to do that if we had to do it, it's to do it, it's to be able to have to see the same thing that if we had to do that if you had to do it's a, it's a huge, it's to see that if it's to be able to have to see the same thing to be able to see that we had to see that if you had to see that we had to see that if you had to see that we had to have to see that we had to see the ground, it's to see that we had to see the ground, it was a big, the same thing that it was a whole whole whole, and you had to see that if you had to see that if you had to see that if you had to see it was a whole, the same thing that it was a
2022-03-23 12:00:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:00:06 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.38 | ppl 1332.45 | bleu 11.57 | wps 4600.9 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 11.57
2022-03-23 12:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 12:00:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:00:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 12 @ 1879 updates, score 11.57) (writing took 1.784282045904547 seconds)
2022-03-23 12:00:08 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:00:08 | INFO | train | epoch 012 | loss 9.346 | ppl 650.79 | wps 39246.7 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.825 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 1243
KL Stats: Epoch 12 Divergences: Uniform: 1.185478404264658 Unigram: 0.826485763267815
2022-03-23 12:00:08 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:00:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:00:16 | INFO | train_inner | epoch 013:     21 / 157 loss=9.36, ppl=657.06, wps=31645.9, ups=1.26, wpb=25090.3, bsz=964, num_updates=1900, lr=0.0002375, gnorm=0.762, loss_scale=4, train_wall=37, gb_free=11.7, wall=1252
2022-03-23 12:00:53 | INFO | train_inner | epoch 013:    121 / 157 loss=9.132, ppl=560.92, wps=67239.8, ups=2.69, wpb=24993.5, bsz=1065.4, num_updates=2000, lr=0.00025, gnorm=0.772, loss_scale=4, train_wall=37, gb_free=11.6, wall=1289
2022-03-23 12:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:01:11 | INFO | fairseq.tasks.translation | example hypothesis: this is not a chemical chemical materials.
2022-03-23 12:01:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:01:15 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, no, you see it, you see the world, you see the world.
2022-03-23 12:01:15 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:01:19 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different weight between, and believe between intelligence, and intelligence and intelligence.
2022-03-23 12:01:19 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:01:23 | INFO | fairseq.tasks.translation | example hypothesis: it's very difficult on japan, in japan, and japan, japan, countries, and the united states, the united states are the united states.
2022-03-23 12:01:23 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:01:27 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, like i'm going to do so so i'm going to put my attention in the other side.
2022-03-23 12:01:27 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:01:31 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer computer, we can imagine the brain of the brain, if it would be a new tool, if it would be a part of the body.
2022-03-23 12:01:31 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:01:35 | INFO | fairseq.tasks.translation | example hypothesis: so it's the impact? we've got from the students from the university of the university, from the university of the university, and the science of our kids are going to go to school.
2022-03-23 12:01:35 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:01:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, if we use the information of this reflection, we can start with a little bit of the traditional traditional materials, and you can start through the whole structure of information, and all the information.
2022-03-23 12:01:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:01:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me, and i'm going to tell you that there's a little bit of women, and then we're going to say, "if you're going to tell you."
2022-03-23 12:01:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:01:43 | INFO | fairseq.tasks.translation | example hypothesis: well, unfortunately, it's still the mother of mother, and the invention of the great work, and we're going to see that if we had to solve a little bit of the ocean, and we had to see it.
2022-03-23 12:01:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:01:43 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.191 | ppl 1169.05 | bleu 13.97 | wps 5081.7 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.97
2022-03-23 12:01:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 12:01:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:01:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.97) (writing took 1.7934731957502663 seconds)
2022-03-23 12:01:45 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:01:45 | INFO | train | epoch 013 | loss 9.143 | ppl 565.47 | wps 40613 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.735 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1341
KL Stats: Epoch 13 Divergences: Uniform: 1.222801425412616 Unigram: 0.8524292439568115
2022-03-23 12:01:45 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:02:10 | INFO | train_inner | epoch 014:     64 / 157 loss=8.914, ppl=482.54, wps=33642, ups=1.3, wpb=25789, bsz=1069.9, num_updates=2100, lr=0.0002625, gnorm=0.707, loss_scale=4, train_wall=37, gb_free=12.1, wall=1366
2022-03-23 12:02:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:02:48 | INFO | fairseq.tasks.translation | example hypothesis: these sunday can't use chemical chemical use.
2022-03-23 12:02:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:02:52 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, they see that they see the world, they see different world.
2022-03-23 12:02:52 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:02:57 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find another weight between weight between weight and intelligence, intelligence and intelligence and intelligence.
2022-03-23 12:02:57 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:03:01 | INFO | fairseq.tasks.translation | example hypothesis: especially very focus on japan, japan, japan and australia, australia, australia, australia, the united states, the united states are the united states.
2022-03-23 12:03:01 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:03:05 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i'm looking at my attention in the other side, in the other side of the other side.
2022-03-23 12:03:05 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:03:09 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer, we can make this new brain, to create this new tool as a new tool, when it would be part of the body, if it would be part of the body.
2022-03-23 12:03:09 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:03:14 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we've got from students from the university of berbery, at stanford, the university of science, and the scientific science of our kids come from our kids.
2022-03-23 12:03:14 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:03:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional traditional face that can start with the traditional face, and we can start able to start with it.
2022-03-23 12:03:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:03:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here at tedtedtedtedtedtedson -- that is that it was the best thing we've been working with you. "
2022-03-23 12:03:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:03:25 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, this is still the mother, the invention of the invention, and a big work that we had to solve on our airplane, that we had to solve a unique way that we had to solve that if we had to solve it in the ground, we had to solve the ground, we had to solve the surface of the ground, and we had to solve the ground, we had to solve the ground, it's a very unique way that it's a very unique system, we had to see that if we had to see that if we had to solve the surface of the surface of the surface of the ground, we had to see that it is that we had to see that it is that we had to see that if we had to see that we had to see that we had to see that if you had to see that if you had to see that we had to see that we had to see that we had to see that we had to see that if you had to see that we had to see that there's a very unique, the ground,
2022-03-23 12:03:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:03:25 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.002 | ppl 1025.64 | bleu 15.57 | wps 4473 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.57
2022-03-23 12:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 12:03:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:03:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.57) (writing took 1.8116859658621252 seconds)
2022-03-23 12:03:27 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:03:27 | INFO | train | epoch 014 | loss 8.981 | ppl 505.25 | wps 38761.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.747 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 1442
KL Stats: Epoch 14 Divergences: Uniform: 1.2541948712366708 Unigram: 0.870325556713716
2022-03-23 12:03:27 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:03:30 | INFO | train_inner | epoch 015:      7 / 157 loss=9.105, ppl=550.53, wps=30581.9, ups=1.25, wpb=24372, bsz=907.3, num_updates=2200, lr=0.000275, gnorm=0.747, loss_scale=4, train_wall=36, gb_free=12.4, wall=1445
2022-03-23 12:04:07 | INFO | train_inner | epoch 015:    107 / 157 loss=8.826, ppl=453.93, wps=66850.7, ups=2.66, wpb=25109.4, bsz=1095.3, num_updates=2300, lr=0.0002875, gnorm=0.72, loss_scale=4, train_wall=37, gb_free=12.8, wall=1483
2022-03-23 12:04:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:04:30 | INFO | fairseq.tasks.translation | example hypothesis: these rocket can't use chemical.
2022-03-23 12:04:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:04:34 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly they see that they see the world.
2022-03-23 12:04:34 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:04:37 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find another weight between balance and uncertainty.
2022-03-23 12:04:37 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:04:41 | INFO | fairseq.tasks.translation | example hypothesis: very focus on japan, japan and australia, australia, australia, australia, the united states are the united states.
2022-03-23 12:04:41 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:04:44 | INFO | fairseq.tasks.translation | example hypothesis: it might also be interested in my attention.
2022-03-23 12:04:44 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:04:48 | INFO | fairseq.tasks.translation | example hypothesis: so, as we can imagine our computer, can make the brain to build this new tool.
2022-03-23 12:04:48 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:04:52 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we've got from the university of berbery, from stanford university, the science institute of science, and the science institute of our children, and the scientific kids come to get a lot of scientific experiments.
2022-03-23 12:04:52 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:04:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of these reflection, we can start with a traditional face of traditional face, and we can start able to start able to start the face of the face of the face of the face of the face, and there's a real shape.
2022-03-23 12:04:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:05:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting for me to be here. "
2022-03-23 12:05:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:05:01 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big work that we're going to see in our airplane was the plane that we had to solve a result that we had to solve the result that we had to solve it.
2022-03-23 12:05:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:05:01 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.929 | ppl 975.12 | bleu 11.86 | wps 5351.2 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 15.57
2022-03-23 12:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 12:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:05:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:05:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 15 @ 2350 updates, score 11.86) (writing took 0.7760335220955312 seconds)
2022-03-23 12:05:01 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:05:01 | INFO | train | epoch 015 | loss 8.814 | ppl 450.11 | wps 41716.1 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.703 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 1537
KL Stats: Epoch 15 Divergences: Uniform: 1.2882513882854487 Unigram: 0.8911541572409583
2022-03-23 12:05:02 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:05:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:21 | INFO | train_inner | epoch 016:     50 / 157 loss=8.612, ppl=391.16, wps=35188.9, ups=1.36, wpb=25944, bsz=1069.2, num_updates=2400, lr=0.0003, gnorm=0.658, loss_scale=4, train_wall=37, gb_free=12.2, wall=1557
2022-03-23 12:05:58 | INFO | train_inner | epoch 016:    150 / 157 loss=8.82, ppl=451.89, wps=66310.9, ups=2.71, wpb=24484.4, bsz=910, num_updates=2500, lr=0.0003125, gnorm=0.689, loss_scale=4, train_wall=37, gb_free=12.9, wall=1594
2022-03-23 12:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example hypothesis: these sunday can't use chemical chemical rations.
2022-03-23 12:06:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without all, you see it, you see the world, you see the different world.
2022-03-23 12:06:09 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:06:14 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between balance and unconscious intelligence, intelligence, intelligence and intelligence.
2022-03-23 12:06:14 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:06:18 | INFO | fairseq.tasks.translation | example hypothesis: especially focus on japan and australia, australia, australia, the countries, the united states, the united states are the united states.
2022-03-23 12:06:18 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:06:22 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, as i'm focused on my attention, so i'm focused on the other side.
2022-03-23 12:06:22 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:06:27 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can imagine our computer computer, can make the brains to form this new tool when it would be part of the body.
2022-03-23 12:06:27 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:06:31 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we've got students from the class of bery, at stanford institute, from the indian science institute, and the scientific experiments, and the scientific experiments that are going to go to the normal experiments that we have?
2022-03-23 12:06:31 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:06:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face of the face of the face, and we can start able to do it through the real shape of the information, and the whole structure of the information, and the whole structure of the information, and all of the information that we use a whole structure, and the information that all of these reflection of these reflection of these reflection of these reflect
2022-03-23 12:06:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:06:42 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons it's interesting, and it's interesting for me to be here in tedtedwomen, that it was the best one of them, "and when someone said," and if we're working with them, "and then we're working on the truth," and then we're working on this, "and then," and then, "and then we're going to do it's going to do it," well, "well," well, "well," well, "and then we have a long time we're going to do it starts to do it starts to do it starts to do it starts to do it," and then we've been working with you know, "and then," and then, "and then," and then, "and then we've been working on this," and then, "and then," and
2022-03-23 12:06:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:06:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, need to be the mother of the invention, and a big design design of design, we have to solve it in our plane, and we had to solve the unique problems that we had to be connected to the ground, and it's still connected to the ground, and if you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see it with the surface, and make it with the surface of a, and the surface of a, and the surface of a, and the surface of a, and the surface of the surface of a
2022-03-23 12:06:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:06:45 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.817 | ppl 901.96 | bleu 16.04 | wps 4106 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.04
2022-03-23 12:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 12:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:06:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 16 @ 2507 updates, score 16.04) (writing took 1.8608362190425396 seconds)
2022-03-23 12:06:47 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:06:47 | INFO | train | epoch 016 | loss 8.673 | ppl 408.09 | wps 37561.7 | ups 1.49 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.69 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1642
KL Stats: Epoch 16 Divergences: Uniform: 1.3218855460921553 Unigram: 0.9072010297258293
2022-03-23 12:06:47 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:06:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:07:22 | INFO | train_inner | epoch 017:     93 / 157 loss=8.576, ppl=381.7, wps=29814.3, ups=1.19, wpb=25136.7, bsz=1023.9, num_updates=2600, lr=0.000325, gnorm=0.663, loss_scale=4, train_wall=37, gb_free=12.5, wall=1678
2022-03-23 12:07:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rocket.
2022-03-23 12:07:50 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:07:54 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without that you see it, you see the world differently.
2022-03-23 12:07:54 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:07:58 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe between faith, and unconscious instinct intelligence and intelligence.
2022-03-23 12:07:58 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:08:02 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea, and australia, australia, countries, the united states, which are the united states.
2022-03-23 12:08:02 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:08:06 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, as i'm focused on my attention in the other side.
2022-03-23 12:08:06 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:08:10 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can imagine our computers, the brain is to form this new tool to form when it would be part of the body.
2022-03-23 12:08:10 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:08:15 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from professors, from berbery, from the indian science institute, from the indian science institute, and the children come to our scientific scientific experiments.
2022-03-23 12:08:15 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:08:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of these reflection reflection, we can start with a traditional face of traditional face, which is the big face of the face of the face and reform it through that information, and the whole structure.
2022-03-23 12:08:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:08:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here in tedtedwomen, that... yes... yeah, that's the best thing that somebody said, "when the men begins on a table," and then we've been working on the table, "and then we have a long time for you know," and then we've been working on this time, "and then we've been working on this time,"
2022-03-23 12:08:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:08:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and one part of the design work that we're on our airplane was a result that we had to solve the problems that we had to solve with the ground, to be connected to the ground, to the surface of an aircraft, if you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 12:08:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:08:26 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.613 | ppl 782.87 | bleu 20.01 | wps 4569.3 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 20.01
2022-03-23 12:08:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 12:08:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:08:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 17 @ 2664 updates, score 20.01) (writing took 1.859166722279042 seconds)
2022-03-23 12:08:28 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:08:28 | INFO | train | epoch 017 | loss 8.534 | ppl 370.56 | wps 39007.6 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.63 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 1743
KL Stats: Epoch 17 Divergences: Uniform: 1.3447972230269436 Unigram: 0.9228034667472428
2022-03-23 12:08:28 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:08:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:08:42 | INFO | train_inner | epoch 018:     36 / 157 loss=8.516, ppl=366.17, wps=31494.3, ups=1.25, wpb=25105.8, bsz=998.2, num_updates=2700, lr=0.0003375, gnorm=0.609, loss_scale=4, train_wall=37, gb_free=11.9, wall=1758
2022-03-23 12:09:20 | INFO | train_inner | epoch 018:    136 / 157 loss=8.357, ppl=327.83, wps=67232.9, ups=2.66, wpb=25301.2, bsz=1070.7, num_updates=2800, lr=0.00035, gnorm=0.587, loss_scale=4, train_wall=37, gb_free=13, wall=1795
2022-03-23 12:09:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:09:31 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rocket.
2022-03-23 12:09:31 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:09:35 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly without that you see it, you see the world differently.
2022-03-23 12:09:35 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:09:39 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between faith, and unconscious instincts and intelligence.
2022-03-23 12:09:39 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:09:43 | INFO | fairseq.tasks.translation | example hypothesis: especially focus on japan, australia, australia and australia, australia, countries, the endangered united states.
2022-03-23 12:09:43 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:09:47 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention in the circuits side of the other side.
2022-03-23 12:09:47 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:09:51 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can reform our computer, the brains to form this new tool when it would be part of the body.
2022-03-23 12:09:51 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:09:55 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berkeley, stanford institute institute of indian science institute, and our kids have a lot of scientific experiments that are going to go to normal school?
2022-03-23 12:09:55 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:10:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face of the face of the face of the face and the real face of this information, all the information, and we can fold it through the information, all of these reflection reflection, and all of these reflection reflection of these reflection reflection reflection, we can make a traditional facial structure, and all of these reflection, and
2022-03-23 12:10:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:10:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me, for tedwomen, "] ["] ["] ["] ["] ["] ["] [" somebody said, "the best reasons," somebody said, "the men '"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 12:10:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:10:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work on our airplane, if we were a unique result that we had to solve the problems that was still connected to the ground -- it was still connected to the ground -- and it's all over the ground, and it's all over the ground, and it's a very large part of the refrifrifrifrifrightening, or a refrifrifrifrightening, or a refrifrifrifrifrightening, or a refrifrightening system, or if you can see that if you're either, you're either, you're either, you're either in the refrifrightened to see that you're either, you're either in the refrifrightening, you're not to see that you're either in the refrifrightening, you're either in the refrightening, you're either in the refrightened to see that you're going to see,
2022-03-23 12:10:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:10:08 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.614 | ppl 783.73 | bleu 20.27 | wps 4393.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.27
2022-03-23 12:10:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 12:10:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:10:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:10:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.27) (writing took 1.7820912720635533 seconds)
2022-03-23 12:10:10 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:10:10 | INFO | train | epoch 018 | loss 8.396 | ppl 336.79 | wps 38644.6 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.6 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 1846
KL Stats: Epoch 18 Divergences: Uniform: 1.3653872090029107 Unigram: 0.9385854972684963
2022-03-23 12:10:10 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:10:41 | INFO | train_inner | epoch 019:     79 / 157 loss=8.239, ppl=302.05, wps=31552.4, ups=1.24, wpb=25544.4, bsz=989.9, num_updates=2900, lr=0.0003625, gnorm=0.557, loss_scale=4, train_wall=37, gb_free=11.7, wall=1876
2022-03-23 12:11:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:11:13 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rocket.
2022-03-23 12:11:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:11:17 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you see it, you see the world different.
2022-03-23 12:11:17 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:11:21 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between believe between believe and real instinct, instinct and intelligence.
2022-03-23 12:11:21 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:11:25 | INFO | fairseq.tasks.translation | example hypothesis: very focused on japan, korea and australia, australia, australia, countries that are very focused on the united states.
2022-03-23 12:11:25 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:11:30 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me as i'm focused on, so i'm focused on my attention level in the circulation of the circuit on the other side.
2022-03-23 12:11:30 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:11:34 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can reconstruct our computers, the brains of this new tool to form as a part of the primate.
2022-03-23 12:11:34 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:11:38 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berkeley, stanford, stanford from the indian science institute that come and bring our kids a lot of scientific experiments to normal education.
2022-03-23 12:11:38 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:11:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial face, the big constructions of the face of the face and the real shape of the face of the information, which is all the whole structure and the whole structure.
2022-03-23 12:11:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:11:48 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting and measure it interesting for me to be here at tedwomen here in tedwomen, is that... yes... when somebody said, "the best thing," somebody said, "the men who said," the table and they say, "when they're working on a table," if we're working on a table and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be here in
2022-03-23 12:11:48 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:11:50 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention of invention, and a big part of design work on our plane, was a result that we had to solve the unique problems that were connected to the ground -- all the way on the ground, and it's all the way to be connected to a huge level of design design work, and a big part of the design design of the design of the design work that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 12:11:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:11:50 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.473 | ppl 710.73 | bleu 22.84 | wps 4403.2 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 22.84
2022-03-23 12:11:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 12:11:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:11:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:11:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 19 @ 2978 updates, score 22.84) (writing took 1.9410915961489081 seconds)
2022-03-23 12:11:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:11:52 | INFO | train | epoch 019 | loss 8.265 | ppl 307.69 | wps 38673.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.551 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 1948
KL Stats: Epoch 19 Divergences: Uniform: 1.3808759080779522 Unigram: 0.9504303812479686
2022-03-23 12:11:53 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:11:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:12:01 | INFO | train_inner | epoch 020:     22 / 157 loss=8.267, ppl=308.08, wps=30586.9, ups=1.24, wpb=24602.2, bsz=1016.5, num_updates=3000, lr=0.000375, gnorm=0.591, loss_scale=4, train_wall=36, gb_free=12, wall=1957
2022-03-23 12:12:39 | INFO | train_inner | epoch 020:    122 / 157 loss=8.111, ppl=276.42, wps=67916.9, ups=2.64, wpb=25699.2, bsz=1067.5, num_updates=3100, lr=0.0003875, gnorm=0.528, loss_scale=4, train_wall=37, gb_free=12.4, wall=1994
2022-03-23 12:12:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:12:55 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rocket.
2022-03-23 12:12:55 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:12:59 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 12:12:59 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:13:03 | INFO | fairseq.tasks.translation | example hypothesis: but each musicians find a different balance between beliefs and reason, instinct and intelligence.
2022-03-23 12:13:03 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:13:07 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are connected to the united states.
2022-03-23 12:13:07 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:13:12 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me how i'm focused, so i can wear my attention degrees in the circuit on the other side.
2022-03-23 12:13:12 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:13:16 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can reconstruct our computers, the brain activity is to form this new tool as it would be part of the primates.
2022-03-23 12:13:16 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:13:20 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact?
2022-03-23 12:13:20 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:13:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection reflection, we can start with a traditional facial face that can start with the big constructions of the facial and reform the basic shape of the face, and restores it through that one of the information that makes it all the
2022-03-23 12:13:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:13:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to be interesting and measure for me to be here in tedwomen, is that...
2022-03-23 12:13:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:13:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention of invention, and a big part of design work that we're at the aircraft, was a result that we had to solve the unique problems that were connected to the ground -- all the variation system, if you're able to use it.
2022-03-23 12:13:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:13:31 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.384 | ppl 668.17 | bleu 22.42 | wps 4600.8 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.84
2022-03-23 12:13:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 12:13:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 20 @ 3135 updates, score 22.42) (writing took 0.7592377788387239 seconds)
2022-03-23 12:13:32 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:13:32 | INFO | train | epoch 020 | loss 8.18 | ppl 290.12 | wps 39661.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.572 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 2047
KL Stats: Epoch 20 Divergences: Uniform: 1.3910858840216027 Unigram: 0.9565209099781611
2022-03-23 12:13:32 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:13:57 | INFO | train_inner | epoch 021:     65 / 157 loss=8.256, ppl=305.64, wps=31621.8, ups=1.28, wpb=24609.9, bsz=972.3, num_updates=3200, lr=0.0004, gnorm=0.561, loss_scale=4, train_wall=36, gb_free=12.6, wall=2072
2022-03-23 12:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:14:35 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 12:14:35 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:14:39 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without them, you see the world different.
2022-03-23 12:14:39 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:14:42 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between faith and reason, instincts and intelligence.
2022-03-23 12:14:42 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:14:46 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries who are connected to the united states.
2022-03-23 12:14:46 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:14:50 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me as concentrating, so i can carry my attention degree in the circuit on the other side.
2022-03-23 12:14:50 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:14:54 | INFO | fairseq.tasks.translation | example hypothesis: so, as quickly as we can restore our computer, the brain activity is to form this new tool, when it was a body part of the primates.
2022-03-23 12:14:54 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:14:58 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from indian science institute, who come from and bring our children to normal forms.
2022-03-23 12:14:58 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:15:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big constructions of the face and the basic shape of the face of the face of the face and restoring it through this.
2022-03-23 12:15:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measures me here at tedwomen is that...
2022-03-23 12:15:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're in the plane, was a result of it that we had to solve the unique problems that were connected to it, and it's connected to the ground -- all of the way to a refrigeration, and if you're in the ground, or if you're able to see the refrigeration of an aircraft.
2022-03-23 12:15:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:08 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.298 | ppl 629.34 | bleu 23.95 | wps 4988.2 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.95
2022-03-23 12:15:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 12:15:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:15:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 21 @ 3292 updates, score 23.95) (writing took 1.7393768052570522 seconds)
2022-03-23 12:15:09 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:15:09 | INFO | train | epoch 021 | loss 8.098 | ppl 273.95 | wps 40406.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.529 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2145
KL Stats: Epoch 21 Divergences: Uniform: 1.4018102015619904 Unigram: 0.9635690854384257
2022-03-23 12:15:10 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:15:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:15:13 | INFO | train_inner | epoch 022:      8 / 157 loss=8.057, ppl=266.3, wps=33067.1, ups=1.31, wpb=25247.4, bsz=1007.4, num_updates=3300, lr=0.0004125, gnorm=0.528, loss_scale=4, train_wall=37, gb_free=12.4, wall=2149
2022-03-23 12:15:51 | INFO | train_inner | epoch 022:    108 / 157 loss=7.896, ppl=238.19, wps=68370.5, ups=2.64, wpb=25856.5, bsz=1029.7, num_updates=3400, lr=0.000425, gnorm=0.453, loss_scale=4, train_wall=37, gb_free=12.3, wall=2186
2022-03-23 12:16:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:16:12 | INFO | fairseq.tasks.translation | example hypothesis: this sunk can't use chemical rockets.
2022-03-23 12:16:12 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:16:16 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world different.
2022-03-23 12:16:16 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:16:20 | INFO | fairseq.tasks.translation | example hypothesis: but each musicians find a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:16:20 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:16:24 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries, the endangered of the united states.
2022-03-23 12:16:24 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:16:28 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so that i can carry my attention degree in the circuit on the other side.
2022-03-23 12:16:28 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:16:32 | INFO | fairseq.tasks.translation | example hypothesis: so as quickly as we can restore our computer, the brain needles to form this new tool when it was a body part of the primates.
2022-03-23 12:16:32 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:16:37 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 12:16:37 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:16:42 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from these reflection reflection, we can start with a traditional facial face, the big constructions of the face and the basic shape of the face of the real face, and reform the basic shape of the real shape, and through it, and through it, which is the whole information that all the porting the ports and a structure.
2022-03-23 12:16:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:16:47 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that somebody said, "turn it up and say," if we start to be here in tedwomen, is that -- that... tweaker, in the best way, when somebody said, "turn you to the men on a table and say," turn it up to the men and tell you, "and when the revolution starts to support me."
2022-03-23 12:16:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:16:49 | INFO | fairseq.tasks.translation | example hypothesis: luckily, a result of solving problems that were connected to the ground, and a big part of the design work that we use in our plane is a result that we had to solve the unique problems that were connected to it -- it was connected to the ground -- everything from a continuous variation, and a huge variation, and a lot of design system, and a refrigering system that allows us to the aircraft, and if you use it to see that if you use it, and you're either the refrightening, and you're able to see that if you're able to do it in the refrightening the aircraft, and you're able to do it, and you're able to see it in the refrightening it, and you're able to see it, and you're able to go out of a refrightening it, and you're able to see it, and you're able to see it, and you're able to do it, it, it
2022-03-23 12:16:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:16:49 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.259 | ppl 612.79 | bleu 25.26 | wps 4474.8 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 25.26
2022-03-23 12:16:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 12:16:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:16:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:16:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 22 @ 3449 updates, score 25.26) (writing took 1.8435333068482578 seconds)
2022-03-23 12:16:51 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:16:51 | INFO | train | epoch 022 | loss 7.996 | ppl 255.24 | wps 38901.6 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.49 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2247
KL Stats: Epoch 22 Divergences: Uniform: 1.4054279946802597 Unigram: 0.9707151416838506
2022-03-23 12:16:51 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:16:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:11 | INFO | train_inner | epoch 023:     51 / 157 loss=8.117, ppl=277.6, wps=30476.3, ups=1.25, wpb=24328.4, bsz=1036.3, num_updates=3500, lr=0.0004375, gnorm=0.515, loss_scale=4, train_wall=36, gb_free=12.1, wall=2266
2022-03-23 12:17:48 | INFO | train_inner | epoch 023:    151 / 157 loss=7.888, ppl=236.92, wps=67840.3, ups=2.7, wpb=25147.8, bsz=992, num_updates=3600, lr=0.00045, gnorm=0.448, loss_scale=4, train_wall=37, gb_free=12.1, wall=2303
2022-03-23 12:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:17:54 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:17:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:17:58 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 12:17:58 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:18:02 | INFO | fairseq.tasks.translation | example hypothesis: but every musicians find a different balance between belief and reason, instinct and intelligence.
2022-03-23 12:18:02 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:18:05 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries, the endangered of the united states.
2022-03-23 12:18:05 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:18:09 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how focused i'm, so i can carry my attention degree in the circuit on the other side.
2022-03-23 12:18:09 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:18:13 | INFO | fairseq.tasks.translation | example hypothesis: so as quickly as we can restore our computer, the brain activity to form this new tool as if it was a body part of primates.
2022-03-23 12:18:13 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:18:17 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we've got professors from, from berkeley, stanford, from indian science institute that come and bring our kids to a lot of scientific formers, experiments that go beyond normal education.
2022-03-23 12:18:17 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:18:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face that gives the big concrete of the face and the basic shape, and refits it through this one of the information, which is the whole ports and all the shape.
2022-03-23 12:18:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:18:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here at tedwomen is that... tyes, when... tacky dinner was the best thing when someone said, "turn on the men on a table and say," if the revolution starts to support you. "
2022-03-23 12:18:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:18:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on the plane was a result of it that we had to solve the unique problems that were connected to the ground -- all of the continuous variation and refrigered to a refrigeration system, or the refrigeration system.
2022-03-23 12:18:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:18:27 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.158 | ppl 571.09 | bleu 26.95 | wps 4902.9 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.95
2022-03-23 12:18:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 12:18:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:18:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.95) (writing took 1.7957888301461935 seconds)
2022-03-23 12:18:29 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:18:29 | INFO | train | epoch 023 | loss 7.923 | ppl 242.62 | wps 40296 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.451 | loss_scale 4 | train_wall 58 | gb_free 12.5 | wall 2345
KL Stats: Epoch 23 Divergences: Uniform: 1.41125273587358 Unigram: 0.9770356584891384
2022-03-23 12:18:29 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:05 | INFO | train_inner | epoch 024:     94 / 157 loss=7.813, ppl=224.92, wps=32950.3, ups=1.3, wpb=25359.4, bsz=1073.3, num_updates=3700, lr=0.0004625, gnorm=0.467, loss_scale=4, train_wall=37, gb_free=12.2, wall=2380
2022-03-23 12:19:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:19:32 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:19:32 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:19:36 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly without you realize the world differently.
2022-03-23 12:19:36 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:19:40 | INFO | fairseq.tasks.translation | example hypothesis: but everybody musicians find another balance between faith and reason, instinct and intelligence.
2022-03-23 12:19:40 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:19:43 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are the united states.
2022-03-23 12:19:43 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:19:48 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me as focused as i am, so i can carry my attention degrees in the circuit on the other side.
2022-03-23 12:19:48 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:19:51 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers.
2022-03-23 12:19:51 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:19:55 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from berkeley, stanford from indian science institute that come and teach our children a lot of scientific formula experiments that go far beyond normal education.
2022-03-23 12:19:55 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:19:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face and the basic shape of the face and the basic shape, which is the whole portion.
2022-03-23 12:19:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be interesting and measured for me here at tedwomen is that... tyes, when somebody said, "turn on men to a table," and say, "if the revolution begins to support you."
2022-03-23 12:20:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a huge part of design work that we're at our plane at the stest, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use a car car, or if you can see the same thing.
2022-03-23 12:20:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:03 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.21 | ppl 592.21 | bleu 24.07 | wps 5294.1 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.95
2022-03-23 12:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 12:20:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 24 @ 3763 updates, score 24.07) (writing took 0.8208111790008843 seconds)
2022-03-23 12:20:04 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:20:04 | INFO | train | epoch 024 | loss 7.868 | ppl 233.68 | wps 41543 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.464 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 2440
KL Stats: Epoch 24 Divergences: Uniform: 1.411684136847323 Unigram: 0.9813002447197843
2022-03-23 12:20:04 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:20:19 | INFO | train_inner | epoch 025:     37 / 157 loss=7.84, ppl=229.07, wps=34193.5, ups=1.35, wpb=25260, bsz=1026.2, num_updates=3800, lr=0.000475, gnorm=0.448, loss_scale=4, train_wall=37, gb_free=12.9, wall=2454
2022-03-23 12:20:56 | INFO | train_inner | epoch 025:    137 / 157 loss=7.798, ppl=222.61, wps=67093.2, ups=2.65, wpb=25303.9, bsz=1010.7, num_updates=3900, lr=0.0004875, gnorm=0.455, loss_scale=4, train_wall=37, gb_free=12.1, wall=2492
2022-03-23 12:21:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:21:07 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:21:07 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:21:11 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world different.
2022-03-23 12:21:11 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:21:15 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instincts and intelligence.
2022-03-23 12:21:15 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:21:19 | INFO | fairseq.tasks.translation | example hypothesis: it's especially focused on japan, korea and australia, countries that are encountered in the united states.
2022-03-23 12:21:19 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:21:23 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me, as i'm focused on, so i can carry my attention degrees in the circuit on the other side.
2022-03-23 12:21:23 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:21:27 | INFO | fairseq.tasks.translation | example hypothesis: so as quickly as we can restore our computers, we can restore the brain activity to form this new tool as if it was a body part of the primates.
2022-03-23 12:21:27 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:21:31 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formulates, experiments that go far beyond normal class.
2022-03-23 12:21:31 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:21:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face that gives the big configuration of the face and the basic form of information that pulls the whole porting structure and all the folds.
2022-03-23 12:21:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:21:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are highly interesting and measuring it: "if the revolution begins to be here at tedwomen," the truth is that... tyes, when someone said, "turn to the men on your table and say," if the revolution begins to support you, "the truth is that women, we've been supporting you is that we've been supporting you," the truth is that women, "well," well, we've already been in this is a long time, "well, we've been supported with stone"
2022-03-23 12:21:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:21:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on the plane was a result that we had to solve the unique problems that were connected to operate on the ground -- all of a continuous variation and refrigeration system that allows us to use is that we're using a liquid, which is that it allows us to use to use a plane on the aircraft to move, and that we're using a special, and that we can use it to move to move to the most vulnerable to the aircraft, or a special.
2022-03-23 12:21:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:21:42 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.057 | ppl 532.53 | bleu 28.4 | wps 4668.2 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.4
2022-03-23 12:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 12:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:21:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.4) (writing took 1.8319510696455836 seconds)
2022-03-23 12:21:44 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:21:44 | INFO | train | epoch 025 | loss 7.809 | ppl 224.27 | wps 39484.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.443 | loss_scale 4 | train_wall 58 | gb_free 12.4 | wall 2540
KL Stats: Epoch 25 Divergences: Uniform: 1.4152177009766655 Unigram: 0.9832989925862027
2022-03-23 12:21:44 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:22:15 | INFO | train_inner | epoch 026:     80 / 157 loss=7.781, ppl=220.01, wps=31399.3, ups=1.27, wpb=24652.2, bsz=1026.6, num_updates=4000, lr=0.0005, gnorm=0.385, loss_scale=4, train_wall=36, gb_free=19.6, wall=2570
2022-03-23 12:22:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:22:48 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:22:48 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:22:52 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly without you notice it, you see the world different.
2022-03-23 12:22:52 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:22:56 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:22:56 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:23:00 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are the enabled of the united states.
2022-03-23 12:23:00 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:23:04 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how concentrate i am, so i can carry my attention level in the board on the other side.
2022-03-23 12:23:04 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:23:08 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can restore our computer, the brain activity would restore this new tool as if it was a body part of the primate.
2022-03-23 12:23:08 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:23:12 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific forms, experiments that go far beyond normal class.
2022-03-23 12:23:12 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:23:16 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face that repeats the big configuration of the face and the basic shape, and pulls it through the whole porting structure and all the folds.
2022-03-23 12:23:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:23:21 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured for me to be here at tedwomen is that -- tyes, when someone said, "turn you to the men on your table, and tell you," if the revolution begins to support you. "'"' "the truth is that we've already been supporting you."
2022-03-23 12:23:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:23:22 | INFO | fairseq.tasks.translation | example hypothesis: luckckily, the mother of invention, and a large part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to see in the ground until you to see that it is either a refrigerator to the ground, or if you're going to see the mechanism.
2022-03-23 12:23:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:23:22 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.064 | ppl 535.15 | bleu 28.39 | wps 4850.6 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.4
2022-03-23 12:23:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 12:23:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:23:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:23:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 26 @ 4077 updates, score 28.39) (writing took 0.8108555763028562 seconds)
2022-03-23 12:23:23 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:23:23 | INFO | train | epoch 026 | loss 7.745 | ppl 214.54 | wps 39968.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.406 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 2638
KL Stats: Epoch 26 Divergences: Uniform: 1.4184744572475427 Unigram: 0.9910015099528101
2022-03-23 12:23:23 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:23:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:23:32 | INFO | train_inner | epoch 027:     23 / 157 loss=7.829, ppl=227.38, wps=32450.4, ups=1.3, wpb=25007.4, bsz=1000.1, num_updates=4100, lr=0.000493865, gnorm=0.427, loss_scale=4, train_wall=37, gb_free=11.9, wall=2648
2022-03-23 12:24:09 | INFO | train_inner | epoch 027:    123 / 157 loss=7.731, ppl=212.49, wps=66873.3, ups=2.68, wpb=24952.8, bsz=975.6, num_updates=4200, lr=0.00048795, gnorm=0.432, loss_scale=4, train_wall=37, gb_free=12.2, wall=2685
2022-03-23 12:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:24:26 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:24:26 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:24:29 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world different.
2022-03-23 12:24:29 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:24:34 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:24:34 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:24:37 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are enconnected in the united states.
2022-03-23 12:24:37 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:24:41 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention degree in the circuit on the other side.
2022-03-23 12:24:41 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:24:45 | INFO | fairseq.tasks.translation | example hypothesis: so as fast as we can restore our computer, the brain activity is shifting to form this new tool as if it was a body part of the primate.
2022-03-23 12:24:45 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:24:49 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific formers, experiments that go far beyond normal education.
2022-03-23 12:24:49 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:24:54 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big configuration of the face and the basic form, and gives it through that one of the single information that makes the whole porter structure and all the folds a fold.
2022-03-23 12:24:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured to me here at tedwomen is that -- tyes, when dinner was made best summarized when someone said, "turn to the men in dtable and say," if the revolution begins to support you. '' '' if the revolution begins, we support them. '' 'the truth is that we've already started to support you. "
2022-03-23 12:24:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we are at our plane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigeration system that allows us to be a refrigerator to be a refrigerator and a refrigerator to a refrigeration of fluid system that is either if you can see the ground.
2022-03-23 12:25:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:01 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.987 | ppl 507.3 | bleu 29.67 | wps 4684 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.67
2022-03-23 12:25:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 12:25:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:25:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:25:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 27 @ 4234 updates, score 29.67) (writing took 1.795444202143699 seconds)
2022-03-23 12:25:02 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:25:02 | INFO | train | epoch 027 | loss 7.708 | ppl 209.07 | wps 39684.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.416 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 2738
KL Stats: Epoch 27 Divergences: Uniform: 1.4192155842252785 Unigram: 0.9901103061272852
2022-03-23 12:25:03 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:25:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:25:27 | INFO | train_inner | epoch 028:     66 / 157 loss=7.567, ppl=189.66, wps=32561.1, ups=1.28, wpb=25425.4, bsz=1071.8, num_updates=4300, lr=0.000482243, gnorm=0.393, loss_scale=4, train_wall=37, gb_free=12.7, wall=2763
2022-03-23 12:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:06 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:26:06 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:26:09 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 12:26:09 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:26:13 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instincts and intelligence.
2022-03-23 12:26:13 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:26:17 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are the encounters of the united states.
2022-03-23 12:26:17 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:26:21 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can carry my attention degrees in the circuit on the other side.
2022-03-23 12:26:21 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:26:25 | INFO | fairseq.tasks.translation | example hypothesis: so, as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of primate.
2022-03-23 12:26:25 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:26:29 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 12:26:29 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:26:34 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that refers the big configuration of the face and the basic shape, and refits it through this single information that refits all the porting structure and all the fits a fold.
2022-03-23 12:26:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:26:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons to be highly interesting and measured for me to be here at tedwomen is that... tyes, with stripped dinner, it was best summarized when someone said, "turn to men on your table and tell them," if the revolution starts to support you. "the truth is that we've already been supporting you with this topic for a long time."
2022-03-23 12:26:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:26:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane is a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuous variation and a refrigeration system that allows us to use a goliar, or if you look at a mechanism, either, if you're going to be able to use the ground.
2022-03-23 12:26:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:26:39 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.939 | ppl 490.86 | bleu 30.25 | wps 4865.5 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.25
2022-03-23 12:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 12:26:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:26:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:26:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.25) (writing took 1.7567981998436153 seconds)
2022-03-23 12:26:41 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:26:41 | INFO | train | epoch 028 | loss 7.645 | ppl 200.18 | wps 40007.2 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.376 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 2837
KL Stats: Epoch 28 Divergences: Uniform: 1.4183053271168018 Unigram: 0.9948979341540354
2022-03-23 12:26:41 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:26:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:26:45 | INFO | train_inner | epoch 029:      9 / 157 loss=7.615, ppl=195.99, wps=32681.4, ups=1.29, wpb=25343.1, bsz=984.4, num_updates=4400, lr=0.000476731, gnorm=0.36, loss_scale=4, train_wall=37, gb_free=11.9, wall=2840
2022-03-23 12:27:22 | INFO | train_inner | epoch 029:    109 / 157 loss=7.653, ppl=201.21, wps=66725.8, ups=2.67, wpb=24969.6, bsz=1032.4, num_updates=4500, lr=0.000471405, gnorm=0.364, loss_scale=4, train_wall=37, gb_free=12.9, wall=2878
2022-03-23 12:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:27:44 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:27:44 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:27:48 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world different.
2022-03-23 12:27:48 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:27:52 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instincts and intelligence.
2022-03-23 12:27:52 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:27:56 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are the enabled of the united states.
2022-03-23 12:27:56 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:28:00 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrating i am, so i can carry my attention degree in the board on the other side.
2022-03-23 12:28:00 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:28:04 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity is restored to form this new tool as if it was a body part of the primate.
2022-03-23 12:28:04 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:28:08 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific forms, experiments that go far beyond normal class.
2022-03-23 12:28:08 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:28:12 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the big configurations of the face and the basic shape, and it's through the one information that pulls the entire portion structure and all the fits.
2022-03-23 12:28:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:28:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me to be here at tedwomen is that... tyes, when dinner was best summarized when someone said, "turn to the men at your table and say," if the revolution starts to support you, "the truth is that we've already started to support you with this theme of the long time of stone carchart."
2022-03-23 12:28:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:28:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operate it on the ground -- all, from a continuous variation and a refrigeration system that allows us to use the aircraft to either be able to move the ground to the security, to see it, if you can see it, to see that if you're going to the ground.
2022-03-23 12:28:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:28:19 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.891 | ppl 474.81 | bleu 30.92 | wps 4727.6 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.92
2022-03-23 12:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 12:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:28:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.92) (writing took 1.8156101531349123 seconds)
2022-03-23 12:28:20 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:28:20 | INFO | train | epoch 029 | loss 7.599 | ppl 193.82 | wps 39732.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.361 | loss_scale 4 | train_wall 58 | gb_free 11.6 | wall 2936
KL Stats: Epoch 29 Divergences: Uniform: 1.4180256074399098 Unigram: 0.9959160001611097
2022-03-23 12:28:21 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:28:40 | INFO | train_inner | epoch 030:     52 / 157 loss=7.544, ppl=186.67, wps=32579.5, ups=1.28, wpb=25459.7, bsz=1003, num_updates=4600, lr=0.000466252, gnorm=0.355, loss_scale=4, train_wall=37, gb_free=12.8, wall=2956
2022-03-23 12:29:18 | INFO | train_inner | epoch 030:    152 / 157 loss=7.589, ppl=192.59, wps=67444, ups=2.69, wpb=25116.1, bsz=1053.4, num_updates=4700, lr=0.000461266, gnorm=0.381, loss_scale=4, train_wall=37, gb_free=11.9, wall=2993
2022-03-23 12:29:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:29:23 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:29:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:29:27 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world different.
2022-03-23 12:29:27 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:29:32 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another balance between faith and reason, instinct and intelligence.
2022-03-23 12:29:32 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:29:35 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are enabled of the united states.
2022-03-23 12:29:35 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:29:40 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how concentrate i am, so i can carry my attention degree in the circuit board on the other side.
2022-03-23 12:29:40 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:29:43 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:29:43 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:29:48 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our kids a lot of scientific formules, experiments that go far beyond normal class.
2022-03-23 12:29:48 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:29:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big conversations of the face and gives it the basic shape, and refuses it through the one information that pulls the entire portion structure and all the fits.
2022-03-23 12:29:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:29:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and appropriate for me to be here at tedwomen is that... tyes, when dinner dinner was best summarized when somebody said, "turn to the men in your table and tell them," 'if the revolution begins to support you.' "'"' the truth is that we've already started to support you for a long time. "
2022-03-23 12:29:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:29:58 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still still the mother of invention, and a big part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything that drives from a continuous variation and a refrigeration system that allows us to use aircraft at the most stare in the ground until you can see it is either when you're working on the ground.
2022-03-23 12:29:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:29:58 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.888 | ppl 473.74 | bleu 31.31 | wps 4732.2 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.31
2022-03-23 12:29:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 12:29:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:29:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.31) (writing took 1.8049485799856484 seconds)
2022-03-23 12:30:00 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:30:00 | INFO | train | epoch 030 | loss 7.576 | ppl 190.82 | wps 39758.9 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.375 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3035
KL Stats: Epoch 30 Divergences: Uniform: 1.4186909653630102 Unigram: 0.9981400155050768
2022-03-23 12:30:00 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:30:36 | INFO | train_inner | epoch 031:     95 / 157 loss=7.519, ppl=183.36, wps=32282.9, ups=1.28, wpb=25253.7, bsz=993, num_updates=4800, lr=0.000456435, gnorm=0.369, loss_scale=4, train_wall=37, gb_free=11.7, wall=3072
2022-03-23 12:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:03 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:31:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:31:07 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you notice it, you see the world different.
2022-03-23 12:31:07 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:31:11 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:31:11 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:31:14 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are closely connected to the united states.
2022-03-23 12:31:14 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:31:18 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in how i'm focused, so i can carry my attention level in the board on the other side.
2022-03-23 12:31:18 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:31:22 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:31:22 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:31:26 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 12:31:26 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:31:31 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big configurations of the face and the basic shape, and encounters it through the one that refers the entire portion structure and all the fits.
2022-03-23 12:31:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:31:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen is that... well, when stripped dinner, it was best summarized when somebody said, "turn to the men at your table, and say," if the revolution begins, we support you. "the truth is that we've already started to support you for a long time."
2022-03-23 12:31:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:31:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a large part of the design work that we're proud about at our plane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variation and a refrigeration system, that allows us to use a believable machine to stop and use it in the aircraft, until a trigger machine, or if you see it, you see it's either the ground, or if you look at it's a mechanism, you see it's a mechanism, or if you see it's a mechanism, you see it's a mechanism, you're going on the ground.
2022-03-23 12:31:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:31:37 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.896 | ppl 476.25 | bleu 31.11 | wps 4776.6 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.31
2022-03-23 12:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 12:31:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:31:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:31:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 31 @ 4862 updates, score 31.11) (writing took 0.8047282849438488 seconds)
2022-03-23 12:31:38 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:31:38 | INFO | train | epoch 031 | loss 7.533 | ppl 185.17 | wps 40151.6 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.36 | loss_scale 4 | train_wall 58 | gb_free 12.6 | wall 3134
KL Stats: Epoch 31 Divergences: Uniform: 1.4200294138219596 Unigram: 1.0044780338382044
2022-03-23 12:31:39 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:31:53 | INFO | train_inner | epoch 032:     38 / 157 loss=7.541, ppl=186.19, wps=32129.8, ups=1.29, wpb=24898.9, bsz=1067.6, num_updates=4900, lr=0.000451754, gnorm=0.35, loss_scale=4, train_wall=36, gb_free=11.9, wall=3149
2022-03-23 12:32:31 | INFO | train_inner | epoch 032:    138 / 157 loss=7.486, ppl=179.3, wps=67511.5, ups=2.66, wpb=25391.9, bsz=991.7, num_updates=5000, lr=0.000447214, gnorm=0.376, loss_scale=4, train_wall=37, gb_free=11.7, wall=3187
2022-03-23 12:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:32:42 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:32:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:32:46 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without realizing it, you see the world different.
2022-03-23 12:32:46 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:32:50 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-23 12:32:50 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:32:54 | INFO | fairseq.tasks.translation | example hypothesis: in particular, it focuses on japan, korea and australia, countries that are close allies of the united states.
2022-03-23 12:32:54 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:32:58 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrating i am, so i can carry my attention degree in the circuit board on the other side.
2022-03-23 12:32:58 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:33:02 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool, as if it was a body part of the primate.
2022-03-23 12:33:02 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:33:06 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our kids a lot of scientific formula, experiments that go beyond normal education.
2022-03-23 12:33:06 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:33:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can, which gives the big contextures of the face and the basic shape, and gives it through the one information that pulls all the porous structure and all the fones.
2022-03-23 12:33:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:33:15 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured for me to be here at tedwomen is that -- well, the stripped dinner was best summarized when someone said, "turn to the men at your table and say," when the revolution starts to support you. "the truth is that we've already started to support you for a long time."
2022-03-23 12:33:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:33:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we are at our airplane on the stumble, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variation system of refrigeration and a refrigeration system, allows us to use a stop and passenger in a particular way, to see the ground.
2022-03-23 12:33:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:33:16 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.829 | ppl 454.68 | bleu 32.45 | wps 4747.8 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 32.45
2022-03-23 12:33:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 12:33:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:33:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:33:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 32 @ 5019 updates, score 32.45) (writing took 1.9419889030978084 seconds)
2022-03-23 12:33:18 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:33:18 | INFO | train | epoch 032 | loss 7.507 | ppl 181.92 | wps 39500.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.362 | loss_scale 4 | train_wall 58 | gb_free 12.1 | wall 3234
KL Stats: Epoch 32 Divergences: Uniform: 1.418832025283728 Unigram: 1.0029726371440806
2022-03-23 12:33:18 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:33:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:33:49 | INFO | train_inner | epoch 033:     81 / 157 loss=7.542, ppl=186.33, wps=31837.4, ups=1.28, wpb=24880.4, bsz=1026.3, num_updates=5100, lr=0.000442807, gnorm=0.339, loss_scale=4, train_wall=37, gb_free=12.9, wall=3265
2022-03-23 12:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:34:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:34:25 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without realizing it, you see the world different.
2022-03-23 12:34:25 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:34:29 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:34:29 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:34:33 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 12:34:33 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:34:38 | INFO | fairseq.tasks.translation | example hypothesis: it could also be interested in me how focused i am, so i can carry my attention degree in the board on the other side.
2022-03-23 12:34:38 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:34:42 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity shifts to form this new tool, as if it was a body part of the primate.
2022-03-23 12:34:42 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:34:46 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our kids a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 12:34:46 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:34:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can, which gives the big contextures of the face and the basic form, and deposits it by the one information that pulls all the porting structure and all the folds.
2022-03-23 12:34:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:34:55 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that -- well, in the controversial dinner, it was best summarized when someone said, "turn you to the men at your table and say to you, 'if the revolution begins to be here, we support you.' '' '' the truth is that we've been supporting you for a long time."
2022-03-23 12:34:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:34:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're proud of at our plane was a result that we had to solve the unique problems that were linked to operate it on the ground -- everything, from a continuous variation of design work, and a refrigeration system with liquid that allows us to use in the aircraft on the ground, until you can see it, to be able to use it in the ground.
2022-03-23 12:34:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:34:57 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.849 | ppl 461.07 | bleu 32.28 | wps 4530.4 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.45
2022-03-23 12:34:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 12:34:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:34:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:34:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 33 @ 5176 updates, score 32.28) (writing took 0.8002167898230255 seconds)
2022-03-23 12:34:58 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:34:58 | INFO | train | epoch 033 | loss 7.471 | ppl 177.44 | wps 39469.8 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.358 | loss_scale 4 | train_wall 58 | gb_free 11.9 | wall 3334
KL Stats: Epoch 33 Divergences: Uniform: 1.4188049292211693 Unigram: 1.005611117225625
2022-03-23 12:34:59 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:35:08 | INFO | train_inner | epoch 034:     24 / 157 loss=7.377, ppl=166.18, wps=32425.7, ups=1.27, wpb=25446.9, bsz=1002.9, num_updates=5200, lr=0.000438529, gnorm=0.376, loss_scale=4, train_wall=37, gb_free=11.9, wall=3343
2022-03-23 12:35:45 | INFO | train_inner | epoch 034:    124 / 157 loss=7.463, ppl=176.4, wps=67012.3, ups=2.67, wpb=25063.4, bsz=1053.4, num_updates=5300, lr=0.000434372, gnorm=0.309, loss_scale=4, train_wall=37, gb_free=12.2, wall=3381
2022-03-23 12:35:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:36:01 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world different.
2022-03-23 12:36:05 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:36:09 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:36:09 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:36:13 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-23 12:36:13 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:36:17 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i'm, so i can put my attention degree in the circuit board on the other side.
2022-03-23 12:36:17 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:36:21 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body of primates.
2022-03-23 12:36:21 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:36:25 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal class.
2022-03-23 12:36:25 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:36:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection reflection of reflection, we can start with a traditional facial can, which restores the big configurations of the face and the basic form of information, which refers all the porting structure and all the folds.
2022-03-23 12:36:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:36:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was best summared, it was best summared when someone said, "turn to the men at your table and say," if the revolution starts to support you. "the truth is that we've already started you with this topic for a long time."
2022-03-23 12:36:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:36:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we are at our airplane at the stumber was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use a tooth machine in a particular way to see the ground when you look at it on the ground.
2022-03-23 12:36:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:36:36 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.809 | ppl 448.54 | bleu 32.19 | wps 4745.7 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.45
2022-03-23 12:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 12:36:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:36:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:36:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.19) (writing took 0.824980940669775 seconds)
2022-03-23 12:36:36 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:36:36 | INFO | train | epoch 034 | loss 7.44 | ppl 173.59 | wps 40211.8 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.33 | loss_scale 4 | train_wall 58 | gb_free 11.5 | wall 3432
KL Stats: Epoch 34 Divergences: Uniform: 1.4176949247365231 Unigram: 1.0090319758555044
2022-03-23 12:36:37 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:02 | INFO | train_inner | epoch 035:     67 / 157 loss=7.53, ppl=184.87, wps=32189.5, ups=1.3, wpb=24815.7, bsz=930.4, num_updates=5400, lr=0.000430331, gnorm=0.343, loss_scale=4, train_wall=37, gb_free=11.9, wall=3458
2022-03-23 12:37:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:37:39 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:37:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:37:43 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without realizing it, you see the world different.
2022-03-23 12:37:43 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:37:48 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instincts and intelligence.
2022-03-23 12:37:48 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:37:52 | INFO | fairseq.tasks.translation | example hypothesis: it's especially focused on japan, korea and australia, countries that are enconnected to the united states.
2022-03-23 12:37:52 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:37:56 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how concentrated i'm, so i can carry my attention degree in the circuit on the other side.
2022-03-23 12:37:56 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:38:00 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:38:00 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:38:04 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formers, experiments that go far beyond normal class.
2022-03-23 12:38:04 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:38:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big contextures of the face and the basic form, and through the instructions that refuse all the pore structure and all the fits.
2022-03-23 12:38:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:38:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured for me to be here at tedwomen is that... well, when striked dinner was best summarized when someone said, "turn to the men at your table, and tell them, '' '' when the revolution begins, we support you. '' '' '' '' '' '' '' the truth, women, we've already been supporting you at this topic for a long time."
2022-03-23 12:38:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:38:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, there's still a mother of invention, and a big part of the design work that we're on at our plane is a result that we had to solve the unique problems that were connected to operating it on the ground -- all, from a continuous variables, and a refrigeration system with liquid that allows us to use a tooth in the clothes, until you can either get rid of the most trigger traffic, or if you're going to operate it on the ground, or if you're going to operate it's a continuous variable, until you're going to see it's a continuous variable able able able to see it's a steady, all, or if you're going to the most refrightened to operate it's a continuous variables that you're going to move from one of the nightstand that you're going to see it's a continuous variables that you're going to see it's in the most refrightened to
2022-03-23 12:38:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:38:16 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.811 | ppl 449.01 | bleu 32.57 | wps 4535.1 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.57
2022-03-23 12:38:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 12:38:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.57) (writing took 1.7802321491762996 seconds)
2022-03-23 12:38:17 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:38:17 | INFO | train | epoch 035 | loss 7.416 | ppl 170.74 | wps 39111.7 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.332 | loss_scale 4 | train_wall 58 | gb_free 12 | wall 3533
KL Stats: Epoch 35 Divergences: Uniform: 1.420966487443417 Unigram: 1.0094496450712678
2022-03-23 12:38:18 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:38:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:38:21 | INFO | train_inner | epoch 036:     10 / 157 loss=7.318, ppl=159.53, wps=31990.6, ups=1.26, wpb=25384, bsz=1089.6, num_updates=5500, lr=0.000426401, gnorm=0.325, loss_scale=4, train_wall=37, gb_free=12, wall=3537
2022-03-23 12:38:59 | INFO | train_inner | epoch 036:    110 / 157 loss=7.359, ppl=164.2, wps=67640.5, ups=2.68, wpb=25274.9, bsz=1040, num_updates=5600, lr=0.000422577, gnorm=0.332, loss_scale=4, train_wall=37, gb_free=12.9, wall=3574
2022-03-23 12:39:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:39:20 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:39:20 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:39:25 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without realizing it, you see the world differently.
2022-03-23 12:39:25 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:39:29 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instincts and intelligence.
2022-03-23 12:39:29 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:39:32 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-23 12:39:32 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:39:37 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how concentrating i am, so i can put my level of attention in the board on the other side.
2022-03-23 12:39:37 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:39:41 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a part of the primate.
2022-03-23 12:39:41 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:39:45 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formula, experiments that go far beyond normal education.
2022-03-23 12:39:45 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:39:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can, which refers the big contextures of the face and gives it the basic shape, and through that one information that refers all the porn structure and all the fits.
2022-03-23 12:39:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:39:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured, for me, is to be here at tedwomen, is that... well, in the strictly dinner dinner, it was best summarized when someone said, "turn to the men at your table and say," if the revolution starts to support you. "'"' "the truth is that we've already been supporting you at this topic for a long time.
2022-03-23 12:39:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:39:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still the mother, and a large part of the design work that we're on at our plane is a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuous variables, and a refrigeration system with liquid that allows us to use a toofteness machine in the stop-go-and to a special transportation machine, until a particular passenger in the ground, if you're going to the propelled in the ground, or if you're going to see it's the wheels at the ground, to a continuously variation of a refrigerator, or if you're going to see it's a refrigeration of a refrigeration of a refrigeration of a refrigeration of a continuous variable plant in the ground, or a refrigerator, or a refrigeration system that you're going to a refrigeration of a
2022-03-23 12:39:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:39:56 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.78 | ppl 439.59 | bleu 32.99 | wps 4581.8 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.99
2022-03-23 12:39:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 12:39:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:39:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:39:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.99) (writing took 1.8058823877945542 seconds)
2022-03-23 12:39:58 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:39:58 | INFO | train | epoch 036 | loss 7.395 | ppl 168.27 | wps 39320.5 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.324 | loss_scale 4 | train_wall 58 | gb_free 12.3 | wall 3633
KL Stats: Epoch 36 Divergences: Uniform: 1.4205665251214743 Unigram: 1.0114689674620625
2022-03-23 12:39:58 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:40:18 | INFO | train_inner | epoch 037:     53 / 157 loss=7.504, ppl=181.58, wps=31386.3, ups=1.26, wpb=24912.3, bsz=1024.3, num_updates=5700, lr=0.000418854, gnorm=0.316, loss_scale=4, train_wall=37, gb_free=12.3, wall=3654
2022-03-23 12:40:55 | INFO | train_inner | epoch 037:    153 / 157 loss=7.265, ppl=153.79, wps=69035.7, ups=2.7, wpb=25589.5, bsz=1001.1, num_updates=5800, lr=0.000415227, gnorm=0.328, loss_scale=4, train_wall=37, gb_free=12.3, wall=3691
2022-03-23 12:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:41:00 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:41:05 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realize it, you see the world differently.
2022-03-23 12:41:05 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:41:09 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds another equilibrium between faith and reason, instinct and intelligence.
2022-03-23 12:41:09 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:41:13 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are closely connected in the united states.
2022-03-23 12:41:13 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:41:17 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how i'm focused so i can put my attention degree in the circuit board on the other side.
2022-03-23 12:41:17 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:41:21 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:41:21 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:41:25 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute that come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-23 12:41:25 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:41:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that resembles the big configurations of the face and the basic form, and empowers it by the one that refers the entire portion structure and all the fits.
2022-03-23 12:41:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:41:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measured for me here to be here at tedwomen is that... well, the striking dinner was best summarized when someone said, "turn to the men at your table and tell you," when the revolution begins, we support you. "''" the truth, women, we've already started supporting you for a long time.
2022-03-23 12:41:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:41:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a big part of the design work that we're on on on our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- all, from a continuous variation and a refrigeration system with liquid that allows us to use an aircraft in stop-go-until you either have to use the most triggery when you look at the ground, or if you see it's in a particular mechanism, until you see it's a refrigerly mechanism, to the bottom of the rapid mechanism, until you can see it's the ground, or if you can see it's a refrigeration system that you can see it's a refrigeration of the rapid security system that you can see it's all the rapid security system that you can see it's all the rays out the rays out the rays out the rays down the rays out the ground,
2022-03-23 12:41:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:41:36 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.757 | ppl 432.6 | bleu 32.68 | wps 4679.4 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.99
2022-03-23 12:41:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 12:41:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:41:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:41:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 37 @ 5804 updates, score 32.68) (writing took 0.7714509419165552 seconds)
2022-03-23 12:41:36 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:41:36 | INFO | train | epoch 037 | loss 7.376 | ppl 166.07 | wps 40078.4 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.328 | loss_scale 4 | train_wall 58 | gb_free 13.1 | wall 3732
KL Stats: Epoch 37 Divergences: Uniform: 1.418684876691011 Unigram: 1.012718408449463
2022-03-23 12:41:37 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:13 | INFO | train_inner | epoch 038:     96 / 157 loss=7.329, ppl=160.8, wps=32448.8, ups=1.29, wpb=25250.9, bsz=1067.8, num_updates=5900, lr=0.000411693, gnorm=0.324, loss_scale=4, train_wall=37, gb_free=12.4, wall=3769
2022-03-23 12:42:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:42:39 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:42:39 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:42:44 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 12:42:44 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:42:48 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between belief and reason, instinct and intelligence.
2022-03-23 12:42:48 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:42:51 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are closely connected to the united states.
2022-03-23 12:42:51 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:42:56 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the circuit board on the other hand.
2022-03-23 12:42:56 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:43:00 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:43:00 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:43:04 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute, who come and teach our children a lot of scientific formulas, experiments that go beyond normal education.
2022-03-23 12:43:04 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:43:08 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big contextures of the face, and the basic shape, and encounters it by the one that refuses all the porting structure and all the fine folds.
2022-03-23 12:43:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:43:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when the strictly dinner dinner was best summarized, when someone said, "turn to the men at your table and tell them," if the revolution starts to support you. "'" the truth, love, women, we've already started to support you at this topic for a long time. "
2022-03-23 12:43:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:43:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother, and a large part of the design work that we're stumbling on at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation of the design work, and a refrigeration system with fluid that allows us to use an aircraft in stop-go-traffic, until you to see that we're either going to see it in the ground when you're going to see it, to the ground, to the most refrigerately variable, to the ground.
2022-03-23 12:43:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:43:15 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.76 | ppl 433.65 | bleu 33.41 | wps 4673.1 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.41
2022-03-23 12:43:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 12:43:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:43:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt
2022-03-23 12:43:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_best.pt (epoch 38 @ 5961 updates, score 33.41) (writing took 1.930204268079251 seconds)
2022-03-23 12:43:17 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:43:17 | INFO | train | epoch 038 | loss 7.353 | ppl 163.51 | wps 39319.6 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.327 | loss_scale 4 | train_wall 58 | gb_free 12.9 | wall 3832
KL Stats: Epoch 38 Divergences: Uniform: 1.4207481307578755 Unigram: 1.0150413095505193
2022-03-23 12:43:17 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:43:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:43:32 | INFO | train_inner | epoch 039:     39 / 157 loss=7.403, ppl=169.24, wps=31610.9, ups=1.27, wpb=24921.4, bsz=967, num_updates=6000, lr=0.000408248, gnorm=0.308, loss_scale=4, train_wall=36, gb_free=11.8, wall=3848
2022-03-23 12:44:09 | INFO | train_inner | epoch 039:    139 / 157 loss=7.346, ppl=162.72, wps=66713.6, ups=2.68, wpb=24936.7, bsz=1028.5, num_updates=6100, lr=0.000404888, gnorm=0.318, loss_scale=4, train_wall=37, gb_free=12.3, wall=3885
2022-03-23 12:44:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:44:20 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:44:24 | INFO | fairseq.tasks.translation | example hypothesis: and suddenly, without you realize it, you see the world differently.
2022-03-23 12:44:24 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:44:28 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:44:28 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:44:32 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are closely connected to the united states.
2022-03-23 12:44:32 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:44:36 | INFO | fairseq.tasks.translation | example hypothesis: i could also care about how focused i am, so i can put my level of attention in the board on the other side.
2022-03-23 12:44:36 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:44:40 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:44:40 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:44:44 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute who come and teach our kids a lot of scientific formula, experiments that go far beyond normal class.
2022-03-23 12:44:44 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:44:48 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection of reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic form, and empowers it through the one information that refers all the porous structure and all the fone folds.
2022-03-23 12:44:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:44:52 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that... well, in the controversial dinner dinner, it was best summarized when someone said, "turn to the men at your table and tell them," if the revolution starts to support you. '"the truth is that we've already been supporting you at this topic for a long time."
2022-03-23 12:44:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:44:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're stumbling at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variables, and a refrigeration system with liquid that allows us to use a tooth in the transportation, to a particular propeller, if you're connected to operate it on the ground -- everything, from one continuously, to a continuously varying on the ground, to a continuously variables, to the ground, if you see it, to the ground, to the ground, to the ground, to the ground, if you see it, to the ground, to the car, to the ground, to the ground, to the ground, to the ground, to the wheel, to the ground, to the ground, if you see it's the rays, to the ground, to the ground, to the ground.
2022-03-23 12:44:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:44:55 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.75 | ppl 430.47 | bleu 33.25 | wps 4788.5 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.41
2022-03-23 12:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 12:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:44:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:44:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 39 @ 6118 updates, score 33.25) (writing took 0.785690207965672 seconds)
2022-03-23 12:44:55 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:44:55 | INFO | train | epoch 039 | loss 7.328 | ppl 160.65 | wps 40065.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.306 | loss_scale 4 | train_wall 58 | gb_free 12.2 | wall 3931
KL Stats: Epoch 39 Divergences: Uniform: 1.4215281104653466 Unigram: 1.0168373450219403
2022-03-23 12:44:56 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:44:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:45:26 | INFO | train_inner | epoch 040:     82 / 157 loss=7.399, ppl=168.74, wps=32232.7, ups=1.3, wpb=24790.6, bsz=935.9, num_updates=6200, lr=0.00040161, gnorm=0.333, loss_scale=4, train_wall=36, gb_free=11.9, wall=3962
2022-03-23 12:45:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:58 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:45:58 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:46:03 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without realizing it, you see the world different.
2022-03-23 12:46:03 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:46:07 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:46:07 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:46:11 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close to the united states.
2022-03-23 12:46:11 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:46:15 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i am, so i can put my attention degree in the circuit board on the other side.
2022-03-23 12:46:15 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:46:19 | INFO | fairseq.tasks.translation | example hypothesis: as quickly as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:46:19 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:46:23 | INFO | fairseq.tasks.translation | example hypothesis: is it the impact? we have professors from mit, from berkeley, stanford, from the indian science institute who come and teach our children a lot of scientific formulas, experiments that go far beyond normal education.
2022-03-23 12:46:23 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:46:27 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big contextures of the face, and gives it the basic form of information that refers the whole porter structure and all the fones.
2022-03-23 12:46:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:46:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... well, when dinner was tested dinner, it was best summarized when someone said, "turn to the men at your table and say to them," if the revolution begins, we'll support you. '"'" the truth, women is that we've already been supporting you at a long time with a silence of stone borlaugh, "and then," to downstream, "
2022-03-23 12:46:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:46:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're stumbling on at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variables, and a refrigeration system with liquid that allows us to use an aircraft in stop-go-to a particular driver when you fly down the ground, or if you see the mechanism, or if you're going to see the ground, you're going to see it in a continuous way, all the mechanism, to the way, until you're going to the mechanism, to the security system, you're going to the ground, you're going to see it's going to the ground, to the
2022-03-23 12:46:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:46:33 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.725 | ppl 423.29 | bleu 33.29 | wps 4756.2 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.41
2022-03-23 12:46:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 12:46:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:46:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:46:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 40 @ 6275 updates, score 33.29) (writing took 0.896222276147455 seconds)
2022-03-23 12:46:34 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:46:34 | INFO | train | epoch 040 | loss 7.314 | ppl 159.15 | wps 39949.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.314 | loss_scale 4 | train_wall 58 | gb_free 11.8 | wall 4030
KL Stats: Epoch 40 Divergences: Uniform: 1.4190640625871833 Unigram: 1.0169850978455264
2022-03-23 12:46:35 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:46:44 | INFO | train_inner | epoch 041:     25 / 157 loss=7.233, ppl=150.42, wps=32733, ups=1.28, wpb=25484.2, bsz=1081.8, num_updates=6300, lr=0.00039841, gnorm=0.29, loss_scale=4, train_wall=37, gb_free=12.2, wall=4040
2022-03-23 12:47:22 | INFO | train_inner | epoch 041:    125 / 157 loss=7.206, ppl=147.66, wps=68165, ups=2.66, wpb=25630.3, bsz=1010.1, num_updates=6400, lr=0.000395285, gnorm=0.314, loss_scale=4, train_wall=37, gb_free=11.8, wall=4077
2022-03-23 12:47:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:47:37 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 12:47:37 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 12:47:42 | INFO | fairseq.tasks.translation | example hypothesis: and all of a sudden, without you realizing it, you see the world different.
2022-03-23 12:47:42 | INFO | fairseq.tasks.translation | example reference: and suddenly, without realizing it, you're seeing the world differently.
2022-03-23 12:47:45 | INFO | fairseq.tasks.translation | example hypothesis: but every musician finds a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:47:45 | INFO | fairseq.tasks.translation | example reference: but every musician strikes a different balance between faith and reason, instinct and intelligence.
2022-03-23 12:47:49 | INFO | fairseq.tasks.translation | example hypothesis: it's particularly focused on japan, korea and australia, countries that are close allies in the united states.
2022-03-23 12:47:49 | INFO | fairseq.tasks.translation | example reference: specifically, it targets japan and korea and australia, countries that are strong allies of the united states.
2022-03-23 12:47:53 | INFO | fairseq.tasks.translation | example hypothesis: i could also be interested in how focused i'm, so i can put my attention degree in the circuit board on the other hand.
2022-03-23 12:47:53 | INFO | fairseq.tasks.translation | example reference: i may also be interested in knowing how focused i am, so i can put my level of attention into the circuit board on the other side.
2022-03-23 12:47:57 | INFO | fairseq.tasks.translation | example hypothesis: as fast as we can restore our computers, the brain activity shifts to form this new tool as if it was a body part of the primate.
2022-03-23 12:47:57 | INFO | fairseq.tasks.translation | example reference: as fast as we can reset our computers, the brain activity shifts to start representing this new tool, as if this too was a part of that primate's body.
2022-03-23 12:48:01 | INFO | fairseq.tasks.translation | example hypothesis: is it the influence? we have professors from mit, from berkeley, stanford, from the indian science institute who come and teach our children a lot of scientific forms, experiments that go far beyond normal education.
2022-03-23 12:48:01 | INFO | fairseq.tasks.translation | example reference: is it the exposure? we have professors from mit, berkeley, stanford, indian institute of science who come and teach our children lots of scientific formulas, experiments, much beyond the classroom.
2022-03-23 12:48:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of mirror reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic form, and empire it through the whole porting structure and all the fine folds.
2022-03-23 12:48:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:48:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when dinner became best summarized when someone said, "turn to the men at your table and tell them," if the revolution begins, we support you. '' '' '"the truth, love is that we've already started you in this topic for a long time." in rachel carent cartheo, "and then she says," goodbye, "to the future of sand."
2022-03-23 12:48:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:48:11 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother, and a large part of the design work that we are on on our airplane the most stumbling was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable operating system, and a cooling system with liquid that allows us to use an airplane in stop-go-traffic, to a special passenger, either if you're in the ground, or if you see the mechanism, to fly down the ground.
2022-03-23 12:48:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:48:11 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.743 | ppl 428.4 | bleu 33.18 | wps 4787.6 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.41
2022-03-23 12:48:11 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 12:48:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 12:48:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt
2022-03-23 12:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.15_0.2_0.65_#2/checkpoint_last.pt (epoch 41 @ 6432 updates, score 33.18) (writing took 0.8263319651596248 seconds)
2022-03-23 12:48:12 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:48:12 | INFO | train | epoch 041 | loss 7.294 | ppl 156.95 | wps 40279.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.308 | loss_scale 4 | train_wall 58 | gb_free 12.8 | wall 4128
2022-03-23 12:48:12 | INFO | fairseq_cli.train | done training in 4127.5 seconds
