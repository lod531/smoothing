Sender: LSF System <lsfadmin@eu-g3-049>
Subject: Job 210582588: <iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:33:03 2022
Job was executed on host(s) <eu-g3-049>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:33:14 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:33:14 2022
Terminated at Wed Mar 23 10:40:58 2022
Results reported at Wed Mar 23 10:40:58 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.5 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4055.10 sec.
    Max Memory :                                 5577 MB
    Average Memory :                             4445.57 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14423.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4064 sec.
    Turnaround time :                            4075 sec.

The output (if any) follows:

2022-03-23 09:33:22 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.5, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.5, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:33:22 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:33:22 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:33:23 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:33:23 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:33:23 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:33:23 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:33:23 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:33:23 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:33:23 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:33:23 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:33:23 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:33:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:33:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:33:27 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:33:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:33:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:33:27 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:33:27 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 09:33:27 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 09:33:27 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:33:27 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:33:27 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:33:27 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:33:28 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:33:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:33:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:34:01 | INFO | train_inner | epoch 001:    103 / 157 loss=12.655, nll_loss=11.897, ppl=3814.26, wps=80154.9, ups=3.19, wpb=25148.6, bsz=969, num_updates=100, lr=1.25e-05, gnorm=1.796, loss_scale=16, train_wall=33, gb_free=14.6, wall=34
2022-03-23 09:34:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:34:21 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 09:34:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:34:24 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:34:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:27 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,....
2022-03-23 09:34:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:30 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 09:34:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:34:34 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:34:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:34:39 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:34:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:34:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:50 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:34:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:34:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:59 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:34:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:59 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 11.691 | nll_loss 10.111 | ppl 1106.22 | bleu 0.01 | wps 4280.7 | wpb 17862.2 | bsz 728.3 | num_updates 154
2022-03-23 09:34:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 154 updates
2022-03-23 09:34:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:35:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 1 @ 154 updates, score 0.01) (writing took 1.6043216650141403 seconds)
2022-03-23 09:35:01 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:35:01 | INFO | train | epoch 001 | loss 12.402 | nll_loss 11.427 | ppl 2752.72 | wps 42361 | ups 1.69 | wpb 25111.2 | bsz 998.2 | num_updates 154 | lr 1.925e-05 | gnorm 1.417 | loss_scale 16 | train_wall 49 | gb_free 22.4 | wall 94
2022-03-23 09:35:01 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:35:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:35:16 | INFO | train_inner | epoch 002:     46 / 157 loss=11.806, nll_loss=10.337, ppl=1293.77, wps=34044, ups=1.34, wpb=25350.7, bsz=1086.7, num_updates=200, lr=2.5e-05, gnorm=0.664, loss_scale=16, train_wall=30, gb_free=14.7, wall=109
2022-03-23 09:35:47 | INFO | train_inner | epoch 002:    146 / 157 loss=11.458, nll_loss=9.656, ppl=806.79, wps=80232.9, ups=3.19, wpb=25173.8, bsz=981.7, num_updates=300, lr=3.75e-05, gnorm=0.749, loss_scale=16, train_wall=31, gb_free=13.6, wall=140
2022-03-23 09:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-23 09:35:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:35:57 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the.
2022-03-23 09:35:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:36:01 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the.
2022-03-23 09:36:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:36:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:36:12 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:36:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:36:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:36:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:36:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:36 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:36:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:38 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:36:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:38 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.299 | nll_loss 9.223 | ppl 597.73 | bleu 0.01 | wps 3660.3 | wpb 17862.2 | bsz 728.3 | num_updates 311 | best_bleu 0.01
2022-03-23 09:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 311 updates
2022-03-23 09:36:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:36:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:36:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 2 @ 311 updates, score 0.01) (writing took 1.670992389001185 seconds)
2022-03-23 09:36:40 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:36:40 | INFO | train | epoch 002 | loss 11.513 | nll_loss 9.773 | ppl 874.7 | wps 39917.6 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 311 | lr 3.8875e-05 | gnorm 0.698 | loss_scale 16 | train_wall 48 | gb_free 13.9 | wall 193
2022-03-23 09:36:40 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:36:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:37:08 | INFO | train_inner | epoch 003:     89 / 157 loss=11.352, nll_loss=9.407, ppl=678.77, wps=30424, ups=1.24, wpb=24571.4, bsz=947.8, num_updates=400, lr=5e-05, gnorm=0.728, loss_scale=16, train_wall=30, gb_free=13.6, wall=221
2022-03-23 09:37:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:33 | INFO | fairseq.tasks.translation | example hypothesis: and we we we we we we we the the the the the the the the the the the the the the the the the
2022-03-23 09:37:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:37:39 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:37:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:37:50 | INFO | fairseq.tasks.translation | example hypothesis: and and it's, and it's, and it's, and it's, and it's, and it's, and it's's, and it's's's, and it's's, and
2022-03-23 09:37:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:37:56 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's, and we's's's, and it's, and we's's's's, and we, and it's, and it's's's's's, and it's's, and it's's, and
2022-03-23 09:37:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:38:02 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and and and and the the the the the the, and the the the the the the, and the the the, and and and the the the the the the the the the the the the the, and and and and and and and the the the the the the
2022-03-23 09:38:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:38:07 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's, and it's, and it's's, and it's's's, and it's, and it's, and it's's's's, and it's's, and and and and and and and and and and and the the the the the the the the the, and it's, it's's's's,
2022-03-23 09:38:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:38:14 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we, and we we we we we we we we we we we we we we we
2022-03-23 09:38:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:38:21 | INFO | fairseq.tasks.translation | example hypothesis: and and we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we, we, and we, and we, and we, and we, and we, we, we, we, we, we, and we, we, we, we, we, and we, and we, and we, and we, and we, we, we, and we, and we, and we, and we, and we, and we, and we, and we, and we, we, we, and we, and we, we, we, and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we, and we, and we, and we,
2022-03-23 09:38:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:38:24 | INFO | fairseq.tasks.translation | example hypothesis: and so we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, we, we, we, we, we, we, we, and we, and we, we, we, we, we, we, and we, and we, we, we, we, and we, and we, and we, and we, we, we, we, we, we, and we, and we, and we, and we, and we, and we, and we, and we, we, we, and we, and we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, we, and we, and we, and we, we, and we, we, we, we, we, we, we, we, we, we, and we, we, we,
2022-03-23 09:38:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:38:24 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 11.247 | nll_loss 9.039 | ppl 526.01 | bleu 0.11 | wps 3261.1 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.11
2022-03-23 09:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:38:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:38:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.11) (writing took 1.6905861110135447 seconds)
2022-03-23 09:38:25 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:38:25 | INFO | train | epoch 003 | loss 11.314 | nll_loss 9.322 | ppl 639.85 | wps 37202.1 | ups 1.48 | wpb 25157 | bsz 1018.6 | num_updates 467 | lr 5.8375e-05 | gnorm 0.779 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 298
2022-03-23 09:38:26 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:38:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:36 | INFO | train_inner | epoch 004:     33 / 157 loss=11.25, nll_loss=9.179, ppl=579.63, wps=28888.7, ups=1.13, wpb=25513.6, bsz=1104.6, num_updates=500, lr=6.25e-05, gnorm=0.743, loss_scale=8, train_wall=31, gb_free=13.9, wall=309
2022-03-23 09:39:08 | INFO | train_inner | epoch 004:    133 / 157 loss=11.156, nll_loss=8.974, ppl=502.86, wps=80230, ups=3.18, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=0.823, loss_scale=8, train_wall=31, gb_free=12.6, wall=340
2022-03-23 09:39:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example hypothesis: and we've've've've've've've've've've've're the the in the in the in the.
2022-03-23 09:39:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:39:24 | INFO | fairseq.tasks.translation | example hypothesis: that's the that's the that's the that's the that's the that's the world.
2022-03-23 09:39:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:29 | INFO | fairseq.tasks.translation | example hypothesis: and you can can can can can can can can can can can can can can be be be be a to be a to be the the.
2022-03-23 09:39:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:34 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's a a a to be a to be to be a to be a.
2022-03-23 09:39:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example hypothesis: and it's a that we can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't know
2022-03-23 09:39:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:39:45 | INFO | fairseq.tasks.translation | example hypothesis: and this is that's in the in the world of the world of the world, and the world of the world of the world of the world of the world of the world.
2022-03-23 09:39:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:39:51 | INFO | fairseq.tasks.translation | example hypothesis: and you can can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't know
2022-03-23 09:39:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:57 | INFO | fairseq.tasks.translation | example hypothesis: and so we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can the the the to the to the to the to the to the to be to be to the of the that that we can can can can can can can can can can can can can can can can can can can can can can can can the
2022-03-23 09:39:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:40:05 | INFO | fairseq.tasks.translation | example hypothesis: and so, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:40:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example hypothesis: and so, we can can can can can can can can can can can can can be a a a a a a a a to be to be to be to be to be a to be to be to be to be to be to be to be to be to be a to be to be to be to be to be to be to be a to be to be to the the the the to be a a to be a a to be to be to be to be to be to be to a to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to to to to be to be to be to be to be to be to to to to to to to be to be to to to to to to to be to to to to to to to to to to be to be to be to be to be to be to be
2022-03-23 09:40:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:40:07 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.015 | nll_loss 8.455 | ppl 350.92 | bleu 0.55 | wps 3376.6 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.55
2022-03-23 09:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:40:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:40:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:40:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.55) (writing took 1.6678427290171385 seconds)
2022-03-23 09:40:09 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:40:09 | INFO | train | epoch 004 | loss 11.159 | nll_loss 8.982 | ppl 505.72 | wps 38032.9 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 0.757 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 402
2022-03-23 09:40:09 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:40:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:40:33 | INFO | train_inner | epoch 005:     76 / 157 loss=11.055, nll_loss=8.747, ppl=429.53, wps=28677.7, ups=1.17, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=0.892, loss_scale=8, train_wall=30, gb_free=13.4, wall=426
2022-03-23 09:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the world of the world.
2022-03-23 09:41:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:41:10 | INFO | fairseq.tasks.translation | example hypothesis: we're a lot of the world of the world.
2022-03-23 09:41:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:41:14 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and there's a lot of the world, and there's a lot of the world.
2022-03-23 09:41:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:41:20 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not that we're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not the
2022-03-23 09:41:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world of the world, and the world in the world of the world, and the world, and the world in the world, and the world in the world, and the world in the world in the world in the world in the world,
2022-03-23 09:41:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:41:31 | INFO | fairseq.tasks.translation | example hypothesis: but it's not not not not not not not not not not not not not not not not not not not not not the world, but but they're the world, but they're the world, but they're not not not not not not not not not not not not not not not not not not not not not not not not not not not not the
2022-03-23 09:41:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:41:37 | INFO | fairseq.tasks.translation | example hypothesis: and we can see the world of the world of the world of the world, and we can see the world of the world, and we can see the world, and we can see the world that we can see the world that we can see the world of the world of the world that we can see the world of the world of the world that we can see the world that we can see the world of the world of the world of the world of the world,
2022-03-23 09:41:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:45 | INFO | fairseq.tasks.translation | example hypothesis: and this is that, "the world," that i've've've've've've've've've have to be the world, "" "" "" "" "the world," "" "" "" "" "" the world, "the world, it's the world," it's the world, "it's the world," it's the first first first first first first first first first first first, "" that we've've've've've've've've've've've've've've've've've know, "" "" "" "" "the first first first first first first first first first first first first first first first first first first first first first first first first first first first," "the first first first first first first first first first first first," "" "" "" "" "" "" "" "" "
2022-03-23 09:41:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:47 | INFO | fairseq.tasks.translation | example hypothesis: so, that we're the world of the world of the world of the world of the world of the world of the world, the world, that we can't know that we can't know that we can't know that the world, the world, the world of the world, the world, the world, the world, the world, the world, the world that we can't have the world, the world, the world of the world of the world, the world that we can't know that we can't have the world, the world that we can't know that we can't know that we can't know that we've've've've've've've've've've've've've've've have to be the world that was the world, the world, the world, the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world, the world of the world of the world, the world, the world, the world, the world of the
2022-03-23 09:41:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:47 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.822 | nll_loss 8.129 | ppl 279.99 | bleu 1.2 | wps 3617.2 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.2
2022-03-23 09:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:41:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.2) (writing took 1.7139731499773916 seconds)
2022-03-23 09:41:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:41:49 | INFO | train | epoch 005 | loss 10.975 | nll_loss 8.566 | ppl 379.07 | wps 39498 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 0.859 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 502
2022-03-23 09:41:49 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:55 | INFO | train_inner | epoch 006:     19 / 157 loss=10.922, nll_loss=8.448, ppl=349.24, wps=30926.9, ups=1.22, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=0.853, loss_scale=8, train_wall=30, gb_free=14.6, wall=508
2022-03-23 09:42:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:42:27 | INFO | train_inner | epoch 006:    120 / 157 loss=10.852, nll_loss=8.289, ppl=312.81, wps=79747.5, ups=3.16, wpb=25234.2, bsz=1007, num_updates=900, lr=0.0001125, gnorm=0.818, loss_scale=4, train_wall=31, gb_free=14.1, wall=540
2022-03-23 09:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:42 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-23 09:42:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:46 | INFO | fairseq.tasks.translation | example hypothesis: this is here, this is here.
2022-03-23 09:42:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:42:50 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be a lot of the world.
2022-03-23 09:42:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of it's a lot of the world.
2022-03-23 09:42:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:42:58 | INFO | fairseq.tasks.translation | example hypothesis: and it's not what we don't know that we're going to do that we're going to do it.
2022-03-23 09:42:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:43:03 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the world, in the world, in the world, in the world, and the world, in the world, in the world, and the world, in the world, and the world, in the world, and the world, and the world, and the
2022-03-23 09:43:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:43:08 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to be a lot of the world, but they're going to be a lot of the world.
2022-03-23 09:43:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:13 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see that we can see the
2022-03-23 09:43:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:43:20 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "you know," you know, "you know," "you know," it's going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "" it's going to say, "" "" "" "" "" "" "" "" "" you know, "you know," you know, "you know," "" "" "" you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "" "" "" "" "
2022-03-23 09:43:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:43:22 | INFO | fairseq.tasks.translation | example hypothesis: now, if you know, we're going to be a lot of a lot of a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world.
2022-03-23 09:43:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:43:22 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.689 | nll_loss 7.707 | ppl 208.92 | bleu 1.98 | wps 4125.3 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.98
2022-03-23 09:43:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:43:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:43:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:43:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.98) (writing took 1.751718471001368 seconds)
2022-03-23 09:43:24 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:43:24 | INFO | train | epoch 006 | loss 10.841 | nll_loss 8.262 | ppl 307.02 | wps 41473.4 | ups 1.65 | wpb 25122.4 | bsz 1014.9 | num_updates 937 | lr 0.000117125 | gnorm 0.828 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 596
2022-03-23 09:43:24 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:43:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:43:44 | INFO | train_inner | epoch 007:     63 / 157 loss=10.741, nll_loss=8.038, ppl=262.77, wps=32784.5, ups=1.3, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=0.714, loss_scale=4, train_wall=30, gb_free=14.9, wall=617
2022-03-23 09:44:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:44:17 | INFO | fairseq.tasks.translation | example hypothesis: we've got to see the world in the world.
2022-03-23 09:44:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:44:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the first thing that this is that is the world, that is that's the world.
2022-03-23 09:44:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:44:26 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be able to be able to be able to be able to be able.
2022-03-23 09:44:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:44:31 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, there are, and there's a lot of the world.
2022-03-23 09:44:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:44:36 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do it, and it's going to do that we're going to do that we're going to do that we're going to do that we're going to do it
2022-03-23 09:44:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:44:41 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the world, and in the world, and the world, and in the world, and the world, and in the world, and the world, and the world, and the world, and the world, and the world, and the world, and the world
2022-03-23 09:44:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:44:46 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to be a lot of the world, but they're going to be, but they're going to be a lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the world.
2022-03-23 09:44:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:44:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see the world, we can see, we can see the world, we can see the world, and we can see the world.
2022-03-23 09:44:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:59 | INFO | fairseq.tasks.translation | example hypothesis: and then, "i'm going to say," you know, "you're going to say," you're going to go to say, "you're going to say," you're going to say, "you're going to go to be a lot of the world," you're going to say, "you're going to go to go to go to go to say," "" "and then you're going to go to get the" "" "" "and" "" "" "and then you're going to go to go to go to go to go to go to go to go to go to say," you're going to go to go to say, "" and then you're going to go to be, "" "" "and then," "" "" "and then you're going to go to be a" "" "
2022-03-23 09:44:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of the world, we're going to go to be a lot of the world, and we're going to be a lot of the world, and then we're going to be able to be a lot of the world.
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:01 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.587 | nll_loss 7.501 | ppl 181.18 | bleu 2.05 | wps 3711.3 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.05
2022-03-23 09:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:45:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.05) (writing took 1.7855142200132832 seconds)
2022-03-23 09:45:03 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:45:03 | INFO | train | epoch 007 | loss 10.693 | nll_loss 7.931 | ppl 244.12 | wps 39737.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 0.727 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 696
2022-03-23 09:45:03 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:05 | INFO | train_inner | epoch 008:      6 / 157 loss=10.663, nll_loss=7.864, ppl=233, wps=30687.1, ups=1.23, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=0.724, loss_scale=4, train_wall=30, gb_free=14.4, wall=698
2022-03-23 09:45:36 | INFO | train_inner | epoch 008:    106 / 157 loss=10.584, nll_loss=7.681, ppl=205.27, wps=81120.6, ups=3.22, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=0.741, loss_scale=4, train_wall=31, gb_free=14.7, wall=729
2022-03-23 09:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:56 | INFO | fairseq.tasks.translation | example hypothesis: we were in the world.
2022-03-23 09:45:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:46:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the most thing that you know, the most thing of the most thing of the most thing.
2022-03-23 09:46:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:06 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 09:46:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:46:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a lot of the world, and there's a lot of the world, and there's a lot of the world, and there's the world.
2022-03-23 09:46:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:46:16 | INFO | fairseq.tasks.translation | example hypothesis: it's it's just a lot of what we're going to do that we're going to do, and it's going to do that we're going to do that we're going to do that we're going to do that we're going
2022-03-23 09:46:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:46:21 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the world, in the world, the world, the world, the world, the world, the world, the world, the people are the people in the people in the people in the world, and the people in the world
2022-03-23 09:46:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:46:26 | INFO | fairseq.tasks.translation | example hypothesis: now, you have a lot of people who are in the world, but there are a lot of the world, but there are not a lot of the world.
2022-03-23 09:46:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:46:32 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can see the world, we can make a lot of the world, and then we can see the world, and then you can see the world, and then we can see that we can see that we can see the world, and the world, and then we can see the world, and then we can see that we can see the world, and then we can see the world, and then we can see the world, and then we can
2022-03-23 09:46:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:46:39 | INFO | fairseq.tasks.translation | example hypothesis: and then, "you know," you know, "this is," you know, "you know," you know, "you know," you know, "you know," you know, "you know," it's going to say, "it's a very," it's a little, "" "it's going to say," "" "" "" "" "" "" it's the first, "" "" "" "" "" "" "" "the first," "" the first, "you know," you know, "it's going to say," it's going to say, "it's going to say," you know, "you know," it's going to say, "it's a good," "" "" "" "" "" "" "" ""
2022-03-23 09:46:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:46:41 | INFO | fairseq.tasks.translation | example hypothesis: and then, if we're going to make a lot of the world, we're going to make a lot of the world, and then it's a lot of the world, which is a lot of the world, and it's a lot of the world, which is a lot of the world, which is that we're going to be a lot of the world, which is a lot of the world, which is that we're going to be a lot of the world, which is a lot of the world, which is that we're going to be a lot of the world, and then we're going to be a lot of the world, and then we're going to do that we're going to be a lot of the world, and then it's a lot of the world, which is a lot of the world, which is that we're going to be a lot of the world, and then we're going to be a lot of the world, which is a lot of the world, and then we're going to be a lot of
2022-03-23 09:46:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:46:41 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.498 | nll_loss 7.241 | ppl 151.31 | bleu 2.57 | wps 3652.4 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.57
2022-03-23 09:46:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:46:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:46:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:46:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.57) (writing took 1.7776281910191756 seconds)
2022-03-23 09:46:43 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:46:43 | INFO | train | epoch 008 | loss 10.6 | nll_loss 7.719 | ppl 210.75 | wps 39534.9 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 0.719 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 796
2022-03-23 09:46:43 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:46:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:46:59 | INFO | train_inner | epoch 009:     49 / 157 loss=10.554, nll_loss=7.618, ppl=196.44, wps=31111, ups=1.21, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=0.637, loss_scale=4, train_wall=31, gb_free=14.9, wall=812
2022-03-23 09:47:30 | INFO | train_inner | epoch 009:    149 / 157 loss=10.488, nll_loss=7.47, ppl=177.32, wps=80420.3, ups=3.24, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=0.676, loss_scale=4, train_wall=30, gb_free=14.4, wall=843
2022-03-23 09:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:47:36 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in this room.
2022-03-23 09:47:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:47:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the most thing that the most most most of the most most most most of the most most of the most of the most most most of the
2022-03-23 09:47:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:47:45 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new york are new new new new new york.
2022-03-23 09:47:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:47:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a example, and there's a example, and it's a lot of life.
2022-03-23 09:47:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:47:55 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to do it, and we're going to do it's not just just just just a little bit of what we're going to do.
2022-03-23 09:47:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:48:01 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the united states, in the united states, in the most people, in the most people, in the most people, in the most people, in the most people, in the most people, and in the most people, in the most people,
2022-03-23 09:48:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:06 | INFO | fairseq.tasks.translation | example hypothesis: some of these are some of some of these things, but they're going to see the same time, but it's not a lot of course, but if you're going to look at the same time, but it's a lot of the same time, they're going to be able to go on the same time, but they're going to see the
2022-03-23 09:48:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:13 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to take the brain, we can see that we can see that we can see the world, and then we can see that we can see the brain can see that we can see that we can see the brain can see the world is a lot of the world, and then we can see that we can see that we can see that we can see that we can see the end of the world can see the world is a lot of the
2022-03-23 09:48:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example hypothesis: one: one: one: there's one: "you know," you know, "you know," you know, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "you're going to say," well, "you're going to say," you're going to say, "you're going to say," you know, "you're going to say," "you're going to say," you know, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you know," you know, "you know," it's one of the first one of the first one of the first one of the
2022-03-23 09:48:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:23 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, there's a lot of course, if we're going to be a lot of the world, we're going to do that we're going to be a lot of the world, we're going to do that we're going to be a lot of the world, and then we're going to do that we're going to be able to do that we're going to be a lot of the world, and then we're going to be a lot of the world, and then we're going to be a lot of a lot of the way that we're going to do that we're going to do that we're going to do that we're going to do that we're going to be a lot of a lot of the way that we're going to be a lot of the same time that we're going to be a lot of the world, and then we're going to do that we're going to do that we're going to be able to be a lot of the way that we're going to be a lot of
2022-03-23 09:48:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:23 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.347 | nll_loss 6.947 | ppl 123.38 | bleu 3.34 | wps 3534.3 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.34
2022-03-23 09:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:48:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:48:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:48:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.34) (writing took 1.7440814430010505 seconds)
2022-03-23 09:48:24 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:48:24 | INFO | train | epoch 009 | loss 10.483 | nll_loss 7.458 | ppl 175.84 | wps 38934 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 0.647 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 897
2022-03-23 09:48:25 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:48:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:48:54 | INFO | train_inner | epoch 010:     92 / 157 loss=10.401, nll_loss=7.273, ppl=154.71, wps=29920, ups=1.19, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=0.611, loss_scale=4, train_wall=31, gb_free=14.3, wall=926
2022-03-23 09:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:17 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the middle of the way.
2022-03-23 09:49:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:49:21 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most most most of the most most most of the most.
2022-03-23 09:49:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:25 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new new new york.
2022-03-23 09:49:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a pop, where where you're going to get up, and where you're going to get up with the right.
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:49:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to see a few years, and so we're going to see what's going to do.
2022-03-23 09:49:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:49:39 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like the people, and the people who are a lot of people, and it's a lot of people, and for a lot of people, and that's a lot of people, and for a lot of people in the people.
2022-03-23 09:49:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of them, but if you're going to see, but if you're going to go, but if you're going to get it, but it's not going to get it, but if you don't have to get it, but it, but it, but if you don't have to get it.
2022-03-23 09:49:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:49:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the brain, and we can see that, and we can get a little bit of the brain, and we can see the brain, and then we can see the brain, and then we can get a little bit of the brain, and all the brain, and the brain, and then we can see that's going to be able to be able to take the brain, and the brain, and all of the brain, and the
2022-03-23 09:49:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:49:58 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the one, and it's going to say, "and it's going to say," and if we're going to say, "well," well, "you know," well, "well," well, "you know," well, "well," well, "well," well, "you know," well, "you know," well, "well," well, "well," well, "you know," you know, "you know," you know, "well," well, "well," well, "well," you're going to say, "well," well, "well," well, "you know," well, "you know," you're going to get a very good for me, "you know," you know, "you know," well, "
2022-03-23 09:49:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example hypothesis: now, it's going to be a lot, and if we're going to get a lot of the world, and if we're going to get a lot of the way that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:00 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.207 | nll_loss 6.579 | ppl 95.58 | bleu 4.89 | wps 3832 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 4.89
2022-03-23 09:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:50:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:50:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:50:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 4.89) (writing took 1.7870014049985912 seconds)
2022-03-23 09:50:02 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:50:02 | INFO | train | epoch 010 | loss 10.367 | nll_loss 7.199 | ppl 146.96 | wps 40402 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 0.624 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 995
2022-03-23 09:50:02 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:50:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:13 | INFO | train_inner | epoch 011:     35 / 157 loss=10.332, nll_loss=7.122, ppl=139.28, wps=31157, ups=1.25, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=0.655, loss_scale=4, train_wall=30, gb_free=13.4, wall=1006
2022-03-23 09:50:45 | INFO | train_inner | epoch 011:    135 / 157 loss=10.221, nll_loss=6.87, ppl=116.98, wps=81976.5, ups=3.21, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=0.617, loss_scale=4, train_wall=31, gb_free=13.3, wall=1037
2022-03-23 09:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:50:55 | INFO | fairseq.tasks.translation | example hypothesis: we had these pp in the way.
2022-03-23 09:50:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:50:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most most most most most of here.
2022-03-23 09:50:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:03 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new two two two two two of two days.
2022-03-23 09:51:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:51:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a human food, where where are going to go and get a little bit.
2022-03-23 09:51:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:51:12 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just a few few years on his head, and what's going to do.
2022-03-23 09:51:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:51:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like the people who have been able to be a lot of people who are going to be a few years.
2022-03-23 09:51:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:20 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are some of the water, but if you don't need to be able to be able to be able to do it.
2022-03-23 09:51:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use this information with a kind of information, and we can use it in the way that we're going to create a kind of information.
2022-03-23 09:51:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:30 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reason that it's very interesting, and it's going to be able to say, "i'm going to tell you that it's going to tell you that we're going to say," well, "if we're going to say," well, "we're going to say," we're going to say, "well," well, "we're going to say that we're going to tell you know that we're going to say," well, "well," well, "well," well, "well," well, "we're going to say," well, "well, if we're going to say that we're going to tell you know that we're going to tell you know," well, "we're going to go to say," we're going to say, "well," well, "you know,"
2022-03-23 09:51:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:32 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still still a mother, and if we're going to be a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world.
2022-03-23 09:51:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:32 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.094 | nll_loss 6.272 | ppl 77.3 | bleu 7.56 | wps 4453 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 7.56
2022-03-23 09:51:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:51:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:51:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 7.56) (writing took 1.769008095987374 seconds)
2022-03-23 09:51:34 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:51:34 | INFO | train | epoch 011 | loss 10.25 | nll_loss 6.935 | ppl 122.37 | wps 42979.4 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 0.63 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1087
2022-03-23 09:51:34 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:51:59 | INFO | train_inner | epoch 012:     78 / 157 loss=10.185, nll_loss=6.795, ppl=111.06, wps=33704.2, ups=1.35, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=0.625, loss_scale=4, train_wall=30, gb_free=14, wall=1112
2022-03-23 09:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:27 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 09:52:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:52:30 | INFO | fairseq.tasks.translation | example hypothesis: that's the right.
2022-03-23 09:52:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:52:34 | INFO | fairseq.tasks.translation | example hypothesis: these are new new york.
2022-03-23 09:52:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:52:39 | INFO | fairseq.tasks.translation | example hypothesis: so for example, there's the chinese chinese chinese chinese chinese food, where they're going to be going to get with and repppy.
2022-03-23 09:52:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:52:43 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that a few few days of his head, and what's going to understand what's going on on on.
2022-03-23 09:52:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:52:48 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the mamamating people like the most of the most people who found the number of the number of the number, and this is a few years.
2022-03-23 09:52:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:52:52 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of them are going to see in the top, but if you don't need to go to the water, if you don't need to have the energy, and if you need to need to have the energy, you need to have the energy and the energy, you need to need to need to have the energy.
2022-03-23 09:52:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this information, we can use this information, we can get to a kind of information, and we can use the information that we can get the information, and we can use it into the structure, and that's all the structure of the information, and all of the information, and all of the information, and all of the information, and all of the information that's all of the structure of the information, and all the information
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:04 | INFO | fairseq.tasks.translation | example hypothesis: okay, one of the reasons that it's interesting, and it's interesting for me to make me, "you know," you know, "if you're going to say," if you're going to say, "you're going to say," well, "you're going to say," well, "if you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you know, "you're going to say," and then you know, "you're going to say," you're going to say, "well," well, "well," well, "well," well, "well," well, "you're going to say," you're going to say, "you're going to say," you're going to say that
2022-03-23 09:53:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:07 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's still still still the mother of the mother, and we've got a lot of the work that we had to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if
2022-03-23 09:53:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:07 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.975 | nll_loss 5.962 | ppl 62.32 | bleu 8.23 | wps 4090.9 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 8.23
2022-03-23 09:53:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:53:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:53:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 8.23) (writing took 1.7651919120107777 seconds)
2022-03-23 09:53:09 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:53:09 | INFO | train | epoch 012 | loss 10.129 | nll_loss 6.671 | ppl 101.87 | wps 41681.5 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 0.624 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1181
2022-03-23 09:53:09 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:16 | INFO | train_inner | epoch 013:     21 / 157 loss=10.073, nll_loss=6.546, ppl=93.43, wps=32666.8, ups=1.3, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=0.651, loss_scale=4, train_wall=30, gb_free=13.9, wall=1188
2022-03-23 09:53:47 | INFO | train_inner | epoch 013:    121 / 157 loss=10.008, nll_loss=6.402, ppl=84.59, wps=80638.6, ups=3.19, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=0.592, loss_scale=4, train_wall=31, gb_free=13.6, wall=1220
2022-03-23 09:53:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:01 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppy in the clinic.
2022-03-23 09:54:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of ha, most of most of most of most of the most.
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will be a new way of two new new new york.
2022-03-23 09:54:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food where they're going to get with.
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:54:17 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a few ways on his head, and all of his mind.
2022-03-23 09:54:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:54:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamase people like this, the number of animals, and this is a number of animals, and this is the most important thing.
2022-03-23 09:54:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of those are in the brain, but it doesn't want to be able to go to the energy, and if you don't need your energy, and the energy.
2022-03-23 09:54:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start from this structure, we can start able to start with a structure of the structure, and that's the structure of the structure of the structure.
2022-03-23 09:54:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:33 | INFO | fairseq.tasks.translation | example hypothesis: th: the reasons it's interesting, and it's interesting for me, "well, you know," well, "well," you know, "you've got to say," well, "you know," well, "you'll say," well, "well," well, "well," you're going to tell you know, "you know," you've got to tell you know, "you know," you know, "you've got to say," you have a long time. "
2022-03-23 09:54:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still the mother of the mother, and we've got to be part of our work, and we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a machine.
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:34 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.866 | nll_loss 5.656 | ppl 50.42 | bleu 11.25 | wps 5000.6 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 11.25
2022-03-23 09:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:54:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 11.25) (writing took 1.7498730619845446 seconds)
2022-03-23 09:54:36 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:54:36 | INFO | train | epoch 013 | loss 9.997 | nll_loss 6.38 | ppl 83.28 | wps 45179.7 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 0.603 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1269
2022-03-23 09:54:36 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:54:57 | INFO | train_inner | epoch 014:     64 / 157 loss=9.933, nll_loss=6.239, ppl=75.54, wps=35857.3, ups=1.44, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=0.587, loss_scale=4, train_wall=30, gb_free=14, wall=1289
2022-03-23 09:55:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:29 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppure in the clinic.
2022-03-23 09:55:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:55:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the car of the doha, ha, most of most of the most of the most of here.
2022-03-23 09:55:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:55:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ores that are going to create two new ways.
2022-03-23 09:55:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:55:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese food, where they're going to get with, and they're going to get.
2022-03-23 09:55:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:55:46 | INFO | fairseq.tasks.translation | example hypothesis: it's sure that we're not just just a couple of electrodes on his head on his head, and what all of his mind is.
2022-03-23 09:55:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:55:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamaking people like the responsibility for the number of people, the number of animals, and the number of animals had become a lot.
2022-03-23 09:55:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of those are the magic of the lines, but in the top of the color, but if you don't have the energy, and the energy is the energy of the energy.
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:55:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the structure of this structure, we can start to start with one of the design, we can start to start with the structure of the structure, and that's a whole structure.
2022-03-23 09:55:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:02 | INFO | fairseq.tasks.translation | example hypothesis: rth: one of the reasons it's interesting, and it's interesting for me to do this for tedtalk to me, "oh," you know, "when you've got a lot of time," and then we've been working with this time. "
2022-03-23 09:56:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:04 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to be the mother's mother, and one part of the design of the design that we had to be a lot of the world, and if we had to see that it was a global system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:56:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:04 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.737 | nll_loss 5.34 | ppl 40.51 | bleu 13.7 | wps 4682.9 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 13.7
2022-03-23 09:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:56:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:56:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 13.7) (writing took 1.813180678000208 seconds)
2022-03-23 09:56:06 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:56:06 | INFO | train | epoch 014 | loss 9.866 | nll_loss 6.092 | ppl 68.2 | wps 43834.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 0.568 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1359
2022-03-23 09:56:06 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:56:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:09 | INFO | train_inner | epoch 015:      7 / 157 loss=9.813, nll_loss=5.977, ppl=62.97, wps=35275.6, ups=1.38, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=0.54, loss_scale=4, train_wall=30, gb_free=13.9, wall=1362
2022-03-23 09:56:40 | INFO | train_inner | epoch 015:    107 / 157 loss=9.748, nll_loss=5.833, ppl=57.01, wps=80777.8, ups=3.21, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=0.583, loss_scale=4, train_wall=31, gb_free=13.9, wall=1393
2022-03-23 09:56:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:56:59 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the hospital.
2022-03-23 09:56:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of the doha, most of the most of you know here.
2022-03-23 09:57:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:57:07 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to make the two new ways.
2022-03-23 09:57:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:57:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where they're going to do with the legs, and they're going to be dididice.
2022-03-23 09:57:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a couple of electrodes on his head, and what all of his mind are on the mind.
2022-03-23 09:57:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamake, like the responsibility of the responsibility, the number of animals, and this is a number of animals, and this is a conviation for the revian.
2022-03-23 09:57:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are some of the magic lines in the field, but it doesn't like the alalty, if you don't need your energy, if you need your energy, you need your energy, you need the energy, and the energy.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start able to start able to start able to start able to start with a traditional form of the information, and we can start with the information, and the whole structure of the information.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for tedwomen -- that it's the best time to say, "oh, if you're going to give you the best revolution," the best revolution, "and then you're going to give you a long revolution," and then we've got a long revolution with you're going to give you a long revolution, "and then we've got a long time to give you a long revolution," oh, "well," you're working with you know, "oh," well, "well," well, "well," well, "well," you're going to give you're going to give you're going to give you know, "oh," oh, "oh," well, "well," well, "well," you've got a long time, "
2022-03-23 09:57:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the need to be the mother, and a big design of the design that we have to solve the airplane on our airplane, we had to solve a unique way that we had to be able to be able to be able to be able to be able to be able to be able to be able to be a unique system, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we were able to be able to be able to be able to be able to be able to be able to use the united states, if we were able to be able to be able to be able to be able to be able to be able to be able to be able to use the power the united states, and see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:57:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:36 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.601 | nll_loss 5.043 | ppl 32.97 | bleu 14.74 | wps 4432.7 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 14.74
2022-03-23 09:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:57:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 09:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 14.74) (writing took 1.746277611993719 seconds)
2022-03-23 09:57:38 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:57:38 | INFO | train | epoch 015 | loss 9.756 | nll_loss 5.847 | ppl 57.57 | wps 43013.2 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 0.56 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1451
2022-03-23 09:57:38 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:54 | INFO | train_inner | epoch 016:     50 / 157 loss=9.746, nll_loss=5.821, ppl=56.55, wps=34235.7, ups=1.35, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=0.522, loss_scale=4, train_wall=31, gb_free=14.3, wall=1467
2022-03-23 09:58:25 | INFO | train_inner | epoch 016:    150 / 157 loss=9.626, nll_loss=5.559, ppl=47.16, wps=79988.9, ups=3.24, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.52, loss_scale=4, train_wall=30, gb_free=14.5, wall=1498
2022-03-23 09:58:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:31 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 09:58:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:58:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha that most of you know.
2022-03-23 09:58:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ances.
2022-03-23 09:58:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where you're going to get with your legs.
2022-03-23 09:58:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:58:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to make some electrodes on his head and understand what all of his mind.
2022-03-23 09:58:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:58:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for people, the number of animals and the number of animals.
2022-03-23 09:58:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:58:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are magnetic lines in the field, but they're not going to move when they need their energy, and they need their energy.
2022-03-23 09:58:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this reflection, we can start to start with a traditional face, and we can start able to start able to start able to start the shape of the shape and the information.
2022-03-23 09:58:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting for me to be here for tedly... "
2022-03-23 09:59:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:01 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother, and one part of the design of the work that we've had to solve is that we had to solve a unique result of the world.
2022-03-23 09:59:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:01 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.591 | nll_loss 4.99 | ppl 31.77 | bleu 13.44 | wps 5506.6 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 14.74
2022-03-23 09:59:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:59:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 09:59:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 09:59:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 13.44) (writing took 0.7568805819901172 seconds)
2022-03-23 09:59:02 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:59:02 | INFO | train | epoch 016 | loss 9.65 | nll_loss 5.613 | ppl 48.94 | wps 47049.2 | ups 1.87 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 0.533 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1535
2022-03-23 09:59:02 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:31 | INFO | train_inner | epoch 017:     93 / 157 loss=9.561, nll_loss=5.419, ppl=42.77, wps=38159.5, ups=1.51, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=0.523, loss_scale=4, train_wall=31, gb_free=14.9, wall=1564
2022-03-23 09:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:59:55 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic clinic in the clinic clinic.
2022-03-23 09:59:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha that most of the most of you know here.
2022-03-23 10:00:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create the two new loads of the two new things that are going to be able.
2022-03-23 10:00:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:00:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food, where happy legs are going to be happy, and they're going to be defeeding.
2022-03-23 10:00:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all of the thoughts are on your mind.
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like the responsibility for people who grew up the number of animals, and this is a process for the world.
2022-03-23 10:00:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:22 | INFO | fairseq.tasks.translation | example hypothesis: first of first, some of these are bols of magnetic lines, but in the field, you don't have a lot of energy, if you need your energy, you need the energy, and you need to move your energy.
2022-03-23 10:00:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start able to start with a traditional face, we can start able to start able to start able to start with a traditional form of the information, and that's the whole structure of the structure of the structure, and the whole structure of the information.
2022-03-23 10:00:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to do with tedwomen, and then you know, "you know, you know, you know, you know, you know," the best thing that you're going to be able to be able to be able to be in this revolution, "and then, if you've been working with you've been working with you've been working with you've been working with you know, you've been working with you have a long time," and then you know, "you've been able to be able to be able to be able to be able to be able to be able to be able to do with you've been able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:00:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, unfortunately, the mother is still the invention of the invention, and a big design of design that we've had to solve on the airplane, that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see in a unique with a unique with a unique, or a unique, or a unique, and see that if you in a unique, or a unique, and see the ground, or a unique, if you in the ground, and see the ground, if you're in the ground, and
2022-03-23 10:00:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:35 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.463 | nll_loss 4.717 | ppl 26.29 | bleu 15.26 | wps 4165.1 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 15.26
2022-03-23 10:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 10:00:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:00:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 15.26) (writing took 1.7428205510077532 seconds)
2022-03-23 10:00:36 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 10:00:36 | INFO | train | epoch 017 | loss 9.548 | nll_loss 5.389 | ppl 41.9 | wps 41758.1 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.511 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1629
2022-03-23 10:00:37 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 10:00:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:48 | INFO | train_inner | epoch 018:     36 / 157 loss=9.514, nll_loss=5.312, ppl=39.72, wps=32810.8, ups=1.3, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.521, loss_scale=4, train_wall=30, gb_free=14.3, wall=1641
2022-03-23 10:01:20 | INFO | train_inner | epoch 018:    136 / 157 loss=9.437, nll_loss=5.147, ppl=35.43, wps=79758.2, ups=3.21, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.458, loss_scale=4, train_wall=31, gb_free=14.2, wall=1672
2022-03-23 10:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:30 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinic.
2022-03-23 10:01:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most know here.
2022-03-23 10:01:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:01:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to be the two new.
2022-03-23 10:01:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:01:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where happy legs are going to be in with salt and pink.
2022-03-23 10:01:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:01:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all of his thoughts are on the way.
2022-03-23 10:01:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:01:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammers like the responsibility for the lives of life, the number of animals, and that's one of the animals.
2022-03-23 10:01:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloop of the magnetic field, but the sulal, it doesn't like that, if you're going to move your energy, if you need your energy, you need your energy, and that's what you need.
2022-03-23 10:01:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start with a traditional face of the big congress, and the shape of the structure, and there's a structure of the structure, and the information that all the structure of the structure and the structure of this structure, and all the structure of the structure of this reflection is going to be able to be able to be able to be able to be able
2022-03-23 10:01:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting to be here in tedwomen, and then it was that... "
2022-03-23 10:02:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of the invention, and a big part of the design of the design that we're in our airplane, is a result of it, that we had to solve the unique problems that we had to be able to be able to be able to see it in the ground, or that it's a certain way to be able to be able to be able to see that if you're going to see the power of a specific, or to see that it is to be able to be able to be able to see the power of a very specific, or to be able to be able to be able to see that we're in the power of a specific, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:07 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.322 | nll_loss 4.422 | ppl 21.43 | bleu 19.89 | wps 4474.3 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 19.89
2022-03-23 10:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 10:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:02:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 19.89) (writing took 1.7796888969896827 seconds)
2022-03-23 10:02:08 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 10:02:08 | INFO | train | epoch 018 | loss 9.444 | nll_loss 5.163 | ppl 35.83 | wps 42935.7 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.469 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1721
2022-03-23 10:02:09 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 10:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:34 | INFO | train_inner | epoch 019:     79 / 157 loss=9.376, nll_loss=5.016, ppl=32.35, wps=34409.4, ups=1.34, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.437, loss_scale=4, train_wall=31, gb_free=14, wall=1747
2022-03-23 10:02:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:02 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 10:03:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most know here.
2022-03-23 10:03:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden lows that make the two new sweet.
2022-03-23 10:03:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where happy legs will be degraded with salz.
2022-03-23 10:03:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:03:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts are.
2022-03-23 10:03:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the wild, the number of animals, and this is a foundation of natural conservation.
2022-03-23 10:03:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloods of magnetic field, but the suck may not move when they need their energy, and so the sucks.
2022-03-23 10:03:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, the big congress of the face of the face of the face and reform the information through the structure of the structure, the whole structure of this structure, and all the portion of these ports are able.
2022-03-23 10:03:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure for me to be here at tedwomen, is that... yes, when someone said, "the best one of you start to tell you about men, and then we've been working on a table revolution, and then we've been doing it.
2022-03-23 10:03:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a great part of the design of the design work that we're at the plane, is a result of the unique problems that we had to solve the problems of the ground -- all the way to be able to be able to be able to be able to see that there's a transfer to be a transmit, or that it's a very large part of the power of the power of the power of the power of the aircraft, and that we're going to be a large part of the tools that we're going to see, or that we're going to see, or that we're going to be a large, or that we're going to be a large, or that we're going to be able to see, or that we're going to be a large, or that we're in our design, to be able to be a high-high-high-high-tech.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:36 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.27 | nll_loss 4.272 | ppl 19.31 | bleu 20.7 | wps 4854.1 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 20.7
2022-03-23 10:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 10:03:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:03:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:03:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 20.7) (writing took 1.7725437339977361 seconds)
2022-03-23 10:03:37 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 10:03:37 | INFO | train | epoch 019 | loss 9.339 | nll_loss 4.936 | ppl 30.61 | wps 44413.1 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.452 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1810
2022-03-23 10:03:38 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 10:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:45 | INFO | train_inner | epoch 020:     22 / 157 loss=9.298, nll_loss=4.847, ppl=28.79, wps=35058.2, ups=1.41, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.444, loss_scale=4, train_wall=30, gb_free=14.7, wall=1818
2022-03-23 10:04:17 | INFO | train_inner | epoch 020:    122 / 157 loss=9.251, nll_loss=4.745, ppl=26.82, wps=81362.5, ups=3.15, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.408, loss_scale=4, train_wall=31, gb_free=13.6, wall=1849
2022-03-23 10:04:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:31 | INFO | fairseq.tasks.translation | example hypothesis: we made these scores in the clinic.
2022-03-23 10:04:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of them.
2022-03-23 10:04:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to create the two new pigments.
2022-03-23 10:04:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:04:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are being done with salz and pink.
2022-03-23 10:04:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:04:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a couple of electrodes on his head and understand exactly what all of the thoughts are on the way.
2022-03-23 10:04:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:04:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the magia, as people took the responsibility for the wild, the number of animals grew up again, and this is a foundation of natural conservation in namibia.
2022-03-23 10:04:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:04:56 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bull of the magnetic field are starting in the inside of the inside of the inside, but the suicide may not move when they need their energy, and so the suck of the suile disorder.
2022-03-23 10:04:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start with a traditional face, the big consequence of the face of the face of the face of the face, and the basic information that makes all the ports of the ports of the ports and the ports.
2022-03-23 10:05:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it high-interesting and measure for me here in tedwomen, is that... in the best way, when somebody said to you, "in the best time," you're going to say, "you're going to give the men on a table and the men who say," if we're going to be able to be able to be able to be here, "to be here for you."
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're in our airplane was a result of them that we had to solve the unique problems that were connected to the ground -- all the way to a continent of the ground -- from a continent to a continent, and a big part of the things that we're going to be able to be able to be able to see that it is to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that if we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:07 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.197 | nll_loss 4.16 | ppl 17.88 | bleu 22.39 | wps 4499 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.39
2022-03-23 10:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 10:05:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:05:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.39) (writing took 1.8431172329874244 seconds)
2022-03-23 10:05:09 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 10:05:09 | INFO | train | epoch 020 | loss 9.243 | nll_loss 4.73 | ppl 26.54 | wps 43018.2 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.416 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1902
2022-03-23 10:05:09 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 10:05:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:30 | INFO | train_inner | epoch 021:     65 / 157 loss=9.179, nll_loss=4.592, ppl=24.12, wps=33879.7, ups=1.36, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.425, loss_scale=4, train_wall=30, gb_free=13.9, wall=1923
2022-03-23 10:05:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:06:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-23 10:06:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:11 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 10:06:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs will be served with salz.
2022-03-23 10:06:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 10:06:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:06:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the magia, how people have been taking responsibility for the wild, the number of animals, and this is a foundation for the natural protection in the namibia.
2022-03-23 10:06:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bull of the magnetic field, but the sucks like it, if they're moving, they don't need their energy, and so the suck disorders.
2022-03-23 10:06:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big constructions of the face and the basic shape, and they restore it through that information that information, and all the structure, and they put it all a structure and put it all the structure.
2022-03-23 10:06:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that you're doing it, and you know, for me, is to be here at tedwomen, and then you have a long time, you know, you know, when someone said, "you're going to tell you about the men," and if we're going to support you. "
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're in our plane, was a result of that we had to solve the unique problems that were connected to the ground -- everything from a variable system, and that we're going to be able to use it to be able to do it in the way that we're going to be able to do it, or that we're going to be able to be able to be able to be able to use it is to be able to be able to be able to be able to be able to be able to be able to be able to use a mechanism, if we're going to be able to be able to be able to be able to get a machine that, or that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:06:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:38 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.113 | nll_loss 4.014 | ppl 16.15 | bleu 23.55 | wps 4576.1 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.55
2022-03-23 10:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 10:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 23.55) (writing took 1.8188095889927354 seconds)
2022-03-23 10:06:40 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 10:06:40 | INFO | train | epoch 021 | loss 9.178 | nll_loss 4.589 | ppl 24.07 | wps 43466 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.423 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1993
2022-03-23 10:06:40 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 10:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:43 | INFO | train_inner | epoch 022:      8 / 157 loss=9.189, nll_loss=4.612, ppl=24.46, wps=33891.3, ups=1.37, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.427, loss_scale=4, train_wall=31, gb_free=13.9, wall=1996
2022-03-23 10:07:14 | INFO | train_inner | epoch 022:    108 / 157 loss=9.138, nll_loss=4.505, ppl=22.71, wps=79285.2, ups=3.22, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.43, loss_scale=4, train_wall=31, gb_free=13.8, wall=2027
2022-03-23 10:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these beetles in the clinic.
2022-03-23 10:07:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:07:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden dicks that are two new pigs.
2022-03-23 10:07:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frog legs are served with salz and pitcase.
2022-03-23 10:07:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are.
2022-03-23 10:07:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wild, the number of wild animals, and this is a foundation of natural protection.
2022-03-23 10:07:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example hypothesis: first, some bands of magnetic field in the inside, but they don't like the sulalous eggs when they're moving, and so the suick disorders of the magnetic disorder.
2022-03-23 10:07:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:08:00 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial face, which is the big constructions of the face and the basic shape of the information, and through the bottom of the information that makes the portion of all the ports of the ports and a structure of the portion of the portion of the face of the face.
2022-03-23 10:08:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that do it high-interesting and measure for me here at tedwomen, is that... well, when someone said, "well, it was the best thing that somebody said," and then said, "you know, if you're going to tell you about the men on a table," and then we're going to help you have a little bit of silly. "
2022-03-23 10:08:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in the airplane was a result of that we had to solve the unique problems that were connected to the ground, so it was on the ground -- everything from a continually refrightening, and it allows us to see that if you're in the aircraft, it was a very specific, or if you're in the air.
2022-03-23 10:08:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:07 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.079 | nll_loss 3.872 | ppl 14.64 | bleu 24.03 | wps 4816.8 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 24.03
2022-03-23 10:08:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 10:08:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:08:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:08:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 22 @ 3449 updates, score 24.03) (writing took 1.7716020289808512 seconds)
2022-03-23 10:08:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 10:08:09 | INFO | train | epoch 022 | loss 9.115 | nll_loss 4.456 | ppl 21.94 | wps 44384.5 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.402 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2082
2022-03-23 10:08:09 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 10:08:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:25 | INFO | train_inner | epoch 023:     51 / 157 loss=9.069, nll_loss=4.357, ppl=20.49, wps=35761.5, ups=1.4, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.329, loss_scale=4, train_wall=31, gb_free=13.8, wall=2098
2022-03-23 10:08:56 | INFO | train_inner | epoch 023:    151 / 157 loss=9.024, nll_loss=4.267, ppl=19.25, wps=81856.4, ups=3.22, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.399, loss_scale=4, train_wall=31, gb_free=13.8, wall=2129
2022-03-23 10:08:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:09:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:09:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden dicks that create the two new pigments.
2022-03-23 10:09:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where happy legs are served with salz and ppet.
2022-03-23 10:09:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 10:09:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for the wild, the number of wild animals grew back. and this is a foundation for natural protection in namibia.
2022-03-23 10:09:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bull of magnetic field are starting in the inside, but the superconductor doesn't like that if they're moving, because their movements need energy, and so the suckness of magnetic disorders.
2022-03-23 10:09:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:31 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional face that can start with the big constructions of the face, and the basic form of the face, and through that information that information that comes all the ports all the ports the portion of this reflection.
2022-03-23 10:09:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measure it for me to be here at tedwomen, is that... yes, in the best way, when someone said, "turn it into the men on a table and say," turn it to the men on a table and say, "when the truth starts to be here."
2022-03-23 10:09:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of design work that we're in our plane, was a result that we had to solve the unique problems that were connected to the ground that we had to solve it on the ground -- everything from a continent of the continent, and a big part of the design work that allows us to see in the aircraft to see in the aircraft, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 10:09:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:38 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.065 | nll_loss 3.848 | ppl 14.4 | bleu 24.73 | wps 4708.3 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 24.73
2022-03-23 10:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 10:09:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:09:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 24.73) (writing took 1.7675994219898712 seconds)
2022-03-23 10:09:39 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 10:09:39 | INFO | train | epoch 023 | loss 9.039 | nll_loss 4.297 | ppl 19.65 | wps 43676.5 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.372 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2172
2022-03-23 10:09:40 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 10:09:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:09 | INFO | train_inner | epoch 024:     94 / 157 loss=8.99, nll_loss=4.194, ppl=18.31, wps=34280.4, ups=1.37, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.349, loss_scale=4, train_wall=31, gb_free=13.8, wall=2202
2022-03-23 10:10:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:32 | INFO | fairseq.tasks.translation | example hypothesis: we put these bears in the clinic.
2022-03-23 10:10:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:10:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden dilocks that will be transmitted by two new pigs.
2022-03-23 10:10:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:10:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 10:10:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 10:10:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the maibia, like people's responsibility for the wild, the number of wild animals grew back again, and that's a foundation for natural protection in namibia.
2022-03-23 10:10:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines in the inside, but the superconductors don't like it, if they move their movements, and so the superconductor disorders.
2022-03-23 10:10:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial, which is the big constructions of the face and the basic form, and through that information that makes the whole portion and all the portion of the ports.
2022-03-23 10:11:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measuring to me here at tedwomen, is that... tweak, when someone said, "turn out to the men on a table and say," if the revolution starts to you. "
2022-03-23 10:11:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the invention, and a big part of the design work that we're at our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration to the refrigerator, or a refrigeration to the air.
2022-03-23 10:11:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:07 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.973 | nll_loss 3.632 | ppl 12.4 | bleu 26.75 | wps 4762.8 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.75
2022-03-23 10:11:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:11:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:11:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:11:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 26.75) (writing took 1.956883197010029 seconds)
2022-03-23 10:11:09 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:11:09 | INFO | train | epoch 024 | loss 8.976 | nll_loss 4.165 | ppl 17.94 | wps 44166 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.337 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2262
2022-03-23 10:11:09 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:11:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:21 | INFO | train_inner | epoch 025:     37 / 157 loss=8.932, nll_loss=4.072, ppl=16.82, wps=35566.5, ups=1.4, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.324, loss_scale=4, train_wall=31, gb_free=14, wall=2274
2022-03-23 10:11:52 | INFO | train_inner | epoch 025:    137 / 157 loss=8.965, nll_loss=4.145, ppl=17.69, wps=80053, ups=3.2, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.373, loss_scale=4, train_wall=31, gb_free=13.9, wall=2305
2022-03-23 10:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these bars in the clinic.
2022-03-23 10:12:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:12:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are two new pigs.
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 10:12:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 10:12:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for the wild, the number of wild animals grew back, and this is a basis for conservation in namibia.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field are caught in the inside, but the superconductor doesn't like that, if you're moving, because your movements need energy, and so the superconductor disorders.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructions of the face and the basic form, and the basic information that makes all the ports of the portion structure and all the fits a fold.
2022-03-23 10:12:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are very interesting and measured to me here at tedwomen is that -- well, when someone said, "turn on the future to you."
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable variation, and a system that allows us to refrigeration to a fluid system, to a fluid system that allows us to refrigeration to the refrigeration to a fluid, to the refrigeration, to a refrightening, to an aircraft, to a mechanism.
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:35 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.949 | nll_loss 3.613 | ppl 12.24 | bleu 26.81 | wps 4907.6 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 26.81
2022-03-23 10:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:12:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:12:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 25 @ 3920 updates, score 26.81) (writing took 1.9013783789996523 seconds)
2022-03-23 10:12:37 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:12:37 | INFO | train | epoch 025 | loss 8.939 | nll_loss 4.09 | ppl 17.04 | wps 44721.3 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.352 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2350
2022-03-23 10:12:37 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:12:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:03 | INFO | train_inner | epoch 026:     80 / 157 loss=8.887, nll_loss=3.98, ppl=15.78, wps=36039.2, ups=1.42, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.324, loss_scale=4, train_wall=30, gb_free=14, wall=2376
2022-03-23 10:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these tweep in the clinic.
2022-03-23 10:13:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:35 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that probably most of you know here.
2022-03-23 10:13:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that make two new pigs.
2022-03-23 10:13:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:13:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the road.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the may like people's responsibility for the wild, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bull of magnetic field lines in the inside, but the superconductor doesn't like it, if they're moving, because their movements need energy, and so the superconductor disorder.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face that gives the big constructions of the face and the basic form, and through the one of the one information that refits the whole porter structure and all the fits.
2022-03-23 10:13:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here in tedwomen is that we've already been supporting -- well, when someone said, "turn you to the men on your table and say," if the revolution starts to support you, "the truth is that we've already been supported for you for a long time."
2022-03-23 10:14:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we are at our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a fluid system that allows us to refrigergeration to be able to use a refrigeration of the aircraft, or a deployment machine in the same way that we're going to be able to be able to use the same time, to be a refugee, to be a global global global global global traffic.
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:05 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.888 | nll_loss 3.474 | ppl 11.11 | bleu 28.31 | wps 4743.8 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.31
2022-03-23 10:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:14:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:14:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.31) (writing took 1.7981648959976155 seconds)
2022-03-23 10:14:07 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:14:07 | INFO | train | epoch 026 | loss 8.885 | nll_loss 3.977 | ppl 15.75 | wps 43946.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.335 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2440
2022-03-23 10:14:07 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:15 | INFO | train_inner | epoch 027:     23 / 157 loss=8.852, nll_loss=3.911, ppl=15.04, wps=34549.8, ups=1.38, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.322, loss_scale=4, train_wall=30, gb_free=14.8, wall=2448
2022-03-23 10:14:46 | INFO | train_inner | epoch 027:    123 / 157 loss=8.854, nll_loss=3.914, ppl=15.07, wps=80598.7, ups=3.22, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.313, loss_scale=4, train_wall=31, gb_free=13.6, wall=2479
2022-03-23 10:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:15:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:15:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to translate two new pigs.
2022-03-23 10:15:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:15:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:15:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature of people's responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 10:15:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines in the inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:15:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can start with the big constraints of the face and the basic shape, and through the one of the themes of all the ports structure and all the fits.
2022-03-23 10:15:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... well, in the striking dinner, it was best embedded when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "
2022-03-23 10:15:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our plane was the result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and a refrigeration system that allows us to be refrigergerator, or a refrigeration system that it allows us to see, that it allows us to see the refrigeration of a refrigeration, or a mechanism, if you can be able to be able to see the refrigergerator, or a progressive, or a machine to see the refrigergergerator, if you're going to see the propheartwork, or the propheartwork, or the propelled, you're going to see the propelled, or a very specific, or the prophecy system that you're going to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 10:15:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:35 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.878 | nll_loss 3.432 | ppl 10.79 | bleu 28.84 | wps 4736.5 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.84
2022-03-23 10:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:15:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:15:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:15:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 27 @ 4234 updates, score 28.84) (writing took 1.80222554600914 seconds)
2022-03-23 10:15:37 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:15:37 | INFO | train | epoch 027 | loss 8.835 | nll_loss 3.874 | ppl 14.66 | wps 44086.1 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.303 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2529
2022-03-23 10:15:37 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:58 | INFO | train_inner | epoch 028:     66 / 157 loss=8.807, nll_loss=3.818, ppl=14.1, wps=34808.1, ups=1.4, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.303, loss_scale=4, train_wall=30, gb_free=14.7, wall=2550
2022-03-23 10:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:16:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will overwrite two new pigs.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the corn like people's responsibility for the wild, the number of wild animals grew back again, and that's a basis for natural protection in namibia.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it, if they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:16:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:16:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constructions of the face, and the basic shape, and through the one of the information that contains the whole portion structure and all the fits a fold.
2022-03-23 10:16:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measurement for me here at tedwomen is that -- well, in the striking dinner, it was best embedded as someone said, "turn to men on your table and say," if the revolution begins, we'll support you. '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"we've already supporting the truth is that we've already supported you've already supported you've already supported you've already supported you know, we've already supported you know, we've already supported you've already supported you know, we've already supported for a long time."
2022-03-23 10:17:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane is the most staggering, which is a result that we had to solve the unique problems that were connected to operating the ground -- everything from a continuous variable variation and a system that allows us to use liquid refrigeration and a refrigeration system that allows us to use it to refrigeration, or the refrightening or to see the aircraft, if you're either if you're going to be able to see the prophecy, you're going to be able to see the fly, you're going to be able to have to be able to be able to see the propheartwork, or the fly, if you're going to be able to have to have to have to have to have to have to have to have to see the propeller, or to be able to be able to be able to be able to be able to be able to see the
2022-03-23 10:17:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:05 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.817 | nll_loss 3.358 | ppl 10.25 | bleu 29.97 | wps 4666.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.97
2022-03-23 10:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:17:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.97) (writing took 1.7585839290113654 seconds)
2022-03-23 10:17:06 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:17:06 | INFO | train | epoch 028 | loss 8.797 | nll_loss 3.797 | ppl 13.9 | wps 43949.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.312 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2619
2022-03-23 10:17:07 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:17:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:10 | INFO | train_inner | epoch 029:      9 / 157 loss=8.806, nll_loss=3.816, ppl=14.09, wps=34965.9, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.331, loss_scale=4, train_wall=30, gb_free=13.6, wall=2622
2022-03-23 10:17:41 | INFO | train_inner | epoch 029:    109 / 157 loss=8.764, nll_loss=3.732, ppl=13.29, wps=80568.3, ups=3.21, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.3, loss_scale=4, train_wall=31, gb_free=13.6, wall=2654
2022-03-23 10:17:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:18:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:18:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:18:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:18:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are served with salz and pills.
2022-03-23 10:18:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:18:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for the wild, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:18:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorders.
2022-03-23 10:18:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the big constructions of the facial and the basic form, and then refers it through that information that refers the whole portion structure and all folds a fold.
2022-03-23 10:18:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:32 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that was very interesting and measured for me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn to men on your table and tell them," if the revolution starts to support you, we've already supported you for you for a long time. "
2022-03-23 10:18:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are at our stump, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation and a refrigeration system that allows us to stop a refrigerator in the aircraft, or if you see the most unique problems that we have to be able to be able to be able to do, or the prophecy of a mechanism.
2022-03-23 10:18:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:35 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.804 | nll_loss 3.334 | ppl 10.09 | bleu 30.23 | wps 4710.9 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.23
2022-03-23 10:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:18:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.23) (writing took 1.7532660569995642 seconds)
2022-03-23 10:18:36 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:18:36 | INFO | train | epoch 029 | loss 8.764 | nll_loss 3.733 | ppl 13.29 | wps 43867.6 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.311 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2709
2022-03-23 10:18:37 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:18:53 | INFO | train_inner | epoch 030:     52 / 157 loss=8.756, nll_loss=3.713, ppl=13.11, wps=34654, ups=1.38, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.308, loss_scale=4, train_wall=30, gb_free=13.9, wall=2726
2022-03-23 10:19:24 | INFO | train_inner | epoch 030:    152 / 157 loss=8.713, nll_loss=3.629, ppl=12.37, wps=81443, ups=3.22, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.266, loss_scale=4, train_wall=31, gb_free=14.7, wall=2757
2022-03-23 10:19:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:19:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:19:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that make two new pigs overwrite.
2022-03-23 10:19:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pill suitcase.
2022-03-23 10:19:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:19:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:19:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the mapping of people's responsibility for the wild, the number of wildlife animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:19:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnet field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:19:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constructions of the face and the basic shape, and through that one of the information that refers the whole portion structure and all the fits.
2022-03-23 10:19:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that's very interesting and measuring it to me here at tedwomen is that... well, in striking dinner, it's best put it together when someone said, "turn to men on your table and tell you," if the revolution starts to support you, "we've already been supporting you for a long time."
2022-03-23 10:20:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our aircraft was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to stop in the aircraft to a particular vehicle, to a particular deal, or to the decrease, if you're going to be able to be able to be able to use that, or to use the same as you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the same.
2022-03-23 10:20:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:03 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.781 | nll_loss 3.302 | ppl 9.86 | bleu 30.14 | wps 4849.6 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.23
2022-03-23 10:20:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:20:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt (epoch 30 @ 4705 updates, score 30.14) (writing took 0.8161172510008328 seconds)
2022-03-23 10:20:04 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:20:04 | INFO | train | epoch 030 | loss 8.724 | nll_loss 3.648 | ppl 12.53 | wps 44982.4 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.28 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2797
2022-03-23 10:20:05 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:20:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:35 | INFO | train_inner | epoch 031:     95 / 157 loss=8.712, nll_loss=3.625, ppl=12.34, wps=36266.2, ups=1.42, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.296, loss_scale=4, train_wall=31, gb_free=13.6, wall=2828
2022-03-23 10:20:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:20:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:20:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 10:21:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:05 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-23 10:21:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:21:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:21:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example hypothesis: and it's like people's responsibility for the wildlife, the number of animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 10:21:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:21 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:21:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that gives the great constructions of the face and restore the basic shape, and recover it through that information that fits the whole portion structure and all the fits.
2022-03-23 10:21:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's highly interesting and measured for me to be here at tedwomen is that... well, in striking dinner, it was the best thing to do when somebody said, "turn you to the men to your table and say," 'if the revolution begins, then we support you. "'" '' "'the truth is that we've already been supporting you for a long time."
2022-03-23 10:21:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a refrigeration system that allows us to stop in our airplane, to be able to use a very staggressive traffic, or to use the most specific deal with the most progressive, to be able to be able to be able to be able to be able to be able to be able to be able to be able to use of a progressive, to use of a mechanical problems that if you to use of a progrgrgrgrgressed that you to be able to use of a mechanism, the most specific, or the most prophearable to be the most prophecy, the most prophecy, that you can either be able to be able to be able to see the same mechanism, that you can either get the
2022-03-23 10:21:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:32 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.75 | nll_loss 3.252 | ppl 9.53 | bleu 30.73 | wps 4721.4 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.73
2022-03-23 10:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:21:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.73) (writing took 1.8014962619927246 seconds)
2022-03-23 10:21:34 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:21:34 | INFO | train | epoch 031 | loss 8.704 | nll_loss 3.608 | ppl 12.19 | wps 44121.2 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.288 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2887
2022-03-23 10:21:34 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:21:46 | INFO | train_inner | epoch 032:     38 / 157 loss=8.67, nll_loss=3.537, ppl=11.61, wps=34772.7, ups=1.4, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.27, loss_scale=4, train_wall=30, gb_free=14.3, wall=2899
2022-03-23 10:22:18 | INFO | train_inner | epoch 032:    138 / 157 loss=8.68, nll_loss=3.562, ppl=11.81, wps=80913.8, ups=3.2, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.297, loss_scale=4, train_wall=31, gb_free=14.4, wall=2930
2022-03-23 10:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:22:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:22:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that are going to overwrite two new pigs.
2022-03-23 10:22:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pill suitcase.
2022-03-23 10:22:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:22:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:22:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:22:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:22:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:22:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:22:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic shape, and recovery it through the one of those information that refers the whole portion structure and all the fits.
2022-03-23 10:22:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:22:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured, for me here at tedwomen, is that... well, in striking dinner, it was best summarized when somebody said, "turn you to your table and tell you, 'if the revolution begins, we support you.' '' '' 'we love you for this time, we've already started with you for a long time, and then we've started with you."
2022-03-23 10:22:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is the most stumble, was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variation and a refrigeration system that allows us to stop a machine in the aircraft, until gosh, to a particular time you're in the ground, or if you're going to be able to do it, or if you're going to see it, you're on, you're in the ground, you're going to see it, you're going to see it, you're on, you're going to be able to be able to be able to be able to be able to be able to see it, you're going to be able to see it, you're going to be able to see it, you're going to be able to be able to be able to be able to be able to see it, you know, you know, you know, you're
2022-03-23 10:23:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:02 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.75 | nll_loss 3.2 | ppl 9.19 | bleu 31.04 | wps 4721.8 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.04
2022-03-23 10:23:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:23:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:23:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 32 @ 5019 updates, score 31.04) (writing took 1.8447329530026764 seconds)
2022-03-23 10:23:03 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:23:03 | INFO | train | epoch 032 | loss 8.673 | nll_loss 3.546 | ppl 11.68 | wps 44052.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.288 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2976
2022-03-23 10:23:04 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:30 | INFO | train_inner | epoch 033:     81 / 157 loss=8.632, nll_loss=3.463, ppl=11.03, wps=34739.1, ups=1.39, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.285, loss_scale=4, train_wall=30, gb_free=14, wall=3003
2022-03-23 10:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:23:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:23:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 10:24:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks deals that create two new pigs.
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pill suitcase.
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people took responsibility for the wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and the superconductor disorder.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape, and through the one of those information that refers the whole portion structure and all the fits.
2022-03-23 10:24:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured, for me here at tedwomen, is that... well, in the striking dinner, it was best summarized when someone said, "turn you to the men on your table, and say," if the revolution starts supporting you. "'"' the truth is that we've been supporting you for this long time. "
2022-03-23 10:24:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention is still the mother of the invention, and a big part of the design work that we're on on our airplane is the result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in the mold traffic, to a specific vehicle, or if you see the prophecy of a mechanism.
2022-03-23 10:24:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:33 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.709 | nll_loss 3.206 | ppl 9.23 | bleu 32.01 | wps 4737 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.01
2022-03-23 10:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:24:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:24:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:24:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.01) (writing took 1.8376676269981544 seconds)
2022-03-23 10:24:35 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:24:35 | INFO | train | epoch 033 | loss 8.648 | nll_loss 3.495 | ppl 11.27 | wps 43318.5 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.277 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3067
2022-03-23 10:24:35 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:24:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:43 | INFO | train_inner | epoch 034:     24 / 157 loss=8.663, nll_loss=3.524, ppl=11.51, wps=34385.7, ups=1.37, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.279, loss_scale=4, train_wall=31, gb_free=13.8, wall=3076
2022-03-23 10:25:14 | INFO | train_inner | epoch 034:    124 / 157 loss=8.619, nll_loss=3.437, ppl=10.83, wps=80180.6, ups=3.19, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.287, loss_scale=4, train_wall=31, gb_free=13.7, wall=3107
2022-03-23 10:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:25:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:25:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of dilocks that make two new pigs overwrite.
2022-03-23 10:25:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pill suitcase.
2022-03-23 10:25:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:25:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 10:25:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, like the people who took responsibility for the wildlife, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 10:25:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it, if they're moving, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:25:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic shape, and through the one of the information that refers the whole portion of the porting structure and all the floods.
2022-03-23 10:25:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn you to the men on your table and tell them," if the revolution begins to support you, "if the truth, then we support you." "" "" "the truth, love, we've already been supporting you for this topic for a long time." "" "
2022-03-23 10:26:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane is the result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to be refrigerated in our aircraft, and a refrigerator system that allows us to stop the aircraft in the aircraft machine in the air, to be able to use the most specific issues that they were connected to the propulsive, if they're connected to the deposit, or to the defend, if they're all the deposit's all of a security system, if they're all the right now they're in the same to the trajected to a security system that they're connected to the deposit's all that they're connected to the deposit, if they're connected to the decrease their propeller's all that they were connected to the decrease, they're
2022-03-23 10:26:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:04 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.717 | nll_loss 3.227 | ppl 9.36 | bleu 32.08 | wps 4591.6 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.08
2022-03-23 10:26:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:26:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:26:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:26:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 34 @ 5333 updates, score 32.08) (writing took 1.8304804019862786 seconds)
2022-03-23 10:26:06 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:26:06 | INFO | train | epoch 034 | loss 8.629 | nll_loss 3.456 | ppl 10.98 | wps 43396.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.292 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3158
2022-03-23 10:26:06 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:27 | INFO | train_inner | epoch 035:     67 / 157 loss=8.632, nll_loss=3.461, ppl=11.01, wps=34572.1, ups=1.38, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.287, loss_scale=4, train_wall=30, gb_free=14.7, wall=3180
2022-03-23 10:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 10:26:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most of you know here.
2022-03-23 10:27:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks disorders that are going to overwrite two new pigs.
2022-03-23 10:27:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepsuitcase.
2022-03-23 10:27:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:27:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people were taking responsibility for wildlife, the number of wild animals grew back up again, and that's a basis for conservation in namibia.
2022-03-23 10:27:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like when they move because their movements use energy, and so the superconductor disorder.
2022-03-23 10:27:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this mirror reflection, we can start with a traditional facial can that gives the big contures of the face and the basic shape, and through the one of the information that pulls the whole portion structure and all the fits.
2022-03-23 10:27:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in striking dinner, it was the best summarized when somebody said, "turn you to the men on your table and say," if the revolution starts supporting you, "the truth is that we've been supporting you for this long time."
2022-03-23 10:27:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:33 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our aircraft is the most stumbling, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable operating and a cooling system with liquid refrigeration that allows us to use an aircraft in the aircraft to a specific transportation, or if you're going to be able to be able to see the case of a mechanism.
2022-03-23 10:27:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:33 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.688 | nll_loss 3.148 | ppl 8.87 | bleu 32.18 | wps 4802.4 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.18
2022-03-23 10:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:27:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:27:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 35 @ 5490 updates, score 32.18) (writing took 1.8503078559879214 seconds)
2022-03-23 10:27:34 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:27:34 | INFO | train | epoch 035 | loss 8.602 | nll_loss 3.401 | ppl 10.56 | wps 44418.4 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.265 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 3247
2022-03-23 10:27:35 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:38 | INFO | train_inner | epoch 036:     10 / 157 loss=8.589, nll_loss=3.377, ppl=10.39, wps=35017.5, ups=1.41, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.255, loss_scale=4, train_wall=31, gb_free=14.7, wall=3251
2022-03-23 10:28:09 | INFO | train_inner | epoch 036:    110 / 157 loss=8.583, nll_loss=3.362, ppl=10.28, wps=80588.1, ups=3.19, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.271, loss_scale=4, train_wall=31, gb_free=14.7, wall=3282
2022-03-23 10:28:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:28:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:28:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks deals that are going to overwrite two new pigs.
2022-03-23 10:28:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pills.
2022-03-23 10:28:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:28:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people returned responsibility for the wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:28:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:28:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and the superconductor disorder.
2022-03-23 10:28:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:28:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form, and refers it through the one of the things that refers the whole portion structure and all the fits.
2022-03-23 10:28:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured, for me here at tedwomen, is that... well, in the strict dinner, it was the best summarized when someone said, "turn you to the men at your table and tell you, '" when the revolution begins, "and then we'll help you.'" '"'" '"the truth, love, is that we've already been supporting you for a long time."
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a big part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variable drive and a refrigerator of the design work that allows us to use an aircraft in the aircraft to the stumber, to stop traffic, to the defeat the same time, or to the defeat the deployment of the defeat the defeat the defeat the defeat the defeat the defeat the defeat the defeat the ground, or the defeat the defeat the defeat the defeat the defeat the defeat the defeat the decrease, and a security level, and a defeat the defeat the defeat the defeat the defeat the defeat the defeat the
2022-03-23 10:29:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:03 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.685 | nll_loss 3.134 | ppl 8.78 | bleu 32.47 | wps 4588.7 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.47
2022-03-23 10:29:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:29:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:29:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.47) (writing took 1.8060803400003351 seconds)
2022-03-23 10:29:05 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:29:05 | INFO | train | epoch 036 | loss 8.587 | nll_loss 3.37 | ppl 10.34 | wps 43636.9 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.274 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3338
2022-03-23 10:29:05 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:29:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:22 | INFO | train_inner | epoch 037:     53 / 157 loss=8.556, nll_loss=3.309, ppl=9.91, wps=35157.8, ups=1.38, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.265, loss_scale=4, train_wall=30, gb_free=14.7, wall=3355
2022-03-23 10:29:53 | INFO | train_inner | epoch 037:    153 / 157 loss=8.602, nll_loss=3.401, ppl=10.56, wps=79943, ups=3.22, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.275, loss_scale=4, train_wall=31, gb_free=13.6, wall=3386
2022-03-23 10:29:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:29:58 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:29:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:30:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that make two new pigs overwrite.
2022-03-23 10:30:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-23 10:30:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 10:30:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people taking responsibility for the wildlife, the number of wild animals grew back, and that's become a foundation for conservation in namibia.
2022-03-23 10:30:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and the superconductor disorders.
2022-03-23 10:30:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and restore the basic shape of that information that refers the whole porn structure and all the fits.
2022-03-23 10:30:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate, to be here at tedwomen, is that... well, in strict dinner, it was best summarized when someone said, "turn you to the men at your table and say," if the revolution starts supporting you. '"' '" the truth, love is that we've already supported you at this point for a long time. at this time, we've started a long time. "
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're the most proud of, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variable operating and a cooling system with fluid, that allows us to use an aircraft in the aircraft of the aircraft to stop traffic, until a special vehicle of a prophecy, or if you're going to be able to see the deployment of a mechanism.
2022-03-23 10:30:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:33 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.668 | nll_loss 3.11 | ppl 8.63 | bleu 32.68 | wps 4676.9 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 32.68
2022-03-23 10:30:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:30:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:30:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 32.68) (writing took 1.8403397539805155 seconds)
2022-03-23 10:30:35 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:30:35 | INFO | train | epoch 037 | loss 8.57 | nll_loss 3.337 | ppl 10.11 | wps 43901 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.266 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3428
2022-03-23 10:30:35 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:30:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:05 | INFO | train_inner | epoch 038:     96 / 157 loss=8.571, nll_loss=3.34, ppl=10.13, wps=34104.2, ups=1.39, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.287, loss_scale=4, train_wall=31, gb_free=14.3, wall=3458
2022-03-23 10:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:31:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:31:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:31:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:31:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that are going to transcend two new pigs.
2022-03-23 10:31:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:31:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:31:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:31:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 10:31:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for the wildlife, the number of wild animals grew back, and that's become a basis for conservation in namibia.
2022-03-23 10:31:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:31:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection of reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic shape, and reconcile it by the one of the information that refers the whole portion structure and all the floods.
2022-03-23 10:31:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn you to the men on your table and tell them, 'when the revolution starts supporting you,' the truth, women love you about this topic for a long time."
2022-03-23 10:32:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:32:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on on our plane is the result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variable drill and a refrigeration system with liquid liquid that allows us to use an aircraft on the traffic to go to a particular vehicle where you can see the ground, or if you see the deployment, or if you can see the mechanism, or the security system that you see the deployment of an aircraft, you can see the deployment of a security system that you see the decrease, you can see the decrease, you can see the decrease, you can use it, you can use it, you see it, you see it, you can use it, you can use it, you can use it, you can use it, you can use it, you can use it
2022-03-23 10:32:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:32:02 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.659 | nll_loss 3.1 | ppl 8.58 | bleu 32.58 | wps 4751.9 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 32.68
2022-03-23 10:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:32:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:32:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.58) (writing took 0.9327364439959638 seconds)
2022-03-23 10:32:03 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:32:03 | INFO | train | epoch 038 | loss 8.564 | nll_loss 3.325 | ppl 10.02 | wps 44705.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.282 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3516
2022-03-23 10:32:04 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:16 | INFO | train_inner | epoch 039:     39 / 157 loss=8.517, nll_loss=3.229, ppl=9.38, wps=36744.8, ups=1.41, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.253, loss_scale=4, train_wall=31, gb_free=13.7, wall=3529
2022-03-23 10:32:47 | INFO | train_inner | epoch 039:    139 / 157 loss=8.557, nll_loss=3.31, ppl=9.92, wps=79858.7, ups=3.22, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.281, loss_scale=4, train_wall=31, gb_free=14.7, wall=3560
2022-03-23 10:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:32:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:32:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:33:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:33:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that are going to overwrite two new pigs.
2022-03-23 10:33:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pill suitcase.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of the thoughts are on the track.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wildlife, the number of wildlife grew back up, and that's become a foundation for conservation in namibia.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection reflection, we can start with a traditional facial can that gives the big constraints of the face, and the basic shape, and through the one of the information that pulls the whole portion structure and all the fits.
2022-03-23 10:33:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen, is that... well, in striking dinner, it was best summarized when someone said, "turn you to the men in your table and tell them, 'when the revolution begins, then we support you."' "'the truth, love, women, we've already been supporting you in this topic for a long time."
2022-03-23 10:33:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our plane is the most stumbling, was a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuous variation and a cooling system of liquid, that it allows us to use an aircraft in the aircraft in the go-and to a particular place, or if you see the deployment of a security, or if you're going to be on the ground, or if you're going to the deployed in a security, or if you're going to the deployment, or if you're going to the deployment, if you're going to be able to the deployed, or you're going to the defeat the decrease, or you're going to the deployment, if you're going to the deployment, or you're going to be able to the deployment
2022-03-23 10:33:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:32 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.655 | nll_loss 3.066 | ppl 8.38 | bleu 33.09 | wps 4603.4 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.09
2022-03-23 10:33:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:33:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:33:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:33:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.09) (writing took 1.8713596370071173 seconds)
2022-03-23 10:33:34 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:33:34 | INFO | train | epoch 039 | loss 8.536 | nll_loss 3.269 | ppl 9.64 | wps 43548.4 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.263 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3607
2022-03-23 10:33:34 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:33:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:34:00 | INFO | train_inner | epoch 040:     82 / 157 loss=8.525, nll_loss=3.243, ppl=9.46, wps=34080.9, ups=1.37, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.24, loss_scale=4, train_wall=30, gb_free=14.1, wall=3633
2022-03-23 10:34:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:34:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:34:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:34:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:34:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:34:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that are going to overwrite two new pigs.
2022-03-23 10:34:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:34:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pills.
2022-03-23 10:34:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:34:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:34:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:34:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for the wildlife, the number of wildlife grew back, and this has become a foundation for conservation in namibia.
2022-03-23 10:34:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:34:51 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:34:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:34:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face can that restores the big constraints of the face, and the basic shape, and then converts it through the one of the information that refers the whole portion structure and all the fine folds.
2022-03-23 10:34:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:34:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in striking dinner, it was best summarized when someone said, "turn to the men on your table and tell them, 'if the revolution starts, then we support you.'" 'the truth, women are supporting you for a long time. "at rael spring, then we started down the future."
2022-03-23 10:34:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:35:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our aircraft is a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variation and a refrigeration system that allows us to use an aircraft in the transportation to a specific drive, or if you see the propmacy, if you're on the ground, you're going to be flowing, you're going to be able to be able to see, if you're going to be able to see, if you're in a security space, you're going to see, you're going to see, you're going to be flowing, if you're going to be able to see the tragic, you're going to fly, and you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 10:35:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:35:01 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.663 | nll_loss 3.089 | ppl 8.51 | bleu 32.96 | wps 4790.7 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.09
2022-03-23 10:35:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:35:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:35:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:35:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 32.96) (writing took 0.7912758399907034 seconds)
2022-03-23 10:35:02 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:35:02 | INFO | train | epoch 040 | loss 8.517 | nll_loss 3.229 | ppl 9.38 | wps 44754.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.248 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3695
2022-03-23 10:35:03 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:35:10 | INFO | train_inner | epoch 041:     25 / 157 loss=8.527, nll_loss=3.251, ppl=9.52, wps=36234.9, ups=1.42, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.263, loss_scale=4, train_wall=31, gb_free=14.4, wall=3703
2022-03-23 10:35:42 | INFO | train_inner | epoch 041:    125 / 157 loss=8.512, nll_loss=3.217, ppl=9.3, wps=79916.6, ups=3.2, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.274, loss_scale=4, train_wall=31, gb_free=13.8, wall=3734
2022-03-23 10:35:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:35:55 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:35:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:35:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, i think, most of you know here.
2022-03-23 10:35:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:36:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to overwrite two new pigs.
2022-03-23 10:36:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:36:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:36:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:36:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 10:36:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:36:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach as people took responsibility for the wildlife, the number of wildlife grew back up, and this has become a basis for conservation in namibia.
2022-03-23 10:36:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:36:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 10:36:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:36:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial can that will restore the big consequences of the face and the basic form, and through the one of the information that refers the whole portion structure and all the fits.
2022-03-23 10:36:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:36:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn to the men at your table and tell you, 'when the revolution starts to support you."' "'the truth, women, love is that we've already started with you for a long time."
2022-03-23 10:36:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:36:30 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're most proud of on on our airplane was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuously variable operating and a refrigerator system that allows us to use an aircraft in the aircraft in the go-and traffic to a particular vehicle that is either appropriate for the ground, or if you see the proper mechanism, or the deployment of a deployment of a deployment that's going to the air.
2022-03-23 10:36:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:36:30 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.626 | nll_loss 3.047 | ppl 8.26 | bleu 33.38 | wps 4761.6 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.38
2022-03-23 10:36:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:36:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:36:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt
2022-03-23 10:36:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.38) (writing took 1.9545813529985026 seconds)
2022-03-23 10:36:32 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:36:32 | INFO | train | epoch 041 | loss 8.512 | nll_loss 3.22 | ppl 9.32 | wps 44151.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.266 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3784
2022-03-23 10:36:32 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:36:53 | INFO | train_inner | epoch 042:     68 / 157 loss=8.494, nll_loss=3.181, ppl=9.07, wps=35088.8, ups=1.4, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.253, loss_scale=4, train_wall=30, gb_free=22.4, wall=3806
2022-03-23 10:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:37:25 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:37:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:37:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:37:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:37:33 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will create two new pigs.
2022-03-23 10:37:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:37:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:37:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:37:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:37:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:37:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wildlife, the number of wild animals grew back up again, and that's become a basis for conservation in namibia.
2022-03-23 10:37:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:37:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:37:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:37:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic form, and then through the one of the information that refers the whole portion structure and all the fine folds.
2022-03-23 10:37:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:37:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured to me here at tedwomen is that... well, the dinner was best summarized when someone said, "turn to the men on your table and tell them, 'when the revolution begins, then we support you.'" the truth, love is that we've been supporting you with this topic for a long time. "
2022-03-23 10:37:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:37:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're the most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuous variation and a cooling system of liquid, that it allows us to use an aircraft in the aircraft on the aircraft of stop and gogo to a special drive that is either propsized, or if you see the ground, to the tragic of a mechanism.
2022-03-23 10:37:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:37:58 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.637 | nll_loss 3.058 | ppl 8.33 | bleu 33.22 | wps 4907.3 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.38
2022-03-23 10:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:37:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:37:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.22) (writing took 0.84745068999473 seconds)
2022-03-23 10:37:59 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:37:59 | INFO | train | epoch 042 | loss 8.493 | nll_loss 3.18 | ppl 9.07 | wps 45233.7 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.252 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3872
2022-03-23 10:37:59 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:37:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:38:03 | INFO | train_inner | epoch 043:     11 / 157 loss=8.479, nll_loss=3.154, ppl=8.9, wps=36580.9, ups=1.43, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.24, loss_scale=4, train_wall=31, gb_free=14, wall=3876
2022-03-23 10:38:34 | INFO | train_inner | epoch 043:    111 / 157 loss=8.505, nll_loss=3.204, ppl=9.22, wps=80055.7, ups=3.22, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.269, loss_scale=4, train_wall=31, gb_free=13.8, wall=3907
2022-03-23 10:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:38:52 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 10:38:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:38:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you probably know here.
2022-03-23 10:38:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:39:00 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to overwrite two new pigs.
2022-03-23 10:39:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:39:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:39:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:39:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-23 10:39:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:39:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wildlife, the number of wildlife grew back up, and that's become a basis for conservation in namibia.
2022-03-23 10:39:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:39:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are trapped by magnetic field lines inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorders.
2022-03-23 10:39:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:39:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic reform, and then through the one of the information that pulls the whole portion structure and all the fonts.
2022-03-23 10:39:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:39:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measured to me here at tedwomen is that... well, the strict dinner was best summarized when someone said, "turn you to the men on your table and tell them, 'when the revolution begins, then we support you."' the truth, love is that we've already supported you in this topic for a long time. "
2022-03-23 10:39:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:39:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on our airplane is the most stumbling, a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously variable gear and a cooling system of refrigeration, that it allows us to use an aircraft in the aircraft to stop until a special passenger, or to the deployment of the propulsion, or to the deployment of a propulsion, or to the degraded space, all the tragic space, all the way down the way to the way down the way to the way to the way to the degraded the tragic space of a mechanism.
2022-03-23 10:39:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:39:27 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.62 | nll_loss 3.043 | ppl 8.24 | bleu 33.28 | wps 4706.6 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.38
2022-03-23 10:39:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:39:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:39:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt (epoch 43 @ 6746 updates, score 33.28) (writing took 0.8954231609823182 seconds)
2022-03-23 10:39:28 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:39:28 | INFO | train | epoch 043 | loss 8.483 | nll_loss 3.16 | ppl 8.94 | wps 44465.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.26 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3961
2022-03-23 10:39:28 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:39:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:39:45 | INFO | train_inner | epoch 044:     54 / 157 loss=8.465, nll_loss=3.122, ppl=8.71, wps=35011.1, ups=1.41, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.268, loss_scale=4, train_wall=30, gb_free=14.2, wall=3978
2022-03-23 10:40:16 | INFO | train_inner | epoch 044:    154 / 157 loss=8.467, nll_loss=3.129, ppl=8.75, wps=82575.9, ups=3.23, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.237, loss_scale=4, train_wall=31, gb_free=13.8, wall=4009
2022-03-23 10:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:40:21 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 10:40:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:40:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 10:40:25 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:40:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will transcend two new pigs.
2022-03-23 10:40:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:40:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:40:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:40:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:40:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:40:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wildlife, the number of wildlife grew back up, and that's become a foundation for conservation in namibia.
2022-03-23 10:40:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:40:45 | INFO | fairseq.tasks.translation | example hypothesis: first, a couple of magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:40:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:40:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that gives the big constraints of the face and the basic shape, and recongestion it through the one of the information that pulls the whole porch structure and all the fine folds.
2022-03-23 10:40:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:40:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured, to me here at tedwomen, is that... well, in the strict dinner, it was best summarized when someone said, "turn to the men on your table and tell you," when the revolution begins, we support you. "the truth, love women, we've already supported you about this topic for a long time. at rael carspring,"
2022-03-23 10:40:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:40:54 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're the stumbling on our aircraft was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuously variable gear and a cooling system of fluid that allows us to use an aircraft to stop and go to a specially appropriate passage that either passes when you fly it, or if you see it, if you can see it on the ground, to the trade-offs.
2022-03-23 10:40:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:40:54 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.63 | nll_loss 3.034 | ppl 8.19 | bleu 33.31 | wps 4876.4 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.38
2022-03-23 10:40:54 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:40:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:40:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:40:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt
2022-03-23 10:40:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.5_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.31) (writing took 0.9413240920112003 seconds)
2022-03-23 10:40:55 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:40:55 | INFO | train | epoch 044 | loss 8.47 | nll_loss 3.134 | ppl 8.78 | wps 45040.6 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.255 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 4048
2022-03-23 10:40:55 | INFO | fairseq_cli.train | done training in 4047.9 seconds
