Sender: LSF System <lsfadmin@eu-lo-s4-064>
Subject: Job 207264029: <w103_size_0.03125_fp16_cross_entropy_#2> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_cross_entropy_#2> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:20:52 2022
Job was executed on host(s) <eu-lo-s4-064>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:24:15 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:24:15 2022
Terminated at Sun Mar  6 08:56:01 2022
Results reported at Sun Mar  6 08:56:01 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575612 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   68687.21 sec.
    Max Memory :                                 4176 MB
    Average Memory :                             2943.90 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15824.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   66712 sec.
    Turnaround time :                            66909 sec.

The output (if any) follows:

2022-03-05 14:24:38 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575612, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575612, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:24:38 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:24:40 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:24:40 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:24:40 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:24:40 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-05 14:24:40 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:24:40 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:24:40 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:24:44 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:24:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:24:44 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = NVIDIA GeForce GTX 1080 Ti              
2022-03-05 14:24:44 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:24:44 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:24:44 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:24:44 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 14:24:44 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 14:24:44 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:24:44 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:24:44 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16 or --amp, please switch to FP32 which is likely to be faster
2022-03-05 14:24:44 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:24:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:24:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:25:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:25:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:25:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:25:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:31:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.326 | ppl 41074.9 | wps 20537 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:31:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:31:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:31:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.326) (writing took 6.691632315050811 seconds)
2022-03-05 14:31:15 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:31:15 | INFO | train | epoch 001 | loss 16.589 | ppl 98546.3 | wps 8445.9 | ups 0.13 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 5.254 | loss_scale 4 | train_wall 356 | gb_free 9 | wall 391
2022-03-05 14:31:15 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:37:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:37:14 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.852 | ppl 14787.2 | wps 20131.2 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 13.852
2022-03-05 14:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:37:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:37:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 13.852) (writing took 6.409126613056287 seconds)
2022-03-05 14:37:21 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:37:21 | INFO | train | epoch 002 | loss 14.568 | ppl 24281.6 | wps 8685.4 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.301 | loss_scale 4 | train_wall 331 | gb_free 9 | wall 757
2022-03-05 14:37:21 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:37:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:11 | INFO | train_inner | epoch 003:      7 / 49 loss=15.408, ppl=43480.9, wps=8608.6, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.549, loss_scale=4, train_wall=735, gb_free=9, wall=807
2022-03-05 14:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:43:20 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.173 | ppl 9234.61 | wps 20084.2 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.173
2022-03-05 14:43:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:43:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:43:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:43:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.173) (writing took 6.548039791872725 seconds)
2022-03-05 14:43:27 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:43:27 | INFO | train | epoch 003 | loss 13.6 | ppl 12414.3 | wps 8692.5 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.493 | loss_scale 8 | train_wall 331 | gb_free 9 | wall 1122
2022-03-05 14:43:27 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:49:26 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.321 | ppl 5117.56 | wps 20187 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.321
2022-03-05 14:49:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:49:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:49:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.321) (writing took 6.278446985874325 seconds)
2022-03-05 14:49:32 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:49:32 | INFO | train | epoch 004 | loss 12.832 | ppl 7289.83 | wps 8696.8 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.306 | loss_scale 8 | train_wall 331 | gb_free 9 | wall 1488
2022-03-05 14:49:32 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:49:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:50:37 | INFO | train_inner | epoch 005:      9 / 49 loss=13.084, ppl=8685.2, wps=8703.5, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.364, loss_scale=8, train_wall=675, gb_free=9, wall=1552
2022-03-05 14:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:55:31 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.497 | ppl 2890.09 | wps 19887.1 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 11.497
2022-03-05 14:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:55:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 14:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 11.497) (writing took 6.2212661078665406 seconds)
2022-03-05 14:55:37 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:55:37 | INFO | train | epoch 005 | loss 11.943 | ppl 3936.13 | wps 8702.2 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 1.037 | loss_scale 8 | train_wall 331 | gb_free 9 | wall 1853
2022-03-05 14:55:37 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:01:36 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 10.843 | ppl 1836.98 | wps 20220.3 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 10.843
2022-03-05 15:01:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 15:01:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:01:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:01:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 10.843) (writing took 8.384492887882516 seconds)
2022-03-05 15:01:45 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 15:01:45 | INFO | train | epoch 006 | loss 11.17 | ppl 2303.68 | wps 8649.5 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.787 | loss_scale 16 | train_wall 331 | gb_free 9 | wall 2220
2022-03-05 15:01:45 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 15:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:03:03 | INFO | train_inner | epoch 007:     11 / 49 loss=11.401, ppl=2704.8, wps=8685.5, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.866, loss_scale=16, train_wall=675, gb_free=9, wall=2299
2022-03-05 15:07:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:07:43 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.405 | ppl 1356.14 | wps 20722.3 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 10.405
2022-03-05 15:07:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 15:07:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 10.405) (writing took 6.153678524075076 seconds)
2022-03-05 15:07:49 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 15:07:49 | INFO | train | epoch 007 | loss 10.6 | ppl 1551.68 | wps 8718.8 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.63 | loss_scale 16 | train_wall 331 | gb_free 9 | wall 2585
2022-03-05 15:07:49 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 15:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:13:48 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.15 | ppl 1135.98 | wps 20604.1 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.15
2022-03-05 15:13:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 15:13:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:13:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:13:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.15) (writing took 6.1238089490216225 seconds)
2022-03-05 15:13:54 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 15:13:54 | INFO | train | epoch 008 | loss 10.234 | ppl 1204.23 | wps 8713.8 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.508 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 2950
2022-03-05 15:13:54 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 15:13:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:15:27 | INFO | train_inner | epoch 009:     13 / 49 loss=10.329, ppl=1286.68, wps=8723, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.552, loss_scale=32, train_wall=675, gb_free=9, wall=3043
2022-03-05 15:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:19:53 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.962 | ppl 997.51 | wps 20639.1 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 9.962
2022-03-05 15:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 15:19:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:19:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 9.962) (writing took 6.560681426897645 seconds)
2022-03-05 15:19:59 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 15:19:59 | INFO | train | epoch 009 | loss 9.992 | ppl 1018.12 | wps 8692.3 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.513 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 3315
2022-03-05 15:19:59 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 15:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:25:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:25:59 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.789 | ppl 884.44 | wps 20654.7 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 9.789
2022-03-05 15:25:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 15:25:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:26:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:26:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 9.789) (writing took 6.090867181075737 seconds)
2022-03-05 15:26:05 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 15:26:05 | INFO | train | epoch 010 | loss 9.798 | ppl 890.03 | wps 8702 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.527 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 3680
2022-03-05 15:26:05 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 15:26:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:27:52 | INFO | train_inner | epoch 011:     15 / 49 loss=9.838, ppl=915.23, wps=8706.2, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.526, loss_scale=32, train_wall=676, gb_free=9, wall=3788
2022-03-05 15:30:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:31:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:32:04 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.655 | ppl 806.42 | wps 20658.6 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 9.655
2022-03-05 15:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 15:32:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:32:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 11 @ 533 updates, score 9.655) (writing took 6.225228315917775 seconds)
2022-03-05 15:32:10 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 15:32:10 | INFO | train | epoch 011 | loss 9.62 | ppl 786.88 | wps 8522.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.598 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 4046
2022-03-05 15:32:10 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 15:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:38:09 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.521 | ppl 734.66 | wps 20631.6 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 9.521
2022-03-05 15:38:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 15:38:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:38:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 9.521) (writing took 6.132688922109082 seconds)
2022-03-05 15:38:15 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 15:38:15 | INFO | train | epoch 012 | loss 9.455 | ppl 702.06 | wps 8706.6 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.607 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 4411
2022-03-05 15:38:15 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 15:38:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:40:24 | INFO | train_inner | epoch 013:     18 / 49 loss=9.483, ppl=715.68, wps=8627.6, ups=0.13, wpb=64867.4, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.626, loss_scale=32, train_wall=683, gb_free=9, wall=4540
2022-03-05 15:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:44:14 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.41 | ppl 680.14 | wps 20499.1 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 9.41
2022-03-05 15:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 15:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:44:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:44:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 9.41) (writing took 6.1881019729189575 seconds)
2022-03-05 15:44:20 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 15:44:20 | INFO | train | epoch 013 | loss 9.297 | ppl 629.11 | wps 8699.8 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.679 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 4776
2022-03-05 15:44:20 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 15:44:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:50:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:50:19 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.295 | ppl 628.29 | wps 20669.4 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 9.295
2022-03-05 15:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 15:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:50:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 9.295) (writing took 6.067711074836552 seconds)
2022-03-05 15:50:25 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 15:50:25 | INFO | train | epoch 014 | loss 9.147 | ppl 566.95 | wps 8522.8 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.693 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 5141
2022-03-05 15:50:25 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 15:50:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:52:56 | INFO | train_inner | epoch 015:     21 / 49 loss=9.161, ppl=572.49, wps=8627.2, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.692, loss_scale=32, train_wall=683, gb_free=9, wall=5292
2022-03-05 15:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:56:24 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.19 | ppl 584.19 | wps 20620.6 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.19
2022-03-05 15:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 15:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:56:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 15:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.19) (writing took 6.0966460139025 seconds)
2022-03-05 15:56:31 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 15:56:31 | INFO | train | epoch 015 | loss 9.003 | ppl 512.94 | wps 8702 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.773 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 5506
2022-03-05 15:56:31 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 15:56:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:02:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:02:29 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.097 | ppl 547.74 | wps 20597.2 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.097
2022-03-05 16:02:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-05 16:02:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:02:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:02:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.097) (writing took 6.093857011990622 seconds)
2022-03-05 16:02:36 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 16:02:36 | INFO | train | epoch 016 | loss 8.862 | ppl 465.38 | wps 8706.8 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.845 | loss_scale 64 | train_wall 331 | gb_free 9 | wall 5871
2022-03-05 16:02:36 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 16:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:02:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:05:28 | INFO | train_inner | epoch 017:     24 / 49 loss=8.87, ppl=467.77, wps=8628.9, ups=0.13, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.822, loss_scale=32, train_wall=683, gb_free=9, wall=6044
2022-03-05 16:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:08:35 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.008 | ppl 514.71 | wps 20573.6 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.008
2022-03-05 16:08:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-05 16:08:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:08:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.008) (writing took 6.3537000310607255 seconds)
2022-03-05 16:08:41 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 16:08:41 | INFO | train | epoch 017 | loss 8.724 | ppl 422.97 | wps 8516.3 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.832 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 6237
2022-03-05 16:08:41 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 16:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:14:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:14:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:14:40 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.924 | ppl 485.8 | wps 20621.1 | wpb 510.9 | bsz 1 | num_updates 873 | best_loss 8.924
2022-03-05 16:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 873 updates
2022-03-05 16:14:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:14:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 18 @ 873 updates, score 8.924) (writing took 6.214239617809653 seconds)
2022-03-05 16:14:47 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 16:14:47 | INFO | train | epoch 018 | loss 8.595 | ppl 386.67 | wps 8515.6 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 873 | lr 0.000109203 | gnorm 0.904 | loss_scale 16 | train_wall 331 | gb_free 9 | wall 6602
2022-03-05 16:14:47 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 16:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:18:01 | INFO | train_inner | epoch 019:     27 / 49 loss=8.589, ppl=385.16, wps=8619.3, ups=0.13, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.887, loss_scale=16, train_wall=683, gb_free=9, wall=6796
2022-03-05 16:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:20:46 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.859 | ppl 464.37 | wps 20611.6 | wpb 510.9 | bsz 1 | num_updates 922 | best_loss 8.859
2022-03-05 16:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 922 updates
2022-03-05 16:20:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:20:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 19 @ 922 updates, score 8.859) (writing took 6.033710479037836 seconds)
2022-03-05 16:20:52 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 16:20:52 | INFO | train | epoch 019 | loss 8.468 | ppl 354.12 | wps 8700.7 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 922 | lr 0.000115327 | gnorm 0.949 | loss_scale 16 | train_wall 331 | gb_free 9 | wall 6968
2022-03-05 16:20:52 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 16:20:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:26:52 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.772 | ppl 437.21 | wps 20107.9 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 8.772
2022-03-05 16:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-05 16:26:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 8.772) (writing took 6.242996440036222 seconds)
2022-03-05 16:26:58 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 16:26:58 | INFO | train | epoch 020 | loss 8.341 | ppl 324.21 | wps 8668 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.8 | loss_scale 16 | train_wall 332 | gb_free 9 | wall 7334
2022-03-05 16:26:58 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 16:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:30:27 | INFO | train_inner | epoch 021:     29 / 49 loss=8.333, ppl=322.48, wps=8693.6, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.884, loss_scale=32, train_wall=677, gb_free=9, wall=7543
2022-03-05 16:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:32:58 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.709 | ppl 418.36 | wps 20592.4 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 8.709
2022-03-05 16:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-05 16:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 8.709) (writing took 6.1546795279718935 seconds)
2022-03-05 16:33:04 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 16:33:04 | INFO | train | epoch 021 | loss 8.222 | ppl 298.61 | wps 8698.4 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.968 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 7700
2022-03-05 16:33:04 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 16:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:38:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:39:05 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.649 | ppl 401.36 | wps 20277.2 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 8.649
2022-03-05 16:39:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 16:39:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:39:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 8.649) (writing took 6.309445193037391 seconds)
2022-03-05 16:39:11 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 16:39:11 | INFO | train | epoch 022 | loss 8.106 | ppl 275.46 | wps 8652.7 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.96 | loss_scale 32 | train_wall 332 | gb_free 9 | wall 8067
2022-03-05 16:39:11 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 16:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:42:56 | INFO | train_inner | epoch 023:     31 / 49 loss=8.094, ppl=273.2, wps=8663.6, ups=0.13, wpb=64876.2, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.979, loss_scale=32, train_wall=679, gb_free=9, wall=8291
2022-03-05 16:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:45:13 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.608 | ppl 390.15 | wps 19923.6 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 8.608
2022-03-05 16:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 16:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:45:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:45:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 23 @ 1118 updates, score 8.608) (writing took 6.388196792919189 seconds)
2022-03-05 16:45:20 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 16:45:20 | INFO | train | epoch 023 | loss 7.992 | ppl 254.64 | wps 8620.3 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 0.94 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 8436
2022-03-05 16:45:20 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 16:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:46:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:51:23 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.567 | ppl 379.35 | wps 20043.2 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 8.567
2022-03-05 16:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-05 16:51:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:51:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 8.567) (writing took 6.491251034196466 seconds)
2022-03-05 16:51:29 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 16:51:29 | INFO | train | epoch 024 | loss 7.882 | ppl 235.89 | wps 8423.4 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.919 | loss_scale 32 | train_wall 334 | gb_free 9 | wall 8805
2022-03-05 16:51:29 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 16:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:55:37 | INFO | train_inner | epoch 025:     34 / 49 loss=7.861, ppl=232.53, wps=8519.6, ups=0.13, wpb=64867.4, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.924, loss_scale=32, train_wall=689, gb_free=9, wall=9053
2022-03-05 16:57:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:57:34 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.524 | ppl 368.04 | wps 20041 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 8.524
2022-03-05 16:57:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-05 16:57:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 16:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 25 @ 1215 updates, score 8.524) (writing took 6.43369804485701 seconds)
2022-03-05 16:57:40 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 16:57:40 | INFO | train | epoch 025 | loss 7.774 | ppl 218.88 | wps 8571.7 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.948 | loss_scale 32 | train_wall 335 | gb_free 9 | wall 9176
2022-03-05 16:57:40 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 16:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:03:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:03:44 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.484 | ppl 358.11 | wps 20025.2 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 8.484
2022-03-05 17:03:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-05 17:03:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:03:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:03:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 8.484) (writing took 6.413349683163688 seconds)
2022-03-05 17:03:50 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 17:03:50 | INFO | train | epoch 026 | loss 7.665 | ppl 203 | wps 8410.2 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 1.015 | loss_scale 32 | train_wall 335 | gb_free 9 | wall 9546
2022-03-05 17:03:50 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 17:03:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:08:19 | INFO | train_inner | epoch 027:     37 / 49 loss=7.64, ppl=199.5, wps=8509, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.996, loss_scale=32, train_wall=690, gb_free=9, wall=9815
2022-03-05 17:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:09:54 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.477 | ppl 356.35 | wps 19946.8 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 8.477
2022-03-05 17:09:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-05 17:09:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:09:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:10:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 8.477) (writing took 6.520334595115855 seconds)
2022-03-05 17:10:01 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 17:10:01 | INFO | train | epoch 027 | loss 7.559 | ppl 188.56 | wps 8577.9 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 1.007 | loss_scale 32 | train_wall 335 | gb_free 9 | wall 9916
2022-03-05 17:10:01 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 17:10:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:15:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:16:04 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.423 | ppl 343.14 | wps 20079.4 | wpb 510.9 | bsz 1 | num_updates 1361 | best_loss 8.423
2022-03-05 17:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1361 updates
2022-03-05 17:16:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:16:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 28 @ 1361 updates, score 8.423) (writing took 6.425296388100833 seconds)
2022-03-05 17:16:11 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 17:16:11 | INFO | train | epoch 028 | loss 7.452 | ppl 175.05 | wps 8584.1 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1361 | lr 0.000170191 | gnorm 1.019 | loss_scale 32 | train_wall 335 | gb_free 9 | wall 10287
2022-03-05 17:16:11 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 17:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:19:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:21:02 | INFO | train_inner | epoch 029:     40 / 49 loss=7.422, ppl=171.51, wps=8508, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=1.014, loss_scale=32, train_wall=690, gb_free=9, wall=10578
2022-03-05 17:22:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:22:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 8.387 | ppl 334.76 | wps 20103 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 8.387
2022-03-05 17:22:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-05 17:22:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:22:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:22:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 8.387) (writing took 9.0544847198762 seconds)
2022-03-05 17:22:24 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 17:22:24 | INFO | train | epoch 029 | loss 7.344 | ppl 162.51 | wps 8349.4 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 1.02 | loss_scale 32 | train_wall 335 | gb_free 9 | wall 10659
2022-03-05 17:22:24 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 17:22:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:28:26 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 8.372 | ppl 331.26 | wps 20353.1 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 8.372
2022-03-05 17:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-05 17:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:28:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:28:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 8.372) (writing took 6.289837956894189 seconds)
2022-03-05 17:28:32 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 17:28:32 | INFO | train | epoch 030 | loss 7.24 | ppl 151.17 | wps 8625.2 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 1.037 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 11028
2022-03-05 17:28:32 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 17:28:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:33:36 | INFO | train_inner | epoch 031:     42 / 49 loss=7.203, ppl=147.35, wps=8599.5, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=1.025, loss_scale=32, train_wall=681, gb_free=9, wall=11332
2022-03-05 17:34:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:34:34 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 8.382 | ppl 333.54 | wps 20338.5 | wpb 510.9 | bsz 1 | num_updates 1507 | best_loss 8.372
2022-03-05 17:34:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1507 updates
2022-03-05 17:34:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 31 @ 1507 updates, score 8.382) (writing took 3.1339297629892826 seconds)
2022-03-05 17:34:37 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 17:34:37 | INFO | train | epoch 031 | loss 7.131 | ppl 140.2 | wps 8706.5 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1507 | lr 0.000188437 | gnorm 0.986 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 11393
2022-03-05 17:34:37 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 17:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:36:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:40:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:40:39 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 8.385 | ppl 334.2 | wps 20029.5 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 8.372
2022-03-05 17:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-05 17:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 32 @ 1555 updates, score 8.385) (writing took 2.9908115740399808 seconds)
2022-03-05 17:40:42 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 17:40:42 | INFO | train | epoch 032 | loss 7.03 | ppl 130.66 | wps 8536.9 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 1.076 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 11757
2022-03-05 17:40:42 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 17:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:46:07 | INFO | train_inner | epoch 033:     45 / 49 loss=6.989, ppl=127.06, wps=8638.3, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=1.065, loss_scale=32, train_wall=686, gb_free=9, wall=12083
2022-03-05 17:46:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:46:43 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.39 | ppl 335.36 | wps 20353.2 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.372
2022-03-05 17:46:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-05 17:46:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:46:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 33 @ 1604 updates, score 8.39) (writing took 3.029588012956083 seconds)
2022-03-05 17:46:46 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 17:46:46 | INFO | train | epoch 033 | loss 6.925 | ppl 121.49 | wps 8715.6 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 1.066 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 12122
2022-03-05 17:46:46 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 17:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:52:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 17:52:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:52:48 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.372 | ppl 331.22 | wps 20410.2 | wpb 510.9 | bsz 1 | num_updates 1652 | best_loss 8.372
2022-03-05 17:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1652 updates
2022-03-05 17:52:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:52:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt
2022-03-05 17:52:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_best.pt (epoch 34 @ 1652 updates, score 8.372) (writing took 6.29875162593089 seconds)
2022-03-05 17:52:54 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 17:52:54 | INFO | train | epoch 034 | loss 6.82 | ppl 112.97 | wps 8466.5 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 1652 | lr 0.000206559 | gnorm 1.052 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 12490
2022-03-05 17:52:54 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 17:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:58:41 | INFO | train_inner | epoch 035:     48 / 49 loss=6.774, ppl=109.44, wps=8606.4, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=1.061, loss_scale=32, train_wall=686, gb_free=9, wall=12837
2022-03-05 17:58:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:58:55 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.402 | ppl 338.18 | wps 20390.5 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.372
2022-03-05 17:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-05 17:58:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:58:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 17:58:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 35 @ 1701 updates, score 8.402) (writing took 2.9970562369562685 seconds)
2022-03-05 17:58:58 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 17:58:58 | INFO | train | epoch 035 | loss 6.719 | ppl 105.37 | wps 8722.1 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 1.072 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 12854
2022-03-05 17:58:58 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 17:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:05:00 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.436 | ppl 346.33 | wps 20362.1 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.372
2022-03-05 18:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-05 18:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 36 @ 1750 updates, score 8.436) (writing took 3.0404902200680226 seconds)
2022-03-05 18:05:03 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 18:05:03 | INFO | train | epoch 036 | loss 6.616 | ppl 98.09 | wps 8718.4 | ups 0.13 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 1.06 | loss_scale 32 | train_wall 333 | gb_free 9 | wall 13219
2022-03-05 18:05:03 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 18:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:08:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:11:03 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.427 | ppl 344.25 | wps 20690.8 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.372
2022-03-05 18:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-05 18:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 37 @ 1798 updates, score 8.427) (writing took 3.0265469481237233 seconds)
2022-03-05 18:11:06 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 18:11:06 | INFO | train | epoch 037 | loss 6.514 | ppl 91.39 | wps 8562 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 1.079 | loss_scale 32 | train_wall 332 | gb_free 9 | wall 13582
2022-03-05 18:11:06 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 18:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:11:21 | INFO | train_inner | epoch 038:      2 / 49 loss=6.563, ppl=94.58, wps=8494.2, ups=0.13, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.071, loss_scale=32, train_wall=682, gb_free=9, wall=13597
2022-03-05 18:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:17:05 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.451 | ppl 350.06 | wps 20725.5 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.372
2022-03-05 18:17:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-05 18:17:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.451) (writing took 2.9797476241365075 seconds)
2022-03-05 18:17:08 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 18:17:08 | INFO | train | epoch 038 | loss 6.415 | ppl 85.35 | wps 8793.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 1.115 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 13944
2022-03-05 18:17:08 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 18:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:22:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:23:06 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.503 | ppl 362.78 | wps 20545.9 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.372
2022-03-05 18:23:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-05 18:23:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 39 @ 1896 updates, score 8.503) (writing took 3.0026477111969143 seconds)
2022-03-05 18:23:09 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 18:23:09 | INFO | train | epoch 039 | loss 6.312 | ppl 79.45 | wps 8798.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 1.063 | loss_scale 32 | train_wall 330 | gb_free 9 | wall 14305
2022-03-05 18:23:09 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 18:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:23:38 | INFO | train_inner | epoch 040:      4 / 49 loss=6.356, ppl=81.92, wps=8803.3, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.09, loss_scale=32, train_wall=674, gb_free=9, wall=14334
2022-03-05 18:25:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:28:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:29:08 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.491 | ppl 359.87 | wps 20535.2 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.372
2022-03-05 18:29:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-05 18:29:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:29:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:29:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.491) (writing took 2.9451658411417156 seconds)
2022-03-05 18:29:11 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 18:29:11 | INFO | train | epoch 040 | loss 6.217 | ppl 74.4 | wps 8607.1 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.17 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 14666
2022-03-05 18:29:11 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 18:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:35:09 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.539 | ppl 371.86 | wps 20637 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.372
2022-03-05 18:35:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-05 18:35:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:35:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:35:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.539) (writing took 2.8954670699313283 seconds)
2022-03-05 18:35:12 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 18:35:12 | INFO | train | epoch 041 | loss 6.118 | ppl 69.45 | wps 8796.1 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.099 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 15028
2022-03-05 18:35:12 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 18:35:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:36:02 | INFO | train_inner | epoch 042:      7 / 49 loss=6.155, ppl=71.27, wps=8714.6, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.133, loss_scale=32, train_wall=682, gb_free=9, wall=15078
2022-03-05 18:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:41:10 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 8.57 | ppl 380.11 | wps 20691.6 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.372
2022-03-05 18:41:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-05 18:41:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:41:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 42 @ 2042 updates, score 8.57) (writing took 2.8821295839734375 seconds)
2022-03-05 18:41:13 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 18:41:13 | INFO | train | epoch 042 | loss 6.019 | ppl 64.83 | wps 8797.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.111 | loss_scale 64 | train_wall 330 | gb_free 9 | wall 15389
2022-03-05 18:41:13 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 18:41:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:41:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:47:12 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 8.604 | ppl 389.12 | wps 20765.5 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.372
2022-03-05 18:47:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-05 18:47:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 43 @ 2090 updates, score 8.604) (writing took 3.0092313659843057 seconds)
2022-03-05 18:47:15 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 18:47:15 | INFO | train | epoch 043 | loss 5.924 | ppl 60.71 | wps 8612.8 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.175 | loss_scale 32 | train_wall 330 | gb_free 9 | wall 15750
2022-03-05 18:47:15 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 18:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:48:26 | INFO | train_inner | epoch 044:     10 / 49 loss=5.953, ppl=61.93, wps=8717.6, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.153, loss_scale=32, train_wall=681, gb_free=9, wall=15822
2022-03-05 18:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:53:13 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 8.693 | ppl 413.93 | wps 20608.8 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.372
2022-03-05 18:53:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-05 18:53:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 44 @ 2139 updates, score 8.693) (writing took 2.9183543061371893 seconds)
2022-03-05 18:53:16 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 18:53:16 | INFO | train | epoch 044 | loss 5.833 | ppl 57 | wps 8795.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.267 | loss_scale 32 | train_wall 330 | gb_free 9 | wall 16112
2022-03-05 18:53:16 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 18:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:58:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 18:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:59:14 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 8.775 | ppl 437.94 | wps 20718.5 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.372
2022-03-05 18:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-05 18:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:59:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 18:59:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 45 @ 2187 updates, score 8.775) (writing took 3.0651581718120724 seconds)
2022-03-05 18:59:17 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 18:59:17 | INFO | train | epoch 045 | loss 5.726 | ppl 52.93 | wps 8614.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.118 | loss_scale 32 | train_wall 330 | gb_free 9 | wall 16473
2022-03-05 18:59:17 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 18:59:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:00:50 | INFO | train_inner | epoch 046:     13 / 49 loss=5.763, ppl=54.32, wps=8717.1, ups=0.13, wpb=64867.4, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.267, loss_scale=32, train_wall=681, gb_free=9, wall=16566
2022-03-05 19:05:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:05:16 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 8.794 | ppl 443.96 | wps 20730.9 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.372
2022-03-05 19:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-05 19:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:05:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:05:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 46 @ 2236 updates, score 8.794) (writing took 2.9711581198498607 seconds)
2022-03-05 19:05:19 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 19:05:19 | INFO | train | epoch 046 | loss 5.644 | ppl 50 | wps 8791 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.264 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 16834
2022-03-05 19:05:19 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 19:05:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:11:17 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 8.845 | ppl 459.91 | wps 20706.6 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.372
2022-03-05 19:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-05 19:11:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 47 @ 2285 updates, score 8.845) (writing took 2.878199091879651 seconds)
2022-03-05 19:11:20 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 19:11:20 | INFO | train | epoch 047 | loss 5.539 | ppl 46.49 | wps 8797.1 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.171 | loss_scale 32 | train_wall 331 | gb_free 9 | wall 17196
2022-03-05 19:11:20 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 19:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:13:08 | INFO | train_inner | epoch 048:     15 / 49 loss=5.557, ppl=47.08, wps=8801.3, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.181, loss_scale=32, train_wall=675, gb_free=9, wall=17303
2022-03-05 19:15:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:17:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:17:18 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 8.951 | ppl 494.92 | wps 20708.4 | wpb 510.9 | bsz 1 | num_updates 2333 | best_loss 8.372
2022-03-05 19:17:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2333 updates
2022-03-05 19:17:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:17:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:17:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 48 @ 2333 updates, score 8.951) (writing took 3.0169273482169956 seconds)
2022-03-05 19:17:21 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 19:17:21 | INFO | train | epoch 048 | loss 5.452 | ppl 43.77 | wps 8609.8 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 2333 | lr 0.000291667 | gnorm 1.324 | loss_scale 32 | train_wall 330 | gb_free 9 | wall 17557
2022-03-05 19:17:21 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 19:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:21:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:23:20 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 8.919 | ppl 484.08 | wps 20725.7 | wpb 510.9 | bsz 1 | num_updates 2381 | best_loss 8.372
2022-03-05 19:23:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2381 updates
2022-03-05 19:23:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:23:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:23:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 49 @ 2381 updates, score 8.919) (writing took 2.9773077860008925 seconds)
2022-03-05 19:23:23 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 19:23:23 | INFO | train | epoch 049 | loss 5.352 | ppl 40.84 | wps 8613.5 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 2381 | lr 0.000297665 | gnorm 1.25 | loss_scale 16 | train_wall 330 | gb_free 9 | wall 17919
2022-03-05 19:23:23 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 19:23:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:25:39 | INFO | train_inner | epoch 050:     19 / 49 loss=5.363, ppl=41.16, wps=8632.5, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.234, loss_scale=16, train_wall=688, gb_free=9, wall=18055
2022-03-05 19:29:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:29:21 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 8.958 | ppl 497.22 | wps 20722.8 | wpb 510.9 | bsz 1 | num_updates 2430 | best_loss 8.372
2022-03-05 19:29:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2430 updates
2022-03-05 19:29:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:29:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:29:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 50 @ 2430 updates, score 8.958) (writing took 2.9288825599942356 seconds)
2022-03-05 19:29:24 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 19:29:24 | INFO | train | epoch 050 | loss 5.262 | ppl 38.38 | wps 8798.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2430 | lr 0.000303789 | gnorm 1.236 | loss_scale 16 | train_wall 330 | gb_free 9 | wall 18280
2022-03-05 19:29:24 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 19:29:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:35:22 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.087 | ppl 543.69 | wps 20674.3 | wpb 510.9 | bsz 1 | num_updates 2479 | best_loss 8.372
2022-03-05 19:35:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2479 updates
2022-03-05 19:35:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 51 @ 2479 updates, score 9.087) (writing took 3.079088073922321 seconds)
2022-03-05 19:35:25 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 19:35:25 | INFO | train | epoch 051 | loss 5.17 | ppl 36.01 | wps 8795.5 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2479 | lr 0.000309913 | gnorm 1.302 | loss_scale 16 | train_wall 330 | gb_free 9 | wall 18641
2022-03-05 19:35:25 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 19:35:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:37:56 | INFO | train_inner | epoch 052:     21 / 49 loss=5.179, ppl=36.23, wps=8803.9, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.321, loss_scale=32, train_wall=674, gb_free=9, wall=18792
2022-03-05 19:41:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:41:24 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.207 | ppl 591.05 | wps 20684.5 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.372
2022-03-05 19:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-05 19:41:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 52 @ 2528 updates, score 9.207) (writing took 2.9945334009826183 seconds)
2022-03-05 19:41:27 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 19:41:27 | INFO | train | epoch 052 | loss 5.076 | ppl 33.72 | wps 8793.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.322 | loss_scale 32 | train_wall 330 | gb_free 9 | wall 19002
2022-03-05 19:41:27 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 19:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:47:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:47:25 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.21 | ppl 592.13 | wps 20668.1 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 8.372
2022-03-05 19:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-05 19:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 53 @ 2577 updates, score 9.21) (writing took 2.985730287153274 seconds)
2022-03-05 19:47:28 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 19:47:28 | INFO | train | epoch 053 | loss 4.979 | ppl 31.53 | wps 8795.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2577 | lr 0.000322161 | gnorm 1.326 | loss_scale 32 | train_wall 330 | gb_free 9 | wall 19364
2022-03-05 19:47:28 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 19:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:50:13 | INFO | train_inner | epoch 054:     23 / 49 loss=4.986, ppl=31.69, wps=8807.1, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.321, loss_scale=32, train_wall=674, gb_free=9, wall=19528
2022-03-05 19:53:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:53:25 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.278 | ppl 620.78 | wps 20945.2 | wpb 510.9 | bsz 1 | num_updates 2626 | best_loss 8.372
2022-03-05 19:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2626 updates
2022-03-05 19:53:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:53:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:53:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 54 @ 2626 updates, score 9.278) (writing took 2.9397682729177177 seconds)
2022-03-05 19:53:28 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 19:53:28 | INFO | train | epoch 054 | loss 4.894 | ppl 29.74 | wps 8836.5 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2626 | lr 0.000328284 | gnorm 1.454 | loss_scale 64 | train_wall 329 | gb_free 9 | wall 19723
2022-03-05 19:53:28 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 19:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:53:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 19:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:59:24 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.426 | ppl 687.9 | wps 20921 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.372
2022-03-05 19:59:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-05 19:59:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:59:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 19:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 55 @ 2674 updates, score 9.426) (writing took 2.8269330330658704 seconds)
2022-03-05 19:59:27 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 19:59:27 | INFO | train | epoch 055 | loss 4.791 | ppl 27.69 | wps 8662.1 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.282 | loss_scale 32 | train_wall 329 | gb_free 9 | wall 20083
2022-03-05 19:59:27 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 19:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:02:32 | INFO | train_inner | epoch 056:     26 / 49 loss=4.795, ppl=27.76, wps=8766.6, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.379, loss_scale=32, train_wall=679, gb_free=9, wall=20268
2022-03-05 20:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:05:23 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.441 | ppl 695.19 | wps 20921 | wpb 510.9 | bsz 1 | num_updates 2723 | best_loss 8.372
2022-03-05 20:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2723 updates
2022-03-05 20:05:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:05:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 56 @ 2723 updates, score 9.441) (writing took 2.880043834913522 seconds)
2022-03-05 20:05:26 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 20:05:26 | INFO | train | epoch 056 | loss 4.707 | ppl 26.12 | wps 8847.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2723 | lr 0.000340407 | gnorm 1.369 | loss_scale 32 | train_wall 329 | gb_free 9 | wall 20442
2022-03-05 20:05:26 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 20:05:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:08:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:11:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:11:22 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.462 | ppl 705.47 | wps 20960.5 | wpb 510.9 | bsz 1 | num_updates 2771 | best_loss 8.372
2022-03-05 20:11:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2771 updates
2022-03-05 20:11:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 57 @ 2771 updates, score 9.462) (writing took 2.8456246231216937 seconds)
2022-03-05 20:11:25 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 20:11:25 | INFO | train | epoch 057 | loss 4.617 | ppl 24.53 | wps 8666.5 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 2771 | lr 0.000346406 | gnorm 1.419 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 20801
2022-03-05 20:11:25 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 20:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:14:52 | INFO | train_inner | epoch 058:     29 / 49 loss=4.612, ppl=24.45, wps=8770.5, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.409, loss_scale=16, train_wall=678, gb_free=9, wall=21008
2022-03-05 20:17:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:17:22 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.601 | ppl 776.34 | wps 20951.8 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.372
2022-03-05 20:17:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-05 20:17:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 58 @ 2820 updates, score 9.601) (writing took 2.8649814820382744 seconds)
2022-03-05 20:17:24 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 20:17:24 | INFO | train | epoch 058 | loss 4.527 | ppl 23.05 | wps 8849 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.447 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 21160
2022-03-05 20:17:25 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 20:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:23:21 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.517 | ppl 732.44 | wps 20963.8 | wpb 510.9 | bsz 1 | num_updates 2869 | best_loss 8.372
2022-03-05 20:23:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2869 updates
2022-03-05 20:23:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:23:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:23:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 59 @ 2869 updates, score 9.517) (writing took 2.8546612539794296 seconds)
2022-03-05 20:23:24 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 20:23:24 | INFO | train | epoch 059 | loss 4.438 | ppl 21.68 | wps 8851.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2869 | lr 0.000358653 | gnorm 1.455 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 21519
2022-03-05 20:23:24 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 20:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:27:05 | INFO | train_inner | epoch 060:     31 / 49 loss=4.423, ppl=21.45, wps=8855.6, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.408, loss_scale=32, train_wall=672, gb_free=9, wall=21740
2022-03-05 20:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:29:20 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.684 | ppl 822.45 | wps 20957.9 | wpb 510.9 | bsz 1 | num_updates 2918 | best_loss 8.372
2022-03-05 20:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2918 updates
2022-03-05 20:29:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:29:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:29:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 60 @ 2918 updates, score 9.684) (writing took 2.8853811328299344 seconds)
2022-03-05 20:29:23 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 20:29:23 | INFO | train | epoch 060 | loss 4.347 | ppl 20.36 | wps 8846.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 2918 | lr 0.000364777 | gnorm 1.469 | loss_scale 32 | train_wall 329 | gb_free 9 | wall 21879
2022-03-05 20:29:23 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 20:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:33:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:35:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:35:19 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.689 | ppl 825.57 | wps 20937.2 | wpb 510.9 | bsz 1 | num_updates 2966 | best_loss 8.372
2022-03-05 20:35:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2966 updates
2022-03-05 20:35:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:35:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:35:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 61 @ 2966 updates, score 9.689) (writing took 2.868994780117646 seconds)
2022-03-05 20:35:22 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 20:35:22 | INFO | train | epoch 061 | loss 4.252 | ppl 19.06 | wps 8667.2 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 2966 | lr 0.000370776 | gnorm 1.423 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 22238
2022-03-05 20:35:22 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 20:35:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:39:24 | INFO | train_inner | epoch 062:     34 / 49 loss=4.244, ppl=18.95, wps=8771.2, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.525, loss_scale=16, train_wall=678, gb_free=9, wall=22480
2022-03-05 20:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:41:18 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.929 | ppl 974.57 | wps 20926.9 | wpb 510.9 | bsz 1 | num_updates 3015 | best_loss 8.372
2022-03-05 20:41:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3015 updates
2022-03-05 20:41:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:41:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:41:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 62 @ 3015 updates, score 9.929) (writing took 2.857514669885859 seconds)
2022-03-05 20:41:21 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 20:41:21 | INFO | train | epoch 062 | loss 4.175 | ppl 18.07 | wps 8852.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3015 | lr 0.0003769 | gnorm 1.522 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 22597
2022-03-05 20:41:21 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 20:41:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:47:17 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 10.048 | ppl 1058.88 | wps 20919 | wpb 510.9 | bsz 1 | num_updates 3064 | best_loss 8.372
2022-03-05 20:47:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3064 updates
2022-03-05 20:47:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:47:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 63 @ 3064 updates, score 10.048) (writing took 2.8780461291316897 seconds)
2022-03-05 20:47:20 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 20:47:20 | INFO | train | epoch 063 | loss 4.077 | ppl 16.88 | wps 8849.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3064 | lr 0.000383023 | gnorm 1.419 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 22956
2022-03-05 20:47:20 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 20:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:51:37 | INFO | train_inner | epoch 064:     36 / 49 loss=4.066, ppl=16.75, wps=8857.7, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.46, loss_scale=32, train_wall=671, gb_free=9, wall=23212
2022-03-05 20:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:53:16 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.978 | ppl 1008.52 | wps 20940.6 | wpb 510.9 | bsz 1 | num_updates 3113 | best_loss 8.372
2022-03-05 20:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3113 updates
2022-03-05 20:53:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:53:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:53:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 64 @ 3113 updates, score 9.978) (writing took 2.8863717480562627 seconds)
2022-03-05 20:53:19 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 20:53:19 | INFO | train | epoch 064 | loss 3.996 | ppl 15.95 | wps 8849 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3113 | lr 0.000389147 | gnorm 1.52 | loss_scale 32 | train_wall 329 | gb_free 9 | wall 23315
2022-03-05 20:53:19 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 20:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:54:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:59:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:59:15 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.152 | ppl 1137.88 | wps 20963 | wpb 510.9 | bsz 1 | num_updates 3161 | best_loss 8.372
2022-03-05 20:59:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3161 updates
2022-03-05 20:59:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:59:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 20:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 65 @ 3161 updates, score 10.152) (writing took 2.884430140024051 seconds)
2022-03-05 20:59:18 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 20:59:18 | INFO | train | epoch 065 | loss 3.91 | ppl 15.03 | wps 8673.2 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 3161 | lr 0.000395146 | gnorm 1.567 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 23674
2022-03-05 20:59:18 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 20:59:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:03:56 | INFO | train_inner | epoch 066:     39 / 49 loss=3.885, ppl=14.77, wps=8774.8, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.527, loss_scale=16, train_wall=678, gb_free=9, wall=23952
2022-03-05 21:05:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:05:14 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.053 | ppl 1062.1 | wps 20947.5 | wpb 510.9 | bsz 1 | num_updates 3210 | best_loss 8.372
2022-03-05 21:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3210 updates
2022-03-05 21:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 66 @ 3210 updates, score 10.053) (writing took 2.8502662361133844 seconds)
2022-03-05 21:05:17 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 21:05:17 | INFO | train | epoch 066 | loss 3.825 | ppl 14.17 | wps 8853.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3210 | lr 0.00040127 | gnorm 1.562 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 24033
2022-03-05 21:05:17 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 21:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:11:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:11:13 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.198 | ppl 1174.8 | wps 20947.2 | wpb 510.9 | bsz 1 | num_updates 3259 | best_loss 8.372
2022-03-05 21:11:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3259 updates
2022-03-05 21:11:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:11:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 67 @ 3259 updates, score 10.198) (writing took 2.934366917004809 seconds)
2022-03-05 21:11:16 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 21:11:16 | INFO | train | epoch 067 | loss 3.742 | ppl 13.38 | wps 8854.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3259 | lr 0.000407394 | gnorm 1.513 | loss_scale 32 | train_wall 329 | gb_free 9 | wall 24392
2022-03-05 21:11:16 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 21:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:14:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:16:15 | INFO | train_inner | epoch 068:     42 / 49 loss=3.718, ppl=13.16, wps=8775.3, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.571, loss_scale=16, train_wall=678, gb_free=9, wall=24691
2022-03-05 21:17:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:17:12 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.238 | ppl 1207.93 | wps 20922.5 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 8.372
2022-03-05 21:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-05 21:17:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:17:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 68 @ 3307 updates, score 10.238) (writing took 2.96111336001195 seconds)
2022-03-05 21:17:15 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 21:17:15 | INFO | train | epoch 068 | loss 3.658 | ppl 12.62 | wps 8668.5 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.541 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 24751
2022-03-05 21:17:15 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 21:17:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:23:11 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.374 | ppl 1327.2 | wps 20826.2 | wpb 510.9 | bsz 1 | num_updates 3356 | best_loss 8.372
2022-03-05 21:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3356 updates
2022-03-05 21:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 69 @ 3356 updates, score 10.374) (writing took 2.9338717141654342 seconds)
2022-03-05 21:23:14 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 21:23:14 | INFO | train | epoch 069 | loss 3.578 | ppl 11.95 | wps 8851.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3356 | lr 0.000419516 | gnorm 1.587 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 25110
2022-03-05 21:23:14 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 21:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:28:27 | INFO | train_inner | epoch 070:     44 / 49 loss=3.547, ppl=11.69, wps=8860.1, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.585, loss_scale=16, train_wall=671, gb_free=9, wall=25423
2022-03-05 21:28:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:29:10 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.539 | ppl 1488.04 | wps 20916.2 | wpb 510.9 | bsz 1 | num_updates 3405 | best_loss 8.372
2022-03-05 21:29:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3405 updates
2022-03-05 21:29:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:29:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:29:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 70 @ 3405 updates, score 10.539) (writing took 2.91136372811161 seconds)
2022-03-05 21:29:13 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 21:29:13 | INFO | train | epoch 070 | loss 3.497 | ppl 11.29 | wps 8857.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3405 | lr 0.00042564 | gnorm 1.61 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 25469
2022-03-05 21:29:13 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 21:29:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:33:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:34:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:35:09 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.626 | ppl 1579.91 | wps 20754.3 | wpb 510.9 | bsz 1 | num_updates 3453 | best_loss 8.372
2022-03-05 21:35:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3453 updates
2022-03-05 21:35:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:35:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:35:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 71 @ 3453 updates, score 10.626) (writing took 2.996390704996884 seconds)
2022-03-05 21:35:12 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 21:35:12 | INFO | train | epoch 071 | loss 3.404 | ppl 10.59 | wps 8665.8 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 3453 | lr 0.000431639 | gnorm 1.49 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 25828
2022-03-05 21:35:12 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 21:35:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:40:47 | INFO | train_inner | epoch 072:     47 / 49 loss=3.378, ppl=10.4, wps=8775.9, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.553, loss_scale=16, train_wall=678, gb_free=9, wall=26162
2022-03-05 21:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:41:08 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.611 | ppl 1563.51 | wps 20686.2 | wpb 510.9 | bsz 1 | num_updates 3502 | best_loss 8.372
2022-03-05 21:41:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3502 updates
2022-03-05 21:41:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:41:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:41:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 72 @ 3502 updates, score 10.611) (writing took 2.8641902001108974 seconds)
2022-03-05 21:41:11 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 21:41:11 | INFO | train | epoch 072 | loss 3.336 | ppl 10.1 | wps 8857.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3502 | lr 0.000437762 | gnorm 1.628 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 26187
2022-03-05 21:41:11 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 21:41:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:46:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:47:07 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.817 | ppl 1804.09 | wps 20681.4 | wpb 510.9 | bsz 1 | num_updates 3551 | best_loss 8.372
2022-03-05 21:47:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3551 updates
2022-03-05 21:47:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:47:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:47:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 73 @ 3551 updates, score 10.817) (writing took 2.845957078039646 seconds)
2022-03-05 21:47:10 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 21:47:10 | INFO | train | epoch 073 | loss 3.242 | ppl 9.46 | wps 8855.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3551 | lr 0.000443886 | gnorm 1.471 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 26545
2022-03-05 21:47:10 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 21:47:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:52:55 | INFO | train_inner | epoch 074:     49 / 49 loss=3.218, ppl=9.3, wps=8859.6, ups=0.14, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.584, loss_scale=32, train_wall=668, gb_free=9, wall=26891
2022-03-05 21:52:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:53:06 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.9 | ppl 1910.76 | wps 20943.5 | wpb 510.9 | bsz 1 | num_updates 3600 | best_loss 8.372
2022-03-05 21:53:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3600 updates
2022-03-05 21:53:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:53:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 74 @ 3600 updates, score 10.9) (writing took 2.8751256649848074 seconds)
2022-03-05 21:53:08 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 21:53:08 | INFO | train | epoch 074 | loss 3.188 | ppl 9.11 | wps 8855.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3600 | lr 0.00045001 | gnorm 1.694 | loss_scale 32 | train_wall 329 | gb_free 9 | wall 26904
2022-03-05 21:53:09 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 21:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:55:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:58:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:59:04 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.851 | ppl 1846.74 | wps 20832.2 | wpb 510.9 | bsz 1 | num_updates 3648 | best_loss 8.372
2022-03-05 21:59:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3648 updates
2022-03-05 21:59:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:59:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 21:59:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 75 @ 3648 updates, score 10.851) (writing took 2.8773771522101015 seconds)
2022-03-05 21:59:07 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 21:59:07 | INFO | train | epoch 075 | loss 3.094 | ppl 8.54 | wps 8674.8 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 3648 | lr 0.000456009 | gnorm 1.589 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 27263
2022-03-05 21:59:07 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 21:59:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:04:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:05:03 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 11.012 | ppl 2065.66 | wps 20930.3 | wpb 510.9 | bsz 1 | num_updates 3697 | best_loss 8.372
2022-03-05 22:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3697 updates
2022-03-05 22:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 76 @ 3697 updates, score 11.012) (writing took 2.8876674089115113 seconds)
2022-03-05 22:05:06 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 22:05:06 | INFO | train | epoch 076 | loss 3.031 | ppl 8.17 | wps 8862 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3697 | lr 0.000462133 | gnorm 1.616 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 27622
2022-03-05 22:05:06 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 22:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:05:27 | INFO | train_inner | epoch 077:      3 / 49 loss=3.057, ppl=8.32, wps=8623.7, ups=0.13, wpb=64867.4, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.598, loss_scale=16, train_wall=678, gb_free=9, wall=27643
2022-03-05 22:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:11:02 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 11.12 | ppl 2225.71 | wps 20922.8 | wpb 510.9 | bsz 1 | num_updates 3746 | best_loss 8.372
2022-03-05 22:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3746 updates
2022-03-05 22:11:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 77 @ 3746 updates, score 11.12) (writing took 2.8446987001225352 seconds)
2022-03-05 22:11:05 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 22:11:05 | INFO | train | epoch 077 | loss 2.945 | ppl 7.7 | wps 8859.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3746 | lr 0.000468256 | gnorm 1.593 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 27980
2022-03-05 22:11:05 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 22:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:13:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:17:00 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.013 | ppl 2067.07 | wps 20991.6 | wpb 510.9 | bsz 1 | num_updates 3794 | best_loss 8.372
2022-03-05 22:17:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3794 updates
2022-03-05 22:17:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:17:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:17:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 78 @ 3794 updates, score 11.013) (writing took 2.8813776611350477 seconds)
2022-03-05 22:17:03 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 22:17:03 | INFO | train | epoch 078 | loss 2.873 | ppl 7.33 | wps 8676.6 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 3794 | lr 0.000474255 | gnorm 1.591 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 28339
2022-03-05 22:17:03 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 22:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:17:46 | INFO | train_inner | epoch 079:      6 / 49 loss=2.903, ppl=7.48, wps=8781.2, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.632, loss_scale=16, train_wall=678, gb_free=9, wall=28382
2022-03-05 22:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:22:59 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.122 | ppl 2228.88 | wps 20920.4 | wpb 510.9 | bsz 1 | num_updates 3843 | best_loss 8.372
2022-03-05 22:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3843 updates
2022-03-05 22:22:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:23:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 79 @ 3843 updates, score 11.122) (writing took 2.85602746414952 seconds)
2022-03-05 22:23:02 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 22:23:02 | INFO | train | epoch 079 | loss 2.817 | ppl 7.05 | wps 8863.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3843 | lr 0.000480379 | gnorm 1.632 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 28698
2022-03-05 22:23:02 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 22:23:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:28:58 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.515 | ppl 2927.35 | wps 20945.4 | wpb 510.9 | bsz 1 | num_updates 3892 | best_loss 8.372
2022-03-05 22:28:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3892 updates
2022-03-05 22:28:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:29:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:29:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 80 @ 3892 updates, score 11.515) (writing took 2.902914969017729 seconds)
2022-03-05 22:29:01 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 22:29:01 | INFO | train | epoch 080 | loss 2.728 | ppl 6.63 | wps 8859.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3892 | lr 0.000486503 | gnorm 1.573 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 29056
2022-03-05 22:29:01 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 22:29:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:29:58 | INFO | train_inner | epoch 081:      8 / 49 loss=2.76, ppl=6.77, wps=8868.7, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.558, loss_scale=32, train_wall=671, gb_free=9, wall=29113
2022-03-05 22:31:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:34:56 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.514 | ppl 2923.87 | wps 20931.6 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 8.372
2022-03-05 22:34:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-05 22:34:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:34:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 81 @ 3940 updates, score 11.514) (writing took 2.880069440929219 seconds)
2022-03-05 22:34:59 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 22:34:59 | INFO | train | epoch 081 | loss 2.669 | ppl 6.36 | wps 8679.3 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.659 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 29415
2022-03-05 22:34:59 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 22:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:40:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:40:55 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.588 | ppl 3077.54 | wps 20957.5 | wpb 510.9 | bsz 1 | num_updates 3989 | best_loss 8.372
2022-03-05 22:40:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3989 updates
2022-03-05 22:40:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 82 @ 3989 updates, score 11.588) (writing took 2.856885536806658 seconds)
2022-03-05 22:40:58 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 22:40:58 | INFO | train | epoch 082 | loss 2.593 | ppl 6.03 | wps 8864.5 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 3989 | lr 0.000498625 | gnorm 1.56 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 29774
2022-03-05 22:40:58 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 22:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:42:16 | INFO | train_inner | epoch 083:     11 / 49 loss=2.615, ppl=6.13, wps=8785, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.639, loss_scale=16, train_wall=677, gb_free=9, wall=29852
2022-03-05 22:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:46:53 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.693 | ppl 3309.9 | wps 20950 | wpb 510.9 | bsz 1 | num_updates 4038 | best_loss 8.372
2022-03-05 22:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4038 updates
2022-03-05 22:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 83 @ 4038 updates, score 11.693) (writing took 2.8439339969772846 seconds)
2022-03-05 22:46:56 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 22:46:56 | INFO | train | epoch 083 | loss 2.526 | ppl 5.76 | wps 8865.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4038 | lr 0.000497642 | gnorm 1.581 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 30132
2022-03-05 22:46:56 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 22:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:47:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:52:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:52:52 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.825 | ppl 3628 | wps 20952.9 | wpb 510.9 | bsz 1 | num_updates 4086 | best_loss 8.372
2022-03-05 22:52:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4086 updates
2022-03-05 22:52:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:52:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:52:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 84 @ 4086 updates, score 11.825) (writing took 2.8517606048844755 seconds)
2022-03-05 22:52:55 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 22:52:55 | INFO | train | epoch 084 | loss 2.46 | ppl 5.5 | wps 8683.6 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 4086 | lr 0.00049471 | gnorm 1.64 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 30490
2022-03-05 22:52:55 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 22:52:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:54:34 | INFO | train_inner | epoch 085:     14 / 49 loss=2.472, ppl=5.55, wps=8787, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.578, loss_scale=16, train_wall=677, gb_free=9, wall=30590
2022-03-05 22:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:58:50 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.837 | ppl 3659.41 | wps 20907 | wpb 510.9 | bsz 1 | num_updates 4135 | best_loss 8.372
2022-03-05 22:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4135 updates
2022-03-05 22:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:58:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 22:58:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 85 @ 4135 updates, score 11.837) (writing took 2.80927207111381 seconds)
2022-03-05 22:58:53 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 22:58:53 | INFO | train | epoch 085 | loss 2.388 | ppl 5.23 | wps 8870.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4135 | lr 0.00049177 | gnorm 1.56 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 30849
2022-03-05 22:58:53 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 22:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:04:49 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.882 | ppl 3775.21 | wps 20884.7 | wpb 510.9 | bsz 1 | num_updates 4184 | best_loss 8.372
2022-03-05 23:04:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4184 updates
2022-03-05 23:04:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:04:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:04:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 86 @ 4184 updates, score 11.882) (writing took 2.838107684860006 seconds)
2022-03-05 23:04:51 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 23:04:51 | INFO | train | epoch 086 | loss 2.314 | ppl 4.97 | wps 8866.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4184 | lr 0.000488882 | gnorm 1.49 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 31207
2022-03-05 23:04:51 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 23:04:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:06:45 | INFO | train_inner | epoch 087:     16 / 49 loss=2.327, ppl=5.02, wps=8872.9, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.518, loss_scale=32, train_wall=670, gb_free=9, wall=31321
2022-03-05 23:09:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:10:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:10:47 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 12.096 | ppl 4378.48 | wps 20925.6 | wpb 510.9 | bsz 1 | num_updates 4232 | best_loss 8.372
2022-03-05 23:10:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4232 updates
2022-03-05 23:10:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:10:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:10:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 87 @ 4232 updates, score 12.096) (writing took 2.8427252050023526 seconds)
2022-03-05 23:10:50 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 23:10:50 | INFO | train | epoch 087 | loss 2.254 | ppl 4.77 | wps 8674.4 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 4232 | lr 0.000486102 | gnorm 1.543 | loss_scale 16 | train_wall 329 | gb_free 9 | wall 31566
2022-03-05 23:10:50 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 23:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:16:46 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 12.197 | ppl 4695.57 | wps 20961.9 | wpb 510.9 | bsz 1 | num_updates 4281 | best_loss 8.372
2022-03-05 23:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4281 updates
2022-03-05 23:16:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:16:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 88 @ 4281 updates, score 12.197) (writing took 2.8111074280459434 seconds)
2022-03-05 23:16:49 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 23:16:49 | INFO | train | epoch 088 | loss 2.183 | ppl 4.54 | wps 8870 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4281 | lr 0.000483312 | gnorm 1.419 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 31924
2022-03-05 23:16:49 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 23:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:19:04 | INFO | train_inner | epoch 089:     19 / 49 loss=2.198, ppl=4.59, wps=8787.6, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.512, loss_scale=16, train_wall=677, gb_free=9, wall=32059
2022-03-05 23:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:22:44 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 12.336 | ppl 5170.36 | wps 20941.4 | wpb 510.9 | bsz 1 | num_updates 4330 | best_loss 8.372
2022-03-05 23:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4330 updates
2022-03-05 23:22:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:22:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:22:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 89 @ 4330 updates, score 12.336) (writing took 2.8226764530409127 seconds)
2022-03-05 23:22:47 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 23:22:47 | INFO | train | epoch 089 | loss 2.131 | ppl 4.38 | wps 8872.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4330 | lr 0.000480569 | gnorm 1.512 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 32282
2022-03-05 23:22:47 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 23:22:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:28:42 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 12.329 | ppl 5143.47 | wps 20929.8 | wpb 510.9 | bsz 1 | num_updates 4379 | best_loss 8.372
2022-03-05 23:28:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4379 updates
2022-03-05 23:28:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:28:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:28:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 90 @ 4379 updates, score 12.329) (writing took 2.8971569589339197 seconds)
2022-03-05 23:28:45 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 23:28:45 | INFO | train | epoch 090 | loss 2.07 | ppl 4.2 | wps 8863.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4379 | lr 0.000477873 | gnorm 1.485 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 32641
2022-03-05 23:28:45 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 23:28:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:31:15 | INFO | train_inner | epoch 091:     21 / 49 loss=2.074, ppl=4.21, wps=8873.8, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.45, loss_scale=32, train_wall=670, gb_free=9, wall=32790
2022-03-05 23:34:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 23:34:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:41 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 12.37 | ppl 5294.54 | wps 20972.6 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 8.372
2022-03-05 23:34:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-05 23:34:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:34:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:34:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 91 @ 4427 updates, score 12.37) (writing took 2.8682392409536988 seconds)
2022-03-05 23:34:44 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 23:34:44 | INFO | train | epoch 091 | loss 2.009 | ppl 4.02 | wps 8685.9 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.441 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 32999
2022-03-05 23:34:44 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 23:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:40:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:40:39 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 12.524 | ppl 5891.51 | wps 20981.1 | wpb 510.9 | bsz 1 | num_updates 4476 | best_loss 8.372
2022-03-05 23:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4476 updates
2022-03-05 23:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 92 @ 4476 updates, score 12.524) (writing took 2.843350693117827 seconds)
2022-03-05 23:40:42 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 23:40:42 | INFO | train | epoch 092 | loss 1.955 | ppl 3.88 | wps 8871.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4476 | lr 0.000472667 | gnorm 1.426 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 33358
2022-03-05 23:40:42 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 23:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:43:33 | INFO | train_inner | epoch 093:     24 / 49 loss=1.957, ppl=3.88, wps=8791.7, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.458, loss_scale=16, train_wall=677, gb_free=9, wall=33528
2022-03-05 23:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:46:37 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 12.657 | ppl 6456.93 | wps 20926.7 | wpb 510.9 | bsz 1 | num_updates 4525 | best_loss 8.372
2022-03-05 23:46:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4525 updates
2022-03-05 23:46:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:46:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 93 @ 4525 updates, score 12.657) (writing took 2.8373123190831393 seconds)
2022-03-05 23:46:40 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 23:46:40 | INFO | train | epoch 093 | loss 1.906 | ppl 3.75 | wps 8868.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4525 | lr 0.0004701 | gnorm 1.474 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 33716
2022-03-05 23:46:40 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 23:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:52:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:52:35 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 12.884 | ppl 7557.85 | wps 20943.4 | wpb 510.9 | bsz 1 | num_updates 4574 | best_loss 8.372
2022-03-05 23:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4574 updates
2022-03-05 23:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 94 @ 4574 updates, score 12.884) (writing took 2.8154725858476013 seconds)
2022-03-05 23:52:38 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 23:52:38 | INFO | train | epoch 094 | loss 1.845 | ppl 3.59 | wps 8873.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4574 | lr 0.000467576 | gnorm 1.416 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 34074
2022-03-05 23:52:38 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 23:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:55:43 | INFO | train_inner | epoch 095:     26 / 49 loss=1.85, ppl=3.6, wps=8877.1, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.422, loss_scale=32, train_wall=670, gb_free=9, wall=34259
2022-03-05 23:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:58:34 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.783 | ppl 7048.38 | wps 20927.9 | wpb 510.9 | bsz 1 | num_updates 4623 | best_loss 8.372
2022-03-05 23:58:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4623 updates
2022-03-05 23:58:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:58:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-05 23:58:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 95 @ 4623 updates, score 12.783) (writing took 2.8814195489976555 seconds)
2022-03-05 23:58:37 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 23:58:37 | INFO | train | epoch 095 | loss 1.796 | ppl 3.47 | wps 8868.5 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4623 | lr 0.000465091 | gnorm 1.42 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 34432
2022-03-05 23:58:37 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 23:58:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:04:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:04:32 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.913 | ppl 7714.65 | wps 20862.6 | wpb 510.9 | bsz 1 | num_updates 4672 | best_loss 8.372
2022-03-06 00:04:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4672 updates
2022-03-06 00:04:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 96 @ 4672 updates, score 12.913) (writing took 2.874273293185979 seconds)
2022-03-06 00:04:35 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 00:04:35 | INFO | train | epoch 096 | loss 1.745 | ppl 3.35 | wps 8868.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4672 | lr 0.000462646 | gnorm 1.381 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 34791
2022-03-06 00:04:35 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 00:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:05:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:08:01 | INFO | train_inner | epoch 097:     29 / 49 loss=1.742, ppl=3.35, wps=8791, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.388, loss_scale=32, train_wall=676, gb_free=9, wall=34997
2022-03-06 00:10:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:10:30 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 13.065 | ppl 8572.1 | wps 20812.8 | wpb 510.9 | bsz 1 | num_updates 4720 | best_loss 8.372
2022-03-06 00:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4720 updates
2022-03-06 00:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 97 @ 4720 updates, score 13.065) (writing took 2.888260137056932 seconds)
2022-03-06 00:10:33 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 00:10:33 | INFO | train | epoch 097 | loss 1.698 | ppl 3.24 | wps 8688 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 4720 | lr 0.000460287 | gnorm 1.379 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 35149
2022-03-06 00:10:33 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 00:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:16:29 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.973 | ppl 8040.77 | wps 20932.6 | wpb 510.9 | bsz 1 | num_updates 4769 | best_loss 8.372
2022-03-06 00:16:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4769 updates
2022-03-06 00:16:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:16:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:16:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 98 @ 4769 updates, score 12.973) (writing took 2.900270852027461 seconds)
2022-03-06 00:16:32 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 00:16:32 | INFO | train | epoch 098 | loss 1.657 | ppl 3.15 | wps 8869.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4769 | lr 0.000457917 | gnorm 1.372 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 35507
2022-03-06 00:16:32 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 00:16:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:20:12 | INFO | train_inner | epoch 099:     31 / 49 loss=1.652, ppl=3.14, wps=8877.9, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.373, loss_scale=32, train_wall=670, gb_free=9, wall=35728
2022-03-06 00:21:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:22:27 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 13.242 | ppl 9687.25 | wps 20878.1 | wpb 510.9 | bsz 1 | num_updates 4817 | best_loss 8.372
2022-03-06 00:22:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4817 updates
2022-03-06 00:22:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:22:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 99 @ 4817 updates, score 13.242) (writing took 2.8624681439250708 seconds)
2022-03-06 00:22:30 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 00:22:30 | INFO | train | epoch 099 | loss 1.609 | ppl 3.05 | wps 8692.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 4817 | lr 0.000455629 | gnorm 1.369 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 35865
2022-03-06 00:22:30 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 00:22:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:28:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:28:25 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 13.239 | ppl 9667.92 | wps 20917.8 | wpb 510.9 | bsz 1 | num_updates 4866 | best_loss 8.372
2022-03-06 00:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4866 updates
2022-03-06 00:28:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 100 @ 4866 updates, score 13.239) (writing took 2.842293659923598 seconds)
2022-03-06 00:28:28 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 00:28:28 | INFO | train | epoch 100 | loss 1.569 | ppl 2.97 | wps 8876.1 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4866 | lr 0.000453329 | gnorm 1.341 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 36223
2022-03-06 00:28:28 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 00:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:32:29 | INFO | train_inner | epoch 101:     34 / 49 loss=1.562, ppl=2.95, wps=8797.4, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.355, loss_scale=32, train_wall=676, gb_free=9, wall=36465
2022-03-06 00:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:34:23 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 13.39 | ppl 10731.2 | wps 20912.9 | wpb 510.9 | bsz 1 | num_updates 4915 | best_loss 8.372
2022-03-06 00:34:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4915 updates
2022-03-06 00:34:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:34:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:34:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 101 @ 4915 updates, score 13.39) (writing took 2.9035249459557235 seconds)
2022-03-06 00:34:26 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 00:34:26 | INFO | train | epoch 101 | loss 1.532 | ppl 2.89 | wps 8875 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 4915 | lr 0.000451064 | gnorm 1.369 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 36582
2022-03-06 00:34:26 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 00:34:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:37:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:40:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:40:21 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 13.401 | ppl 10819.4 | wps 20957.4 | wpb 510.9 | bsz 1 | num_updates 4963 | best_loss 8.372
2022-03-06 00:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4963 updates
2022-03-06 00:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:40:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 102 @ 4963 updates, score 13.401) (writing took 2.8560287312138826 seconds)
2022-03-06 00:40:24 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 00:40:24 | INFO | train | epoch 102 | loss 1.486 | ppl 2.8 | wps 8695.2 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 4963 | lr 0.000448878 | gnorm 1.302 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 36940
2022-03-06 00:40:24 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 00:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:44:47 | INFO | train_inner | epoch 103:     37 / 49 loss=1.483, ppl=2.8, wps=8797.4, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.339, loss_scale=32, train_wall=676, gb_free=9, wall=37203
2022-03-06 00:46:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:46:19 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 13.351 | ppl 10449 | wps 20955.1 | wpb 510.9 | bsz 1 | num_updates 5012 | best_loss 8.372
2022-03-06 00:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5012 updates
2022-03-06 00:46:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:46:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:46:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 103 @ 5012 updates, score 13.351) (writing took 2.814430780010298 seconds)
2022-03-06 00:46:22 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 00:46:22 | INFO | train | epoch 103 | loss 1.458 | ppl 2.75 | wps 8876.1 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5012 | lr 0.000446678 | gnorm 1.362 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 37298
2022-03-06 00:46:22 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 00:46:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:52:17 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 13.529 | ppl 11823.7 | wps 20947.1 | wpb 510.9 | bsz 1 | num_updates 5061 | best_loss 8.372
2022-03-06 00:52:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5061 updates
2022-03-06 00:52:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:52:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 104 @ 5061 updates, score 13.529) (writing took 2.8315033230464906 seconds)
2022-03-06 00:52:20 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 00:52:20 | INFO | train | epoch 104 | loss 1.415 | ppl 2.67 | wps 8879 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5061 | lr 0.00044451 | gnorm 1.284 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 37656
2022-03-06 00:52:20 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 00:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:53:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:54:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:57:11 | INFO | train_inner | epoch 105:     41 / 49 loss=1.411, ppl=2.66, wps=8716.4, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.31, loss_scale=16, train_wall=683, gb_free=9, wall=37947
2022-03-06 00:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:58:15 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 13.667 | ppl 13004 | wps 20835.9 | wpb 510.9 | bsz 1 | num_updates 5108 | best_loss 8.372
2022-03-06 00:58:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5108 updates
2022-03-06 00:58:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 00:58:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 105 @ 5108 updates, score 13.667) (writing took 2.8530372350942343 seconds)
2022-03-06 00:58:18 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 00:58:18 | INFO | train | epoch 105 | loss 1.385 | ppl 2.61 | wps 8512.6 | ups 0.13 | wpb 64829.4 | bsz 126.6 | num_updates 5108 | lr 0.000442461 | gnorm 1.324 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 38013
2022-03-06 00:58:18 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 00:58:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:04:13 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 13.794 | ppl 14204.3 | wps 20922.9 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 8.372
2022-03-06 01:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-06 01:04:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 106 @ 5157 updates, score 13.794) (writing took 2.903236989863217 seconds)
2022-03-06 01:04:15 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 01:04:15 | INFO | train | epoch 106 | loss 1.349 | ppl 2.55 | wps 8882.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5157 | lr 0.000440353 | gnorm 1.277 | loss_scale 16 | train_wall 328 | gb_free 9 | wall 38371
2022-03-06 01:04:15 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 01:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:21 | INFO | train_inner | epoch 107:     43 / 49 loss=1.34, ppl=2.53, wps=8887.3, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.275, loss_scale=16, train_wall=669, gb_free=9, wall=38677
2022-03-06 01:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:10:10 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 13.863 | ppl 14901.9 | wps 20953.5 | wpb 510.9 | bsz 1 | num_updates 5206 | best_loss 8.372
2022-03-06 01:10:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5206 updates
2022-03-06 01:10:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:10:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:10:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 107 @ 5206 updates, score 13.863) (writing took 2.8094729899894446 seconds)
2022-03-06 01:10:13 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 01:10:13 | INFO | train | epoch 107 | loss 1.317 | ppl 2.49 | wps 8880.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5206 | lr 0.000438276 | gnorm 1.278 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 38729
2022-03-06 01:10:13 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 01:10:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:15:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:16:08 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 13.95 | ppl 15829.5 | wps 20957.4 | wpb 510.9 | bsz 1 | num_updates 5255 | best_loss 8.372
2022-03-06 01:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5255 updates
2022-03-06 01:16:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:16:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:16:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 108 @ 5255 updates, score 13.95) (writing took 2.879063891014084 seconds)
2022-03-06 01:16:11 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 01:16:11 | INFO | train | epoch 108 | loss 1.281 | ppl 2.43 | wps 8877.5 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5255 | lr 0.000436228 | gnorm 1.239 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 39087
2022-03-06 01:16:11 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 01:16:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:21:31 | INFO | train_inner | epoch 109:     45 / 49 loss=1.27, ppl=2.41, wps=8885.3, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.25, loss_scale=32, train_wall=669, gb_free=9, wall=39407
2022-03-06 01:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:22:06 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 14.014 | ppl 16548.3 | wps 20937.6 | wpb 510.9 | bsz 1 | num_updates 5304 | best_loss 8.372
2022-03-06 01:22:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5304 updates
2022-03-06 01:22:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:22:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 109 @ 5304 updates, score 14.014) (writing took 2.8382297239731997 seconds)
2022-03-06 01:22:09 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 01:22:09 | INFO | train | epoch 109 | loss 1.256 | ppl 2.39 | wps 8877.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5304 | lr 0.000434208 | gnorm 1.259 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 39445
2022-03-06 01:22:09 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 01:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:25:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:27:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:28:04 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 14.126 | ppl 17881.6 | wps 20934.9 | wpb 510.9 | bsz 1 | num_updates 5352 | best_loss 8.372
2022-03-06 01:28:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5352 updates
2022-03-06 01:28:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:28:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:28:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 110 @ 5352 updates, score 14.126) (writing took 2.828749829903245 seconds)
2022-03-06 01:28:07 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 01:28:07 | INFO | train | epoch 110 | loss 1.221 | ppl 2.33 | wps 8695.2 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 5352 | lr 0.000432257 | gnorm 1.253 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 39803
2022-03-06 01:28:07 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 01:28:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:33:49 | INFO | train_inner | epoch 111:     48 / 49 loss=1.214, ppl=2.32, wps=8797.5, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.252, loss_scale=32, train_wall=676, gb_free=9, wall=40144
2022-03-06 01:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:34:03 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 14.123 | ppl 17837.2 | wps 20917.3 | wpb 510.9 | bsz 1 | num_updates 5401 | best_loss 8.372
2022-03-06 01:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5401 updates
2022-03-06 01:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 111 @ 5401 updates, score 14.123) (writing took 2.8638815849553794 seconds)
2022-03-06 01:34:05 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 01:34:05 | INFO | train | epoch 111 | loss 1.199 | ppl 2.3 | wps 8873.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5401 | lr 0.000430292 | gnorm 1.25 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 40161
2022-03-06 01:34:05 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 01:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:40:00 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 14.249 | ppl 19467.2 | wps 20914.1 | wpb 510.9 | bsz 1 | num_updates 5450 | best_loss 8.372
2022-03-06 01:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5450 updates
2022-03-06 01:40:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:40:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 112 @ 5450 updates, score 14.249) (writing took 2.8297470069956034 seconds)
2022-03-06 01:40:03 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 01:40:03 | INFO | train | epoch 112 | loss 1.169 | ppl 2.25 | wps 8880.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5450 | lr 0.000428353 | gnorm 1.223 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 40519
2022-03-06 01:40:03 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 01:40:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:43:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:45:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:45:58 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 14.349 | ppl 20874.3 | wps 20916.1 | wpb 510.9 | bsz 1 | num_updates 5498 | best_loss 8.372
2022-03-06 01:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5498 updates
2022-03-06 01:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:46:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:46:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 113 @ 5498 updates, score 14.349) (writing took 2.8633246689569205 seconds)
2022-03-06 01:46:01 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 01:46:01 | INFO | train | epoch 113 | loss 1.143 | ppl 2.21 | wps 8695 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 5498 | lr 0.000426479 | gnorm 1.222 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 40877
2022-03-06 01:46:01 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 01:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:46:16 | INFO | train_inner | epoch 114:      2 / 49 loss=1.155, ppl=2.23, wps=8639.6, ups=0.13, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.225, loss_scale=32, train_wall=673, gb_free=9, wall=40891
2022-03-06 01:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:51:56 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 14.4 | ppl 21625.7 | wps 20944.6 | wpb 510.9 | bsz 1 | num_updates 5547 | best_loss 8.372
2022-03-06 01:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5547 updates
2022-03-06 01:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:51:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:51:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 114 @ 5547 updates, score 14.4) (writing took 2.8916001371107996 seconds)
2022-03-06 01:51:59 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 01:51:59 | INFO | train | epoch 114 | loss 1.119 | ppl 2.17 | wps 8878.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5547 | lr 0.000424591 | gnorm 1.194 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 41235
2022-03-06 01:51:59 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 01:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:57:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:57:54 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 14.546 | ppl 23917.2 | wps 20946.9 | wpb 510.9 | bsz 1 | num_updates 5596 | best_loss 8.372
2022-03-06 01:57:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5596 updates
2022-03-06 01:57:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:57:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 01:57:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 115 @ 5596 updates, score 14.546) (writing took 2.8188394240569323 seconds)
2022-03-06 01:57:57 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 01:57:57 | INFO | train | epoch 115 | loss 1.091 | ppl 2.13 | wps 8881.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5596 | lr 0.000422728 | gnorm 1.17 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 41593
2022-03-06 01:57:57 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 01:57:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:58:26 | INFO | train_inner | epoch 116:      4 / 49 loss=1.101, ppl=2.15, wps=8886.8, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.182, loss_scale=32, train_wall=669, gb_free=9, wall=41621
2022-03-06 02:00:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:03:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:03:52 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 14.546 | ppl 23928.2 | wps 20959.3 | wpb 510.9 | bsz 1 | num_updates 5644 | best_loss 8.372
2022-03-06 02:03:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5644 updates
2022-03-06 02:03:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:03:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:03:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 116 @ 5644 updates, score 14.546) (writing took 2.9011137220077217 seconds)
2022-03-06 02:03:55 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 02:03:55 | INFO | train | epoch 116 | loss 1.072 | ppl 2.1 | wps 8697.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 5644 | lr 0.000420927 | gnorm 1.197 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 41951
2022-03-06 02:03:55 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 02:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:09:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:09:50 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 14.706 | ppl 26724.3 | wps 20901.2 | wpb 510.9 | bsz 1 | num_updates 5693 | best_loss 8.372
2022-03-06 02:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5693 updates
2022-03-06 02:09:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:09:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:09:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 117 @ 5693 updates, score 14.706) (writing took 2.8495569061487913 seconds)
2022-03-06 02:09:53 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 02:09:53 | INFO | train | epoch 117 | loss 1.046 | ppl 2.07 | wps 8882 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5693 | lr 0.000419111 | gnorm 1.162 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 42308
2022-03-06 02:09:53 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 02:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:10:43 | INFO | train_inner | epoch 118:      7 / 49 loss=1.056, ppl=2.08, wps=8802.4, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.176, loss_scale=32, train_wall=676, gb_free=9, wall=42358
2022-03-06 02:15:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:15:48 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 14.746 | ppl 27483.9 | wps 20949 | wpb 510.9 | bsz 1 | num_updates 5742 | best_loss 8.372
2022-03-06 02:15:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5742 updates
2022-03-06 02:15:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:15:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:15:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 118 @ 5742 updates, score 14.746) (writing took 2.853786979801953 seconds)
2022-03-06 02:15:51 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 02:15:51 | INFO | train | epoch 118 | loss 1.027 | ppl 2.04 | wps 8881.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5742 | lr 0.000417319 | gnorm 1.161 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 42666
2022-03-06 02:15:51 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 02:15:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:17:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:21:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:21:46 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 14.896 | ppl 30485.1 | wps 20971.6 | wpb 510.9 | bsz 1 | num_updates 5790 | best_loss 8.372
2022-03-06 02:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5790 updates
2022-03-06 02:21:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:21:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 119 @ 5790 updates, score 14.896) (writing took 2.8729694271460176 seconds)
2022-03-06 02:21:48 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 02:21:48 | INFO | train | epoch 119 | loss 1.004 | ppl 2.01 | wps 8696.5 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 5790 | lr 0.000415586 | gnorm 1.166 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 43024
2022-03-06 02:21:48 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 02:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:22:59 | INFO | train_inner | epoch 120:     10 / 49 loss=1.011, ppl=2.01, wps=8802.7, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.162, loss_scale=32, train_wall=676, gb_free=9, wall=43095
2022-03-06 02:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:27:43 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 14.945 | ppl 31545.6 | wps 20900 | wpb 510.9 | bsz 1 | num_updates 5839 | best_loss 8.372
2022-03-06 02:27:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5839 updates
2022-03-06 02:27:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:27:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:27:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 120 @ 5839 updates, score 14.945) (writing took 2.871702475938946 seconds)
2022-03-06 02:27:46 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 02:27:46 | INFO | train | epoch 120 | loss 0.981 | ppl 1.97 | wps 8881.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5839 | lr 0.000413838 | gnorm 1.134 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 43382
2022-03-06 02:27:46 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 02:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:33:41 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 14.97 | ppl 32093.7 | wps 20938.5 | wpb 510.9 | bsz 1 | num_updates 5888 | best_loss 8.372
2022-03-06 02:33:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5888 updates
2022-03-06 02:33:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:33:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:33:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 121 @ 5888 updates, score 14.97) (writing took 2.853602248011157 seconds)
2022-03-06 02:33:44 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 02:33:44 | INFO | train | epoch 121 | loss 0.967 | ppl 1.95 | wps 8880.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5888 | lr 0.000412113 | gnorm 1.152 | loss_scale 64 | train_wall 328 | gb_free 9 | wall 43740
2022-03-06 02:33:44 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 02:33:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:35:09 | INFO | train_inner | epoch 122:     12 / 49 loss=0.969, ppl=1.96, wps=8886.7, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.14, loss_scale=64, train_wall=669, gb_free=9, wall=43825
2022-03-06 02:35:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:39:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:39:39 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 15.165 | ppl 36735.7 | wps 20924.9 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 8.372
2022-03-06 02:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-06 02:39:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 122 @ 5936 updates, score 15.165) (writing took 2.877876781858504 seconds)
2022-03-06 02:39:42 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 02:39:42 | INFO | train | epoch 122 | loss 0.947 | ppl 1.93 | wps 8694.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 1.158 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 44098
2022-03-06 02:39:42 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 02:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:45:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:45:37 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 15.092 | ppl 34915.3 | wps 20930 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 8.372
2022-03-06 02:45:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-06 02:45:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:45:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:45:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 123 @ 5985 updates, score 15.092) (writing took 2.8235368879977614 seconds)
2022-03-06 02:45:40 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 02:45:40 | INFO | train | epoch 123 | loss 0.924 | ppl 1.9 | wps 8879.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 1.108 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 44456
2022-03-06 02:45:40 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 02:45:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:47:27 | INFO | train_inner | epoch 124:     15 / 49 loss=0.93, ppl=1.9, wps=8800.2, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.134, loss_scale=32, train_wall=676, gb_free=9, wall=44562
2022-03-06 02:51:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:51:35 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 15.294 | ppl 40167.3 | wps 20906.4 | wpb 510.9 | bsz 1 | num_updates 6033 | best_loss 8.372
2022-03-06 02:51:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6033 updates
2022-03-06 02:51:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:51:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:51:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 124 @ 6033 updates, score 15.294) (writing took 2.879018692066893 seconds)
2022-03-06 02:51:38 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 02:51:38 | INFO | train | epoch 124 | loss 0.911 | ppl 1.88 | wps 8693.8 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 6033 | lr 0.00040713 | gnorm 1.134 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 44814
2022-03-06 02:51:38 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 02:51:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:57:33 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 15.25 | ppl 38976.5 | wps 20968.7 | wpb 510.9 | bsz 1 | num_updates 6082 | best_loss 8.372
2022-03-06 02:57:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6082 updates
2022-03-06 02:57:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:57:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 02:57:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 125 @ 6082 updates, score 15.25) (writing took 2.8216667489614338 seconds)
2022-03-06 02:57:36 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 02:57:36 | INFO | train | epoch 125 | loss 0.894 | ppl 1.86 | wps 8883.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6082 | lr 0.000405487 | gnorm 1.104 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 45172
2022-03-06 02:57:36 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 02:57:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:59:44 | INFO | train_inner | epoch 126:     18 / 49 loss=0.897, ppl=1.86, wps=8801, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.112, loss_scale=32, train_wall=676, gb_free=9, wall=45299
2022-03-06 03:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:03:31 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 15.372 | ppl 42413.4 | wps 20928 | wpb 510.9 | bsz 1 | num_updates 6131 | best_loss 8.372
2022-03-06 03:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6131 updates
2022-03-06 03:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:03:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 126 @ 6131 updates, score 15.372) (writing took 2.8334059230983257 seconds)
2022-03-06 03:03:34 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 03:03:34 | INFO | train | epoch 126 | loss 0.876 | ppl 1.84 | wps 8884 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6131 | lr 0.000403863 | gnorm 1.098 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 45529
2022-03-06 03:03:34 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 03:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:09:28 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 15.463 | ppl 45178.5 | wps 20908.5 | wpb 510.9 | bsz 1 | num_updates 6179 | best_loss 8.372
2022-03-06 03:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6179 updates
2022-03-06 03:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 127 @ 6179 updates, score 15.463) (writing took 2.906595648964867 seconds)
2022-03-06 03:09:31 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 03:09:31 | INFO | train | epoch 127 | loss 0.861 | ppl 1.82 | wps 8699.6 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 6179 | lr 0.000402292 | gnorm 1.098 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 45887
2022-03-06 03:09:31 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 03:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:12:01 | INFO | train_inner | epoch 128:     21 / 49 loss=0.862, ppl=1.82, wps=8804.5, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=1.095, loss_scale=32, train_wall=676, gb_free=9, wall=46036
2022-03-06 03:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:15:26 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 15.524 | ppl 47107.6 | wps 20971.8 | wpb 510.9 | bsz 1 | num_updates 6228 | best_loss 8.372
2022-03-06 03:15:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6228 updates
2022-03-06 03:15:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:15:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 128 @ 6228 updates, score 15.524) (writing took 2.792874202132225 seconds)
2022-03-06 03:15:29 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 03:15:29 | INFO | train | epoch 128 | loss 0.845 | ppl 1.8 | wps 8885.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6228 | lr 0.000400706 | gnorm 1.087 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 46245
2022-03-06 03:15:29 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 03:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:21:24 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 15.459 | ppl 45043.4 | wps 20939.6 | wpb 510.9 | bsz 1 | num_updates 6277 | best_loss 8.372
2022-03-06 03:21:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6277 updates
2022-03-06 03:21:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:21:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:21:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 129 @ 6277 updates, score 15.459) (writing took 2.799548925133422 seconds)
2022-03-06 03:21:27 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 03:21:27 | INFO | train | epoch 129 | loss 0.829 | ppl 1.78 | wps 8881.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6277 | lr 0.000399139 | gnorm 1.062 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 46603
2022-03-06 03:21:27 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 03:21:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:24:10 | INFO | train_inner | epoch 130:     23 / 49 loss=0.83, ppl=1.78, wps=8891.9, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=1.071, loss_scale=64, train_wall=669, gb_free=9, wall=46766
2022-03-06 03:24:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:27:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:27:22 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 15.569 | ppl 48603.8 | wps 20947.7 | wpb 510.9 | bsz 1 | num_updates 6325 | best_loss 8.372
2022-03-06 03:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6325 updates
2022-03-06 03:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:27:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 130 @ 6325 updates, score 15.569) (writing took 2.8066785300616175 seconds)
2022-03-06 03:27:24 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 03:27:24 | INFO | train | epoch 130 | loss 0.814 | ppl 1.76 | wps 8702.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 6325 | lr 0.000397621 | gnorm 1.074 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 46960
2022-03-06 03:27:24 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 03:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:33:19 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 15.743 | ppl 54847.4 | wps 20907.9 | wpb 510.9 | bsz 1 | num_updates 6374 | best_loss 8.372
2022-03-06 03:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6374 updates
2022-03-06 03:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 131 @ 6374 updates, score 15.743) (writing took 2.9158520048949867 seconds)
2022-03-06 03:33:22 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 03:33:22 | INFO | train | epoch 131 | loss 0.802 | ppl 1.74 | wps 8882.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6374 | lr 0.00039609 | gnorm 1.058 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 47318
2022-03-06 03:33:22 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 03:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:36:27 | INFO | train_inner | epoch 132:     26 / 49 loss=0.802, ppl=1.74, wps=8805.2, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=1.069, loss_scale=32, train_wall=675, gb_free=9, wall=47503
2022-03-06 03:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:39:17 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 15.791 | ppl 56686 | wps 20954.7 | wpb 510.9 | bsz 1 | num_updates 6423 | best_loss 8.372
2022-03-06 03:39:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6423 updates
2022-03-06 03:39:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:39:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:39:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 132 @ 6423 updates, score 15.791) (writing took 2.840424210065976 seconds)
2022-03-06 03:39:20 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 03:39:20 | INFO | train | epoch 132 | loss 0.792 | ppl 1.73 | wps 8884.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6423 | lr 0.000394576 | gnorm 1.069 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 47676
2022-03-06 03:39:20 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 03:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:40:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:45:15 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 15.852 | ppl 59131.3 | wps 20904.7 | wpb 510.9 | bsz 1 | num_updates 6471 | best_loss 8.372
2022-03-06 03:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6471 updates
2022-03-06 03:45:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 133 @ 6471 updates, score 15.852) (writing took 2.864679381949827 seconds)
2022-03-06 03:45:18 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 03:45:18 | INFO | train | epoch 133 | loss 0.773 | ppl 1.71 | wps 8703.2 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 6471 | lr 0.00039311 | gnorm 1.054 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 48033
2022-03-06 03:45:18 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 03:45:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:48:43 | INFO | train_inner | epoch 134:     29 / 49 loss=0.776, ppl=1.71, wps=8806.5, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=1.054, loss_scale=32, train_wall=675, gb_free=9, wall=48239
2022-03-06 03:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:51:12 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 15.852 | ppl 59143.5 | wps 20909.4 | wpb 510.9 | bsz 1 | num_updates 6520 | best_loss 8.372
2022-03-06 03:51:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6520 updates
2022-03-06 03:51:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:51:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 134 @ 6520 updates, score 15.852) (writing took 2.80149377300404 seconds)
2022-03-06 03:51:15 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 03:51:15 | INFO | train | epoch 134 | loss 0.762 | ppl 1.7 | wps 8884.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6520 | lr 0.00039163 | gnorm 1.03 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 48391
2022-03-06 03:51:15 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 03:51:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:57:10 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 15.916 | ppl 61822.9 | wps 20910.5 | wpb 510.9 | bsz 1 | num_updates 6569 | best_loss 8.372
2022-03-06 03:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6569 updates
2022-03-06 03:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 03:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 135 @ 6569 updates, score 15.916) (writing took 2.7957905870862305 seconds)
2022-03-06 03:57:13 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 03:57:13 | INFO | train | epoch 135 | loss 0.752 | ppl 1.68 | wps 8885.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6569 | lr 0.000390167 | gnorm 1.039 | loss_scale 64 | train_wall 328 | gb_free 9 | wall 48749
2022-03-06 03:57:13 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 03:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:01:00 | INFO | train_inner | epoch 136:     32 / 49 loss=0.749, ppl=1.68, wps=8806.1, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=1.028, loss_scale=32, train_wall=675, gb_free=9, wall=48976
2022-03-06 04:02:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:03:08 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 16.065 | ppl 68576 | wps 20901.1 | wpb 510.9 | bsz 1 | num_updates 6617 | best_loss 8.372
2022-03-06 04:03:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6617 updates
2022-03-06 04:03:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:03:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:03:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 136 @ 6617 updates, score 16.065) (writing took 2.825088812969625 seconds)
2022-03-06 04:03:11 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 04:03:11 | INFO | train | epoch 136 | loss 0.738 | ppl 1.67 | wps 8701.9 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 6617 | lr 0.000388749 | gnorm 1.037 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 49106
2022-03-06 04:03:11 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 04:03:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:08:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:09:05 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 16.069 | ppl 68754.7 | wps 20974.6 | wpb 510.9 | bsz 1 | num_updates 6666 | best_loss 8.372
2022-03-06 04:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6666 updates
2022-03-06 04:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:09:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:09:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 137 @ 6666 updates, score 16.069) (writing took 2.8916931229177862 seconds)
2022-03-06 04:09:08 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 04:09:08 | INFO | train | epoch 137 | loss 0.727 | ppl 1.66 | wps 8883.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6666 | lr 0.000387318 | gnorm 1.018 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 49464
2022-03-06 04:09:08 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 04:09:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:13:10 | INFO | train_inner | epoch 138:     34 / 49 loss=0.726, ppl=1.65, wps=8891.9, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=1.02, loss_scale=64, train_wall=669, gb_free=9, wall=49705
2022-03-06 04:13:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:15:03 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 16.148 | ppl 72601.3 | wps 20910.4 | wpb 510.9 | bsz 1 | num_updates 6714 | best_loss 8.372
2022-03-06 04:15:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6714 updates
2022-03-06 04:15:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:15:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:15:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 138 @ 6714 updates, score 16.148) (writing took 2.8535333110485226 seconds)
2022-03-06 04:15:06 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 04:15:06 | INFO | train | epoch 138 | loss 0.716 | ppl 1.64 | wps 8704.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 6714 | lr 0.000385931 | gnorm 1.018 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 49822
2022-03-06 04:15:06 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 04:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:20:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:21:01 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 16.191 | ppl 74837.3 | wps 20943.1 | wpb 510.9 | bsz 1 | num_updates 6763 | best_loss 8.372
2022-03-06 04:21:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6763 updates
2022-03-06 04:21:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:21:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:21:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 139 @ 6763 updates, score 16.191) (writing took 2.839689309010282 seconds)
2022-03-06 04:21:03 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 04:21:03 | INFO | train | epoch 139 | loss 0.705 | ppl 1.63 | wps 8887.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6763 | lr 0.00038453 | gnorm 1.016 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 50179
2022-03-06 04:21:03 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 04:21:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:25:26 | INFO | train_inner | epoch 140:     37 / 49 loss=0.703, ppl=1.63, wps=8808.1, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=1.006, loss_scale=32, train_wall=675, gb_free=9, wall=50442
2022-03-06 04:26:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:26:58 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 16.294 | ppl 80325.4 | wps 20941 | wpb 510.9 | bsz 1 | num_updates 6812 | best_loss 8.372
2022-03-06 04:26:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6812 updates
2022-03-06 04:26:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 140 @ 6812 updates, score 16.294) (writing took 2.851696748053655 seconds)
2022-03-06 04:27:01 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 04:27:01 | INFO | train | epoch 140 | loss 0.693 | ppl 1.62 | wps 8885.1 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6812 | lr 0.000383145 | gnorm 0.979 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 50537
2022-03-06 04:27:01 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 04:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:30:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:32:56 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 16.224 | ppl 76566.9 | wps 20931.6 | wpb 510.9 | bsz 1 | num_updates 6860 | best_loss 8.372
2022-03-06 04:32:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6860 updates
2022-03-06 04:32:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:32:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:32:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 141 @ 6860 updates, score 16.224) (writing took 2.8087785649113357 seconds)
2022-03-06 04:32:59 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-06 04:32:59 | INFO | train | epoch 141 | loss 0.683 | ppl 1.61 | wps 8704.1 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 6860 | lr 0.000381802 | gnorm 0.994 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 50895
2022-03-06 04:32:59 | INFO | fairseq.trainer | begin training epoch 142
2022-03-06 04:32:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:37:43 | INFO | train_inner | epoch 142:     40 / 49 loss=0.681, ppl=1.6, wps=8806.6, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.985, loss_scale=32, train_wall=675, gb_free=9, wall=51179
2022-03-06 04:38:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:38:54 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 16.223 | ppl 76515.8 | wps 20884.8 | wpb 510.9 | bsz 1 | num_updates 6909 | best_loss 8.372
2022-03-06 04:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6909 updates
2022-03-06 04:38:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:38:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 142 @ 6909 updates, score 16.223) (writing took 2.899770147865638 seconds)
2022-03-06 04:38:57 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-06 04:38:57 | INFO | train | epoch 142 | loss 0.673 | ppl 1.59 | wps 8881.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6909 | lr 0.000380445 | gnorm 0.986 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 51252
2022-03-06 04:38:57 | INFO | fairseq.trainer | begin training epoch 143
2022-03-06 04:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:44:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:44:51 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 16.483 | ppl 91578.1 | wps 20922.3 | wpb 510.9 | bsz 1 | num_updates 6958 | best_loss 8.372
2022-03-06 04:44:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6958 updates
2022-03-06 04:44:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:44:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:44:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 143 @ 6958 updates, score 16.483) (writing took 2.796366774942726 seconds)
2022-03-06 04:44:54 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-06 04:44:54 | INFO | train | epoch 143 | loss 0.665 | ppl 1.59 | wps 8889.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 6958 | lr 0.000379103 | gnorm 0.974 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 51610
2022-03-06 04:44:54 | INFO | fairseq.trainer | begin training epoch 144
2022-03-06 04:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:46:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:49:59 | INFO | train_inner | epoch 144:     43 / 49 loss=0.663, ppl=1.58, wps=8807.2, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.978, loss_scale=32, train_wall=675, gb_free=9, wall=51915
2022-03-06 04:50:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:50:49 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 16.417 | ppl 87480.9 | wps 20963.4 | wpb 510.9 | bsz 1 | num_updates 7006 | best_loss 8.372
2022-03-06 04:50:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7006 updates
2022-03-06 04:50:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 144 @ 7006 updates, score 16.417) (writing took 2.8396750760730356 seconds)
2022-03-06 04:50:52 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-06 04:50:52 | INFO | train | epoch 144 | loss 0.656 | ppl 1.58 | wps 8701.8 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 7006 | lr 0.000377803 | gnorm 0.97 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 51968
2022-03-06 04:50:52 | INFO | fairseq.trainer | begin training epoch 145
2022-03-06 04:50:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:56:47 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 16.669 | ppl 104217 | wps 20896.7 | wpb 510.9 | bsz 1 | num_updates 7055 | best_loss 8.372
2022-03-06 04:56:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7055 updates
2022-03-06 04:56:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:56:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 04:56:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 145 @ 7055 updates, score 16.669) (writing took 2.8513226110953838 seconds)
2022-03-06 04:56:49 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-06 04:56:49 | INFO | train | epoch 145 | loss 0.646 | ppl 1.56 | wps 8886.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7055 | lr 0.000376488 | gnorm 0.966 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 52325
2022-03-06 04:56:49 | INFO | fairseq.trainer | begin training epoch 146
2022-03-06 04:56:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:02:09 | INFO | train_inner | epoch 146:     45 / 49 loss=0.643, ppl=1.56, wps=8894.9, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.967, loss_scale=64, train_wall=668, gb_free=9, wall=52644
2022-03-06 05:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:02:44 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 16.545 | ppl 95624.1 | wps 20931.9 | wpb 510.9 | bsz 1 | num_updates 7104 | best_loss 8.372
2022-03-06 05:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7104 updates
2022-03-06 05:02:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:02:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 146 @ 7104 updates, score 16.545) (writing took 2.8574186880141497 seconds)
2022-03-06 05:02:47 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-06 05:02:47 | INFO | train | epoch 146 | loss 0.638 | ppl 1.56 | wps 8889.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7104 | lr 0.000375188 | gnorm 0.97 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 52683
2022-03-06 05:02:47 | INFO | fairseq.trainer | begin training epoch 147
2022-03-06 05:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:03:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:08:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:08:42 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 16.604 | ppl 99585.3 | wps 20882.9 | wpb 510.9 | bsz 1 | num_updates 7152 | best_loss 8.372
2022-03-06 05:08:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7152 updates
2022-03-06 05:08:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:08:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:08:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 147 @ 7152 updates, score 16.604) (writing took 2.8522233918774873 seconds)
2022-03-06 05:08:44 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-06 05:08:44 | INFO | train | epoch 147 | loss 0.626 | ppl 1.54 | wps 8704.3 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 7152 | lr 0.000373927 | gnorm 0.942 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 53040
2022-03-06 05:08:45 | INFO | fairseq.trainer | begin training epoch 148
2022-03-06 05:08:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:14:25 | INFO | train_inner | epoch 148:     48 / 49 loss=0.625, ppl=1.54, wps=8808.6, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.947, loss_scale=32, train_wall=675, gb_free=9, wall=53381
2022-03-06 05:14:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:14:39 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 16.605 | ppl 99668.8 | wps 20943 | wpb 510.9 | bsz 1 | num_updates 7201 | best_loss 8.372
2022-03-06 05:14:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7201 updates
2022-03-06 05:14:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:14:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 148 @ 7201 updates, score 16.605) (writing took 2.9043763279914856 seconds)
2022-03-06 05:14:42 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-06 05:14:42 | INFO | train | epoch 148 | loss 0.622 | ppl 1.54 | wps 8886.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7201 | lr 0.000372652 | gnorm 0.948 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 53398
2022-03-06 05:14:42 | INFO | fairseq.trainer | begin training epoch 149
2022-03-06 05:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:20:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:20:37 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 16.689 | ppl 105689 | wps 20850.8 | wpb 510.9 | bsz 1 | num_updates 7250 | best_loss 8.372
2022-03-06 05:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7250 updates
2022-03-06 05:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:20:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:20:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 149 @ 7250 updates, score 16.689) (writing took 2.8928390918299556 seconds)
2022-03-06 05:20:40 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-06 05:20:40 | INFO | train | epoch 149 | loss 0.612 | ppl 1.53 | wps 8882.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7250 | lr 0.000371391 | gnorm 0.943 | loss_scale 64 | train_wall 328 | gb_free 9 | wall 53756
2022-03-06 05:20:40 | INFO | fairseq.trainer | begin training epoch 150
2022-03-06 05:20:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:22:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:26:35 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 16.731 | ppl 108781 | wps 20750.2 | wpb 510.9 | bsz 1 | num_updates 7298 | best_loss 8.372
2022-03-06 05:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7298 updates
2022-03-06 05:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:26:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:26:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 150 @ 7298 updates, score 16.731) (writing took 2.9690046631731093 seconds)
2022-03-06 05:26:38 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-06 05:26:38 | INFO | train | epoch 150 | loss 0.602 | ppl 1.52 | wps 8698.6 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 7298 | lr 0.000370167 | gnorm 0.925 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 54113
2022-03-06 05:26:38 | INFO | fairseq.trainer | begin training epoch 151
2022-03-06 05:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:26:52 | INFO | train_inner | epoch 151:      2 / 49 loss=0.607, ppl=1.52, wps=8642.1, ups=0.13, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.937, loss_scale=32, train_wall=672, gb_free=9, wall=54128
2022-03-06 05:32:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:32:32 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 16.89 | ppl 121468 | wps 20665.3 | wpb 510.9 | bsz 1 | num_updates 7347 | best_loss 8.372
2022-03-06 05:32:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7347 updates
2022-03-06 05:32:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:32:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:32:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 151 @ 7347 updates, score 16.89) (writing took 2.8099828520789742 seconds)
2022-03-06 05:32:35 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-06 05:32:35 | INFO | train | epoch 151 | loss 0.598 | ppl 1.51 | wps 8888.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7347 | lr 0.000368931 | gnorm 0.941 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 54471
2022-03-06 05:32:35 | INFO | fairseq.trainer | begin training epoch 152
2022-03-06 05:32:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:38:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:38:30 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 16.956 | ppl 127108 | wps 20698.6 | wpb 510.9 | bsz 1 | num_updates 7396 | best_loss 8.372
2022-03-06 05:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7396 updates
2022-03-06 05:38:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:38:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:38:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 152 @ 7396 updates, score 16.956) (writing took 2.8327757029328495 seconds)
2022-03-06 05:38:33 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-06 05:38:33 | INFO | train | epoch 152 | loss 0.591 | ppl 1.51 | wps 8889.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7396 | lr 0.000367707 | gnorm 0.923 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 54829
2022-03-06 05:38:33 | INFO | fairseq.trainer | begin training epoch 153
2022-03-06 05:38:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:39:01 | INFO | train_inner | epoch 153:      4 / 49 loss=0.593, ppl=1.51, wps=8896, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.931, loss_scale=64, train_wall=668, gb_free=9, wall=54857
2022-03-06 05:39:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:44:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:44:27 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 16.94 | ppl 125757 | wps 20926.8 | wpb 510.9 | bsz 1 | num_updates 7444 | best_loss 8.372
2022-03-06 05:44:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7444 updates
2022-03-06 05:44:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 153 @ 7444 updates, score 16.94) (writing took 2.8507918471004814 seconds)
2022-03-06 05:44:30 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-06 05:44:30 | INFO | train | epoch 153 | loss 0.58 | ppl 1.49 | wps 8707 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 7444 | lr 0.000366519 | gnorm 0.913 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 55186
2022-03-06 05:44:30 | INFO | fairseq.trainer | begin training epoch 154
2022-03-06 05:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:50:25 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 16.934 | ppl 125212 | wps 20931.5 | wpb 510.9 | bsz 1 | num_updates 7493 | best_loss 8.372
2022-03-06 05:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7493 updates
2022-03-06 05:50:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 154 @ 7493 updates, score 16.934) (writing took 2.8700771080330014 seconds)
2022-03-06 05:50:28 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-06 05:50:28 | INFO | train | epoch 154 | loss 0.577 | ppl 1.49 | wps 8889.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7493 | lr 0.000365319 | gnorm 0.936 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 55544
2022-03-06 05:50:28 | INFO | fairseq.trainer | begin training epoch 155
2022-03-06 05:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:51:18 | INFO | train_inner | epoch 155:      7 / 49 loss=0.577, ppl=1.49, wps=8811.3, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.924, loss_scale=32, train_wall=675, gb_free=9, wall=55593
2022-03-06 05:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:56:23 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 16.985 | ppl 129736 | wps 20948.5 | wpb 510.9 | bsz 1 | num_updates 7542 | best_loss 8.372
2022-03-06 05:56:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7542 updates
2022-03-06 05:56:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 05:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 155 @ 7542 updates, score 16.985) (writing took 2.845859316876158 seconds)
2022-03-06 05:56:25 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-06 05:56:25 | INFO | train | epoch 155 | loss 0.567 | ppl 1.48 | wps 8887.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7542 | lr 0.00036413 | gnorm 0.908 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 55901
2022-03-06 05:56:25 | INFO | fairseq.trainer | begin training epoch 156
2022-03-06 05:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:59:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:02:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:02:20 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 16.954 | ppl 126995 | wps 20937.9 | wpb 510.9 | bsz 1 | num_updates 7590 | best_loss 8.372
2022-03-06 06:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7590 updates
2022-03-06 06:02:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:02:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 156 @ 7590 updates, score 16.954) (writing took 2.8364128400571644 seconds)
2022-03-06 06:02:23 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-06 06:02:23 | INFO | train | epoch 156 | loss 0.56 | ppl 1.47 | wps 8705.6 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 7590 | lr 0.000362977 | gnorm 0.91 | loss_scale 32 | train_wall 328 | gb_free 9 | wall 56259
2022-03-06 06:02:23 | INFO | fairseq.trainer | begin training epoch 157
2022-03-06 06:02:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:03:34 | INFO | train_inner | epoch 157:     10 / 49 loss=0.562, ppl=1.48, wps=8808.2, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.905, loss_scale=32, train_wall=675, gb_free=9, wall=56330
2022-03-06 06:08:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:08:18 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 17.06 | ppl 136640 | wps 20962.4 | wpb 510.9 | bsz 1 | num_updates 7639 | best_loss 8.372
2022-03-06 06:08:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7639 updates
2022-03-06 06:08:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:08:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:08:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 157 @ 7639 updates, score 17.06) (writing took 2.877348800888285 seconds)
2022-03-06 06:08:20 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-06 06:08:20 | INFO | train | epoch 157 | loss 0.553 | ppl 1.47 | wps 8889 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7639 | lr 0.000361811 | gnorm 0.891 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 56616
2022-03-06 06:08:20 | INFO | fairseq.trainer | begin training epoch 158
2022-03-06 06:08:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:14:15 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 17.103 | ppl 140810 | wps 20924.1 | wpb 510.9 | bsz 1 | num_updates 7688 | best_loss 8.372
2022-03-06 06:14:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7688 updates
2022-03-06 06:14:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 158 @ 7688 updates, score 17.103) (writing took 2.8136958428658545 seconds)
2022-03-06 06:14:18 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-06 06:14:18 | INFO | train | epoch 158 | loss 0.547 | ppl 1.46 | wps 8891.4 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7688 | lr 0.000360656 | gnorm 0.895 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 56974
2022-03-06 06:14:18 | INFO | fairseq.trainer | begin training epoch 159
2022-03-06 06:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:15:43 | INFO | train_inner | epoch 159:     12 / 49 loss=0.549, ppl=1.46, wps=8897.4, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.895, loss_scale=64, train_wall=668, gb_free=9, wall=57059
2022-03-06 06:17:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:20:13 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 17.062 | ppl 136839 | wps 20858.2 | wpb 510.9 | bsz 1 | num_updates 7736 | best_loss 8.372
2022-03-06 06:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7736 updates
2022-03-06 06:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 159 @ 7736 updates, score 17.062) (writing took 2.824552671983838 seconds)
2022-03-06 06:20:15 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-06 06:20:15 | INFO | train | epoch 159 | loss 0.541 | ppl 1.45 | wps 8704.3 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 7736 | lr 0.000359535 | gnorm 0.89 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 57331
2022-03-06 06:20:15 | INFO | fairseq.trainer | begin training epoch 160
2022-03-06 06:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:26:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:26:10 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 17.211 | ppl 151704 | wps 20883.5 | wpb 510.9 | bsz 1 | num_updates 7785 | best_loss 8.372
2022-03-06 06:26:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7785 updates
2022-03-06 06:26:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:26:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:26:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 160 @ 7785 updates, score 17.211) (writing took 2.8856485709547997 seconds)
2022-03-06 06:26:13 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-06 06:26:13 | INFO | train | epoch 160 | loss 0.534 | ppl 1.45 | wps 8889.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7785 | lr 0.000358402 | gnorm 0.878 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 57689
2022-03-06 06:26:13 | INFO | fairseq.trainer | begin training epoch 161
2022-03-06 06:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:27:59 | INFO | train_inner | epoch 161:     15 / 49 loss=0.536, ppl=1.45, wps=8810.4, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.882, loss_scale=32, train_wall=675, gb_free=9, wall=57795
2022-03-06 06:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:32:08 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 17.189 | ppl 149374 | wps 20901.8 | wpb 510.9 | bsz 1 | num_updates 7834 | best_loss 8.372
2022-03-06 06:32:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7834 updates
2022-03-06 06:32:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 161 @ 7834 updates, score 17.189) (writing took 2.865890213055536 seconds)
2022-03-06 06:32:10 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-06 06:32:10 | INFO | train | epoch 161 | loss 0.53 | ppl 1.44 | wps 8889.7 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7834 | lr 0.00035728 | gnorm 0.884 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 58046
2022-03-06 06:32:10 | INFO | fairseq.trainer | begin training epoch 162
2022-03-06 06:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:37:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:38:05 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 17.453 | ppl 179482 | wps 20967.8 | wpb 510.9 | bsz 1 | num_updates 7883 | best_loss 8.372
2022-03-06 06:38:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7883 updates
2022-03-06 06:38:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 162 @ 7883 updates, score 17.453) (writing took 2.8071062609087676 seconds)
2022-03-06 06:38:08 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-06 06:38:08 | INFO | train | epoch 162 | loss 0.525 | ppl 1.44 | wps 8891.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7883 | lr 0.000356167 | gnorm 0.876 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 58404
2022-03-06 06:38:08 | INFO | fairseq.trainer | begin training epoch 163
2022-03-06 06:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:40:09 | INFO | train_inner | epoch 163:     17 / 49 loss=0.526, ppl=1.44, wps=8896.1, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.879, loss_scale=64, train_wall=668, gb_free=9, wall=58524
2022-03-06 06:43:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:44:03 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 17.331 | ppl 164864 | wps 20913.4 | wpb 510.9 | bsz 1 | num_updates 7931 | best_loss 8.372
2022-03-06 06:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7931 updates
2022-03-06 06:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:44:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:44:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 163 @ 7931 updates, score 17.331) (writing took 2.92447573505342 seconds)
2022-03-06 06:44:06 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-06 06:44:06 | INFO | train | epoch 163 | loss 0.516 | ppl 1.43 | wps 8702.9 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 7931 | lr 0.000355088 | gnorm 0.873 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 58761
2022-03-06 06:44:06 | INFO | fairseq.trainer | begin training epoch 164
2022-03-06 06:44:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:49:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:50:00 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 17.443 | ppl 178164 | wps 20964 | wpb 510.9 | bsz 1 | num_updates 7980 | best_loss 8.372
2022-03-06 06:50:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7980 updates
2022-03-06 06:50:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 164 @ 7980 updates, score 17.443) (writing took 2.951981085818261 seconds)
2022-03-06 06:50:03 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-06 06:50:03 | INFO | train | epoch 164 | loss 0.512 | ppl 1.43 | wps 8889.8 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 7980 | lr 0.000353996 | gnorm 0.879 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 59119
2022-03-06 06:50:03 | INFO | fairseq.trainer | begin training epoch 165
2022-03-06 06:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:52:25 | INFO | train_inner | epoch 165:     20 / 49 loss=0.512, ppl=1.43, wps=8810.2, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.872, loss_scale=32, train_wall=675, gb_free=9, wall=59261
2022-03-06 06:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:55:58 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 17.666 | ppl 207896 | wps 20919.7 | wpb 510.9 | bsz 1 | num_updates 8029 | best_loss 8.372
2022-03-06 06:55:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8029 updates
2022-03-06 06:55:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 06:56:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 165 @ 8029 updates, score 17.666) (writing took 2.9398186351172626 seconds)
2022-03-06 06:56:00 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-06 06:56:00 | INFO | train | epoch 165 | loss 0.505 | ppl 1.42 | wps 8890.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8029 | lr 0.000352914 | gnorm 0.856 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 59476
2022-03-06 06:56:01 | INFO | fairseq.trainer | begin training epoch 166
2022-03-06 06:56:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:00:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:01:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:01:55 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 17.609 | ppl 199892 | wps 20917.4 | wpb 510.9 | bsz 1 | num_updates 8077 | best_loss 8.372
2022-03-06 07:01:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8077 updates
2022-03-06 07:01:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:01:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:01:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 166 @ 8077 updates, score 17.609) (writing took 2.856362188933417 seconds)
2022-03-06 07:01:58 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-06 07:01:58 | INFO | train | epoch 166 | loss 0.5 | ppl 1.41 | wps 8707.6 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 8077 | lr 0.000351864 | gnorm 0.864 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 59834
2022-03-06 07:01:58 | INFO | fairseq.trainer | begin training epoch 167
2022-03-06 07:01:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:04:41 | INFO | train_inner | epoch 167:     23 / 49 loss=0.5, ppl=1.41, wps=8811.6, ups=0.14, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.855, loss_scale=32, train_wall=675, gb_free=9, wall=59997
2022-03-06 07:07:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:07:53 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 17.467 | ppl 181212 | wps 20894.7 | wpb 510.9 | bsz 1 | num_updates 8126 | best_loss 8.372
2022-03-06 07:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8126 updates
2022-03-06 07:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 167 @ 8126 updates, score 17.467) (writing took 2.879957769997418 seconds)
2022-03-06 07:07:55 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-06 07:07:55 | INFO | train | epoch 167 | loss 0.494 | ppl 1.41 | wps 8889.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8126 | lr 0.000350802 | gnorm 0.844 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 60191
2022-03-06 07:07:55 | INFO | fairseq.trainer | begin training epoch 168
2022-03-06 07:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:13:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:13:50 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 17.559 | ppl 193059 | wps 20914.3 | wpb 510.9 | bsz 1 | num_updates 8175 | best_loss 8.372
2022-03-06 07:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8175 updates
2022-03-06 07:13:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:13:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 168 @ 8175 updates, score 17.559) (writing took 2.893166227033362 seconds)
2022-03-06 07:13:53 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-06 07:13:53 | INFO | train | epoch 168 | loss 0.49 | ppl 1.4 | wps 8890.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8175 | lr 0.000349749 | gnorm 0.847 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 60549
2022-03-06 07:13:53 | INFO | fairseq.trainer | begin training epoch 169
2022-03-06 07:13:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:16:50 | INFO | train_inner | epoch 169:     25 / 49 loss=0.489, ppl=1.4, wps=8896.9, ups=0.14, wpb=64867.4, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.847, loss_scale=64, train_wall=668, gb_free=9, wall=60726
2022-03-06 07:19:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:19:48 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 17.685 | ppl 210652 | wps 20934.6 | wpb 510.9 | bsz 1 | num_updates 8224 | best_loss 8.372
2022-03-06 07:19:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8224 updates
2022-03-06 07:19:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:19:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:19:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 169 @ 8224 updates, score 17.685) (writing took 2.9141850920859724 seconds)
2022-03-06 07:19:51 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-06 07:19:51 | INFO | train | epoch 169 | loss 0.486 | ppl 1.4 | wps 8887 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8224 | lr 0.000348705 | gnorm 0.856 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 60906
2022-03-06 07:19:51 | INFO | fairseq.trainer | begin training epoch 170
2022-03-06 07:19:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:24:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:25:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:25:45 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 17.732 | ppl 217773 | wps 20953.5 | wpb 510.9 | bsz 1 | num_updates 8272 | best_loss 8.372
2022-03-06 07:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8272 updates
2022-03-06 07:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:25:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:25:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 170 @ 8272 updates, score 17.732) (writing took 2.8128858858253807 seconds)
2022-03-06 07:25:48 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-06 07:25:48 | INFO | train | epoch 170 | loss 0.479 | ppl 1.39 | wps 8710.2 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 8272 | lr 0.000347692 | gnorm 0.83 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 61264
2022-03-06 07:25:48 | INFO | fairseq.trainer | begin training epoch 171
2022-03-06 07:25:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:29:07 | INFO | train_inner | epoch 171:     28 / 49 loss=0.48, ppl=1.4, wps=8811.7, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.84, loss_scale=32, train_wall=675, gb_free=9, wall=61462
2022-03-06 07:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:31:42 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 17.745 | ppl 219708 | wps 20935 | wpb 510.9 | bsz 1 | num_updates 8321 | best_loss 8.372
2022-03-06 07:31:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8321 updates
2022-03-06 07:31:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:31:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:31:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 171 @ 8321 updates, score 17.745) (writing took 2.839096751064062 seconds)
2022-03-06 07:31:45 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-06 07:31:45 | INFO | train | epoch 171 | loss 0.476 | ppl 1.39 | wps 8893.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8321 | lr 0.000346667 | gnorm 0.842 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 61621
2022-03-06 07:31:45 | INFO | fairseq.trainer | begin training epoch 172
2022-03-06 07:31:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:37:40 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 17.722 | ppl 216191 | wps 20842.4 | wpb 510.9 | bsz 1 | num_updates 8370 | best_loss 8.372
2022-03-06 07:37:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8370 updates
2022-03-06 07:37:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:37:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:37:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 172 @ 8370 updates, score 17.722) (writing took 2.8516685869544744 seconds)
2022-03-06 07:37:43 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-06 07:37:43 | INFO | train | epoch 172 | loss 0.471 | ppl 1.39 | wps 8893.5 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8370 | lr 0.000345651 | gnorm 0.836 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 61978
2022-03-06 07:37:43 | INFO | fairseq.trainer | begin training epoch 173
2022-03-06 07:37:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:41:15 | INFO | train_inner | epoch 173:     30 / 49 loss=0.471, ppl=1.39, wps=8901.3, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.834, loss_scale=64, train_wall=668, gb_free=9, wall=62191
2022-03-06 07:43:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:43:37 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 17.759 | ppl 221746 | wps 20893.9 | wpb 510.9 | bsz 1 | num_updates 8419 | best_loss 8.372
2022-03-06 07:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8419 updates
2022-03-06 07:43:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:43:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 173 @ 8419 updates, score 17.759) (writing took 2.866645493078977 seconds)
2022-03-06 07:43:40 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-06 07:43:40 | INFO | train | epoch 173 | loss 0.465 | ppl 1.38 | wps 8893.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8419 | lr 0.000344643 | gnorm 0.829 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 62336
2022-03-06 07:43:40 | INFO | fairseq.trainer | begin training epoch 174
2022-03-06 07:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:49:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:49:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:49:34 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 17.763 | ppl 222474 | wps 20930.1 | wpb 510.9 | bsz 1 | num_updates 8467 | best_loss 8.372
2022-03-06 07:49:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8467 updates
2022-03-06 07:49:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:49:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:49:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 174 @ 8467 updates, score 17.763) (writing took 2.8088234439492226 seconds)
2022-03-06 07:49:37 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-06 07:49:37 | INFO | train | epoch 174 | loss 0.46 | ppl 1.38 | wps 8709.7 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 8467 | lr 0.000343665 | gnorm 0.825 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 62693
2022-03-06 07:49:37 | INFO | fairseq.trainer | begin training epoch 175
2022-03-06 07:49:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:53:31 | INFO | train_inner | epoch 175:     33 / 49 loss=0.461, ppl=1.38, wps=8814.3, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.831, loss_scale=32, train_wall=675, gb_free=9, wall=62927
2022-03-06 07:55:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:55:32 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 17.784 | ppl 225649 | wps 20932.5 | wpb 510.9 | bsz 1 | num_updates 8516 | best_loss 8.372
2022-03-06 07:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8516 updates
2022-03-06 07:55:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:55:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 07:55:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 175 @ 8516 updates, score 17.784) (writing took 2.9236981640569866 seconds)
2022-03-06 07:55:35 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-06 07:55:35 | INFO | train | epoch 175 | loss 0.457 | ppl 1.37 | wps 8892.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8516 | lr 0.000342675 | gnorm 0.83 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 63050
2022-03-06 07:55:35 | INFO | fairseq.trainer | begin training epoch 176
2022-03-06 07:55:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:01:29 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 17.846 | ppl 235605 | wps 20944.9 | wpb 510.9 | bsz 1 | num_updates 8565 | best_loss 8.372
2022-03-06 08:01:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8565 updates
2022-03-06 08:01:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:01:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 176 @ 8565 updates, score 17.846) (writing took 2.860044453991577 seconds)
2022-03-06 08:01:32 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-06 08:01:32 | INFO | train | epoch 176 | loss 0.451 | ppl 1.37 | wps 8892.6 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8565 | lr 0.000341693 | gnorm 0.818 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 63408
2022-03-06 08:01:32 | INFO | fairseq.trainer | begin training epoch 177
2022-03-06 08:01:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:05:40 | INFO | train_inner | epoch 177:     35 / 49 loss=0.45, ppl=1.37, wps=8898.6, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.815, loss_scale=64, train_wall=668, gb_free=9, wall=63656
2022-03-06 08:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:07:27 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 18.023 | ppl 266333 | wps 20912.6 | wpb 510.9 | bsz 1 | num_updates 8614 | best_loss 8.372
2022-03-06 08:07:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8614 updates
2022-03-06 08:07:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:07:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:07:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 177 @ 8614 updates, score 18.023) (writing took 2.803907004185021 seconds)
2022-03-06 08:07:29 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-06 08:07:29 | INFO | train | epoch 177 | loss 0.448 | ppl 1.36 | wps 8894.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8614 | lr 0.00034072 | gnorm 0.806 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 63765
2022-03-06 08:07:29 | INFO | fairseq.trainer | begin training epoch 178
2022-03-06 08:07:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:13:24 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 17.966 | ppl 255969 | wps 20960.7 | wpb 510.9 | bsz 1 | num_updates 8663 | best_loss 8.372
2022-03-06 08:13:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8663 updates
2022-03-06 08:13:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:13:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:13:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 178 @ 8663 updates, score 17.966) (writing took 2.8674426139332354 seconds)
2022-03-06 08:13:27 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-06 08:13:27 | INFO | train | epoch 178 | loss 0.444 | ppl 1.36 | wps 8892.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8663 | lr 0.000339755 | gnorm 0.808 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 64122
2022-03-06 08:13:27 | INFO | fairseq.trainer | begin training epoch 179
2022-03-06 08:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:17:49 | INFO | train_inner | epoch 179:     37 / 49 loss=0.443, ppl=1.36, wps=8899.7, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.806, loss_scale=64, train_wall=668, gb_free=9, wall=64385
2022-03-06 08:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:19:21 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 18.132 | ppl 287238 | wps 20957 | wpb 510.9 | bsz 1 | num_updates 8712 | best_loss 8.372
2022-03-06 08:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8712 updates
2022-03-06 08:19:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:19:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:19:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 179 @ 8712 updates, score 18.132) (writing took 2.8360228771343827 seconds)
2022-03-06 08:19:24 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-06 08:19:24 | INFO | train | epoch 179 | loss 0.438 | ppl 1.36 | wps 8893.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8712 | lr 0.000338798 | gnorm 0.801 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 64480
2022-03-06 08:19:24 | INFO | fairseq.trainer | begin training epoch 180
2022-03-06 08:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:20:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 08:22:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:25:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:25:19 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 18.113 | ppl 283472 | wps 20897.7 | wpb 510.9 | bsz 1 | num_updates 8759 | best_loss 8.372
2022-03-06 08:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8759 updates
2022-03-06 08:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:25:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:25:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 180 @ 8759 updates, score 18.113) (writing took 2.8293977279681712 seconds)
2022-03-06 08:25:21 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-06 08:25:21 | INFO | train | epoch 180 | loss 0.436 | ppl 1.35 | wps 8526.9 | ups 0.13 | wpb 64829.4 | bsz 126.6 | num_updates 8759 | lr 0.000337888 | gnorm 0.825 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 64837
2022-03-06 08:25:21 | INFO | fairseq.trainer | begin training epoch 181
2022-03-06 08:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:30:12 | INFO | train_inner | epoch 181:     41 / 49 loss=0.435, ppl=1.35, wps=8732.3, ups=0.13, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.811, loss_scale=32, train_wall=681, gb_free=9, wall=65128
2022-03-06 08:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:31:16 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 18.059 | ppl 273118 | wps 20931.8 | wpb 510.9 | bsz 1 | num_updates 8808 | best_loss 8.372
2022-03-06 08:31:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8808 updates
2022-03-06 08:31:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:31:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:31:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 181 @ 8808 updates, score 18.059) (writing took 2.8006858630105853 seconds)
2022-03-06 08:31:19 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-06 08:31:19 | INFO | train | epoch 181 | loss 0.43 | ppl 1.35 | wps 8898.3 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8808 | lr 0.000336947 | gnorm 0.795 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 65194
2022-03-06 08:31:19 | INFO | fairseq.trainer | begin training epoch 182
2022-03-06 08:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:37:13 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 18.143 | ppl 289397 | wps 20912.2 | wpb 510.9 | bsz 1 | num_updates 8857 | best_loss 8.372
2022-03-06 08:37:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8857 updates
2022-03-06 08:37:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:37:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 182 @ 8857 updates, score 18.143) (writing took 2.8942500329576433 seconds)
2022-03-06 08:37:16 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-06 08:37:16 | INFO | train | epoch 182 | loss 0.426 | ppl 1.34 | wps 8894.2 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8857 | lr 0.000336013 | gnorm 0.787 | loss_scale 32 | train_wall 327 | gb_free 9 | wall 65552
2022-03-06 08:37:16 | INFO | fairseq.trainer | begin training epoch 183
2022-03-06 08:37:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:42:21 | INFO | train_inner | epoch 183:     43 / 49 loss=0.425, ppl=1.34, wps=8901.6, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.788, loss_scale=64, train_wall=668, gb_free=9, wall=65857
2022-03-06 08:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:43:10 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 18.241 | ppl 309760 | wps 20968.8 | wpb 510.9 | bsz 1 | num_updates 8906 | best_loss 8.372
2022-03-06 08:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8906 updates
2022-03-06 08:43:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:43:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:43:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 183 @ 8906 updates, score 18.241) (writing took 2.9208946130238473 seconds)
2022-03-06 08:43:13 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-06 08:43:13 | INFO | train | epoch 183 | loss 0.424 | ppl 1.34 | wps 8891.9 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8906 | lr 0.000335088 | gnorm 0.789 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 65909
2022-03-06 08:43:13 | INFO | fairseq.trainer | begin training epoch 184
2022-03-06 08:43:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:49:08 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 18.217 | ppl 304607 | wps 20952.9 | wpb 510.9 | bsz 1 | num_updates 8955 | best_loss 8.372
2022-03-06 08:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8955 updates
2022-03-06 08:49:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:49:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:49:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 184 @ 8955 updates, score 18.217) (writing took 2.886329262983054 seconds)
2022-03-06 08:49:11 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-06 08:49:11 | INFO | train | epoch 184 | loss 0.42 | ppl 1.34 | wps 8894 | ups 0.14 | wpb 64858.2 | bsz 126.7 | num_updates 8955 | lr 0.00033417 | gnorm 0.773 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 66266
2022-03-06 08:49:11 | INFO | fairseq.trainer | begin training epoch 185
2022-03-06 08:49:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:53:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 08:54:37 | INFO | train_inner | epoch 185:     46 / 49 loss=0.419, ppl=1.34, wps=8814.4, ups=0.14, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.783, loss_scale=64, train_wall=675, gb_free=9, wall=66593
2022-03-06 08:54:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:55:05 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 18.273 | ppl 316756 | wps 20953.1 | wpb 510.9 | bsz 1 | num_updates 9003 | best_loss 8.372
2022-03-06 08:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9003 updates
2022-03-06 08:55:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:55:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt
2022-03-06 08:55:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-cross_entropy_#2/checkpoint_last.pt (epoch 185 @ 9003 updates, score 18.273) (writing took 2.9062502558808774 seconds)
2022-03-06 08:55:08 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-06 08:55:08 | INFO | train | epoch 185 | loss 0.417 | ppl 1.33 | wps 8709.9 | ups 0.13 | wpb 64844.1 | bsz 126.7 | num_updates 9003 | lr 0.000333278 | gnorm 0.791 | loss_scale 64 | train_wall 327 | gb_free 9 | wall 66624
2022-03-06 08:55:08 | INFO | fairseq.trainer | begin training epoch 186
2022-03-06 08:55:08 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/cross_entropy.py", line 35, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 328, in extract_features_scriptable
    if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():
KeyboardInterrupt
