Sender: LSF System <lsfadmin@eu-g3-053>
Subject: Job 210580341: <iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 09:22:31 2022
Job was executed on host(s) <eu-g3-053>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 09:22:53 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 09:22:53 2022
Terminated at Wed Mar 23 10:33:31 2022
Results reported at Wed Mar 23 10:33:31 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4215.69 sec.
    Max Memory :                                 5455 MB
    Average Memory :                             4277.82 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14545.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   4246 sec.
    Turnaround time :                            4260 sec.

The output (if any) follows:

2022-03-23 09:23:05 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 09:23:05 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 09:23:05 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 09:23:06 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 09:23:06 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 09:23:06 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 09:23:06 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-23 09:23:06 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 09:23:06 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 09:23:06 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 09:23:06 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 09:23:06 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 09:23:12 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 09:23:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:23:12 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 09:23:12 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 09:23:12 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 09:23:12 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 09:23:12 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:23:12 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:23:12 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 09:23:12 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 09:23:12 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 09:23:12 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 09:23:13 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 09:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:23:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 09:23:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 09:23:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 09:23:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 09:23:50 | INFO | train_inner | epoch 001:    104 / 157 loss=12.018, nll_loss=11.855, ppl=3703.58, wps=79283.3, ups=3.15, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.309, loss_scale=8, train_wall=36, gb_free=14, wall=38
2022-03-23 09:24:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:24:10 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:24:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:24:12 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 09:24:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:24:15 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,...
2022-03-23 09:24:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:24:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 09:24:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:24:22 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:24:27 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:24:32 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:24:38 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:24:45 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:24:47 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:24:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:24:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.373 | nll_loss 10.007 | ppl 1028.95 | bleu 0.01 | wps 4335.9 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 09:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 09:24:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.6184019185602665 seconds)
2022-03-23 09:24:49 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 09:24:49 | INFO | train | epoch 001 | loss 11.581 | nll_loss 11.367 | ppl 2641.41 | wps 42220.1 | ups 1.68 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.643 | loss_scale 8 | train_wall 52 | gb_free 22.4 | wall 97
2022-03-23 09:24:49 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 09:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:25:04 | INFO | train_inner | epoch 002:     47 / 157 loss=10.515, nll_loss=10.175, ppl=1156.02, wps=34160.4, ups=1.35, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=1.313, loss_scale=8, train_wall=30, gb_free=14.7, wall=112
2022-03-23 09:25:36 | INFO | train_inner | epoch 002:    147 / 157 loss=9.816, nll_loss=9.362, ppl=658.22, wps=79889.3, ups=3.17, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=1.428, loss_scale=8, train_wall=31, gb_free=14, wall=143
2022-03-23 09:25:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:25:42 | INFO | fairseq.tasks.translation | example hypothesis: we we we we.
2022-03-23 09:25:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:25:46 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the.
2022-03-23 09:25:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:25:50 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:25:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:25:55 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:25:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:26:00 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:26:06 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:26:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:26:12 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:26:17 | INFO | fairseq.tasks.translation | example hypothesis: and and we we we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:26:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:26:25 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:26:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:26:27 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 09:26:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:26:27 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.478 | nll_loss 8.928 | ppl 487.18 | bleu 0.01 | wps 3613.5 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 09:26:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 09:26:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:26:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:26:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 1.6971156899817288 seconds)
2022-03-23 09:26:29 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 09:26:29 | INFO | train | epoch 002 | loss 9.937 | nll_loss 9.506 | ppl 727.05 | wps 39525.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.359 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 196
2022-03-23 09:26:29 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 09:26:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:26:57 | INFO | train_inner | epoch 003:     90 / 157 loss=9.507, nll_loss=8.979, ppl=504.75, wps=30092.7, ups=1.22, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=1.304, loss_scale=8, train_wall=30, gb_free=13.7, wall=225
2022-03-23 09:27:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:27:22 | INFO | fairseq.tasks.translation | example hypothesis: we we the the the the the the the the the the the the the.
2022-03-23 09:27:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:27:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the.
2022-03-23 09:27:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:27:31 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the the
2022-03-23 09:27:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:27:35 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, and it's's's's, it's, and it's's, and it's's's, and it's's's's's's's's's.
2022-03-23 09:27:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:27:41 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's's's's's that that that's's's's's's that that that that that that that that's's's's's's's's's's's's.
2022-03-23 09:27:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:27:47 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:27:52 | INFO | fairseq.tasks.translation | example hypothesis: and it's, and the the the the the the, and the, and the, and it's, and the the the the the, and the the the the the, and the the the the, and the, and the the the the the, and the the the the the, and the, and the, and the the the the the the
2022-03-23 09:27:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:27:59 | INFO | fairseq.tasks.translation | example hypothesis: and and we the the the the the the the the the the the the the the the the the the the the the the of the the the the the the the the the the the the the the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 09:27:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:28:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 09:28:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:28:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's a a a a a a a a a a a a, and the a a a a, and the a a a, and the the a a a a a a a a a, and the a a a a, and the a a a a a a a a a a a, and the a a a a a a a a, and the a a a a a a a a a a a a a a a a, and the a a a a a a a a a a a a a a a a a, and the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a, and the, and the, and the a a a a a a a a a a a a a a a a a a a a a a a a a a a a, and the, and the, and the a a a a a a a a a a a a a a a a a a a a a
2022-03-23 09:28:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:28:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.197 | nll_loss 8.588 | ppl 384.88 | bleu 0.1 | wps 3490.6 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.1
2022-03-23 09:28:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 09:28:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.1) (writing took 1.7345516928471625 seconds)
2022-03-23 09:28:11 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 09:28:11 | INFO | train | epoch 003 | loss 9.425 | nll_loss 8.882 | ppl 471.72 | wps 38808.6 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.408 | loss_scale 8 | train_wall 48 | gb_free 13.7 | wall 298
2022-03-23 09:28:11 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 09:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:28:22 | INFO | train_inner | epoch 004:     33 / 157 loss=9.282, nll_loss=8.714, ppl=419.86, wps=30222.2, ups=1.19, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.503, loss_scale=8, train_wall=31, gb_free=13.9, wall=309
2022-03-23 09:28:53 | INFO | train_inner | epoch 004:    133 / 157 loss=9.055, nll_loss=8.453, ppl=350.37, wps=79928.9, ups=3.16, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.484, loss_scale=8, train_wall=31, gb_free=12.6, wall=341
2022-03-23 09:29:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:29:04 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 09:29:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:29:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the world is the world of the world is the world.
2022-03-23 09:29:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:29:12 | INFO | fairseq.tasks.translation | example hypothesis: so we have to have to have to be the world of the world.
2022-03-23 09:29:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example hypothesis: and there's a world, there's a world, and there's a world.
2022-03-23 09:29:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's not not not not not not not not not not not not not not not not not not not not not not not not not not not that we have that we're not not not not not not not not not not that
2022-03-23 09:29:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world, and the world, and the world, and the world of the world of the world.
2022-03-23 09:29:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:29:31 | INFO | fairseq.tasks.translation | example hypothesis: but there's the world, but there are are are are are the world, but there are the world, but they are are are are the world, but they are are are are are are the world, but they are are are are are are are are are are are are are are are are are are are are are are are the world, but there
2022-03-23 09:29:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:29:37 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can can see the world, and we can can can can can see the world of the world of the world, and we have the world of the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 09:29:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 09:29:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:29:47 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to have to have to have to be the world of the world of the world, which is the world of the world of the world of the world of the world of the world, and we've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've've have to have to be be be be be be be be be be be be be be to be be be be be to be to be to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be be be be be be be be be be be be to be to be to be to be to be be be be be be be be be be be be be be be be be to be to be to be be to be be be be be be be be be be be be be be be be be be be be be
2022-03-23 09:29:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:29:47 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.692 | nll_loss 8.004 | ppl 256.75 | bleu 1.06 | wps 3801.9 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.06
2022-03-23 09:29:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 09:29:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:29:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:29:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.06) (writing took 1.7367510083131492 seconds)
2022-03-23 09:29:49 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 09:29:49 | INFO | train | epoch 004 | loss 9.062 | nll_loss 8.462 | ppl 352.53 | wps 40177.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.496 | loss_scale 8 | train_wall 48 | gb_free 13.9 | wall 397
2022-03-23 09:29:49 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 09:29:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:30:13 | INFO | train_inner | epoch 005:     76 / 157 loss=8.812, nll_loss=8.172, ppl=288.43, wps=30730.9, ups=1.25, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.749, loss_scale=8, train_wall=30, gb_free=13.4, wall=421
2022-03-23 09:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:30:42 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world.
2022-03-23 09:30:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:30:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the world.
2022-03-23 09:30:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a new new lot.
2022-03-23 09:30:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:30:52 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world.
2022-03-23 09:30:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:30:56 | INFO | fairseq.tasks.translation | example hypothesis: and this is what we're going to do that we're going to do it.
2022-03-23 09:30:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:31:00 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the world of the world in the world in the world in the world.
2022-03-23 09:31:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example hypothesis: but there are a lot of the lot of the world, but they're going to be a lot of the world, but they're going to be a lot of the lot of the world, but they're going to be in the world, but they're going to be in the world, but they're going to be in the world, but they're
2022-03-23 09:31:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:31:11 | INFO | fairseq.tasks.translation | example hypothesis: so, we can see the world of the world of the world, and we can see the world of the world of the world, and we can see the world of the world of the world of the world of the world, and we can see the world of the world, and we can see the world of the world of the world of the world of the world of the world of the world, and we can see the world of the world, and we can
2022-03-23 09:31:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "" "" "" "" "" "" "" "this is the world," it's the world, "it's the first first" "" "" "" "" "" "" "it's the world," it's the world, "" "" "" it's the world, "it's the world," "" "" "" "" "" "" "it's the world," "" "" "" "" "" "" "" "" "" "" "" "" "the first first first first first first first first first first first first first first first first first first first first first first first first first first first," "" "" "" "" the first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 09:31:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example hypothesis: so, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world,
2022-03-23 09:31:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:31:21 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.314 | nll_loss 7.566 | ppl 189.43 | bleu 1.7 | wps 4190.5 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.7
2022-03-23 09:31:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 09:31:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:31:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:31:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.7) (writing took 1.7484663217328489 seconds)
2022-03-23 09:31:23 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 09:31:23 | INFO | train | epoch 005 | loss 8.631 | nll_loss 7.961 | ppl 249.13 | wps 42030.4 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.617 | loss_scale 8 | train_wall 48 | gb_free 14 | wall 491
2022-03-23 09:31:23 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 09:31:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:31:29 | INFO | train_inner | epoch 006:     19 / 157 loss=8.51, nll_loss=7.819, ppl=225.84, wps=33380.9, ups=1.32, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.611, loss_scale=8, train_wall=31, gb_free=14.6, wall=497
2022-03-23 09:31:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 09:32:01 | INFO | train_inner | epoch 006:    120 / 157 loss=8.334, nll_loss=7.61, ppl=195.37, wps=79111.4, ups=3.14, wpb=25234.2, bsz=1007, num_updates=900, lr=0.0001125, gnorm=1.509, loss_scale=4, train_wall=31, gb_free=14.1, wall=529
2022-03-23 09:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:32:16 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 09:32:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:32:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the idea of the world.
2022-03-23 09:32:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:32:25 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be a new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 09:32:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:32:29 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of course, there's a lot of the world.
2022-03-23 09:32:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:32:34 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not what we're going to do that we're going to do it's going to do it's not not not not not going to do.
2022-03-23 09:32:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:32:39 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, and in the world, in the world, in the world, in the world, and in the world.
2022-03-23 09:32:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example hypothesis: but if you're going to see, but they're going to be a lot of the way, but they're not going to be a lot of the way, but they're going to be a lot of the same way, but they're going to be a lot of the way.
2022-03-23 09:32:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:32:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to get a lot of the world, and we're going to see the world, and then we can see, and we're going to see the world.
2022-03-23 09:32:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:32:58 | INFO | fairseq.tasks.translation | example hypothesis: so, "this is," "" you know, "" "it's a" it's a lot of the first, "it's," "it's," it's a "" "" "" it's, "it's," you said, "well," you know, "" it's a "you know," you know, "you know," "" it's a first first first first first, "" "" "" "" it's a first first first first first first first first first first first first first first, "" "it's," "" "" it's, "it's going to do," "it's," it's, "it's," it's, "it's a first first first first first first first first first first first first first first first first first," "" ""
2022-03-23 09:32:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:33:01 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of fact, but we're going to be a lot of the world, but we're going to be a lot of the world, but we're going to be a lot of the world, but it, but it's a lot of the world.
2022-03-23 09:33:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:33:01 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.003 | nll_loss 7.177 | ppl 144.72 | bleu 1.93 | wps 3709.3 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.93
2022-03-23 09:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 09:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.93) (writing took 1.7645710832439363 seconds)
2022-03-23 09:33:02 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 09:33:02 | INFO | train | epoch 006 | loss 8.318 | nll_loss 7.592 | ppl 192.9 | wps 39360.2 | ups 1.57 | wpb 25122.4 | bsz 1014.9 | num_updates 937 | lr 0.000117125 | gnorm 1.58 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 590
2022-03-23 09:33:03 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 09:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:33:23 | INFO | train_inner | epoch 007:     63 / 157 loss=8.109, nll_loss=7.351, ppl=163.23, wps=30859.3, ups=1.23, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.336, loss_scale=4, train_wall=30, gb_free=14.9, wall=610
2022-03-23 09:33:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:33:56 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the world.
2022-03-23 09:33:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:33:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the most idea of course.
2022-03-23 09:33:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:34:04 | INFO | fairseq.tasks.translation | example hypothesis: so we're going to be new new new new new new new new new new new new new new new york.
2022-03-23 09:34:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:34:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a lot, and it's going to be going to be, and it's going to be going to be, and it, and it's going to be going to be going to
2022-03-23 09:34:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example hypothesis: it's it's just just just just to do that we're going to do it, and we're going to do it, and we're going to do it, and we're going to do that we're going to do it's going
2022-03-23 09:34:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:34:20 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, in the world, in the world, in the world, and it's the world, and it's the world for the people, and the people for the world, and the world, for the world, and the world, and it's in the people
2022-03-23 09:34:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:34:26 | INFO | fairseq.tasks.translation | example hypothesis: well, some of course, if you're going to get a lot of these are going to go, but they're going to be able to be able, but it, but they're going to be able to be able to be able, but they're going to be able, but they're going to be able, but they're going to be able
2022-03-23 09:34:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take a lot of the world, and we're going to take the world, and we're going to see the world, and we can see the world, and we can see that we're going to see the world, and we can see the world, and we can see that we can see that we can see the world, and we're going to see the world, and we can see the world, and we're going to
2022-03-23 09:34:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:34:40 | INFO | fairseq.tasks.translation | example hypothesis: well, if you know, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "well," you're going to say, "you're going to say," well, "you're going to say," you're going to say, "well," well, "well," well, "well," you're going to say, "well," well, "you're going to say," well, "you're going to say," well, "you're going to say," you're going to say, "you know," you're going to say, "you're going to say," you're going to say, "you're going to say," well, "you're going to say," "
2022-03-23 09:34:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:34:42 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to get a lot of the world, and we're going to be able to see the world, and we're going to be a little little little little little little little little bit that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:34:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:34:42 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.742 | nll_loss 6.863 | ppl 116.42 | bleu 2.06 | wps 3525 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.06
2022-03-23 09:34:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 09:34:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:34:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:34:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.06) (writing took 1.8176893657073379 seconds)
2022-03-23 09:34:44 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 09:34:44 | INFO | train | epoch 007 | loss 7.996 | nll_loss 7.22 | ppl 149.05 | wps 38906.4 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.317 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 692
2022-03-23 09:34:44 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 09:34:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:34:46 | INFO | train_inner | epoch 008:      6 / 157 loss=7.931, nll_loss=7.144, ppl=141.41, wps=29920.2, ups=1.2, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.372, loss_scale=4, train_wall=31, gb_free=14.4, wall=694
2022-03-23 09:35:17 | INFO | train_inner | epoch 008:    106 / 157 loss=7.694, nll_loss=6.869, ppl=116.86, wps=80600.4, ups=3.19, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.338, loss_scale=4, train_wall=31, gb_free=14.7, wall=725
2022-03-23 09:35:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:35:38 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in this.
2022-03-23 09:35:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:35:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the most idea of the most most most most most most of the most most most most most most of the most most most most most most of
2022-03-23 09:35:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:35:46 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new york.
2022-03-23 09:35:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:35:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's an example, and there's an example, where it's going to be going to be where you're going to see where where you're going to see where where where
2022-03-23 09:35:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:35:56 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're going to do it, and what we're going to do, and what we're going to do.
2022-03-23 09:35:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:36:02 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people in the most people for the people for the people, for the people, for the people, for the people, for the people, for the people, for the people, for the people, for the people, for the people, for the people, and the
2022-03-23 09:36:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:36:08 | INFO | fairseq.tasks.translation | example hypothesis: some are some of some of some of them, but if you're going to see, but if you're going to see it, but if you're going to see, it, but it, it's all the same time, if you're not the same, if you're not the same, but it's the same, if you're going to
2022-03-23 09:36:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the way that we can see the brain, we can see that we can see the brain, and we can see that we can see the brain, and then we can see that we can see the brain, we can see the brain, and then we can see that we can see the one of the brain, we can see the brain, we can see the one of the brain, we can see the one of the brain,
2022-03-23 09:36:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:36:21 | INFO | fairseq.tasks.translation | example hypothesis: one: the one: the one one: it's going to say, "well," well, "you know," well, "you know," you know, "well," well, "you know," well, "you know," well, "well," it's the first thing, "well," you know, "you know," well, "well," it's the first one of the first one of the first one of the first one of the first one of the first thing, "well," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "it's the first thing," it's the first one, "you know,"
2022-03-23 09:36:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:36:24 | INFO | fairseq.tasks.translation | example hypothesis: now, it's only only more than the same time, if we're going to be a, if we're going to take the same time, if we're going to be a, if we're going to take the same time, if we're going to be a, if we're going to take the same time, if we're going to get the same time, if we're going to take the same time, if we're going to take the same time, if we're going to take the same time, if we're going to take the same time, and then we're going to be a, if we're going to take the same time, if we're going to take the same time, if we're going to be a, if we're going to take the same time, if we're going to take the same time, if we're going to take the same time, if we're going to take the same time, if we're going to be a, if we're going to be a, if we're going to
2022-03-23 09:36:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:36:24 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.444 | nll_loss 6.514 | ppl 91.4 | bleu 3.37 | wps 3551.9 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.37
2022-03-23 09:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 09:36:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:36:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.37) (writing took 1.798855836968869 seconds)
2022-03-23 09:36:26 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 09:36:26 | INFO | train | epoch 008 | loss 7.729 | nll_loss 6.909 | ppl 120.14 | wps 38827.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.318 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 793
2022-03-23 09:36:26 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 09:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:36:42 | INFO | train_inner | epoch 009:     49 / 157 loss=7.654, nll_loss=6.819, ppl=112.94, wps=30529.9, ups=1.19, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.304, loss_scale=4, train_wall=31, gb_free=14.9, wall=809
2022-03-23 09:37:13 | INFO | train_inner | epoch 009:    149 / 157 loss=7.483, nll_loss=6.621, ppl=98.41, wps=79654.4, ups=3.21, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.273, loss_scale=4, train_wall=31, gb_free=14.3, wall=840
2022-03-23 09:37:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:37:19 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the ppon in the top of the top.
2022-03-23 09:37:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most most of the most most.
2022-03-23 09:37:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new york.
2022-03-23 09:37:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:37:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a poy, where it's going to go, and where it's going to go.
2022-03-23 09:37:31 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to do a few years, and what's going to do.
2022-03-23 09:37:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, like people like people for the people for the people, for the people, and it's a lot of people in the united states.
2022-03-23 09:37:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of the water, but if you're going to look at the water, but it doesn't have to go, but if you can't get it, it, it's the same way, but it's the same way, and then it's going to go to be able to go, and then it's going to go out
2022-03-23 09:37:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:37:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we can see the information that we can see that we can see that we can see the brain, and then we can use the brain, and then we can use the brain, and then we can use the brain, and then we can use the brain.
2022-03-23 09:37:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:37:56 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the world, and it's going to say, "well," and then it's going to say, "oh," you know, "you know," well, "well," you know, "well," well, "well," well, "well," well, "well, if you're going to say," well, "well, if you're going to say," well, "well," you know, "well," well, "you're going to say," well, "well," well, "well," well, "you're going to go to go to say," well, "you know," you know, "you know, you know," well, "oh," you know, "well," well, "oh," you're going to say, "well,
2022-03-23 09:37:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example hypothesis: now, it's still still still still still at the same time, and if you're going to have a little bit that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 09:37:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:37:58 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.104 | nll_loss 6.125 | ppl 69.79 | bleu 6.25 | wps 4166.6 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 6.25
2022-03-23 09:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 09:37:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:38:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 6.25) (writing took 1.8160130539909005 seconds)
2022-03-23 09:38:00 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 09:38:00 | INFO | train | epoch 009 | loss 7.493 | nll_loss 6.633 | ppl 99.26 | wps 41707.2 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.314 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 888
2022-03-23 09:38:01 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 09:38:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:38:30 | INFO | train_inner | epoch 010:     92 / 157 loss=7.284, nll_loss=6.39, ppl=83.87, wps=32496.6, ups=1.29, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.26, loss_scale=4, train_wall=31, gb_free=14.3, wall=918
2022-03-23 09:38:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the top of the ground.
2022-03-23 09:38:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:38:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the most point of the ha, "most of most most most most most most most most most most most most most.
2022-03-23 09:38:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:39:02 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be two new new new new new york.
2022-03-23 09:39:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:39:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese, where it's going to be where it's going to go up.
2022-03-23 09:39:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:39:10 | INFO | fairseq.tasks.translation | example hypothesis: it's not just just a few years ago, and we're not going to understand what's going on.
2022-03-23 09:39:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example hypothesis: and it's like people like people like people for the most people for the people, and the number of the people, and it's a number of people in the number of the most people.
2022-03-23 09:39:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:39:20 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are in the water, but it's not able to be able to get the energy, but if you need to get the energy, and it's not the energy, and if you need to get the energy.
2022-03-23 09:39:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:39:26 | INFO | fairseq.tasks.translation | example hypothesis: so, if we can use the information of this information, we can use this structure, we can use a structure, and we can use the brain, and all of the structure, and all of the structure, and all of the structure, and all of the structure, and all of the structure, and all of the structure, and that's all of the structure, and all of the structure, and all of the structure, and the structure, and we can
2022-03-23 09:39:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the reason, and it's interesting to be interesting for me, and it's going to say, "for me," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "is that," is that, "is," is that, "is a lot of the first time," is that, "is," is, "is," is that, "is," is that, "is a lot of the first," is a lot of the first time, "is a lot of the first time," is, "is that," is, "is,"
2022-03-23 09:39:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:39:34 | INFO | fairseq.tasks.translation | example hypothesis: it's still still still still still the mother, and the first thing that we're going to have a lot of work, and if we have a lot of the system that we had to have a new system, and then we had to have a new system, and then we had to have a new system that we had to have a new system that we had to have a new system that we had to have to have a new system that we had to have a new system that we had to have a new system, to get a new system, to be able system, to get a new system, to be able system, and the system that we had a new system that we had to have a new system that we have a new system that we had a new system, to get a new system, to be able system, to be able system, and then we have a new system that we had to have a new system, to be able system that we had to have a new system, to be able system, and then have a new system,
2022-03-23 09:39:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:39:34 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.841 | nll_loss 5.809 | ppl 56.06 | bleu 6.98 | wps 4048.1 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.98
2022-03-23 09:39:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 09:39:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:39:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:39:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.98) (writing took 1.780856667086482 seconds)
2022-03-23 09:39:36 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 09:39:36 | INFO | train | epoch 010 | loss 7.2 | nll_loss 6.292 | ppl 78.37 | wps 41228.1 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.266 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 984
2022-03-23 09:39:36 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 09:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:39:48 | INFO | train_inner | epoch 011:     35 / 157 loss=7.108, nll_loss=6.184, ppl=72.72, wps=32013.6, ups=1.29, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.273, loss_scale=4, train_wall=30, gb_free=13.4, wall=995
2022-03-23 09:40:19 | INFO | train_inner | epoch 011:    135 / 157 loss=6.889, nll_loss=5.932, ppl=61.07, wps=81245.7, ups=3.18, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.262, loss_scale=4, train_wall=31, gb_free=13.3, wall=1027
2022-03-23 09:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:40:30 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppon the clinic.
2022-03-23 09:40:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:40:34 | INFO | fairseq.tasks.translation | example hypothesis: and this is the makha, most of most of most of most of the most.
2022-03-23 09:40:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:40:38 | INFO | fairseq.tasks.translation | example hypothesis: these are new york will be two new new new new cells.
2022-03-23 09:40:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:40:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese, where they're going to go with the pppppppppon.
2022-03-23 09:40:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:40:46 | INFO | fairseq.tasks.translation | example hypothesis: it's not sure that we're not just just a few years on his head, and what's going on.
2022-03-23 09:40:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:40:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamase of people who have been used for the number of the number of animals, and that's a lot of the population.
2022-03-23 09:40:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:40:54 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the water, but if you don't need to use the energy, if you don't need your energy, and if you need to use your energy.
2022-03-23 09:40:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:40:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use this structure, we can be able to be able to create a structure of the structure, and the information that are all the structure of the information that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create the structure of the information.
2022-03-23 09:40:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example hypothesis: second, one of the reasons, and it's interesting for me, "you know," you know, "you know," oh, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," oh, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know,
2022-03-23 09:41:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:41:05 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and a lot of work that we were going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:41:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:41:05 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.576 | nll_loss 5.479 | ppl 44.61 | bleu 10.08 | wps 4702.2 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 10.08
2022-03-23 09:41:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 09:41:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:41:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:41:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 10.08) (writing took 1.7942610858008265 seconds)
2022-03-23 09:41:07 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 09:41:07 | INFO | train | epoch 011 | loss 6.941 | nll_loss 5.991 | ppl 63.61 | wps 43641.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.245 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1074
2022-03-23 09:41:07 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 09:41:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:41:31 | INFO | train_inner | epoch 012:     78 / 157 loss=6.789, nll_loss=5.814, ppl=56.25, wps=34505.6, ups=1.38, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.21, loss_scale=4, train_wall=31, gb_free=14, wall=1099
2022-03-23 09:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:42:00 | INFO | fairseq.tasks.translation | example hypothesis: we did this pm in the clinics.
2022-03-23 09:42:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:42:04 | INFO | fairseq.tasks.translation | example hypothesis: that's the right line of doha, most of most of most of most of most here.
2022-03-23 09:42:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:42:08 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able to make two new ways.
2022-03-23 09:42:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:42:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese chinese food, where they're going to get up with it.
2022-03-23 09:42:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:42:16 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just just a few different camera on his head on his head, and what all of your mind.
2022-03-23 09:42:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:42:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamace of people who took the number of animals, and this is a number of animals that has been used to be a huge amount of reviiiiiiiiiiiiiiiiiiiiii
2022-03-23 09:42:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:42:24 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the rocks in the top, but it doesn't have to be able to go to the energy, if they don't need their energy, and they need their energy, and they need to use their energy.
2022-03-23 09:42:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:42:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of this structure, we can start to take a different structure, we can start to start with a different structure of the structure, and the information that we can start through the structure of the structure, and all the structure of the structure of the structure, and all the structure.
2022-03-23 09:42:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:42:33 | INFO | fairseq.tasks.translation | example hypothesis: jth: one of the reasons, and it's interesting for me to be able to be here for example, "oh," well, "if we're going to say," well, "if we're going to say," well, "you're going to say," well, "well," well, "well," you're going to tell you know, "well," well, "well," well, "well," well, "you know," well, "well," well, "well," well, "well," you know, "you know," you know, "you know," you know, "well," well, "well," well, "well," well, "well," well, "you know," well, "you know," well, "well," well, "
2022-03-23 09:42:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:42:35 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still the mother, and the great design of the work that we had to use our work on the ground that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that
2022-03-23 09:42:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:42:35 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.28 | nll_loss 5.124 | ppl 34.88 | bleu 10.56 | wps 4691.7 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 10.56
2022-03-23 09:42:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 09:42:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:42:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 10.56) (writing took 1.847385389264673 seconds)
2022-03-23 09:42:37 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 09:42:37 | INFO | train | epoch 012 | loss 6.661 | nll_loss 5.666 | ppl 50.76 | wps 43726.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.199 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1165
2022-03-23 09:42:37 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 09:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:42:44 | INFO | train_inner | epoch 013:     21 / 157 loss=6.534, nll_loss=5.519, ppl=45.87, wps=34677.6, ups=1.38, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.233, loss_scale=4, train_wall=31, gb_free=13.9, wall=1172
2022-03-23 09:43:15 | INFO | train_inner | epoch 013:    121 / 157 loss=6.427, nll_loss=5.39, ppl=41.93, wps=80397.9, ups=3.18, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.144, loss_scale=4, train_wall=31, gb_free=13.6, wall=1203
2022-03-23 09:43:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:43:30 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppppon in the clinic.
2022-03-23 09:43:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:43:34 | INFO | fairseq.tasks.translation | example hypothesis: that's the car line of doha ha ha, most of most of here.
2022-03-23 09:43:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:43:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new ororororts of the new orts that will be used.
2022-03-23 09:43:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:43:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food food, where they're going to do with pppace.
2022-03-23 09:43:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:43:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just just a few electroelectroelectrodes on his head, and what all of his mind.
2022-03-23 09:43:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:43:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamace of people for the responsibility, the number of animals, and this is a number of animals that has been built for the authiiiiibia.
2022-03-23 09:43:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:43:54 | INFO | fairseq.tasks.translation | example hypothesis: first of those are a few fice of neurons in the lines, but it doesn't have to move the alalalalalalalalalable energy energy, if you need your energy and the energy.
2022-03-23 09:43:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:43:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information information that we can be able to be able to be able to be able to start with a traditional traditional form of the shape of the structure, and see the information of the information and the information that all the structure of the structure.
2022-03-23 09:43:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting for me to be here for women -- yeah, "yeah," yeah, "if you're going to say," the best time, "and then you're going to say," and then you've been working with this time. "
2022-03-23 09:44:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:44:06 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, we're still able to see the mother, and the big design part of our work on our airplane, which was a unique system that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the
2022-03-23 09:44:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:44:06 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.023 | nll_loss 4.82 | ppl 28.26 | bleu 13.6 | wps 4671.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 13.6
2022-03-23 09:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 09:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:44:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 13.6) (writing took 1.8065859996713698 seconds)
2022-03-23 09:44:07 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 09:44:07 | INFO | train | epoch 013 | loss 6.403 | nll_loss 5.364 | ppl 41.17 | wps 43635.4 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.164 | loss_scale 4 | train_wall 48 | gb_free 13.5 | wall 1255
2022-03-23 09:44:08 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 09:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:44:28 | INFO | train_inner | epoch 014:     64 / 157 loss=6.264, nll_loss=5.2, ppl=36.77, wps=34389.9, ups=1.38, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.119, loss_scale=4, train_wall=31, gb_free=14, wall=1276
2022-03-23 09:44:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example hypothesis: we made this pppills in the clinics.
2022-03-23 09:45:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of most of the most knows here.
2022-03-23 09:45:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new ananananum.
2022-03-23 09:45:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:45:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where they're happy, and they're going to be able to get a salt.
2022-03-23 09:45:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:45:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head on his head, and what all of the thoughts are going on.
2022-03-23 09:45:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:45:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamace of responsibility for the responsibility, the number of animals grew up, and that has become become become a global.
2022-03-23 09:45:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:45:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic magnetic lines in the lines, but it doesn't have to move, but if you need to move the energy, and the energy.
2022-03-23 09:45:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional light, we can start able to start with a huge form of information, and the whole structure of the structure.
2022-03-23 09:45:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:45:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here at tedtedly, and then, when we said, "when we're talking about," and then we've been talking to you're talking about this word. "
2022-03-23 09:45:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:45:35 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big design of the work that we had to see that we had to be a unique system, and if we had to use a global system, and it had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, and see, and see, and see, and see, and see, and see, and see, and see that if it, and see the global global global global global global global global, and see, and see,
2022-03-23 09:45:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:45:35 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.885 | nll_loss 4.621 | ppl 24.62 | bleu 15.47 | wps 4805 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 15.47
2022-03-23 09:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 09:45:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 15.47) (writing took 1.8230291986837983 seconds)
2022-03-23 09:45:37 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 09:45:37 | INFO | train | epoch 014 | loss 6.132 | nll_loss 5.046 | ppl 33.04 | wps 44255.2 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.094 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1344
2022-03-23 09:45:37 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 09:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:45:39 | INFO | train_inner | epoch 015:      7 / 157 loss=6.034, nll_loss=4.932, ppl=30.53, wps=35699.1, ups=1.4, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.046, loss_scale=4, train_wall=31, gb_free=13.9, wall=1347
2022-03-23 09:46:11 | INFO | train_inner | epoch 015:    107 / 157 loss=5.886, nll_loss=4.759, ppl=27.07, wps=80236.6, ups=3.19, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.104, loss_scale=4, train_wall=31, gb_free=13.9, wall=1379
2022-03-23 09:46:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:46:30 | INFO | fairseq.tasks.translation | example hypothesis: we made this pills in the clinic clinic.
2022-03-23 09:46:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:46:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha doha, most of you know here.
2022-03-23 09:46:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:46:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks that are going to create two new covers.
2022-03-23 09:46:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food food, where happy legs are and salt and salt.
2022-03-23 09:46:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:46:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all its thoughts are on the mind.
2022-03-23 09:46:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:46:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamace of how people took the responsibility of life, and this is a number of animals that has become a devaiiiiiiiibia.
2022-03-23 09:46:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bber magnetic magnetic magnetic lines in the lines, but it doesn't like this, if you don't want to move your energy, you need your energy, and you need to move your energy, and you need to move your energy.
2022-03-23 09:46:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, we can start able to start able to start able to start with a traditional face of the face of the information, and the whole structure of all the structure of the structure, and all the structure of the information.
2022-03-23 09:47:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:47:05 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and interesting to make me here for tedwomen -- that's the best thing that the best thing was, "oh, if you're going to say," oh, you know, "you know," oh, you know, "oh," if you're going to support you're going to support you're going to have a long time for you know, "oh," oh, "oh," oh, "you know," you're going to do you're going to do you're going to have a long time for you know, "oh," oh, "oh," you're going to make you're going to make you know, "you know," oh, "oh," oh, "oh," oh, "you know," you're going to do you're going to have a long time
2022-03-23 09:47:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:47:07 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, fortunately, the mother is still the invention of the invention of the invention, and one part of the work that we're going to solve is that we had to use a unique result of all the problems that we had to be able to be able to be able to be able to be able to be able to be able to use, and see that if you're able to use the power of a rererestore, that if you're able to use the power of a reconstruct, if you're able to use the power of a restore, you're able to see that if you're able to see that if you're able to use the power of the reconstruct, you're able to use, you're able to use, or you're able to use, you're able to see that if you're able to use the power of a big, or you're able to use, or you're going to see that if you're going to use the power of a great, you're able to use the power of a
2022-03-23 09:47:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:47:07 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 5.566 | nll_loss 4.252 | ppl 19.05 | bleu 17.17 | wps 4467.7 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 17.17
2022-03-23 09:47:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 09:47:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:47:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 17.17) (writing took 1.8958002403378487 seconds)
2022-03-23 09:47:09 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 09:47:09 | INFO | train | epoch 015 | loss 5.905 | nll_loss 4.779 | ppl 27.46 | wps 42771.6 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.069 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1437
2022-03-23 09:47:09 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 09:47:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:47:26 | INFO | train_inner | epoch 016:     50 / 157 loss=5.886, nll_loss=4.753, ppl=26.96, wps=34010.9, ups=1.34, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.063, loss_scale=4, train_wall=31, gb_free=14.3, wall=1453
2022-03-23 09:47:57 | INFO | train_inner | epoch 016:    150 / 157 loss=5.599, nll_loss=4.42, ppl=21.41, wps=79418.3, ups=3.22, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=0.937, loss_scale=4, train_wall=31, gb_free=14.5, wall=1484
2022-03-23 09:47:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:48:03 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in clinic clinics.
2022-03-23 09:48:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:48:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know.
2022-03-23 09:48:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:48:11 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf.
2022-03-23 09:48:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:48:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where happy legs and pink.
2022-03-23 09:48:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:48:18 | INFO | fairseq.tasks.translation | example hypothesis: it's not just a few electrodes on his head and understand what all its thoughts are on the mind.
2022-03-23 09:48:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:48:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals of responsibility, the number of animals grew up, and this is a foundation for conservation.
2022-03-23 09:48:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:48:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic lines in the field, but the sullant doesn't move if you need your energy, and you need your energy.
2022-03-23 09:48:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from these reflection reflection, we can start with a traditional face that can start able to start able to start able to start able to start able to create the very big face of the face of the information, and the information that all the structure of the structure.
2022-03-23 09:48:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure me to be here for tedsters, "and then it's the best thing that we're talking about it as somebody said," when we're going to support them. "
2022-03-23 09:48:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:48:35 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention, and one part of the design that we're able to use the plane on our plane, and if we were a unique result that we had to solve a unique result that we had to solve all the problems that we had to use it, it would be connected to be able to be able to use it.
2022-03-23 09:48:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:48:35 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.469 | nll_loss 4.141 | ppl 17.64 | bleu 15.57 | wps 5060 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 17.17
2022-03-23 09:48:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 09:48:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:48:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:48:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 15.57) (writing took 0.7960971309803426 seconds)
2022-03-23 09:48:36 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 09:48:36 | INFO | train | epoch 016 | loss 5.665 | nll_loss 4.496 | ppl 22.57 | wps 45264.6 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.013 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1524
2022-03-23 09:48:37 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 09:48:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:49:06 | INFO | train_inner | epoch 017:     93 / 157 loss=5.522, nll_loss=4.329, ppl=20.1, wps=36372.5, ups=1.44, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.01, loss_scale=4, train_wall=31, gb_free=14.9, wall=1554
2022-03-23 09:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic clinic on the clinic.
2022-03-23 09:49:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:49:34 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you know here.
2022-03-23 09:49:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:49:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be able to create new golsticks, and the two new swiss are going to be transmitted.
2022-03-23 09:49:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:49:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food, where happy legs salt with salsales and fat.
2022-03-23 09:49:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:49:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all its thoughts are on the top.
2022-03-23 09:49:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:49:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamaa, as the responsibility for the wild, the number of animals grew up, and this is a foundation for conservation in namibia.
2022-03-23 09:49:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodl of magnetic lines, but the susulalalalalalalalty doesn't move, if you need your energy, and so that's how the sulle of the magnetic field of magnetic field is, and so forth.
2022-03-23 09:49:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face of a traditional face, we can start able to start with a traditional face of the face, and that's where the information is going through the whole structure, and all the structure, and all the structure of the structure, and the structure comes from the structure of this reflection, and the structure comes from a reflection of this reflection, and the structure,
2022-03-23 09:50:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting and measure me for tedwomen, and then we've started to be in tedsters, and then when we're going to say, "if you're going to say," in a table, "if you're going to be in a table, and then we're going to do it up with you're going to do it," and then we're going to do it for me, "well," you're going to do it, "you know," you know, you're going to have a long time, "you know," you're going to have a matter, you're going to be going to say, you're going to say, "you know, you're going to say," you know, "you know," you know, "you're going to be in this time," you know, "
2022-03-23 09:50:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:50:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the design, and a big part of the design work that we're in our airplane, that we've had to solve a result of that we had to solve the problems that we had to be connected to the ground -- all of the ground, and if you're able to use it, it, you're able to be able to be able to be able to be able to be able to be able to be able to be able to see that if you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:50:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:50:09 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.255 | nll_loss 3.868 | ppl 14.6 | bleu 19.07 | wps 4242 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 19.07
2022-03-23 09:50:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 09:50:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:50:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:50:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 19.07) (writing took 1.81282472377643 seconds)
2022-03-23 09:50:10 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 09:50:10 | INFO | train | epoch 017 | loss 5.495 | nll_loss 4.297 | ppl 19.65 | wps 41925.7 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 0.979 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 1618
2022-03-23 09:50:11 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 09:50:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:50:22 | INFO | train_inner | epoch 018:     36 / 157 loss=5.418, nll_loss=4.206, ppl=18.45, wps=33123.9, ups=1.31, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=0.961, loss_scale=4, train_wall=31, gb_free=14.3, wall=1630
2022-03-23 09:50:54 | INFO | train_inner | epoch 018:    136 / 157 loss=5.291, nll_loss=4.058, ppl=16.66, wps=79201.3, ups=3.19, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=0.893, loss_scale=4, train_wall=31, gb_free=14.1, wall=1661
2022-03-23 09:51:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:51:04 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic clinic.
2022-03-23 09:51:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:51:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:51:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:51:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks of dines that create two new pigs.
2022-03-23 09:51:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:51:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are being involved with salz and fat.
2022-03-23 09:51:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:51:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head, and understand exactly what all its thoughts are on the way.
2022-03-23 09:51:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:51:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the maibia, the responsibility of responsibility for the wild, grew up to the number of wild animals, and this is a foundation for the natural protection of conservation in namibia.
2022-03-23 09:51:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:51:28 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloose of magnetic field in the inner lines, but the susulalalan may not be able to move if you need energy, your energy, your energy, and so that's how the superconductor is.
2022-03-23 09:51:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:51:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial facial faces that can start with a traditional facial face of the face, and the shape of the face, and the information that has been able to fold it through the whole structure, which is to fold the whole structure.
2022-03-23 09:51:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure it interesting, for me here for tedwomen, is that "oh..." oh, when i'm talking about, "and then we've started talking to you," if you're talking about, "oh, you know, it's a silent issue for example, it's a long time," and then we've started to support for example, we've got a silent, "and then we've started to support for example," oh, "oh," oh, we've started to support for example, for example, for example, for example, it's a coordinarily for example, "oh, we've got a coordinarily, for example," oh, we're going to support for example, for example, "oh," oh, "oh," oh, we've started to support women
2022-03-23 09:51:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:51:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother's invention of invention, and a big part of the design work that we're using the plane, and it's a result that we had to solve the unique problems that we had to solve it in the ground -- it's all the way to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:51:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:51:40 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.035 | nll_loss 3.61 | ppl 12.21 | bleu 22.42 | wps 4575.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 22.42
2022-03-23 09:51:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 09:51:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:51:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 22.42) (writing took 1.7926488500088453 seconds)
2022-03-23 09:51:42 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 09:51:42 | INFO | train | epoch 018 | loss 5.294 | nll_loss 4.062 | ppl 16.7 | wps 43282.3 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 0.88 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 1709
2022-03-23 09:51:42 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 09:51:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:52:07 | INFO | train_inner | epoch 019:     79 / 157 loss=5.191, nll_loss=3.942, ppl=15.36, wps=34842.5, ups=1.36, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.848, loss_scale=4, train_wall=31, gb_free=14, wall=1735
2022-03-23 09:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:52:35 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 09:52:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:52:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:52:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:52:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldial dines of the two new new pigs.
2022-03-23 09:52:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:52:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are salt with salz and fat.
2022-03-23 09:52:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:52:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just making a couple of electrodes on his head and understand exactly what all its thoughts are on the way.
2022-03-23 09:52:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people like responsibility, the number of wild animals grew back again, and this is a foundation for conservation in namibia.
2022-03-23 09:52:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodough lines in the inside the inner, but the sususuicide doesn't move when they need energy and so forth.
2022-03-23 09:52:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:53:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial face, the big constrains of the face, and the basic shape of the information that we can take it through the entire reflection of this reflection, and the whole structure of this reflection of this reflection, and we can begin to fold the whole whole whole structure.
2022-03-23 09:53:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:53:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here, for me, is that, when we've been talking to you. "
2022-03-23 09:53:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:53:11 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of the design work that we're going to be able to be able to resolution in the aircraft, so that we had to solve the unique problems in the ground -- all the way that we had to resolution in the ground -- and a large part of the design system, if we're able to use the locked up with a refufufugegegegeous, or to be able to see that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:53:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:53:11 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.021 | nll_loss 3.601 | ppl 12.13 | bleu 22.07 | wps 4607.4 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 22.42
2022-03-23 09:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 09:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 19 @ 2978 updates, score 22.07) (writing took 0.8201006669551134 seconds)
2022-03-23 09:53:11 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 09:53:11 | INFO | train | epoch 019 | loss 5.126 | nll_loss 3.867 | ppl 14.59 | wps 43999.9 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 0.881 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 1799
2022-03-23 09:53:12 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 09:53:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:53:19 | INFO | train_inner | epoch 020:     22 / 157 loss=5.05, nll_loss=3.779, ppl=13.73, wps=34676, ups=1.4, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.853, loss_scale=4, train_wall=30, gb_free=14.7, wall=1806
2022-03-23 09:53:51 | INFO | train_inner | epoch 020:    122 / 157 loss=4.96, nll_loss=3.673, ppl=12.76, wps=81481.9, ups=3.15, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.721, loss_scale=4, train_wall=31, gb_free=13.6, wall=1838
2022-03-23 09:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 09:54:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:54:08 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you know.
2022-03-23 09:54:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks.
2022-03-23 09:54:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:54:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frog legs are served with salz and grappet.
2022-03-23 09:54:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:54:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all its thoughts are on the road.
2022-03-23 09:54:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:54:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, as people would have grown responsibility for the wild, the number of wild animals came back again, and that's a foundation of conservation.
2022-03-23 09:54:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:54:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic fields are caught in the inside the inside of the inner, but the susulalan may not be if they're moving, because their movements need their movements, and so the sulalarm of magnetic field.
2022-03-23 09:54:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this reflection, we can start with a traditional facial facial, the big constructions of the face and the basic shape of the face, and the basic shape of the information that comes from the entire portion of this reflection, the whole reflection of this reflection.
2022-03-23 09:54:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:54:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and measure it interesting, for me here at tedwomen is that... yes, when...... when the best tested, somebody said, "] ["] ["] ["] ["] [the men 'men who are doing it very interesting and measure it very interesting and measure it very interesting and measure it very interesting and measure it interesting and measure it interesting and measure it interesting, and measure it interesting, and measure it, if we've been supported for me here in a while we've been supported for me here for me here at tedwomen,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 09:54:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the design, and a big part of design work that we're in our airplane, was a result of it that we had to solve a unique problems that were connected to the ground -- all the mother of the invention of the invention of the invention of the invention of the invention, and a large part of the design of the design, and a large part of the design of the design work, and a huge part of the airplane, and a large part of the design work that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 09:54:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:54:43 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.932 | nll_loss 3.485 | ppl 11.2 | bleu 22.91 | wps 4303.1 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 22.91
2022-03-23 09:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 09:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:54:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 22.91) (writing took 1.7505555050447583 seconds)
2022-03-23 09:54:44 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 09:54:44 | INFO | train | epoch 020 | loss 4.966 | nll_loss 3.681 | ppl 12.83 | wps 42421.6 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.802 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1892
2022-03-23 09:54:45 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 09:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:55:06 | INFO | train_inner | epoch 021:     65 / 157 loss=4.881, nll_loss=3.584, ppl=11.99, wps=33175.4, ups=1.33, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.869, loss_scale=4, train_wall=30, gb_free=13.9, wall=1913
2022-03-23 09:55:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:55:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:55:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:55:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 09:55:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:55:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create two new pigments.
2022-03-23 09:55:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:55:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and ppet.
2022-03-23 09:55:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all of his thoughts are on the road.
2022-03-23 09:55:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:55:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the case, as people took responsibility for the wild, the number of wild animals grew back again, and this is a foundation for conservation in namibia.
2022-03-23 09:55:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:56:03 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodle of the magnetic rock lines start inside the inner, but the sulant eggs don't like it, if they're moving, because their movements need to move, and so the superconducting disorder.
2022-03-23 09:56:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:56:07 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial, the big constructions of the face and the basic shape, and then we can fold it through it, and through it, which is the whole structure and put it into it.
2022-03-23 09:56:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:56:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measuring it to me here at tedwomen, is that... well, when you were going to be able to be the best, when someone said, "you know, if you're going to be on a table and you're going to tell me," if we're going to support you. "
2022-03-23 09:56:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:56:14 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of the design work that we're working on on our plane, and it was a result of it that we had to solve the unique problems that were connected to the ground -- everything from a continent, and it's going to be able to be able to make a refrigergered system, and it allows us to be able to see that, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 09:56:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:56:14 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.72 | nll_loss 3.252 | ppl 9.53 | bleu 25.92 | wps 4574.9 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 25.92
2022-03-23 09:56:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 09:56:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:56:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 09:56:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 25.92) (writing took 1.8816453707404435 seconds)
2022-03-23 09:56:16 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 09:56:16 | INFO | train | epoch 021 | loss 4.853 | nll_loss 3.549 | ppl 11.71 | wps 43054 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.778 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 1984
2022-03-23 09:56:17 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 09:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:56:19 | INFO | train_inner | epoch 022:      8 / 157 loss=4.864, nll_loss=3.562, ppl=11.81, wps=33615.9, ups=1.36, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.779, loss_scale=4, train_wall=31, gb_free=13.9, wall=1987
2022-03-23 09:56:50 | INFO | train_inner | epoch 022:    108 / 157 loss=4.767, nll_loss=3.452, ppl=10.94, wps=79313.1, ups=3.22, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.784, loss_scale=4, train_wall=31, gb_free=13.8, wall=2018
2022-03-23 09:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:57:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:57:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:57:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 09:57:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:57:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 09:57:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:57:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz.
2022-03-23 09:57:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand what all his thoughts are on the track.
2022-03-23 09:57:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation for the people's responsibility for the wild animals, and this is a foundation for conservation.
2022-03-23 09:57:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:57:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bber of magnetic fields are caught inside, but the supralter may not like if they're moving, because they need their movements, and so the suired disorder.
2022-03-23 09:57:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:57:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which pulls the big constructions of the face, and the basic shape of the face.
2022-03-23 09:57:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's highly interesting and measured, for me here at tedwomen, is that... "well," and then we've been supported to you. "
2022-03-23 09:57:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:57:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're on on our airplane, was a result of refrightening, and if you're able to solve the unique problems that were connected to the ground.
2022-03-23 09:57:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:57:41 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.722 | nll_loss 3.248 | ppl 9.5 | bleu 23.69 | wps 5177.6 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 25.92
2022-03-23 09:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 09:57:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 23.69) (writing took 0.7702845870517194 seconds)
2022-03-23 09:57:42 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 09:57:42 | INFO | train | epoch 022 | loss 4.739 | nll_loss 3.42 | ppl 10.7 | wps 45959.6 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.747 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 2070
2022-03-23 09:57:42 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 09:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:57:59 | INFO | train_inner | epoch 023:     51 / 157 loss=4.685, nll_loss=3.356, ppl=10.24, wps=37310.5, ups=1.46, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.653, loss_scale=4, train_wall=31, gb_free=13.8, wall=2086
2022-03-23 09:58:30 | INFO | train_inner | epoch 023:    151 / 157 loss=4.578, nll_loss=3.238, ppl=9.43, wps=81587.3, ups=3.21, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.713, loss_scale=4, train_wall=31, gb_free=13.8, wall=2117
2022-03-23 09:58:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 09:58:35 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 09:58:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 09:58:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 09:58:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 09:58:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden lolocks that create two new pigs.
2022-03-23 09:58:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and ppet suitcase.
2022-03-23 09:58:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 09:58:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation for conservation in namibia.
2022-03-23 09:58:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 09:58:59 | INFO | fairseq.tasks.translation | example hypothesis: first, there are some legs of magnetic field lines in the inner inner, but the superconductor may not be able to move when they're moving, because their movements need their energy, and so the supralty disorder.
2022-03-23 09:58:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 09:59:04 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, the big constructions of the face, and the basic basic shape of the face and the basic basic constructions of the basic information, and through the basic information that gives the whole portion of the whole portion and all the whole portion of the whole portion of the whole portion of it.
2022-03-23 09:59:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was very interesting and measured to me in tedwomen is that we've been supporting -- yeah, at the best dinner dinner, when somebody said, "turn you to the men on a dtable," and they say, "if you start to support them, it starts to be a lot of time, we've already started to support you."
2022-03-23 09:59:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design system that we're in our plane, was a result that we had to solve the unique problems that we had to be connected to the unique problems that we had to operate on the ground -- everything from a continuous variation, which is something that we're able to do with a refrigeration, which is that we can use to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 09:59:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 09:59:12 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.665 | nll_loss 3.184 | ppl 9.09 | bleu 25.64 | wps 4522.5 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.92
2022-03-23 09:59:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 09:59:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:59:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 09:59:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 23 @ 3606 updates, score 25.64) (writing took 0.787280754186213 seconds)
2022-03-23 09:59:12 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 09:59:12 | INFO | train | epoch 023 | loss 4.615 | nll_loss 3.279 | ppl 9.7 | wps 43758.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.692 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2160
2022-03-23 09:59:13 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 09:59:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 09:59:42 | INFO | train_inner | epoch 024:     94 / 157 loss=4.567, nll_loss=3.224, ppl=9.34, wps=34361.4, ups=1.38, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.701, loss_scale=4, train_wall=31, gb_free=13.8, wall=2190
2022-03-23 10:00:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:00:06 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 10:00:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:00:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:00:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create the two new pigs.
2022-03-23 10:00:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:00:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:00:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:00:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:00:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:00:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the maggots like the people of responsibility for wildlife, grew up the number of wild animals, and that's a foundation for conservation in namibia.
2022-03-23 10:00:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:00:30 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field lines are caught inside, but the supraleggs don't like it, if they're moving, because they need their energy, and so the superconducting disorders.
2022-03-23 10:00:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constructions of the face and the basic shape and restoring it through the theast information that pulls the whole portion and a fold.
2022-03-23 10:00:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:00:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen is that... well, when they were posted, "] ["] ["] ["]] ["]]]] ["]]] don't help you on the men on a table and tell you that if the revolution starts to help you. "
2022-03-23 10:00:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:00:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system to a refrightening system to the air, or to see if we're able to use the aircraft.
2022-03-23 10:00:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:00:40 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.495 | nll_loss 2.983 | ppl 7.91 | bleu 27.55 | wps 4765.7 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 27.55
2022-03-23 10:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 10:00:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:00:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 27.55) (writing took 1.7961702798493207 seconds)
2022-03-23 10:00:42 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 10:00:42 | INFO | train | epoch 024 | loss 4.536 | nll_loss 3.187 | ppl 9.11 | wps 44028.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.661 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2250
2022-03-23 10:00:42 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 10:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:00:54 | INFO | train_inner | epoch 025:     37 / 157 loss=4.447, nll_loss=3.086, ppl=8.49, wps=35453.7, ups=1.39, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.611, loss_scale=4, train_wall=31, gb_free=14, wall=2262
2022-03-23 10:01:25 | INFO | train_inner | epoch 025:    137 / 157 loss=4.488, nll_loss=3.132, ppl=8.77, wps=80220.6, ups=3.2, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.679, loss_scale=4, train_wall=31, gb_free=13.9, wall=2293
2022-03-23 10:01:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:01:35 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 10:01:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:01:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:01:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:01:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golf locks that are going to cross two new pigs.
2022-03-23 10:01:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:01:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and phits.
2022-03-23 10:01:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:01:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:01:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildanimals grew again, and this is a foundation for conservation in namibia.
2022-03-23 10:01:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:01:58 | INFO | fairseq.tasks.translation | example hypothesis: first is some bundle of magnetic field lines in the inner inner, but the superconductor doesn't like it, if you're moving, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:01:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:02:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which is the big constructions of the face, and the basic shape, and then put it through the one of the information that pulls the whole porter structure and all the folds.
2022-03-23 10:02:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured for me here at tedwomen is that, "well, when someone said," turn to the men on a table and tell you, "if the revolution starts to support you on your desk and tell you," if the revolution starts you. "
2022-03-23 10:02:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're at our plane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variable system and a refrigeration system, and a refrigerator system that we're going to refrigering a refrigerator to a refrigerator, or to a refrigerator, or to a refrigerator, or to a refrigerator, or to a refrigerator, or to a refrigerator, or to the refrigerator, if we're either see the refrigerator, if we're going to the refrigerator, if we're going to the refrigerator, if we're going to the refrigerator, or the air system, it's not going to the refrigerator, if we're going to the refrigerator, it's going to the refrigerator, it
2022-03-23 10:02:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:02:09 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.503 | nll_loss 3.003 | ppl 8.02 | bleu 26.83 | wps 4846.5 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 27.55
2022-03-23 10:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 10:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 26.83) (writing took 0.8481798451393843 seconds)
2022-03-23 10:02:10 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 10:02:10 | INFO | train | epoch 025 | loss 4.453 | nll_loss 3.093 | ppl 8.53 | wps 44948.6 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.662 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2338
2022-03-23 10:02:10 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 10:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:02:36 | INFO | train_inner | epoch 026:     80 / 157 loss=4.371, nll_loss=3, ppl=8, wps=36239.9, ups=1.42, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.621, loss_scale=4, train_wall=31, gb_free=14, wall=2363
2022-03-23 10:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:03:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep sheep in the clinic.
2022-03-23 10:03:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:03:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-23 10:03:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:03:11 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are two new pigs.
2022-03-23 10:03:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:03:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:03:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:03:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:03:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:03:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people's responsibility for wildlife, the number of animals grew up again, and this is a foundation for conservation in namibia.
2022-03-23 10:03:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:03:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloody of magnetic field lines are caught inside, but the superconductor doesn't like to move when they're moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:03:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:03:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflection that comes from this reflection, we can start with a traditional face, which is the big constructions of the face and restoring the basic shape, and by the theast information that pulls all the porn structure and all the fits.
2022-03-23 10:03:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate to be here for me at tedwomen is that -- well, when dinner was best summarized when someone said, "turn you to the men on a table and tell you," if the revolution starts to support you, "the truth is that we've already been supporting you for you for a long time, we've already been supporting you that time," well, for example, for example, we've been supporting you're already supported to you, "carbonnie carria long time."
2022-03-23 10:03:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:03:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of the design work that we're at our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use in a refrigerator to become a refrigerator, or to be able to be able to be able to be able to see, if we're either be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-23 10:03:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:03:38 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.35 | nll_loss 2.825 | ppl 7.09 | bleu 29.37 | wps 4698.5 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.37
2022-03-23 10:03:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 10:03:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:03:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.37) (writing took 1.8076563430950046 seconds)
2022-03-23 10:03:40 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 10:03:40 | INFO | train | epoch 026 | loss 4.36 | nll_loss 2.988 | ppl 7.93 | wps 43895 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.61 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 2428
2022-03-23 10:03:40 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 10:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:03:48 | INFO | train_inner | epoch 027:     23 / 157 loss=4.311, nll_loss=2.933, ppl=7.64, wps=34520.3, ups=1.38, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.609, loss_scale=4, train_wall=30, gb_free=14.8, wall=2436
2022-03-23 10:04:19 | INFO | train_inner | epoch 027:    123 / 157 loss=4.324, nll_loss=2.946, ppl=7.71, wps=80204.8, ups=3.2, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.6, loss_scale=4, train_wall=31, gb_free=13.6, wall=2467
2022-03-23 10:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:04:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppets in the clinic.
2022-03-23 10:04:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:04:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 10:04:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are becoming new goldilocks that produce two new pigs.
2022-03-23 10:04:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:04:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:04:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:04:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:04:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:04:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wild animals grew back. and this is a foundation for conservation in namibia.
2022-03-23 10:04:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:04:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are captured inside, but the supraleiter doesn't like to move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:04:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:05:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection of reflection, we can start with a traditional facial can that restores the large constructions of the face and the basic shape, and through the theast information that pulls all the ports structure and all the fits.
2022-03-23 10:05:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on your desk and tell you," if the revolution starts to support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 10:05:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane at the stumest toes was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous refrigerator system, and we're going to see that it allows us to refrigerators and refrigerators in the ground, or if we're going to see the propellism, or when we're either going to see the refrigerators of a refrigerator, or if we're going to see the aircraft.
2022-03-23 10:05:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:05:07 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.317 | nll_loss 2.796 | ppl 6.95 | bleu 29.31 | wps 4861.6 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.37
2022-03-23 10:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 10:05:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:05:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 29.31) (writing took 0.7798251262865961 seconds)
2022-03-23 10:05:08 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 10:05:08 | INFO | train | epoch 027 | loss 4.291 | nll_loss 2.91 | ppl 7.51 | wps 44881.6 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.595 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 2516
2022-03-23 10:05:08 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 10:05:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:05:29 | INFO | train_inner | epoch 028:     66 / 157 loss=4.238, nll_loss=2.849, ppl=7.2, wps=35622.7, ups=1.43, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.585, loss_scale=4, train_wall=31, gb_free=14.7, wall=2537
2022-03-23 10:05:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:06:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters up in the clinic.
2022-03-23 10:06:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:06:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of here.
2022-03-23 10:06:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:06:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 10:06:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:06:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:06:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:06:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildanimals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:06:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it, if they move, because their movements use their energy, and so the superconducting disorder.
2022-03-23 10:06:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:06:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the big constructures of the face and restoring the basic shape, and through the one of the one that pulls the whole porter structure and all the fits.
2022-03-23 10:06:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's going to be highly interesting and appropriate to me here at tedwomen is that -- well, in the strictly dinner, it was best summarized when someone said, "turn you to men on your table and say, if the revolution starts to support you." the truth is that we have supported you, you know, women have already been supporting you at this long time with silks. "& lt; em & gt; & lt;
2022-03-23 10:06:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane are the stumest, was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variable and a cooling system that allows us to be able to use a refrigerator in the aircraft, or to be able to use a refrigerator, if you can see the propelled by a mechanism, if you can see the earth, the earth is either be able to use a trajectory of a flying device that is available to become a refrigerator of a flying device that the earth.
2022-03-23 10:06:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:06:36 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.255 | nll_loss 2.72 | ppl 6.59 | bleu 30.49 | wps 4722.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.49
2022-03-23 10:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 10:06:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:06:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:06:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.49) (writing took 1.8086346290074289 seconds)
2022-03-23 10:06:38 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 10:06:38 | INFO | train | epoch 028 | loss 4.234 | nll_loss 2.844 | ppl 7.18 | wps 43755.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.606 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2606
2022-03-23 10:06:38 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 10:06:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:06:41 | INFO | train_inner | epoch 029:      9 / 157 loss=4.257, nll_loss=2.871, ppl=7.32, wps=34833.2, ups=1.38, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.643, loss_scale=4, train_wall=31, gb_free=13.6, wall=2609
2022-03-23 10:07:13 | INFO | train_inner | epoch 029:    109 / 157 loss=4.163, nll_loss=2.764, ppl=6.79, wps=80240.8, ups=3.19, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.564, loss_scale=4, train_wall=31, gb_free=13.6, wall=2640
2022-03-23 10:07:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:07:31 | INFO | fairseq.tasks.translation | example hypothesis: we put this piepter in the clinic.
2022-03-23 10:07:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:07:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 10:07:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:07:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to transcend two new pigs.
2022-03-23 10:07:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:07:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 10:07:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:07:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all your thoughts are on the track.
2022-03-23 10:07:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:07:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people responsibility for wildlife, the number of wildanimals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:07:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:07:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:07:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:07:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial reflection that gives the big constructions of the face and the basic shape, and reconstructing it through the one of the information that refers all the por-structure and all the fits.
2022-03-23 10:07:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:08:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen is that... tum, when dinner became the best summarized when someone said, "turn you to men on your table and tell them," if the revolution starts to support you, then we support you. "the truth is that we've been supporting you in this topic for a long time."
2022-03-23 10:08:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane are the stumest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable and a cooling system that allows us to use a vehicle in the air, or if you can see the propelled, or if you can use a mechanism, or if you can use a mechanism, or if you can use a mechanism, it, it's either, it's a mechanism, it would be the same, it would allow us to use it, or if you can use it, it, it, it, it, it would be the air, or if you can use a mechanism, or if you can use a mechanism, if you can use a mechanism, if you can use it, it, it, it, it's either, it, it, it, it, it, it will use a mechanism
2022-03-23 10:08:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:08:06 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.237 | nll_loss 2.701 | ppl 6.5 | bleu 30.72 | wps 4746.8 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.72
2022-03-23 10:08:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 10:08:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:08:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:08:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.72) (writing took 1.7826466686092317 seconds)
2022-03-23 10:08:08 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 10:08:08 | INFO | train | epoch 029 | loss 4.158 | nll_loss 2.758 | ppl 6.77 | wps 44090 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.569 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2695
2022-03-23 10:08:08 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 10:08:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:08:25 | INFO | train_inner | epoch 030:     52 / 157 loss=4.143, nll_loss=2.741, ppl=6.69, wps=34876.9, ups=1.39, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.577, loss_scale=4, train_wall=31, gb_free=13.9, wall=2712
2022-03-23 10:08:56 | INFO | train_inner | epoch 030:    152 / 157 loss=4.066, nll_loss=2.655, ppl=6.3, wps=81126.2, ups=3.2, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.485, loss_scale=4, train_wall=31, gb_free=14.7, wall=2743
2022-03-23 10:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:09:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:09:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:09:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 10:09:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:09:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will generate two new vibrations.
2022-03-23 10:09:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:09:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where happy legs are served with salt and pepper.
2022-03-23 10:09:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:09:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 10:09:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:09:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the name of how people took responsibility to the wild, the number of wild animals grew again, and this has become a basis for conservation in namibia.
2022-03-23 10:09:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:09:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:09:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:09:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which gives the big contures of the face and the basic shape, and then then refuse it through the one of the one information that pulls all the por-structure and all the fits.
2022-03-23 10:09:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn you to the men on your table and say," if the revolution starts to support you. "
2022-03-23 10:09:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:09:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use in the aircraft until a particular basis that we had to solve the unique problems that were connected to the earth, if you can see it, or if you can use the propelled in the same way, or if you can use the propeller, or if you can use it to the land in the same way, or if you can use it, or if you can use it to the earth to the air, or if you can use it, or if you can use it, you can use it, until you can use it to the air, until you can use it, or if you can use it, you can use a very specific, until you can use it to the earth, you can use it, you can use it to the
2022-03-23 10:09:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:09:36 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.195 | nll_loss 2.651 | ppl 6.28 | bleu 30.94 | wps 4719.9 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.94
2022-03-23 10:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 10:09:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:09:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:09:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.94) (writing took 1.8099116128869355 seconds)
2022-03-23 10:09:38 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 10:09:38 | INFO | train | epoch 030 | loss 4.088 | nll_loss 2.679 | ppl 6.4 | wps 43895.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.53 | loss_scale 4 | train_wall 48 | gb_free 13.4 | wall 2785
2022-03-23 10:09:38 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 10:09:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:10:08 | INFO | train_inner | epoch 031:     95 / 157 loss=4.07, nll_loss=2.659, ppl=6.32, wps=35191.1, ups=1.38, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.565, loss_scale=4, train_wall=31, gb_free=13.6, wall=2816
2022-03-23 10:10:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:10:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:10:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:10:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:10:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:10:39 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will be transferred to two new pigs.
2022-03-23 10:10:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:10:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salt and pills.
2022-03-23 10:10:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:10:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:10:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:10:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildanimals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:10:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:10:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor may not be able to move, because your movements use energy, and so the superconducting disorder.
2022-03-23 10:10:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:10:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which gives the big constructions of the face and the basic shape, and restoring it through the one of the information that refers the entire por-structure and all the fits.
2022-03-23 10:10:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that -- tja, when dinner was best summarized, when someone said, "turn you to the men on your table and say," if the revolution starts, we support you. '"'" the truth is that we've been supporting you for this long time. "
2022-03-23 10:11:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:11:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our plane was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variables and a refrigeration system that allows us to use a building in the air, or a particular car traffic, or if you're in the air, or whatever you're going to do it is, you have to do it, you have to do it, you have to do it, you can use it, you can use it, you can use it, you can use it, you can use the same as well, you can use it, you can use it, you can't see the same as you can use it, you can use it, you can use it, you can use it, you can use it, you can use it, you can use it, until you can use it, you can use it, you can use it, you can use it, or you can
2022-03-23 10:11:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:11:06 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.148 | nll_loss 2.604 | ppl 6.08 | bleu 31.59 | wps 4783.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.59
2022-03-23 10:11:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 10:11:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:11:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:11:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.59) (writing took 1.8915327992290258 seconds)
2022-03-23 10:11:08 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 10:11:08 | INFO | train | epoch 031 | loss 4.053 | nll_loss 2.64 | ppl 6.24 | wps 43898.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.544 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 2875
2022-03-23 10:11:08 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 10:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:11:20 | INFO | train_inner | epoch 032:     38 / 157 loss=3.982, nll_loss=2.56, ppl=5.9, wps=34637.5, ups=1.39, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.494, loss_scale=4, train_wall=30, gb_free=14.3, wall=2888
2022-03-23 10:11:52 | INFO | train_inner | epoch 032:    138 / 157 loss=4.006, nll_loss=2.587, ppl=6.01, wps=80372.5, ups=3.18, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.553, loss_scale=4, train_wall=31, gb_free=14.4, wall=2919
2022-03-23 10:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:12:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:12:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:12:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably know most here.
2022-03-23 10:12:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new pigs.
2022-03-23 10:12:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:12:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:12:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:12:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:12:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew back, and this is a basis for conservation in namibia.
2022-03-23 10:12:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and the superconducting disorder.
2022-03-23 10:12:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:12:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which gives the big contextures of the face and the basic shape, and reconstructions it through the one that refers the entire por-structure and all the fits.
2022-03-23 10:12:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and appropriate to be here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn you to your desk and tell you, 'when the revolution begins, we support you.'"
2022-03-23 10:12:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to it -- everything, from a continuous variables and a refrigeration system, that allows us to use an aircraft in the air, to go to a stop, to a specific transport, to the earth, to the casual traffic, or to a specially, if you look at the earth, to the casual passenger, if you look at the land, you have to the air, you have to the earth, you can see the same mechanism, you can see the same mechanism, you can see the earth, if you can see the same mechanism, if you see the air, you can see the earth, you can see the air, you can see, you see, you see the same to the earth, if you see the united states, you see that you see the casually variables, the air,
2022-03-23 10:12:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:12:35 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.14 | nll_loss 2.598 | ppl 6.05 | bleu 31.19 | wps 4804.6 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.59
2022-03-23 10:12:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 10:12:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 31.19) (writing took 0.7798165651038289 seconds)
2022-03-23 10:12:36 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 10:12:36 | INFO | train | epoch 032 | loss 3.989 | nll_loss 2.567 | ppl 5.93 | wps 44693.8 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.531 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 2964
2022-03-23 10:12:36 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 10:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:13:02 | INFO | train_inner | epoch 033:     81 / 157 loss=3.93, nll_loss=2.502, ppl=5.66, wps=35647.2, ups=1.42, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.545, loss_scale=4, train_wall=30, gb_free=14, wall=2990
2022-03-23 10:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:13:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:13:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:13:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 10:13:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that are going to transcend two new pigs.
2022-03-23 10:13:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:13:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 10:13:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 10:13:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people adopted responsibility for wildlife, the number of wild animals grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:13:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:13:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial bar that gives the big contextures of the face and the basic shape, and restores it through the dietrous information that pulls the whole por-structure and all the fits.
2022-03-23 10:13:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:14:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... tja, when dinner was best summarized, when someone said, "turn you to the men on your table and say," if the revolution starts to support you, "the truth is that we have been supporting you, we've been supporting you for a long time," silly, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] don
2022-03-23 10:14:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on our airplane was a result that we had to solve the unique problems that were connected to it, to operate on the ground -- everything, from a continuous variable and a cooling system, that allows us to use a machine in the aircraft to stop, to be able to be able to be able to be able to be able to be able to see, or to be able to be able to be able to be able to be able to see the ground, if we're going to be able to see the aircraft, or to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the land,
2022-03-23 10:14:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:14:05 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.1 | nll_loss 2.546 | ppl 5.84 | bleu 32.55 | wps 4602.7 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.55
2022-03-23 10:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 10:14:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:14:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.55) (writing took 2.0287711708806455 seconds)
2022-03-23 10:14:07 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 10:14:07 | INFO | train | epoch 033 | loss 3.955 | nll_loss 2.529 | ppl 5.77 | wps 43258 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.526 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 3055
2022-03-23 10:14:08 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 10:14:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:14:16 | INFO | train_inner | epoch 034:     24 / 157 loss=3.97, nll_loss=2.545, ppl=5.84, wps=34202.6, ups=1.36, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.507, loss_scale=4, train_wall=31, gb_free=13.8, wall=3063
2022-03-23 10:14:47 | INFO | train_inner | epoch 034:    124 / 157 loss=3.884, nll_loss=2.449, ppl=5.46, wps=80021, ups=3.18, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.508, loss_scale=4, train_wall=31, gb_free=13.7, wall=3095
2022-03-23 10:14:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:15:01 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepters in the clinic.
2022-03-23 10:15:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:15:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here.
2022-03-23 10:15:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:15:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:15:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:15:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-23 10:15:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:15:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:15:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew again. and that's a basis for conservation in namibia.
2022-03-23 10:15:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:15:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements are using energy, and the superconducting disorder.
2022-03-23 10:15:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bar that gives the big contextures of the face and refuse it through the one that refers the entire porter structure and all the fits.
2022-03-23 10:15:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, in the strictly dinner, it was best summarized when someone said, "turn you to your men on your table and tell you, 'when the revolution begins, we support you.'" the truth, women, we've already supported you for this long time. "
2022-03-23 10:15:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:15:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're most stumbling at our plane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable operator and a cooling system with a refrigeration system that allows us to use an aircraft in the traffic, to a specially, to the passport, if you can see the most promoting, the civic of a mechanism, which is either when you see the propeller in the air, when you see the ground, the propeller, when you see the propeller, the constitution.
2022-03-23 10:15:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:15:35 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.103 | nll_loss 2.557 | ppl 5.89 | bleu 32.49 | wps 4727.1 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.55
2022-03-23 10:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 10:15:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:15:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.49) (writing took 0.8222862128168344 seconds)
2022-03-23 10:15:36 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 10:15:36 | INFO | train | epoch 034 | loss 3.903 | nll_loss 2.47 | ppl 5.54 | wps 44350 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.518 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 3144
2022-03-23 10:15:37 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 10:15:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:15:58 | INFO | train_inner | epoch 035:     67 / 157 loss=3.909, nll_loss=2.476, ppl=5.56, wps=35467.6, ups=1.41, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.525, loss_scale=4, train_wall=30, gb_free=14.7, wall=3166
2022-03-23 10:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:16:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:16:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 10:16:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new pigs.
2022-03-23 10:16:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:16:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:16:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:16:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:16:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial view that gives the big contextures of the face and the basic shape, and then you add it through that one information that pulls all the por-structure and all the fits.
2022-03-23 10:16:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:17:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to be here at tedwomen is that... tyes, when dinner was best summarized, when someone said, "turn you to your table and say," if the revolution starts to support you, "the truth, women is that we've already been supporting you for this long time," silks "and" yields "down the future.
2022-03-23 10:17:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:17:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, need to be the mother of invention, and a large part of the design work that we're on our airplane is the most stumbling result that we had to solve the unique problems that were connected to surgery on the ground -- everything, from a continuous variable and a refrigerator system with fluid that allows us to use a machine in the aircraft to the traffic, or if you can see the propelled, the land in the same way that we can see it as a promoting mechanism, the land as you can see it, and you can see it's made up to the land in the same way that you can see it, and you can see it, if you can see it's made it, by a continuously variables us to use it, by a continuously variable way that you can use it to use it to use it, by a continuously variable way that you can use it to use it to use it to use it to use it to use it,
2022-03-23 10:17:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:17:04 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.06 | nll_loss 2.506 | ppl 5.68 | bleu 32.28 | wps 4794 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.55
2022-03-23 10:17:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 10:17:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:17:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 32.28) (writing took 0.8178632161580026 seconds)
2022-03-23 10:17:05 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 10:17:05 | INFO | train | epoch 035 | loss 3.859 | nll_loss 2.42 | ppl 5.35 | wps 44755.9 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.49 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 3232
2022-03-23 10:17:05 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 10:17:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:17:08 | INFO | train_inner | epoch 036:     10 / 157 loss=3.839, nll_loss=2.399, ppl=5.27, wps=35405, ups=1.42, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.468, loss_scale=4, train_wall=31, gb_free=14.7, wall=3236
2022-03-23 10:17:40 | INFO | train_inner | epoch 036:    110 / 157 loss=3.814, nll_loss=2.369, ppl=5.16, wps=79883, ups=3.16, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.492, loss_scale=4, train_wall=31, gb_free=14.7, wall=3268
2022-03-23 10:17:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:17:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers up in the clinic.
2022-03-23 10:17:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:18:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 10:18:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks signs that will transcend two new pigs.
2022-03-23 10:18:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:18:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:18:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:18:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:18:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:18:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 10:18:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:18:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements use energy, and that's how the superconductor disorder is.
2022-03-23 10:18:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:18:27 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form, and the thief information that refers the entire porter structure and all the faters.
2022-03-23 10:18:27 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:18:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and interesting and appropriate for me here at tedwomen is that... tja, in the strict dinner, it was best summarized when someone said, "turn to the men on your table and tell them, 'if the revolution starts, we will support you.'" 'the truth, love, is that we've already been supporting you for a long time. "silly, and then we're going to downharbor harbor, and then we're going to downharbor harbor harbor de the dear, and then we're going to downharbor harbor hunter harbor harbor harbor harbor de the dear future, and then we're going to download the men, and then we're going to downstream, and tell you
2022-03-23 10:18:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:18:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're on on our plane are stumbling, was a result that we had to solve the unique problems that were connected to operating it -- everything, from a continuous variable, and a refrigerator system of liquid, that allows us to use an aircraft, or to move the propellism, or to be able to get rid of the earth, which is either, which is, which is what we had to do, which is to make it happen to be able to make it happen to make it happen to make it happen to make it happen to make it happen to make it happen to make it happen to make it happen to make it happen to make it happen to make it happen to make it happen to be able to be able to be able to make it happen to make it happen to be able to make it happen to make it happen to be able to make it happen, and make it happen to be able to
2022-03-23 10:18:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:18:34 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.043 | nll_loss 2.496 | ppl 5.64 | bleu 32.68 | wps 4621 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.68
2022-03-23 10:18:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 10:18:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:18:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 36 @ 5647 updates, score 32.68) (writing took 1.8553755092434585 seconds)
2022-03-23 10:18:35 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 10:18:35 | INFO | train | epoch 036 | loss 3.825 | nll_loss 2.382 | ppl 5.21 | wps 43461 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.502 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 3323
2022-03-23 10:18:36 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 10:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:18:53 | INFO | train_inner | epoch 037:     53 / 157 loss=3.78, nll_loss=2.331, ppl=5.03, wps=35019.9, ups=1.37, wpb=25515.8, bsz=1098.2, num_updates=5700, lr=0.000418854, gnorm=0.501, loss_scale=4, train_wall=30, gb_free=14.7, wall=3340
2022-03-23 10:19:24 | INFO | train_inner | epoch 037:    153 / 157 loss=3.847, nll_loss=2.406, ppl=5.3, wps=79486.2, ups=3.2, wpb=24809.7, bsz=898.1, num_updates=5800, lr=0.000415227, gnorm=0.497, loss_scale=4, train_wall=31, gb_free=13.5, wall=3372
2022-03-23 10:19:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:19:29 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:19:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:19:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 10:19:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:19:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:19:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:19:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:19:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:19:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:19:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife was growing again, and this is a basis for conservation conservation in namibia.
2022-03-23 10:19:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:19:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if you move, because your movements are using energy, and that's how the superconducting disorder is.
2022-03-23 10:19:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big constraints of the face and restore it through the thief information that refers all the pores structure and all the fits.
2022-03-23 10:19:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen, is that -- well, in the most strictly dinner, when someone said, "turn you to the men on your table and say," if the revolution starts, we'll support you. '"the truth, love is that we've already been supporting you with this topic for a long time."
2022-03-23 10:20:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on our plane are the proud toes, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable drift and a cooling system of fluid that allows us to use a flying machine in the aircraft on the road to a specially, to a specially, or to get rid of the propelled mechanism, to the ground, if you're in the same way that you're in a state of a constitute mechanical space.
2022-03-23 10:20:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:20:04 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.016 | nll_loss 2.462 | ppl 5.51 | bleu 33.22 | wps 4727.5 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 33.22
2022-03-23 10:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-23 10:20:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:20:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 37 @ 5804 updates, score 33.22) (writing took 1.817174076102674 seconds)
2022-03-23 10:20:05 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 10:20:05 | INFO | train | epoch 037 | loss 3.795 | nll_loss 2.347 | ppl 5.09 | wps 43859.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.487 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 3413
2022-03-23 10:20:06 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 10:20:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:20:36 | INFO | train_inner | epoch 038:     96 / 157 loss=3.767, nll_loss=2.315, ppl=4.98, wps=34140.1, ups=1.39, wpb=24614.8, bsz=1007.2, num_updates=5900, lr=0.000411693, gnorm=0.485, loss_scale=4, train_wall=31, gb_free=14.3, wall=3444
2022-03-23 10:20:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:20:59 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppets up in the clinic.
2022-03-23 10:20:59 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:21:03 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 10:21:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:21:07 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:21:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:21:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:21:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:21:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:21:19 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:21:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:21:23 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:21:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that will restore the big contures of the face and the basic form, and then add it through the thief of information that refers the whole por-structure and all the fine.
2022-03-23 10:21:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, the best time when someone said, "turn to your table and say," if the revolution begins, we support you. "the truth is that we've already been supporting you with this theme for a long time.
2022-03-23 10:21:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:21:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on on on our airplane are the stumbling toes, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a cooling system with fluid that allows us to use aircraft in our aircraft in the interactions until we had to use a special transport, or a particular output in a particular way that would be able way to deal with a promoting device that would be used to be driven by a promoting device that would be driven by a promoting device that would be driven by a promoting machine to a refrigeration to a refrigeration to a refrigeration of a refrigeration, until you can see the ground, or a refrigeration of a refrigeration of a refrigeration, until you can see everything that allows us to see the ground
2022-03-23 10:21:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:21:33 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 4.024 | nll_loss 2.464 | ppl 5.52 | bleu 32.44 | wps 4841.1 | wpb 17862.2 | bsz 728.3 | num_updates 5961 | best_bleu 33.22
2022-03-23 10:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5961 updates
2022-03-23 10:21:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 38 @ 5961 updates, score 32.44) (writing took 0.8210732252337039 seconds)
2022-03-23 10:21:34 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 10:21:34 | INFO | train | epoch 038 | loss 3.765 | nll_loss 2.314 | ppl 4.97 | wps 44576.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.491 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 3502
2022-03-23 10:21:34 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 10:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:21:47 | INFO | train_inner | epoch 039:     39 / 157 loss=3.7, nll_loss=2.24, ppl=4.73, wps=36760.8, ups=1.41, wpb=26087.3, bsz=1154.7, num_updates=6000, lr=0.000408248, gnorm=0.463, loss_scale=4, train_wall=31, gb_free=13.6, wall=3515
2022-03-23 10:22:18 | INFO | train_inner | epoch 039:    139 / 157 loss=3.771, nll_loss=2.32, ppl=4.99, wps=79381.4, ups=3.2, wpb=24831, bsz=942.8, num_updates=6100, lr=0.000404888, gnorm=0.526, loss_scale=4, train_wall=31, gb_free=14.7, wall=3546
2022-03-23 10:22:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:22:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 10:22:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:22:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people know here.
2022-03-23 10:22:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:22:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:22:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:22:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salt and pepper.
2022-03-23 10:22:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:22:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:22:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:22:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:22:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:22:52 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor may not be able to move because their movements are using energy, and so the superconductor.
2022-03-23 10:22:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:22:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which will restore the big constraints of the face and the basic form, and then go through the thief of information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 10:22:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:23:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, the dinner was best summarized when someone said, "turn you to the men on your table and support you," 'if the revolution starts to support you.' "'"] the truth, love is that we've already supported you in this topic for a long time. "
2022-03-23 10:23:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:23:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a huge part of the design work that we're on our airplane is the stumbling, which is a result that we had to solve the unique problems that were connected to operating on the ground -- everything from a continuously variable system, and a cooling system with fluid that allows us to use an aircraft in the stop-go-traffic, until one particular drive, or when you're flying around the ground, which is the basement of an aircraft, to the basement, to the bottom of a mechanically variable space that we see in the basement, to the basement, to the basement, to the ground, to the ground, to become the basement of a mechanically variable space that we see in the basement, to the basement.
2022-03-23 10:23:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:23:03 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.996 | nll_loss 2.432 | ppl 5.4 | bleu 33.23 | wps 4728.6 | wpb 17862.2 | bsz 728.3 | num_updates 6118 | best_bleu 33.23
2022-03-23 10:23:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6118 updates
2022-03-23 10:23:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:23:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 39 @ 6118 updates, score 33.23) (writing took 2.0087280101142824 seconds)
2022-03-23 10:23:05 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 10:23:05 | INFO | train | epoch 039 | loss 3.733 | nll_loss 2.277 | ppl 4.85 | wps 43535.8 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 6118 | lr 0.000404292 | gnorm 0.49 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 3592
2022-03-23 10:23:05 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 10:23:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:23:31 | INFO | train_inner | epoch 040:     82 / 157 loss=3.7, nll_loss=2.239, ppl=4.72, wps=34098.7, ups=1.37, wpb=24801.7, bsz=991.6, num_updates=6200, lr=0.00040161, gnorm=0.442, loss_scale=4, train_wall=30, gb_free=14.1, wall=3619
2022-03-23 10:23:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:23:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 10:23:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:24:03 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here know.
2022-03-23 10:24:03 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:24:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frogs are served with salt and pepper.
2022-03-23 10:24:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:24:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew back, and that has become a foundation for conservation in namibia.
2022-03-23 10:24:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like moving because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:24:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that restores the big constraints of the face and the basic shape, and then add it through the thief of information that refers the whole porn structure and all the fine.
2022-03-23 10:24:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:24:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was summarized, it was best summarized when someone said, "turn you to the men on your desk and tell you, 'if the revolution starts, then we support you.' '" the truth is that we've been supporting you for this long time with rachel carel's "silyno:" and then, by the future, we're going to download our cake's future. "
2022-03-23 10:24:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:24:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our airplane at the pristest, was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuously variables and a cooling system, that allows us to use an aircraft in the stopand traffic to a particular driver that either drives the basement of a propeller, or if we're going to see the flowing the ground, or if you're going to see the aircraft in the aircraft in the air, until you're in the air, the air, the air to be the air, until you're in the air, you're in the air, until you're in the airline, you're in the airline, you're in the air, until you're in the air, you're in the airline, until you're in the air, you're in the air, until you're in the air, you're in the
2022-03-23 10:24:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:24:33 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 4.024 | nll_loss 2.458 | ppl 5.49 | bleu 32.88 | wps 4853.6 | wpb 17862.2 | bsz 728.3 | num_updates 6275 | best_bleu 33.23
2022-03-23 10:24:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6275 updates
2022-03-23 10:24:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:24:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:24:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 40 @ 6275 updates, score 32.88) (writing took 0.7940776692703366 seconds)
2022-03-23 10:24:33 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 10:24:33 | INFO | train | epoch 040 | loss 3.696 | nll_loss 2.235 | ppl 4.71 | wps 44556 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6275 | lr 0.000399202 | gnorm 0.47 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3681
2022-03-23 10:24:34 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 10:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:24:42 | INFO | train_inner | epoch 041:     25 / 157 loss=3.717, nll_loss=2.259, ppl=4.79, wps=36044.8, ups=1.42, wpb=25466.7, bsz=997.1, num_updates=6300, lr=0.00039841, gnorm=0.494, loss_scale=4, train_wall=31, gb_free=14.4, wall=3689
2022-03-23 10:25:13 | INFO | train_inner | epoch 041:    125 / 157 loss=3.671, nll_loss=2.206, ppl=4.61, wps=79647, ups=3.19, wpb=24946.4, bsz=1024.5, num_updates=6400, lr=0.000395285, gnorm=0.491, loss_scale=4, train_wall=31, gb_free=13.8, wall=3721
2022-03-23 10:25:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:25:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppets in the clinic.
2022-03-23 10:25:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:25:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-23 10:25:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:25:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 10:25:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:25:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:25:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:25:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:25:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a foundation for conservation in namibia.
2022-03-23 10:25:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:25:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor may not be able to move because their movements use energy, and so the superconducting disorder.
2022-03-23 10:25:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that will restore the big contures of the face and the basic form, and then go back through the one thing that refers the whole porn structure and all the wrinkles.
2022-03-23 10:25:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, the dinner was best summarized, when someone said, "turn to the men on your desk and say," if the revolution starts, we support you. '"the truth is that we already have supported you for a long time. at rachel carbonson's" silynson: "and"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:25:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we were on our airplane at the stumest was a result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuously varied, cooling system, that allows us to use an aircraft in stopand traffic until a particular passenger, or if you fly the ground, or if you look at the propelled, or if you look at the bottom of a continuously variable space, to see the aircraft, you're going to see the ground, you're going to see it as well.
2022-03-23 10:26:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:26:02 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.969 | nll_loss 2.407 | ppl 5.3 | bleu 33.68 | wps 4688.8 | wpb 17862.2 | bsz 728.3 | num_updates 6432 | best_bleu 33.68
2022-03-23 10:26:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6432 updates
2022-03-23 10:26:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:26:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:26:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 41 @ 6432 updates, score 33.68) (writing took 1.7535927519202232 seconds)
2022-03-23 10:26:03 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 10:26:03 | INFO | train | epoch 041 | loss 3.675 | nll_loss 2.211 | ppl 4.63 | wps 43860.7 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6432 | lr 0.0003943 | gnorm 0.476 | loss_scale 4 | train_wall 48 | gb_free 13.6 | wall 3771
2022-03-23 10:26:04 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 10:26:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:26:25 | INFO | train_inner | epoch 042:     68 / 157 loss=3.643, nll_loss=2.174, ppl=4.51, wps=34753.3, ups=1.38, wpb=25105.9, bsz=1015, num_updates=6500, lr=0.000392232, gnorm=0.458, loss_scale=4, train_wall=31, gb_free=22.4, wall=3793
2022-03-23 10:26:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:26:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers up in the clinic.
2022-03-23 10:26:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:27:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people know here.
2022-03-23 10:27:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:27:05 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 10:27:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:27:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:27:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:27:13 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:27:13 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:27:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the face of how people took responsibility for wildlife, the number of wildlife grew back. and this has become a foundation for conservation in namibia.
2022-03-23 10:27:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field bundle captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:27:21 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:27:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the big contures of the face and the basic shape, and then go through that information that refers the whole porn structure and all the fine.
2022-03-23 10:27:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:27:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was best summarized when someone said, "turn to men on your table and say," when the revolution begins, we support you. '"the truth is that we've already supported you in this topic for a long time."
2022-03-23 10:27:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:27:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our airplane at the stumbling toes was a result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuous variables and cooling system with coolness that allows us to use an aircraft machine in stopand traffic to a special passenger that either drives the propellers or when you see the ground, the land of a mechanism, to the ground, to the deployment of an aircraft, to the ground, to the deployment of a mechanism, to the ground, to the deployment that we see the land, to the aircraft, to the aircraft, to the ground, to the deployment of a mechanism, to the land, to the air, to the land, to the ground, to the aircraft, to the land, to the end, to the end, to the land
2022-03-23 10:27:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:27:31 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.993 | nll_loss 2.417 | ppl 5.34 | bleu 33.22 | wps 4766.4 | wpb 17862.2 | bsz 728.3 | num_updates 6589 | best_bleu 33.68
2022-03-23 10:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6589 updates
2022-03-23 10:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 42 @ 6589 updates, score 33.22) (writing took 0.7884603352285922 seconds)
2022-03-23 10:27:32 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 10:27:32 | INFO | train | epoch 042 | loss 3.642 | nll_loss 2.173 | ppl 4.51 | wps 44506.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 6589 | lr 0.000389574 | gnorm 0.462 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 3860
2022-03-23 10:27:33 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 10:27:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:27:36 | INFO | train_inner | epoch 043:     11 / 157 loss=3.624, nll_loss=2.155, ppl=4.45, wps=35978.3, ups=1.41, wpb=25544.7, bsz=1097.3, num_updates=6600, lr=0.000389249, gnorm=0.45, loss_scale=4, train_wall=31, gb_free=13.9, wall=3864
2022-03-23 10:28:08 | INFO | train_inner | epoch 043:    111 / 157 loss=3.652, nll_loss=2.183, ppl=4.54, wps=79450.7, ups=3.19, wpb=24890.2, bsz=907.4, num_updates=6700, lr=0.000386334, gnorm=0.48, loss_scale=4, train_wall=31, gb_free=13.8, wall=3895
2022-03-23 10:28:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:28:26 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieppers up in the clinic.
2022-03-23 10:28:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:28:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you are familiar with.
2022-03-23 10:28:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:28:34 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 10:28:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:28:38 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:28:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:28:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:28:46 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew back, and that's a basis for conservation in namibia.
2022-03-23 10:28:46 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor may not be able to move because their movements use energy, and so the superconducting disorder.
2022-03-23 10:28:50 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:28:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which resembles the big contures of the face and the basic form, and admit it through the thief of information that refers the whole porn structure and all the fits.
2022-03-23 10:28:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- well, in the controversial dinner, it was best summarized when someone said, "turn to the men on your desk and tell them, 'when the revolution begins to download you.' '" the truth, love is that we've already supported you for a long time, and rachel carspring's "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [
2022-03-23 10:28:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're on on our airplane is a result that we had to solve the unique problems that were linked to operate on the ground -- everything from a continuously variables and a cooling system of fluid that allows us to use an aircraft in stop traffic until a specially appropriate passenger, either a propelled drive, or a propellant, or a flying space that's going to be connected to the ground.
2022-03-23 10:29:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:29:01 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.957 | nll_loss 2.389 | ppl 5.24 | bleu 33.87 | wps 4679.7 | wpb 17862.2 | bsz 728.3 | num_updates 6746 | best_bleu 33.87
2022-03-23 10:29:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6746 updates
2022-03-23 10:29:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:29:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt
2022-03-23 10:29:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_best.pt (epoch 43 @ 6746 updates, score 33.87) (writing took 1.7588780550286174 seconds)
2022-03-23 10:29:02 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 10:29:02 | INFO | train | epoch 043 | loss 3.619 | nll_loss 2.147 | ppl 4.43 | wps 43772.9 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 6746 | lr 0.000385014 | gnorm 0.465 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3950
2022-03-23 10:29:03 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 10:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:29:20 | INFO | train_inner | epoch 044:     54 / 157 loss=3.592, nll_loss=2.117, ppl=4.34, wps=34397, ups=1.38, wpb=24859.6, bsz=1076.2, num_updates=6800, lr=0.000383482, gnorm=0.499, loss_scale=4, train_wall=31, gb_free=14.2, wall=3968
2022-03-23 10:29:51 | INFO | train_inner | epoch 044:    154 / 157 loss=3.6, nll_loss=2.126, ppl=4.36, wps=82046, ups=3.21, wpb=25561.4, bsz=1044.7, num_updates=6900, lr=0.000380693, gnorm=0.447, loss_scale=4, train_wall=31, gb_free=13.8, wall=3999
2022-03-23 10:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:29:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-23 10:29:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:30:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here know.
2022-03-23 10:30:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:30:04 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new pigs.
2022-03-23 10:30:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:30:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:30:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:30:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:30:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:30:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife regrew, and that's become a foundation for conservation in namibia.
2022-03-23 10:30:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:30:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 10:30:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:30:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that repeats the big constraints of the face and the basic form, and then go through the thief of information that refers the whole porn structure and all the wrinkles.
2022-03-23 10:30:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:30:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, at the controversial dinner, it's been best summarized when someone said, "turn to men on your desk and tell them, 'when the revolution begins, we support you.'" the truth, women are that we already supported you for a long time.
2022-03-23 10:30:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, necessity is still the mother of invention, and a large part of the design work that we're on on our aircraft on the proud toes, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable operations and a refrigeration system, that allows us to use an aircraft in stopand traffic to a special passenger, which is either propeller, or a propellant, or a propeller, to propelled, to the ground, to the propelled, to the propellant, to the propellant, to the point where you can be made up until you can see that you can see that you can see that you can see that you can see that you can see that you can see that you can see the ground, you can see it's either be made up until you can see it's all the mechanical condition-of-the-ground, you can see the mechanism
2022-03-23 10:30:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:30:31 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.965 | nll_loss 2.401 | ppl 5.28 | bleu 33.67 | wps 4700.5 | wpb 17862.2 | bsz 728.3 | num_updates 6903 | best_bleu 33.87
2022-03-23 10:30:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6903 updates
2022-03-23 10:30:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:30:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:30:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 44 @ 6903 updates, score 33.67) (writing took 0.8553193882107735 seconds)
2022-03-23 10:30:32 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 10:30:32 | INFO | train | epoch 044 | loss 3.603 | nll_loss 2.129 | ppl 4.37 | wps 44268.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 6903 | lr 0.000380611 | gnorm 0.481 | loss_scale 4 | train_wall 48 | gb_free 13.3 | wall 4039
2022-03-23 10:30:32 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 10:30:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:31:03 | INFO | train_inner | epoch 045:     97 / 157 loss=3.565, nll_loss=2.086, ppl=4.24, wps=35707.9, ups=1.39, wpb=25640.8, bsz=1040.4, num_updates=7000, lr=0.000377964, gnorm=0.472, loss_scale=4, train_wall=31, gb_free=14.6, wall=4071
2022-03-23 10:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:31:25 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:31:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:31:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 10:31:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:31:33 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new vibrations.
2022-03-23 10:31:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:31:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 10:31:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:31:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 10:31:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:31:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the measure of how people took responsibility for wildlife, the number of wildlife grew up again, and this has become a basis for conservation in namibia.
2022-03-23 10:31:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:31:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like moving because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:31:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:31:53 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which gives the big contures of the face, and restores the basic shape, and match it through the thief of information that refers the whole porn structure and all the fine wrinkles.
2022-03-23 10:31:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:31:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that -- well, in the controversial dinner, it was best summarized when someone said, "turn to the men on your desk and tell them, 'if the revolution starts, we'll support you.'" the truth, women, we've already supported you for a long time. "
2022-03-23 10:31:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're on our airplane is the stumbling toe, was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuously variable drive and refrigerating system, that allows us to use an aircraft in the stop-go-traffic to a specially appropriate drive, or if you're going to see the ground, you're going to see it all the way down the mechanism, the same as we're going to see the aircraft.
2022-03-23 10:31:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:31:59 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.951 | nll_loss 2.384 | ppl 5.22 | bleu 33.76 | wps 4824.9 | wpb 17862.2 | bsz 728.3 | num_updates 7060 | best_bleu 33.87
2022-03-23 10:31:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7060 updates
2022-03-23 10:31:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:32:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 45 @ 7060 updates, score 33.76) (writing took 0.8166196481324732 seconds)
2022-03-23 10:32:00 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 10:32:00 | INFO | train | epoch 045 | loss 3.584 | nll_loss 2.107 | ppl 4.31 | wps 44702.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 7060 | lr 0.000376355 | gnorm 0.488 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 4128
2022-03-23 10:32:00 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 10:32:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 10:32:13 | INFO | train_inner | epoch 046:     40 / 157 loss=3.595, nll_loss=2.118, ppl=4.34, wps=34742.8, ups=1.43, wpb=24304.7, bsz=957.9, num_updates=7100, lr=0.000375293, gnorm=0.498, loss_scale=4, train_wall=30, gb_free=14.3, wall=4141
2022-03-23 10:32:44 | INFO | train_inner | epoch 046:    140 / 157 loss=3.549, nll_loss=2.067, ppl=4.19, wps=80532.8, ups=3.17, wpb=25441.7, bsz=1021.5, num_updates=7200, lr=0.000372678, gnorm=0.448, loss_scale=4, train_wall=31, gb_free=13.6, wall=4172
2022-03-23 10:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 10:32:53 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 10:32:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 10:32:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know.
2022-03-23 10:32:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 10:33:01 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will create two new pigs transcend.
2022-03-23 10:33:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 10:33:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 10:33:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example hypothesis: and in the measure of how people took responsibility for wildlife, the number of wildlife grew back. and this has become a basis for conservation in namibia.
2022-03-23 10:33:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor may not be able to move because their movements are using energy, and so the superconducting disorder.
2022-03-23 10:33:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which gives the big contures of the face and the basic form, and then add it through the threshold of that information that refers all the porn structure and all the fine.
2022-03-23 10:33:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 10:33:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and reasonable to be here at tedwomen is that -- well, in the strict dinner, it's been best summarized when someone said, "turn to men on your desk and say to them, 'when the revolution begins, we support you.'" the truth, women, love is that we've already supported you for a long time.
2022-03-23 10:33:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're on our airplane is the stumbling toes, was a result that we had to solve the unique problems that were linked to operate on the ground -- everything, from a continuously variable propulsion and a refrigeration system with fluid that allows us to use an aircraft in stopand traffic to a specially appropriate passenger, which is either propelled to fly, or if you can see the ground, to the mechanism, to the point where you can see the basement.
2022-03-23 10:33:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 10:33:27 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.954 | nll_loss 2.389 | ppl 5.24 | bleu 33.47 | wps 4822.3 | wpb 17862.2 | bsz 728.3 | num_updates 7217 | best_bleu 33.87
2022-03-23 10:33:27 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 10:33:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7217 updates
2022-03-23 10:33:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:33:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt
2022-03-23 10:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_label_smoothing_0.1_#1/checkpoint_last.pt (epoch 46 @ 7217 updates, score 33.47) (writing took 0.8329486772418022 seconds)
2022-03-23 10:33:28 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 10:33:28 | INFO | train | epoch 046 | loss 3.552 | nll_loss 2.071 | ppl 4.2 | wps 44763 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 7217 | lr 0.000372239 | gnorm 0.463 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 4216
2022-03-23 10:33:28 | INFO | fairseq_cli.train | done training in 4215.3 seconds
