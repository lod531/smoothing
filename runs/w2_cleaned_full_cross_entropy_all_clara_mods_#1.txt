Sender: LSF System <lsfadmin@eu-g3-030>
Subject: Job 207642489: <w2_cleaned_full_cross_entropy_all_clara_mods_#1> in cluster <euler> Done

Job <w2_cleaned_full_cross_entropy_all_clara_mods_#1> was submitted from host <eu-login-03> by user <andriusb> in cluster <euler> at Tue Mar  8 20:01:33 2022
Job was executed on host(s) <eu-g3-030>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Tue Mar  8 20:02:04 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Tue Mar  8 20:02:04 2022
Terminated at Tue Mar  8 21:18:57 2022
Results reported at Tue Mar  8 21:18:57 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-cleaned-full --save-dir /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575614 --fp16 --no-epoch-checkpoints --patience 3 --decoder-ffn-embed-dim 1024 --decoder-attention-heads 4 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4599.39 sec.
    Max Memory :                                 4297 MB
    Average Memory :                             3408.97 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15703.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   4613 sec.
    Turnaround time :                            4644 sec.

The output (if any) follows:

2022-03-08 20:02:09 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 1024, 'decoder_layers': 6, 'decoder_attention_heads': 4, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-cleaned-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575614, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-08 20:02:10 | INFO | fairseq.tasks.language_modeling | dictionary: 33280 types
2022-03-08 20:02:10 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(33280, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=33280, bias=False)
  )
)
2022-03-08 20:02:10 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-08 20:02:10 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-08 20:02:10 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-08 20:02:10 | INFO | fairseq_cli.train | num. shared model params: 29,656,064 (num. trained: 29,656,064)
2022-03-08 20:02:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-08 20:02:10 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-cleaned-full/valid
2022-03-08 20:02:13 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-08 20:02:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-08 20:02:13 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-08 20:02:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-08 20:02:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-08 20:02:13 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-08 20:02:13 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 20:02:13 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 20:02:13 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-08 20:02:13 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-cleaned-full/train
2022-03-08 20:02:13 | INFO | fairseq.trainer | begin training epoch 1
2022-03-08 20:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:02:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-08 20:02:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 20:02:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 20:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-08 20:02:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-08 20:03:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:03:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.199 | ppl 37617.1 | wps 52370.2 | wpb 510.9 | bsz 1 | num_updates 27
2022-03-08 20:03:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 27 updates
2022-03-08 20:03:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:03:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:03:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 1 @ 27 updates, score 15.199) (writing took 1.4827917348593473 seconds)
2022-03-08 20:03:43 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-08 20:03:43 | INFO | train | epoch 001 | loss 15.714 | ppl 53741.6 | wps 27836.3 | ups 0.43 | wpb 65220.3 | bsz 127.4 | num_updates 27 | lr 3.47433e-06 | gnorm 5.735 | loss_scale 4 | train_wall 77 | gb_free 9.9 | wall 90
2022-03-08 20:03:43 | INFO | fairseq.trainer | begin training epoch 2
2022-03-08 20:03:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:04:55 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.538 | ppl 11897.9 | wps 52261.2 | wpb 510.9 | bsz 1 | num_updates 59 | best_loss 13.538
2022-03-08 20:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 59 updates
2022-03-08 20:04:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:04:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:04:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 2 @ 59 updates, score 13.538) (writing took 1.5714054442942142 seconds)
2022-03-08 20:04:56 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-08 20:04:56 | INFO | train | epoch 002 | loss 14.541 | ppl 23835.9 | wps 28244.5 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 59 | lr 7.47353e-06 | gnorm 4.105 | loss_scale 4 | train_wall 61 | gb_free 9.9 | wall 164
2022-03-08 20:04:56 | INFO | fairseq.trainer | begin training epoch 3
2022-03-08 20:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:06:09 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.402 | ppl 5411.42 | wps 52514.4 | wpb 510.9 | bsz 1 | num_updates 91 | best_loss 12.402
2022-03-08 20:06:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 91 updates
2022-03-08 20:06:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 3 @ 91 updates, score 12.402) (writing took 1.5514827715232968 seconds)
2022-03-08 20:06:10 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-08 20:06:10 | INFO | train | epoch 003 | loss 13.201 | ppl 9418.01 | wps 28257.3 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 91 | lr 1.14727e-05 | gnorm 2.334 | loss_scale 4 | train_wall 61 | gb_free 9.9 | wall 238
2022-03-08 20:06:10 | INFO | fairseq.trainer | begin training epoch 4
2022-03-08 20:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:06:30 | INFO | train_inner | epoch 004:      9 / 32 loss=14.256, ppl=19560.1, wps=28346.4, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=100, lr=1.25975e-05, gnorm=3.761, loss_scale=4, train_wall=215, gb_free=9.9, wall=257
2022-03-08 20:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:07:23 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.844 | ppl 3676.06 | wps 52400.1 | wpb 510.9 | bsz 1 | num_updates 123 | best_loss 11.844
2022-03-08 20:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 123 updates
2022-03-08 20:07:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:07:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 4 @ 123 updates, score 11.844) (writing took 1.5379508873447776 seconds)
2022-03-08 20:07:24 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-08 20:07:24 | INFO | train | epoch 004 | loss 12.439 | ppl 5551.56 | wps 28255.2 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 123 | lr 1.54719e-05 | gnorm 1.526 | loss_scale 4 | train_wall 61 | gb_free 9.9 | wall 312
2022-03-08 20:07:24 | INFO | fairseq.trainer | begin training epoch 5
2022-03-08 20:07:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:08:37 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.435 | ppl 2769.2 | wps 52224.7 | wpb 510.9 | bsz 1 | num_updates 155 | best_loss 11.435
2022-03-08 20:08:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 155 updates
2022-03-08 20:08:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:08:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:08:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 5 @ 155 updates, score 11.435) (writing took 1.5530897667631507 seconds)
2022-03-08 20:08:38 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-08 20:08:38 | INFO | train | epoch 005 | loss 11.985 | ppl 4054.99 | wps 28272.3 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 155 | lr 1.94711e-05 | gnorm 1.294 | loss_scale 8 | train_wall 61 | gb_free 9.9 | wall 386
2022-03-08 20:08:38 | INFO | fairseq.trainer | begin training epoch 6
2022-03-08 20:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:09:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:09:51 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.007 | ppl 2057.68 | wps 52242 | wpb 510.9 | bsz 1 | num_updates 187 | best_loss 11.007
2022-03-08 20:09:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 187 updates
2022-03-08 20:09:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:09:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 6 @ 187 updates, score 11.007) (writing took 1.5370457787066698 seconds)
2022-03-08 20:09:52 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-08 20:09:52 | INFO | train | epoch 006 | loss 11.567 | ppl 3033.57 | wps 28243.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 187 | lr 2.34703e-05 | gnorm 1.145 | loss_scale 8 | train_wall 61 | gb_free 9.9 | wall 460
2022-03-08 20:09:52 | INFO | fairseq.trainer | begin training epoch 7
2022-03-08 20:09:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:10:20 | INFO | train_inner | epoch 007:     13 / 32 loss=11.843, ppl=3674.52, wps=28336.3, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=200, lr=2.5095e-05, gnorm=1.25, loss_scale=8, train_wall=190, gb_free=9.9, wall=487
2022-03-08 20:11:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:11:05 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 10.559 | ppl 1508.48 | wps 52261.8 | wpb 510.9 | bsz 1 | num_updates 219 | best_loss 10.559
2022-03-08 20:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 219 updates
2022-03-08 20:11:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:11:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:11:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 7 @ 219 updates, score 10.559) (writing took 1.5531201930716634 seconds)
2022-03-08 20:11:06 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-08 20:11:06 | INFO | train | epoch 007 | loss 11.123 | ppl 2229.54 | wps 28228.1 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 219 | lr 2.74695e-05 | gnorm 0.973 | loss_scale 8 | train_wall 61 | gb_free 9.9 | wall 534
2022-03-08 20:11:06 | INFO | fairseq.trainer | begin training epoch 8
2022-03-08 20:11:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:12:19 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.168 | ppl 1150.22 | wps 52343.5 | wpb 510.9 | bsz 1 | num_updates 251 | best_loss 10.168
2022-03-08 20:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 251 updates
2022-03-08 20:12:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 8 @ 251 updates, score 10.168) (writing took 1.5280370451509953 seconds)
2022-03-08 20:12:20 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-08 20:12:20 | INFO | train | epoch 008 | loss 10.69 | ppl 1651.47 | wps 28208 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 251 | lr 3.14687e-05 | gnorm 0.753 | loss_scale 8 | train_wall 61 | gb_free 9.9 | wall 608
2022-03-08 20:12:20 | INFO | fairseq.trainer | begin training epoch 9
2022-03-08 20:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:13:33 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.862 | ppl 930.85 | wps 52504.1 | wpb 510.9 | bsz 1 | num_updates 283 | best_loss 9.862
2022-03-08 20:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 283 updates
2022-03-08 20:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 9 @ 283 updates, score 9.862) (writing took 1.5681420220062137 seconds)
2022-03-08 20:13:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-08 20:13:34 | INFO | train | epoch 009 | loss 10.343 | ppl 1299.26 | wps 28258.8 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 283 | lr 3.54679e-05 | gnorm 0.579 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 681
2022-03-08 20:13:34 | INFO | fairseq.trainer | begin training epoch 10
2022-03-08 20:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:14:11 | INFO | train_inner | epoch 010:     17 / 32 loss=10.546, ppl=1495.4, wps=28312.6, ups=0.43, wpb=65277, bsz=127.5, num_updates=300, lr=3.75925e-05, gnorm=0.689, loss_scale=16, train_wall=190, gb_free=9.9, wall=718
2022-03-08 20:14:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:14:46 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 9.63 | ppl 792.25 | wps 52426.5 | wpb 510.9 | bsz 1 | num_updates 315 | best_loss 9.63
2022-03-08 20:14:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 315 updates
2022-03-08 20:14:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:14:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 10 @ 315 updates, score 9.63) (writing took 1.5915455548092723 seconds)
2022-03-08 20:14:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-08 20:14:48 | INFO | train | epoch 010 | loss 10.065 | ppl 1071.33 | wps 28238 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 315 | lr 3.94671e-05 | gnorm 0.483 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 755
2022-03-08 20:14:48 | INFO | fairseq.trainer | begin training epoch 11
2022-03-08 20:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:15:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:16:01 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 9.466 | ppl 707.39 | wps 52251.4 | wpb 510.9 | bsz 1 | num_updates 347 | best_loss 9.466
2022-03-08 20:16:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 347 updates
2022-03-08 20:16:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:16:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 11 @ 347 updates, score 9.466) (writing took 1.5668797623366117 seconds)
2022-03-08 20:16:02 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-08 20:16:02 | INFO | train | epoch 011 | loss 9.861 | ppl 929.99 | wps 28202.1 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 347 | lr 4.34663e-05 | gnorm 0.421 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 829
2022-03-08 20:16:02 | INFO | fairseq.trainer | begin training epoch 12
2022-03-08 20:16:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:17:14 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 9.348 | ppl 651.7 | wps 52321.4 | wpb 510.9 | bsz 1 | num_updates 379 | best_loss 9.348
2022-03-08 20:17:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 379 updates
2022-03-08 20:17:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:17:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:17:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 12 @ 379 updates, score 9.348) (writing took 1.5540667632594705 seconds)
2022-03-08 20:17:16 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-08 20:17:16 | INFO | train | epoch 012 | loss 9.716 | ppl 840.88 | wps 28274.8 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 379 | lr 4.74655e-05 | gnorm 0.386 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 903
2022-03-08 20:17:16 | INFO | fairseq.trainer | begin training epoch 13
2022-03-08 20:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:18:01 | INFO | train_inner | epoch 013:     21 / 32 loss=9.783, ppl=881.24, wps=28340.4, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=400, lr=5.009e-05, gnorm=0.414, loss_scale=32, train_wall=190, gb_free=9.9, wall=948
2022-03-08 20:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:18:28 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 9.244 | ppl 606.53 | wps 52338.5 | wpb 510.9 | bsz 1 | num_updates 411 | best_loss 9.244
2022-03-08 20:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 411 updates
2022-03-08 20:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:18:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 13 @ 411 updates, score 9.244) (writing took 1.5935447495430708 seconds)
2022-03-08 20:18:30 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-08 20:18:30 | INFO | train | epoch 013 | loss 9.599 | ppl 775.42 | wps 28250.7 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 411 | lr 5.14647e-05 | gnorm 0.401 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 977
2022-03-08 20:18:30 | INFO | fairseq.trainer | begin training epoch 14
2022-03-08 20:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:19:42 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 9.137 | ppl 563.13 | wps 52349 | wpb 510.9 | bsz 1 | num_updates 443 | best_loss 9.137
2022-03-08 20:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 443 updates
2022-03-08 20:19:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:19:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:19:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 14 @ 443 updates, score 9.137) (writing took 1.541937604546547 seconds)
2022-03-08 20:19:44 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-08 20:19:44 | INFO | train | epoch 014 | loss 9.488 | ppl 717.94 | wps 28301 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 443 | lr 5.54639e-05 | gnorm 0.441 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1051
2022-03-08 20:19:44 | INFO | fairseq.trainer | begin training epoch 15
2022-03-08 20:19:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:20:56 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.027 | ppl 521.84 | wps 52185.7 | wpb 510.9 | bsz 1 | num_updates 475 | best_loss 9.027
2022-03-08 20:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 475 updates
2022-03-08 20:20:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:20:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 15 @ 475 updates, score 9.027) (writing took 1.5610032649710774 seconds)
2022-03-08 20:20:58 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-08 20:20:58 | INFO | train | epoch 015 | loss 9.377 | ppl 664.97 | wps 28209.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 475 | lr 5.94631e-05 | gnorm 0.448 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1125
2022-03-08 20:20:58 | INFO | fairseq.trainer | begin training epoch 16
2022-03-08 20:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:21:51 | INFO | train_inner | epoch 016:     25 / 32 loss=9.407, ppl=679.08, wps=28352.7, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=500, lr=6.25875e-05, gnorm=0.462, loss_scale=32, train_wall=190, gb_free=9.9, wall=1179
2022-03-08 20:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:22:10 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.922 | ppl 484.91 | wps 52867.7 | wpb 510.9 | bsz 1 | num_updates 507 | best_loss 8.922
2022-03-08 20:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 507 updates
2022-03-08 20:22:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:22:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 16 @ 507 updates, score 8.922) (writing took 1.5539395781233907 seconds)
2022-03-08 20:22:12 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-08 20:22:12 | INFO | train | epoch 016 | loss 9.268 | ppl 616.56 | wps 28298.6 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 507 | lr 6.34623e-05 | gnorm 0.539 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1199
2022-03-08 20:22:12 | INFO | fairseq.trainer | begin training epoch 17
2022-03-08 20:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:22:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 20:23:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:23:24 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.824 | ppl 453.2 | wps 52205 | wpb 510.9 | bsz 1 | num_updates 538 | best_loss 8.824
2022-03-08 20:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 538 updates
2022-03-08 20:23:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:23:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 17 @ 538 updates, score 8.824) (writing took 1.5420618122443557 seconds)
2022-03-08 20:23:26 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-08 20:23:26 | INFO | train | epoch 017 | loss 9.16 | ppl 572 | wps 27351.3 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 538 | lr 6.73366e-05 | gnorm 0.511 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1273
2022-03-08 20:23:26 | INFO | fairseq.trainer | begin training epoch 18
2022-03-08 20:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:24:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:24:38 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 8.73 | ppl 424.62 | wps 52375.4 | wpb 510.9 | bsz 1 | num_updates 570 | best_loss 8.73
2022-03-08 20:24:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 570 updates
2022-03-08 20:24:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:24:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 18 @ 570 updates, score 8.73) (writing took 1.5536770932376385 seconds)
2022-03-08 20:24:39 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-08 20:24:39 | INFO | train | epoch 018 | loss 9.055 | ppl 531.86 | wps 28320.3 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 570 | lr 7.13358e-05 | gnorm 0.535 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1347
2022-03-08 20:24:39 | INFO | fairseq.trainer | begin training epoch 19
2022-03-08 20:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:25:43 | INFO | train_inner | epoch 019:     30 / 32 loss=9.07, ppl=537.36, wps=28105.7, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=600, lr=7.5085e-05, gnorm=0.554, loss_scale=32, train_wall=192, gb_free=9.9, wall=1411
2022-03-08 20:25:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:25:52 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 8.648 | ppl 401.2 | wps 52369.9 | wpb 510.9 | bsz 1 | num_updates 602 | best_loss 8.648
2022-03-08 20:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 602 updates
2022-03-08 20:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:25:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:25:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 19 @ 602 updates, score 8.648) (writing took 1.5653742020949721 seconds)
2022-03-08 20:25:53 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-08 20:25:53 | INFO | train | epoch 019 | loss 8.95 | ppl 494.63 | wps 28257.1 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 602 | lr 7.5335e-05 | gnorm 0.627 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1421
2022-03-08 20:25:53 | INFO | fairseq.trainer | begin training epoch 20
2022-03-08 20:25:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:27:06 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 8.568 | ppl 379.61 | wps 52364.1 | wpb 510.9 | bsz 1 | num_updates 634 | best_loss 8.568
2022-03-08 20:27:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 634 updates
2022-03-08 20:27:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:27:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:27:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 20 @ 634 updates, score 8.568) (writing took 1.5525405127555132 seconds)
2022-03-08 20:27:07 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-08 20:27:07 | INFO | train | epoch 020 | loss 8.849 | ppl 461.26 | wps 28255.5 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 634 | lr 7.93342e-05 | gnorm 0.627 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1494
2022-03-08 20:27:07 | INFO | fairseq.trainer | begin training epoch 21
2022-03-08 20:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:27:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 20:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:28:19 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 8.492 | ppl 360 | wps 52363.2 | wpb 510.9 | bsz 1 | num_updates 665 | best_loss 8.492
2022-03-08 20:28:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 665 updates
2022-03-08 20:28:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:28:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:28:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 21 @ 665 updates, score 8.492) (writing took 1.581609819084406 seconds)
2022-03-08 20:28:21 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-08 20:28:21 | INFO | train | epoch 021 | loss 8.751 | ppl 430.84 | wps 27361.8 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 665 | lr 8.32084e-05 | gnorm 0.656 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1568
2022-03-08 20:28:21 | INFO | fairseq.trainer | begin training epoch 22
2022-03-08 20:28:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:29:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:29:33 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 8.423 | ppl 343.11 | wps 52224.7 | wpb 510.9 | bsz 1 | num_updates 697 | best_loss 8.423
2022-03-08 20:29:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 697 updates
2022-03-08 20:29:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:29:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 22 @ 697 updates, score 8.423) (writing took 1.5620317636057734 seconds)
2022-03-08 20:29:35 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-08 20:29:35 | INFO | train | epoch 022 | loss 8.659 | ppl 404.33 | wps 28300.3 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 697 | lr 8.72076e-05 | gnorm 0.805 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1642
2022-03-08 20:29:35 | INFO | fairseq.trainer | begin training epoch 23
2022-03-08 20:29:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:29:41 | INFO | train_inner | epoch 023:      3 / 32 loss=8.753, ppl=431.35, wps=27403.8, ups=0.42, wpb=65198.4, bsz=127.4, num_updates=700, lr=8.75825e-05, gnorm=0.701, loss_scale=32, train_wall=191, gb_free=9.9, wall=1649
2022-03-08 20:30:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:30:47 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 8.349 | ppl 326.17 | wps 52707.6 | wpb 510.9 | bsz 1 | num_updates 729 | best_loss 8.349
2022-03-08 20:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 729 updates
2022-03-08 20:30:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:30:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 23 @ 729 updates, score 8.349) (writing took 1.5829014237970114 seconds)
2022-03-08 20:30:49 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-08 20:30:49 | INFO | train | epoch 023 | loss 8.565 | ppl 378.62 | wps 28222.7 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 729 | lr 9.12068e-05 | gnorm 0.717 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1716
2022-03-08 20:30:49 | INFO | fairseq.trainer | begin training epoch 24
2022-03-08 20:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:32:01 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 8.276 | ppl 309.88 | wps 52376.4 | wpb 510.9 | bsz 1 | num_updates 761 | best_loss 8.276
2022-03-08 20:32:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 761 updates
2022-03-08 20:32:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:32:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:32:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 24 @ 761 updates, score 8.276) (writing took 1.6311642630025744 seconds)
2022-03-08 20:32:03 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-08 20:32:03 | INFO | train | epoch 024 | loss 8.474 | ppl 355.58 | wps 28211.7 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 761 | lr 9.5206e-05 | gnorm 0.783 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1790
2022-03-08 20:32:03 | INFO | fairseq.trainer | begin training epoch 25
2022-03-08 20:32:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:32:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 20:33:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:33:15 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 8.208 | ppl 295.76 | wps 52317.7 | wpb 510.9 | bsz 1 | num_updates 792 | best_loss 8.208
2022-03-08 20:33:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 792 updates
2022-03-08 20:33:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:33:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 25 @ 792 updates, score 8.208) (writing took 1.6882256045937538 seconds)
2022-03-08 20:33:17 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-08 20:33:17 | INFO | train | epoch 025 | loss 8.385 | ppl 334.35 | wps 27322.8 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 792 | lr 9.90802e-05 | gnorm 0.793 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1864
2022-03-08 20:33:17 | INFO | fairseq.trainer | begin training epoch 26
2022-03-08 20:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:33:34 | INFO | train_inner | epoch 026:      8 / 32 loss=8.459, ppl=351.95, wps=28052.9, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=800, lr=0.00010008, gnorm=0.757, loss_scale=32, train_wall=192, gb_free=9.9, wall=1881
2022-03-08 20:34:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:34:29 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 8.145 | ppl 282.97 | wps 52483.2 | wpb 510.9 | bsz 1 | num_updates 824 | best_loss 8.145
2022-03-08 20:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 824 updates
2022-03-08 20:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:34:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 26 @ 824 updates, score 8.145) (writing took 1.6600539349019527 seconds)
2022-03-08 20:34:31 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-08 20:34:31 | INFO | train | epoch 026 | loss 8.297 | ppl 314.63 | wps 28281.1 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 824 | lr 0.000103079 | gnorm 0.742 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 1938
2022-03-08 20:34:31 | INFO | fairseq.trainer | begin training epoch 27
2022-03-08 20:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:35:43 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 8.087 | ppl 271.9 | wps 52118.9 | wpb 510.9 | bsz 1 | num_updates 856 | best_loss 8.087
2022-03-08 20:35:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 856 updates
2022-03-08 20:35:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:35:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:35:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 27 @ 856 updates, score 8.087) (writing took 1.633067760616541 seconds)
2022-03-08 20:35:45 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-08 20:35:45 | INFO | train | epoch 027 | loss 8.213 | ppl 296.78 | wps 28191.3 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 856 | lr 0.000107079 | gnorm 0.815 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2012
2022-03-08 20:35:45 | INFO | fairseq.trainer | begin training epoch 28
2022-03-08 20:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:36:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:36:57 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 8.028 | ppl 261 | wps 52105.2 | wpb 510.9 | bsz 1 | num_updates 888 | best_loss 8.028
2022-03-08 20:36:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 888 updates
2022-03-08 20:36:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:36:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 28 @ 888 updates, score 8.028) (writing took 1.482324581593275 seconds)
2022-03-08 20:36:59 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-08 20:36:59 | INFO | train | epoch 028 | loss 8.13 | ppl 280.17 | wps 28249.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 888 | lr 0.000111078 | gnorm 0.782 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2086
2022-03-08 20:36:59 | INFO | fairseq.trainer | begin training epoch 29
2022-03-08 20:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:37:24 | INFO | train_inner | epoch 029:     12 / 32 loss=8.186, ppl=291.28, wps=28324.6, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=900, lr=0.000112578, gnorm=0.789, loss_scale=32, train_wall=190, gb_free=9.9, wall=2112
2022-03-08 20:37:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 20:38:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:38:11 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.975 | ppl 251.51 | wps 52338.2 | wpb 510.9 | bsz 1 | num_updates 919 | best_loss 7.975
2022-03-08 20:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 919 updates
2022-03-08 20:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:38:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:38:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 29 @ 919 updates, score 7.975) (writing took 6.014069457538426 seconds)
2022-03-08 20:38:17 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-08 20:38:17 | INFO | train | epoch 029 | loss 8.049 | ppl 264.85 | wps 25787.3 | ups 0.4 | wpb 65261 | bsz 127.5 | num_updates 919 | lr 0.000114952 | gnorm 0.76 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2165
2022-03-08 20:38:17 | INFO | fairseq.trainer | begin training epoch 30
2022-03-08 20:38:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:39:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-08 20:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:39:30 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.923 | ppl 242.77 | wps 52015.5 | wpb 510.9 | bsz 1 | num_updates 950 | best_loss 7.923
2022-03-08 20:39:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 950 updates
2022-03-08 20:39:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:39:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:39:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 30 @ 950 updates, score 7.923) (writing took 1.6054182536900043 seconds)
2022-03-08 20:39:31 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-08 20:39:31 | INFO | train | epoch 030 | loss 7.974 | ppl 251.4 | wps 27283.6 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 950 | lr 0.000118826 | gnorm 0.853 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 2239
2022-03-08 20:39:31 | INFO | fairseq.trainer | begin training epoch 31
2022-03-08 20:39:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:40:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:40:44 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.872 | ppl 234.28 | wps 52143.6 | wpb 510.9 | bsz 1 | num_updates 982 | best_loss 7.872
2022-03-08 20:40:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 982 updates
2022-03-08 20:40:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:40:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:40:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 31 @ 982 updates, score 7.872) (writing took 1.554002751596272 seconds)
2022-03-08 20:40:45 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-08 20:40:45 | INFO | train | epoch 031 | loss 7.899 | ppl 238.7 | wps 28217.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 982 | lr 0.000122825 | gnorm 0.785 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 2313
2022-03-08 20:40:45 | INFO | fairseq.trainer | begin training epoch 32
2022-03-08 20:40:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:41:24 | INFO | train_inner | epoch 032:     18 / 32 loss=7.938, ppl=245.3, wps=27254.4, ups=0.42, wpb=65277, bsz=127.5, num_updates=1000, lr=0.000125075, gnorm=0.818, loss_scale=16, train_wall=194, gb_free=9.9, wall=2351
2022-03-08 20:41:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:41:58 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.831 | ppl 227.73 | wps 52076.5 | wpb 510.9 | bsz 1 | num_updates 1014 | best_loss 7.831
2022-03-08 20:41:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1014 updates
2022-03-08 20:41:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:41:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:42:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 32 @ 1014 updates, score 7.831) (writing took 1.5583864590153098 seconds)
2022-03-08 20:42:00 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-08 20:42:00 | INFO | train | epoch 032 | loss 7.825 | ppl 226.82 | wps 28197.5 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1014 | lr 0.000126825 | gnorm 0.827 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 2387
2022-03-08 20:42:00 | INFO | fairseq.trainer | begin training epoch 33
2022-03-08 20:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:43:12 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.785 | ppl 220.54 | wps 52331.4 | wpb 510.9 | bsz 1 | num_updates 1046 | best_loss 7.785
2022-03-08 20:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1046 updates
2022-03-08 20:43:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:43:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:43:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 33 @ 1046 updates, score 7.785) (writing took 1.577277472242713 seconds)
2022-03-08 20:43:13 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-08 20:43:13 | INFO | train | epoch 033 | loss 7.751 | ppl 215.41 | wps 28289.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1046 | lr 0.000130824 | gnorm 0.838 | loss_scale 16 | train_wall 61 | gb_free 9.9 | wall 2461
2022-03-08 20:43:13 | INFO | fairseq.trainer | begin training epoch 34
2022-03-08 20:43:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:44:26 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.738 | ppl 213.44 | wps 52211.7 | wpb 510.9 | bsz 1 | num_updates 1078 | best_loss 7.738
2022-03-08 20:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1078 updates
2022-03-08 20:44:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:44:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 34 @ 1078 updates, score 7.738) (writing took 1.5840987227857113 seconds)
2022-03-08 20:44:27 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-08 20:44:27 | INFO | train | epoch 034 | loss 7.679 | ppl 204.9 | wps 28195.1 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1078 | lr 0.000134823 | gnorm 0.834 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2535
2022-03-08 20:44:27 | INFO | fairseq.trainer | begin training epoch 35
2022-03-08 20:44:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:45:14 | INFO | train_inner | epoch 035:     22 / 32 loss=7.703, ppl=208.43, wps=28332.1, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=1100, lr=0.000137573, gnorm=0.814, loss_scale=32, train_wall=190, gb_free=9.9, wall=2582
2022-03-08 20:45:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:45:40 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.698 | ppl 207.71 | wps 52476 | wpb 510.9 | bsz 1 | num_updates 1110 | best_loss 7.698
2022-03-08 20:45:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1110 updates
2022-03-08 20:45:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:45:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:45:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 35 @ 1110 updates, score 7.698) (writing took 1.6079141339287162 seconds)
2022-03-08 20:45:41 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-08 20:45:41 | INFO | train | epoch 035 | loss 7.607 | ppl 194.9 | wps 28233.4 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1110 | lr 0.000138822 | gnorm 0.826 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2609
2022-03-08 20:45:41 | INFO | fairseq.trainer | begin training epoch 36
2022-03-08 20:45:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:46:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:46:54 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.664 | ppl 202.78 | wps 52221.4 | wpb 510.9 | bsz 1 | num_updates 1142 | best_loss 7.664
2022-03-08 20:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1142 updates
2022-03-08 20:46:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 36 @ 1142 updates, score 7.664) (writing took 1.571240953169763 seconds)
2022-03-08 20:46:55 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-08 20:46:55 | INFO | train | epoch 036 | loss 7.539 | ppl 185.92 | wps 28183.3 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1142 | lr 0.000142821 | gnorm 0.866 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2683
2022-03-08 20:46:56 | INFO | fairseq.trainer | begin training epoch 37
2022-03-08 20:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:48:08 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.624 | ppl 197.29 | wps 52407.9 | wpb 510.9 | bsz 1 | num_updates 1174 | best_loss 7.624
2022-03-08 20:48:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1174 updates
2022-03-08 20:48:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 37 @ 1174 updates, score 7.624) (writing took 1.579994972795248 seconds)
2022-03-08 20:48:09 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-08 20:48:09 | INFO | train | epoch 037 | loss 7.469 | ppl 177.15 | wps 28251 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1174 | lr 0.000146821 | gnorm 0.876 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2757
2022-03-08 20:48:09 | INFO | fairseq.trainer | begin training epoch 38
2022-03-08 20:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:49:05 | INFO | train_inner | epoch 038:     26 / 32 loss=7.486, ppl=179.33, wps=28318.4, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=1200, lr=0.00015007, gnorm=0.87, loss_scale=64, train_wall=190, gb_free=9.9, wall=2812
2022-03-08 20:49:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 20:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:49:22 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.589 | ppl 192.47 | wps 52216 | wpb 510.9 | bsz 1 | num_updates 1205 | best_loss 7.589
2022-03-08 20:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1205 updates
2022-03-08 20:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 38 @ 1205 updates, score 7.589) (writing took 1.5941324355080724 seconds)
2022-03-08 20:49:23 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-08 20:49:23 | INFO | train | epoch 038 | loss 7.399 | ppl 168.77 | wps 27349.6 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 1205 | lr 0.000150695 | gnorm 0.859 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2831
2022-03-08 20:49:23 | INFO | fairseq.trainer | begin training epoch 39
2022-03-08 20:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:50:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:50:36 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.554 | ppl 187.97 | wps 52354.2 | wpb 510.9 | bsz 1 | num_updates 1237 | best_loss 7.554
2022-03-08 20:50:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1237 updates
2022-03-08 20:50:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 39 @ 1237 updates, score 7.554) (writing took 1.5508372215554118 seconds)
2022-03-08 20:50:37 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-08 20:50:37 | INFO | train | epoch 039 | loss 7.329 | ppl 160.78 | wps 28214.6 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1237 | lr 0.000154694 | gnorm 0.805 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2905
2022-03-08 20:50:37 | INFO | fairseq.trainer | begin training epoch 40
2022-03-08 20:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:51:50 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.522 | ppl 183.83 | wps 51685.5 | wpb 510.9 | bsz 1 | num_updates 1269 | best_loss 7.522
2022-03-08 20:51:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1269 updates
2022-03-08 20:51:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:51:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:51:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 40 @ 1269 updates, score 7.522) (writing took 1.6051850020885468 seconds)
2022-03-08 20:51:51 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-08 20:51:51 | INFO | train | epoch 040 | loss 7.264 | ppl 153.65 | wps 28242.8 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1269 | lr 0.000158693 | gnorm 0.965 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 2979
2022-03-08 20:51:51 | INFO | fairseq.trainer | begin training epoch 41
2022-03-08 20:51:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:52:58 | INFO | train_inner | epoch 041:     31 / 32 loss=7.27, ppl=154.31, wps=28053.8, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=1300, lr=0.000162568, gnorm=0.879, loss_scale=32, train_wall=192, gb_free=9.9, wall=3045
2022-03-08 20:53:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:53:04 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.493 | ppl 180.11 | wps 51799.5 | wpb 510.9 | bsz 1 | num_updates 1301 | best_loss 7.493
2022-03-08 20:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1301 updates
2022-03-08 20:53:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:53:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 41 @ 1301 updates, score 7.493) (writing took 1.630035188049078 seconds)
2022-03-08 20:53:05 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-08 20:53:05 | INFO | train | epoch 041 | loss 7.193 | ppl 146.32 | wps 28203.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1301 | lr 0.000162692 | gnorm 0.876 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3053
2022-03-08 20:53:05 | INFO | fairseq.trainer | begin training epoch 42
2022-03-08 20:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:54:18 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.465 | ppl 176.66 | wps 51767.7 | wpb 510.9 | bsz 1 | num_updates 1333 | best_loss 7.465
2022-03-08 20:54:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 1333 updates
2022-03-08 20:54:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:54:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:54:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 42 @ 1333 updates, score 7.465) (writing took 1.6002883967012167 seconds)
2022-03-08 20:54:20 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-08 20:54:20 | INFO | train | epoch 042 | loss 7.121 | ppl 139.22 | wps 28190.7 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1333 | lr 0.000166692 | gnorm 0.808 | loss_scale 64 | train_wall 61 | gb_free 9.9 | wall 3127
2022-03-08 20:54:20 | INFO | fairseq.trainer | begin training epoch 43
2022-03-08 20:54:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:54:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 20:55:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:55:32 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.426 | ppl 172.02 | wps 51993.6 | wpb 510.9 | bsz 1 | num_updates 1364 | best_loss 7.426
2022-03-08 20:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 1364 updates
2022-03-08 20:55:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 43 @ 1364 updates, score 7.426) (writing took 1.6870957417413592 seconds)
2022-03-08 20:55:34 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-08 20:55:34 | INFO | train | epoch 043 | loss 7.058 | ppl 133.27 | wps 27258.2 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 1364 | lr 0.000170566 | gnorm 0.968 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3201
2022-03-08 20:55:34 | INFO | fairseq.trainer | begin training epoch 44
2022-03-08 20:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:56:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:56:46 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.389 | ppl 167.67 | wps 52378.8 | wpb 510.9 | bsz 1 | num_updates 1396 | best_loss 7.389
2022-03-08 20:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 1396 updates
2022-03-08 20:56:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:56:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 44 @ 1396 updates, score 7.389) (writing took 1.5949926357716322 seconds)
2022-03-08 20:56:48 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-08 20:56:48 | INFO | train | epoch 044 | loss 6.988 | ppl 126.93 | wps 28295.5 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1396 | lr 0.000174565 | gnorm 0.896 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3275
2022-03-08 20:56:48 | INFO | fairseq.trainer | begin training epoch 45
2022-03-08 20:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:56:56 | INFO | train_inner | epoch 045:      4 / 32 loss=7.051, ppl=132.61, wps=27330.5, ups=0.42, wpb=65198.4, bsz=127.4, num_updates=1400, lr=0.000175065, gnorm=0.887, loss_scale=32, train_wall=192, gb_free=9.9, wall=3284
2022-03-08 20:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:58:00 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.372 | ppl 165.65 | wps 52279.1 | wpb 510.9 | bsz 1 | num_updates 1428 | best_loss 7.372
2022-03-08 20:58:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 1428 updates
2022-03-08 20:58:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:58:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 45 @ 1428 updates, score 7.372) (writing took 1.5733957942575216 seconds)
2022-03-08 20:58:02 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-08 20:58:02 | INFO | train | epoch 045 | loss 6.918 | ppl 120.93 | wps 28186 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1428 | lr 0.000178564 | gnorm 0.891 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3349
2022-03-08 20:58:02 | INFO | fairseq.trainer | begin training epoch 46
2022-03-08 20:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 20:59:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 20:59:14 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.353 | ppl 163.43 | wps 52049.2 | wpb 510.9 | bsz 1 | num_updates 1460 | best_loss 7.353
2022-03-08 20:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 1460 updates
2022-03-08 20:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:59:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 20:59:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 46 @ 1460 updates, score 7.353) (writing took 1.5884110517799854 seconds)
2022-03-08 20:59:16 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-08 20:59:16 | INFO | train | epoch 046 | loss 6.849 | ppl 115.31 | wps 28171.1 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1460 | lr 0.000182564 | gnorm 0.853 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3423
2022-03-08 20:59:16 | INFO | fairseq.trainer | begin training epoch 47
2022-03-08 20:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:00:28 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.316 | ppl 159.38 | wps 52156.6 | wpb 510.9 | bsz 1 | num_updates 1492 | best_loss 7.316
2022-03-08 21:00:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 1492 updates
2022-03-08 21:00:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:00:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 47 @ 1492 updates, score 7.316) (writing took 1.5702780801802874 seconds)
2022-03-08 21:00:30 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-08 21:00:30 | INFO | train | epoch 047 | loss 6.783 | ppl 110.09 | wps 28210.8 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1492 | lr 0.000186563 | gnorm 0.907 | loss_scale 64 | train_wall 61 | gb_free 9.9 | wall 3497
2022-03-08 21:00:30 | INFO | fairseq.trainer | begin training epoch 48
2022-03-08 21:00:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:00:47 | INFO | train_inner | epoch 048:      8 / 32 loss=6.838, ppl=114.4, wps=28278.9, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=1500, lr=0.000187563, gnorm=0.882, loss_scale=64, train_wall=190, gb_free=9.9, wall=3514
2022-03-08 21:00:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 21:01:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:01:42 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.297 | ppl 157.24 | wps 52348.7 | wpb 510.9 | bsz 1 | num_updates 1523 | best_loss 7.297
2022-03-08 21:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 1523 updates
2022-03-08 21:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:01:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 48 @ 1523 updates, score 7.297) (writing took 1.5853263176977634 seconds)
2022-03-08 21:01:44 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-08 21:01:44 | INFO | train | epoch 048 | loss 6.712 | ppl 104.8 | wps 27396.1 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 1523 | lr 0.000190437 | gnorm 0.88 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3571
2022-03-08 21:01:44 | INFO | fairseq.trainer | begin training epoch 49
2022-03-08 21:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:02:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:02:56 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.288 | ppl 156.25 | wps 52156 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 7.288
2022-03-08 21:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 1555 updates
2022-03-08 21:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:02:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 49 @ 1555 updates, score 7.288) (writing took 1.5686676362529397 seconds)
2022-03-08 21:02:58 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-08 21:02:58 | INFO | train | epoch 049 | loss 6.649 | ppl 100.36 | wps 28157.5 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1555 | lr 0.000194436 | gnorm 0.897 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3645
2022-03-08 21:02:58 | INFO | fairseq.trainer | begin training epoch 50
2022-03-08 21:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:04:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:04:10 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.252 | ppl 152.45 | wps 51179.9 | wpb 510.9 | bsz 1 | num_updates 1587 | best_loss 7.252
2022-03-08 21:04:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 1587 updates
2022-03-08 21:04:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:04:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:04:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 50 @ 1587 updates, score 7.252) (writing took 1.6093720020726323 seconds)
2022-03-08 21:04:12 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-08 21:04:12 | INFO | train | epoch 050 | loss 6.582 | ppl 95.81 | wps 28178.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1587 | lr 0.000198435 | gnorm 0.9 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3719
2022-03-08 21:04:12 | INFO | fairseq.trainer | begin training epoch 51
2022-03-08 21:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:04:40 | INFO | train_inner | epoch 051:     13 / 32 loss=6.623, ppl=98.54, wps=28044.6, ups=0.43, wpb=65277, bsz=127.5, num_updates=1600, lr=0.00020006, gnorm=0.899, loss_scale=32, train_wall=192, gb_free=9.9, wall=3747
2022-03-08 21:05:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:05:24 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.258 | ppl 153.06 | wps 51893.7 | wpb 510.9 | bsz 1 | num_updates 1619 | best_loss 7.252
2022-03-08 21:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 1619 updates
2022-03-08 21:05:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:05:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:05:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt (epoch 51 @ 1619 updates, score 7.258) (writing took 0.701731950044632 seconds)
2022-03-08 21:05:25 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-08 21:05:25 | INFO | train | epoch 051 | loss 6.516 | ppl 91.51 | wps 28604.2 | ups 0.44 | wpb 65269.6 | bsz 127.5 | num_updates 1619 | lr 0.000202435 | gnorm 0.961 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3792
2022-03-08 21:05:25 | INFO | fairseq.trainer | begin training epoch 52
2022-03-08 21:05:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:06:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 21:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:06:37 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.23 | ppl 150.07 | wps 52198.7 | wpb 510.9 | bsz 1 | num_updates 1650 | best_loss 7.23
2022-03-08 21:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 1650 updates
2022-03-08 21:06:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:06:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:06:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 52 @ 1650 updates, score 7.23) (writing took 1.5574270775541663 seconds)
2022-03-08 21:06:39 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-08 21:06:39 | INFO | train | epoch 052 | loss 6.449 | ppl 87.36 | wps 27346 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 1650 | lr 0.000206309 | gnorm 0.888 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3866
2022-03-08 21:06:39 | INFO | fairseq.trainer | begin training epoch 53
2022-03-08 21:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:07:51 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.206 | ppl 147.64 | wps 52298.2 | wpb 510.9 | bsz 1 | num_updates 1682 | best_loss 7.206
2022-03-08 21:07:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 1682 updates
2022-03-08 21:07:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:07:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 53 @ 1682 updates, score 7.206) (writing took 1.569373408332467 seconds)
2022-03-08 21:07:53 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-08 21:07:53 | INFO | train | epoch 053 | loss 6.384 | ppl 83.54 | wps 28237.9 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1682 | lr 0.000210308 | gnorm 0.872 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 3940
2022-03-08 21:07:53 | INFO | fairseq.trainer | begin training epoch 54
2022-03-08 21:07:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:08:32 | INFO | train_inner | epoch 054:     18 / 32 loss=6.418, ppl=85.5, wps=28170.3, ups=0.43, wpb=65280.3, bsz=127.5, num_updates=1700, lr=0.000212558, gnorm=0.919, loss_scale=32, train_wall=192, gb_free=9.9, wall=3979
2022-03-08 21:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:09:06 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.197 | ppl 146.77 | wps 52266.8 | wpb 510.9 | bsz 1 | num_updates 1714 | best_loss 7.197
2022-03-08 21:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 1714 updates
2022-03-08 21:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:09:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 54 @ 1714 updates, score 7.197) (writing took 1.4947854969650507 seconds)
2022-03-08 21:09:07 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-08 21:09:07 | INFO | train | epoch 054 | loss 6.322 | ppl 80.03 | wps 28190.4 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1714 | lr 0.000214307 | gnorm 0.931 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4014
2022-03-08 21:09:07 | INFO | fairseq.trainer | begin training epoch 55
2022-03-08 21:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:10:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:10:19 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.191 | ppl 146.1 | wps 52312.8 | wpb 510.9 | bsz 1 | num_updates 1746 | best_loss 7.191
2022-03-08 21:10:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 1746 updates
2022-03-08 21:10:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:10:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:10:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 55 @ 1746 updates, score 7.191) (writing took 1.5911874063313007 seconds)
2022-03-08 21:10:21 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-08 21:10:21 | INFO | train | epoch 055 | loss 6.255 | ppl 76.38 | wps 28278.8 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1746 | lr 0.000218306 | gnorm 0.884 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4088
2022-03-08 21:10:21 | INFO | fairseq.trainer | begin training epoch 56
2022-03-08 21:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:11:33 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.18 | ppl 144.98 | wps 52255.5 | wpb 510.9 | bsz 1 | num_updates 1778 | best_loss 7.18
2022-03-08 21:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 1778 updates
2022-03-08 21:11:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:11:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 56 @ 1778 updates, score 7.18) (writing took 1.5685048094019294 seconds)
2022-03-08 21:11:35 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-08 21:11:35 | INFO | train | epoch 056 | loss 6.191 | ppl 73.06 | wps 28163.1 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1778 | lr 0.000222306 | gnorm 0.927 | loss_scale 64 | train_wall 61 | gb_free 9.9 | wall 4162
2022-03-08 21:11:35 | INFO | fairseq.trainer | begin training epoch 57
2022-03-08 21:11:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:11:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 21:12:24 | INFO | train_inner | epoch 057:     23 / 32 loss=6.215, ppl=74.31, wps=28051.2, ups=0.43, wpb=65283.6, bsz=127.5, num_updates=1800, lr=0.000225055, gnorm=0.912, loss_scale=32, train_wall=192, gb_free=9.9, wall=4212
2022-03-08 21:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:12:47 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.167 | ppl 143.72 | wps 52112.7 | wpb 510.9 | bsz 1 | num_updates 1809 | best_loss 7.167
2022-03-08 21:12:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 1809 updates
2022-03-08 21:12:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:12:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:12:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 57 @ 1809 updates, score 7.167) (writing took 1.5611855508759618 seconds)
2022-03-08 21:12:49 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-08 21:12:49 | INFO | train | epoch 057 | loss 6.13 | ppl 70.02 | wps 27355.8 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 1809 | lr 0.00022618 | gnorm 0.945 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4236
2022-03-08 21:12:49 | INFO | fairseq.trainer | begin training epoch 58
2022-03-08 21:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:13:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:14:02 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.181 | ppl 145.13 | wps 52213.7 | wpb 510.9 | bsz 1 | num_updates 1841 | best_loss 7.167
2022-03-08 21:14:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 1841 updates
2022-03-08 21:14:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:14:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt (epoch 58 @ 1841 updates, score 7.181) (writing took 0.6883495626971126 seconds)
2022-03-08 21:14:02 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-08 21:14:02 | INFO | train | epoch 058 | loss 6.068 | ppl 67.07 | wps 28514.8 | ups 0.44 | wpb 65269.6 | bsz 127.5 | num_updates 1841 | lr 0.000230179 | gnorm 0.943 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4310
2022-03-08 21:14:02 | INFO | fairseq.trainer | begin training epoch 59
2022-03-08 21:14:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:15:15 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.159 | ppl 142.95 | wps 52198.6 | wpb 510.9 | bsz 1 | num_updates 1873 | best_loss 7.159
2022-03-08 21:15:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 1873 updates
2022-03-08 21:15:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:15:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt
2022-03-08 21:15:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_best.pt (epoch 59 @ 1873 updates, score 7.159) (writing took 1.5578447002917528 seconds)
2022-03-08 21:15:16 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-08 21:15:16 | INFO | train | epoch 059 | loss 6.006 | ppl 64.28 | wps 28284.5 | ups 0.43 | wpb 65269.6 | bsz 127.5 | num_updates 1873 | lr 0.000234178 | gnorm 1.006 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4383
2022-03-08 21:15:16 | INFO | fairseq.trainer | begin training epoch 60
2022-03-08 21:15:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:16:14 | INFO | train_inner | epoch 060:     27 / 32 loss=6.021, ppl=64.95, wps=28419, ups=0.44, wpb=65277, bsz=127.5, num_updates=1900, lr=0.000237553, gnorm=0.964, loss_scale=32, train_wall=190, gb_free=9.9, wall=4441
2022-03-08 21:16:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:16:29 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.176 | ppl 144.63 | wps 52264.7 | wpb 510.9 | bsz 1 | num_updates 1905 | best_loss 7.159
2022-03-08 21:16:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 1905 updates
2022-03-08 21:16:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:16:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:16:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt (epoch 60 @ 1905 updates, score 7.176) (writing took 0.7027718322351575 seconds)
2022-03-08 21:16:29 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-08 21:16:29 | INFO | train | epoch 060 | loss 5.942 | ppl 61.49 | wps 28531.9 | ups 0.44 | wpb 65269.6 | bsz 127.5 | num_updates 1905 | lr 0.000238177 | gnorm 0.957 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4457
2022-03-08 21:16:29 | INFO | fairseq.trainer | begin training epoch 61
2022-03-08 21:16:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:17:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 21:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:17:42 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 7.176 | ppl 144.64 | wps 52250.7 | wpb 510.9 | bsz 1 | num_updates 1936 | best_loss 7.159
2022-03-08 21:17:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 1936 updates
2022-03-08 21:17:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:17:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:17:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt (epoch 61 @ 1936 updates, score 7.176) (writing took 0.7894651535898447 seconds)
2022-03-08 21:17:42 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-08 21:17:42 | INFO | train | epoch 061 | loss 5.884 | ppl 59.04 | wps 27661 | ups 0.42 | wpb 65261 | bsz 127.5 | num_updates 1936 | lr 0.000242052 | gnorm 0.99 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4530
2022-03-08 21:17:42 | INFO | fairseq.trainer | begin training epoch 62
2022-03-08 21:17:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 21:18:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 21:18:55 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 7.162 | ppl 143.2 | wps 52145.9 | wpb 510.9 | bsz 1 | num_updates 1968 | best_loss 7.159
2022-03-08 21:18:55 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-08 21:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 1968 updates
2022-03-08 21:18:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt
2022-03-08 21:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2_cleaned_full_cross_entropy_all_clara_mods_#1/checkpoint_last.pt (epoch 62 @ 1968 updates, score 7.162) (writing took 0.6959238955751061 seconds)
2022-03-08 21:18:56 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-08 21:18:56 | INFO | train | epoch 062 | loss 5.821 | ppl 56.54 | wps 28523.7 | ups 0.44 | wpb 65269.6 | bsz 127.5 | num_updates 1968 | lr 0.000246051 | gnorm 0.933 | loss_scale 32 | train_wall 61 | gb_free 9.9 | wall 4603
2022-03-08 21:18:56 | INFO | fairseq_cli.train | done training in 4603.0 seconds
