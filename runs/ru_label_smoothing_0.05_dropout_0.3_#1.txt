Sender: LSF System <lsfadmin@eu-g2-07>
Subject: Job 208068413: <ru_label_smoothing_0.05_dropout_0.3_#1> in cluster <euler> Done

Job <ru_label_smoothing_0.05_dropout_0.3_#1> was submitted from host <eu-login-45> by user <andriusb> in cluster <euler> at Sun Mar 13 12:01:28 2022
Job was executed on host(s) <eu-g2-07>, in queue <gpu.120h>, as user <andriusb> in cluster <euler> at Sun Mar 13 12:01:43 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar 13 12:01:43 2022
Terminated at Mon Mar 14 06:31:36 2022
Results reported at Mon Mar 14 06:31:36 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/ru --save-dir /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.3 --criterion label_smoothed_cross_entropy --label-smoothing 0.05 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --patience 3 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   70541.84 sec.
    Max Memory :                                 3739 MB
    Average Memory :                             2891.50 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               16261.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   66593 sec.
    Turnaround time :                            66608 sec.

The output (if any) follows:

2022-03-13 12:01:51 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.3, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/ru', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.05, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-13 12:01:51 | INFO | fairseq.tasks.language_modeling | dictionary: 35920 types
2022-03-13 12:01:52 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(35920, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=35920, bias=False)
  )
)
2022-03-13 12:01:52 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-13 12:01:52 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-13 12:01:52 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-13 12:01:52 | INFO | fairseq_cli.train | num. shared model params: 37,305,344 (num. trained: 37,305,344)
2022-03-13 12:01:52 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-13 12:01:52 | INFO | fairseq.data.data_utils | loaded 2,558 examples from: data-bin/ru/valid
2022-03-13 12:01:55 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-13 12:01:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 12:01:55 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-13 12:01:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-13 12:01:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-13 12:01:55 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-13 12:01:55 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 12:01:55 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 12:01:55 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-13 12:01:55 | INFO | fairseq.data.data_utils | loaded 53,136 examples from: data-bin/ru/train
2022-03-13 12:01:56 | INFO | fairseq.trainer | begin training epoch 1
2022-03-13 12:01:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:02:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-13 12:02:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:02:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 12:02:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-13 12:05:55 | INFO | train_inner | epoch 001:    104 / 407 loss=14.869, nll_loss=14.814, ppl=28810.4, wps=29690.7, ups=0.45, wpb=65536, bsz=128, num_updates=100, lr=1.25975e-05, gnorm=2.132, loss_scale=8, train_wall=214, gb_free=9.7, wall=240
2022-03-13 12:09:35 | INFO | train_inner | epoch 001:    204 / 407 loss=13.446, nll_loss=13.319, ppl=10219.4, wps=29791, ups=0.45, wpb=65536, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=0.623, loss_scale=16, train_wall=196, gb_free=9.7, wall=460
2022-03-13 12:13:16 | INFO | train_inner | epoch 001:    304 / 407 loss=12.607, nll_loss=12.427, ppl=5506.8, wps=29639.3, ups=0.45, wpb=65536, bsz=128, num_updates=300, lr=3.75925e-05, gnorm=0.389, loss_scale=32, train_wall=197, gb_free=9.7, wall=681
2022-03-13 12:16:59 | INFO | train_inner | epoch 001:    404 / 407 loss=12.191, nll_loss=11.966, ppl=3999.72, wps=29414.2, ups=0.45, wpb=65534.2, bsz=128, num_updates=400, lr=5.009e-05, gnorm=0.384, loss_scale=64, train_wall=199, gb_free=9.7, wall=904
2022-03-13 12:17:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:17:31 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.018 | nll_loss 11.77 | ppl 3491.28 | wps 51684.8 | wpb 511.9 | bsz 1 | num_updates 403
2022-03-13 12:17:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 403 updates
2022-03-13 12:17:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:17:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 1 @ 403 updates, score 12.018) (writing took 2.145693862985354 seconds)
2022-03-13 12:17:33 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-13 12:17:33 | INFO | train | epoch 001 | loss 13.27 | nll_loss 13.123 | ppl 8920.95 | wps 28720 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 403 | lr 5.04649e-05 | gnorm 0.879 | loss_scale 64 | train_wall 813 | gb_free 9.7 | wall 938
2022-03-13 12:17:33 | INFO | fairseq.trainer | begin training epoch 2
2022-03-13 12:17:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:19:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:21:11 | INFO | train_inner | epoch 002:     98 / 407 loss=12.013, nll_loss=11.766, ppl=3482.17, wps=25893.7, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=500, lr=6.25875e-05, gnorm=0.402, loss_scale=32, train_wall=200, gb_free=9.7, wall=1156
2022-03-13 12:24:54 | INFO | train_inner | epoch 002:    198 / 407 loss=11.791, nll_loss=11.526, ppl=2948.76, wps=29380.8, ups=0.45, wpb=65536, bsz=128, num_updates=600, lr=7.5085e-05, gnorm=0.44, loss_scale=64, train_wall=199, gb_free=9.7, wall=1379
2022-03-13 12:27:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:28:39 | INFO | train_inner | epoch 002:    299 / 407 loss=11.505, nll_loss=11.218, ppl=2382.08, wps=29118, ups=0.44, wpb=65536, bsz=128, num_updates=700, lr=8.75825e-05, gnorm=0.439, loss_scale=32, train_wall=201, gb_free=9.7, wall=1604
2022-03-13 12:32:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:32:23 | INFO | train_inner | epoch 002:    400 / 407 loss=11.171, nll_loss=10.86, ppl=1857.97, wps=29286.4, ups=0.45, wpb=65536, bsz=128, num_updates=800, lr=0.00010008, gnorm=0.509, loss_scale=32, train_wall=200, gb_free=9.7, wall=1828
2022-03-13 12:32:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:33:04 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 10.781 | nll_loss 10.434 | ppl 1383.03 | wps 52257.8 | wpb 511.9 | bsz 1 | num_updates 807 | best_loss 10.781
2022-03-13 12:33:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 807 updates
2022-03-13 12:33:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:33:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:33:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 2 @ 807 updates, score 10.781) (writing took 2.187048234976828 seconds)
2022-03-13 12:33:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-13 12:33:06 | INFO | train | epoch 002 | loss 11.606 | nll_loss 11.327 | ppl 2568.96 | wps 28355.4 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 807 | lr 0.000100955 | gnorm 0.448 | loss_scale 32 | train_wall 808 | gb_free 9.7 | wall 1871
2022-03-13 12:33:06 | INFO | fairseq.trainer | begin training epoch 3
2022-03-13 12:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:36:32 | INFO | train_inner | epoch 003:     93 / 407 loss=10.834, nll_loss=10.494, ppl=1441.95, wps=26281.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=900, lr=0.000112578, gnorm=0.522, loss_scale=32, train_wall=197, gb_free=9.7, wall=2077
2022-03-13 12:37:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:40:14 | INFO | train_inner | epoch 003:    194 / 407 loss=10.585, nll_loss=10.221, ppl=1193.89, wps=29458.1, ups=0.45, wpb=65536, bsz=128, num_updates=1000, lr=0.000125075, gnorm=0.511, loss_scale=32, train_wall=198, gb_free=9.7, wall=2299
2022-03-13 12:43:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:43:58 | INFO | train_inner | epoch 003:    295 / 407 loss=10.371, nll_loss=9.987, ppl=1014.48, wps=29291.2, ups=0.45, wpb=65536, bsz=128, num_updates=1100, lr=0.000137573, gnorm=0.581, loss_scale=32, train_wall=200, gb_free=9.7, wall=2523
2022-03-13 12:47:39 | INFO | train_inner | epoch 003:    395 / 407 loss=10.173, nll_loss=9.769, ppl=872.27, wps=29636, ups=0.45, wpb=65536, bsz=128, num_updates=1200, lr=0.00015007, gnorm=0.578, loss_scale=32, train_wall=197, gb_free=9.7, wall=2744
2022-03-13 12:47:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 12:48:31 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 9.86 | nll_loss 9.42 | ppl 684.93 | wps 51726.4 | wpb 511.9 | bsz 1 | num_updates 1211 | best_loss 9.86
2022-03-13 12:48:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1211 updates
2022-03-13 12:48:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:48:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 12:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 3 @ 1211 updates, score 9.86) (writing took 2.2460374779766425 seconds)
2022-03-13 12:48:33 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-13 12:48:33 | INFO | train | epoch 003 | loss 10.471 | nll_loss 10.095 | ppl 1093.98 | wps 28531.5 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 1211 | lr 0.000151445 | gnorm 0.554 | loss_scale 32 | train_wall 802 | gb_free 9.7 | wall 2798
2022-03-13 12:48:33 | INFO | fairseq.trainer | begin training epoch 4
2022-03-13 12:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 12:51:51 | INFO | train_inner | epoch 004:     89 / 407 loss=9.972, nll_loss=9.549, ppl=749.21, wps=25932.5, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=1300, lr=0.000162568, gnorm=0.635, loss_scale=32, train_wall=200, gb_free=9.7, wall=2996
2022-03-13 12:53:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:55:34 | INFO | train_inner | epoch 004:    190 / 407 loss=9.79, nll_loss=9.351, ppl=653.04, wps=29347.9, ups=0.45, wpb=65536, bsz=128, num_updates=1400, lr=0.000175065, gnorm=0.663, loss_scale=32, train_wall=199, gb_free=9.7, wall=3219
2022-03-13 12:58:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 12:59:18 | INFO | train_inner | epoch 004:    291 / 407 loss=9.611, nll_loss=9.155, ppl=570.14, wps=29355.9, ups=0.45, wpb=65536, bsz=128, num_updates=1500, lr=0.000187563, gnorm=0.657, loss_scale=32, train_wall=199, gb_free=9.7, wall=3443
2022-03-13 13:02:59 | INFO | train_inner | epoch 004:    391 / 407 loss=9.439, nll_loss=8.967, ppl=500.46, wps=29596.6, ups=0.45, wpb=65536, bsz=128, num_updates=1600, lr=0.00020006, gnorm=0.673, loss_scale=32, train_wall=198, gb_free=9.7, wall=3664
2022-03-13 13:03:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:04:00 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 9.117 | nll_loss 8.598 | ppl 387.51 | wps 51305.9 | wpb 511.9 | bsz 1 | num_updates 1616 | best_loss 9.117
2022-03-13 13:04:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1616 updates
2022-03-13 13:04:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 4 @ 1616 updates, score 9.117) (writing took 2.2937382829841226 seconds)
2022-03-13 13:04:02 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-13 13:04:02 | INFO | train | epoch 004 | loss 9.68 | nll_loss 9.231 | ppl 600.71 | wps 28565.4 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 1616 | lr 0.00020206 | gnorm 0.658 | loss_scale 64 | train_wall 803 | gb_free 9.7 | wall 3727
2022-03-13 13:04:02 | INFO | fairseq.trainer | begin training epoch 5
2022-03-13 13:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:04:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:07:10 | INFO | train_inner | epoch 005:     85 / 407 loss=9.271, nll_loss=8.784, ppl=440.74, wps=26068.4, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=1700, lr=0.000212558, gnorm=0.685, loss_scale=32, train_wall=198, gb_free=9.7, wall=3915
2022-03-13 13:09:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:10:51 | INFO | train_inner | epoch 005:    186 / 407 loss=9.123, nll_loss=8.621, ppl=393.69, wps=29564, ups=0.45, wpb=65536, bsz=128, num_updates=1800, lr=0.000225055, gnorm=0.705, loss_scale=32, train_wall=198, gb_free=9.7, wall=4136
2022-03-13 13:14:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:14:36 | INFO | train_inner | epoch 005:    287 / 407 loss=8.978, nll_loss=8.462, ppl=352.67, wps=29193.7, ups=0.45, wpb=65534.2, bsz=128, num_updates=1900, lr=0.000237553, gnorm=0.689, loss_scale=32, train_wall=200, gb_free=9.7, wall=4361
2022-03-13 13:18:17 | INFO | train_inner | epoch 005:    387 / 407 loss=8.859, nll_loss=8.332, ppl=322.17, wps=29684.7, ups=0.45, wpb=65536, bsz=128, num_updates=2000, lr=0.00025005, gnorm=0.69, loss_scale=32, train_wall=197, gb_free=9.7, wall=4582
2022-03-13 13:18:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:19:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:19:26 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.559 | nll_loss 7.982 | ppl 252.83 | wps 52005.7 | wpb 511.9 | bsz 1 | num_updates 2019 | best_loss 8.559
2022-03-13 13:19:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2019 updates
2022-03-13 13:19:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:19:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 5 @ 2019 updates, score 8.559) (writing took 2.1563444880302995 seconds)
2022-03-13 13:19:28 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-13 13:19:28 | INFO | train | epoch 005 | loss 9.033 | nll_loss 8.523 | ppl 367.77 | wps 28507.2 | ups 0.44 | wpb 65492.3 | bsz 127.9 | num_updates 2019 | lr 0.000252425 | gnorm 0.693 | loss_scale 32 | train_wall 801 | gb_free 9.7 | wall 4653
2022-03-13 13:19:28 | INFO | fairseq.trainer | begin training epoch 6
2022-03-13 13:19:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:21:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:22:28 | INFO | train_inner | epoch 006:     82 / 407 loss=8.716, nll_loss=8.177, ppl=289.34, wps=25996.4, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=2100, lr=0.000262548, gnorm=0.7, loss_scale=16, train_wall=199, gb_free=9.7, wall=4833
2022-03-13 13:26:09 | INFO | train_inner | epoch 006:    182 / 407 loss=8.591, nll_loss=8.04, ppl=263.12, wps=29616.7, ups=0.45, wpb=65536, bsz=128, num_updates=2200, lr=0.000275045, gnorm=0.675, loss_scale=16, train_wall=197, gb_free=9.7, wall=5054
2022-03-13 13:29:51 | INFO | train_inner | epoch 006:    282 / 407 loss=8.495, nll_loss=7.935, ppl=244.65, wps=29614.2, ups=0.45, wpb=65536, bsz=128, num_updates=2300, lr=0.000287543, gnorm=0.686, loss_scale=32, train_wall=197, gb_free=9.7, wall=5276
2022-03-13 13:31:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:33:35 | INFO | train_inner | epoch 006:    383 / 407 loss=8.399, nll_loss=7.829, ppl=227.46, wps=29195, ups=0.45, wpb=65536, bsz=128, num_updates=2400, lr=0.00030004, gnorm=0.664, loss_scale=32, train_wall=200, gb_free=9.7, wall=5500
2022-03-13 13:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:34:54 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 8.142 | nll_loss 7.518 | ppl 183.28 | wps 51621.9 | wpb 511.9 | bsz 1 | num_updates 2424 | best_loss 8.142
2022-03-13 13:34:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2424 updates
2022-03-13 13:34:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:34:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:34:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 6 @ 2424 updates, score 8.142) (writing took 2.1872752319904976 seconds)
2022-03-13 13:34:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-13 13:34:56 | INFO | train | epoch 006 | loss 8.529 | nll_loss 7.971 | ppl 250.91 | wps 28563.1 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 2424 | lr 0.000303039 | gnorm 0.674 | loss_scale 32 | train_wall 803 | gb_free 9.7 | wall 5581
2022-03-13 13:34:56 | INFO | fairseq.trainer | begin training epoch 7
2022-03-13 13:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:36:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:37:47 | INFO | train_inner | epoch 007:     77 / 407 loss=8.278, nll_loss=7.698, ppl=207.62, wps=25990.8, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=2500, lr=0.000312538, gnorm=0.648, loss_scale=32, train_wall=199, gb_free=9.7, wall=5752
2022-03-13 13:38:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 13:41:30 | INFO | train_inner | epoch 007:    178 / 407 loss=8.207, nll_loss=7.62, ppl=196.68, wps=29310.3, ups=0.45, wpb=65536, bsz=128, num_updates=2600, lr=0.000325035, gnorm=0.658, loss_scale=16, train_wall=199, gb_free=9.7, wall=5975
2022-03-13 13:45:13 | INFO | train_inner | epoch 007:    278 / 407 loss=8.135, nll_loss=7.541, ppl=186.23, wps=29442.6, ups=0.45, wpb=65536, bsz=128, num_updates=2700, lr=0.000337533, gnorm=0.633, loss_scale=32, train_wall=199, gb_free=9.7, wall=6198
2022-03-13 13:47:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:48:58 | INFO | train_inner | epoch 007:    379 / 407 loss=8.06, nll_loss=7.46, ppl=176.02, wps=29085.1, ups=0.44, wpb=65536, bsz=128, num_updates=2800, lr=0.00035003, gnorm=0.629, loss_scale=32, train_wall=201, gb_free=9.7, wall=6423
2022-03-13 13:49:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 13:50:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.83 | nll_loss 7.174 | ppl 144.4 | wps 51429.3 | wpb 511.9 | bsz 1 | num_updates 2828 | best_loss 7.83
2022-03-13 13:50:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2828 updates
2022-03-13 13:50:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:50:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 13:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 7 @ 2828 updates, score 7.83) (writing took 2.1892630160436966 seconds)
2022-03-13 13:50:28 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-13 13:50:28 | INFO | train | epoch 007 | loss 8.148 | nll_loss 7.556 | ppl 188.24 | wps 28413.9 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 2828 | lr 0.000353529 | gnorm 0.642 | loss_scale 32 | train_wall 806 | gb_free 9.7 | wall 6513
2022-03-13 13:50:28 | INFO | fairseq.trainer | begin training epoch 8
2022-03-13 13:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 13:53:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 13:53:09 | INFO | train_inner | epoch 008:     73 / 407 loss=7.958, nll_loss=7.35, ppl=163.15, wps=26035.1, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=2900, lr=0.000362528, gnorm=0.604, loss_scale=32, train_wall=199, gb_free=9.7, wall=6674
2022-03-13 13:56:50 | INFO | train_inner | epoch 008:    173 / 407 loss=7.898, nll_loss=7.285, ppl=155.91, wps=29668.9, ups=0.45, wpb=65534.2, bsz=128, num_updates=3000, lr=0.000375025, gnorm=0.604, loss_scale=32, train_wall=197, gb_free=9.7, wall=6895
2022-03-13 13:57:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 14:00:34 | INFO | train_inner | epoch 008:    274 / 407 loss=7.847, nll_loss=7.23, ppl=150.09, wps=29317.4, ups=0.45, wpb=65536, bsz=128, num_updates=3100, lr=0.000387523, gnorm=0.596, loss_scale=32, train_wall=199, gb_free=9.7, wall=7119
2022-03-13 14:00:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:04:16 | INFO | train_inner | epoch 008:    375 / 407 loss=7.793, nll_loss=7.171, ppl=144.14, wps=29453.7, ups=0.45, wpb=65536, bsz=128, num_updates=3200, lr=0.00040002, gnorm=0.581, loss_scale=16, train_wall=198, gb_free=9.7, wall=7341
2022-03-13 14:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:05:53 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.581 | nll_loss 6.907 | ppl 120 | wps 52321.8 | wpb 511.9 | bsz 1 | num_updates 3232 | best_loss 7.581
2022-03-13 14:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3232 updates
2022-03-13 14:05:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:05:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 8 @ 3232 updates, score 7.581) (writing took 2.242957124952227 seconds)
2022-03-13 14:05:55 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-13 14:05:55 | INFO | train | epoch 008 | loss 7.854 | nll_loss 7.237 | ppl 150.83 | wps 28528 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 3232 | lr 0.000404019 | gnorm 0.597 | loss_scale 32 | train_wall 802 | gb_free 9.7 | wall 7440
2022-03-13 14:05:55 | INFO | fairseq.trainer | begin training epoch 9
2022-03-13 14:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:08:27 | INFO | train_inner | epoch 009:     68 / 407 loss=7.7, nll_loss=7.07, ppl=134.39, wps=26096.6, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=3300, lr=0.000412518, gnorm=0.59, loss_scale=32, train_wall=199, gb_free=9.7, wall=7592
2022-03-13 14:10:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 14:12:11 | INFO | train_inner | epoch 009:    169 / 407 loss=7.641, nll_loss=7.007, ppl=128.6, wps=29256.2, ups=0.45, wpb=65536, bsz=128, num_updates=3400, lr=0.000425015, gnorm=0.562, loss_scale=32, train_wall=200, gb_free=9.7, wall=7816
2022-03-13 14:13:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:15:53 | INFO | train_inner | epoch 009:    270 / 407 loss=7.597, nll_loss=6.96, ppl=124.46, wps=29406.9, ups=0.45, wpb=65536, bsz=128, num_updates=3500, lr=0.000437513, gnorm=0.561, loss_scale=16, train_wall=199, gb_free=9.7, wall=8039
2022-03-13 14:19:35 | INFO | train_inner | epoch 009:    370 / 407 loss=7.547, nll_loss=6.906, ppl=119.89, wps=29543.1, ups=0.45, wpb=65536, bsz=128, num_updates=3600, lr=0.00045001, gnorm=0.555, loss_scale=32, train_wall=198, gb_free=9.7, wall=8260
2022-03-13 14:19:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:20:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:21:23 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.33 | nll_loss 6.632 | ppl 99.2 | wps 51976.7 | wpb 511.9 | bsz 1 | num_updates 3636 | best_loss 7.33
2022-03-13 14:21:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3636 updates
2022-03-13 14:21:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:21:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:21:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 9 @ 3636 updates, score 7.33) (writing took 2.2311212240019813 seconds)
2022-03-13 14:21:25 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-13 14:21:25 | INFO | train | epoch 009 | loss 7.602 | nll_loss 6.964 | ppl 124.89 | wps 28444 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 3636 | lr 0.000454509 | gnorm 0.562 | loss_scale 16 | train_wall 805 | gb_free 9.7 | wall 8370
2022-03-13 14:21:25 | INFO | fairseq.trainer | begin training epoch 10
2022-03-13 14:21:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:23:46 | INFO | train_inner | epoch 010:     64 / 407 loss=7.456, nll_loss=6.808, ppl=112.02, wps=26084.6, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=3700, lr=0.000462508, gnorm=0.55, loss_scale=16, train_wall=198, gb_free=9.7, wall=8511
2022-03-13 14:27:27 | INFO | train_inner | epoch 010:    164 / 407 loss=7.408, nll_loss=6.755, ppl=108, wps=29620.5, ups=0.45, wpb=65536, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.543, loss_scale=32, train_wall=197, gb_free=9.7, wall=8732
2022-03-13 14:29:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:31:12 | INFO | train_inner | epoch 010:    265 / 407 loss=7.371, nll_loss=6.716, ppl=105.1, wps=29171.6, ups=0.45, wpb=65536, bsz=128, num_updates=3900, lr=0.000487503, gnorm=0.536, loss_scale=16, train_wall=201, gb_free=9.7, wall=8957
2022-03-13 14:34:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:34:55 | INFO | train_inner | epoch 010:    366 / 407 loss=7.329, nll_loss=6.67, ppl=101.85, wps=29312.3, ups=0.45, wpb=65534.2, bsz=128, num_updates=4000, lr=0.0005, gnorm=0.524, loss_scale=16, train_wall=200, gb_free=9.7, wall=9180
2022-03-13 14:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:36:51 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.122 | nll_loss 6.405 | ppl 84.74 | wps 52941.2 | wpb 511.9 | bsz 1 | num_updates 4041 | best_loss 7.122
2022-03-13 14:36:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4041 updates
2022-03-13 14:36:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:36:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 10 @ 4041 updates, score 7.122) (writing took 2.217482727020979 seconds)
2022-03-13 14:36:53 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-13 14:36:53 | INFO | train | epoch 010 | loss 7.371 | nll_loss 6.716 | ppl 105.13 | wps 28582.7 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 4041 | lr 0.000497457 | gnorm 0.536 | loss_scale 16 | train_wall 803 | gb_free 9.7 | wall 9298
2022-03-13 14:36:53 | INFO | fairseq.trainer | begin training epoch 11
2022-03-13 14:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:39:03 | INFO | train_inner | epoch 011:     59 / 407 loss=7.245, nll_loss=6.581, ppl=95.71, wps=26350.2, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4100, lr=0.000493865, gnorm=0.532, loss_scale=16, train_wall=197, gb_free=9.7, wall=9428
2022-03-13 14:40:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:42:45 | INFO | train_inner | epoch 011:    160 / 407 loss=7.198, nll_loss=6.529, ppl=92.32, wps=29592.9, ups=0.45, wpb=65536, bsz=128, num_updates=4200, lr=0.00048795, gnorm=0.515, loss_scale=16, train_wall=197, gb_free=9.7, wall=9650
2022-03-13 14:46:27 | INFO | train_inner | epoch 011:    260 / 407 loss=7.155, nll_loss=6.483, ppl=89.47, wps=29529, ups=0.45, wpb=65536, bsz=128, num_updates=4300, lr=0.000482243, gnorm=0.505, loss_scale=32, train_wall=198, gb_free=9.7, wall=9872
2022-03-13 14:49:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:50:14 | INFO | train_inner | epoch 011:    361 / 407 loss=7.135, nll_loss=6.462, ppl=88.17, wps=28804, ups=0.44, wpb=65534.2, bsz=128, num_updates=4400, lr=0.000476731, gnorm=0.517, loss_scale=16, train_wall=203, gb_free=9.7, wall=10099
2022-03-13 14:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 14:52:23 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.956 | nll_loss 6.222 | ppl 74.65 | wps 51855.8 | wpb 511.9 | bsz 1 | num_updates 4446 | best_loss 6.956
2022-03-13 14:52:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4446 updates
2022-03-13 14:52:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:52:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 14:52:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 11 @ 4446 updates, score 6.956) (writing took 2.2098469639895484 seconds)
2022-03-13 14:52:25 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-13 14:52:25 | INFO | train | epoch 011 | loss 7.164 | nll_loss 6.493 | ppl 90.04 | wps 28465.2 | ups 0.43 | wpb 65492.6 | bsz 127.9 | num_updates 4446 | lr 0.000474259 | gnorm 0.514 | loss_scale 16 | train_wall 807 | gb_free 9.7 | wall 10230
2022-03-13 14:52:25 | INFO | fairseq.trainer | begin training epoch 12
2022-03-13 14:52:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 14:54:24 | INFO | train_inner | epoch 012:     54 / 407 loss=7.062, nll_loss=6.383, ppl=83.44, wps=26201, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4500, lr=0.000471405, gnorm=0.491, loss_scale=32, train_wall=197, gb_free=9.7, wall=10349
2022-03-13 14:55:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 14:58:06 | INFO | train_inner | epoch 012:    155 / 407 loss=7.013, nll_loss=6.33, ppl=80.47, wps=29522.6, ups=0.45, wpb=65534.2, bsz=128, num_updates=4600, lr=0.000466252, gnorm=0.485, loss_scale=16, train_wall=198, gb_free=9.7, wall=10571
2022-03-13 15:01:47 | INFO | train_inner | epoch 012:    255 / 407 loss=7.007, nll_loss=6.324, ppl=80.13, wps=29681, ups=0.45, wpb=65536, bsz=128, num_updates=4700, lr=0.000461266, gnorm=0.492, loss_scale=32, train_wall=197, gb_free=9.7, wall=10792
2022-03-13 15:04:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:05:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 15:05:32 | INFO | train_inner | epoch 012:    357 / 407 loss=6.984, nll_loss=6.299, ppl=78.75, wps=29049.4, ups=0.44, wpb=65536, bsz=128, num_updates=4800, lr=0.000456435, gnorm=0.475, loss_scale=16, train_wall=201, gb_free=9.7, wall=11017
2022-03-13 15:07:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:07:47 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.85 | nll_loss 6.103 | ppl 68.75 | wps 51873.9 | wpb 511.9 | bsz 1 | num_updates 4850 | best_loss 6.85
2022-03-13 15:07:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 4850 updates
2022-03-13 15:07:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 12 @ 4850 updates, score 6.85) (writing took 2.228962433000561 seconds)
2022-03-13 15:07:49 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-13 15:07:49 | INFO | train | epoch 012 | loss 7.001 | nll_loss 6.318 | ppl 79.76 | wps 28630.7 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 4850 | lr 0.000454077 | gnorm 0.485 | loss_scale 16 | train_wall 799 | gb_free 9.7 | wall 11154
2022-03-13 15:07:49 | INFO | fairseq.trainer | begin training epoch 13
2022-03-13 15:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:09:40 | INFO | train_inner | epoch 013:     50 / 407 loss=6.93, nll_loss=6.241, ppl=75.65, wps=26393.5, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=4900, lr=0.000451754, gnorm=0.488, loss_scale=16, train_wall=196, gb_free=9.7, wall=11265
2022-03-13 15:13:21 | INFO | train_inner | epoch 013:    150 / 407 loss=6.884, nll_loss=6.192, ppl=73.11, wps=29621.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=5000, lr=0.000447214, gnorm=0.473, loss_scale=32, train_wall=197, gb_free=9.7, wall=11486
2022-03-13 15:15:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:17:04 | INFO | train_inner | epoch 013:    251 / 407 loss=6.883, nll_loss=6.19, ppl=73.02, wps=29386.9, ups=0.45, wpb=65536, bsz=128, num_updates=5100, lr=0.000442807, gnorm=0.472, loss_scale=32, train_wall=199, gb_free=9.7, wall=11709
2022-03-13 15:20:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:20:47 | INFO | train_inner | epoch 013:    352 / 407 loss=6.867, nll_loss=6.174, ppl=72.2, wps=29334.6, ups=0.45, wpb=65536, bsz=128, num_updates=5200, lr=0.000438529, gnorm=0.47, loss_scale=32, train_wall=199, gb_free=9.7, wall=11933
2022-03-13 15:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:23:14 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.763 | nll_loss 6.013 | ppl 64.58 | wps 52517.1 | wpb 511.9 | bsz 1 | num_updates 5255 | best_loss 6.763
2022-03-13 15:23:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5255 updates
2022-03-13 15:23:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 13 @ 5255 updates, score 6.763) (writing took 2.5547960699768737 seconds)
2022-03-13 15:23:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-13 15:23:17 | INFO | train | epoch 013 | loss 6.876 | nll_loss 6.183 | ppl 72.66 | wps 28590.9 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 5255 | lr 0.000436228 | gnorm 0.474 | loss_scale 32 | train_wall 803 | gb_free 9.7 | wall 12082
2022-03-13 15:23:17 | INFO | fairseq.trainer | begin training epoch 14
2022-03-13 15:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:24:58 | INFO | train_inner | epoch 014:     45 / 407 loss=6.818, nll_loss=6.121, ppl=69.6, wps=26124.9, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=5300, lr=0.000434372, gnorm=0.476, loss_scale=32, train_wall=198, gb_free=9.7, wall=12183
2022-03-13 15:25:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:28:44 | INFO | train_inner | epoch 014:    146 / 407 loss=6.78, nll_loss=6.079, ppl=67.6, wps=28956.8, ups=0.44, wpb=65536, bsz=128, num_updates=5400, lr=0.000430331, gnorm=0.468, loss_scale=32, train_wall=202, gb_free=9.7, wall=12409
2022-03-13 15:30:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:32:27 | INFO | train_inner | epoch 014:    247 / 407 loss=6.78, nll_loss=6.08, ppl=67.66, wps=29383.9, ups=0.45, wpb=65536, bsz=128, num_updates=5500, lr=0.000426401, gnorm=0.466, loss_scale=32, train_wall=199, gb_free=9.7, wall=12632
2022-03-13 15:35:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:36:09 | INFO | train_inner | epoch 014:    348 / 407 loss=6.776, nll_loss=6.076, ppl=67.45, wps=29483.6, ups=0.45, wpb=65536, bsz=128, num_updates=5600, lr=0.000422577, gnorm=0.459, loss_scale=32, train_wall=198, gb_free=9.7, wall=12854
2022-03-13 15:38:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:38:45 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.695 | nll_loss 5.937 | ppl 61.29 | wps 52419.3 | wpb 511.9 | bsz 1 | num_updates 5659 | best_loss 6.695
2022-03-13 15:38:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 5659 updates
2022-03-13 15:38:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:38:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:38:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 14 @ 5659 updates, score 6.695) (writing took 2.2162562249577604 seconds)
2022-03-13 15:38:48 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-13 15:38:48 | INFO | train | epoch 014 | loss 6.776 | nll_loss 6.076 | ppl 67.45 | wps 28430.3 | ups 0.43 | wpb 65492.5 | bsz 127.9 | num_updates 5659 | lr 0.000420368 | gnorm 0.466 | loss_scale 32 | train_wall 806 | gb_free 9.7 | wall 13013
2022-03-13 15:38:48 | INFO | fairseq.trainer | begin training epoch 15
2022-03-13 15:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:40:19 | INFO | train_inner | epoch 015:     41 / 407 loss=6.737, nll_loss=6.034, ppl=65.52, wps=26160.3, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=5700, lr=0.000418854, gnorm=0.465, loss_scale=32, train_wall=198, gb_free=9.7, wall=13104
2022-03-13 15:40:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:44:04 | INFO | train_inner | epoch 015:    142 / 407 loss=6.707, nll_loss=6.001, ppl=64.03, wps=29129.9, ups=0.44, wpb=65536, bsz=128, num_updates=5800, lr=0.000415227, gnorm=0.467, loss_scale=32, train_wall=201, gb_free=9.7, wall=13329
2022-03-13 15:45:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:47:47 | INFO | train_inner | epoch 015:    243 / 407 loss=6.698, nll_loss=5.992, ppl=63.64, wps=29470, ups=0.45, wpb=65536, bsz=128, num_updates=5900, lr=0.000411693, gnorm=0.464, loss_scale=32, train_wall=198, gb_free=9.7, wall=13552
2022-03-13 15:50:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:51:29 | INFO | train_inner | epoch 015:    344 / 407 loss=6.693, nll_loss=5.986, ppl=63.39, wps=29487.8, ups=0.45, wpb=65534.2, bsz=128, num_updates=6000, lr=0.000408248, gnorm=0.465, loss_scale=32, train_wall=198, gb_free=9.7, wall=13774
2022-03-13 15:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 15:54:12 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.632 | nll_loss 5.869 | ppl 58.45 | wps 52530 | wpb 511.9 | bsz 1 | num_updates 6063 | best_loss 6.632
2022-03-13 15:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6063 updates
2022-03-13 15:54:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:54:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 15:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 15 @ 6063 updates, score 6.632) (writing took 2.1418834979995154 seconds)
2022-03-13 15:54:14 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-13 15:54:14 | INFO | train | epoch 015 | loss 6.696 | nll_loss 5.989 | ppl 63.52 | wps 28561.5 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 6063 | lr 0.000406122 | gnorm 0.465 | loss_scale 32 | train_wall 802 | gb_free 9.7 | wall 13939
2022-03-13 15:54:14 | INFO | fairseq.trainer | begin training epoch 16
2022-03-13 15:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 15:55:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 15:55:38 | INFO | train_inner | epoch 016:     38 / 407 loss=6.655, nll_loss=5.945, ppl=61.62, wps=26271.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6100, lr=0.000404888, gnorm=0.466, loss_scale=32, train_wall=197, gb_free=9.7, wall=14023
2022-03-13 15:59:18 | INFO | train_inner | epoch 016:    138 / 407 loss=6.629, nll_loss=5.917, ppl=60.44, wps=29757.9, ups=0.45, wpb=65534.2, bsz=128, num_updates=6200, lr=0.00040161, gnorm=0.464, loss_scale=32, train_wall=196, gb_free=9.7, wall=14243
2022-03-13 15:59:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:03:00 | INFO | train_inner | epoch 016:    239 / 407 loss=6.633, nll_loss=5.922, ppl=60.63, wps=29463.6, ups=0.45, wpb=65536, bsz=128, num_updates=6300, lr=0.00039841, gnorm=0.455, loss_scale=32, train_wall=198, gb_free=9.7, wall=14465
2022-03-13 16:04:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:06:42 | INFO | train_inner | epoch 016:    340 / 407 loss=6.622, nll_loss=5.91, ppl=60.13, wps=29584.1, ups=0.45, wpb=65536, bsz=128, num_updates=6400, lr=0.000395285, gnorm=0.46, loss_scale=32, train_wall=198, gb_free=9.7, wall=14687
2022-03-13 16:09:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:09:35 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.579 | nll_loss 5.813 | ppl 56.22 | wps 52435.1 | wpb 511.9 | bsz 1 | num_updates 6467 | best_loss 6.579
2022-03-13 16:09:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6467 updates
2022-03-13 16:09:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:09:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:09:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 16 @ 6467 updates, score 6.579) (writing took 2.1891182719846256 seconds)
2022-03-13 16:09:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-13 16:09:38 | INFO | train | epoch 016 | loss 6.626 | nll_loss 5.914 | ppl 60.31 | wps 28649.5 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 6467 | lr 0.000393232 | gnorm 0.459 | loss_scale 32 | train_wall 799 | gb_free 9.7 | wall 14863
2022-03-13 16:09:38 | INFO | fairseq.trainer | begin training epoch 17
2022-03-13 16:09:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:09:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:10:52 | INFO | train_inner | epoch 017:     34 / 407 loss=6.604, nll_loss=5.891, ppl=59.34, wps=26094, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6500, lr=0.000392232, gnorm=0.453, loss_scale=32, train_wall=199, gb_free=9.7, wall=14937
2022-03-13 16:14:32 | INFO | train_inner | epoch 017:    134 / 407 loss=6.562, nll_loss=5.845, ppl=57.48, wps=29833.6, ups=0.46, wpb=65534.2, bsz=128, num_updates=6600, lr=0.000389249, gnorm=0.455, loss_scale=32, train_wall=196, gb_free=9.7, wall=15157
2022-03-13 16:14:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:18:15 | INFO | train_inner | epoch 017:    235 / 407 loss=6.567, nll_loss=5.851, ppl=57.71, wps=29340.9, ups=0.45, wpb=65536, bsz=128, num_updates=6700, lr=0.000386334, gnorm=0.458, loss_scale=32, train_wall=199, gb_free=9.7, wall=15380
2022-03-13 16:19:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:22:00 | INFO | train_inner | epoch 017:    336 / 407 loss=6.568, nll_loss=5.852, ppl=57.77, wps=29121.9, ups=0.44, wpb=65536, bsz=128, num_updates=6800, lr=0.000383482, gnorm=0.466, loss_scale=32, train_wall=201, gb_free=9.7, wall=15605
2022-03-13 16:23:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 16:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:25:03 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.533 | nll_loss 5.763 | ppl 54.31 | wps 52889.3 | wpb 511.9 | bsz 1 | num_updates 6870 | best_loss 6.533
2022-03-13 16:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 6870 updates
2022-03-13 16:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:25:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 17 @ 6870 updates, score 6.533) (writing took 2.193281523010228 seconds)
2022-03-13 16:25:05 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-13 16:25:05 | INFO | train | epoch 017 | loss 6.567 | nll_loss 5.85 | ppl 57.69 | wps 28447.2 | ups 0.43 | wpb 65492.3 | bsz 127.9 | num_updates 6870 | lr 0.000381524 | gnorm 0.46 | loss_scale 16 | train_wall 803 | gb_free 9.7 | wall 15790
2022-03-13 16:25:05 | INFO | fairseq.trainer | begin training epoch 18
2022-03-13 16:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:26:12 | INFO | train_inner | epoch 018:     30 / 407 loss=6.547, nll_loss=5.829, ppl=56.86, wps=26001.1, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=6900, lr=0.000380693, gnorm=0.464, loss_scale=16, train_wall=200, gb_free=9.7, wall=15857
2022-03-13 16:29:51 | INFO | train_inner | epoch 018:    130 / 407 loss=6.506, nll_loss=5.784, ppl=55.12, wps=29925.2, ups=0.46, wpb=65534.2, bsz=128, num_updates=7000, lr=0.000377964, gnorm=0.451, loss_scale=32, train_wall=195, gb_free=9.7, wall=16076
2022-03-13 16:33:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:33:33 | INFO | train_inner | epoch 018:    231 / 407 loss=6.518, nll_loss=5.798, ppl=55.63, wps=29460.2, ups=0.45, wpb=65536, bsz=128, num_updates=7100, lr=0.000375293, gnorm=0.458, loss_scale=32, train_wall=198, gb_free=9.7, wall=16298
2022-03-13 16:37:16 | INFO | train_inner | epoch 018:    331 / 407 loss=6.517, nll_loss=5.797, ppl=55.59, wps=29419.9, ups=0.45, wpb=65536, bsz=128, num_updates=7200, lr=0.000372678, gnorm=0.461, loss_scale=32, train_wall=199, gb_free=9.7, wall=16521
2022-03-13 16:38:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:40:32 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.494 | nll_loss 5.723 | ppl 52.8 | wps 51695.3 | wpb 511.9 | bsz 1 | num_updates 7275 | best_loss 6.494
2022-03-13 16:40:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 7275 updates
2022-03-13 16:40:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:40:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:40:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 18 @ 7275 updates, score 6.494) (writing took 2.151944754004944 seconds)
2022-03-13 16:40:34 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-13 16:40:34 | INFO | train | epoch 018 | loss 6.514 | nll_loss 5.794 | ppl 55.49 | wps 28568.2 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 7275 | lr 0.000370752 | gnorm 0.461 | loss_scale 32 | train_wall 803 | gb_free 9.7 | wall 16719
2022-03-13 16:40:34 | INFO | fairseq.trainer | begin training epoch 19
2022-03-13 16:40:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:41:29 | INFO | train_inner | epoch 019:     25 / 407 loss=6.511, nll_loss=5.79, ppl=55.33, wps=25823.5, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=7300, lr=0.000370117, gnorm=0.47, loss_scale=32, train_wall=201, gb_free=9.7, wall=16774
2022-03-13 16:43:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:45:12 | INFO | train_inner | epoch 019:    126 / 407 loss=6.46, nll_loss=5.735, ppl=53.25, wps=29424.3, ups=0.45, wpb=65536, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.457, loss_scale=32, train_wall=199, gb_free=9.7, wall=16997
2022-03-13 16:48:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:48:53 | INFO | train_inner | epoch 019:    227 / 407 loss=6.464, nll_loss=5.739, ppl=53.42, wps=29575.2, ups=0.45, wpb=65534.2, bsz=128, num_updates=7500, lr=0.000365148, gnorm=0.459, loss_scale=32, train_wall=198, gb_free=9.7, wall=17218
2022-03-13 16:52:33 | INFO | train_inner | epoch 019:    327 / 407 loss=6.476, nll_loss=5.753, ppl=53.93, wps=29806.4, ups=0.45, wpb=65536, bsz=128, num_updates=7600, lr=0.000362738, gnorm=0.46, loss_scale=32, train_wall=196, gb_free=9.7, wall=17438
2022-03-13 16:52:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:55:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 16:55:55 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.465 | nll_loss 5.692 | ppl 51.7 | wps 51661.2 | wpb 511.9 | bsz 1 | num_updates 7679 | best_loss 6.465
2022-03-13 16:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 7679 updates
2022-03-13 16:55:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:55:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 16:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 19 @ 7679 updates, score 6.465) (writing took 2.130554611037951 seconds)
2022-03-13 16:55:58 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-13 16:55:58 | INFO | train | epoch 019 | loss 6.468 | nll_loss 5.744 | ppl 53.61 | wps 28646.2 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 7679 | lr 0.000360867 | gnorm 0.457 | loss_scale 32 | train_wall 799 | gb_free 9.7 | wall 17643
2022-03-13 16:55:58 | INFO | fairseq.trainer | begin training epoch 20
2022-03-13 16:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 16:56:43 | INFO | train_inner | epoch 020:     21 / 407 loss=6.464, nll_loss=5.74, ppl=53.44, wps=26151.7, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=7700, lr=0.000360375, gnorm=0.453, loss_scale=32, train_wall=198, gb_free=9.7, wall=17688
2022-03-13 16:58:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 16:58:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:00:26 | INFO | train_inner | epoch 020:    123 / 407 loss=6.411, nll_loss=5.682, ppl=51.34, wps=29385.1, ups=0.45, wpb=65534.2, bsz=128, num_updates=7800, lr=0.000358057, gnorm=0.459, loss_scale=16, train_wall=199, gb_free=9.7, wall=17911
2022-03-13 17:04:06 | INFO | train_inner | epoch 020:    223 / 407 loss=6.432, nll_loss=5.705, ppl=52.16, wps=29778.2, ups=0.45, wpb=65536, bsz=128, num_updates=7900, lr=0.000355784, gnorm=0.454, loss_scale=32, train_wall=196, gb_free=9.7, wall=18131
2022-03-13 17:07:46 | INFO | train_inner | epoch 020:    323 / 407 loss=6.435, nll_loss=5.708, ppl=52.29, wps=29786.3, ups=0.45, wpb=65536, bsz=128, num_updates=8000, lr=0.000353553, gnorm=0.453, loss_scale=32, train_wall=196, gb_free=9.7, wall=18351
2022-03-13 17:07:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:11:19 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.441 | nll_loss 5.663 | ppl 50.68 | wps 50981.4 | wpb 511.9 | bsz 1 | num_updates 8083 | best_loss 6.441
2022-03-13 17:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 8083 updates
2022-03-13 17:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:11:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 20 @ 8083 updates, score 6.441) (writing took 2.2140430840081535 seconds)
2022-03-13 17:11:22 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-13 17:11:22 | INFO | train | epoch 020 | loss 6.427 | nll_loss 5.7 | ppl 51.98 | wps 28633.8 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 8083 | lr 0.000351733 | gnorm 0.457 | loss_scale 32 | train_wall 798 | gb_free 9.7 | wall 18567
2022-03-13 17:11:22 | INFO | fairseq.trainer | begin training epoch 21
2022-03-13 17:11:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:11:59 | INFO | train_inner | epoch 021:     17 / 407 loss=6.424, nll_loss=5.697, ppl=51.88, wps=25817.9, ups=0.39, wpb=65361.9, bsz=127.7, num_updates=8100, lr=0.000351364, gnorm=0.464, loss_scale=32, train_wall=201, gb_free=9.7, wall=18604
2022-03-13 17:13:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:15:46 | INFO | train_inner | epoch 021:    118 / 407 loss=6.372, nll_loss=5.64, ppl=49.88, wps=28883, ups=0.44, wpb=65536, bsz=128, num_updates=8200, lr=0.000349215, gnorm=0.459, loss_scale=32, train_wall=203, gb_free=9.7, wall=18831
2022-03-13 17:17:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:19:27 | INFO | train_inner | epoch 021:    219 / 407 loss=6.395, nll_loss=5.665, ppl=50.76, wps=29694.8, ups=0.45, wpb=65536, bsz=128, num_updates=8300, lr=0.000347105, gnorm=0.457, loss_scale=32, train_wall=197, gb_free=9.7, wall=19052
2022-03-13 17:22:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:23:05 | INFO | train_inner | epoch 021:    320 / 407 loss=6.393, nll_loss=5.664, ppl=50.69, wps=30059.2, ups=0.46, wpb=65536, bsz=128, num_updates=8400, lr=0.000345033, gnorm=0.455, loss_scale=32, train_wall=194, gb_free=9.7, wall=19270
2022-03-13 17:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:26:38 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.413 | nll_loss 5.636 | ppl 49.73 | wps 53316.8 | wpb 511.9 | bsz 1 | num_updates 8487 | best_loss 6.413
2022-03-13 17:26:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 8487 updates
2022-03-13 17:26:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:26:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:26:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 21 @ 8487 updates, score 6.413) (writing took 2.2021192190004513 seconds)
2022-03-13 17:26:40 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-13 17:26:40 | INFO | train | epoch 021 | loss 6.39 | nll_loss 5.66 | ppl 50.55 | wps 28802.1 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 8487 | lr 0.00034326 | gnorm 0.456 | loss_scale 32 | train_wall 795 | gb_free 9.7 | wall 19485
2022-03-13 17:26:40 | INFO | fairseq.trainer | begin training epoch 22
2022-03-13 17:26:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:27:08 | INFO | train_inner | epoch 022:     13 / 407 loss=6.397, nll_loss=5.668, ppl=50.85, wps=26869, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=8500, lr=0.000342997, gnorm=0.454, loss_scale=32, train_wall=192, gb_free=9.7, wall=19513
2022-03-13 17:27:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:29:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:30:49 | INFO | train_inner | epoch 022:    115 / 407 loss=6.343, nll_loss=5.609, ppl=48.8, wps=29700.3, ups=0.45, wpb=65536, bsz=128, num_updates=8600, lr=0.000340997, gnorm=0.462, loss_scale=16, train_wall=196, gb_free=9.7, wall=19734
2022-03-13 17:34:25 | INFO | train_inner | epoch 022:    215 / 407 loss=6.353, nll_loss=5.62, ppl=49.18, wps=30338.1, ups=0.46, wpb=65534.2, bsz=128, num_updates=8700, lr=0.000339032, gnorm=0.459, loss_scale=32, train_wall=192, gb_free=9.7, wall=19950
2022-03-13 17:38:02 | INFO | train_inner | epoch 022:    315 / 407 loss=6.367, nll_loss=5.635, ppl=49.7, wps=30260, ups=0.46, wpb=65536, bsz=128, num_updates=8800, lr=0.0003371, gnorm=0.453, loss_scale=32, train_wall=193, gb_free=9.7, wall=20167
2022-03-13 17:38:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 17:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:41:47 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.396 | nll_loss 5.615 | ppl 49 | wps 52804.3 | wpb 511.9 | bsz 1 | num_updates 8891 | best_loss 6.396
2022-03-13 17:41:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 8891 updates
2022-03-13 17:41:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:41:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 22 @ 8891 updates, score 6.396) (writing took 2.18170488497708 seconds)
2022-03-13 17:41:49 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-13 17:41:49 | INFO | train | epoch 022 | loss 6.357 | nll_loss 5.624 | ppl 49.32 | wps 29123.9 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 8891 | lr 0.00033537 | gnorm 0.458 | loss_scale 32 | train_wall 784 | gb_free 9.7 | wall 20394
2022-03-13 17:41:49 | INFO | fairseq.trainer | begin training epoch 23
2022-03-13 17:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:42:08 | INFO | train_inner | epoch 023:      9 / 407 loss=6.361, nll_loss=5.63, ppl=49.51, wps=26472.8, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=8900, lr=0.000335201, gnorm=0.46, loss_scale=32, train_wall=195, gb_free=9.7, wall=20413
2022-03-13 17:43:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:45:48 | INFO | train_inner | epoch 023:    110 / 407 loss=6.308, nll_loss=5.571, ppl=47.55, wps=29838.5, ups=0.46, wpb=65536, bsz=128, num_updates=9000, lr=0.000333333, gnorm=0.456, loss_scale=16, train_wall=196, gb_free=9.7, wall=20633
2022-03-13 17:49:24 | INFO | train_inner | epoch 023:    210 / 407 loss=6.32, nll_loss=5.584, ppl=47.96, wps=30297.3, ups=0.46, wpb=65536, bsz=128, num_updates=9100, lr=0.000331497, gnorm=0.463, loss_scale=32, train_wall=193, gb_free=9.7, wall=20849
2022-03-13 17:51:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 17:53:05 | INFO | train_inner | epoch 023:    311 / 407 loss=6.348, nll_loss=5.614, ppl=48.99, wps=29761.5, ups=0.45, wpb=65534.2, bsz=128, num_updates=9200, lr=0.00032969, gnorm=0.456, loss_scale=16, train_wall=196, gb_free=9.7, wall=21070
2022-03-13 17:56:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 17:56:57 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.373 | nll_loss 5.592 | ppl 48.24 | wps 53276.8 | wpb 511.9 | bsz 1 | num_updates 9296 | best_loss 6.373
2022-03-13 17:56:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 9296 updates
2022-03-13 17:56:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:56:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 17:56:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 23 @ 9296 updates, score 6.373) (writing took 2.2298078699968755 seconds)
2022-03-13 17:56:59 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-13 17:56:59 | INFO | train | epoch 023 | loss 6.327 | nll_loss 5.591 | ppl 48.21 | wps 29134.4 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 9296 | lr 0.000327983 | gnorm 0.459 | loss_scale 32 | train_wall 786 | gb_free 9.7 | wall 21304
2022-03-13 17:56:59 | INFO | fairseq.trainer | begin training epoch 24
2022-03-13 17:56:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 17:57:08 | INFO | train_inner | epoch 024:      4 / 407 loss=6.33, nll_loss=5.595, ppl=48.34, wps=26873.9, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=9300, lr=0.000327913, gnorm=0.462, loss_scale=32, train_wall=192, gb_free=9.7, wall=21313
2022-03-13 18:00:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:00:46 | INFO | train_inner | epoch 024:    105 / 407 loss=6.279, nll_loss=5.54, ppl=46.52, wps=29992.5, ups=0.46, wpb=65534.2, bsz=128, num_updates=9400, lr=0.000326164, gnorm=0.467, loss_scale=16, train_wall=194, gb_free=9.7, wall=21531
2022-03-13 18:04:22 | INFO | train_inner | epoch 024:    205 / 407 loss=6.295, nll_loss=5.557, ppl=47.08, wps=30408.9, ups=0.46, wpb=65536, bsz=128, num_updates=9500, lr=0.000324443, gnorm=0.46, loss_scale=16, train_wall=192, gb_free=9.7, wall=21747
2022-03-13 18:08:00 | INFO | train_inner | epoch 024:    305 / 407 loss=6.307, nll_loss=5.57, ppl=47.51, wps=30014.5, ups=0.46, wpb=65536, bsz=128, num_updates=9600, lr=0.000322749, gnorm=0.457, loss_scale=32, train_wall=195, gb_free=9.7, wall=21965
2022-03-13 18:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:11:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:11:40 | INFO | train_inner | epoch 024:    407 / 407 loss=6.317, nll_loss=5.581, ppl=47.88, wps=29712.5, ups=0.45, wpb=65361.9, bsz=127.7, num_updates=9700, lr=0.000321081, gnorm=0.453, loss_scale=16, train_wall=196, gb_free=9.7, wall=22185
2022-03-13 18:11:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:12:05 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.354 | nll_loss 5.57 | ppl 47.49 | wps 53524.7 | wpb 511.9 | bsz 1 | num_updates 9700 | best_loss 6.354
2022-03-13 18:12:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 9700 updates
2022-03-13 18:12:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:12:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:12:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 24 @ 9700 updates, score 6.354) (writing took 2.210411751992069 seconds)
2022-03-13 18:12:07 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-13 18:12:07 | INFO | train | epoch 024 | loss 6.299 | nll_loss 5.562 | ppl 47.23 | wps 29132.2 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 9700 | lr 0.000321081 | gnorm 0.459 | loss_scale 16 | train_wall 784 | gb_free 9.7 | wall 22212
2022-03-13 18:12:07 | INFO | fairseq.trainer | begin training epoch 25
2022-03-13 18:12:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:15:59 | INFO | train_inner | epoch 025:    100 / 407 loss=6.251, nll_loss=5.509, ppl=45.55, wps=25290.6, ups=0.39, wpb=65534.2, bsz=128, num_updates=9800, lr=0.000319438, gnorm=0.46, loss_scale=16, train_wall=208, gb_free=9.7, wall=22444
2022-03-13 18:19:52 | INFO | train_inner | epoch 025:    200 / 407 loss=6.263, nll_loss=5.523, ppl=45.98, wps=28162.7, ups=0.43, wpb=65536, bsz=128, num_updates=9900, lr=0.000317821, gnorm=0.461, loss_scale=32, train_wall=209, gb_free=9.7, wall=22677
2022-03-13 18:22:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:23:49 | INFO | train_inner | epoch 025:    301 / 407 loss=6.288, nll_loss=5.55, ppl=46.85, wps=27625.2, ups=0.42, wpb=65536, bsz=128, num_updates=10000, lr=0.000316228, gnorm=0.462, loss_scale=32, train_wall=213, gb_free=9.7, wall=22914
2022-03-13 18:27:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:27:47 | INFO | train_inner | epoch 025:    402 / 407 loss=6.287, nll_loss=5.549, ppl=46.82, wps=27540.3, ups=0.42, wpb=65536, bsz=128, num_updates=10100, lr=0.000314658, gnorm=0.456, loss_scale=32, train_wall=214, gb_free=9.7, wall=23152
2022-03-13 18:27:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:28:25 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.337 | nll_loss 5.552 | ppl 46.92 | wps 50236.7 | wpb 511.9 | bsz 1 | num_updates 10105 | best_loss 6.337
2022-03-13 18:28:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 10105 updates
2022-03-13 18:28:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:28:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 25 @ 10105 updates, score 6.337) (writing took 2.1657763300463557 seconds)
2022-03-13 18:28:27 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-13 18:28:27 | INFO | train | epoch 025 | loss 6.272 | nll_loss 5.533 | ppl 46.3 | wps 27068.1 | ups 0.41 | wpb 65492.6 | bsz 127.9 | num_updates 10105 | lr 0.000314581 | gnorm 0.46 | loss_scale 32 | train_wall 854 | gb_free 9.7 | wall 23192
2022-03-13 18:28:27 | INFO | fairseq.trainer | begin training epoch 26
2022-03-13 18:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:32:13 | INFO | train_inner | epoch 026:     95 / 407 loss=6.23, nll_loss=5.487, ppl=44.84, wps=24628.6, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=10200, lr=0.000313112, gnorm=0.467, loss_scale=32, train_wall=213, gb_free=9.7, wall=23418
2022-03-13 18:32:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:36:10 | INFO | train_inner | epoch 026:    196 / 407 loss=6.248, nll_loss=5.506, ppl=45.46, wps=27589.7, ups=0.42, wpb=65536, bsz=128, num_updates=10300, lr=0.000311588, gnorm=0.461, loss_scale=32, train_wall=213, gb_free=9.7, wall=23655
2022-03-13 18:37:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:40:08 | INFO | train_inner | epoch 026:    297 / 407 loss=6.247, nll_loss=5.505, ppl=45.42, wps=27557.1, ups=0.42, wpb=65534.2, bsz=128, num_updates=10400, lr=0.000310087, gnorm=0.458, loss_scale=32, train_wall=214, gb_free=9.7, wall=23893
2022-03-13 18:42:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:44:03 | INFO | train_inner | epoch 026:    398 / 407 loss=6.268, nll_loss=5.528, ppl=46.15, wps=27893.9, ups=0.43, wpb=65536, bsz=128, num_updates=10500, lr=0.000308607, gnorm=0.457, loss_scale=32, train_wall=211, gb_free=9.7, wall=24128
2022-03-13 18:44:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 18:44:51 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.328 | nll_loss 5.543 | ppl 46.61 | wps 49415.6 | wpb 511.9 | bsz 1 | num_updates 10509 | best_loss 6.328
2022-03-13 18:44:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 10509 updates
2022-03-13 18:44:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:44:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 18:44:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 26 @ 10509 updates, score 6.328) (writing took 2.230256629001815 seconds)
2022-03-13 18:44:53 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-13 18:44:53 | INFO | train | epoch 026 | loss 6.249 | nll_loss 5.507 | ppl 45.49 | wps 26842 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 10509 | lr 0.000308475 | gnorm 0.46 | loss_scale 32 | train_wall 859 | gb_free 9.7 | wall 24178
2022-03-13 18:44:53 | INFO | fairseq.trainer | begin training epoch 27
2022-03-13 18:44:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 18:48:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 18:48:28 | INFO | train_inner | epoch 027:     92 / 407 loss=6.215, nll_loss=5.47, ppl=44.33, wps=24665, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=10600, lr=0.000307148, gnorm=0.467, loss_scale=32, train_wall=212, gb_free=9.7, wall=24393
2022-03-13 18:48:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:52:22 | INFO | train_inner | epoch 027:    193 / 407 loss=6.227, nll_loss=5.484, ppl=44.75, wps=27959.6, ups=0.43, wpb=65536, bsz=128, num_updates=10700, lr=0.000305709, gnorm=0.464, loss_scale=16, train_wall=210, gb_free=9.7, wall=24627
2022-03-13 18:55:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 18:56:18 | INFO | train_inner | epoch 027:    294 / 407 loss=6.222, nll_loss=5.478, ppl=44.57, wps=27799.8, ups=0.42, wpb=65536, bsz=128, num_updates=10800, lr=0.00030429, gnorm=0.462, loss_scale=16, train_wall=212, gb_free=9.7, wall=24863
2022-03-13 19:00:12 | INFO | train_inner | epoch 027:    394 / 407 loss=6.25, nll_loss=5.509, ppl=45.54, wps=28055.7, ups=0.43, wpb=65536, bsz=128, num_updates=10900, lr=0.000302891, gnorm=0.461, loss_scale=16, train_wall=210, gb_free=9.7, wall=25097
2022-03-13 19:00:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:01:08 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.309 | nll_loss 5.52 | ppl 45.89 | wps 50805.1 | wpb 511.9 | bsz 1 | num_updates 10913 | best_loss 6.309
2022-03-13 19:01:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 10913 updates
2022-03-13 19:01:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:01:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 27 @ 10913 updates, score 6.309) (writing took 2.172328475979157 seconds)
2022-03-13 19:01:10 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-13 19:01:10 | INFO | train | epoch 027 | loss 6.227 | nll_loss 5.483 | ppl 44.73 | wps 27069 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 10913 | lr 0.000302711 | gnorm 0.463 | loss_scale 16 | train_wall 852 | gb_free 9.7 | wall 25156
2022-03-13 19:01:11 | INFO | fairseq.trainer | begin training epoch 28
2022-03-13 19:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:03:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:04:36 | INFO | train_inner | epoch 028:     88 / 407 loss=6.181, nll_loss=5.434, ppl=43.22, wps=24723.7, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=11000, lr=0.000301511, gnorm=0.467, loss_scale=16, train_wall=212, gb_free=9.7, wall=25361
2022-03-13 19:08:31 | INFO | train_inner | epoch 028:    188 / 407 loss=6.196, nll_loss=5.45, ppl=43.72, wps=27930.1, ups=0.43, wpb=65536, bsz=128, num_updates=11100, lr=0.00030015, gnorm=0.459, loss_scale=16, train_wall=211, gb_free=9.7, wall=25596
2022-03-13 19:09:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:12:29 | INFO | train_inner | epoch 028:    289 / 407 loss=6.221, nll_loss=5.478, ppl=44.56, wps=27491.6, ups=0.42, wpb=65536, bsz=128, num_updates=11200, lr=0.000298807, gnorm=0.466, loss_scale=16, train_wall=214, gb_free=9.7, wall=25834
2022-03-13 19:16:23 | INFO | train_inner | epoch 028:    389 / 407 loss=6.22, nll_loss=5.476, ppl=44.52, wps=27966.8, ups=0.43, wpb=65536, bsz=128, num_updates=11300, lr=0.000297482, gnorm=0.466, loss_scale=32, train_wall=211, gb_free=9.7, wall=26068
2022-03-13 19:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:17:33 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.295 | nll_loss 5.506 | ppl 45.45 | wps 49343.3 | wpb 511.9 | bsz 1 | num_updates 11318 | best_loss 6.295
2022-03-13 19:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 11318 updates
2022-03-13 19:17:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:17:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:17:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 28 @ 11318 updates, score 6.295) (writing took 2.15048770501744 seconds)
2022-03-13 19:17:35 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-13 19:17:35 | INFO | train | epoch 028 | loss 6.206 | nll_loss 5.461 | ppl 44.04 | wps 26944.9 | ups 0.41 | wpb 65492.6 | bsz 127.9 | num_updates 11318 | lr 0.000297245 | gnorm 0.465 | loss_scale 32 | train_wall 858 | gb_free 9.7 | wall 26140
2022-03-13 19:17:35 | INFO | fairseq.trainer | begin training epoch 29
2022-03-13 19:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:20:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:20:50 | INFO | train_inner | epoch 029:     83 / 407 loss=6.175, nll_loss=5.427, ppl=43.02, wps=24517.7, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=11400, lr=0.000296174, gnorm=0.464, loss_scale=32, train_wall=213, gb_free=9.7, wall=26335
2022-03-13 19:24:46 | INFO | train_inner | epoch 029:    183 / 407 loss=6.193, nll_loss=5.447, ppl=43.62, wps=27737.1, ups=0.42, wpb=65534.2, bsz=128, num_updates=11500, lr=0.000294884, gnorm=0.464, loss_scale=32, train_wall=212, gb_free=9.7, wall=26571
2022-03-13 19:25:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:26:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:28:49 | INFO | train_inner | epoch 029:    285 / 407 loss=6.179, nll_loss=5.432, ppl=43.17, wps=26940.6, ups=0.41, wpb=65536, bsz=128, num_updates=11600, lr=0.00029361, gnorm=0.465, loss_scale=16, train_wall=219, gb_free=9.7, wall=26814
2022-03-13 19:32:44 | INFO | train_inner | epoch 029:    385 / 407 loss=6.202, nll_loss=5.457, ppl=43.93, wps=27891.4, ups=0.43, wpb=65536, bsz=128, num_updates=11700, lr=0.000292353, gnorm=0.463, loss_scale=32, train_wall=211, gb_free=9.7, wall=27049
2022-03-13 19:33:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:34:03 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.286 | nll_loss 5.495 | ppl 45.11 | wps 48474.3 | wpb 511.9 | bsz 1 | num_updates 11721 | best_loss 6.286
2022-03-13 19:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 11721 updates
2022-03-13 19:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 29 @ 11721 updates, score 6.286) (writing took 2.2775647310190834 seconds)
2022-03-13 19:34:05 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-13 19:34:05 | INFO | train | epoch 029 | loss 6.187 | nll_loss 5.44 | ppl 43.41 | wps 26652.2 | ups 0.41 | wpb 65492.3 | bsz 127.9 | num_updates 11721 | lr 0.000292091 | gnorm 0.464 | loss_scale 16 | train_wall 863 | gb_free 9.7 | wall 27130
2022-03-13 19:34:05 | INFO | fairseq.trainer | begin training epoch 30
2022-03-13 19:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:37:08 | INFO | train_inner | epoch 030:     79 / 407 loss=6.164, nll_loss=5.415, ppl=42.68, wps=24762.2, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=11800, lr=0.000291111, gnorm=0.465, loss_scale=16, train_wall=210, gb_free=9.7, wall=27313
2022-03-13 19:40:57 | INFO | train_inner | epoch 030:    179 / 407 loss=6.154, nll_loss=5.404, ppl=42.36, wps=28673, ups=0.44, wpb=65536, bsz=128, num_updates=11900, lr=0.000289886, gnorm=0.464, loss_scale=32, train_wall=205, gb_free=9.7, wall=27542
2022-03-13 19:41:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:45:01 | INFO | train_inner | epoch 030:    280 / 407 loss=6.176, nll_loss=5.429, ppl=43.07, wps=26902.5, ups=0.41, wpb=65536, bsz=128, num_updates=12000, lr=0.000288675, gnorm=0.464, loss_scale=16, train_wall=219, gb_free=9.7, wall=27786
2022-03-13 19:46:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 19:48:57 | INFO | train_inner | epoch 030:    381 / 407 loss=6.182, nll_loss=5.436, ppl=43.28, wps=27688.7, ups=0.42, wpb=65534.2, bsz=128, num_updates=12100, lr=0.00028748, gnorm=0.473, loss_scale=16, train_wall=213, gb_free=9.7, wall=28022
2022-03-13 19:50:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 19:50:27 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.277 | nll_loss 5.486 | ppl 44.82 | wps 48616.4 | wpb 511.9 | bsz 1 | num_updates 12126 | best_loss 6.277
2022-03-13 19:50:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 12126 updates
2022-03-13 19:50:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:50:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 19:50:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 30 @ 12126 updates, score 6.277) (writing took 2.176443852018565 seconds)
2022-03-13 19:50:30 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-13 19:50:30 | INFO | train | epoch 030 | loss 6.169 | nll_loss 5.42 | ppl 42.83 | wps 26942.4 | ups 0.41 | wpb 65492.6 | bsz 127.9 | num_updates 12126 | lr 0.000287171 | gnorm 0.466 | loss_scale 16 | train_wall 857 | gb_free 9.7 | wall 28115
2022-03-13 19:50:30 | INFO | fairseq.trainer | begin training epoch 31
2022-03-13 19:50:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 19:53:23 | INFO | train_inner | epoch 031:     74 / 407 loss=6.133, nll_loss=5.382, ppl=41.69, wps=24620.3, ups=0.38, wpb=65360.1, bsz=127.7, num_updates=12200, lr=0.000286299, gnorm=0.474, loss_scale=32, train_wall=212, gb_free=9.7, wall=28288
2022-03-13 19:57:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 19:57:24 | INFO | train_inner | epoch 031:    175 / 407 loss=6.145, nll_loss=5.395, ppl=42.07, wps=27156.5, ups=0.41, wpb=65536, bsz=128, num_updates=12300, lr=0.000285133, gnorm=0.462, loss_scale=32, train_wall=217, gb_free=9.7, wall=28529
2022-03-13 20:01:16 | INFO | train_inner | epoch 031:    275 / 407 loss=6.161, nll_loss=5.412, ppl=42.57, wps=28302, ups=0.43, wpb=65536, bsz=128, num_updates=12400, lr=0.000283981, gnorm=0.469, loss_scale=32, train_wall=208, gb_free=9.7, wall=28761
2022-03-13 20:02:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:05:16 | INFO | train_inner | epoch 031:    376 / 407 loss=6.171, nll_loss=5.424, ppl=42.92, wps=27301.9, ups=0.42, wpb=65536, bsz=128, num_updates=12500, lr=0.000282843, gnorm=0.467, loss_scale=32, train_wall=216, gb_free=9.7, wall=29001
2022-03-13 20:06:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:06:57 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.263 | nll_loss 5.474 | ppl 44.44 | wps 48386 | wpb 511.9 | bsz 1 | num_updates 12531 | best_loss 6.263
2022-03-13 20:06:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 12531 updates
2022-03-13 20:06:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:06:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:07:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 31 @ 12531 updates, score 6.263) (writing took 2.175489748013206 seconds)
2022-03-13 20:07:00 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-13 20:07:00 | INFO | train | epoch 031 | loss 6.151 | nll_loss 5.402 | ppl 42.28 | wps 26795.5 | ups 0.41 | wpb 65492.6 | bsz 127.9 | num_updates 12531 | lr 0.000282493 | gnorm 0.469 | loss_scale 32 | train_wall 863 | gb_free 9.7 | wall 29105
2022-03-13 20:07:00 | INFO | fairseq.trainer | begin training epoch 32
2022-03-13 20:07:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:09:43 | INFO | train_inner | epoch 032:     70 / 407 loss=6.126, nll_loss=5.374, ppl=41.48, wps=24426.6, ups=0.37, wpb=65361.9, bsz=127.7, num_updates=12600, lr=0.000281718, gnorm=0.467, loss_scale=32, train_wall=214, gb_free=9.7, wall=29268
2022-03-13 20:12:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:13:41 | INFO | train_inner | epoch 032:    171 / 407 loss=6.127, nll_loss=5.375, ppl=41.5, wps=27550.2, ups=0.42, wpb=65536, bsz=128, num_updates=12700, lr=0.000280607, gnorm=0.465, loss_scale=32, train_wall=214, gb_free=9.7, wall=29506
2022-03-13 20:17:33 | INFO | train_inner | epoch 032:    271 / 407 loss=6.142, nll_loss=5.392, ppl=41.98, wps=28252.1, ups=0.43, wpb=65534.2, bsz=128, num_updates=12800, lr=0.000279508, gnorm=0.465, loss_scale=32, train_wall=208, gb_free=9.7, wall=29738
2022-03-13 20:17:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:20:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:21:23 | INFO | train_inner | epoch 032:    373 / 407 loss=6.156, nll_loss=5.407, ppl=42.43, wps=28498.6, ups=0.43, wpb=65536, bsz=128, num_updates=12900, lr=0.000278423, gnorm=0.47, loss_scale=16, train_wall=206, gb_free=9.7, wall=29968
2022-03-13 20:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:23:08 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.255 | nll_loss 5.462 | ppl 44.06 | wps 49985.5 | wpb 511.9 | bsz 1 | num_updates 12934 | best_loss 6.255
2022-03-13 20:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 12934 updates
2022-03-13 20:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:23:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 32 @ 12934 updates, score 6.255) (writing took 2.1723459950299002 seconds)
2022-03-13 20:23:10 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-13 20:23:10 | INFO | train | epoch 032 | loss 6.136 | nll_loss 5.385 | ppl 41.79 | wps 27183.6 | ups 0.42 | wpb 65492.3 | bsz 127.9 | num_updates 12934 | lr 0.000278057 | gnorm 0.467 | loss_scale 16 | train_wall 845 | gb_free 9.7 | wall 30076
2022-03-13 20:23:10 | INFO | fairseq.trainer | begin training epoch 33
2022-03-13 20:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:25:44 | INFO | train_inner | epoch 033:     66 / 407 loss=6.108, nll_loss=5.355, ppl=40.92, wps=25081.8, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=13000, lr=0.00027735, gnorm=0.469, loss_scale=16, train_wall=208, gb_free=9.7, wall=30229
2022-03-13 20:29:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:29:33 | INFO | train_inner | epoch 033:    167 / 407 loss=6.112, nll_loss=5.359, ppl=41.04, wps=28544.7, ups=0.44, wpb=65534.2, bsz=128, num_updates=13100, lr=0.000276289, gnorm=0.473, loss_scale=16, train_wall=206, gb_free=9.7, wall=30458
2022-03-13 20:33:22 | INFO | train_inner | epoch 033:    267 / 407 loss=6.129, nll_loss=5.377, ppl=41.57, wps=28694.7, ups=0.44, wpb=65536, bsz=128, num_updates=13200, lr=0.000275241, gnorm=0.474, loss_scale=16, train_wall=205, gb_free=9.7, wall=30687
2022-03-13 20:37:14 | INFO | train_inner | epoch 033:    367 / 407 loss=6.134, nll_loss=5.383, ppl=41.72, wps=28145.1, ups=0.43, wpb=65536, bsz=128, num_updates=13300, lr=0.000274204, gnorm=0.468, loss_scale=32, train_wall=209, gb_free=9.7, wall=30919
2022-03-13 20:38:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:39:15 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.244 | nll_loss 5.451 | ppl 43.74 | wps 49139.4 | wpb 511.9 | bsz 1 | num_updates 13340 | best_loss 6.244
2022-03-13 20:39:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 13340 updates
2022-03-13 20:39:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:39:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 33 @ 13340 updates, score 6.244) (writing took 2.2566845699911937 seconds)
2022-03-13 20:39:17 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-13 20:39:17 | INFO | train | epoch 033 | loss 6.121 | nll_loss 5.369 | ppl 41.32 | wps 27513.3 | ups 0.42 | wpb 65492.7 | bsz 127.9 | num_updates 13340 | lr 0.000273793 | gnorm 0.47 | loss_scale 32 | train_wall 840 | gb_free 9.7 | wall 31042
2022-03-13 20:39:17 | INFO | fairseq.trainer | begin training epoch 34
2022-03-13 20:39:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:39:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:40:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:41:44 | INFO | train_inner | epoch 034:     62 / 407 loss=6.102, nll_loss=5.348, ppl=40.74, wps=24289.9, ups=0.37, wpb=65361.9, bsz=127.7, num_updates=13400, lr=0.000273179, gnorm=0.473, loss_scale=16, train_wall=215, gb_free=9.7, wall=31189
2022-03-13 20:45:34 | INFO | train_inner | epoch 034:    162 / 407 loss=6.092, nll_loss=5.337, ppl=40.43, wps=28488.3, ups=0.43, wpb=65534.2, bsz=128, num_updates=13500, lr=0.000272166, gnorm=0.469, loss_scale=32, train_wall=206, gb_free=9.7, wall=31419
2022-03-13 20:49:25 | INFO | train_inner | epoch 034:    262 / 407 loss=6.116, nll_loss=5.363, ppl=41.17, wps=28367, ups=0.43, wpb=65536, bsz=128, num_updates=13600, lr=0.000271163, gnorm=0.467, loss_scale=32, train_wall=207, gb_free=9.7, wall=31650
2022-03-13 20:50:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 20:50:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 20:53:25 | INFO | train_inner | epoch 034:    364 / 407 loss=6.124, nll_loss=5.372, ppl=41.41, wps=27262.8, ups=0.42, wpb=65536, bsz=128, num_updates=13700, lr=0.000270172, gnorm=0.465, loss_scale=16, train_wall=216, gb_free=9.7, wall=31890
2022-03-13 20:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 20:55:32 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.234 | nll_loss 5.441 | ppl 43.45 | wps 49103.4 | wpb 511.9 | bsz 1 | num_updates 13743 | best_loss 6.234
2022-03-13 20:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 13743 updates
2022-03-13 20:55:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:55:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 20:55:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 34 @ 13743 updates, score 6.234) (writing took 2.182916663994547 seconds)
2022-03-13 20:55:34 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-13 20:55:34 | INFO | train | epoch 034 | loss 6.106 | nll_loss 5.353 | ppl 40.86 | wps 27020.2 | ups 0.41 | wpb 65492.3 | bsz 127.9 | num_updates 13743 | lr 0.000269749 | gnorm 0.468 | loss_scale 16 | train_wall 851 | gb_free 9.7 | wall 32019
2022-03-13 20:55:34 | INFO | fairseq.trainer | begin training epoch 35
2022-03-13 20:55:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 20:57:45 | INFO | train_inner | epoch 035:     57 / 407 loss=6.084, nll_loss=5.328, ppl=40.18, wps=25104.2, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=13800, lr=0.000269191, gnorm=0.463, loss_scale=32, train_wall=207, gb_free=9.7, wall=32150
2022-03-13 21:00:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:01:37 | INFO | train_inner | epoch 035:    158 / 407 loss=6.083, nll_loss=5.327, ppl=40.15, wps=28338.5, ups=0.43, wpb=65534.2, bsz=128, num_updates=13900, lr=0.000268221, gnorm=0.47, loss_scale=32, train_wall=207, gb_free=9.7, wall=32382
2022-03-13 21:05:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:05:29 | INFO | train_inner | epoch 035:    259 / 407 loss=6.099, nll_loss=5.345, ppl=40.64, wps=28171.6, ups=0.43, wpb=65536, bsz=128, num_updates=14000, lr=0.000267261, gnorm=0.473, loss_scale=16, train_wall=209, gb_free=9.7, wall=32614
2022-03-13 21:09:20 | INFO | train_inner | epoch 035:    359 / 407 loss=6.111, nll_loss=5.358, ppl=41.02, wps=28432.6, ups=0.43, wpb=65536, bsz=128, num_updates=14100, lr=0.000266312, gnorm=0.475, loss_scale=16, train_wall=207, gb_free=9.7, wall=32845
2022-03-13 21:11:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:11:32 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.225 | nll_loss 5.432 | ppl 43.16 | wps 52469.5 | wpb 511.9 | bsz 1 | num_updates 14148 | best_loss 6.225
2022-03-13 21:11:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 14148 updates
2022-03-13 21:11:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:11:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 35 @ 14148 updates, score 6.225) (writing took 2.1306714859674685 seconds)
2022-03-13 21:11:34 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-13 21:11:34 | INFO | train | epoch 035 | loss 6.093 | nll_loss 5.338 | ppl 40.45 | wps 27611.8 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 14148 | lr 0.00026586 | gnorm 0.471 | loss_scale 32 | train_wall 836 | gb_free 9.7 | wall 32979
2022-03-13 21:11:34 | INFO | fairseq.trainer | begin training epoch 36
2022-03-13 21:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:13:31 | INFO | train_inner | epoch 036:     52 / 407 loss=6.084, nll_loss=5.329, ppl=40.2, wps=26020.9, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=14200, lr=0.000265372, gnorm=0.472, loss_scale=32, train_wall=200, gb_free=9.7, wall=33096
2022-03-13 21:15:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:17:26 | INFO | train_inner | epoch 036:    153 / 407 loss=6.071, nll_loss=5.314, ppl=39.78, wps=27849.2, ups=0.42, wpb=65534.2, bsz=128, num_updates=14300, lr=0.000264443, gnorm=0.471, loss_scale=32, train_wall=211, gb_free=9.7, wall=33331
2022-03-13 21:20:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:21:23 | INFO | train_inner | epoch 036:    254 / 407 loss=6.078, nll_loss=5.322, ppl=40, wps=27709.2, ups=0.42, wpb=65536, bsz=128, num_updates=14400, lr=0.000263523, gnorm=0.467, loss_scale=32, train_wall=213, gb_free=9.7, wall=33568
2022-03-13 21:25:17 | INFO | train_inner | epoch 036:    354 / 407 loss=6.094, nll_loss=5.339, ppl=40.49, wps=28023.6, ups=0.43, wpb=65536, bsz=128, num_updates=14500, lr=0.000262613, gnorm=0.469, loss_scale=32, train_wall=210, gb_free=9.7, wall=33802
2022-03-13 21:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:27:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:27:45 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.218 | nll_loss 5.423 | ppl 42.91 | wps 49130.1 | wpb 511.9 | bsz 1 | num_updates 14552 | best_loss 6.218
2022-03-13 21:27:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 14552 updates
2022-03-13 21:27:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:27:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:27:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 36 @ 14552 updates, score 6.218) (writing took 2.1586260870099068 seconds)
2022-03-13 21:27:47 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-13 21:27:47 | INFO | train | epoch 036 | loss 6.08 | nll_loss 5.324 | ppl 40.07 | wps 27193.7 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 14552 | lr 0.000262143 | gnorm 0.47 | loss_scale 32 | train_wall 847 | gb_free 9.7 | wall 33952
2022-03-13 21:27:47 | INFO | fairseq.trainer | begin training epoch 37
2022-03-13 21:27:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:29:41 | INFO | train_inner | epoch 037:     48 / 407 loss=6.061, nll_loss=5.304, ppl=39.49, wps=24750.9, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=14600, lr=0.000261712, gnorm=0.471, loss_scale=32, train_wall=211, gb_free=9.7, wall=34066
2022-03-13 21:31:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:33:37 | INFO | train_inner | epoch 037:    149 / 407 loss=6.055, nll_loss=5.296, ppl=39.3, wps=27731, ups=0.42, wpb=65536, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.469, loss_scale=32, train_wall=212, gb_free=9.7, wall=34302
2022-03-13 21:36:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:37:36 | INFO | train_inner | epoch 037:    250 / 407 loss=6.069, nll_loss=5.313, ppl=39.74, wps=27390.4, ups=0.42, wpb=65536, bsz=128, num_updates=14800, lr=0.000259938, gnorm=0.47, loss_scale=32, train_wall=215, gb_free=9.7, wall=34541
2022-03-13 21:40:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:41:26 | INFO | train_inner | epoch 037:    351 / 407 loss=6.089, nll_loss=5.334, ppl=40.35, wps=28587.5, ups=0.44, wpb=65534.2, bsz=128, num_updates=14900, lr=0.000259064, gnorm=0.474, loss_scale=16, train_wall=205, gb_free=9.7, wall=34771
2022-03-13 21:43:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 21:44:03 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.211 | nll_loss 5.415 | ppl 42.68 | wps 50691.4 | wpb 511.9 | bsz 1 | num_updates 14956 | best_loss 6.211
2022-03-13 21:44:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 14956 updates
2022-03-13 21:44:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:44:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 21:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 37 @ 14956 updates, score 6.211) (writing took 2.1892862700042315 seconds)
2022-03-13 21:44:05 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-13 21:44:05 | INFO | train | epoch 037 | loss 6.068 | nll_loss 5.311 | ppl 39.69 | wps 27059.8 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 14956 | lr 0.000258578 | gnorm 0.471 | loss_scale 16 | train_wall 852 | gb_free 9.7 | wall 34930
2022-03-13 21:44:05 | INFO | fairseq.trainer | begin training epoch 38
2022-03-13 21:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 21:45:49 | INFO | train_inner | epoch 038:     44 / 407 loss=6.058, nll_loss=5.3, ppl=39.4, wps=24809.6, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=15000, lr=0.000258199, gnorm=0.469, loss_scale=16, train_wall=211, gb_free=9.7, wall=35034
2022-03-13 21:49:41 | INFO | train_inner | epoch 038:    144 / 407 loss=6.03, nll_loss=5.27, ppl=38.59, wps=28261.2, ups=0.43, wpb=65536, bsz=128, num_updates=15100, lr=0.000257343, gnorm=0.473, loss_scale=32, train_wall=208, gb_free=9.7, wall=35266
2022-03-13 21:50:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:53:36 | INFO | train_inner | epoch 038:    245 / 407 loss=6.07, nll_loss=5.314, ppl=39.77, wps=27862.6, ups=0.43, wpb=65536, bsz=128, num_updates=15200, lr=0.000256495, gnorm=0.471, loss_scale=32, train_wall=211, gb_free=9.7, wall=35501
2022-03-13 21:55:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 21:57:30 | INFO | train_inner | epoch 038:    346 / 407 loss=6.068, nll_loss=5.312, ppl=39.72, wps=27999.2, ups=0.43, wpb=65534.2, bsz=128, num_updates=15300, lr=0.000255655, gnorm=0.476, loss_scale=32, train_wall=210, gb_free=9.7, wall=35735
2022-03-13 21:57:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 21:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:00:13 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.204 | nll_loss 5.409 | ppl 42.5 | wps 51768.4 | wpb 511.9 | bsz 1 | num_updates 15360 | best_loss 6.204
2022-03-13 22:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 15360 updates
2022-03-13 22:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:00:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 38 @ 15360 updates, score 6.204) (writing took 2.184503469034098 seconds)
2022-03-13 22:00:16 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-13 22:00:16 | INFO | train | epoch 038 | loss 6.056 | nll_loss 5.298 | ppl 39.36 | wps 27260.9 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 15360 | lr 0.000255155 | gnorm 0.473 | loss_scale 16 | train_wall 846 | gb_free 9.7 | wall 35901
2022-03-13 22:00:16 | INFO | fairseq.trainer | begin training epoch 39
2022-03-13 22:00:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:01:45 | INFO | train_inner | epoch 039:     40 / 407 loss=6.056, nll_loss=5.298, ppl=39.35, wps=25684.7, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=15400, lr=0.000254824, gnorm=0.474, loss_scale=16, train_wall=202, gb_free=9.7, wall=35990
2022-03-13 22:05:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:05:31 | INFO | train_inner | epoch 039:    141 / 407 loss=6.032, nll_loss=5.271, ppl=38.62, wps=28907.9, ups=0.44, wpb=65536, bsz=128, num_updates=15500, lr=0.000254, gnorm=0.473, loss_scale=16, train_wall=203, gb_free=9.7, wall=36216
2022-03-13 22:09:11 | INFO | train_inner | epoch 039:    241 / 407 loss=6.047, nll_loss=5.288, ppl=39.06, wps=29793.8, ups=0.45, wpb=65536, bsz=128, num_updates=15600, lr=0.000253185, gnorm=0.474, loss_scale=16, train_wall=196, gb_free=9.7, wall=36436
2022-03-13 22:12:52 | INFO | train_inner | epoch 039:    341 / 407 loss=6.057, nll_loss=5.299, ppl=39.37, wps=29746.4, ups=0.45, wpb=65536, bsz=128, num_updates=15700, lr=0.000252377, gnorm=0.477, loss_scale=32, train_wall=197, gb_free=9.7, wall=36657
2022-03-13 22:14:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:15:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:15:41 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.197 | nll_loss 5.401 | ppl 42.26 | wps 51680 | wpb 511.9 | bsz 1 | num_updates 15765 | best_loss 6.197
2022-03-13 22:15:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 15765 updates
2022-03-13 22:15:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:15:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 39 @ 15765 updates, score 6.197) (writing took 2.2011124279815704 seconds)
2022-03-13 22:15:44 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-13 22:15:44 | INFO | train | epoch 039 | loss 6.045 | nll_loss 5.286 | ppl 39.02 | wps 28582 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 15765 | lr 0.000251856 | gnorm 0.475 | loss_scale 32 | train_wall 803 | gb_free 9.7 | wall 36829
2022-03-13 22:15:44 | INFO | fairseq.trainer | begin training epoch 40
2022-03-13 22:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:17:00 | INFO | train_inner | epoch 040:     35 / 407 loss=6.044, nll_loss=5.285, ppl=39, wps=26288.5, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=15800, lr=0.000251577, gnorm=0.473, loss_scale=32, train_wall=197, gb_free=9.7, wall=36905
2022-03-13 22:19:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:20:41 | INFO | train_inner | epoch 040:    136 / 407 loss=6.012, nll_loss=5.25, ppl=38.06, wps=29619.1, ups=0.45, wpb=65536, bsz=128, num_updates=15900, lr=0.000250785, gnorm=0.472, loss_scale=32, train_wall=197, gb_free=9.7, wall=37127
2022-03-13 22:24:22 | INFO | train_inner | epoch 040:    236 / 407 loss=6.029, nll_loss=5.269, ppl=38.55, wps=29770.7, ups=0.45, wpb=65534.2, bsz=128, num_updates=16000, lr=0.00025, gnorm=0.474, loss_scale=32, train_wall=196, gb_free=9.7, wall=37347
2022-03-13 22:24:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:26:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:28:04 | INFO | train_inner | epoch 040:    338 / 407 loss=6.055, nll_loss=5.297, ppl=39.32, wps=29426.3, ups=0.45, wpb=65536, bsz=128, num_updates=16100, lr=0.000249222, gnorm=0.472, loss_scale=16, train_wall=199, gb_free=9.7, wall=37569
2022-03-13 22:30:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:31:02 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.197 | nll_loss 5.398 | ppl 42.15 | wps 51914.2 | wpb 511.9 | bsz 1 | num_updates 16169 | best_loss 6.197
2022-03-13 22:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 16169 updates
2022-03-13 22:31:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:31:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 40 @ 16169 updates, score 6.197) (writing took 2.1381297769839875 seconds)
2022-03-13 22:31:04 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-13 22:31:04 | INFO | train | epoch 040 | loss 6.035 | nll_loss 5.275 | ppl 38.71 | wps 28738.7 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 16169 | lr 0.00024869 | gnorm 0.473 | loss_scale 16 | train_wall 796 | gb_free 9.7 | wall 37749
2022-03-13 22:31:04 | INFO | fairseq.trainer | begin training epoch 41
2022-03-13 22:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:32:12 | INFO | train_inner | epoch 041:     31 / 407 loss=6.033, nll_loss=5.274, ppl=38.68, wps=26382.4, ups=0.4, wpb=65360.1, bsz=127.7, num_updates=16200, lr=0.000248452, gnorm=0.474, loss_scale=32, train_wall=196, gb_free=9.7, wall=37817
2022-03-13 22:34:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:35:53 | INFO | train_inner | epoch 041:    132 / 407 loss=6.013, nll_loss=5.251, ppl=38.07, wps=29710.6, ups=0.45, wpb=65536, bsz=128, num_updates=16300, lr=0.000247689, gnorm=0.477, loss_scale=16, train_wall=197, gb_free=9.7, wall=38038
2022-03-13 22:39:31 | INFO | train_inner | epoch 041:    232 / 407 loss=6.024, nll_loss=5.263, ppl=38.41, wps=29986.4, ups=0.46, wpb=65536, bsz=128, num_updates=16400, lr=0.000246932, gnorm=0.473, loss_scale=32, train_wall=195, gb_free=9.7, wall=38256
2022-03-13 22:40:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 22:43:13 | INFO | train_inner | epoch 041:    333 / 407 loss=6.035, nll_loss=5.275, ppl=38.72, wps=29616.7, ups=0.45, wpb=65536, bsz=128, num_updates=16500, lr=0.000246183, gnorm=0.473, loss_scale=16, train_wall=197, gb_free=9.7, wall=38478
2022-03-13 22:45:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 22:46:18 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.193 | nll_loss 5.396 | ppl 42.11 | wps 52898.8 | wpb 511.9 | bsz 1 | num_updates 16574 | best_loss 6.193
2022-03-13 22:46:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 16574 updates
2022-03-13 22:46:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:46:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 22:46:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 41 @ 16574 updates, score 6.193) (writing took 2.179600831994321 seconds)
2022-03-13 22:46:20 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-13 22:46:20 | INFO | train | epoch 041 | loss 6.024 | nll_loss 5.263 | ppl 38.4 | wps 28955.7 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 16574 | lr 0.000245633 | gnorm 0.475 | loss_scale 32 | train_wall 792 | gb_free 9.7 | wall 38665
2022-03-13 22:46:20 | INFO | fairseq.trainer | begin training epoch 42
2022-03-13 22:46:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 22:47:17 | INFO | train_inner | epoch 042:     26 / 407 loss=6.026, nll_loss=5.266, ppl=38.47, wps=26712.2, ups=0.41, wpb=65361.9, bsz=127.7, num_updates=16600, lr=0.00024544, gnorm=0.478, loss_scale=32, train_wall=193, gb_free=9.7, wall=38722
2022-03-13 22:50:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:50:58 | INFO | train_inner | epoch 042:    127 / 407 loss=5.999, nll_loss=5.236, ppl=37.69, wps=29637.3, ups=0.45, wpb=65536, bsz=128, num_updates=16700, lr=0.000244704, gnorm=0.471, loss_scale=32, train_wall=197, gb_free=9.7, wall=38943
2022-03-13 22:54:37 | INFO | train_inner | epoch 042:    227 / 407 loss=6.008, nll_loss=5.245, ppl=37.93, wps=29973.9, ups=0.46, wpb=65536, bsz=128, num_updates=16800, lr=0.000243975, gnorm=0.477, loss_scale=32, train_wall=195, gb_free=9.7, wall=39162
2022-03-13 22:55:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 22:58:20 | INFO | train_inner | epoch 042:    328 / 407 loss=6.033, nll_loss=5.273, ppl=38.67, wps=29402.6, ups=0.45, wpb=65534.2, bsz=128, num_updates=16900, lr=0.000243252, gnorm=0.48, loss_scale=32, train_wall=199, gb_free=9.7, wall=39385
2022-03-13 22:59:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:01:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:01:39 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.18 | nll_loss 5.385 | ppl 41.8 | wps 52102.2 | wpb 511.9 | bsz 1 | num_updates 16978 | best_loss 6.18
2022-03-13 23:01:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 16978 updates
2022-03-13 23:01:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:01:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:01:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 42 @ 16978 updates, score 6.18) (writing took 2.2047433449770324 seconds)
2022-03-13 23:01:41 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-13 23:01:41 | INFO | train | epoch 042 | loss 6.015 | nll_loss 5.254 | ppl 38.15 | wps 28734.2 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 16978 | lr 0.000242693 | gnorm 0.477 | loss_scale 32 | train_wall 796 | gb_free 9.7 | wall 39586
2022-03-13 23:01:41 | INFO | fairseq.trainer | begin training epoch 43
2022-03-13 23:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:02:29 | INFO | train_inner | epoch 043:     22 / 407 loss=6.019, nll_loss=5.258, ppl=38.26, wps=26184, ups=0.4, wpb=65361.9, bsz=127.7, num_updates=17000, lr=0.000242536, gnorm=0.478, loss_scale=32, train_wall=198, gb_free=9.7, wall=39635
2022-03-13 23:05:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:05:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:06:12 | INFO | train_inner | epoch 043:    124 / 407 loss=5.988, nll_loss=5.224, ppl=37.36, wps=29397.8, ups=0.45, wpb=65536, bsz=128, num_updates=17100, lr=0.000241825, gnorm=0.477, loss_scale=16, train_wall=199, gb_free=9.7, wall=39857
2022-03-13 23:09:51 | INFO | train_inner | epoch 043:    224 / 407 loss=6.011, nll_loss=5.249, ppl=38.02, wps=29969.5, ups=0.46, wpb=65536, bsz=128, num_updates=17200, lr=0.000241121, gnorm=0.476, loss_scale=16, train_wall=195, gb_free=9.7, wall=40076
2022-03-13 23:12:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:13:34 | INFO | train_inner | epoch 043:    325 / 407 loss=6.01, nll_loss=5.248, ppl=38.01, wps=29454.1, ups=0.45, wpb=65536, bsz=128, num_updates=17300, lr=0.000240424, gnorm=0.48, loss_scale=16, train_wall=199, gb_free=9.7, wall=40299
2022-03-13 23:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:16:59 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.181 | nll_loss 5.384 | ppl 41.75 | wps 52897.7 | wpb 511.9 | bsz 1 | num_updates 17382 | best_loss 6.18
2022-03-13 23:16:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 17382 updates
2022-03-13 23:16:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:17:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-13 23:17:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt (epoch 43 @ 17382 updates, score 6.181) (writing took 1.2292549279518425 seconds)
2022-03-13 23:17:00 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-13 23:17:00 | INFO | train | epoch 043 | loss 6.005 | nll_loss 5.243 | ppl 37.86 | wps 28801.1 | ups 0.44 | wpb 65492.5 | bsz 127.9 | num_updates 17382 | lr 0.000239856 | gnorm 0.478 | loss_scale 16 | train_wall 796 | gb_free 9.7 | wall 40505
2022-03-13 23:17:00 | INFO | fairseq.trainer | begin training epoch 44
2022-03-13 23:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:17:39 | INFO | train_inner | epoch 044:     18 / 407 loss=6.012, nll_loss=5.25, ppl=38.05, wps=26591.5, ups=0.41, wpb=65360.1, bsz=127.7, num_updates=17400, lr=0.000239732, gnorm=0.48, loss_scale=32, train_wall=196, gb_free=9.7, wall=40544
2022-03-13 23:21:19 | INFO | train_inner | epoch 044:    118 / 407 loss=5.977, nll_loss=5.212, ppl=37.06, wps=29857.9, ups=0.46, wpb=65536, bsz=128, num_updates=17500, lr=0.000239046, gnorm=0.475, loss_scale=32, train_wall=196, gb_free=9.7, wall=40764
2022-03-13 23:21:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:25:00 | INFO | train_inner | epoch 044:    219 / 407 loss=5.995, nll_loss=5.232, ppl=37.58, wps=29673.4, ups=0.45, wpb=65536, bsz=128, num_updates=17600, lr=0.000238366, gnorm=0.481, loss_scale=16, train_wall=197, gb_free=9.7, wall=40985
2022-03-13 23:28:40 | INFO | train_inner | epoch 044:    319 / 407 loss=6.009, nll_loss=5.247, ppl=37.98, wps=29786.8, ups=0.45, wpb=65536, bsz=128, num_updates=17700, lr=0.000237691, gnorm=0.479, loss_scale=32, train_wall=196, gb_free=9.7, wall=41205
2022-03-13 23:31:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:32:23 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.174 | nll_loss 5.375 | ppl 41.5 | wps 50528.6 | wpb 511.9 | bsz 1 | num_updates 17787 | best_loss 6.174
2022-03-13 23:32:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 17787 updates
2022-03-13 23:32:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:32:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:32:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 44 @ 17787 updates, score 6.174) (writing took 2.2438046640018 seconds)
2022-03-13 23:32:26 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-13 23:32:26 | INFO | train | epoch 044 | loss 5.996 | nll_loss 5.233 | ppl 37.6 | wps 28653.4 | ups 0.44 | wpb 65492.6 | bsz 127.9 | num_updates 17787 | lr 0.000237109 | gnorm 0.479 | loss_scale 32 | train_wall 800 | gb_free 9.7 | wall 41431
2022-03-13 23:32:26 | INFO | fairseq.trainer | begin training epoch 45
2022-03-13 23:32:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:32:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-13 23:32:58 | INFO | train_inner | epoch 045:     14 / 407 loss=6, nll_loss=5.237, ppl=37.72, wps=25277.3, ups=0.39, wpb=65360.1, bsz=127.7, num_updates=17800, lr=0.000237023, gnorm=0.482, loss_scale=16, train_wall=206, gb_free=9.7, wall=41463
2022-03-13 23:36:48 | INFO | train_inner | epoch 045:    114 / 407 loss=5.96, nll_loss=5.193, ppl=36.58, wps=28508.7, ups=0.44, wpb=65536, bsz=128, num_updates=17900, lr=0.00023636, gnorm=0.471, loss_scale=16, train_wall=206, gb_free=9.7, wall=41693
2022-03-13 23:40:41 | INFO | train_inner | epoch 045:    214 / 407 loss=5.98, nll_loss=5.215, ppl=37.15, wps=28177.9, ups=0.43, wpb=65536, bsz=128, num_updates=18000, lr=0.000235702, gnorm=0.477, loss_scale=32, train_wall=209, gb_free=9.7, wall=41926
2022-03-13 23:42:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:44:37 | INFO | train_inner | epoch 045:    315 / 407 loss=6.008, nll_loss=5.246, ppl=37.94, wps=27730, ups=0.42, wpb=65534.2, bsz=128, num_updates=18100, lr=0.00023505, gnorm=0.479, loss_scale=32, train_wall=212, gb_free=9.7, wall=42162
2022-03-13 23:47:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-13 23:48:41 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.169 | nll_loss 5.369 | ppl 41.34 | wps 49150.6 | wpb 511.9 | bsz 1 | num_updates 18191 | best_loss 6.169
2022-03-13 23:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 18191 updates
2022-03-13 23:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:48:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-13 23:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 45 @ 18191 updates, score 6.169) (writing took 2.279503339959774 seconds)
2022-03-13 23:48:43 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-13 23:48:43 | INFO | train | epoch 045 | loss 5.988 | nll_loss 5.223 | ppl 37.36 | wps 27067.8 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 18191 | lr 0.000234462 | gnorm 0.476 | loss_scale 32 | train_wall 851 | gb_free 9.7 | wall 42408
2022-03-13 23:48:43 | INFO | fairseq.trainer | begin training epoch 46
2022-03-13 23:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-13 23:49:03 | INFO | train_inner | epoch 046:      9 / 407 loss=6.005, nll_loss=5.242, ppl=37.85, wps=24541.2, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=18200, lr=0.000234404, gnorm=0.477, loss_scale=32, train_wall=213, gb_free=9.7, wall=42429
2022-03-13 23:52:53 | INFO | train_inner | epoch 046:    109 / 407 loss=5.956, nll_loss=5.189, ppl=36.47, wps=28593.4, ups=0.44, wpb=65534.2, bsz=128, num_updates=18300, lr=0.000233762, gnorm=0.482, loss_scale=64, train_wall=205, gb_free=9.7, wall=42658
2022-03-13 23:52:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-13 23:56:51 | INFO | train_inner | epoch 046:    210 / 407 loss=5.981, nll_loss=5.216, ppl=37.16, wps=27483.2, ups=0.42, wpb=65536, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.477, loss_scale=32, train_wall=214, gb_free=9.7, wall=42896
2022-03-13 23:57:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:00:49 | INFO | train_inner | epoch 046:    311 / 407 loss=5.988, nll_loss=5.224, ppl=37.38, wps=27540.8, ups=0.42, wpb=65536, bsz=128, num_updates=18500, lr=0.000232495, gnorm=0.484, loss_scale=32, train_wall=214, gb_free=9.7, wall=43134
2022-03-14 00:03:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:04:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:04:57 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.16 | nll_loss 5.364 | ppl 41.17 | wps 48710.7 | wpb 511.9 | bsz 1 | num_updates 18595 | best_loss 6.16
2022-03-14 00:04:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 18595 updates
2022-03-14 00:04:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:05:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 46 @ 18595 updates, score 6.16) (writing took 2.2576348839793354 seconds)
2022-03-14 00:05:00 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 00:05:00 | INFO | train | epoch 046 | loss 5.979 | nll_loss 5.214 | ppl 37.11 | wps 27093.6 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 18595 | lr 0.000231901 | gnorm 0.48 | loss_scale 32 | train_wall 850 | gb_free 9.7 | wall 43385
2022-03-14 00:05:00 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 00:05:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:05:12 | INFO | train_inner | epoch 047:      5 / 407 loss=5.992, nll_loss=5.228, ppl=37.49, wps=24894.5, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=18600, lr=0.000231869, gnorm=0.475, loss_scale=32, train_wall=209, gb_free=9.7, wall=43397
2022-03-14 00:08:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:09:02 | INFO | train_inner | epoch 047:    106 / 407 loss=5.947, nll_loss=5.179, ppl=36.22, wps=28473.5, ups=0.43, wpb=65536, bsz=128, num_updates=18700, lr=0.000231249, gnorm=0.474, loss_scale=32, train_wall=206, gb_free=9.7, wall=43627
2022-03-14 00:12:59 | INFO | train_inner | epoch 047:    206 / 407 loss=5.956, nll_loss=5.189, ppl=36.47, wps=27623.8, ups=0.42, wpb=65534.2, bsz=128, num_updates=18800, lr=0.000230633, gnorm=0.48, loss_scale=32, train_wall=213, gb_free=9.7, wall=43864
2022-03-14 00:13:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:16:57 | INFO | train_inner | epoch 047:    307 / 407 loss=5.99, nll_loss=5.225, ppl=37.41, wps=27567.3, ups=0.42, wpb=65536, bsz=128, num_updates=18900, lr=0.000230022, gnorm=0.479, loss_scale=32, train_wall=214, gb_free=9.7, wall=44102
2022-03-14 00:18:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:21:18 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.158 | nll_loss 5.357 | ppl 40.99 | wps 50453.2 | wpb 511.9 | bsz 1 | num_updates 18999 | best_loss 6.158
2022-03-14 00:21:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 18999 updates
2022-03-14 00:21:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:21:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 47 @ 18999 updates, score 6.158) (writing took 2.1573285299818963 seconds)
2022-03-14 00:21:20 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 00:21:20 | INFO | train | epoch 047 | loss 5.971 | nll_loss 5.205 | ppl 36.9 | wps 26978.8 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 18999 | lr 0.000229422 | gnorm 0.478 | loss_scale 32 | train_wall 855 | gb_free 9.7 | wall 44365
2022-03-14 00:21:20 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 00:21:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:21:23 | INFO | train_inner | epoch 048:      1 / 407 loss=5.995, nll_loss=5.231, ppl=37.57, wps=24574.8, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19000, lr=0.000229416, gnorm=0.48, loss_scale=32, train_wall=213, gb_free=9.7, wall=44368
2022-03-14 00:22:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:25:18 | INFO | train_inner | epoch 048:    102 / 407 loss=5.943, nll_loss=5.175, ppl=36.13, wps=27884.4, ups=0.43, wpb=65534.2, bsz=128, num_updates=19100, lr=0.000228814, gnorm=0.478, loss_scale=16, train_wall=211, gb_free=9.7, wall=44603
2022-03-14 00:29:07 | INFO | train_inner | epoch 048:    202 / 407 loss=5.957, nll_loss=5.19, ppl=36.5, wps=28587.1, ups=0.44, wpb=65536, bsz=128, num_updates=19200, lr=0.000228218, gnorm=0.476, loss_scale=32, train_wall=205, gb_free=9.7, wall=44832
2022-03-14 00:31:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:33:01 | INFO | train_inner | epoch 048:    303 / 407 loss=5.972, nll_loss=5.207, ppl=36.93, wps=28006.1, ups=0.43, wpb=65536, bsz=128, num_updates=19300, lr=0.000227626, gnorm=0.477, loss_scale=32, train_wall=210, gb_free=9.7, wall=45066
2022-03-14 00:36:57 | INFO | train_inner | epoch 048:    403 / 407 loss=5.979, nll_loss=5.214, ppl=37.11, wps=27725.9, ups=0.42, wpb=65536, bsz=128, num_updates=19400, lr=0.000227038, gnorm=0.476, loss_scale=32, train_wall=213, gb_free=9.7, wall=45302
2022-03-14 00:37:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:37:34 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.157 | nll_loss 5.356 | ppl 40.97 | wps 49117.2 | wpb 511.9 | bsz 1 | num_updates 19403 | best_loss 6.157
2022-03-14 00:37:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 19403 updates
2022-03-14 00:37:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:37:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 48 @ 19403 updates, score 6.157) (writing took 2.209564062010031 seconds)
2022-03-14 00:37:36 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 00:37:36 | INFO | train | epoch 048 | loss 5.963 | nll_loss 5.197 | ppl 36.67 | wps 27128.6 | ups 0.41 | wpb 65492.5 | bsz 127.9 | num_updates 19403 | lr 0.000227021 | gnorm 0.477 | loss_scale 32 | train_wall 849 | gb_free 9.7 | wall 45341
2022-03-14 00:37:36 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 00:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:38:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:41:20 | INFO | train_inner | epoch 049:     98 / 407 loss=5.931, nll_loss=5.162, ppl=35.8, wps=24918.3, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19500, lr=0.000226455, gnorm=0.482, loss_scale=16, train_wall=208, gb_free=9.7, wall=45565
2022-03-14 00:45:07 | INFO | train_inner | epoch 049:    198 / 407 loss=5.959, nll_loss=5.192, ppl=36.56, wps=28801.4, ups=0.44, wpb=65534.2, bsz=128, num_updates=19600, lr=0.000225877, gnorm=0.477, loss_scale=32, train_wall=204, gb_free=9.7, wall=45792
2022-03-14 00:48:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 00:49:02 | INFO | train_inner | epoch 049:    299 / 407 loss=5.963, nll_loss=5.197, ppl=36.68, wps=27892.5, ups=0.43, wpb=65536, bsz=128, num_updates=19700, lr=0.000225303, gnorm=0.481, loss_scale=32, train_wall=211, gb_free=9.7, wall=46027
2022-03-14 00:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 00:53:00 | INFO | train_inner | epoch 049:    400 / 407 loss=5.969, nll_loss=5.204, ppl=36.85, wps=27579.7, ups=0.42, wpb=65536, bsz=128, num_updates=19800, lr=0.000224733, gnorm=0.484, loss_scale=16, train_wall=214, gb_free=9.7, wall=46265
2022-03-14 00:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 00:53:42 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.157 | nll_loss 5.356 | ppl 40.96 | wps 50179.4 | wpb 511.9 | bsz 1 | num_updates 19807 | best_loss 6.157
2022-03-14 00:53:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 19807 updates
2022-03-14 00:53:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 00:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 49 @ 19807 updates, score 6.157) (writing took 2.1603647480369546 seconds)
2022-03-14 00:53:44 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 00:53:44 | INFO | train | epoch 049 | loss 5.956 | nll_loss 5.189 | ppl 36.48 | wps 27327 | ups 0.42 | wpb 65492.5 | bsz 127.9 | num_updates 19807 | lr 0.000224694 | gnorm 0.481 | loss_scale 16 | train_wall 842 | gb_free 9.7 | wall 46309
2022-03-14 00:53:44 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 00:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 00:57:20 | INFO | train_inner | epoch 050:     93 / 407 loss=5.926, nll_loss=5.156, ppl=35.65, wps=25129.7, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=19900, lr=0.000224168, gnorm=0.481, loss_scale=32, train_wall=207, gb_free=9.7, wall=46525
2022-03-14 00:59:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:01:13 | INFO | train_inner | epoch 050:    194 / 407 loss=5.946, nll_loss=5.178, ppl=36.2, wps=28064.9, ups=0.43, wpb=65534.2, bsz=128, num_updates=20000, lr=0.000223607, gnorm=0.482, loss_scale=32, train_wall=209, gb_free=9.7, wall=46758
2022-03-14 01:04:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:05:09 | INFO | train_inner | epoch 050:    295 / 407 loss=5.953, nll_loss=5.185, ppl=36.39, wps=27847.9, ups=0.42, wpb=65536, bsz=128, num_updates=20100, lr=0.00022305, gnorm=0.483, loss_scale=32, train_wall=211, gb_free=9.7, wall=46994
2022-03-14 01:08:58 | INFO | train_inner | epoch 050:    395 / 407 loss=5.968, nll_loss=5.202, ppl=36.8, wps=28532.3, ups=0.44, wpb=65536, bsz=128, num_updates=20200, lr=0.000222497, gnorm=0.48, loss_scale=32, train_wall=206, gb_free=9.7, wall=47224
2022-03-14 01:09:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:09:50 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.144 | nll_loss 5.345 | ppl 40.63 | wps 52028.9 | wpb 511.9 | bsz 1 | num_updates 20212 | best_loss 6.144
2022-03-14 01:09:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 20212 updates
2022-03-14 01:09:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:09:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:09:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 50 @ 20212 updates, score 6.144) (writing took 2.14259718201356 seconds)
2022-03-14 01:09:53 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 01:09:53 | INFO | train | epoch 050 | loss 5.949 | nll_loss 5.181 | ppl 36.29 | wps 27384.9 | ups 0.42 | wpb 65492.6 | bsz 127.9 | num_updates 20212 | lr 0.000222431 | gnorm 0.482 | loss_scale 64 | train_wall 844 | gb_free 9.7 | wall 47278
2022-03-14 01:09:53 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 01:09:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:13:19 | INFO | train_inner | epoch 051:     89 / 407 loss=5.922, nll_loss=5.151, ppl=35.54, wps=25065.3, ups=0.38, wpb=65361.9, bsz=127.7, num_updates=20300, lr=0.000221948, gnorm=0.49, loss_scale=32, train_wall=209, gb_free=9.7, wall=47484
2022-03-14 01:14:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:17:13 | INFO | train_inner | epoch 051:    190 / 407 loss=5.936, nll_loss=5.167, ppl=35.92, wps=28013.1, ups=0.43, wpb=65536, bsz=128, num_updates=20400, lr=0.000221404, gnorm=0.484, loss_scale=32, train_wall=210, gb_free=9.7, wall=47718
2022-03-14 01:19:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:21:07 | INFO | train_inner | epoch 051:    291 / 407 loss=5.949, nll_loss=5.181, ppl=36.28, wps=28011.3, ups=0.43, wpb=65536, bsz=128, num_updates=20500, lr=0.000220863, gnorm=0.485, loss_scale=32, train_wall=210, gb_free=9.7, wall=47952
2022-03-14 01:24:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:25:01 | INFO | train_inner | epoch 051:    392 / 407 loss=5.964, nll_loss=5.197, ppl=36.69, wps=28010.7, ups=0.43, wpb=65534.2, bsz=128, num_updates=20600, lr=0.000220326, gnorm=0.479, loss_scale=32, train_wall=210, gb_free=9.7, wall=48186
2022-03-14 01:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:26:02 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.148 | nll_loss 5.346 | ppl 40.68 | wps 51904 | wpb 511.9 | bsz 1 | num_updates 20615 | best_loss 6.144
2022-03-14 01:26:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 20615 updates
2022-03-14 01:26:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:26:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 01:26:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt (epoch 51 @ 20615 updates, score 6.148) (writing took 1.260178783966694 seconds)
2022-03-14 01:26:03 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 01:26:03 | INFO | train | epoch 051 | loss 5.942 | nll_loss 5.173 | ppl 36.08 | wps 27184.2 | ups 0.42 | wpb 65492.3 | bsz 127.9 | num_updates 20615 | lr 0.000220246 | gnorm 0.484 | loss_scale 32 | train_wall 847 | gb_free 9.7 | wall 48249
2022-03-14 01:26:03 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 01:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:29:31 | INFO | train_inner | epoch 052:     85 / 407 loss=5.92, nll_loss=5.149, ppl=35.48, wps=24173.8, ups=0.37, wpb=65360.1, bsz=127.7, num_updates=20700, lr=0.000219793, gnorm=0.486, loss_scale=32, train_wall=219, gb_free=9.7, wall=48457
2022-03-14 01:30:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:33:53 | INFO | train_inner | epoch 052:    186 / 407 loss=5.933, nll_loss=5.163, ppl=35.82, wps=25072.2, ups=0.38, wpb=65536, bsz=128, num_updates=20800, lr=0.000219265, gnorm=0.486, loss_scale=32, train_wall=236, gb_free=9.7, wall=48718
2022-03-14 01:36:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:38:16 | INFO | train_inner | epoch 052:    287 / 407 loss=5.943, nll_loss=5.174, ppl=36.11, wps=24938.3, ups=0.38, wpb=65536, bsz=128, num_updates=20900, lr=0.000218739, gnorm=0.48, loss_scale=32, train_wall=238, gb_free=9.7, wall=48981
2022-03-14 01:41:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 01:42:38 | INFO | train_inner | epoch 052:    388 / 407 loss=5.946, nll_loss=5.178, ppl=36.21, wps=25024.8, ups=0.38, wpb=65536, bsz=128, num_updates=21000, lr=0.000218218, gnorm=0.489, loss_scale=32, train_wall=237, gb_free=9.7, wall=49243
2022-03-14 01:43:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 01:43:57 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.141 | nll_loss 5.34 | ppl 40.51 | wps 45737.9 | wpb 511.9 | bsz 1 | num_updates 21019 | best_loss 6.141
2022-03-14 01:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 21019 updates
2022-03-14 01:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 01:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 52 @ 21019 updates, score 6.141) (writing took 2.4742302810191177 seconds)
2022-03-14 01:43:59 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 01:43:59 | INFO | train | epoch 052 | loss 5.935 | nll_loss 5.166 | ppl 35.9 | wps 24597.5 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 21019 | lr 0.000218119 | gnorm 0.485 | loss_scale 32 | train_wall 943 | gb_free 9.7 | wall 49324
2022-03-14 01:43:59 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 01:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 01:46:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 01:47:33 | INFO | train_inner | epoch 053:     82 / 407 loss=5.908, nll_loss=5.136, ppl=35.16, wps=22098.1, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=21100, lr=0.0002177, gnorm=0.488, loss_scale=16, train_wall=239, gb_free=9.7, wall=49538
2022-03-14 01:51:52 | INFO | train_inner | epoch 053:    182 / 407 loss=5.917, nll_loss=5.146, ppl=35.42, wps=25287.9, ups=0.39, wpb=65536, bsz=128, num_updates=21200, lr=0.000217186, gnorm=0.481, loss_scale=16, train_wall=234, gb_free=9.7, wall=49798
2022-03-14 01:56:11 | INFO | train_inner | epoch 053:    282 / 407 loss=5.948, nll_loss=5.18, ppl=36.26, wps=25330.9, ups=0.39, wpb=65534.2, bsz=128, num_updates=21300, lr=0.000216676, gnorm=0.486, loss_scale=32, train_wall=234, gb_free=9.7, wall=50056
2022-03-14 01:58:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:00:32 | INFO | train_inner | epoch 053:    383 / 407 loss=5.945, nll_loss=5.178, ppl=36.19, wps=25108.3, ups=0.38, wpb=65536, bsz=128, num_updates=21400, lr=0.000216169, gnorm=0.482, loss_scale=32, train_wall=236, gb_free=9.7, wall=50317
2022-03-14 02:01:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:02:04 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.143 | nll_loss 5.341 | ppl 40.54 | wps 46180.5 | wpb 511.9 | bsz 1 | num_updates 21424 | best_loss 6.141
2022-03-14 02:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 21424 updates
2022-03-14 02:02:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 02:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 02:02:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt (epoch 53 @ 21424 updates, score 6.143) (writing took 1.258450069988612 seconds)
2022-03-14 02:02:06 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 02:02:06 | INFO | train | epoch 053 | loss 5.928 | nll_loss 5.159 | ppl 35.72 | wps 24415.7 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 21424 | lr 0.000216048 | gnorm 0.485 | loss_scale 32 | train_wall 955 | gb_free 9.7 | wall 50411
2022-03-14 02:02:06 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 02:02:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:02:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 02:05:26 | INFO | train_inner | epoch 054:     77 / 407 loss=5.892, nll_loss=5.119, ppl=34.76, wps=22275, ups=0.34, wpb=65360.1, bsz=127.7, num_updates=21500, lr=0.000215666, gnorm=0.485, loss_scale=16, train_wall=238, gb_free=9.7, wall=50611
2022-03-14 02:09:45 | INFO | train_inner | epoch 054:    177 / 407 loss=5.916, nll_loss=5.145, ppl=35.39, wps=25293.3, ups=0.39, wpb=65536, bsz=128, num_updates=21600, lr=0.000215166, gnorm=0.487, loss_scale=32, train_wall=234, gb_free=9.7, wall=50870
2022-03-14 02:14:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:14:06 | INFO | train_inner | epoch 054:    278 / 407 loss=5.932, nll_loss=5.162, ppl=35.81, wps=25085.5, ups=0.38, wpb=65536, bsz=128, num_updates=21700, lr=0.000214669, gnorm=0.479, loss_scale=32, train_wall=236, gb_free=9.7, wall=51131
2022-03-14 02:18:24 | INFO | train_inner | epoch 054:    378 / 407 loss=5.944, nll_loss=5.175, ppl=36.14, wps=25447.7, ups=0.39, wpb=65536, bsz=128, num_updates=21800, lr=0.000214176, gnorm=0.484, loss_scale=32, train_wall=233, gb_free=9.7, wall=51389
2022-03-14 02:19:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:20:09 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.134 | nll_loss 5.333 | ppl 40.3 | wps 45253.6 | wpb 511.9 | bsz 1 | num_updates 21828 | best_loss 6.134
2022-03-14 02:20:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 21828 updates
2022-03-14 02:20:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:20:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 54 @ 21828 updates, score 6.134) (writing took 2.3388528099749237 seconds)
2022-03-14 02:20:11 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 02:20:11 | INFO | train | epoch 054 | loss 5.922 | nll_loss 5.152 | ppl 35.56 | wps 24374.9 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 21828 | lr 0.000214039 | gnorm 0.484 | loss_scale 32 | train_wall 953 | gb_free 9.7 | wall 51496
2022-03-14 02:20:11 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 02:20:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:23:19 | INFO | train_inner | epoch 055:     72 / 407 loss=5.913, nll_loss=5.142, ppl=35.3, wps=22090.2, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=21900, lr=0.000213687, gnorm=0.493, loss_scale=32, train_wall=239, gb_free=9.7, wall=51684
2022-03-14 02:25:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:27:40 | INFO | train_inner | epoch 055:    173 / 407 loss=5.91, nll_loss=5.138, ppl=35.21, wps=25125, ups=0.38, wpb=65536, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.481, loss_scale=32, train_wall=236, gb_free=9.7, wall=51945
2022-03-14 02:31:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:32:03 | INFO | train_inner | epoch 055:    274 / 407 loss=5.91, nll_loss=5.138, ppl=35.22, wps=24912.7, ups=0.38, wpb=65536, bsz=128, num_updates=22100, lr=0.000212718, gnorm=0.482, loss_scale=32, train_wall=238, gb_free=9.7, wall=52208
2022-03-14 02:36:21 | INFO | train_inner | epoch 055:    374 / 407 loss=5.93, nll_loss=5.16, ppl=35.76, wps=25390.5, ups=0.39, wpb=65534.2, bsz=128, num_updates=22200, lr=0.000212238, gnorm=0.481, loss_scale=32, train_wall=233, gb_free=9.7, wall=52466
2022-03-14 02:36:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:38:18 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.135 | nll_loss 5.335 | ppl 40.36 | wps 44538.4 | wpb 511.9 | bsz 1 | num_updates 22232 | best_loss 6.134
2022-03-14 02:38:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 22232 updates
2022-03-14 02:38:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 02:38:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 02:38:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt (epoch 55 @ 22232 updates, score 6.135) (writing took 1.3204764259862714 seconds)
2022-03-14 02:38:19 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 02:38:19 | INFO | train | epoch 055 | loss 5.916 | nll_loss 5.145 | ppl 35.39 | wps 24316.7 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 22232 | lr 0.000212085 | gnorm 0.484 | loss_scale 32 | train_wall 956 | gb_free 9.7 | wall 52584
2022-03-14 02:38:19 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 02:38:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:41:16 | INFO | train_inner | epoch 056:     68 / 407 loss=5.902, nll_loss=5.13, ppl=35.01, wps=22160.5, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=22300, lr=0.000211762, gnorm=0.488, loss_scale=32, train_wall=238, gb_free=9.7, wall=52761
2022-03-14 02:43:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:44:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 02:45:40 | INFO | train_inner | epoch 056:    170 / 407 loss=5.9, nll_loss=5.127, ppl=34.95, wps=24846.4, ups=0.38, wpb=65536, bsz=128, num_updates=22400, lr=0.000211289, gnorm=0.486, loss_scale=16, train_wall=239, gb_free=9.7, wall=53025
2022-03-14 02:49:59 | INFO | train_inner | epoch 056:    270 / 407 loss=5.919, nll_loss=5.148, ppl=35.46, wps=25274.3, ups=0.39, wpb=65536, bsz=128, num_updates=22500, lr=0.000210819, gnorm=0.483, loss_scale=16, train_wall=235, gb_free=9.7, wall=53284
2022-03-14 02:54:19 | INFO | train_inner | epoch 056:    370 / 407 loss=5.927, nll_loss=5.157, ppl=35.68, wps=25228.7, ups=0.38, wpb=65534.2, bsz=128, num_updates=22600, lr=0.000210352, gnorm=0.489, loss_scale=32, train_wall=235, gb_free=9.7, wall=53544
2022-03-14 02:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 02:56:24 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 6.128 | nll_loss 5.326 | ppl 40.12 | wps 45730 | wpb 511.9 | bsz 1 | num_updates 22637 | best_loss 6.128
2022-03-14 02:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 22637 updates
2022-03-14 02:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 02:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 56 @ 22637 updates, score 6.128) (writing took 2.295744155999273 seconds)
2022-03-14 02:56:26 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 02:56:26 | INFO | train | epoch 056 | loss 5.911 | nll_loss 5.139 | ppl 35.24 | wps 24393.8 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 22637 | lr 0.00021018 | gnorm 0.486 | loss_scale 64 | train_wall 955 | gb_free 9.7 | wall 53671
2022-03-14 02:56:26 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 02:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 02:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 02:59:13 | INFO | train_inner | epoch 057:     64 / 407 loss=5.894, nll_loss=5.121, ppl=34.8, wps=22234.8, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=22700, lr=0.000209888, gnorm=0.484, loss_scale=32, train_wall=237, gb_free=9.7, wall=53838
2022-03-14 03:02:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:03:36 | INFO | train_inner | epoch 057:    165 / 407 loss=5.896, nll_loss=5.123, ppl=34.85, wps=24973.2, ups=0.38, wpb=65536, bsz=128, num_updates=22800, lr=0.000209427, gnorm=0.488, loss_scale=32, train_wall=237, gb_free=9.7, wall=54101
2022-03-14 03:07:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:07:57 | INFO | train_inner | epoch 057:    266 / 407 loss=5.906, nll_loss=5.134, ppl=35.1, wps=25100.4, ups=0.38, wpb=65534.2, bsz=128, num_updates=22900, lr=0.000208969, gnorm=0.484, loss_scale=32, train_wall=236, gb_free=9.7, wall=54362
2022-03-14 03:12:16 | INFO | train_inner | epoch 057:    366 / 407 loss=5.925, nll_loss=5.155, ppl=35.63, wps=25286, ups=0.39, wpb=65536, bsz=128, num_updates=23000, lr=0.000208514, gnorm=0.487, loss_scale=32, train_wall=234, gb_free=9.7, wall=54621
2022-03-14 03:13:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:13:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:14:33 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 6.124 | nll_loss 5.32 | ppl 39.96 | wps 44598.3 | wpb 511.9 | bsz 1 | num_updates 23039 | best_loss 6.124
2022-03-14 03:14:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 23039 updates
2022-03-14 03:14:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:14:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:14:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 57 @ 23039 updates, score 6.124) (writing took 2.2946404769900255 seconds)
2022-03-14 03:14:35 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 03:14:35 | INFO | train | epoch 057 | loss 5.905 | nll_loss 5.133 | ppl 35.08 | wps 24178.4 | ups 0.37 | wpb 65492.2 | bsz 127.9 | num_updates 23039 | lr 0.000208338 | gnorm 0.485 | loss_scale 16 | train_wall 956 | gb_free 9.7 | wall 54760
2022-03-14 03:14:35 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 03:14:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:17:15 | INFO | train_inner | epoch 058:     61 / 407 loss=5.893, nll_loss=5.12, ppl=34.76, wps=21861.3, ups=0.33, wpb=65361.9, bsz=127.7, num_updates=23100, lr=0.000208063, gnorm=0.483, loss_scale=16, train_wall=241, gb_free=9.7, wall=54920
2022-03-14 03:21:34 | INFO | train_inner | epoch 058:    161 / 407 loss=5.885, nll_loss=5.111, ppl=34.55, wps=25288.9, ups=0.39, wpb=65536, bsz=128, num_updates=23200, lr=0.000207614, gnorm=0.486, loss_scale=32, train_wall=234, gb_free=9.7, wall=55179
2022-03-14 03:25:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:25:54 | INFO | train_inner | epoch 058:    262 / 407 loss=5.898, nll_loss=5.126, ppl=34.91, wps=25158.3, ups=0.38, wpb=65534.2, bsz=128, num_updates=23300, lr=0.000207168, gnorm=0.484, loss_scale=32, train_wall=236, gb_free=9.7, wall=55440
2022-03-14 03:30:12 | INFO | train_inner | epoch 058:    362 / 407 loss=5.913, nll_loss=5.142, ppl=35.3, wps=25416.3, ups=0.39, wpb=65536, bsz=128, num_updates=23400, lr=0.000206725, gnorm=0.483, loss_scale=32, train_wall=233, gb_free=9.7, wall=55697
2022-03-14 03:30:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:32:37 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 6.124 | nll_loss 5.322 | ppl 40.01 | wps 45323.3 | wpb 511.9 | bsz 1 | num_updates 23444 | best_loss 6.124
2022-03-14 03:32:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 23444 updates
2022-03-14 03:32:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:32:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 58 @ 23444 updates, score 6.124) (writing took 2.2579750660224818 seconds)
2022-03-14 03:32:39 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 03:32:39 | INFO | train | epoch 058 | loss 5.898 | nll_loss 5.126 | ppl 34.92 | wps 24473.3 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 23444 | lr 0.00020653 | gnorm 0.485 | loss_scale 32 | train_wall 952 | gb_free 9.7 | wall 55844
2022-03-14 03:32:39 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 03:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:35:04 | INFO | train_inner | epoch 059:     56 / 407 loss=5.896, nll_loss=5.123, ppl=34.86, wps=22393.5, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=23500, lr=0.000206284, gnorm=0.486, loss_scale=32, train_wall=235, gb_free=9.7, wall=55989
2022-03-14 03:36:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:39:25 | INFO | train_inner | epoch 059:    157 / 407 loss=5.874, nll_loss=5.099, ppl=34.27, wps=25117.3, ups=0.38, wpb=65534.2, bsz=128, num_updates=23600, lr=0.000205847, gnorm=0.485, loss_scale=32, train_wall=236, gb_free=9.7, wall=56250
2022-03-14 03:41:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 03:43:45 | INFO | train_inner | epoch 059:    258 / 407 loss=5.9, nll_loss=5.127, ppl=34.96, wps=25246.3, ups=0.39, wpb=65536, bsz=128, num_updates=23700, lr=0.000205412, gnorm=0.488, loss_scale=16, train_wall=235, gb_free=9.7, wall=56510
2022-03-14 03:48:04 | INFO | train_inner | epoch 059:    358 / 407 loss=5.905, nll_loss=5.132, ppl=35.08, wps=25271.5, ups=0.39, wpb=65536, bsz=128, num_updates=23800, lr=0.00020498, gnorm=0.485, loss_scale=32, train_wall=235, gb_free=9.7, wall=56769
2022-03-14 03:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 03:50:41 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 6.12 | nll_loss 5.316 | ppl 39.82 | wps 45505.6 | wpb 511.9 | bsz 1 | num_updates 23849 | best_loss 6.12
2022-03-14 03:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 23849 updates
2022-03-14 03:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:50:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 03:50:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 59 @ 23849 updates, score 6.12) (writing took 2.325457122991793 seconds)
2022-03-14 03:50:44 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 03:50:44 | INFO | train | epoch 059 | loss 5.893 | nll_loss 5.12 | ppl 34.78 | wps 24459.7 | ups 0.37 | wpb 65492.6 | bsz 127.9 | num_updates 23849 | lr 0.000204769 | gnorm 0.487 | loss_scale 32 | train_wall 952 | gb_free 9.7 | wall 56929
2022-03-14 03:50:44 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 03:50:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 03:52:58 | INFO | train_inner | epoch 060:     51 / 407 loss=5.887, nll_loss=5.114, ppl=34.62, wps=22238.4, ups=0.34, wpb=65360.1, bsz=127.7, num_updates=23900, lr=0.000204551, gnorm=0.491, loss_scale=32, train_wall=237, gb_free=9.7, wall=57063
2022-03-14 03:53:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 03:57:21 | INFO | train_inner | epoch 060:    152 / 407 loss=5.875, nll_loss=5.1, ppl=34.3, wps=24934.8, ups=0.38, wpb=65536, bsz=128, num_updates=24000, lr=0.000204124, gnorm=0.489, loss_scale=32, train_wall=238, gb_free=9.7, wall=57326
2022-03-14 03:59:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:01:42 | INFO | train_inner | epoch 060:    253 / 407 loss=5.885, nll_loss=5.111, ppl=34.56, wps=25072.2, ups=0.38, wpb=65536, bsz=128, num_updates=24100, lr=0.0002037, gnorm=0.484, loss_scale=32, train_wall=236, gb_free=9.7, wall=57587
2022-03-14 04:04:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:06:06 | INFO | train_inner | epoch 060:    354 / 407 loss=5.91, nll_loss=5.139, ppl=35.23, wps=24851.3, ups=0.38, wpb=65536, bsz=128, num_updates=24200, lr=0.000203279, gnorm=0.487, loss_scale=32, train_wall=239, gb_free=9.7, wall=57851
2022-03-14 04:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:08:53 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 6.119 | nll_loss 5.314 | ppl 39.79 | wps 44504.2 | wpb 511.9 | bsz 1 | num_updates 24253 | best_loss 6.119
2022-03-14 04:08:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 24253 updates
2022-03-14 04:08:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:08:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:08:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 60 @ 24253 updates, score 6.119) (writing took 2.337093140988145 seconds)
2022-03-14 04:08:55 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 04:08:55 | INFO | train | epoch 060 | loss 5.888 | nll_loss 5.115 | ppl 34.65 | wps 24242.8 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 24253 | lr 0.000203057 | gnorm 0.487 | loss_scale 32 | train_wall 958 | gb_free 9.7 | wall 58020
2022-03-14 04:08:55 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 04:08:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:10:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:11:00 | INFO | train_inner | epoch 061:     48 / 407 loss=5.886, nll_loss=5.112, ppl=34.59, wps=22241.8, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=24300, lr=0.00020286, gnorm=0.488, loss_scale=32, train_wall=236, gb_free=9.7, wall=58145
2022-03-14 04:15:18 | INFO | train_inner | epoch 061:    148 / 407 loss=5.871, nll_loss=5.096, ppl=34.2, wps=25347.6, ups=0.39, wpb=65536, bsz=128, num_updates=24400, lr=0.000202444, gnorm=0.489, loss_scale=32, train_wall=234, gb_free=9.7, wall=58403
2022-03-14 04:16:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:19:41 | INFO | train_inner | epoch 061:    249 / 407 loss=5.878, nll_loss=5.104, ppl=34.38, wps=24898.7, ups=0.38, wpb=65534.2, bsz=128, num_updates=24500, lr=0.000202031, gnorm=0.493, loss_scale=32, train_wall=238, gb_free=9.7, wall=58667
2022-03-14 04:19:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:24:03 | INFO | train_inner | epoch 061:    350 / 407 loss=5.901, nll_loss=5.128, ppl=34.98, wps=25041.8, ups=0.38, wpb=65536, bsz=128, num_updates=24600, lr=0.000201619, gnorm=0.488, loss_scale=16, train_wall=237, gb_free=9.7, wall=58928
2022-03-14 04:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:26:59 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 6.121 | nll_loss 5.316 | ppl 39.83 | wps 45469 | wpb 511.9 | bsz 1 | num_updates 24657 | best_loss 6.119
2022-03-14 04:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 24657 updates
2022-03-14 04:26:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:27:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 04:27:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt (epoch 61 @ 24657 updates, score 6.121) (writing took 1.3127318280166946 seconds)
2022-03-14 04:27:00 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 04:27:00 | INFO | train | epoch 061 | loss 5.883 | nll_loss 5.109 | ppl 34.51 | wps 24376.8 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 24657 | lr 0.000201386 | gnorm 0.489 | loss_scale 32 | train_wall 954 | gb_free 9.7 | wall 59105
2022-03-14 04:27:00 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 04:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:27:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:28:55 | INFO | train_inner | epoch 062:     44 / 407 loss=5.883, nll_loss=5.109, ppl=34.52, wps=22413.6, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=24700, lr=0.000201211, gnorm=0.489, loss_scale=16, train_wall=236, gb_free=9.7, wall=59220
2022-03-14 04:33:13 | INFO | train_inner | epoch 062:    144 / 407 loss=5.864, nll_loss=5.088, ppl=34.01, wps=25383.9, ups=0.39, wpb=65534.2, bsz=128, num_updates=24800, lr=0.000200805, gnorm=0.493, loss_scale=32, train_wall=233, gb_free=9.7, wall=59478
2022-03-14 04:37:32 | INFO | train_inner | epoch 062:    244 / 407 loss=5.878, nll_loss=5.103, ppl=34.38, wps=25303.7, ups=0.39, wpb=65536, bsz=128, num_updates=24900, lr=0.000200401, gnorm=0.486, loss_scale=32, train_wall=234, gb_free=9.7, wall=59737
2022-03-14 04:38:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:41:53 | INFO | train_inner | epoch 062:    345 / 407 loss=5.892, nll_loss=5.118, ppl=34.74, wps=25092, ups=0.38, wpb=65536, bsz=128, num_updates=25000, lr=0.0002, gnorm=0.487, loss_scale=32, train_wall=236, gb_free=9.7, wall=59998
2022-03-14 04:44:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 04:44:58 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 6.113 | nll_loss 5.308 | ppl 39.62 | wps 46396.6 | wpb 511.9 | bsz 1 | num_updates 25061 | best_loss 6.113
2022-03-14 04:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 25061 updates
2022-03-14 04:44:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:44:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 04:45:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 62 @ 25061 updates, score 6.113) (writing took 2.2319022479932755 seconds)
2022-03-14 04:45:01 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 04:45:01 | INFO | train | epoch 062 | loss 5.878 | nll_loss 5.103 | ppl 34.37 | wps 24496.6 | ups 0.37 | wpb 65492.5 | bsz 127.9 | num_updates 25061 | lr 0.000199756 | gnorm 0.49 | loss_scale 32 | train_wall 949 | gb_free 9.7 | wall 60186
2022-03-14 04:45:01 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 04:45:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 04:46:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 04:46:43 | INFO | train_inner | epoch 063:     40 / 407 loss=5.874, nll_loss=5.099, ppl=34.27, wps=22550.5, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=25100, lr=0.000199601, gnorm=0.492, loss_scale=16, train_wall=234, gb_free=9.7, wall=60288
2022-03-14 04:50:58 | INFO | train_inner | epoch 063:    140 / 407 loss=5.861, nll_loss=5.085, ppl=33.95, wps=25655.8, ups=0.39, wpb=65536, bsz=128, num_updates=25200, lr=0.000199205, gnorm=0.49, loss_scale=16, train_wall=231, gb_free=9.7, wall=60544
2022-03-14 04:55:15 | INFO | train_inner | epoch 063:    240 / 407 loss=5.874, nll_loss=5.099, ppl=34.26, wps=25570.5, ups=0.39, wpb=65534.2, bsz=128, num_updates=25300, lr=0.000198811, gnorm=0.49, loss_scale=32, train_wall=232, gb_free=9.7, wall=60800
2022-03-14 04:57:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 04:59:33 | INFO | train_inner | epoch 063:    341 / 407 loss=5.884, nll_loss=5.11, ppl=34.53, wps=25374.1, ups=0.39, wpb=65536, bsz=128, num_updates=25400, lr=0.000198419, gnorm=0.489, loss_scale=32, train_wall=234, gb_free=9.7, wall=61058
2022-03-14 05:01:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 05:02:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:02:49 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 6.112 | nll_loss 5.309 | ppl 39.65 | wps 46342.1 | wpb 511.9 | bsz 1 | num_updates 25465 | best_loss 6.112
2022-03-14 05:02:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 25465 updates
2022-03-14 05:02:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:02:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 63 @ 25465 updates, score 6.112) (writing took 2.2698403850081377 seconds)
2022-03-14 05:02:52 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 05:02:52 | INFO | train | epoch 063 | loss 5.873 | nll_loss 5.098 | ppl 34.25 | wps 24701.3 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 25465 | lr 0.000198166 | gnorm 0.49 | loss_scale 16 | train_wall 940 | gb_free 9.7 | wall 61257
2022-03-14 05:02:52 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 05:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:04:23 | INFO | train_inner | epoch 064:     35 / 407 loss=5.873, nll_loss=5.098, ppl=34.24, wps=22574.1, ups=0.35, wpb=65360.1, bsz=127.7, num_updates=25500, lr=0.00019803, gnorm=0.49, loss_scale=16, train_wall=233, gb_free=9.7, wall=61348
2022-03-14 05:08:38 | INFO | train_inner | epoch 064:    135 / 407 loss=5.856, nll_loss=5.079, ppl=33.81, wps=25661.6, ups=0.39, wpb=65536, bsz=128, num_updates=25600, lr=0.000197642, gnorm=0.49, loss_scale=32, train_wall=231, gb_free=9.7, wall=61603
2022-03-14 05:12:53 | INFO | train_inner | epoch 064:    235 / 407 loss=5.87, nll_loss=5.095, ppl=34.17, wps=25653.3, ups=0.39, wpb=65536, bsz=128, num_updates=25700, lr=0.000197257, gnorm=0.499, loss_scale=32, train_wall=231, gb_free=9.7, wall=61858
2022-03-14 05:13:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:17:10 | INFO | train_inner | epoch 064:    336 / 407 loss=5.874, nll_loss=5.1, ppl=34.29, wps=25523.8, ups=0.39, wpb=65536, bsz=128, num_updates=25800, lr=0.000196875, gnorm=0.497, loss_scale=32, train_wall=232, gb_free=9.7, wall=62115
2022-03-14 05:18:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:20:40 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 6.107 | nll_loss 5.303 | ppl 39.48 | wps 45062.7 | wpb 511.9 | bsz 1 | num_updates 25870 | best_loss 6.107
2022-03-14 05:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 25870 updates
2022-03-14 05:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:20:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 64 @ 25870 updates, score 6.107) (writing took 2.259258377016522 seconds)
2022-03-14 05:20:42 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 05:20:42 | INFO | train | epoch 064 | loss 5.869 | nll_loss 5.093 | ppl 34.14 | wps 24775.1 | ups 0.38 | wpb 65492.6 | bsz 127.9 | num_updates 25870 | lr 0.000196608 | gnorm 0.495 | loss_scale 32 | train_wall 938 | gb_free 9.7 | wall 62327
2022-03-14 05:20:42 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 05:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:22:01 | INFO | train_inner | epoch 065:     30 / 407 loss=5.879, nll_loss=5.104, ppl=34.4, wps=22497.9, ups=0.34, wpb=65361.9, bsz=127.7, num_updates=25900, lr=0.000196494, gnorm=0.498, loss_scale=32, train_wall=234, gb_free=9.7, wall=62406
2022-03-14 05:24:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:26:17 | INFO | train_inner | epoch 065:    131 / 407 loss=5.851, nll_loss=5.074, ppl=33.68, wps=25553.7, ups=0.39, wpb=65536, bsz=128, num_updates=26000, lr=0.000196116, gnorm=0.494, loss_scale=32, train_wall=232, gb_free=9.7, wall=62662
2022-03-14 05:30:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:30:33 | INFO | train_inner | epoch 065:    232 / 407 loss=5.866, nll_loss=5.091, ppl=34.07, wps=25585.3, ups=0.39, wpb=65536, bsz=128, num_updates=26100, lr=0.00019574, gnorm=0.492, loss_scale=32, train_wall=231, gb_free=9.7, wall=62918
2022-03-14 05:34:47 | INFO | train_inner | epoch 065:    332 / 407 loss=5.875, nll_loss=5.1, ppl=34.3, wps=25787.4, ups=0.39, wpb=65534.2, bsz=128, num_updates=26200, lr=0.000195366, gnorm=0.494, loss_scale=32, train_wall=230, gb_free=9.7, wall=63173
2022-03-14 05:35:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:37:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:38:25 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 6.104 | nll_loss 5.301 | ppl 39.42 | wps 45064.4 | wpb 511.9 | bsz 1 | num_updates 26274 | best_loss 6.104
2022-03-14 05:38:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 26274 updates
2022-03-14 05:38:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:38:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 65 @ 26274 updates, score 6.104) (writing took 2.2981910860398784 seconds)
2022-03-14 05:38:28 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 05:38:28 | INFO | train | epoch 065 | loss 5.864 | nll_loss 5.089 | ppl 34.02 | wps 24836.7 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 26274 | lr 0.000195091 | gnorm 0.494 | loss_scale 32 | train_wall 933 | gb_free 9.7 | wall 63393
2022-03-14 05:38:28 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 05:38:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:39:35 | INFO | train_inner | epoch 066:     26 / 407 loss=5.865, nll_loss=5.089, ppl=34.04, wps=22756.3, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=26300, lr=0.000194994, gnorm=0.496, loss_scale=32, train_wall=230, gb_free=9.7, wall=63460
2022-03-14 05:41:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:43:53 | INFO | train_inner | epoch 066:    127 / 407 loss=5.843, nll_loss=5.065, ppl=33.47, wps=25370.2, ups=0.39, wpb=65536, bsz=128, num_updates=26400, lr=0.000194625, gnorm=0.488, loss_scale=32, train_wall=233, gb_free=9.7, wall=63718
2022-03-14 05:47:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:48:11 | INFO | train_inner | epoch 066:    228 / 407 loss=5.861, nll_loss=5.085, ppl=33.94, wps=25445, ups=0.39, wpb=65536, bsz=128, num_updates=26500, lr=0.000194257, gnorm=0.493, loss_scale=32, train_wall=233, gb_free=9.7, wall=63976
2022-03-14 05:52:27 | INFO | train_inner | epoch 066:    328 / 407 loss=5.866, nll_loss=5.091, ppl=34.07, wps=25585.1, ups=0.39, wpb=65536, bsz=128, num_updates=26600, lr=0.000193892, gnorm=0.49, loss_scale=32, train_wall=232, gb_free=9.7, wall=64232
2022-03-14 05:52:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 05:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 05:56:15 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 6.104 | nll_loss 5.298 | ppl 39.35 | wps 44939.7 | wpb 511.9 | bsz 1 | num_updates 26678 | best_loss 6.104
2022-03-14 05:56:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 26678 updates
2022-03-14 05:56:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt
2022-03-14 05:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_best.pt (epoch 66 @ 26678 updates, score 6.104) (writing took 2.2917300149565563 seconds)
2022-03-14 05:56:18 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 05:56:18 | INFO | train | epoch 066 | loss 5.86 | nll_loss 5.084 | ppl 33.91 | wps 24728.5 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 26678 | lr 0.000193608 | gnorm 0.491 | loss_scale 32 | train_wall 938 | gb_free 9.7 | wall 64463
2022-03-14 05:56:18 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 05:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 05:57:14 | INFO | train_inner | epoch 067:     22 / 407 loss=5.87, nll_loss=5.095, ppl=34.17, wps=22721.4, ups=0.35, wpb=65360.1, bsz=127.7, num_updates=26700, lr=0.000193528, gnorm=0.494, loss_scale=32, train_wall=231, gb_free=9.7, wall=64519
2022-03-14 05:58:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 06:01:34 | INFO | train_inner | epoch 067:    123 / 407 loss=5.831, nll_loss=5.052, ppl=33.18, wps=25272, ups=0.39, wpb=65536, bsz=128, num_updates=26800, lr=0.000193167, gnorm=0.492, loss_scale=32, train_wall=234, gb_free=9.7, wall=64779
2022-03-14 06:02:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:05:51 | INFO | train_inner | epoch 067:    224 / 407 loss=5.854, nll_loss=5.077, ppl=33.76, wps=25442.6, ups=0.39, wpb=65534.2, bsz=128, num_updates=26900, lr=0.000192807, gnorm=0.496, loss_scale=16, train_wall=233, gb_free=9.7, wall=65036
2022-03-14 06:10:06 | INFO | train_inner | epoch 067:    324 / 407 loss=5.868, nll_loss=5.093, ppl=34.13, wps=25681.3, ups=0.39, wpb=65536, bsz=128, num_updates=27000, lr=0.00019245, gnorm=0.496, loss_scale=32, train_wall=231, gb_free=9.7, wall=65292
2022-03-14 06:13:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 06:13:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:14:04 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 6.109 | nll_loss 5.301 | ppl 39.43 | wps 45610.1 | wpb 511.9 | bsz 1 | num_updates 27082 | best_loss 6.104
2022-03-14 06:14:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 27082 updates
2022-03-14 06:14:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt (epoch 67 @ 27082 updates, score 6.109) (writing took 1.262131363968365 seconds)
2022-03-14 06:14:06 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 06:14:06 | INFO | train | epoch 067 | loss 5.856 | nll_loss 5.079 | ppl 33.8 | wps 24774.4 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 27082 | lr 0.000192159 | gnorm 0.495 | loss_scale 32 | train_wall 937 | gb_free 9.7 | wall 65531
2022-03-14 06:14:06 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 06:14:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 06:14:52 | INFO | train_inner | epoch 068:     18 / 407 loss=5.867, nll_loss=5.092, ppl=34.1, wps=22931, ups=0.35, wpb=65361.9, bsz=127.7, num_updates=27100, lr=0.000192095, gnorm=0.495, loss_scale=32, train_wall=230, gb_free=9.7, wall=65577
2022-03-14 06:19:05 | INFO | train_inner | epoch 068:    118 / 407 loss=5.829, nll_loss=5.05, ppl=33.12, wps=25892.6, ups=0.4, wpb=65534.2, bsz=128, num_updates=27200, lr=0.000191741, gnorm=0.492, loss_scale=32, train_wall=228, gb_free=9.7, wall=65830
2022-03-14 06:19:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 06:20:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:23:20 | INFO | train_inner | epoch 068:    220 / 407 loss=5.845, nll_loss=5.067, ppl=33.53, wps=25677.2, ups=0.39, wpb=65536, bsz=128, num_updates=27300, lr=0.00019139, gnorm=0.496, loss_scale=16, train_wall=230, gb_free=9.7, wall=66085
2022-03-14 06:27:30 | INFO | train_inner | epoch 068:    320 / 407 loss=5.863, nll_loss=5.087, ppl=33.98, wps=26207, ups=0.4, wpb=65536, bsz=128, num_updates=27400, lr=0.00019104, gnorm=0.492, loss_scale=32, train_wall=226, gb_free=9.7, wall=66335
2022-03-14 06:27:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 06:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 06:31:34 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 6.105 | nll_loss 5.301 | ppl 39.43 | wps 45957.8 | wpb 511.9 | bsz 1 | num_updates 27486 | best_loss 6.104
2022-03-14 06:31:34 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 06:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 27486 updates
2022-03-14 06:31:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt
2022-03-14 06:31:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/ru_label_smoothing_0.05_dropout_0.3_#1/checkpoint_last.pt (epoch 68 @ 27486 updates, score 6.105) (writing took 1.2828822250012308 seconds)
2022-03-14 06:31:35 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 06:31:35 | INFO | train | epoch 068 | loss 5.851 | nll_loss 5.074 | ppl 33.68 | wps 25212.7 | ups 0.38 | wpb 65492.5 | bsz 127.9 | num_updates 27486 | lr 0.000190741 | gnorm 0.493 | loss_scale 16 | train_wall 919 | gb_free 9.7 | wall 66580
2022-03-14 06:31:35 | INFO | fairseq_cli.train | done training in 66579.5 seconds
