Sender: LSF System <lsfadmin@eu-g3-053>
Subject: Job 208118001: <iwslt14_de_en_dropout_0.05> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.05> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 07:11:36 2022
Job was executed on host(s) <eu-g3-053>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Mon Mar 14 07:12:11 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 07:12:11 2022
Terminated at Mon Mar 14 08:04:41 2022
Results reported at Mon Mar 14 08:04:41 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.05 --weight-decay 0.0001 --criterion cross_entropy --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3136.68 sec.
    Max Memory :                                 4737 MB
    Average Memory :                             3306.60 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15263.00 MB
    Max Swap :                                   54 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3149 sec.
    Turnaround time :                            3185 sec.

The output (if any) follows:

2022-03-14 07:12:24 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.05, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 07:12:24 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-14 07:12:24 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-14 07:12:25 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-14 07:12:25 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-14 07:12:25 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-14 07:12:25 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-14 07:12:25 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-14 07:12:25 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 07:12:25 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-14 07:12:25 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-14 07:12:25 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-14 07:12:28 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 07:12:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:12:28 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-14 07:12:28 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:12:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 07:12:28 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-14 07:12:28 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:12:28 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:12:28 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 07:12:28 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-14 07:12:28 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-14 07:12:28 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-14 07:12:29 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 07:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:12:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 07:12:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 07:12:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:12:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 07:12:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-14 07:13:04 | INFO | train_inner | epoch 001:    105 / 157 loss=11.659, ppl=3233.03, wps=81040.9, ups=3.22, wpb=25186.5, bsz=962.7, num_updates=100, lr=1.25e-05, gnorm=4.324, loss_scale=4, train_wall=34, gb_free=14.3, wall=36
2022-03-14 07:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:13:24 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the....
2022-03-14 07:13:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:13:28 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the
2022-03-14 07:13:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:13:32 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-14 07:13:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:13:37 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,........
2022-03-14 07:13:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:13:42 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:13:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:13:47 | INFO | fairseq.tasks.translation | example hypothesis: and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-14 07:13:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:13:53 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:13:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:13:59 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:13:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:14:06 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:14:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:14:08 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:14:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:14:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.908 | ppl 961.01 | bleu 0.02 | wps 3681 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-14 07:14:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-14 07:14:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:14:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.02) (writing took 2.1383707928471267 seconds)
2022-03-14 07:14:10 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 07:14:10 | INFO | train | epoch 001 | loss 11.174 | ppl 2310.51 | wps 38934 | ups 1.55 | wpb 25082.4 | bsz 995.7 | num_updates 152 | lr 1.9e-05 | gnorm 3.499 | loss_scale 4 | train_wall 50 | gb_free 22.4 | wall 102
2022-03-14 07:14:11 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 07:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:14:26 | INFO | train_inner | epoch 002:     48 / 157 loss=9.94, ppl=982.45, wps=30836.7, ups=1.22, wpb=25339.2, bsz=1116.9, num_updates=200, lr=2.5e-05, gnorm=2.456, loss_scale=4, train_wall=30, gb_free=14.6, wall=118
2022-03-14 07:14:57 | INFO | train_inner | epoch 002:    148 / 157 loss=9.188, ppl=583.31, wps=79847.4, ups=3.2, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.795, loss_scale=4, train_wall=31, gb_free=20.2, wall=149
2022-03-14 07:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:15:03 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-14 07:15:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:15:07 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the.
2022-03-14 07:15:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:15:10 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the.
2022-03-14 07:15:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:15:13 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the,,,,,,,,,,,,,,,,,,.
2022-03-14 07:15:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:15:17 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the the.
2022-03-14 07:15:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:15:21 | INFO | fairseq.tasks.translation | example hypothesis: and and the the the the the the the the the the the the the the the the.
2022-03-14 07:15:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:15:26 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the
2022-03-14 07:15:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:15:31 | INFO | fairseq.tasks.translation | example hypothesis: and we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-14 07:15:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:15:37 | INFO | fairseq.tasks.translation | example hypothesis: and the,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" "" "" "" "". "" "" ""
2022-03-14 07:15:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:15:40 | INFO | fairseq.tasks.translation | example hypothesis: and the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:15:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:15:40 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.838 | ppl 457.59 | bleu 0.04 | wps 4502.2 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.04
2022-03-14 07:15:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-14 07:15:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:15:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.04) (writing took 2.1572726289741695 seconds)
2022-03-14 07:15:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 07:15:42 | INFO | train | epoch 002 | loss 9.313 | ppl 636.02 | wps 43202 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 2.225 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 194
2022-03-14 07:15:42 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 07:15:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:16:11 | INFO | train_inner | epoch 003:     91 / 157 loss=8.773, ppl=437.54, wps=33807.2, ups=1.36, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=2.094, loss_scale=4, train_wall=30, gb_free=13.8, wall=223
2022-03-14 07:16:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:16:35 | INFO | fairseq.tasks.translation | example hypothesis: we're're the the in the in the of the in the of the of the of the.
2022-03-14 07:16:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:16:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the the the of the of the of the of the of the of the.
2022-03-14 07:16:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:16:45 | INFO | fairseq.tasks.translation | example hypothesis: now now, this is a of the a of the a of the of the.
2022-03-14 07:16:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:16:50 | INFO | fairseq.tasks.translation | example hypothesis: and there's a a of the of the of the of a of the of the of the of the.
2022-03-14 07:16:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:16:55 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not not not not not not not not that's a that's the that's a of the that's a of the.
2022-03-14 07:16:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:17:01 | INFO | fairseq.tasks.translation | example hypothesis: and this this is a a a of the of the of the world of the of the world of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the world, and the
2022-03-14 07:17:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:17:07 | INFO | fairseq.tasks.translation | example hypothesis: now, if if if if if if if if if you're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're the the the
2022-03-14 07:17:07 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:17:13 | INFO | fairseq.tasks.translation | example hypothesis: so so, if if if if if if if if if if if if if if if if if if if if if if if if if if if we we we're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're're the the the the the the the the the the the the the the the the the the
2022-03-14 07:17:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:17:21 | INFO | fairseq.tasks.translation | example hypothesis: and this is a a a a, "the a," the a, "" the a, "", "the a,", "" "" "the a a a a,", ",", ",", ",", "" ",", ",", ",", "" ",", "" "" "" "" "" "" the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a, ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", ",", "
2022-03-14 07:17:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:17:23 | INFO | fairseq.tasks.translation | example hypothesis: now, we a a a a a a a a a a a, and the a a a a, and the a a a a a, and the a a a a a a a a a a, and the a, and the a a a a a a a a a a a a, and the a, and the a a a a, and the a a a a a a a a a a a a a a a a a, and the a a, and the of the a, and the a a a a a a, and the a a a a a, and the a a a a a a a a a a a a a a a, and a a a a a a, and a, and a a a a a a, and a a a a, and a, and a a a a, and the, and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the a,
2022-03-14 07:17:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:17:24 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.281 | ppl 310.96 | bleu 0.43 | wps 3405.7 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.43
2022-03-14 07:17:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-14 07:17:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:17:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.43) (writing took 2.1627520038746297 seconds)
2022-03-14 07:17:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 07:17:26 | INFO | train | epoch 003 | loss 8.616 | ppl 392.46 | wps 38034.1 | ups 1.51 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 2.14 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 298
2022-03-14 07:17:26 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 07:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:17:37 | INFO | train_inner | epoch 004:     34 / 157 loss=8.338, ppl=323.55, wps=29454.1, ups=1.16, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=2.159, loss_scale=4, train_wall=31, gb_free=13.9, wall=309
2022-03-14 07:18:08 | INFO | train_inner | epoch 004:    134 / 157 loss=7.94, ppl=245.49, wps=80558.3, ups=3.19, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=2.403, loss_scale=4, train_wall=31, gb_free=14.6, wall=340
2022-03-14 07:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:18:19 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-14 07:18:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:18:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most of the most.
2022-03-14 07:18:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:18:27 | INFO | fairseq.tasks.translation | example hypothesis: these are a new new new new new new new new new new new new new new new new new.
2022-03-14 07:18:27 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:18:30 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of this is a lot, and it's a lot of the world.
2022-03-14 07:18:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:18:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not not that we're going to do that we're going to do it.
2022-03-14 07:18:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:18:38 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of the most of people, and it's a lot of the world, and it's a lot of people in the people.
2022-03-14 07:18:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:18:43 | INFO | fairseq.tasks.translation | example hypothesis: now, you're going to be a lot of the way, but they're going to be a lot of the way, but they're going to be be be be be be be be be be be be be be a lot, but it.
2022-03-14 07:18:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:18:47 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to make the world.
2022-03-14 07:18:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:18:52 | INFO | fairseq.tasks.translation | example hypothesis: this is a "" "the" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-14 07:18:52 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:18:54 | INFO | fairseq.tasks.translation | example hypothesis: so, we're a lot of the way that we have to be a lot of the way that we have that we're going to be a lot of the world, which is a lot of the way that we have that we have to be a lot of the world, and it's a lot of the world, and we have to be be be be be be be a lot of the world, which is a lot of the way that we have that we have to have to be be be a lot of the way that we have to be be be be be be be be be a lot of the world, which is that we have to have to be be be be be be be be be be be be be be be be be be be a lot of the way.
2022-03-14 07:18:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:18:54 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.568 | ppl 189.78 | bleu 2.03 | wps 4633.2 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 2.03
2022-03-14 07:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-14 07:18:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:18:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 4 @ 623 updates, score 2.03) (writing took 2.1528416408691555 seconds)
2022-03-14 07:18:56 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 07:18:56 | INFO | train | epoch 004 | loss 7.964 | ppl 249.65 | wps 43502.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 2.293 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 388
2022-03-14 07:18:57 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 07:18:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:19:21 | INFO | train_inner | epoch 005:     77 / 157 loss=7.59, ppl=192.64, wps=33752.5, ups=1.38, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=2.552, loss_scale=4, train_wall=30, gb_free=15.5, wall=413
2022-03-14 07:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:19:50 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the way.
2022-03-14 07:19:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:19:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most most of the most of the most of the most.
2022-03-14 07:19:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:19:58 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-14 07:19:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:20:01 | INFO | fairseq.tasks.translation | example hypothesis: and for example, there's a lot of example, and it's going to be a lot of the world.
2022-03-14 07:20:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:20:05 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do that we're going to do it.
2022-03-14 07:20:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:20:10 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in fact, as as as as the people, for the people, for the way, and the people is in the most most most most most people.
2022-03-14 07:20:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:20:14 | INFO | fairseq.tasks.translation | example hypothesis: now, if you're going to see, but it's going to be a lot of the time, but it's not not not not, but they're going to be able to be able to be able to be able to be able.
2022-03-14 07:20:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:20:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to make the world of the world, and we can see that's going to be a lot of the world, and we're going to be a lot of the world, and we're going to be going to be a lot of the world.
2022-03-14 07:20:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:20:27 | INFO | fairseq.tasks.translation | example hypothesis: so, this is a lot of the world, and then it's going to say, and then it's going to say, "it's a lot of the world," and then it's really really really really really really really, "" and then it's going to the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first, and then, "" "" and then it's going to say, and then it's going to say, and then it's really really really really really really really really really really really really really really really really really really really really really really really really really really really really really really really really really, "it's going to say, and then it's going to do, and then it's going to do," "" "" "" "
2022-03-14 07:20:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:20:30 | INFO | fairseq.tasks.translation | example hypothesis: now, this is a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and so it's not not not not, and so that we think that we think that we can't think of the world of the world, and then it's a lot of the world, and then it's a lot of the world, and then it's a lot of the other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other other of the world, it's a lot of the world, and so so so so so so so it's a lot of the world,
2022-03-14 07:20:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:20:30 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.999 | ppl 127.89 | bleu 3.08 | wps 4127.6 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 3.08
2022-03-14 07:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-14 07:20:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:20:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:20:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 5 @ 780 updates, score 3.08) (writing took 2.286328246118501 seconds)
2022-03-14 07:20:32 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 07:20:32 | INFO | train | epoch 005 | loss 7.344 | ppl 162.51 | wps 41337.1 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 2.274 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 484
2022-03-14 07:20:32 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 07:20:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:20:39 | INFO | train_inner | epoch 006:     20 / 157 loss=7.18, ppl=145.01, wps=32741.6, ups=1.29, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=2.151, loss_scale=4, train_wall=30, gb_free=13, wall=491
2022-03-14 07:21:10 | INFO | train_inner | epoch 006:    120 / 157 loss=6.877, ppl=117.52, wps=80621.1, ups=3.19, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=2.1, loss_scale=4, train_wall=31, gb_free=14.5, wall=522
2022-03-14 07:21:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:21:25 | INFO | fairseq.tasks.translation | example hypothesis: we have this picture in the future.
2022-03-14 07:21:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:21:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most of the most most most of the most most most most most.
2022-03-14 07:21:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:21:34 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new new new new york.
2022-03-14 07:21:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:21:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's no, where where where you're going to see, where it's going to be in the world.
2022-03-14 07:21:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:21:43 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to make a few few few few few few of the world, and what's going to do.
2022-03-14 07:21:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:21:49 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as as a lot of people who are going to be in the most people, for a lot of people, and it's going to be a lot of people in the united states.
2022-03-14 07:21:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:21:55 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of the same, but if you don't know, but if you don't know, it's going to get the same same, but if you don't have the same, it's going to make the same, but it's going to get the same same, but if you don't know,
2022-03-14 07:21:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:22:01 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to take the idea of this idea of this, we can see that we're going to make a lot of the world, which is a lot of the world, and we can see that's going to get a lot of the world, and the world, and the world, and we're going to be going to get a lot of a lot of a lot of a lot of a lot of a lot of a lot of the world
2022-03-14 07:22:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:22:09 | INFO | fairseq.tasks.translation | example hypothesis: well: one of the one of the world, and it's going to say, "you know," you know, "you know," you know, and then, "you know," this is that's going to be a lot of a lot of this is, "you know," you know, "and then you know, you know," and then it's going to go to go to be going to be going to go to be an an an an an an an "and then you know," you know, "and then you know," and then, "and then you know," and then you know, "that's going to go to be an an an an an an an an inininininininininininininininininininininan an an an an an" is, "and then,"
2022-03-14 07:22:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:22:11 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of the world, which is a lot of the world, and if we're going to be a lot of a lot of the world, and we have a lot of a lot of a lot of a lot of the world, which is that we have a lot of the world, which is a lot of a lot of the world, which is that we have a lot of a lot of the world, which is a lot of the world, and then we have a lot of which is a little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little bit of the future, which is that we've been been been been been been been been been been been been been a lot of the world, which is that we have to be in a lot of the world, and then, in a lot of the way to be a
2022-03-14 07:22:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:22:11 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.49 | ppl 89.88 | bleu 3.9 | wps 3594.2 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 3.9
2022-03-14 07:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-14 07:22:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:22:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 6 @ 937 updates, score 3.9) (writing took 2.291839900892228 seconds)
2022-03-14 07:22:13 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 07:22:13 | INFO | train | epoch 006 | loss 6.846 | ppl 115.06 | wps 38988.9 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 2.166 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 585
2022-03-14 07:22:14 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 07:22:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:22:33 | INFO | train_inner | epoch 007:     63 / 157 loss=6.487, ppl=89.71, wps=30164.8, ups=1.2, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.885, loss_scale=4, train_wall=30, gb_free=15.3, wall=605
2022-03-14 07:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:23:06 | INFO | fairseq.tasks.translation | example hypothesis: we've got this.
2022-03-14 07:23:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:23:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the point of the most most most.
2022-03-14 07:23:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:23:13 | INFO | fairseq.tasks.translation | example hypothesis: these are new york.
2022-03-14 07:23:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:23:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there is the chinese chinese, where where you're going to get up.
2022-03-14 07:23:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:23:21 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just a few few few few of his head, and what's going to understand what's going on.
2022-03-14 07:23:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:23:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamay, the most people who are in the number of the people, and the number of the number of the people, and that is a number of the time.
2022-03-14 07:23:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:23:32 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of these are in the internet, but if you don't have to see, if you don't see, if you don't have the energy, it's the energy, and if you don't have to be able to see, and it, you have to be able to see it, it, you can't have to get
2022-03-14 07:23:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:23:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information of these information, we can see that we can see with a lot of information that we can be able to create a lot of the information, and we can be able to be able to be able to be able to be able to the information, and the information of the information of the information that we can be able to be able to be able to the information of the information of the information of the information that we can
2022-03-14 07:23:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:23:45 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the reasons, and it's going to make me, and it's going to be here for me, "you know, if you know, you know, you know, you're going to be, you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to go to go to go to go to be, you know, you know, you know, you know, you know, you know, you know, you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to go
2022-03-14 07:23:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:23:47 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's still still, and the same thing that we're going to create a lot of the world, and we're going to create a lot of the world, which is that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-14 07:23:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:23:47 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.107 | ppl 68.91 | bleu 6.19 | wps 3987.8 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 6.19
2022-03-14 07:23:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-14 07:23:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:23:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:23:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 7 @ 1094 updates, score 6.19) (writing took 2.3560055010020733 seconds)
2022-03-14 07:23:50 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 07:23:50 | INFO | train | epoch 007 | loss 6.325 | ppl 80.19 | wps 40889.9 | ups 1.63 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 2.015 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 682
2022-03-14 07:23:50 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 07:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:23:52 | INFO | train_inner | epoch 008:      6 / 157 loss=6.231, ppl=75.1, wps=31723.3, ups=1.27, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=2.14, loss_scale=4, train_wall=30, gb_free=14.8, wall=684
2022-03-14 07:24:23 | INFO | train_inner | epoch 008:    106 / 157 loss=5.847, ppl=57.57, wps=81095, ups=3.21, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=2.12, loss_scale=4, train_wall=31, gb_free=15.1, wall=715
2022-03-14 07:24:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:24:43 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppppm.
2022-03-14 07:24:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:24:47 | INFO | fairseq.tasks.translation | example hypothesis: that's the car.
2022-03-14 07:24:47 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:24:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new york.
2022-03-14 07:24:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese, where you're going to be in the ppppm.
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:24:58 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we're not just just just a few of his head, and what's all of his head.
2022-03-14 07:24:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:25:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamamamay of people, the number of the most people, and this is a number of the number of the number of the reviviviiiiiiiiiiiy.
2022-03-14 07:25:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:25:06 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of the bbbbman, but it doesn't have to be able, if you don't have the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy.
2022-03-14 07:25:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:25:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information of these information, we can see that we can create a piece of the world, and we can make it.
2022-03-14 07:25:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:25:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, the reasons it's interesting for me, and it's really interesting for me, "oh, you know," you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, "oh, the best, the best time, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, is,
2022-03-14 07:25:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:25:19 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, if you're still still still still, the fact of the world, we've got a little bit of the world, which is that we had to create a whole system that we had to create a whole whole system that we had to use of the best system.
2022-03-14 07:25:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:25:19 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.665 | ppl 50.74 | bleu 7.99 | wps 4586.1 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 7.99
2022-03-14 07:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-14 07:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:25:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 8 @ 1251 updates, score 7.99) (writing took 2.2839912259951234 seconds)
2022-03-14 07:25:21 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 07:25:21 | INFO | train | epoch 008 | loss 5.877 | ppl 58.75 | wps 43266.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 2.079 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 773
2022-03-14 07:25:21 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 07:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:25:37 | INFO | train_inner | epoch 009:     49 / 157 loss=5.693, ppl=51.75, wps=34800.2, ups=1.36, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=2.071, loss_scale=4, train_wall=31, gb_free=15.3, wall=789
2022-03-14 07:26:08 | INFO | train_inner | epoch 009:    149 / 157 loss=5.488, ppl=44.87, wps=79913.8, ups=3.22, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=2.146, loss_scale=4, train_wall=31, gb_free=14.8, wall=820
2022-03-14 07:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:26:15 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppppist in the morning.
2022-03-14 07:26:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:26:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the new dododoha, which most most most of most most here.
2022-03-14 07:26:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:26:24 | INFO | fairseq.tasks.translation | example hypothesis: stars are new york.
2022-03-14 07:26:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:26:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese, where they're going to go up with ppppppppppest, and they're going to go up.
2022-03-14 07:26:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:26:32 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we just just get a few of his head on his head, and what's going on his head.
2022-03-14 07:26:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:26:37 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamated people like the responsibility, the number of animals, and it's a number of animals, and this is a number of the most most important thing.
2022-03-14 07:26:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:26:41 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are some of the mamamammmmes, but if it doesn't go back to the energy, if you don't have the energy energy energy, you need the energy energy energy, and the energy.
2022-03-14 07:26:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:26:46 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the information of these reflection, we can go up with a single single single single piece of the world, and we can go through the shape of the information, which is all the structure of the structure of the structure, and the structure, which is all the structure.
2022-03-14 07:26:46 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:26:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for tedtedwomen, "oh," oh, "oh," oh, "oh, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know," the best time. "
2022-03-14 07:26:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:26:53 | INFO | fairseq.tasks.translation | example hypothesis: so, unfortunately, there's still still the mother, and a big thing that we had a lot of work on the world, and we had to get a little bit of the bottom of the best system that we had had to get a little bit of the bottom.
2022-03-14 07:26:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:26:53 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.161 | ppl 35.78 | bleu 11.94 | wps 4304.8 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 11.94
2022-03-14 07:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-14 07:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:26:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:26:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 9 @ 1408 updates, score 11.94) (writing took 2.1209702270571142 seconds)
2022-03-14 07:26:55 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 07:26:55 | INFO | train | epoch 009 | loss 5.472 | ppl 44.39 | wps 42047.2 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 2.136 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 867
2022-03-14 07:26:56 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 07:26:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:27:25 | INFO | train_inner | epoch 010:     92 / 157 loss=5.108, ppl=34.49, wps=32799.8, ups=1.31, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.836, loss_scale=4, train_wall=31, gb_free=14.7, wall=897
2022-03-14 07:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:27:48 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppppin the clinic.
2022-03-14 07:27:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:27:53 | INFO | fairseq.tasks.translation | example hypothesis: that's the right line of doha, most of you know, most of you know.
2022-03-14 07:27:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:27:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are new new aaeeeeeds of the new new new york.
2022-03-14 07:27:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:28:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese food, where the legs are happy, and with pppest.
2022-03-14 07:28:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:28:05 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we don't just get a couple of electrodes on his head on his head, and what's going on.
2022-03-14 07:28:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:28:09 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamab, as the responsibility of the responsibility, the number of the number of animals, and that is a number of the most important, and it's a dededevaiiiiibia.
2022-03-14 07:28:09 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:28:13 | INFO | fairseq.tasks.translation | example hypothesis: first of some of these are some of the canic, but in the top of the bottom, not, but if they don't have the energy, they're going to move out of the energy, and they don't need the alalalalalalalalalalalalalalalalalalalala.
2022-03-14 07:28:13 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:28:18 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use information, the information comes from this reflection, we can go with a traditional design, we can start with a natural natural natural information, and the face of the information, which is all the information of the information, and there's a whole structure, and there's a whole structure, which is all the whole structure, and there's a whole structure, which is a whole structure, which is a whole structure, which is a whole structure
2022-03-14 07:28:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:28:26 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons, and it's interesting, and it's interesting for me, for tedwomen, for tedwomen, "oh," yes, "yes," yes, "well," well, "well," well, "well," well, "well," if you know, "well," well, "if you know," if you're a "you're a" if you're a "the best," the best, "if you're a" you're a "well," well, "you're a" you're a "you're going to get a" the "" the best best best, "the best," the best, "you're a" you know, "you're going to go," you're a "the best," you're going to get a "you're a" '"'"
2022-03-14 07:28:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:28:28 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still, and the invention of the invention, and a big part of the design that we have to solve our work on our airplane, which was a little bit of the world that we had to solve, to solve it, or to solve it, which is, to solve it's a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of the world, which is to solve, or to solve, or to solve, or to solve it, to solve it, or to solve it, to solve, to solve it's a little bit of a little bit of a little bit of a little bit more more more more, or to solve it, to solve it, or to solve it's, to solve, or to be a little bit that, or to be a little bit of a little bit of the top top top top of the top of the top top top top top top top top top top top top top top top, or to be, or to solve,
2022-03-14 07:28:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:28:28 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.856 | ppl 28.96 | bleu 13.25 | wps 4123.7 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 13.25
2022-03-14 07:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-14 07:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:28:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 10 @ 1565 updates, score 13.25) (writing took 2.1899175548460335 seconds)
2022-03-14 07:28:30 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 07:28:30 | INFO | train | epoch 010 | loss 5.024 | ppl 32.55 | wps 41414.4 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.944 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 962
2022-03-14 07:28:31 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 07:28:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:28:42 | INFO | train_inner | epoch 011:     35 / 157 loss=4.94, ppl=30.7, wps=32256.3, ups=1.3, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=2.037, loss_scale=4, train_wall=30, gb_free=13.8, wall=974
2022-03-14 07:29:13 | INFO | train_inner | epoch 011:    135 / 157 loss=4.589, ppl=24.07, wps=81261.8, ups=3.18, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.836, loss_scale=4, train_wall=31, gb_free=13.7, wall=1005
2022-03-14 07:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:29:24 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppace in the clinic.
2022-03-14 07:29:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:29:28 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that most of you know here.
2022-03-14 07:29:28 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:29:32 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new locks to create two new ores that are going to be going to be used.
2022-03-14 07:29:32 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:29:36 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where they're going to be salt, and they're going to be able to get it.
2022-03-14 07:29:36 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:29:40 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just understand a few electrodes on his head and understand what his thoughts are on.
2022-03-14 07:29:40 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:29:44 | INFO | fairseq.tasks.translation | example hypothesis: and in the mab of people who went to the responsibility for the number of animals, and this is a number for conservaiibia.
2022-03-14 07:29:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:29:48 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic magnetic magnetic lines in the back, but if you don't need to move it, if you don't need your energy and the energy.
2022-03-14 07:29:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:29:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can go from this reflection, we can begin to be able to be able to go through the face of the information, and there's a whole structure of information that are all the structure of the structure, and all the structure that we all the structure of the information that we all the information.
2022-03-14 07:29:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:29:57 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and for me to be here for tedwomen, is that... "yes, you know, it's the best thing that we said to you know," men, and you know, you know, the time, we're working on this time, we're working with a time, and we're working on that time, "for a cash of the time," and then, we're working on this time, for a pound, "for a pocket," and we're working on that, you know, and we're working working on that time time time time time time, for a time time time time time, we're working on this is a pocket, you know, for example, for example, "and that time, for example," for example, and then, you know, you know, for example, "
2022-03-14 07:29:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:30:00 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother of the invention, and a lot of work that we had to be able to solve the airplane that we had to solve a result of the problems that we had to solve it -- it was to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a national national national national national national bibibibibibibibibibibible, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a
2022-03-14 07:30:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:30:00 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.591 | ppl 24.11 | bleu 15.64 | wps 4597.7 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 15.64
2022-03-14 07:30:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-14 07:30:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:30:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 11 @ 1722 updates, score 15.64) (writing took 2.2795930239371955 seconds)
2022-03-14 07:30:02 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 07:30:02 | INFO | train | epoch 011 | loss 4.676 | ppl 25.57 | wps 43142.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.869 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 1054
2022-03-14 07:30:03 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 07:30:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:30:27 | INFO | train_inner | epoch 012:     78 / 157 loss=4.508, ppl=22.75, wps=33899.3, ups=1.36, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.816, loss_scale=4, train_wall=30, gb_free=14.4, wall=1079
2022-03-14 07:30:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:30:55 | INFO | fairseq.tasks.translation | example hypothesis: we made these pace in the clinics.
2022-03-14 07:30:55 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:30:59 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know.
2022-03-14 07:30:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:31:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks. they're going to create two new york.
2022-03-14 07:31:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:31:07 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food food food, where salsalz and grace are going to be serpat.
2022-03-14 07:31:07 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:31:11 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head on his head, and understand what all of his thoughts are on the thoughts.
2022-03-14 07:31:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:31:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals, as humans grew up to the number of life, the number of animals, again, and this is a foundation for conservation.
2022-03-14 07:31:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:31:20 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic magnetic lines in the field, but it's not the superconductor, if you don't need the energy, you need your energy, and you need your energy.
2022-03-14 07:31:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:31:24 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information from this reflection of reflection, we can start with a traditional face, with a big face of the face of the information, and there's a natural shape of the information that are all the structure and the entire structure.
2022-03-14 07:31:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:31:28 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the things that are interesting, and it's interesting for me to be here for tedwomen -- yeah, it's the best thing that she said, when she said, "yeah, when someone's the best men said, we're working with them.
2022-03-14 07:31:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:31:29 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, if you were able to use the invention of the invention of design, and a lot of work on our airplane, we had to solve a little result that we had to solve the unique problems that we had to solve everything on the ground.
2022-03-14 07:31:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:31:29 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.284 | ppl 19.48 | bleu 15.63 | wps 4884.1 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 15.64
2022-03-14 07:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-14 07:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:31:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:31:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 12 @ 1879 updates, score 15.63) (writing took 1.0745946881361306 seconds)
2022-03-14 07:31:30 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 07:31:30 | INFO | train | epoch 012 | loss 4.36 | ppl 20.54 | wps 44943.1 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.719 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 1142
2022-03-14 07:31:30 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 07:31:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:31:37 | INFO | train_inner | epoch 013:     21 / 157 loss=4.203, ppl=18.42, wps=35931, ups=1.43, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.7, loss_scale=4, train_wall=30, gb_free=14.3, wall=1149
2022-03-14 07:32:08 | INFO | train_inner | epoch 013:    121 / 157 loss=4.107, ppl=17.23, wps=80467.7, ups=3.18, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.569, loss_scale=4, train_wall=31, gb_free=14, wall=1180
2022-03-14 07:32:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:32:23 | INFO | fairseq.tasks.translation | example hypothesis: we asked this pet in the clinic clinic.
2022-03-14 07:32:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:32:27 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line from doha, which most of you know.
2022-03-14 07:32:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:32:31 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf dines that create two new new ores.
2022-03-14 07:32:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:32:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where they are frog with sales.
2022-03-14 07:32:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:32:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just understand some electrodes on his head, and understand what all of his thoughts are on the mind.
2022-03-14 07:32:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:32:43 | INFO | fairseq.tasks.translation | example hypothesis: and in the case, people like responsibility for the family, grew up to the number of wildlife, and this is a number of conservatives for conservation protection.
2022-03-14 07:32:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:32:47 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic magnetic field in the inner lines, but the superconductor doesn't like the superconductor, and if they need their energy and the alty of the aluminum.
2022-03-14 07:32:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:32:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection of reflection, we can start with a traditional face of the face of the face of the information and the information of the information and the whole structure of the entire structure and the whole structure of the structure, which is all the structure of the structure.
2022-03-14 07:32:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:32:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to be able to make me here for tedwomen in tedwomen, "yes," yes, "as the best class of the best men," when the best men said, "and the men," if you start to support you know, "if you start to support you know," if you know, "if you're working with a cold."
2022-03-14 07:32:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:32:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, is still the mother of the invention, and a big part of work on our airplane that we had to solve a very unique result that the problems that we had to solve the unique part of the problems that we had to solve everything on the ground -- it's a neural system that if you can use it.
2022-03-14 07:32:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:32:58 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.031 | ppl 16.35 | bleu 18.2 | wps 4705.2 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 18.2
2022-03-14 07:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-14 07:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:32:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:33:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 13 @ 2036 updates, score 18.2) (writing took 2.09086698689498 seconds)
2022-03-14 07:33:00 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 07:33:00 | INFO | train | epoch 013 | loss 4.08 | ppl 16.91 | wps 43605.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.63 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 1232
2022-03-14 07:33:01 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 07:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:33:21 | INFO | train_inner | epoch 014:     64 / 157 loss=3.922, ppl=15.16, wps=34340.5, ups=1.38, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.565, loss_scale=4, train_wall=31, gb_free=14.4, wall=1253
2022-03-14 07:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:33:54 | INFO | fairseq.tasks.translation | example hypothesis: we asked this pelly in the clinic.
2022-03-14 07:33:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:33:58 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line from doha, probably most of you know.
2022-03-14 07:33:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:34:02 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf locks that create the two new pigs are going to get rid of these two new stars.
2022-03-14 07:34:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:34:06 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food, where frog salt legs and salt with sales.
2022-03-14 07:34:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:34:10 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a couple of electrodes on his head and understand exactly what all of his thoughts are.
2022-03-14 07:34:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:34:15 | INFO | fairseq.tasks.translation | example hypothesis: and in the mab of the people like responsibility for survival, grew up to the number of wildlife, and that's a basis for conservation.
2022-03-14 07:34:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:34:18 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodust of magnetic lines in the inner lines, but the superconductor may not move to the energy, and so the alignment.
2022-03-14 07:34:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:34:22 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection comes from this reflection, we can start with a traditional facial, the shape of the information, and through the whole structure of the whole structure.
2022-03-14 07:34:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:34:27 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that it's interesting, and measuring out, for me to be here, "yes, that's the best men, and somebody said," you know, "the men who are going to tell you about the table," and the men, "if you're going to support the table."
2022-03-14 07:34:27 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:34:29 | INFO | fairseq.tasks.translation | example hypothesis: luluckily, is still the mother of the invention, and a big part of the design work on our airplane, which was a unique result that had to solve the problems that were connected to the ground.
2022-03-14 07:34:29 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:34:29 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.849 | ppl 14.41 | bleu 20.54 | wps 4627.5 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 20.54
2022-03-14 07:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-14 07:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:34:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 14 @ 2193 updates, score 20.54) (writing took 2.213104875991121 seconds)
2022-03-14 07:34:31 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 07:34:31 | INFO | train | epoch 014 | loss 3.775 | ppl 13.69 | wps 43377.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.413 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1323
2022-03-14 07:34:32 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 07:34:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:34:34 | INFO | train_inner | epoch 015:      7 / 157 loss=3.687, ppl=12.88, wps=34844.5, ups=1.36, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.342, loss_scale=4, train_wall=30, gb_free=14.3, wall=1326
2022-03-14 07:35:06 | INFO | train_inner | epoch 015:    107 / 157 loss=3.547, ppl=11.69, wps=80063.1, ups=3.18, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.478, loss_scale=4, train_wall=31, gb_free=14.3, wall=1358
2022-03-14 07:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:35:25 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-14 07:35:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:35:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-14 07:35:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:35:33 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks of golf dines.
2022-03-14 07:35:33 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:35:37 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food, where frog legs are and feeds are served.
2022-03-14 07:35:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:35:41 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring some electrodes on his head and understand what all of his thoughts are on the way.
2022-03-14 07:35:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:35:45 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people like the responsibility for wildlife, the number of wildlife, and this is a foundation for conservation conservation conservation protection in namibia.
2022-03-14 07:35:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:35:49 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic field lines in the inner field, but the superconductor doesn't like you, if you move your energy movements, you need to move your energy movements, and so the super-conducting disorders.
2022-03-14 07:35:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:35:54 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of this reflection, we can begin to start with a traditional facial, and we can begin with the shape of the observer and the shape of the information that gives you the whole structure of the structure.
2022-03-14 07:35:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:35:58 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to be interesting and measure, to be here for me to be here at tedwomen, and then, in fact, "yeah, somebody who said," you know, when the best men who starts to support you, "to support the question is that the time we've got to support for women."
2022-03-14 07:35:58 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:36:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention of the invention of the invention, and a big part of the design that we've got to solve was a result that we had to solve the unique problems that we had to solve, to solve all the problems of the problems -- it's all connected to a refrightening system that allows us to be able to use the propellyielm system, if you can use a mechanism to use a mechanism to use the propelled to use a mechanism or a mechanism to use the propelli think that you can use the mechanism to use to use of a mechanism to use to use, to use, to use, to use the mechanism or a mechanism or a mechanism, to use the mechanism, to use the mechanism, to use the mechanism, to use the propelly---to-to-to-to-to-to-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-the-ball system,
2022-03-14 07:36:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:36:01 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.588 | ppl 12.02 | bleu 22.25 | wps 4643.6 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 22.25
2022-03-14 07:36:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-14 07:36:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:36:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:36:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 15 @ 2350 updates, score 22.25) (writing took 2.352815425954759 seconds)
2022-03-14 07:36:03 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 07:36:03 | INFO | train | epoch 015 | loss 3.582 | ppl 11.97 | wps 43130.7 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.455 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1415
2022-03-14 07:36:03 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 07:36:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:36:20 | INFO | train_inner | epoch 016:     50 / 157 loss=3.558, ppl=11.78, wps=34422.2, ups=1.35, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.401, loss_scale=4, train_wall=31, gb_free=14.7, wall=1432
2022-03-14 07:36:50 | INFO | train_inner | epoch 016:    150 / 157 loss=3.322, ppl=10, wps=80149.1, ups=3.25, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.276, loss_scale=4, train_wall=30, gb_free=14.9, wall=1462
2022-03-14 07:36:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:36:57 | INFO | fairseq.tasks.translation | example hypothesis: we made these tweep in the clinic.
2022-03-14 07:36:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:37:00 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha who probably knows most of you here.
2022-03-14 07:37:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:37:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf locks that produce two new pigs.
2022-03-14 07:37:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:37:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food, where frog legs are being served with salce.
2022-03-14 07:37:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:37:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are.
2022-03-14 07:37:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:37:16 | INFO | fairseq.tasks.translation | example hypothesis: and that's what people have been growing responsibility for wildlife. and this is a basis of wildlife in namibia.
2022-03-14 07:37:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:37:20 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are magnetic field lines in interior lines, but the superconductor doesn't like it, if you're moving your energy movements, and so that's how you're going to use your energy.
2022-03-14 07:37:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:37:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, we can begin to begin with a traditional facial configuration of the face of the face, and the shape of the information and the shape of that information, and we're able to fold it all the information information and all the structure.
2022-03-14 07:37:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:37:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and measuring it for me to be here at tedwomen, is that, "yes," was the best day, "when somebody said," when somebody said, "and then," if you're going to get a table, "and you know," if you're going to have a long time, "well," well, "let you know," let me have a silly, "well," you know, "you know," let me have a silly, "well," well, "well, let me have a silly, let me have a silly, if you have a silly," you know, "you know," -- you know, "if you've got it's have a silly," if you've got it's have a silly, "well," "
2022-03-14 07:37:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:37:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the mother of invention, and a big part of design work that we've got on our airplane, was a result that we had to solve the idea that we had to solve the unique problems that we had to resolve the ground so that it was connected to a refrightening system, and allows us to use a system, and allows us to use a neutragic system to use it to be able to be able to be able to be able to use it to use the air, if you to use, if you can use, if you're actually use it, if you want to use it to use it to use it, if you can use it, if you're a neural, or be able to solve the air, if you're a neural, if you can use, if you're a little bit more expensive, if you're actually use it, or be able to use, if you're actually use, if you're actually use it, or be able to use it,
2022-03-14 07:37:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:37:32 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.504 | ppl 11.35 | bleu 21.46 | wps 4660.6 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 22.25
2022-03-14 07:37:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-14 07:37:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:37:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 16 @ 2507 updates, score 21.46) (writing took 1.1270765790250152 seconds)
2022-03-14 07:37:33 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 07:37:33 | INFO | train | epoch 016 | loss 3.358 | ppl 10.25 | wps 43860.2 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.335 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1505
2022-03-14 07:37:33 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 07:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:38:03 | INFO | train_inner | epoch 017:     93 / 157 loss=3.187, ppl=9.11, wps=34813.2, ups=1.38, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.285, loss_scale=4, train_wall=31, gb_free=15.3, wall=1535
2022-03-14 07:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:38:27 | INFO | fairseq.tasks.translation | example hypothesis: and we made this sheep in the clinic clinic.
2022-03-14 07:38:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:38:31 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, most of you know.
2022-03-14 07:38:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:38:35 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that create the two new pigs.
2022-03-14 07:38:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:38:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food food, where frog legs are going to be served with sales and ppets.
2022-03-14 07:38:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:38:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all his thoughts on the track on the track.
2022-03-14 07:38:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:38:48 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis of the people like the responsibility for the wildlife of wildlife, and this is a basis for the conservation of conservation protection in namibia.
2022-03-14 07:38:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:38:53 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic field lines in the inner field, but the superconductor doesn't like it, if you move your energy, and so the superconduction.
2022-03-14 07:38:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:38:57 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can begin with a traditional factoric, we can start with a traditional faculty of the face of the face of the face, and the basic information that all the information and the structure comes through the information that all the information and all the structure of the information that comes from that comes from this reflection, we can start with with a traditional reflection of these reflection of these
2022-03-14 07:38:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:39:03 | INFO | fairseq.tasks.translation | example hypothesis: th th: one of the reasons that this is interesting and measure, for me, to be here at tedsters, is that, in fact, when he said, "oh, when somebody said," you know, "and you know, if you're going to say," you know, "you know, it's a silent revolution," and you know, we're going to have a silent thing to do with the piano, "you know," you know, "you know," is that the piano, "
2022-03-14 07:39:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:39:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention of the invention, and a big part of the design work we're at the plane that we had to solve is a result of it that we had to solve the unique problems that were connected to the ground -- it's all connected to the ground system, and it allows us to use a green system, and that allows us to use a little bit of the air system, if you can use it to see it, or a mechanism, if you can use it in the air system, or a mechanism, or a little bit of the surface system, or a mechanism, we use it to see that we use it to use it to see it, or a mechanism, it, it, you can use it's's a mechanism, if you can use it to see the surface system, it, and then you can use it to see them to see the most powerful, you can use it's all the surface system system system system, or when you can use it in the most powerful,
2022-03-14 07:39:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:39:05 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.388 | ppl 10.47 | bleu 23.41 | wps 4320.2 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 23.41
2022-03-14 07:39:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-14 07:39:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:39:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 17 @ 2664 updates, score 23.41) (writing took 2.170310261892155 seconds)
2022-03-14 07:39:07 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 07:39:07 | INFO | train | epoch 017 | loss 3.202 | ppl 9.2 | wps 41887.1 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.299 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1599
2022-03-14 07:39:08 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 07:39:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:39:20 | INFO | train_inner | epoch 018:     36 / 157 loss=3.164, ppl=8.96, wps=32915.8, ups=1.3, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.292, loss_scale=4, train_wall=30, gb_free=14.7, wall=1612
2022-03-14 07:39:51 | INFO | train_inner | epoch 018:    136 / 157 loss=3.011, ppl=8.06, wps=79849.2, ups=3.22, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.153, loss_scale=4, train_wall=31, gb_free=14.5, wall=1643
2022-03-14 07:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:40:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-14 07:40:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:40:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which most of you know.
2022-03-14 07:40:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:40:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that create the two pigs.
2022-03-14 07:40:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:40:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are being served.
2022-03-14 07:40:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:40:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what his thoughts are on the track.
2022-03-14 07:40:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:40:22 | INFO | fairseq.tasks.translation | example hypothesis: and in that case, people like responsibility for wildlife, grew up with the number of wildwildlife. and this is a basis for conservation conservation protection in namibia.
2022-03-14 07:40:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:40:26 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines in the inside, but the superconductor doesn't like the superconductor, if you're moving, you don't need it, and so the superconductor.
2022-03-14 07:40:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:40:31 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, the grocery can start with the big constraints of the face, and the basic shape of it, and then gives it through the information that the whole structure and all the structure, and all the structure, and all the structure, and all the structure, and all the structure, and all the structure will fold up.
2022-03-14 07:40:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:40:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and measured, for me here at tedwomen, is that -- yes, when it was the best thing, when somebody said to him, "and he said," oh, you know, if you go to your table, and you know, your table revolution, and then you know, if you're going to support for a long time, you know, you know, you know, there's a long time, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, there's a long time, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, there's a long time,
2022-03-14 07:40:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:40:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a great part of the design work that we're at our plane, was a result that we had to solve the unique problems that we had to solve the unique problems that they had to do with it at the ground -- everything from a operuable system, everything from a continuous system, everything from a continuous system, and that allows us to be able to see that there's an aircraft, and that allows us to do, to see, to be a little bit of the motor system, and that allows us to do, to see if you to deal with a gps system, to see, to see, if there's an object, or a gps system, or a little bit of time, if there's an object, or a mechanism, to be a gps system, or a gps, and to deal with the way to see that allows us to deal with a gps, if you, to see, and to see, and to be able to deal with the way to do
2022-03-14 07:40:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:40:38 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.194 | ppl 9.15 | bleu 25.44 | wps 4546.8 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 25.44
2022-03-14 07:40:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-14 07:40:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:40:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 18 @ 2821 updates, score 25.44) (writing took 2.185355898924172 seconds)
2022-03-14 07:40:40 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 07:40:40 | INFO | train | epoch 018 | loss 3.014 | ppl 8.08 | wps 42573.8 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.129 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1692
2022-03-14 07:40:40 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 07:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:41:06 | INFO | train_inner | epoch 019:     79 / 157 loss=2.888, ppl=7.4, wps=34216, ups=1.33, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=1.033, loss_scale=4, train_wall=31, gb_free=14.3, wall=1718
2022-03-14 07:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:41:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters in the clinic.
2022-03-14 07:41:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:41:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of the most here.
2022-03-14 07:41:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:41:42 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs overwhelmed.
2022-03-14 07:41:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:41:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are and pit serves.
2022-03-14 07:41:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:41:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:41:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:41:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people's responsibility for wildlife, the number of wildlife has become again. and this is a foundation for conservation conservation in namibia.
2022-03-14 07:41:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:41:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, these are magnetic field lines inside the inside, but the superconductors don't like the superconductors, if they move move their movements, and so the superconduction.
2022-03-14 07:41:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:42:02 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can begin with a traditional facial, which is the grocery of the face of the information, the whole structure of the structure, and all the structure.
2022-03-14 07:42:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:42:06 | INFO | fairseq.tasks.translation | example hypothesis: th one of the reasons it's highly interesting and measure, for me to be here at tedwomen, is that -- well, when a caves became the top of the men who begins to support you, and said, "if the revolution, '' 90s starts to support you. '' 'em,' em & gt; / em & lt; / em & gt; / em & lt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & lt; / em & gt; / em & gt; / em & gt;
2022-03-14 07:42:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:42:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're using the troops, we had to be able to solve the troops that were connected to the ground -- everything from a continuous system, a refrigeral system, and a very cooling system that allows us to a refrigerator, and allows us to the fly that allows us to the fly, and allows us to the flies to the propellum that allows us to the propellum that we need to the propellum that we need to the motor motor motor motor motor motor motor motor motor motor motor motor motor system, and that allows us to the car, and the propellum that allows us to be a floors, or the stairs, and the propellum that allows us to the stairs to the propellum that allows us to the propellum that allows us to the propellum that allows us to the propellum that allows us to the stairs to the stairs to a
2022-03-14 07:42:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:42:09 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.239 | ppl 9.44 | bleu 24.62 | wps 4738.5 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 25.44
2022-03-14 07:42:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-14 07:42:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:42:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:42:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 19 @ 2978 updates, score 24.62) (writing took 1.0538983109872788 seconds)
2022-03-14 07:42:10 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 07:42:10 | INFO | train | epoch 019 | loss 2.834 | ppl 7.13 | wps 44075.3 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.047 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1782
2022-03-14 07:42:10 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 07:42:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:42:17 | INFO | train_inner | epoch 020:     22 / 157 loss=2.776, ppl=6.85, wps=34658.4, ups=1.4, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=1.053, loss_scale=4, train_wall=30, gb_free=15.1, wall=1789
2022-03-14 07:42:49 | INFO | train_inner | epoch 020:    122 / 157 loss=2.7, ppl=6.5, wps=81335.9, ups=3.14, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.939, loss_scale=4, train_wall=31, gb_free=14.1, wall=1821
2022-03-14 07:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:43:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters in the clinic.
2022-03-14 07:43:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:43:07 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here.
2022-03-14 07:43:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:43:11 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new goldilocks to the two new sponsores.
2022-03-14 07:43:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:43:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are being served with salz and pitcase.
2022-03-14 07:43:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:43:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to take some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:43:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:43:24 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis for conservation, like people's responsibility for wildlife, and this is a basis for wildlife conservation.
2022-03-14 07:43:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:43:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of the magnetic field of magnetic field are caught inside inside the inside, but the superconductor doesn't like it if you're moving around, and so the superconducting disorder.
2022-03-14 07:43:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:43:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can begin with the big convictions of the face of the face, and the basic shape of the information that comes through the entire pork structure, and all the folding structure, and all the folds up.
2022-03-14 07:43:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:43:37 | INFO | fairseq.tasks.translation | example hypothesis: th one: one of the reasons that it's been interesting, and measured, for me, to be here at tedwomen, is that -- well, in stripping dinner, when someone was best summarized by the men in a table, and say, "if the revolution begins to support you."
2022-03-14 07:43:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:43:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention of the invention of the invention, and a big part of the design work that we had to solve in our aircraft, a result of it, that we had to solve the unique problems that were connected to the ground -- everything from a continuing system, everything from a continual system, and a cooling system that allows us to be able to see that in the aircraft.
2022-03-14 07:43:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:43:39 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.172 | ppl 9.01 | bleu 25.21 | wps 4674.1 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 25.44
2022-03-14 07:43:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-14 07:43:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:43:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:43:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 20 @ 3135 updates, score 25.21) (writing took 1.1557571771554649 seconds)
2022-03-14 07:43:40 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 07:43:40 | INFO | train | epoch 020 | loss 2.71 | ppl 6.54 | wps 43871.7 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 1.064 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 1872
2022-03-14 07:43:40 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 07:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:44:01 | INFO | train_inner | epoch 021:     65 / 157 loss=2.629, ppl=6.19, wps=34757.8, ups=1.4, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=1.163, loss_scale=4, train_wall=30, gb_free=14.3, wall=1893
2022-03-14 07:44:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:44:33 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pietsters in the clinic.
2022-03-14 07:44:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:44:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which is probably the most familiar here.
2022-03-14 07:44:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:44:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new goldilocks, create the new sponsors.
2022-03-14 07:44:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:44:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and ppepper.
2022-03-14 07:44:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:44:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what's his thoughts on the track.
2022-03-14 07:44:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:44:53 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis for conservation protection of people's responsibility for wildlife, the number of wildlife revenue again. and this is a basis for conservation conservation protection in namibia.
2022-03-14 07:44:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:44:58 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like, if you move around, you know, your movements, and that's how the superconductors use.
2022-03-14 07:44:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:45:03 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructures of the face of the face, and then repair it through that information, which is the whole structure, and all the folds that fits its its its its its its its its its its its own structure, and all the folds.
2022-03-14 07:45:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:45:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and measured to be here for me here at tedwomen, here, is that, yes, when it was best summarized when someone said, "turn you on on your table," and tell you, "if the revolution starts to support you," you know, that the truth is for me, "you know, you know, you have a long cake."
2022-03-14 07:45:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:45:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a big part of the design work that we're on on our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables to operate on a continuous variable system, and a refrigerator system that allows us to use, to use the aircraft, until you use aircraft.
2022-03-14 07:45:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:45:10 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.024 | ppl 8.14 | bleu 27.22 | wps 4518.7 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 27.22
2022-03-14 07:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-14 07:45:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:45:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:45:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 21 @ 3292 updates, score 27.22) (writing took 2.1082143569365144 seconds)
2022-03-14 07:45:12 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 07:45:12 | INFO | train | epoch 021 | loss 2.595 | ppl 6.04 | wps 42889.8 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 1.008 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 1964
2022-03-14 07:45:12 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 07:45:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:45:15 | INFO | train_inner | epoch 022:      8 / 157 loss=2.608, ppl=6.09, wps=33390.3, ups=1.35, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.962, loss_scale=4, train_wall=30, gb_free=14.3, wall=1967
2022-03-14 07:45:46 | INFO | train_inner | epoch 022:    108 / 157 loss=2.475, ppl=5.56, wps=79089.9, ups=3.21, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=1.022, loss_scale=4, train_wall=31, gb_free=14.2, wall=1998
2022-03-14 07:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:46:05 | INFO | fairseq.tasks.translation | example hypothesis: we made these piesters in the clinic.
2022-03-14 07:46:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:46:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha most of you know.
2022-03-14 07:46:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:46:13 | INFO | fairseq.tasks.translation | example hypothesis: stars become new goldilocks revelations of the two new pigs.
2022-03-14 07:46:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:46:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food where salt legs are being served.
2022-03-14 07:46:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:46:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are.
2022-03-14 07:46:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:46:25 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, grew up again, and this is a foundation for conservation in namibia.
2022-03-14 07:46:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:46:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are trapped inside, but the superconductors don't like it when they move their movements, and so the superconducting alignment.
2022-03-14 07:46:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:46:33 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can begin with a traditional facial can begin with the main constraints of the face of the face, and the basic shape of the information that information comes through through which information is the one of the one that comes through information that's all the information that comes in.
2022-03-14 07:46:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:46:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been very interesting and measured for me to be here at tedwomen, is that, right?
2022-03-14 07:46:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:46:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we use in our plane was a result that we had to solve the unique problems that they had to be connected with with it, which were connected to the ground ground, and then they had to operate on the ground on the ground.
2022-03-14 07:46:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:46:39 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 2.996 | ppl 7.98 | bleu 26.89 | wps 4804 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 27.22
2022-03-14 07:46:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-14 07:46:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:46:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:46:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 22 @ 3449 updates, score 26.89) (writing took 0.9580396139062941 seconds)
2022-03-14 07:46:40 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 07:46:40 | INFO | train | epoch 022 | loss 2.474 | ppl 5.55 | wps 44663.7 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.949 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 2052
2022-03-14 07:46:41 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 07:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:46:57 | INFO | train_inner | epoch 023:     51 / 157 loss=2.405, ppl=5.29, wps=35659.5, ups=1.4, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.807, loss_scale=4, train_wall=31, gb_free=14.2, wall=2069
2022-03-14 07:47:28 | INFO | train_inner | epoch 023:    151 / 157 loss=2.362, ppl=5.14, wps=81989.4, ups=3.23, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.97, loss_scale=4, train_wall=31, gb_free=14.2, wall=2100
2022-03-14 07:47:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:47:34 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-14 07:47:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:47:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-14 07:47:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:47:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to run new goldilocks into the two new pigs.
2022-03-14 07:47:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:47:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salz and ppets.
2022-03-14 07:47:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:47:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:47:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:47:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the make-like people's responsibility for wildlife, the number of wildwildlife. and this is a foundation for conservation protection in namibia.
2022-03-14 07:47:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:47:58 | INFO | fairseq.tasks.translation | example hypothesis: first, strands of magnetic field are captured inside, but the superconductors don't like the superconductors, if they move around, because their movements use their movements, and so the superconductors use.
2022-03-14 07:47:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:48:02 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can begin with the size of the face of the face, the basic shape of the face, and then the basic shape that we use, which is the entire portion structure, and all the fuse.
2022-03-14 07:48:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:48:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting to be here for me to be here at tedwomen, is that -- yes, when the strikes dinner was best, when somebody said, "" turn your men on your table table, and say, "if the revolution starts to support you." we're supporting you. "
2022-03-14 07:48:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:48:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a great part of design work that we're in our plane, was a result that we had to solve the unique problems that were linked to the ground -- all of a continuous mechanized system, and that allows us to do it to operate -- that allows us to use aircraft until the most of a car car car, and that allows us to use the most of our neighbors, or when you use a car car car car car car car car car car car car car, when you use, and that allows us to do, if you use a system that allows us to use a system that allows us to use in the first time, and that allows us to use, or when you can use a crash, or when you can use it's a crash.
2022-03-14 07:48:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:48:09 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 2.987 | ppl 7.93 | bleu 26.96 | wps 4659.5 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.22
2022-03-14 07:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-14 07:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:48:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:48:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 23 @ 3606 updates, score 26.96) (writing took 1.0012567029334605 seconds)
2022-03-14 07:48:10 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 07:48:10 | INFO | train | epoch 023 | loss 2.35 | ppl 5.1 | wps 43877.6 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.906 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 2142
2022-03-14 07:48:11 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 07:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:48:40 | INFO | train_inner | epoch 024:     94 / 157 loss=2.264, ppl=4.8, wps=34767.2, ups=1.39, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.946, loss_scale=4, train_wall=31, gb_free=14.2, wall=2172
2022-03-14 07:49:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:49:04 | INFO | fairseq.tasks.translation | example hypothesis: we made these bleep in the clinic.
2022-03-14 07:49:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:49:08 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here.
2022-03-14 07:49:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:49:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks prayers of the two new pigs.
2022-03-14 07:49:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:49:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-14 07:49:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:49:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts on the track.
2022-03-14 07:49:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:49:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature, as people took responsibility for wildlife, the number of wildlife has become again. and this is a foundation for conservation in namibia.
2022-03-14 07:49:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:49:28 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are captured inside, but the superconductor doesn't like moving, if you move around, you use your energy, and you use the superconductor.
2022-03-14 07:49:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:49:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection, we can start with a traditional facial, which is the groundly contexts of the face and the basic shape of information that comes through which all the whole porter structure and all the fits into this particular particular reflection, and we can begin with a feeder.
2022-03-14 07:49:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:49:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and appropriate to be here for me to be here at tedwomen, is that... tar dinner dinner was put it together when someone said, "turn you on the men in your desk, and say," wow, "turn it to the men in your desk and say," well, '"hey, we're supporting you guys guys guys guys who have started a longhook at tedwomen who are in this world of mine mine mine," oh oh oh oh, we've got to live in the future. "'"
2022-03-14 07:49:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:49:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we have at our pristest, was a result that we had to solve the unique problems so that it was connected to operates on the ground -- everything from a continuous variable system, and a frifrightening system and a frightening system that allows us to see that it would be able to use some aircraft, or to take care of the mechanism that if you could either use a mechanism to see the mechanism with the mechanism, or to see the mechanism, or to see that if you can can use a mechanism in the mechanism in the mechanism in the static space where you can either, or to see it would be able to the mechanism, or to see that it would be able to be able to see in the stairrigins in the mechanism, or to see in the staver in the mechanism, or to see in the staver, or to see that
2022-03-14 07:49:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:49:40 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.926 | ppl 7.6 | bleu 28.04 | wps 4553.3 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 28.04
2022-03-14 07:49:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-14 07:49:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:49:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 24 @ 3763 updates, score 28.04) (writing took 2.196333836996928 seconds)
2022-03-14 07:49:42 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 07:49:42 | INFO | train | epoch 024 | loss 2.252 | ppl 4.76 | wps 43084.8 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.889 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2234
2022-03-14 07:49:42 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 07:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:49:54 | INFO | train_inner | epoch 025:     37 / 157 loss=2.156, ppl=4.46, wps=34488.2, ups=1.35, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.78, loss_scale=4, train_wall=31, gb_free=14.4, wall=2246
2022-03-14 07:50:25 | INFO | train_inner | epoch 025:    137 / 157 loss=2.211, ppl=4.63, wps=80140.5, ups=3.2, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.942, loss_scale=4, train_wall=31, gb_free=14.3, wall=2277
2022-03-14 07:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:50:35 | INFO | fairseq.tasks.translation | example hypothesis: we made these peep in the clinic.
2022-03-14 07:50:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:50:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha probably most of you know.
2022-03-14 07:50:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:50:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will be making new dilocks prayers of the two new pigs.
2022-03-14 07:50:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:50:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-14 07:50:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:50:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are.
2022-03-14 07:50:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:50:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the magical sense, people are taking responsibility for wildlife, grew up with number of wildwildwildlife. and that has become a basis for conservation in namibia.
2022-03-14 07:50:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:50:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductors don't like they move, when they move their energy, and so the superconducting disorders.
2022-03-14 07:50:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:51:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use that information that comes from these reflection, we can start with a traditional facial, the big constraints of the face, and the basic shape of the information that comes in.
2022-03-14 07:51:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:51:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been interesting and appropriate to be here at tedwomen, here is that... yes, in the courtyerra dinner, as a woman said, "turn you on the men in your table and say to them," if the truth is that we have been supporting to you, "we've got to support the truth is that we've already been supporting a long time of caricuries."
2022-03-14 07:51:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:51:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention still is the invention of the invention, and a great part of design work that we have on our plane, was a single result that we had to solve the unique problems associated with doing it on the ground -- all of one continuously variables and a refrigerated system with a refrigeration system that allows us to use the aircraft, if you can use a steam, or a mechanic force.
2022-03-14 07:51:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:51:08 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.944 | ppl 7.7 | bleu 27.28 | wps 5042 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.04
2022-03-14 07:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-14 07:51:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:51:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:51:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 25 @ 3920 updates, score 27.28) (writing took 1.113697879947722 seconds)
2022-03-14 07:51:09 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 07:51:09 | INFO | train | epoch 025 | loss 2.162 | ppl 4.48 | wps 45390.4 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.888 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 2321
2022-03-14 07:51:09 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 07:51:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:51:35 | INFO | train_inner | epoch 026:     80 / 157 loss=2.051, ppl=4.14, wps=36741.3, ups=1.44, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.838, loss_scale=4, train_wall=30, gb_free=14.3, wall=2347
2022-03-14 07:51:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:52:02 | INFO | fairseq.tasks.translation | example hypothesis: we set up these papers in the clinic.
2022-03-14 07:52:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:52:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of the people here.
2022-03-14 07:52:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:52:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will make new goldilocks prayers of the two new pigs.
2022-03-14 07:52:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:52:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where froswallows are served with salt and pepper.
2022-03-14 07:52:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:52:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what his minds are.
2022-03-14 07:52:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:52:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people have stepped responsibility for wildlife revenue, the number of wildlife wildlife. and this has become a foundation for conservation in namibia.
2022-03-14 07:52:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:52:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like the superconductor, when they move their movements, and so the superconducting disorder.
2022-03-14 07:52:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:52:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we take the information that comes from this reflection, we can begin with a traditional facial can, the gross consideration of the face, the basic shape of the face, and then refuse it through that one of the unfolding information, which embedded all the structure and all the shape.
2022-03-14 07:52:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:52:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's utterly interesting and appropriate for me to be here at tedwomen, is that -- yes, when controversial dinner, it was best summarized as someone said, "turn on men in your desk, and say," if the revolution begins, we'll support you. '' '"the truth, we've got to support you here with you," we've already got a women here in my heart, "if we've already got swalkie," if you're in, "if you're in the future."
2022-03-14 07:52:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:52:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and the big part of the design work that we have on on the plane was a result of that we have to solve the unique problems that were connected to operations on the ground -- all of a continuous distribution and refrigerated system with a refrigerent refriction, a refrigeration system that allows us to use to get rid of the aircraft, if you're using to fly in the air, if you can't see the substance of a mechanism.
2022-03-14 07:52:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:52:38 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.904 | ppl 7.49 | bleu 28.65 | wps 4539.2 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.65
2022-03-14 07:52:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-14 07:52:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:52:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.65) (writing took 2.1158639369532466 seconds)
2022-03-14 07:52:40 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 07:52:40 | INFO | train | epoch 026 | loss 2.053 | ppl 4.15 | wps 43156 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.85 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2412
2022-03-14 07:52:41 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 07:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:52:49 | INFO | train_inner | epoch 027:     23 / 157 loss=2.016, ppl=4.05, wps=33597.2, ups=1.35, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.84, loss_scale=4, train_wall=30, gb_free=15.2, wall=2421
2022-03-14 07:53:20 | INFO | train_inner | epoch 027:    123 / 157 loss=1.953, ppl=3.87, wps=80707.1, ups=3.22, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.805, loss_scale=4, train_wall=31, gb_free=14, wall=2452
2022-03-14 07:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:53:34 | INFO | fairseq.tasks.translation | example hypothesis: we set up these little bleep in the clinic.
2022-03-14 07:53:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:53:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-14 07:53:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:53:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to cross new goldilocks betting the two new pigs.
2022-03-14 07:53:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:53:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-14 07:53:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:53:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are.
2022-03-14 07:53:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:53:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the wild, like the people for wildlife revenues grew up the number of wildlife. and this is a foundation for conservation in namibia.
2022-03-14 07:53:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:53:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside the inner, but the superconductors don't like it when they move their energy movements, and so the superconducting disorder.
2022-03-14 07:53:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:54:03 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can begin with a traditional facial can, the larger constraints of the face and the basic shape replicating information, which is the whole portion of the information and all the folding information.
2022-03-14 07:54:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:54:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's kind of interesting and measured for me here at tedwomen, is that... well, in the strict dinner, it was best summarized as someone said, "turn your men on your desk and saying to you, 'when the revolution begins, we're supporting you.'"
2022-03-14 07:54:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:54:08 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention still is the most important part of the design work that we're on on our plane, was a result that we had to solve the unique problems with the ground, it was possible to operate on the ground -- anything from a continuous variable system, and a cooler system with a refrigerator that allows us to use aircraft.
2022-03-14 07:54:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:54:08 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.885 | ppl 7.39 | bleu 28.42 | wps 4893 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.65
2022-03-14 07:54:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-14 07:54:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:54:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:54:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 27 @ 4234 updates, score 28.42) (writing took 1.0806080400943756 seconds)
2022-03-14 07:54:09 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 07:54:09 | INFO | train | epoch 027 | loss 1.937 | ppl 3.83 | wps 44539.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.797 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2501
2022-03-14 07:54:09 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 07:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:54:30 | INFO | train_inner | epoch 028:     66 / 157 loss=1.839, ppl=3.58, wps=35414.3, ups=1.42, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.778, loss_scale=4, train_wall=30, gb_free=15.1, wall=2522
2022-03-14 07:54:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:55:02 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-14 07:55:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:55:06 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha probably most of you know.
2022-03-14 07:55:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:55:10 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to run new goldilocks into the two new pigs.
2022-03-14 07:55:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:55:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 07:55:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:55:18 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring an electrodes on his head and understand exactly what all his thoughts are.
2022-03-14 07:55:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:55:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the same way that people actually adopted the wildlife population, grew up again, and this has become a basis for wildlife conservation in namibia.
2022-03-14 07:55:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:55:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductors don't like it if they move, because their movements use their energy, and so the superconducting disorder.
2022-03-14 07:55:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:55:30 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can begin with a traditional facial can, which is the larger constraints of the face, and the basic shape of the information that gives you the whole porx and all the folds.
2022-03-14 07:55:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:55:35 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and detailed, to be here at tedwomen, is that, yes, when torn dinner, it was best summarized as someone said, "shut you guys at your table and say, 'when the revolution begins, we support you.'" the truth is that we have supported you with you. "
2022-03-14 07:55:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:55:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the idea is still the invention of invention, and a large part of the design work that we have on our plane, was a result that we had to solve the unique problems associated with operations on the ground -- all of a continuous distribution and a refrigeration that allows us to use aircraft, that allows us to use aircraft, that allows us to get rid of the aircraft, or when you use a regardless of the machine that allows us to use.
2022-03-14 07:55:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:55:37 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.881 | ppl 7.37 | bleu 28.91 | wps 4743.5 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 28.91
2022-03-14 07:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-14 07:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:55:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 07:55:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 28 @ 4391 updates, score 28.91) (writing took 2.1318996699992567 seconds)
2022-03-14 07:55:39 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 07:55:39 | INFO | train | epoch 028 | loss 1.843 | ppl 3.59 | wps 43963 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.808 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 2591
2022-03-14 07:55:39 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 07:55:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:55:42 | INFO | train_inner | epoch 029:      9 / 157 loss=1.895, ppl=3.72, wps=35008.4, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.871, loss_scale=4, train_wall=30, gb_free=14, wall=2594
2022-03-14 07:56:13 | INFO | train_inner | epoch 029:    109 / 157 loss=1.71, ppl=3.27, wps=80204.7, ups=3.19, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.772, loss_scale=4, train_wall=31, gb_free=14, wall=2625
2022-03-14 07:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:56:32 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-14 07:56:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:56:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-14 07:56:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:56:40 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks prayers of two new pigs.
2022-03-14 07:56:40 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:56:44 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-14 07:56:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:56:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just take an electrodes on his head and understand exactly what they're all thoughts on the distance.
2022-03-14 07:56:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:56:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the same way that people took responsibility for wildlife revenues, grew up to wild animals, and this has become a foundation for conservation in namibia.
2022-03-14 07:56:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:56:56 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductors don't like it when they move their movements, and so the superconductors are disrupting.
2022-03-14 07:56:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:57:00 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can begin with a traditional facial can, the larger constraints of facial constraints, the basic shape of the facial constraints that endected the whole structure and all of the fine instructions.
2022-03-14 07:57:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:57:04 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's kind of interesting and appropriate to be here for me here at tedwomen, is that... well, in the strict dinner, it was best summarized when someone said, "turn on men in a table and say to them, 'cause the revolution, we support them.'"
2022-03-14 07:57:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:57:06 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great piece of design work that we're on on on our plane, was a result that we had to solve the unique problems associated with operations on the ground -- all of a continuous variability, and cooling system, if you use aircraft, we will use airplanes to a car that allows you to stop, or if you use aircraft.
2022-03-14 07:57:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:57:06 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.909 | ppl 7.51 | bleu 28.89 | wps 4989.6 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 28.91
2022-03-14 07:57:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-14 07:57:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:57:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 29 @ 4548 updates, score 28.89) (writing took 0.9063688719179481 seconds)
2022-03-14 07:57:07 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 07:57:07 | INFO | train | epoch 029 | loss 1.731 | ppl 3.32 | wps 44990.5 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.795 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2679
2022-03-14 07:57:07 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 07:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:57:24 | INFO | train_inner | epoch 030:     52 / 157 loss=1.675, ppl=3.19, wps=35582.7, ups=1.42, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.772, loss_scale=4, train_wall=31, gb_free=14.3, wall=2696
2022-03-14 07:57:55 | INFO | train_inner | epoch 030:    152 / 157 loss=1.639, ppl=3.11, wps=81562.8, ups=3.22, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.746, loss_scale=4, train_wall=31, gb_free=15.1, wall=2727
2022-03-14 07:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:58:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up in the clinic.
2022-03-14 07:58:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:58:05 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, which probably most of you know.
2022-03-14 07:58:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:58:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new goldilocks prayers of two new pigs.
2022-03-14 07:58:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:58:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served and peppered.
2022-03-14 07:58:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:58:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on the head and just understand what all his thoughts are.
2022-03-14 07:58:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:58:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the dimensions, like people's responsibility for wildlife revenues, the number of wildlife revenues. and that's a foundation for conservation in namibia.
2022-03-14 07:58:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:58:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductors don't like it when they move, because their movements use their energy, and so the superconducting disorder.
2022-03-14 07:58:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:58:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can begin with a traditional facial can, which is the big constraints of the face and the basic shape, and then you can add it through the information that makes the whole porture and all the fine information.
2022-03-14 07:58:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:58:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and measured, for me here at tedwomen, is that... well, the strictly dinner was put it on the best thing to do, as someone said, "turn on the men in your table and say, 'if the revolution begins, we support you.' '' ''" the truth is for you guys guys guys guys who have been supporting currency. "
2022-03-14 07:58:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:58:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the idea is still the mother of invention, and a big piece of design work that we're most proud of our airplane, was a result that we had to solve the unique issues associated with being able to operate on the ground, all of one continuous variables, and a cooler system that allows us to use to gather the aircraft, and allows us to use the air force, and use it to highlight.
2022-03-14 07:58:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:58:35 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.951 | ppl 7.73 | bleu 28.08 | wps 4843.8 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 28.91
2022-03-14 07:58:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-14 07:58:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:58:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 07:58:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 30 @ 4705 updates, score 28.08) (writing took 1.096594933187589 seconds)
2022-03-14 07:58:36 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 07:58:36 | INFO | train | epoch 030 | loss 1.616 | ppl 3.07 | wps 44274.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.749 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2768
2022-03-14 07:58:36 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 07:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:59:06 | INFO | train_inner | epoch 031:     95 / 157 loss=1.545, ppl=2.92, wps=35705.2, ups=1.4, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.808, loss_scale=4, train_wall=31, gb_free=14, wall=2798
2022-03-14 07:59:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:59:29 | INFO | fairseq.tasks.translation | example hypothesis: we set up these little bleep in the clinic.
2022-03-14 07:59:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:59:33 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha i think most people know here.
2022-03-14 07:59:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:59:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks conditions that are going to be headed into two new pigs.
2022-03-14 07:59:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:59:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frossed legs with salt and peppered.
2022-03-14 07:59:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:59:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-14 07:59:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:59:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the size of the people who took responsibility for wildlife, grew up, and this is a foundation for wildlife conservation in namibia.
2022-03-14 07:59:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:59:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductors don't like it if you move, because your movements use, and so the superconducting disorder.
2022-03-14 07:59:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:59:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use that information that comes from this mirror reflection, we can begin with a traditional facial can, which is the big constraints of the face and the basic basic shape, and then it comes through that kind of information that accomplished the whole structure and all of the structure.
2022-03-14 07:59:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:00:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate to be here for me to be here at tedwomen is that -- well, in the strict dinner, it was best summarized as someone said, "turn your men on your table and say to them," if the revolution begins, then we'll support you. "the truth is that we've started to get you on this big spring,"
2022-03-14 08:00:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:00:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big piece of design work that we're on on our plane, was a result that we had to solve the unique problems that were connected to operations on the ground -- all of them, from one continuously variation of pigs and cooled a refrigeration system that allows us to use a machine that allows us to get rid of an aircraft, up up to a plug on the highway to the highlight, or a motor motor vehicle, to the autodesks, to the autoplegic force, to the auto forces, to the auto-belli machine, to be able, to the autostick, to the highway, to be able, to the car, to the air, to the autoplegic, to be able, to the air, to be able, to be able to do that you know, to do when you know, to do that you can, to do that you can, to do that you know, to do that you
2022-03-14 08:00:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:00:05 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.961 | ppl 7.79 | bleu 29.01 | wps 4592.7 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 29.01
2022-03-14 08:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-14 08:00:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 08:00:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt
2022-03-14 08:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_best.pt (epoch 31 @ 4862 updates, score 29.01) (writing took 2.2364400059450418 seconds)
2022-03-14 08:00:07 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 08:00:07 | INFO | train | epoch 031 | loss 1.552 | ppl 2.93 | wps 43298.7 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.795 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2859
2022-03-14 08:00:07 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 08:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:00:20 | INFO | train_inner | epoch 032:     38 / 157 loss=1.471, ppl=2.77, wps=34041.1, ups=1.37, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.734, loss_scale=4, train_wall=30, gb_free=14.7, wall=2872
2022-03-14 08:00:51 | INFO | train_inner | epoch 032:    138 / 157 loss=1.479, ppl=2.79, wps=80435, ups=3.18, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.816, loss_scale=4, train_wall=31, gb_free=14.8, wall=2903
2022-03-14 08:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:01:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-14 08:01:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:01:04 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha probably most of you know.
2022-03-14 08:01:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:01:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will make new goldilocks conditions that will exceed the two new pigs.
2022-03-14 08:01:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:01:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served and peppered.
2022-03-14 08:01:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:01:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting an electrodes on his head and exactly understanding what everybody's thoughts on the track.
2022-03-14 08:01:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:01:20 | INFO | fairseq.tasks.translation | example hypothesis: and the purpose of people who took responsibility to wildlife support, grew the number of wildlife wildlife. and this is a foundation for conservation in namibia.
2022-03-14 08:01:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:01:24 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductors don't like it when they move around, because their energy motions use, and so the pracounce.
2022-03-14 08:01:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:01:28 | INFO | fairseq.tasks.translation | example hypothesis: so when we use that information that comes from this mirror reflection, we can start with a traditional facial can, which is the big constraints of the face and the basic shape, and then refits it through died-making information that contains the whole structure and fits its its its its its into the structure.
2022-03-14 08:01:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:01:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and appropriate, for me here at tedwomen, is that -- yeah, the strive dinner was best summed when someone said, "turn your men on a table and say, 'when the revolution begins, we support you.'" the truth is that we've been supported for you, "women who have been supporting you on this table for granny cardiose."
2022-03-14 08:01:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:01:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother still has the invention, and a large piece of design work that we have on our plane, was a outcome of that we had to solve the unique problems associated with operations on the ground -- all of a continuous distribution and a refrigeration system that allowed us to use airplanes, or a caribbeast between the carrion the ground.
2022-03-14 08:01:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:01:34 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.071 | ppl 8.41 | bleu 27.03 | wps 4918.3 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 29.01
2022-03-14 08:01:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-14 08:01:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 08:01:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 08:01:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 32 @ 5019 updates, score 27.03) (writing took 1.1046128990128636 seconds)
2022-03-14 08:01:35 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 08:01:35 | INFO | train | epoch 032 | loss 1.444 | ppl 2.72 | wps 44936.4 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.78 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 2947
2022-03-14 08:01:35 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 08:01:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:02:01 | INFO | train_inner | epoch 033:     81 / 157 loss=1.337, ppl=2.53, wps=35916.6, ups=1.43, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.767, loss_scale=4, train_wall=30, gb_free=14.4, wall=2973
2022-03-14 08:02:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:02:28 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-14 08:02:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:02:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people know here.
2022-03-14 08:02:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:02:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new goldilocks conditions the two new pigs.
2022-03-14 08:02:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:02:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served and peppered.
2022-03-14 08:02:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:02:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't bring some electrodes on his head and understand exactly what everybody's thoughts on the track.
2022-03-14 08:02:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:02:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the same way that people surveyed responsibility for wildlife expectancy, the number of wildlife that has become reproductive, and that has become a foundation for conservation in namibia.
2022-03-14 08:02:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:02:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of strands of magnetic field are trapped inside, but the superconductors don't like it when they move around, because their movements use, and so the proudy disorder.
2022-03-14 08:02:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:02:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use that information that comes from this mirror reflection, we can begin with with a traditional facial can that the larger constraints of face and the basic form of information, and we can add it through that one of those who deals with the whole porter of the structure and all the structure.
2022-03-14 08:02:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:03:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons why it's immensely interesting and measured, for me here at tedwomen, is that -- well, in fact, the strictly dinner, it's best written as someone said, "turn your husbands on your table and say," if the revolution begins, we support you. '"the truth is that we have got you on this long, cardiose carbonate cardiovascular thing."
2022-03-14 08:03:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:03:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the need for the invention of the invention, and a big part of the design work that we're doing on on the plane, was a result that we had to solve the unique problems that were linked to the ground, all of which, from a continuous variables, and a refrigerator system that would allow us to use on the air, and that would be propelled to a revenuulent, or a machine that would be able to tackle any propelled, or a specializing, without having to use.
2022-03-14 08:03:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:03:05 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.051 | ppl 8.29 | bleu 28.62 | wps 4517.6 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 29.01
2022-03-14 08:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-14 08:03:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 08:03:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 08:03:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 33 @ 5176 updates, score 28.62) (writing took 1.1157087078318 seconds)
2022-03-14 08:03:06 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 08:03:06 | INFO | train | epoch 033 | loss 1.365 | ppl 2.58 | wps 43464.6 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.782 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 3038
2022-03-14 08:03:06 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 08:03:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:03:14 | INFO | train_inner | epoch 034:     24 / 157 loss=1.378, ppl=2.6, wps=34282, ups=1.36, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.804, loss_scale=4, train_wall=31, gb_free=14.2, wall=3046
2022-03-14 08:03:46 | INFO | train_inner | epoch 034:    124 / 157 loss=1.277, ppl=2.42, wps=80483.2, ups=3.2, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.796, loss_scale=4, train_wall=31, gb_free=14.1, wall=3077
2022-03-14 08:03:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:04:00 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-14 08:04:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:04:04 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, which probably most of you know about this.
2022-03-14 08:04:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:04:08 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new dilocks into these two new pigs.
2022-03-14 08:04:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:04:12 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served and peppered.
2022-03-14 08:04:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:04:16 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just put some electrodes on his head and exactly understanding what all of his thoughts are.
2022-03-14 08:04:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:04:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the same way that people surveyed responsibility for wildlife, the rates of wildlife grew up again, and that's a foundation for conservation in namibia.
2022-03-14 08:04:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:04:24 | INFO | fairseq.tasks.translation | example hypothesis: first of all, a bunch of strands are trapped inside, but the superconductor doesn't like to move when their motions use their power, and so the superconductor.
2022-03-14 08:04:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:04:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information reflection from these mirror reflection, we can begin with a traditional facial can, which gives the chief constrains of the face and the basic form, and then we refuse it through the tuna that gives you the entire portubes that intract the entire portion of the structure and the fits.
2022-03-14 08:04:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been very interesting and measured, for me here at tedwomen, is that -- well, in fact, the strict dinner was best put it together when someone said, "turn on the men in your desk and say to you, 'if the revolution started supporting you,' the truth is, 'women, we have a long time behind you, that we have a cardiose se, we have a long time of cardioxide, and then we're scratch.' 9ra's' 84. 's, and then we're scratch, and then we're scratch and then we have it's right over.' s. 's.' 84: no, and then we get you. '84 have it's the best.' 84, and then we'll have it was best. '9ra
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:04:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great portion of design work that we're at our plane right now was a result that we had to solve the unique problems that were connected to operational to operate on the ground -- all of the time, from one continuous mechanics that allows us to land, and a cooling system that allows us to use on the air, which is a bribe, we can use on the air, and we can't use on the air, and then we can't have a bribe in the air, and we can't use that allows us to force for the bribe able to use that allows us to get rid of a factor in the most vulnerable to the wild.
2022-03-14 08:04:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:04:36 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.138 | ppl 8.81 | bleu 28.34 | wps 4560.7 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 29.01
2022-03-14 08:04:36 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 08:04:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-14 08:04:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 08:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt
2022-03-14 08:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.05/checkpoint_last.pt (epoch 34 @ 5333 updates, score 28.34) (writing took 1.069244836922735 seconds)
2022-03-14 08:04:37 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 08:04:37 | INFO | train | epoch 034 | loss 1.289 | ppl 2.44 | wps 43292.2 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.807 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3129
2022-03-14 08:04:37 | INFO | fairseq_cli.train | done training in 3128.3 seconds
