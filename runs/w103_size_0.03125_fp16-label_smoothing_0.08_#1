Sender: LSF System <lsfadmin@eu-g3-067>
Subject: Job 207263916: <w103_size_0.03125_fp16_label_smoothing_0.08_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.08_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:18:28 2022
Job was executed on host(s) <eu-g3-067>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:18:46 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:18:46 2022
Terminated at Sat Mar  5 14:18:55 2022
Results reported at Sat Mar  5 14:18:55 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.08 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   3.59 sec.
    Max Memory :                                 378 MB
    Average Memory :                             180.67 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               19622.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   10 sec.
    Turnaround time :                            27 sec.

The output (if any) follows:

2022-03-05 14:18:54 | ERROR | fairseq.dataclass.utils | Error when composing. Overrides: ['common.no_progress_bar=False', 'common.log_interval=100', 'common.log_format=null', 'common.log_file=null', 'common.tensorboard_logdir=null', 'common.wandb_project=null', 'common.azureml_logging=False', 'common.seed=66575611', 'common.cpu=False', 'common.tpu=False', 'common.bf16=False', 'common.memory_efficient_bf16=False', 'common.fp16=True', 'common.memory_efficient_fp16=False', 'common.fp16_no_flatten_grads=False', 'common.fp16_init_scale=128', 'common.fp16_scale_window=null', 'common.fp16_scale_tolerance=0.0', 'common.on_cpu_convert_precision=False', 'common.min_loss_scale=0.0001', 'common.threshold_loss_scale=null', 'common.amp=False', 'common.amp_batch_retries=2', 'common.amp_init_scale=128', 'common.amp_scale_window=null', 'common.user_dir=null', 'common.empty_cache_freq=0', 'common.all_gather_list_size=16384', 'common.model_parallel_size=1', 'common.quantization_config_path=null', 'common.profile=False', 'common.reset_logging=False', 'common.suppress_crashes=False', 'common.use_plasma_view=False', "common.plasma_path='/tmp/plasma'", 'common_eval.path=null', 'common_eval.post_process=null', 'common_eval.quiet=False', "common_eval.model_overrides='{}'", 'common_eval.results_path=null', 'distributed_training.distributed_world_size=1', 'distributed_training.distributed_num_procs=1', 'distributed_training.distributed_rank=0', "distributed_training.distributed_backend='nccl'", 'distributed_training.distributed_init_method=null', 'distributed_training.distributed_port=-1', 'distributed_training.device_id=0', 'distributed_training.distributed_no_spawn=False', "distributed_training.ddp_backend='pytorch_ddp'", "distributed_training.ddp_comm_hook='none'", 'distributed_training.bucket_cap_mb=25', 'distributed_training.fix_batches_to_gpus=False', 'distributed_training.find_unused_parameters=False', 'distributed_training.gradient_as_bucket_view=False', 'distributed_training.fast_stat_sync=False', 'distributed_training.heartbeat_timeout=-1', 'distributed_training.broadcast_buffers=False', 'distributed_training.slowmo_momentum=null', "distributed_training.slowmo_algorithm='LocalSGD'", 'distributed_training.localsgd_frequency=3', 'distributed_training.nprocs_per_node=1', 'distributed_training.pipeline_model_parallel=False', 'distributed_training.pipeline_balance=null', 'distributed_training.pipeline_devices=null', 'distributed_training.pipeline_chunks=0', 'distributed_training.pipeline_encoder_balance=null', 'distributed_training.pipeline_encoder_devices=null', 'distributed_training.pipeline_decoder_balance=null', 'distributed_training.pipeline_decoder_devices=null', "distributed_training.pipeline_checkpoint='never'", "distributed_training.zero_sharding='none'", 'distributed_training.fp16=True', 'distributed_training.memory_efficient_fp16=False', 'distributed_training.tpu=False', 'distributed_training.no_reshard_after_forward=False', 'distributed_training.fp32_reduce_scatter=False', 'distributed_training.cpu_offload=False', 'distributed_training.use_sharded_state=False', 'dataset.num_workers=1', 'dataset.skip_invalid_size_inputs_valid_test=False', 'dataset.max_tokens=512', 'dataset.batch_size=null', 'dataset.required_batch_size_multiple=8', 'dataset.required_seq_len_multiple=1', 'dataset.dataset_impl=null', 'dataset.data_buffer_size=10', "dataset.train_subset='train'", "dataset.valid_subset='valid'", 'dataset.combine_valid_subsets=null', 'dataset.ignore_unused_valid_subsets=False', 'dataset.validate_interval=1', 'dataset.validate_interval_updates=0', 'dataset.validate_after_updates=0', 'dataset.fixed_validation_seed=null', 'dataset.disable_validation=False', 'dataset.max_tokens_valid=512', 'dataset.batch_size_valid=null', 'dataset.max_valid_steps=null', 'dataset.curriculum=0', "dataset.gen_subset='test'", 'dataset.num_shards=1', 'dataset.shard_id=0', 'optimization.max_epoch=0', 'optimization.max_update=50000', 'optimization.stop_time_hours=0.0', 'optimization.clip_norm=0.0', 'optimization.sentence_avg=False', 'optimization.update_freq=[128]', 'optimization.lr=[0.0005]', 'optimization.stop_min_lr=-1.0', 'optimization.use_bmuf=False', "checkpoint.save_dir='/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1'", "checkpoint.restore_file='checkpoint_last.pt'", 'checkpoint.finetune_from_model=null', 'checkpoint.reset_dataloader=False', 'checkpoint.reset_lr_scheduler=False', 'checkpoint.reset_meters=False', 'checkpoint.reset_optimizer=False', "checkpoint.optimizer_overrides='{}'", 'checkpoint.save_interval=1', 'checkpoint.save_interval_updates=0', 'checkpoint.keep_interval_updates=-1', 'checkpoint.keep_interval_updates_pattern=-1', 'checkpoint.keep_last_epochs=-1', 'checkpoint.keep_best_checkpoints=-1', 'checkpoint.no_save=False', 'checkpoint.no_epoch_checkpoints=True', 'checkpoint.no_last_checkpoints=False', 'checkpoint.no_save_optimizer_state=False', "checkpoint.best_checkpoint_metric='loss'", 'checkpoint.maximize_best_checkpoint_metric=False', 'checkpoint.patience=-1', "checkpoint.checkpoint_suffix=''", 'checkpoint.checkpoint_shard_count=1', 'checkpoint.load_checkpoint_on_all_dp_ranks=False', 'checkpoint.write_checkpoints_asynchronously=False', 'checkpoint.model_parallel_size=1', 'bmuf.block_lr=1.0', 'bmuf.block_momentum=0.875', 'bmuf.global_sync_iter=50', 'bmuf.warmup_iterations=500', 'bmuf.use_nbm=False', 'bmuf.average_sync=False', 'bmuf.distributed_world_size=1', 'generation.beam=5', 'generation.nbest=1', 'generation.max_len_a=0.0', 'generation.max_len_b=200', 'generation.min_len=1', 'generation.match_source_len=False', 'generation.unnormalized=False', 'generation.no_early_stop=False', 'generation.no_beamable_mm=False', 'generation.lenpen=1.0', 'generation.unkpen=0.0', 'generation.replace_unk=null', 'generation.sacrebleu=False', 'generation.score_reference=False', 'generation.prefix_size=0', 'generation.no_repeat_ngram_size=0', 'generation.sampling=False', 'generation.sampling_topk=-1', 'generation.sampling_topp=-1.0', 'generation.constraints=null', 'generation.temperature=1.0', 'generation.diverse_beam_groups=-1', 'generation.diverse_beam_strength=0.5', 'generation.diversity_rate=-1.0', 'generation.print_alignment=null', 'generation.print_step=False', 'generation.lm_path=null', 'generation.lm_weight=0.0', 'generation.iter_decode_eos_penalty=0.0', 'generation.iter_decode_max_iter=10', 'generation.iter_decode_force_max_iter=False', 'generation.iter_decode_with_beam=1', 'generation.iter_decode_with_external_reranker=False', 'generation.retain_iter_history=False', 'generation.retain_dropout=False', 'generation.retain_dropout_modules=null', 'generation.decoding_format=null', 'generation.no_seed_provided=False', 'eval_lm.output_word_probs=False', 'eval_lm.output_word_stats=False', 'eval_lm.context_window=0', 'eval_lm.softmax_batch=9223372036854775807', 'interactive.buffer_size=0', "interactive.input='-'", 'ema.store_ema=False', 'ema.ema_decay=0.9999', 'ema.ema_start_update=0', 'ema.ema_seed_model=null', 'ema.ema_update_freq=1', 'ema.ema_fp32=False', 'task=language_modeling', 'task._name=language_modeling', "task.data='data-bin/wikitext-103-raw-size-0.0625'", "task.sample_break_mode='none'", 'task.tokens_per_sample=512', 'task.output_dictionary_size=-1', 'task.self_target=False', 'task.future_target=False', 'task.past_target=False', 'task.add_bos_token=False', 'task.max_target_positions=null', "task.shorten_method='none'", "task.shorten_data_split_list=''", 'task.pad_to_fixed_length=False', 'task.pad_to_fixed_bsz=False', 'task.seed=66575611', 'task.batch_size=null', 'task.batch_size_valid=null', 'task.dataset_impl=null', 'task.data_buffer_size=10', 'task.tpu=False', 'task.use_plasma_view=False', "task.plasma_path='/tmp/plasma'", 'criterion=label_smoothed_cross_entropy', 'criterion._name=label_smoothed_cross_entropy', 'criterion.label_smoothing=0.08', 'criterion.report_accuracy=False', 'criterion.ignore_prefix_size=0', 'criterion.sentence_avg=False', 'optimizer=adam', 'optimizer._name=adam', "optimizer.adam_betas='(0.9, 0.98)'", 'optimizer.adam_eps=1e-08', 'optimizer.weight_decay=0.01', 'optimizer.use_old_adam=False', 'optimizer.fp16_adam_stats=False', 'optimizer.tpu=False', 'optimizer.lr=[0.0005]', 'lr_scheduler=inverse_sqrt', 'lr_scheduler._name=inverse_sqrt', 'lr_scheduler.warmup_updates=4000', 'lr_scheduler.warmup_init_lr=1e-07', 'lr_scheduler.lr=[0.0005]', 'scoring=bleu', 'scoring._name=bleu', 'scoring.pad=1', 'scoring.eos=2', 'scoring.unk=3', 'model=transformer_lm', 'model._name=transformer_lm', "model.activation_fn='relu'", 'model.dropout=0.1', 'model.attention_dropout=0.0', 'model.activation_dropout=0.0', 'model.relu_dropout=0.0', 'model.decoder_embed_dim=512', 'model.decoder_output_dim=512', 'model.decoder_input_dim=512', 'model.decoder_ffn_embed_dim=2048', 'model.decoder_layers=6', 'model.decoder_attention_heads=8', 'model.decoder_normalize_before=False', 'model.no_decoder_final_norm=False', 'model.adaptive_softmax_cutoff=null', 'model.adaptive_softmax_dropout=0.0', 'model.adaptive_softmax_factor=4.0', 'model.no_token_positional_embeddings=False', 'model.share_decoder_input_output_embed=True', 'model.character_embeddings=False', "model.character_filters='[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]'", 'model.character_embedding_dim=4', 'model.char_embedder_highway_layers=2', 'model.adaptive_input=False', 'model.adaptive_input_factor=4.0', 'model.adaptive_input_cutoff=null', 'model.tie_adaptive_weights=False', 'model.tie_adaptive_proj=False', 'model.decoder_learned_pos=False', 'model.layernorm_embedding=False', 'model.no_scale_embedding=False', 'model.checkpoint_activations=False', 'model.offload_activations=False', 'model.decoder_layerdrop=0.0', 'model.decoder_layers_to_keep=null', 'model.quant_noise_pq=0.0', 'model.quant_noise_pq_block_size=8', 'model.quant_noise_scalar=0.0', 'model.min_params_to_wrap=100000000', 'model.base_layers=0', 'model.base_sublayers=1', 'model.base_shuffle=1', 'model.scale_fc=False', 'model.scale_attn=False', 'model.scale_heads=False', 'model.scale_resids=False', 'model.add_bos_token=False', 'model.tokens_per_sample=512', 'model.max_target_positions=null', 'model.tpu=False']
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 533, in cli_main
    cfg = convert_namespace_to_omegaconf(args)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/dataclass/utils.py", line 389, in convert_namespace_to_omegaconf
    composed_cfg = compose("config", overrides=overrides, strict=False)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/experimental/compose.py", line 31, in compose
    cfg = gh.hydra.compose_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/hydra.py", line 507, in compose_config
    cfg = self.config_loader.load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 151, in load_configuration
    return self._load_configuration(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 224, in _load_configuration
    job_cfg, job_cfg_load_trace = self._load_primary_config(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 819, in _load_primary_config
    ret, load_trace = self._load_config_impl(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/hydra/_internal/config_loader_impl.py", line 614, in _load_config_impl
    schema.config = OmegaConf.merge(
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/omegaconf.py", line 321, in merge
    target.merge_with(*others[1:])
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 329, in merge_with
    self._merge_with(*others)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 347, in _merge_with
    BaseContainer._map_merge(self, other)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 312, in _map_merge
    dest[key] = src._get_node(key)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 256, in __setitem__
    self.__set_impl(key=key, value=value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 266, in __set_impl
    self._set_item_impl(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 475, in _set_item_impl
    assign(key, value)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/basecontainer.py", line 452, in assign
    v = copy.deepcopy(value_to_assign)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/dictconfig.py", line 93, in __deepcopy__
    res.__dict__[k] = copy.deepcopy(v, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 222, in __deepcopy__
    self._deepcopy_impl(res, memo)
  File "/cluster/home/andriusb/fq/env/lib64/python3.8/site-packages/omegaconf/nodes.py", line 76, in _deepcopy_impl
    res.__dict__ = copy.deepcopy(self.__dict__, memo=memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 270, in _reconstruct
    state = deepcopy(state, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/copy.py", line 146, in deepcopy
    y = copier(x, memo)
KeyboardInterrupt
Sender: LSF System <lsfadmin@eu-g3-082>
Subject: Job 207264067: <w103_size_0.03125_fp16_label_smoothing_0.08_#1> in cluster <euler> Exited

Job <w103_size_0.03125_fp16_label_smoothing_0.08_#1> was submitted from host <eu-login-33> by user <andriusb> in cluster <euler> at Sat Mar  5 14:21:45 2022
Job was executed on host(s) <eu-g3-082>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Sat Mar  5 14:22:16 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sat Mar  5 14:22:16 2022
Terminated at Sun Mar  6 08:56:02 2022
Results reported at Sun Mar  6 08:56:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.08 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575611 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66750.25 sec.
    Max Memory :                                 7640 MB
    Average Memory :                             4473.95 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               12360.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   66826 sec.
    Turnaround time :                            66857 sec.

The output (if any) follows:

2022-03-05 14:22:31 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575611, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.08, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-05 14:22:31 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-05 14:22:33 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-05 14:22:33 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-05 14:22:33 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-05 14:22:33 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-05 14:22:33 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-05 14:22:33 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-05 14:22:33 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-05 14:22:41 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-05 14:22:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:41 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-05 14:22:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-05 14:22:41 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-05 14:22:41 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-05 14:22:41 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 14:22:41 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 14:22:41 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-05 14:22:41 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-05 14:22:41 | INFO | fairseq.trainer | begin training epoch 1
2022-03-05 14:22:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:22:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-05 14:22:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:22:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:23:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 14:23:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-05 14:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:24:53 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.553 | nll_loss 15.397 | ppl 43134 | wps 46425.1 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-05 14:24:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-05 14:24:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:24:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:24:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.553) (writing took 3.6876591062173247 seconds)
2022-03-05 14:24:56 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-05 14:24:56 | INFO | train | epoch 001 | loss 16.592 | nll_loss 16.527 | ppl 94418.6 | wps 27020.1 | ups 0.42 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.686 | loss_scale 4 | train_wall 115 | gb_free 21.6 | wall 135
2022-03-05 14:24:56 | INFO | fairseq.trainer | begin training epoch 2
2022-03-05 14:24:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:26:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.158 | nll_loss 13.88 | ppl 15078.2 | wps 46284.7 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 14.158
2022-03-05 14:26:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-05 14:26:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:26:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:26:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 2 @ 93 updates, score 14.158) (writing took 3.9890699591487646 seconds)
2022-03-05 14:26:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-05 14:26:53 | INFO | train | epoch 002 | loss 14.807 | nll_loss 14.588 | ppl 24628.3 | wps 27218.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.117 | loss_scale 4 | train_wall 97 | gb_free 21.6 | wall 252
2022-03-05 14:26:53 | INFO | fairseq.trainer | begin training epoch 3
2022-03-05 14:26:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:27:09 | INFO | train_inner | epoch 003:      7 / 49 loss=15.548, nll_loss=15.393, ppl=43015.7, wps=27262.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.202, loss_scale=4, train_wall=226, gb_free=21.6, wall=267
2022-03-05 14:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:28:46 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.518 | nll_loss 13.19 | ppl 9342.52 | wps 45903.7 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.518
2022-03-05 14:28:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-05 14:28:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:28:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.518) (writing took 3.8903702860698104 seconds)
2022-03-05 14:28:50 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-05 14:28:50 | INFO | train | epoch 003 | loss 13.909 | nll_loss 13.614 | ppl 12538.1 | wps 27154.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.396 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 369
2022-03-05 14:28:50 | INFO | fairseq.trainer | begin training epoch 4
2022-03-05 14:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:30:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.722 | nll_loss 12.317 | ppl 5103 | wps 45789 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.722
2022-03-05 14:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-05 14:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.722) (writing took 3.9017003187909722 seconds)
2022-03-05 14:30:47 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-05 14:30:47 | INFO | train | epoch 004 | loss 13.184 | nll_loss 12.827 | ppl 7264.39 | wps 27165.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.195 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 486
2022-03-05 14:30:47 | INFO | fairseq.trainer | begin training epoch 5
2022-03-05 14:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:31:07 | INFO | train_inner | epoch 005:      9 / 49 loss=13.423, nll_loss=13.086, ppl=8694.27, wps=27206.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.257, loss_scale=8, train_wall=198, gb_free=21.6, wall=506
2022-03-05 14:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:32:40 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.002 | nll_loss 11.517 | ppl 2931.64 | wps 45662.3 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 12.002
2022-03-05 14:32:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-05 14:32:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:32:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 5 @ 240 updates, score 12.002) (writing took 4.125066907145083 seconds)
2022-03-05 14:32:44 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-05 14:32:44 | INFO | train | epoch 005 | loss 12.38 | nll_loss 11.942 | ppl 3933.67 | wps 27108.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.904 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 603
2022-03-05 14:32:44 | INFO | fairseq.trainer | begin training epoch 6
2022-03-05 14:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:34:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:34:38 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.433 | nll_loss 10.873 | ppl 1874.97 | wps 45257.9 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.433
2022-03-05 14:34:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-05 14:34:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:34:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.433) (writing took 4.051448716782033 seconds)
2022-03-05 14:34:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-05 14:34:42 | INFO | train | epoch 006 | loss 11.705 | nll_loss 11.189 | ppl 2334.44 | wps 27108 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.7 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 720
2022-03-05 14:34:42 | INFO | fairseq.trainer | begin training epoch 7
2022-03-05 14:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:35:06 | INFO | train_inner | epoch 007:     11 / 49 loss=11.906, nll_loss=11.413, ppl=2726.79, wps=27148.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.762, loss_scale=16, train_wall=198, gb_free=21.6, wall=745
2022-03-05 14:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:36:35 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.077 | nll_loss 10.454 | ppl 1402.64 | wps 45694.7 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 11.077
2022-03-05 14:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-05 14:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:36:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 7 @ 338 updates, score 11.077) (writing took 4.561640969477594 seconds)
2022-03-05 14:36:39 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-05 14:36:39 | INFO | train | epoch 007 | loss 11.214 | nll_loss 10.625 | ppl 1579.04 | wps 26979.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.572 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 838
2022-03-05 14:36:39 | INFO | fairseq.trainer | begin training epoch 8
2022-03-05 14:36:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:38:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.862 | nll_loss 10.189 | ppl 1167.67 | wps 45911.3 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.862
2022-03-05 14:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-05 14:38:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.862) (writing took 4.08198119699955 seconds)
2022-03-05 14:38:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-05 14:38:36 | INFO | train | epoch 008 | loss 10.919 | nll_loss 10.272 | ppl 1236.19 | wps 27132.8 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 955
2022-03-05 14:38:37 | INFO | fairseq.trainer | begin training epoch 9
2022-03-05 14:38:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:39:06 | INFO | train_inner | epoch 009:     13 / 49 loss=10.997, nll_loss=10.365, ppl=1318.72, wps=27100, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.48, loss_scale=32, train_wall=199, gb_free=21.6, wall=984
2022-03-05 14:40:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:40:30 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.699 | nll_loss 9.993 | ppl 1018.94 | wps 45621.7 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.699
2022-03-05 14:40:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-05 14:40:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:40:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.699) (writing took 3.933178700506687 seconds)
2022-03-05 14:40:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-05 14:40:34 | INFO | train | epoch 009 | loss 10.726 | nll_loss 10.038 | ppl 1051.15 | wps 27159.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.475 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1072
2022-03-05 14:40:34 | INFO | fairseq.trainer | begin training epoch 10
2022-03-05 14:40:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:42:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:42:27 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.544 | nll_loss 9.814 | ppl 900.44 | wps 45393.5 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.544
2022-03-05 14:42:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-05 14:42:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:42:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.544) (writing took 3.937293054535985 seconds)
2022-03-05 14:42:31 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-05 14:42:31 | INFO | train | epoch 010 | loss 10.563 | nll_loss 9.846 | ppl 920.02 | wps 27119.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.496 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1189
2022-03-05 14:42:31 | INFO | fairseq.trainer | begin training epoch 11
2022-03-05 14:42:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:43:04 | INFO | train_inner | epoch 011:     15 / 49 loss=10.6, nll_loss=9.889, ppl=947.89, wps=27171.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.503, loss_scale=32, train_wall=199, gb_free=21.6, wall=1223
2022-03-05 14:43:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:44:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:44:24 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.41 | nll_loss 9.662 | ppl 810.27 | wps 45645.7 | wpb 510.9 | bsz 1 | num_updates 533 | best_loss 10.41
2022-03-05 14:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 533 updates
2022-03-05 14:44:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 11 @ 533 updates, score 10.41) (writing took 3.9186668256297708 seconds)
2022-03-05 14:44:28 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-05 14:44:28 | INFO | train | epoch 011 | loss 10.41 | nll_loss 9.671 | ppl 814.99 | wps 26555.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 533 | lr 6.67117e-05 | gnorm 0.525 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1307
2022-03-05 14:44:28 | INFO | fairseq.trainer | begin training epoch 12
2022-03-05 14:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:46:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:46:21 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.277 | nll_loss 9.512 | ppl 729.93 | wps 45343.1 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 10.277
2022-03-05 14:46:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-05 14:46:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:46:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:46:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 12 @ 582 updates, score 10.277) (writing took 4.088952923193574 seconds)
2022-03-05 14:46:25 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-05 14:46:25 | INFO | train | epoch 012 | loss 10.263 | nll_loss 9.506 | ppl 727.03 | wps 27078.4 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.59 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1424
2022-03-05 14:46:25 | INFO | fairseq.trainer | begin training epoch 13
2022-03-05 14:46:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:47:06 | INFO | train_inner | epoch 013:     18 / 49 loss=10.284, nll_loss=9.53, ppl=739.19, wps=26894.7, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.571, loss_scale=32, train_wall=201, gb_free=21.6, wall=1464
2022-03-05 14:48:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:48:18 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.172 | nll_loss 9.395 | ppl 673.29 | wps 45239.6 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 10.172
2022-03-05 14:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-05 14:48:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:48:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 13 @ 631 updates, score 10.172) (writing took 3.8693061927333474 seconds)
2022-03-05 14:48:22 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-05 14:48:22 | INFO | train | epoch 013 | loss 10.126 | nll_loss 9.351 | ppl 653.13 | wps 27149.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.664 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1541
2022-03-05 14:48:22 | INFO | fairseq.trainer | begin training epoch 14
2022-03-05 14:48:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:48:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 14:50:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:50:16 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.057 | nll_loss 9.261 | ppl 613.39 | wps 45388.5 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 10.057
2022-03-05 14:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-05 14:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 14 @ 679 updates, score 10.057) (writing took 3.7637898176908493 seconds)
2022-03-05 14:50:19 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-05 14:50:19 | INFO | train | epoch 014 | loss 9.998 | nll_loss 9.207 | ppl 591.1 | wps 26586.9 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.674 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1658
2022-03-05 14:50:19 | INFO | fairseq.trainer | begin training epoch 15
2022-03-05 14:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:51:06 | INFO | train_inner | epoch 015:     21 / 49 loss=10.01, nll_loss=9.221, ppl=596.8, wps=26934.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.678, loss_scale=16, train_wall=201, gb_free=21.6, wall=1705
2022-03-05 14:52:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:52:13 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.966 | nll_loss 9.16 | ppl 571.87 | wps 45116.7 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.966
2022-03-05 14:52:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-05 14:52:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:52:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:52:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.966) (writing took 3.8170940335839987 seconds)
2022-03-05 14:52:17 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-05 14:52:17 | INFO | train | epoch 015 | loss 9.874 | nll_loss 9.068 | ppl 536.69 | wps 27125.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.698 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 1775
2022-03-05 14:52:17 | INFO | fairseq.trainer | begin training epoch 16
2022-03-05 14:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:54:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:54:10 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.884 | nll_loss 9.063 | ppl 534.75 | wps 45307 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.884
2022-03-05 14:54:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-05 14:54:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:54:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.884) (writing took 3.909635601565242 seconds)
2022-03-05 14:54:14 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-05 14:54:14 | INFO | train | epoch 016 | loss 9.753 | nll_loss 8.932 | ppl 488.34 | wps 27121.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.777 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 1892
2022-03-05 14:54:14 | INFO | fairseq.trainer | begin training epoch 17
2022-03-05 14:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:55:05 | INFO | train_inner | epoch 017:     23 / 49 loss=9.76, nll_loss=8.939, ppl=490.95, wps=27163.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.762, loss_scale=32, train_wall=199, gb_free=21.6, wall=1944
2022-03-05 14:56:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:56:07 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.788 | nll_loss 8.953 | ppl 495.68 | wps 45421.6 | wpb 510.9 | bsz 1 | num_updates 826 | best_loss 9.788
2022-03-05 14:56:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 826 updates
2022-03-05 14:56:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:56:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:56:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 17 @ 826 updates, score 9.788) (writing took 3.7786297174170613 seconds)
2022-03-05 14:56:11 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-05 14:56:11 | INFO | train | epoch 017 | loss 9.634 | nll_loss 8.797 | ppl 444.8 | wps 27158.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 826 | lr 0.000103329 | gnorm 0.78 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2009
2022-03-05 14:56:11 | INFO | fairseq.trainer | begin training epoch 18
2022-03-05 14:56:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 14:58:04 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.707 | nll_loss 8.873 | ppl 468.97 | wps 45654.6 | wpb 510.9 | bsz 1 | num_updates 875 | best_loss 9.707
2022-03-05 14:58:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 875 updates
2022-03-05 14:58:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:58:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 14:58:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 18 @ 875 updates, score 9.707) (writing took 4.309036459773779 seconds)
2022-03-05 14:58:08 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-05 14:58:08 | INFO | train | epoch 018 | loss 9.52 | nll_loss 8.668 | ppl 406.89 | wps 27018 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 875 | lr 0.000109453 | gnorm 0.847 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2127
2022-03-05 14:58:08 | INFO | fairseq.trainer | begin training epoch 19
2022-03-05 14:58:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 14:58:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 14:59:06 | INFO | train_inner | epoch 019:     26 / 49 loss=9.52, nll_loss=8.668, ppl=406.89, wps=26885.2, ups=0.41, wpb=64876.2, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.85, loss_scale=32, train_wall=201, gb_free=21.6, wall=2185
2022-03-05 14:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:00:02 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.626 | nll_loss 8.762 | ppl 434.28 | wps 45737.1 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.626
2022-03-05 15:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-05 15:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:00:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:00:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.626) (writing took 3.880278059281409 seconds)
2022-03-05 15:00:05 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-05 15:00:05 | INFO | train | epoch 019 | loss 9.411 | nll_loss 8.545 | ppl 373.59 | wps 26578.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.88 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2244
2022-03-05 15:00:06 | INFO | fairseq.trainer | begin training epoch 20
2022-03-05 15:00:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:01:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:01:59 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.552 | nll_loss 8.677 | ppl 409.18 | wps 45791.8 | wpb 510.9 | bsz 1 | num_updates 972 | best_loss 9.552
2022-03-05 15:01:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 972 updates
2022-03-05 15:01:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:02:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:02:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 20 @ 972 updates, score 9.552) (writing took 3.805144887417555 seconds)
2022-03-05 15:02:03 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-05 15:02:03 | INFO | train | epoch 020 | loss 9.302 | nll_loss 8.423 | ppl 343.23 | wps 27134.1 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 972 | lr 0.000121576 | gnorm 0.844 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2361
2022-03-05 15:02:03 | INFO | fairseq.trainer | begin training epoch 21
2022-03-05 15:02:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:03:05 | INFO | train_inner | epoch 021:     28 / 49 loss=9.298, nll_loss=8.418, ppl=342.07, wps=27160.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.839, loss_scale=32, train_wall=199, gb_free=21.6, wall=2424
2022-03-05 15:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:03:56 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.482 | nll_loss 8.594 | ppl 386.42 | wps 45682.8 | wpb 510.9 | bsz 1 | num_updates 1021 | best_loss 9.482
2022-03-05 15:03:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1021 updates
2022-03-05 15:03:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:03:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 21 @ 1021 updates, score 9.482) (writing took 3.8666954850777984 seconds)
2022-03-05 15:04:00 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-05 15:04:00 | INFO | train | epoch 021 | loss 9.199 | nll_loss 8.307 | ppl 316.65 | wps 27104.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1021 | lr 0.000127699 | gnorm 0.834 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 2479
2022-03-05 15:04:00 | INFO | fairseq.trainer | begin training epoch 22
2022-03-05 15:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:04:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:05:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:05:53 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.421 | nll_loss 8.53 | ppl 369.56 | wps 45790.3 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.421
2022-03-05 15:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-05 15:05:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:05:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.421) (writing took 3.8214117269963026 seconds)
2022-03-05 15:05:57 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-05 15:05:57 | INFO | train | epoch 022 | loss 9.099 | nll_loss 8.193 | ppl 292.67 | wps 26578.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.854 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2596
2022-03-05 15:05:57 | INFO | fairseq.trainer | begin training epoch 23
2022-03-05 15:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:07:06 | INFO | train_inner | epoch 023:     31 / 49 loss=9.09, nll_loss=8.183, ppl=290.64, wps=26924.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.872, loss_scale=32, train_wall=201, gb_free=21.6, wall=2665
2022-03-05 15:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:07:50 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.365 | nll_loss 8.468 | ppl 354.06 | wps 45841.5 | wpb 510.9 | bsz 1 | num_updates 1118 | best_loss 9.365
2022-03-05 15:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1118 updates
2022-03-05 15:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 23 @ 1118 updates, score 9.365) (writing took 3.6776481652632356 seconds)
2022-03-05 15:07:54 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-05 15:07:54 | INFO | train | epoch 023 | loss 9.008 | nll_loss 8.09 | ppl 272.53 | wps 27196.5 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1118 | lr 0.000139822 | gnorm 0.962 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2712
2022-03-05 15:07:54 | INFO | fairseq.trainer | begin training epoch 24
2022-03-05 15:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:09:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:09:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:09:47 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.321 | nll_loss 8.407 | ppl 339.33 | wps 45907 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 9.321
2022-03-05 15:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-05 15:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:09:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 24 @ 1166 updates, score 9.321) (writing took 3.6865034671500325 seconds)
2022-03-05 15:09:51 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-05 15:09:51 | INFO | train | epoch 024 | loss 8.913 | nll_loss 7.983 | ppl 253.05 | wps 26605.6 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.862 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2829
2022-03-05 15:09:51 | INFO | fairseq.trainer | begin training epoch 25
2022-03-05 15:09:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:11:07 | INFO | train_inner | epoch 025:     34 / 49 loss=8.897, nll_loss=7.965, ppl=249.86, wps=26966.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.902, loss_scale=32, train_wall=201, gb_free=21.6, wall=2905
2022-03-05 15:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:11:44 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.265 | nll_loss 8.356 | ppl 327.53 | wps 45738.1 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 9.265
2022-03-05 15:11:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-05 15:11:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:11:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:11:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 25 @ 1215 updates, score 9.265) (writing took 3.756073680706322 seconds)
2022-03-05 15:11:48 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-05 15:11:48 | INFO | train | epoch 025 | loss 8.823 | nll_loss 7.881 | ppl 235.74 | wps 27168.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.886 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 2946
2022-03-05 15:11:48 | INFO | fairseq.trainer | begin training epoch 26
2022-03-05 15:11:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:13:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:13:41 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.221 | nll_loss 8.296 | ppl 314.35 | wps 45965.4 | wpb 510.9 | bsz 1 | num_updates 1264 | best_loss 9.221
2022-03-05 15:13:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1264 updates
2022-03-05 15:13:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:13:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:13:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 26 @ 1264 updates, score 9.221) (writing took 3.7157131023705006 seconds)
2022-03-05 15:13:45 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-05 15:13:45 | INFO | train | epoch 026 | loss 8.733 | nll_loss 7.78 | ppl 219.72 | wps 27158.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1264 | lr 0.000158068 | gnorm 0.937 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3063
2022-03-05 15:13:45 | INFO | fairseq.trainer | begin training epoch 27
2022-03-05 15:13:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:14:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:15:07 | INFO | train_inner | epoch 027:     37 / 49 loss=8.715, nll_loss=7.759, ppl=216.61, wps=26960, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.908, loss_scale=32, train_wall=201, gb_free=21.6, wall=3146
2022-03-05 15:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:15:38 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.184 | nll_loss 8.253 | ppl 305.02 | wps 45932.3 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 9.184
2022-03-05 15:15:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-05 15:15:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 27 @ 1312 updates, score 9.184) (writing took 5.816307954490185 seconds)
2022-03-05 15:15:44 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-05 15:15:44 | INFO | train | epoch 027 | loss 8.643 | nll_loss 7.677 | ppl 204.69 | wps 26161.9 | ups 0.4 | wpb 64844.1 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.894 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3182
2022-03-05 15:15:44 | INFO | fairseq.trainer | begin training epoch 28
2022-03-05 15:15:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:17:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:17:37 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.136 | nll_loss 8.196 | ppl 293.16 | wps 46590.6 | wpb 510.9 | bsz 1 | num_updates 1361 | best_loss 9.136
2022-03-05 15:17:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1361 updates
2022-03-05 15:17:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:17:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 28 @ 1361 updates, score 9.136) (writing took 4.684228558093309 seconds)
2022-03-05 15:17:42 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-05 15:17:42 | INFO | train | epoch 028 | loss 8.556 | nll_loss 7.578 | ppl 191.14 | wps 26958 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1361 | lr 0.000170191 | gnorm 0.926 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3300
2022-03-05 15:17:42 | INFO | fairseq.trainer | begin training epoch 29
2022-03-05 15:17:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:19:09 | INFO | train_inner | epoch 029:     39 / 49 loss=8.528, nll_loss=7.547, ppl=187.04, wps=26870.2, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.941, loss_scale=32, train_wall=199, gb_free=21.6, wall=3387
2022-03-05 15:19:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:19:35 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.106 | nll_loss 8.155 | ppl 285.11 | wps 46477.1 | wpb 510.9 | bsz 1 | num_updates 1410 | best_loss 9.106
2022-03-05 15:19:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1410 updates
2022-03-05 15:19:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:19:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:19:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 29 @ 1410 updates, score 9.106) (writing took 3.650804844684899 seconds)
2022-03-05 15:19:39 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-05 15:19:39 | INFO | train | epoch 029 | loss 8.465 | nll_loss 7.476 | ppl 178.03 | wps 27178.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1410 | lr 0.000176315 | gnorm 0.958 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3417
2022-03-05 15:19:39 | INFO | fairseq.trainer | begin training epoch 30
2022-03-05 15:19:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:20:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:21:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:21:32 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.102 | nll_loss 8.153 | ppl 284.56 | wps 46489.7 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 9.102
2022-03-05 15:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-05 15:21:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:21:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:21:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 30 @ 1458 updates, score 9.102) (writing took 3.8412851048633456 seconds)
2022-03-05 15:21:36 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-05 15:21:36 | INFO | train | epoch 030 | loss 8.375 | nll_loss 7.375 | ppl 165.94 | wps 26613.4 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.978 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3534
2022-03-05 15:21:36 | INFO | fairseq.trainer | begin training epoch 31
2022-03-05 15:21:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:23:09 | INFO | train_inner | epoch 031:     42 / 49 loss=8.346, nll_loss=7.341, ppl=162.16, wps=26968, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.969, loss_scale=32, train_wall=201, gb_free=21.6, wall=3628
2022-03-05 15:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:23:29 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.036 | nll_loss 8.068 | ppl 268.33 | wps 46506.3 | wpb 510.9 | bsz 1 | num_updates 1507 | best_loss 9.036
2022-03-05 15:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1507 updates
2022-03-05 15:23:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:23:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 31 @ 1507 updates, score 9.036) (writing took 3.636063067242503 seconds)
2022-03-05 15:23:32 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-05 15:23:32 | INFO | train | epoch 031 | loss 8.286 | nll_loss 7.274 | ppl 154.8 | wps 27206 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1507 | lr 0.000188437 | gnorm 0.973 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3651
2022-03-05 15:23:32 | INFO | fairseq.trainer | begin training epoch 32
2022-03-05 15:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:25:26 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.032 | nll_loss 8.068 | ppl 268.29 | wps 46572.1 | wpb 510.9 | bsz 1 | num_updates 1556 | best_loss 9.032
2022-03-05 15:25:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1556 updates
2022-03-05 15:25:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:25:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:25:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 32 @ 1556 updates, score 9.032) (writing took 3.687354665249586 seconds)
2022-03-05 15:25:29 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-05 15:25:29 | INFO | train | epoch 032 | loss 8.193 | nll_loss 7.169 | ppl 143.87 | wps 27181.6 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1556 | lr 0.000194561 | gnorm 0.902 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 3768
2022-03-05 15:25:29 | INFO | fairseq.trainer | begin training epoch 33
2022-03-05 15:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:25:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:27:10 | INFO | train_inner | epoch 033:     45 / 49 loss=8.16, nll_loss=7.131, ppl=140.18, wps=26993, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.949, loss_scale=32, train_wall=201, gb_free=21.6, wall=3868
2022-03-05 15:27:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:27:22 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.999 | nll_loss 8.022 | ppl 259.97 | wps 46539.4 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.999
2022-03-05 15:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-05 15:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:27:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.999) (writing took 3.6702623795717955 seconds)
2022-03-05 15:27:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-05 15:27:26 | INFO | train | epoch 033 | loss 8.107 | nll_loss 7.071 | ppl 134.44 | wps 26664.1 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.993 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 3885
2022-03-05 15:27:26 | INFO | fairseq.trainer | begin training epoch 34
2022-03-05 15:27:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:29:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:29:19 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.989 | nll_loss 8 | ppl 256.05 | wps 46538.2 | wpb 510.9 | bsz 1 | num_updates 1653 | best_loss 8.989
2022-03-05 15:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1653 updates
2022-03-05 15:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:29:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:29:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 34 @ 1653 updates, score 8.989) (writing took 3.6840434707701206 seconds)
2022-03-05 15:29:23 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-05 15:29:23 | INFO | train | epoch 034 | loss 8.017 | nll_loss 6.97 | ppl 125.35 | wps 27186.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1653 | lr 0.000206684 | gnorm 0.971 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4002
2022-03-05 15:29:23 | INFO | fairseq.trainer | begin training epoch 35
2022-03-05 15:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:30:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:31:10 | INFO | train_inner | epoch 035:     48 / 49 loss=7.98, nll_loss=6.927, ppl=121.71, wps=26970.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.981, loss_scale=32, train_wall=201, gb_free=21.6, wall=4109
2022-03-05 15:31:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:31:16 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.983 | nll_loss 8.013 | ppl 258.4 | wps 46605.7 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.983
2022-03-05 15:31:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-05 15:31:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:31:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:31:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 35 @ 1701 updates, score 8.983) (writing took 3.75536516495049 seconds)
2022-03-05 15:31:20 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-05 15:31:20 | INFO | train | epoch 035 | loss 7.931 | nll_loss 6.872 | ppl 117.1 | wps 26610.7 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 0.991 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4119
2022-03-05 15:31:20 | INFO | fairseq.trainer | begin training epoch 36
2022-03-05 15:31:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:33:13 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.965 | nll_loss 7.967 | ppl 250.19 | wps 46295.4 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.965
2022-03-05 15:33:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-05 15:33:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:33:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:33:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.965) (writing took 3.723537005484104 seconds)
2022-03-05 15:33:17 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-05 15:33:17 | INFO | train | epoch 036 | loss 7.844 | nll_loss 6.773 | ppl 109.39 | wps 27188.9 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 0.989 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4235
2022-03-05 15:33:17 | INFO | fairseq.trainer | begin training epoch 37
2022-03-05 15:33:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:35:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:35:10 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.953 | nll_loss 7.955 | ppl 248.22 | wps 46354.3 | wpb 510.9 | bsz 1 | num_updates 1799 | best_loss 8.953
2022-03-05 15:35:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1799 updates
2022-03-05 15:35:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:35:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt
2022-03-05 15:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_best.pt (epoch 37 @ 1799 updates, score 8.953) (writing took 3.72949537076056 seconds)
2022-03-05 15:35:14 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-05 15:35:14 | INFO | train | epoch 037 | loss 7.757 | nll_loss 6.675 | ppl 102.15 | wps 27148.7 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 1799 | lr 0.00022493 | gnorm 1.016 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4352
2022-03-05 15:35:14 | INFO | fairseq.trainer | begin training epoch 38
2022-03-05 15:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:35:16 | INFO | train_inner | epoch 038:      1 / 49 loss=7.799, nll_loss=6.722, ppl=105.56, wps=26250.3, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=1.001, loss_scale=32, train_wall=198, gb_free=21.6, wall=4355
2022-03-05 15:36:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:37:07 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.96 | nll_loss 7.964 | ppl 249.77 | wps 46416.5 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.953
2022-03-05 15:37:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-05 15:37:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:37:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:37:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.96) (writing took 1.674928960390389 seconds)
2022-03-05 15:37:09 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-05 15:37:09 | INFO | train | epoch 038 | loss 7.669 | nll_loss 6.575 | ppl 95.32 | wps 27117.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 0.98 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4467
2022-03-05 15:37:09 | INFO | fairseq.trainer | begin training epoch 39
2022-03-05 15:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:39:02 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.977 | nll_loss 7.986 | ppl 253.48 | wps 46474.2 | wpb 510.9 | bsz 1 | num_updates 1896 | best_loss 8.953
2022-03-05 15:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1896 updates
2022-03-05 15:39:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:39:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:39:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 39 @ 1896 updates, score 8.977) (writing took 1.711175262928009 seconds)
2022-03-05 15:39:03 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-05 15:39:03 | INFO | train | epoch 039 | loss 7.586 | nll_loss 6.481 | ppl 89.3 | wps 27694.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1896 | lr 0.000237053 | gnorm 1.05 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4582
2022-03-05 15:39:03 | INFO | fairseq.trainer | begin training epoch 40
2022-03-05 15:39:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:39:12 | INFO | train_inner | epoch 040:      4 / 49 loss=7.622, nll_loss=6.522, ppl=91.89, wps=27454.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.016, loss_scale=32, train_wall=201, gb_free=21.6, wall=4591
2022-03-05 15:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:40:57 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.006 | nll_loss 8.015 | ppl 258.59 | wps 46433.1 | wpb 510.9 | bsz 1 | num_updates 1945 | best_loss 8.953
2022-03-05 15:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1945 updates
2022-03-05 15:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:40:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 40 @ 1945 updates, score 9.006) (writing took 1.6786458417773247 seconds)
2022-03-05 15:40:58 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-05 15:40:58 | INFO | train | epoch 040 | loss 7.501 | nll_loss 6.383 | ppl 83.47 | wps 27644 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1945 | lr 0.000243176 | gnorm 1.013 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4697
2022-03-05 15:40:58 | INFO | fairseq.trainer | begin training epoch 41
2022-03-05 15:40:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:42:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:42:52 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.03 | nll_loss 8.041 | ppl 263.35 | wps 46482.3 | wpb 510.9 | bsz 1 | num_updates 1994 | best_loss 8.953
2022-03-05 15:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1994 updates
2022-03-05 15:42:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:42:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:42:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 41 @ 1994 updates, score 9.03) (writing took 1.6224734298884869 seconds)
2022-03-05 15:42:53 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-05 15:42:53 | INFO | train | epoch 041 | loss 7.416 | nll_loss 6.288 | ppl 78.12 | wps 27679.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 1994 | lr 0.0002493 | gnorm 1.042 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 4812
2022-03-05 15:42:53 | INFO | fairseq.trainer | begin training epoch 42
2022-03-05 15:42:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:43:07 | INFO | train_inner | epoch 042:      6 / 49 loss=7.448, nll_loss=6.323, ppl=80.09, wps=27701.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.034, loss_scale=64, train_wall=199, gb_free=21.6, wall=4825
2022-03-05 15:43:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:44:46 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.072 | nll_loss 8.072 | ppl 269.16 | wps 46451.4 | wpb 510.9 | bsz 1 | num_updates 2042 | best_loss 8.953
2022-03-05 15:44:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2042 updates
2022-03-05 15:44:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:44:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:44:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 42 @ 2042 updates, score 9.072) (writing took 1.6412187023088336 seconds)
2022-03-05 15:44:48 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-05 15:44:48 | INFO | train | epoch 042 | loss 7.331 | nll_loss 6.19 | ppl 73.02 | wps 27083.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2042 | lr 0.000255299 | gnorm 1.052 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 4927
2022-03-05 15:44:48 | INFO | fairseq.trainer | begin training epoch 43
2022-03-05 15:44:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:46:41 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.086 | nll_loss 8.096 | ppl 273.56 | wps 46565.5 | wpb 510.9 | bsz 1 | num_updates 2091 | best_loss 8.953
2022-03-05 15:46:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2091 updates
2022-03-05 15:46:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:46:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:46:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 43 @ 2091 updates, score 9.086) (writing took 1.6722271759063005 seconds)
2022-03-05 15:46:43 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-05 15:46:43 | INFO | train | epoch 043 | loss 7.252 | nll_loss 6.101 | ppl 68.63 | wps 27642.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2091 | lr 0.000261423 | gnorm 1.065 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5042
2022-03-05 15:46:43 | INFO | fairseq.trainer | begin training epoch 44
2022-03-05 15:46:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:47:03 | INFO | train_inner | epoch 044:      9 / 49 loss=7.276, nll_loss=6.128, ppl=69.94, wps=27419.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.061, loss_scale=32, train_wall=201, gb_free=21.6, wall=5062
2022-03-05 15:48:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 15:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:48:36 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.131 | nll_loss 8.144 | ppl 282.86 | wps 46365.3 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.953
2022-03-05 15:48:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-05 15:48:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:48:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:48:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 44 @ 2139 updates, score 9.131) (writing took 1.6708011953160167 seconds)
2022-03-05 15:48:38 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-05 15:48:38 | INFO | train | epoch 044 | loss 7.17 | nll_loss 6.007 | ppl 64.29 | wps 27084.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.125 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5157
2022-03-05 15:48:38 | INFO | fairseq.trainer | begin training epoch 45
2022-03-05 15:48:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:50:31 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.159 | nll_loss 8.181 | ppl 290.18 | wps 46488 | wpb 510.9 | bsz 1 | num_updates 2188 | best_loss 8.953
2022-03-05 15:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2188 updates
2022-03-05 15:50:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 45 @ 2188 updates, score 9.159) (writing took 1.666886366903782 seconds)
2022-03-05 15:50:33 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-05 15:50:33 | INFO | train | epoch 045 | loss 7.086 | nll_loss 5.912 | ppl 60.2 | wps 27639.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2188 | lr 0.000273545 | gnorm 1.06 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 5272
2022-03-05 15:50:33 | INFO | fairseq.trainer | begin training epoch 46
2022-03-05 15:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:51:00 | INFO | train_inner | epoch 046:     12 / 49 loss=7.109, nll_loss=5.938, ppl=61.31, wps=27417.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.086, loss_scale=32, train_wall=201, gb_free=21.6, wall=5298
2022-03-05 15:52:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 15:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:52:26 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.165 | nll_loss 8.17 | ppl 288.06 | wps 46474 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.953
2022-03-05 15:52:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-05 15:52:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 46 @ 2236 updates, score 9.165) (writing took 1.7044690288603306 seconds)
2022-03-05 15:52:28 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-05 15:52:28 | INFO | train | epoch 046 | loss 7.006 | nll_loss 5.82 | ppl 56.5 | wps 27115.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.137 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5386
2022-03-05 15:52:28 | INFO | fairseq.trainer | begin training epoch 47
2022-03-05 15:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:54:21 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.211 | nll_loss 8.227 | ppl 299.66 | wps 46597.2 | wpb 510.9 | bsz 1 | num_updates 2285 | best_loss 8.953
2022-03-05 15:54:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2285 updates
2022-03-05 15:54:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:54:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 47 @ 2285 updates, score 9.211) (writing took 1.6436537019908428 seconds)
2022-03-05 15:54:23 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-05 15:54:23 | INFO | train | epoch 047 | loss 6.925 | nll_loss 5.728 | ppl 53 | wps 27668.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2285 | lr 0.000285668 | gnorm 1.076 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5501
2022-03-05 15:54:23 | INFO | fairseq.trainer | begin training epoch 48
2022-03-05 15:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:54:56 | INFO | train_inner | epoch 048:     15 / 49 loss=6.943, nll_loss=5.748, ppl=53.74, wps=27449, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.124, loss_scale=16, train_wall=201, gb_free=21.6, wall=5535
2022-03-05 15:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:56:16 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.268 | nll_loss 8.286 | ppl 312.15 | wps 46560.3 | wpb 510.9 | bsz 1 | num_updates 2334 | best_loss 8.953
2022-03-05 15:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2334 updates
2022-03-05 15:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:56:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:56:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 48 @ 2334 updates, score 9.268) (writing took 1.6145861018449068 seconds)
2022-03-05 15:56:17 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-05 15:56:17 | INFO | train | epoch 048 | loss 6.845 | nll_loss 5.637 | ppl 49.75 | wps 27687.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2334 | lr 0.000291792 | gnorm 1.126 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 5616
2022-03-05 15:56:17 | INFO | fairseq.trainer | begin training epoch 49
2022-03-05 15:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 15:58:11 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.3 | nll_loss 8.307 | ppl 316.73 | wps 46556.8 | wpb 510.9 | bsz 1 | num_updates 2383 | best_loss 8.953
2022-03-05 15:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2383 updates
2022-03-05 15:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:58:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 15:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 49 @ 2383 updates, score 9.3) (writing took 1.6501852422952652 seconds)
2022-03-05 15:58:12 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-05 15:58:12 | INFO | train | epoch 049 | loss 6.767 | nll_loss 5.547 | ppl 46.74 | wps 27668.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2383 | lr 0.000297915 | gnorm 1.19 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5731
2022-03-05 15:58:12 | INFO | fairseq.trainer | begin training epoch 50
2022-03-05 15:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 15:58:50 | INFO | train_inner | epoch 050:     17 / 49 loss=6.781, nll_loss=5.563, ppl=47.27, wps=27711.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.148, loss_scale=32, train_wall=199, gb_free=21.6, wall=5769
2022-03-05 16:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:00:06 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.329 | nll_loss 8.341 | ppl 324.34 | wps 46563.6 | wpb 510.9 | bsz 1 | num_updates 2432 | best_loss 8.953
2022-03-05 16:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2432 updates
2022-03-05 16:00:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 50 @ 2432 updates, score 9.329) (writing took 1.6441530622541904 seconds)
2022-03-05 16:00:07 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-05 16:00:07 | INFO | train | epoch 050 | loss 6.683 | nll_loss 5.452 | ppl 43.76 | wps 27654.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2432 | lr 0.000304039 | gnorm 1.138 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5846
2022-03-05 16:00:07 | INFO | fairseq.trainer | begin training epoch 51
2022-03-05 16:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:01:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:02:00 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.338 | nll_loss 8.34 | ppl 324.02 | wps 46579.5 | wpb 510.9 | bsz 1 | num_updates 2481 | best_loss 8.953
2022-03-05 16:02:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2481 updates
2022-03-05 16:02:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:02:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:02:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 51 @ 2481 updates, score 9.338) (writing took 1.6473711915314198 seconds)
2022-03-05 16:02:02 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-05 16:02:02 | INFO | train | epoch 051 | loss 6.605 | nll_loss 5.362 | ppl 41.12 | wps 27687.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2481 | lr 0.000310163 | gnorm 1.2 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 5961
2022-03-05 16:02:02 | INFO | fairseq.trainer | begin training epoch 52
2022-03-05 16:02:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:02:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 16:02:47 | INFO | train_inner | epoch 052:     20 / 49 loss=6.607, nll_loss=5.364, ppl=41.2, wps=27431.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.156, loss_scale=32, train_wall=201, gb_free=21.6, wall=6005
2022-03-05 16:03:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:03:55 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.367 | nll_loss 8.372 | ppl 331.24 | wps 46413.9 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.953
2022-03-05 16:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-05 16:03:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:03:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:03:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 52 @ 2528 updates, score 9.367) (writing took 1.6369863832369447 seconds)
2022-03-05 16:03:57 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-05 16:03:57 | INFO | train | epoch 052 | loss 6.528 | nll_loss 5.274 | ppl 38.69 | wps 26514.9 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 2528 | lr 0.000316037 | gnorm 1.233 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6075
2022-03-05 16:03:57 | INFO | fairseq.trainer | begin training epoch 53
2022-03-05 16:03:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:05:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:05:50 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.441 | nll_loss 8.452 | ppl 350.16 | wps 46450.9 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 8.953
2022-03-05 16:05:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-05 16:05:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:05:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 53 @ 2577 updates, score 9.441) (writing took 1.6186741748824716 seconds)
2022-03-05 16:05:52 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-05 16:05:52 | INFO | train | epoch 053 | loss 6.449 | nll_loss 5.184 | ppl 36.34 | wps 27678.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2577 | lr 0.000322161 | gnorm 1.205 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6190
2022-03-05 16:05:52 | INFO | fairseq.trainer | begin training epoch 54
2022-03-05 16:05:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:06:43 | INFO | train_inner | epoch 054:     23 / 49 loss=6.456, nll_loss=5.192, ppl=36.55, wps=27446.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.238, loss_scale=16, train_wall=201, gb_free=21.6, wall=6242
2022-03-05 16:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:07:45 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.464 | nll_loss 8.467 | ppl 353.88 | wps 46478.7 | wpb 510.9 | bsz 1 | num_updates 2626 | best_loss 8.953
2022-03-05 16:07:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2626 updates
2022-03-05 16:07:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:07:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:07:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 54 @ 2626 updates, score 9.464) (writing took 1.666368487291038 seconds)
2022-03-05 16:07:47 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-05 16:07:47 | INFO | train | epoch 054 | loss 6.369 | nll_loss 5.092 | ppl 34.1 | wps 27672.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2626 | lr 0.000328284 | gnorm 1.191 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6305
2022-03-05 16:07:47 | INFO | fairseq.trainer | begin training epoch 55
2022-03-05 16:07:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:09:39 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.472 | nll_loss 8.465 | ppl 353.36 | wps 46708.6 | wpb 510.9 | bsz 1 | num_updates 2675 | best_loss 8.953
2022-03-05 16:09:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2675 updates
2022-03-05 16:09:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:09:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 55 @ 2675 updates, score 9.472) (writing took 1.6512719113379717 seconds)
2022-03-05 16:09:41 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-05 16:09:41 | INFO | train | epoch 055 | loss 6.291 | nll_loss 5.002 | ppl 32.05 | wps 27732.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2675 | lr 0.000334408 | gnorm 1.238 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6420
2022-03-05 16:09:41 | INFO | fairseq.trainer | begin training epoch 56
2022-03-05 16:09:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:10:37 | INFO | train_inner | epoch 056:     25 / 49 loss=6.292, nll_loss=5.003, ppl=32.07, wps=27726.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.242, loss_scale=32, train_wall=199, gb_free=21.6, wall=6476
2022-03-05 16:11:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:11:34 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.511 | nll_loss 8.504 | ppl 363.05 | wps 46376.4 | wpb 510.9 | bsz 1 | num_updates 2724 | best_loss 8.953
2022-03-05 16:11:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2724 updates
2022-03-05 16:11:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:11:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:11:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 56 @ 2724 updates, score 9.511) (writing took 1.661399234086275 seconds)
2022-03-05 16:11:36 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-05 16:11:36 | INFO | train | epoch 056 | loss 6.217 | nll_loss 4.917 | ppl 30.21 | wps 27656.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2724 | lr 0.000340532 | gnorm 1.292 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 6535
2022-03-05 16:11:36 | INFO | fairseq.trainer | begin training epoch 57
2022-03-05 16:11:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:11:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:13:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:13:29 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.61 | nll_loss 8.613 | ppl 391.47 | wps 46291.1 | wpb 510.9 | bsz 1 | num_updates 2772 | best_loss 8.953
2022-03-05 16:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2772 updates
2022-03-05 16:13:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 57 @ 2772 updates, score 9.61) (writing took 1.6323697958141565 seconds)
2022-03-05 16:13:31 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-05 16:13:31 | INFO | train | epoch 057 | loss 6.136 | nll_loss 4.824 | ppl 28.33 | wps 27085.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2772 | lr 0.000346531 | gnorm 1.292 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6650
2022-03-05 16:13:31 | INFO | fairseq.trainer | begin training epoch 58
2022-03-05 16:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:14:33 | INFO | train_inner | epoch 058:     28 / 49 loss=6.131, nll_loss=4.819, ppl=28.23, wps=27444.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.255, loss_scale=16, train_wall=201, gb_free=21.6, wall=6712
2022-03-05 16:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:15:24 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.63 | nll_loss 8.637 | ppl 397.99 | wps 46378.7 | wpb 510.9 | bsz 1 | num_updates 2821 | best_loss 8.953
2022-03-05 16:15:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2821 updates
2022-03-05 16:15:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 58 @ 2821 updates, score 9.63) (writing took 1.6566404411569238 seconds)
2022-03-05 16:15:26 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-05 16:15:26 | INFO | train | epoch 058 | loss 6.058 | nll_loss 4.735 | ppl 26.62 | wps 27709.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2821 | lr 0.000352654 | gnorm 1.258 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6764
2022-03-05 16:15:26 | INFO | fairseq.trainer | begin training epoch 59
2022-03-05 16:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:17:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:17:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:17:19 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.672 | nll_loss 8.647 | ppl 400.83 | wps 46458 | wpb 510.9 | bsz 1 | num_updates 2869 | best_loss 8.953
2022-03-05 16:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2869 updates
2022-03-05 16:17:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:17:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 59 @ 2869 updates, score 9.672) (writing took 1.671847497113049 seconds)
2022-03-05 16:17:21 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-05 16:17:21 | INFO | train | epoch 059 | loss 5.979 | nll_loss 4.644 | ppl 25 | wps 27096.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 2869 | lr 0.000358653 | gnorm 1.238 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6879
2022-03-05 16:17:21 | INFO | fairseq.trainer | begin training epoch 60
2022-03-05 16:17:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:18:30 | INFO | train_inner | epoch 060:     31 / 49 loss=5.978, nll_loss=4.642, ppl=24.97, wps=27446.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.318, loss_scale=16, train_wall=201, gb_free=21.6, wall=6948
2022-03-05 16:19:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:19:14 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.736 | nll_loss 8.71 | ppl 418.66 | wps 46288.8 | wpb 510.9 | bsz 1 | num_updates 2918 | best_loss 8.953
2022-03-05 16:19:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2918 updates
2022-03-05 16:19:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:19:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:19:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 60 @ 2918 updates, score 9.736) (writing took 1.6710342532023787 seconds)
2022-03-05 16:19:15 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-05 16:19:15 | INFO | train | epoch 060 | loss 5.908 | nll_loss 4.561 | ppl 23.61 | wps 27665.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2918 | lr 0.000364777 | gnorm 1.292 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 6994
2022-03-05 16:19:15 | INFO | fairseq.trainer | begin training epoch 61
2022-03-05 16:19:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:21:09 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.798 | nll_loss 8.825 | ppl 453.38 | wps 46406.1 | wpb 510.9 | bsz 1 | num_updates 2967 | best_loss 8.953
2022-03-05 16:21:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2967 updates
2022-03-05 16:21:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:21:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:21:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 61 @ 2967 updates, score 9.798) (writing took 1.6837585605680943 seconds)
2022-03-05 16:21:10 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-05 16:21:10 | INFO | train | epoch 061 | loss 5.839 | nll_loss 4.482 | ppl 22.34 | wps 27638.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 2967 | lr 0.000370901 | gnorm 1.412 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7109
2022-03-05 16:21:10 | INFO | fairseq.trainer | begin training epoch 62
2022-03-05 16:21:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:22:24 | INFO | train_inner | epoch 062:     33 / 49 loss=5.823, nll_loss=4.464, ppl=22.07, wps=27678.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.338, loss_scale=32, train_wall=199, gb_free=21.6, wall=7183
2022-03-05 16:22:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:23:04 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.765 | nll_loss 8.76 | ppl 433.49 | wps 46569 | wpb 510.9 | bsz 1 | num_updates 3016 | best_loss 8.953
2022-03-05 16:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3016 updates
2022-03-05 16:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:23:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 62 @ 3016 updates, score 9.765) (writing took 1.6268881373107433 seconds)
2022-03-05 16:23:05 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-05 16:23:05 | INFO | train | epoch 062 | loss 5.763 | nll_loss 4.394 | ppl 21.03 | wps 27668.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3016 | lr 0.000377025 | gnorm 1.319 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 7224
2022-03-05 16:23:05 | INFO | fairseq.trainer | begin training epoch 63
2022-03-05 16:23:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:23:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:24:58 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.847 | nll_loss 8.818 | ppl 451.25 | wps 46542.9 | wpb 510.9 | bsz 1 | num_updates 3064 | best_loss 8.953
2022-03-05 16:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3064 updates
2022-03-05 16:24:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:25:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:25:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 63 @ 3064 updates, score 9.847) (writing took 1.652344474568963 seconds)
2022-03-05 16:25:00 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-05 16:25:00 | INFO | train | epoch 063 | loss 5.683 | nll_loss 4.302 | ppl 19.73 | wps 27115.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3064 | lr 0.000383023 | gnorm 1.378 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7339
2022-03-05 16:25:00 | INFO | fairseq.trainer | begin training epoch 64
2022-03-05 16:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:26:21 | INFO | train_inner | epoch 064:     36 / 49 loss=5.668, nll_loss=4.284, ppl=19.48, wps=27443.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.334, loss_scale=16, train_wall=201, gb_free=21.6, wall=7419
2022-03-05 16:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:26:53 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.902 | nll_loss 8.892 | ppl 475.08 | wps 46438.9 | wpb 510.9 | bsz 1 | num_updates 3113 | best_loss 8.953
2022-03-05 16:26:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3113 updates
2022-03-05 16:26:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:26:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:26:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 64 @ 3113 updates, score 9.902) (writing took 1.6881907330825925 seconds)
2022-03-05 16:26:55 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-05 16:26:55 | INFO | train | epoch 064 | loss 5.608 | nll_loss 4.215 | ppl 18.57 | wps 27632.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3113 | lr 0.000389147 | gnorm 1.308 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7454
2022-03-05 16:26:55 | INFO | fairseq.trainer | begin training epoch 65
2022-03-05 16:26:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:28:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:28:48 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 10.014 | nll_loss 9.016 | ppl 517.71 | wps 46296.5 | wpb 510.9 | bsz 1 | num_updates 3161 | best_loss 8.953
2022-03-05 16:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3161 updates
2022-03-05 16:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:28:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 65 @ 3161 updates, score 10.014) (writing took 1.6330227507278323 seconds)
2022-03-05 16:28:50 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-05 16:28:50 | INFO | train | epoch 065 | loss 5.538 | nll_loss 4.133 | ppl 17.55 | wps 27083.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3161 | lr 0.000395146 | gnorm 1.402 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7569
2022-03-05 16:28:50 | INFO | fairseq.trainer | begin training epoch 66
2022-03-05 16:28:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:30:17 | INFO | train_inner | epoch 066:     39 / 49 loss=5.521, nll_loss=4.114, ppl=17.32, wps=27422.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.408, loss_scale=16, train_wall=201, gb_free=21.6, wall=7656
2022-03-05 16:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:30:43 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.023 | nll_loss 9.032 | ppl 523.52 | wps 46340 | wpb 510.9 | bsz 1 | num_updates 3210 | best_loss 8.953
2022-03-05 16:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3210 updates
2022-03-05 16:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:30:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:30:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 66 @ 3210 updates, score 10.023) (writing took 1.6736031956970692 seconds)
2022-03-05 16:30:45 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-05 16:30:45 | INFO | train | epoch 066 | loss 5.468 | nll_loss 4.053 | ppl 16.59 | wps 27662.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3210 | lr 0.00040127 | gnorm 1.428 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7683
2022-03-05 16:30:45 | INFO | fairseq.trainer | begin training epoch 67
2022-03-05 16:30:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:32:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:32:38 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.102 | nll_loss 9.105 | ppl 550.69 | wps 46558.9 | wpb 510.9 | bsz 1 | num_updates 3259 | best_loss 8.953
2022-03-05 16:32:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3259 updates
2022-03-05 16:32:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:32:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:32:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 67 @ 3259 updates, score 10.102) (writing took 1.6329247644171119 seconds)
2022-03-05 16:32:40 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-05 16:32:40 | INFO | train | epoch 067 | loss 5.395 | nll_loss 3.968 | ppl 15.65 | wps 27640.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3259 | lr 0.000407394 | gnorm 1.465 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7798
2022-03-05 16:32:40 | INFO | fairseq.trainer | begin training epoch 68
2022-03-05 16:32:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:34:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:34:14 | INFO | train_inner | epoch 068:     42 / 49 loss=5.368, nll_loss=3.937, ppl=15.32, wps=27427.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.384, loss_scale=16, train_wall=201, gb_free=21.6, wall=7892
2022-03-05 16:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:34:33 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.218 | nll_loss 9.244 | ppl 606.24 | wps 46527.3 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 8.953
2022-03-05 16:34:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-05 16:34:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 68 @ 3307 updates, score 10.218) (writing took 1.65749697573483 seconds)
2022-03-05 16:34:35 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-05 16:34:35 | INFO | train | epoch 068 | loss 5.317 | nll_loss 3.877 | ppl 14.7 | wps 27115.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.319 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 7913
2022-03-05 16:34:35 | INFO | fairseq.trainer | begin training epoch 69
2022-03-05 16:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:36:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:36:28 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.283 | nll_loss 9.298 | ppl 629.67 | wps 46490.6 | wpb 510.9 | bsz 1 | num_updates 3356 | best_loss 8.953
2022-03-05 16:36:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3356 updates
2022-03-05 16:36:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 69 @ 3356 updates, score 10.283) (writing took 1.6471514105796814 seconds)
2022-03-05 16:36:29 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-05 16:36:29 | INFO | train | epoch 069 | loss 5.252 | nll_loss 3.802 | ppl 13.95 | wps 27666.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3356 | lr 0.000419516 | gnorm 1.432 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8028
2022-03-05 16:36:29 | INFO | fairseq.trainer | begin training epoch 70
2022-03-05 16:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:38:08 | INFO | train_inner | epoch 070:     44 / 49 loss=5.23, nll_loss=3.776, ppl=13.7, wps=27691.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.455, loss_scale=16, train_wall=199, gb_free=21.6, wall=8127
2022-03-05 16:38:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:38:23 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.305 | nll_loss 9.299 | ppl 629.86 | wps 46343.6 | wpb 510.9 | bsz 1 | num_updates 3405 | best_loss 8.953
2022-03-05 16:38:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3405 updates
2022-03-05 16:38:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:38:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 70 @ 3405 updates, score 10.305) (writing took 1.6573141384869814 seconds)
2022-03-05 16:38:24 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-05 16:38:24 | INFO | train | epoch 070 | loss 5.188 | nll_loss 3.727 | ppl 13.24 | wps 27657.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3405 | lr 0.00042564 | gnorm 1.448 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8143
2022-03-05 16:38:24 | INFO | fairseq.trainer | begin training epoch 71
2022-03-05 16:38:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:40:18 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.391 | nll_loss 9.392 | ppl 671.73 | wps 46470.5 | wpb 510.9 | bsz 1 | num_updates 3454 | best_loss 8.953
2022-03-05 16:40:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3454 updates
2022-03-05 16:40:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:40:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:40:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 71 @ 3454 updates, score 10.391) (writing took 1.6778942476958036 seconds)
2022-03-05 16:40:19 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-05 16:40:19 | INFO | train | epoch 071 | loss 5.111 | nll_loss 3.637 | ppl 12.44 | wps 27672.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3454 | lr 0.000431764 | gnorm 1.398 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 8258
2022-03-05 16:40:19 | INFO | fairseq.trainer | begin training epoch 72
2022-03-05 16:40:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:40:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:42:04 | INFO | train_inner | epoch 072:     47 / 49 loss=5.082, nll_loss=3.604, ppl=12.16, wps=27439.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.403, loss_scale=16, train_wall=201, gb_free=21.6, wall=8363
2022-03-05 16:42:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:42:12 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.455 | nll_loss 9.481 | ppl 714.61 | wps 46421.8 | wpb 510.9 | bsz 1 | num_updates 3502 | best_loss 8.953
2022-03-05 16:42:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3502 updates
2022-03-05 16:42:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:42:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:42:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 72 @ 3502 updates, score 10.455) (writing took 1.6643989365547895 seconds)
2022-03-05 16:42:14 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-05 16:42:14 | INFO | train | epoch 072 | loss 5.041 | nll_loss 3.556 | ppl 11.76 | wps 27096 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3502 | lr 0.000437762 | gnorm 1.452 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8373
2022-03-05 16:42:14 | INFO | fairseq.trainer | begin training epoch 73
2022-03-05 16:42:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:44:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:44:07 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.523 | nll_loss 9.533 | ppl 740.82 | wps 46396.5 | wpb 510.9 | bsz 1 | num_updates 3551 | best_loss 8.953
2022-03-05 16:44:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3551 updates
2022-03-05 16:44:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 73 @ 3551 updates, score 10.523) (writing took 1.6639303648844361 seconds)
2022-03-05 16:44:09 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-05 16:44:09 | INFO | train | epoch 073 | loss 4.977 | nll_loss 3.481 | ppl 11.17 | wps 27648.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3551 | lr 0.000443886 | gnorm 1.455 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8488
2022-03-05 16:44:09 | INFO | fairseq.trainer | begin training epoch 74
2022-03-05 16:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:45:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:46:02 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.576 | nll_loss 9.575 | ppl 762.5 | wps 46420 | wpb 510.9 | bsz 1 | num_updates 3599 | best_loss 8.953
2022-03-05 16:46:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3599 updates
2022-03-05 16:46:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:46:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:46:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 74 @ 3599 updates, score 10.576) (writing took 1.644434740766883 seconds)
2022-03-05 16:46:04 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-05 16:46:04 | INFO | train | epoch 074 | loss 4.913 | nll_loss 3.406 | ppl 10.6 | wps 27084.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3599 | lr 0.000449885 | gnorm 1.466 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 8603
2022-03-05 16:46:04 | INFO | fairseq.trainer | begin training epoch 75
2022-03-05 16:46:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:46:06 | INFO | train_inner | epoch 075:      1 / 49 loss=4.946, nll_loss=3.445, ppl=10.89, wps=26675.9, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.467, loss_scale=16, train_wall=200, gb_free=21.6, wall=8605
2022-03-05 16:47:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 16:47:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:47:57 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.657 | nll_loss 9.661 | ppl 809.72 | wps 46389.8 | wpb 510.9 | bsz 1 | num_updates 3647 | best_loss 8.953
2022-03-05 16:47:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3647 updates
2022-03-05 16:47:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:47:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 75 @ 3647 updates, score 10.657) (writing took 1.670995763503015 seconds)
2022-03-05 16:47:59 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-05 16:47:59 | INFO | train | epoch 075 | loss 4.865 | nll_loss 3.348 | ppl 10.18 | wps 27102.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3647 | lr 0.000455884 | gnorm 1.617 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 8717
2022-03-05 16:47:59 | INFO | fairseq.trainer | begin training epoch 76
2022-03-05 16:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:49:52 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.743 | nll_loss 9.768 | ppl 871.68 | wps 46488 | wpb 510.9 | bsz 1 | num_updates 3696 | best_loss 8.953
2022-03-05 16:49:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3696 updates
2022-03-05 16:49:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:49:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:49:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 76 @ 3696 updates, score 10.743) (writing took 1.678325803950429 seconds)
2022-03-05 16:49:54 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-05 16:49:54 | INFO | train | epoch 076 | loss 4.78 | nll_loss 3.251 | ppl 9.52 | wps 27655.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3696 | lr 0.000462008 | gnorm 1.33 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 8832
2022-03-05 16:49:54 | INFO | fairseq.trainer | begin training epoch 77
2022-03-05 16:49:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:50:03 | INFO | train_inner | epoch 077:      4 / 49 loss=4.817, nll_loss=3.293, ppl=9.8, wps=27434.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.469, loss_scale=8, train_wall=201, gb_free=21.6, wall=8841
2022-03-05 16:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:51:47 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.843 | nll_loss 9.864 | ppl 932.04 | wps 46510.1 | wpb 510.9 | bsz 1 | num_updates 3745 | best_loss 8.953
2022-03-05 16:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3745 updates
2022-03-05 16:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:51:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:51:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 77 @ 3745 updates, score 10.843) (writing took 1.6482277205213904 seconds)
2022-03-05 16:51:49 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-05 16:51:49 | INFO | train | epoch 077 | loss 4.719 | nll_loss 3.179 | ppl 9.06 | wps 27646 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3745 | lr 0.000468131 | gnorm 1.449 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 8947
2022-03-05 16:51:49 | INFO | fairseq.trainer | begin training epoch 78
2022-03-05 16:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:53:42 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 10.942 | nll_loss 9.982 | ppl 1011.17 | wps 46312.3 | wpb 510.9 | bsz 1 | num_updates 3794 | best_loss 8.953
2022-03-05 16:53:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3794 updates
2022-03-05 16:53:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:53:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 78 @ 3794 updates, score 10.942) (writing took 1.6486046817153692 seconds)
2022-03-05 16:53:44 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-05 16:53:44 | INFO | train | epoch 078 | loss 4.662 | nll_loss 3.111 | ppl 8.64 | wps 27678.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3794 | lr 0.000474255 | gnorm 1.496 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9062
2022-03-05 16:53:44 | INFO | fairseq.trainer | begin training epoch 79
2022-03-05 16:53:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:53:57 | INFO | train_inner | epoch 079:      6 / 49 loss=4.682, nll_loss=3.135, ppl=8.79, wps=27695.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.458, loss_scale=16, train_wall=199, gb_free=21.6, wall=9076
2022-03-05 16:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:55:37 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.022 | nll_loss 10.066 | ppl 1071.67 | wps 46427.6 | wpb 510.9 | bsz 1 | num_updates 3843 | best_loss 8.953
2022-03-05 16:55:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3843 updates
2022-03-05 16:55:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:55:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:55:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 79 @ 3843 updates, score 11.022) (writing took 1.6487339874729514 seconds)
2022-03-05 16:55:38 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-05 16:55:38 | INFO | train | epoch 079 | loss 4.593 | nll_loss 3.032 | ppl 8.18 | wps 27664 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3843 | lr 0.000480379 | gnorm 1.431 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9177
2022-03-05 16:55:38 | INFO | fairseq.trainer | begin training epoch 80
2022-03-05 16:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:57:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:57:32 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.1 | nll_loss 10.136 | ppl 1125.44 | wps 46399.5 | wpb 510.9 | bsz 1 | num_updates 3892 | best_loss 8.953
2022-03-05 16:57:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3892 updates
2022-03-05 16:57:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:57:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:57:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 80 @ 3892 updates, score 11.1) (writing took 1.6566448360681534 seconds)
2022-03-05 16:57:33 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-05 16:57:33 | INFO | train | epoch 080 | loss 4.543 | nll_loss 2.971 | ppl 7.84 | wps 27664.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3892 | lr 0.000486503 | gnorm 1.525 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 9292
2022-03-05 16:57:33 | INFO | fairseq.trainer | begin training epoch 81
2022-03-05 16:57:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 16:57:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 16:57:53 | INFO | train_inner | epoch 081:      9 / 49 loss=4.557, nll_loss=2.989, ppl=7.94, wps=27434.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.478, loss_scale=16, train_wall=201, gb_free=21.6, wall=9312
2022-03-05 16:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 16:59:26 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.212 | nll_loss 10.266 | ppl 1231.09 | wps 46333.2 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 8.953
2022-03-05 16:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-05 16:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 16:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 81 @ 3940 updates, score 11.212) (writing took 1.6709335846826434 seconds)
2022-03-05 16:59:28 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-05 16:59:28 | INFO | train | epoch 081 | loss 4.478 | nll_loss 2.896 | ppl 7.44 | wps 27108 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.443 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9407
2022-03-05 16:59:28 | INFO | fairseq.trainer | begin training epoch 82
2022-03-05 16:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:01:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:01:21 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.233 | nll_loss 10.269 | ppl 1233.72 | wps 46456.2 | wpb 510.9 | bsz 1 | num_updates 3989 | best_loss 8.953
2022-03-05 17:01:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3989 updates
2022-03-05 17:01:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:01:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:01:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 82 @ 3989 updates, score 11.233) (writing took 1.7421106155961752 seconds)
2022-03-05 17:01:23 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-05 17:01:23 | INFO | train | epoch 082 | loss 4.419 | nll_loss 2.827 | ppl 7.09 | wps 27636.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 3989 | lr 0.000498625 | gnorm 1.476 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9522
2022-03-05 17:01:23 | INFO | fairseq.trainer | begin training epoch 83
2022-03-05 17:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:01:48 | INFO | train_inner | epoch 083:     11 / 49 loss=4.434, nll_loss=2.844, ppl=7.18, wps=27691.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.46, loss_scale=16, train_wall=199, gb_free=21.6, wall=9546
2022-03-05 17:02:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 17:03:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:03:16 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.404 | nll_loss 10.454 | ppl 1402.44 | wps 46296.1 | wpb 510.9 | bsz 1 | num_updates 4037 | best_loss 8.953
2022-03-05 17:03:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4037 updates
2022-03-05 17:03:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:03:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:03:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 83 @ 4037 updates, score 11.404) (writing took 1.6599486926570535 seconds)
2022-03-05 17:03:18 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-05 17:03:18 | INFO | train | epoch 083 | loss 4.361 | nll_loss 2.758 | ppl 6.76 | wps 27081.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4037 | lr 0.000497703 | gnorm 1.494 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 9637
2022-03-05 17:03:18 | INFO | fairseq.trainer | begin training epoch 84
2022-03-05 17:03:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:04:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:05:11 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.435 | nll_loss 10.467 | ppl 1415.87 | wps 46331.2 | wpb 510.9 | bsz 1 | num_updates 4085 | best_loss 8.953
2022-03-05 17:05:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4085 updates
2022-03-05 17:05:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:05:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:05:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 84 @ 4085 updates, score 11.435) (writing took 1.6575868194922805 seconds)
2022-03-05 17:05:13 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-05 17:05:13 | INFO | train | epoch 084 | loss 4.297 | nll_loss 2.684 | ppl 6.42 | wps 27126.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4085 | lr 0.000494771 | gnorm 1.423 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9751
2022-03-05 17:05:13 | INFO | fairseq.trainer | begin training epoch 85
2022-03-05 17:05:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:05:46 | INFO | train_inner | epoch 085:     15 / 49 loss=4.314, nll_loss=2.703, ppl=6.51, wps=27184.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.461, loss_scale=8, train_wall=203, gb_free=21.6, wall=9785
2022-03-05 17:07:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:07:06 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.588 | nll_loss 10.675 | ppl 1634.47 | wps 46500.3 | wpb 510.9 | bsz 1 | num_updates 4134 | best_loss 8.953
2022-03-05 17:07:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4134 updates
2022-03-05 17:07:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:07:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:07:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 85 @ 4134 updates, score 11.588) (writing took 1.6750416923314333 seconds)
2022-03-05 17:07:08 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-05 17:07:08 | INFO | train | epoch 085 | loss 4.239 | nll_loss 2.616 | ppl 6.13 | wps 27685.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4134 | lr 0.00049183 | gnorm 1.401 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9866
2022-03-05 17:07:08 | INFO | fairseq.trainer | begin training epoch 86
2022-03-05 17:07:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:08:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:09:01 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.556 | nll_loss 10.609 | ppl 1561.65 | wps 46325.8 | wpb 510.9 | bsz 1 | num_updates 4183 | best_loss 8.953
2022-03-05 17:09:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4183 updates
2022-03-05 17:09:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:09:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:09:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 86 @ 4183 updates, score 11.556) (writing took 1.6596084870398045 seconds)
2022-03-05 17:09:02 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-05 17:09:02 | INFO | train | epoch 086 | loss 4.18 | nll_loss 2.546 | ppl 5.84 | wps 27672.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4183 | lr 0.000488941 | gnorm 1.411 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 9981
2022-03-05 17:09:02 | INFO | fairseq.trainer | begin training epoch 87
2022-03-05 17:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:09:40 | INFO | train_inner | epoch 087:     17 / 49 loss=4.188, nll_loss=2.555, ppl=5.88, wps=27711.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.398, loss_scale=16, train_wall=199, gb_free=21.6, wall=10019
2022-03-05 17:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:10:56 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.734 | nll_loss 10.813 | ppl 1798.8 | wps 46192.8 | wpb 510.9 | bsz 1 | num_updates 4232 | best_loss 8.953
2022-03-05 17:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4232 updates
2022-03-05 17:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:10:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 87 @ 4232 updates, score 11.734) (writing took 1.7003465257585049 seconds)
2022-03-05 17:10:57 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-05 17:10:57 | INFO | train | epoch 087 | loss 4.123 | nll_loss 2.479 | ppl 5.58 | wps 27629.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4232 | lr 0.000486102 | gnorm 1.332 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10096
2022-03-05 17:10:57 | INFO | fairseq.trainer | begin training epoch 88
2022-03-05 17:10:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:11:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:12:50 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.867 | nll_loss 10.923 | ppl 1941.7 | wps 46175.2 | wpb 510.9 | bsz 1 | num_updates 4280 | best_loss 8.953
2022-03-05 17:12:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4280 updates
2022-03-05 17:12:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:12:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 88 @ 4280 updates, score 11.867) (writing took 1.6404319806024432 seconds)
2022-03-05 17:12:52 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-05 17:12:52 | INFO | train | epoch 088 | loss 4.067 | nll_loss 2.414 | ppl 5.33 | wps 27132.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4280 | lr 0.000483368 | gnorm 1.379 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10211
2022-03-05 17:12:52 | INFO | fairseq.trainer | begin training epoch 89
2022-03-05 17:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:13:37 | INFO | train_inner | epoch 089:     20 / 49 loss=4.077, nll_loss=2.426, ppl=5.37, wps=27439.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.378, loss_scale=8, train_wall=201, gb_free=21.6, wall=10255
2022-03-05 17:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:14:45 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 12.042 | nll_loss 11.163 | ppl 2293.22 | wps 46586 | wpb 510.9 | bsz 1 | num_updates 4329 | best_loss 8.953
2022-03-05 17:14:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4329 updates
2022-03-05 17:14:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:14:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 89 @ 4329 updates, score 12.042) (writing took 1.6970622092485428 seconds)
2022-03-05 17:14:47 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-05 17:14:47 | INFO | train | epoch 089 | loss 4.018 | nll_loss 2.357 | ppl 5.12 | wps 27668.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4329 | lr 0.000480625 | gnorm 1.372 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10326
2022-03-05 17:14:47 | INFO | fairseq.trainer | begin training epoch 90
2022-03-05 17:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:16:40 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.999 | nll_loss 11.127 | ppl 2236.26 | wps 46550.7 | wpb 510.9 | bsz 1 | num_updates 4378 | best_loss 8.953
2022-03-05 17:16:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4378 updates
2022-03-05 17:16:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:16:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 90 @ 4378 updates, score 11.999) (writing took 1.6114106243476272 seconds)
2022-03-05 17:16:42 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-05 17:16:42 | INFO | train | epoch 090 | loss 3.964 | nll_loss 2.293 | ppl 4.9 | wps 27685.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4378 | lr 0.000477928 | gnorm 1.342 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10440
2022-03-05 17:16:42 | INFO | fairseq.trainer | begin training epoch 91
2022-03-05 17:16:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:16:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:17:33 | INFO | train_inner | epoch 091:     23 / 49 loss=3.97, nll_loss=2.3, ppl=4.92, wps=27453.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.348, loss_scale=8, train_wall=201, gb_free=21.6, wall=10492
2022-03-05 17:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:18:35 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 12.056 | nll_loss 11.155 | ppl 2280.24 | wps 46424.1 | wpb 510.9 | bsz 1 | num_updates 4426 | best_loss 8.953
2022-03-05 17:18:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4426 updates
2022-03-05 17:18:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:18:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 91 @ 4426 updates, score 12.056) (writing took 1.6340508023276925 seconds)
2022-03-05 17:18:37 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-05 17:18:37 | INFO | train | epoch 091 | loss 3.919 | nll_loss 2.241 | ppl 4.73 | wps 27131.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4426 | lr 0.000475329 | gnorm 1.358 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10555
2022-03-05 17:18:37 | INFO | fairseq.trainer | begin training epoch 92
2022-03-05 17:18:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:20:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:20:30 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 12.145 | nll_loss 11.24 | ppl 2418.71 | wps 46360.4 | wpb 510.9 | bsz 1 | num_updates 4475 | best_loss 8.953
2022-03-05 17:20:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4475 updates
2022-03-05 17:20:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:20:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:20:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 92 @ 4475 updates, score 12.145) (writing took 1.6799824712798 seconds)
2022-03-05 17:20:31 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-05 17:20:31 | INFO | train | epoch 092 | loss 3.867 | nll_loss 2.18 | ppl 4.53 | wps 27660.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4475 | lr 0.000472719 | gnorm 1.297 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10670
2022-03-05 17:20:31 | INFO | fairseq.trainer | begin training epoch 93
2022-03-05 17:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:21:27 | INFO | train_inner | epoch 093:     25 / 49 loss=3.868, nll_loss=2.18, ppl=4.53, wps=27714.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.313, loss_scale=8, train_wall=199, gb_free=21.6, wall=10726
2022-03-05 17:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:22:24 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 12.304 | nll_loss 11.423 | ppl 2745.89 | wps 46549.3 | wpb 510.9 | bsz 1 | num_updates 4524 | best_loss 8.953
2022-03-05 17:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4524 updates
2022-03-05 17:22:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 93 @ 4524 updates, score 12.304) (writing took 1.6837218375876546 seconds)
2022-03-05 17:22:26 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-05 17:22:26 | INFO | train | epoch 093 | loss 3.825 | nll_loss 2.131 | ppl 4.38 | wps 27691.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4524 | lr 0.000470152 | gnorm 1.321 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 10785
2022-03-05 17:22:26 | INFO | fairseq.trainer | begin training epoch 94
2022-03-05 17:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:24:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:24:19 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 12.286 | nll_loss 11.407 | ppl 2715.26 | wps 46411.1 | wpb 510.9 | bsz 1 | num_updates 4572 | best_loss 8.953
2022-03-05 17:24:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4572 updates
2022-03-05 17:24:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 94 @ 4572 updates, score 12.286) (writing took 1.6502812067046762 seconds)
2022-03-05 17:24:21 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-05 17:24:21 | INFO | train | epoch 094 | loss 3.776 | nll_loss 2.073 | ppl 4.21 | wps 27083.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4572 | lr 0.000467678 | gnorm 1.302 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 10900
2022-03-05 17:24:21 | INFO | fairseq.trainer | begin training epoch 95
2022-03-05 17:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:25:24 | INFO | train_inner | epoch 095:     28 / 49 loss=3.776, nll_loss=2.073, ppl=4.21, wps=27429.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.297, loss_scale=8, train_wall=201, gb_free=21.6, wall=10962
2022-03-05 17:26:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:26:14 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.4 | nll_loss 11.522 | ppl 2940.26 | wps 46397.6 | wpb 510.9 | bsz 1 | num_updates 4621 | best_loss 8.953
2022-03-05 17:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4621 updates
2022-03-05 17:26:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:26:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 95 @ 4621 updates, score 12.4) (writing took 1.68737524561584 seconds)
2022-03-05 17:26:16 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-05 17:26:16 | INFO | train | epoch 095 | loss 3.738 | nll_loss 2.028 | ppl 4.08 | wps 27643.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4621 | lr 0.000465192 | gnorm 1.313 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11015
2022-03-05 17:26:16 | INFO | fairseq.trainer | begin training epoch 96
2022-03-05 17:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:28:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:28:09 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.433 | nll_loss 11.573 | ppl 3046.53 | wps 46418.1 | wpb 510.9 | bsz 1 | num_updates 4670 | best_loss 8.953
2022-03-05 17:28:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4670 updates
2022-03-05 17:28:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:28:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 96 @ 4670 updates, score 12.433) (writing took 1.6256168074905872 seconds)
2022-03-05 17:28:11 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-05 17:28:11 | INFO | train | epoch 096 | loss 3.695 | nll_loss 1.977 | ppl 3.94 | wps 27675.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4670 | lr 0.000462745 | gnorm 1.276 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11130
2022-03-05 17:28:11 | INFO | fairseq.trainer | begin training epoch 97
2022-03-05 17:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:29:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:29:20 | INFO | train_inner | epoch 097:     31 / 49 loss=3.691, nll_loss=1.973, ppl=3.93, wps=27435.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.28, loss_scale=8, train_wall=201, gb_free=21.6, wall=11199
2022-03-05 17:29:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:30:04 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.55 | nll_loss 11.679 | ppl 3278.79 | wps 46241.5 | wpb 510.9 | bsz 1 | num_updates 4718 | best_loss 8.953
2022-03-05 17:30:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4718 updates
2022-03-05 17:30:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:30:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:30:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 97 @ 4718 updates, score 12.55) (writing took 1.6694618556648493 seconds)
2022-03-05 17:30:06 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-05 17:30:06 | INFO | train | epoch 097 | loss 3.653 | nll_loss 1.929 | ppl 3.81 | wps 27098 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4718 | lr 0.000460385 | gnorm 1.27 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11244
2022-03-05 17:30:06 | INFO | fairseq.trainer | begin training epoch 98
2022-03-05 17:30:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:31:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:31:59 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.59 | nll_loss 11.741 | ppl 3422.21 | wps 46231.4 | wpb 510.9 | bsz 1 | num_updates 4767 | best_loss 8.953
2022-03-05 17:31:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4767 updates
2022-03-05 17:31:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 98 @ 4767 updates, score 12.59) (writing took 1.6549657778814435 seconds)
2022-03-05 17:32:01 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-05 17:32:01 | INFO | train | epoch 098 | loss 3.617 | nll_loss 1.887 | ppl 3.7 | wps 27640.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4767 | lr 0.000458013 | gnorm 1.265 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11359
2022-03-05 17:32:01 | INFO | fairseq.trainer | begin training epoch 99
2022-03-05 17:32:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:33:14 | INFO | train_inner | epoch 099:     33 / 49 loss=3.615, nll_loss=1.884, ppl=3.69, wps=27690.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.268, loss_scale=8, train_wall=199, gb_free=21.6, wall=11433
2022-03-05 17:33:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:33:54 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.653 | nll_loss 11.808 | ppl 3584.78 | wps 46239.8 | wpb 510.9 | bsz 1 | num_updates 4816 | best_loss 8.953
2022-03-05 17:33:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4816 updates
2022-03-05 17:33:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:33:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 99 @ 4816 updates, score 12.653) (writing took 1.701826000586152 seconds)
2022-03-05 17:33:56 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-05 17:33:56 | INFO | train | epoch 099 | loss 3.577 | nll_loss 1.841 | ppl 3.58 | wps 27653 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4816 | lr 0.000455677 | gnorm 1.245 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11474
2022-03-05 17:33:56 | INFO | fairseq.trainer | begin training epoch 100
2022-03-05 17:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:34:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:35:49 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.586 | nll_loss 11.7 | ppl 3327.18 | wps 46201.4 | wpb 510.9 | bsz 1 | num_updates 4864 | best_loss 8.953
2022-03-05 17:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4864 updates
2022-03-05 17:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:35:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:35:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 100 @ 4864 updates, score 12.586) (writing took 1.6830323319882154 seconds)
2022-03-05 17:35:51 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-05 17:35:51 | INFO | train | epoch 100 | loss 3.539 | nll_loss 1.796 | ppl 3.47 | wps 27070 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 4864 | lr 0.000453423 | gnorm 1.221 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11589
2022-03-05 17:35:51 | INFO | fairseq.trainer | begin training epoch 101
2022-03-05 17:35:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:37:11 | INFO | train_inner | epoch 101:     36 / 49 loss=3.532, nll_loss=1.788, ppl=3.45, wps=27406.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.224, loss_scale=8, train_wall=201, gb_free=21.6, wall=11670
2022-03-05 17:37:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:37:44 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.823 | nll_loss 11.983 | ppl 4049.33 | wps 46212.1 | wpb 510.9 | bsz 1 | num_updates 4913 | best_loss 8.953
2022-03-05 17:37:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4913 updates
2022-03-05 17:37:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:37:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 101 @ 4913 updates, score 12.823) (writing took 1.7053940501064062 seconds)
2022-03-05 17:37:46 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-05 17:37:46 | INFO | train | epoch 101 | loss 3.507 | nll_loss 1.759 | ppl 3.38 | wps 27635.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4913 | lr 0.000451156 | gnorm 1.22 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11704
2022-03-05 17:37:46 | INFO | fairseq.trainer | begin training epoch 102
2022-03-05 17:37:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:39:39 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.827 | nll_loss 11.99 | ppl 4068.27 | wps 46327.1 | wpb 510.9 | bsz 1 | num_updates 4962 | best_loss 8.953
2022-03-05 17:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4962 updates
2022-03-05 17:39:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:39:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:39:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 102 @ 4962 updates, score 12.827) (writing took 1.6588793098926544 seconds)
2022-03-05 17:39:40 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-05 17:39:40 | INFO | train | epoch 102 | loss 3.473 | nll_loss 1.719 | ppl 3.29 | wps 27673.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 4962 | lr 0.000448923 | gnorm 1.222 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 11819
2022-03-05 17:39:40 | INFO | fairseq.trainer | begin training epoch 103
2022-03-05 17:39:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:39:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:41:08 | INFO | train_inner | epoch 103:     39 / 49 loss=3.464, nll_loss=1.708, ppl=3.27, wps=27440.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.2, loss_scale=8, train_wall=201, gb_free=21.6, wall=11906
2022-03-05 17:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:41:34 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.847 | nll_loss 12.011 | ppl 4126.67 | wps 46249.8 | wpb 510.9 | bsz 1 | num_updates 5010 | best_loss 8.953
2022-03-05 17:41:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5010 updates
2022-03-05 17:41:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:41:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:41:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 103 @ 5010 updates, score 12.847) (writing took 1.6309131123125553 seconds)
2022-03-05 17:41:35 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-05 17:41:35 | INFO | train | epoch 103 | loss 3.441 | nll_loss 1.681 | ppl 3.21 | wps 27122 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5010 | lr 0.000446767 | gnorm 1.193 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 11934
2022-03-05 17:41:35 | INFO | fairseq.trainer | begin training epoch 104
2022-03-05 17:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:43:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:43:28 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.888 | nll_loss 12.049 | ppl 4238.94 | wps 46265.8 | wpb 510.9 | bsz 1 | num_updates 5059 | best_loss 8.953
2022-03-05 17:43:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5059 updates
2022-03-05 17:43:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:43:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:43:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 104 @ 5059 updates, score 12.888) (writing took 1.6810559118166566 seconds)
2022-03-05 17:43:30 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-05 17:43:30 | INFO | train | epoch 104 | loss 3.413 | nll_loss 1.649 | ppl 3.14 | wps 27660 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5059 | lr 0.000444598 | gnorm 1.213 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12049
2022-03-05 17:43:30 | INFO | fairseq.trainer | begin training epoch 105
2022-03-05 17:43:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:44:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:45:04 | INFO | train_inner | epoch 105:     42 / 49 loss=3.403, nll_loss=1.638, ppl=3.11, wps=27430.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.208, loss_scale=8, train_wall=201, gb_free=21.6, wall=12143
2022-03-05 17:45:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:45:23 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.98 | nll_loss 12.165 | ppl 4591.67 | wps 46246.2 | wpb 510.9 | bsz 1 | num_updates 5107 | best_loss 8.953
2022-03-05 17:45:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5107 updates
2022-03-05 17:45:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:45:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:45:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 105 @ 5107 updates, score 12.98) (writing took 1.6922496734187007 seconds)
2022-03-05 17:45:25 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-05 17:45:25 | INFO | train | epoch 105 | loss 3.376 | nll_loss 1.607 | ppl 3.05 | wps 27076.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5107 | lr 0.000442504 | gnorm 1.18 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12164
2022-03-05 17:45:25 | INFO | fairseq.trainer | begin training epoch 106
2022-03-05 17:45:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:47:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:47:18 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.95 | nll_loss 12.13 | ppl 4480.7 | wps 46299.7 | wpb 510.9 | bsz 1 | num_updates 5156 | best_loss 8.953
2022-03-05 17:47:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5156 updates
2022-03-05 17:47:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:47:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:47:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 106 @ 5156 updates, score 12.95) (writing took 1.6933044651523232 seconds)
2022-03-05 17:47:20 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-05 17:47:20 | INFO | train | epoch 106 | loss 3.35 | nll_loss 1.576 | ppl 2.98 | wps 27640.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5156 | lr 0.000440396 | gnorm 1.172 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12279
2022-03-05 17:47:20 | INFO | fairseq.trainer | begin training epoch 107
2022-03-05 17:47:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:48:58 | INFO | train_inner | epoch 107:     44 / 49 loss=3.342, nll_loss=1.568, ppl=2.96, wps=27676, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.178, loss_scale=8, train_wall=199, gb_free=21.6, wall=12377
2022-03-05 17:49:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:49:13 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.888 | nll_loss 12.049 | ppl 4237.02 | wps 46311 | wpb 510.9 | bsz 1 | num_updates 5205 | best_loss 8.953
2022-03-05 17:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5205 updates
2022-03-05 17:49:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:49:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 107 @ 5205 updates, score 12.888) (writing took 1.7400875678285956 seconds)
2022-03-05 17:49:15 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-05 17:49:15 | INFO | train | epoch 107 | loss 3.324 | nll_loss 1.546 | ppl 2.92 | wps 27640 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5205 | lr 0.000438318 | gnorm 1.17 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12394
2022-03-05 17:49:15 | INFO | fairseq.trainer | begin training epoch 108
2022-03-05 17:49:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:50:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:51:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:51:08 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 13.009 | nll_loss 12.187 | ppl 4663.75 | wps 46394.5 | wpb 510.9 | bsz 1 | num_updates 5253 | best_loss 8.953
2022-03-05 17:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5253 updates
2022-03-05 17:51:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:51:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:51:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 108 @ 5253 updates, score 13.009) (writing took 1.6316607613116503 seconds)
2022-03-05 17:51:10 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-05 17:51:10 | INFO | train | epoch 108 | loss 3.293 | nll_loss 1.51 | ppl 2.85 | wps 27087.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5253 | lr 0.000436311 | gnorm 1.134 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12509
2022-03-05 17:51:10 | INFO | fairseq.trainer | begin training epoch 109
2022-03-05 17:51:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:52:55 | INFO | train_inner | epoch 109:     47 / 49 loss=3.285, nll_loss=1.502, ppl=2.83, wps=27421.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.145, loss_scale=8, train_wall=201, gb_free=21.6, wall=12614
2022-03-05 17:52:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:53:03 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 13.044 | nll_loss 12.227 | ppl 4794.8 | wps 46412.4 | wpb 510.9 | bsz 1 | num_updates 5302 | best_loss 8.953
2022-03-05 17:53:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5302 updates
2022-03-05 17:53:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 109 @ 5302 updates, score 13.044) (writing took 1.6494476115331054 seconds)
2022-03-05 17:53:05 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-05 17:53:05 | INFO | train | epoch 109 | loss 3.272 | nll_loss 1.486 | ppl 2.8 | wps 27669.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5302 | lr 0.00043429 | gnorm 1.159 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12623
2022-03-05 17:53:05 | INFO | fairseq.trainer | begin training epoch 110
2022-03-05 17:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:54:58 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 13.053 | nll_loss 12.225 | ppl 4787.47 | wps 46423 | wpb 510.9 | bsz 1 | num_updates 5351 | best_loss 8.953
2022-03-05 17:54:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5351 updates
2022-03-05 17:54:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:55:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:55:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 110 @ 5351 updates, score 13.053) (writing took 1.64284713473171 seconds)
2022-03-05 17:55:00 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-05 17:55:00 | INFO | train | epoch 110 | loss 3.244 | nll_loss 1.454 | ppl 2.74 | wps 27662.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5351 | lr 0.000432297 | gnorm 1.138 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12738
2022-03-05 17:55:00 | INFO | fairseq.trainer | begin training epoch 111
2022-03-05 17:55:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:56:48 | INFO | train_inner | epoch 111:     49 / 49 loss=3.233, nll_loss=1.441, ppl=2.72, wps=27671, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=5400, lr=0.000430331, gnorm=1.124, loss_scale=16, train_wall=198, gb_free=21.6, wall=12847
2022-03-05 17:56:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:56:53 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 13.133 | nll_loss 12.327 | ppl 5136.61 | wps 46304.5 | wpb 510.9 | bsz 1 | num_updates 5400 | best_loss 8.953
2022-03-05 17:56:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5400 updates
2022-03-05 17:56:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:56:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 111 @ 5400 updates, score 13.133) (writing took 1.6923614237457514 seconds)
2022-03-05 17:56:55 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-05 17:56:55 | INFO | train | epoch 111 | loss 3.219 | nll_loss 1.425 | ppl 2.69 | wps 27622.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5400 | lr 0.000430331 | gnorm 1.109 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 12853
2022-03-05 17:56:55 | INFO | fairseq.trainer | begin training epoch 112
2022-03-05 17:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 17:57:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 17:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 17:58:48 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 13.112 | nll_loss 12.291 | ppl 5012.38 | wps 46274.6 | wpb 510.9 | bsz 1 | num_updates 5448 | best_loss 8.953
2022-03-05 17:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5448 updates
2022-03-05 17:58:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:58:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 17:58:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 112 @ 5448 updates, score 13.112) (writing took 2.6496763229370117 seconds)
2022-03-05 17:58:51 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-05 17:58:51 | INFO | train | epoch 112 | loss 3.194 | nll_loss 1.397 | ppl 2.63 | wps 26866.2 | ups 0.41 | wpb 64844.1 | bsz 126.7 | num_updates 5448 | lr 0.000428432 | gnorm 1.103 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 12969
2022-03-05 17:58:51 | INFO | fairseq.trainer | begin training epoch 113
2022-03-05 17:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:00:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:00:44 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 13.156 | nll_loss 12.343 | ppl 5196.35 | wps 46488.9 | wpb 510.9 | bsz 1 | num_updates 5497 | best_loss 8.953
2022-03-05 18:00:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5497 updates
2022-03-05 18:00:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:00:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:00:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 113 @ 5497 updates, score 13.156) (writing took 1.627777093090117 seconds)
2022-03-05 18:00:45 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-05 18:00:45 | INFO | train | epoch 113 | loss 3.175 | nll_loss 1.376 | ppl 2.6 | wps 27672.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5497 | lr 0.000426518 | gnorm 1.095 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13084
2022-03-05 18:00:45 | INFO | fairseq.trainer | begin training epoch 114
2022-03-05 18:00:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:00:52 | INFO | train_inner | epoch 114:      3 / 49 loss=3.182, nll_loss=1.383, ppl=2.61, wps=26595.1, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=5500, lr=0.000426401, gnorm=1.1, loss_scale=8, train_wall=201, gb_free=21.6, wall=13091
2022-03-05 18:02:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:02:39 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 13.071 | nll_loss 12.252 | ppl 4877.57 | wps 46138.5 | wpb 510.9 | bsz 1 | num_updates 5546 | best_loss 8.953
2022-03-05 18:02:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5546 updates
2022-03-05 18:02:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:02:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:02:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 114 @ 5546 updates, score 13.071) (writing took 1.6558601027354598 seconds)
2022-03-05 18:02:40 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-05 18:02:40 | INFO | train | epoch 114 | loss 3.151 | nll_loss 1.348 | ppl 2.55 | wps 27655.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5546 | lr 0.000424629 | gnorm 1.077 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13199
2022-03-05 18:02:40 | INFO | fairseq.trainer | begin training epoch 115
2022-03-05 18:02:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:03:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:04:34 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 13.251 | nll_loss 12.454 | ppl 5609.02 | wps 46191.5 | wpb 510.9 | bsz 1 | num_updates 5594 | best_loss 8.953
2022-03-05 18:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5594 updates
2022-03-05 18:04:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:04:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:04:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 115 @ 5594 updates, score 13.251) (writing took 1.6443174416199327 seconds)
2022-03-05 18:04:35 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-05 18:04:35 | INFO | train | epoch 115 | loss 3.13 | nll_loss 1.324 | ppl 2.5 | wps 27097 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5594 | lr 0.000422804 | gnorm 1.102 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13314
2022-03-05 18:04:35 | INFO | fairseq.trainer | begin training epoch 116
2022-03-05 18:04:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:04:49 | INFO | train_inner | epoch 116:      6 / 49 loss=3.138, nll_loss=1.333, ppl=2.52, wps=27431.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.086, loss_scale=8, train_wall=201, gb_free=21.6, wall=13327
2022-03-05 18:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:06:28 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 13.178 | nll_loss 12.37 | ppl 5294.22 | wps 46304.3 | wpb 510.9 | bsz 1 | num_updates 5643 | best_loss 8.953
2022-03-05 18:06:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5643 updates
2022-03-05 18:06:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:06:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:06:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 116 @ 5643 updates, score 13.178) (writing took 1.6561348298564553 seconds)
2022-03-05 18:06:30 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-05 18:06:30 | INFO | train | epoch 116 | loss 3.11 | nll_loss 1.302 | ppl 2.47 | wps 27678.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5643 | lr 0.000420964 | gnorm 1.076 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13429
2022-03-05 18:06:30 | INFO | fairseq.trainer | begin training epoch 117
2022-03-05 18:06:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:08:23 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 13.106 | nll_loss 12.287 | ppl 4998.91 | wps 46384.3 | wpb 510.9 | bsz 1 | num_updates 5692 | best_loss 8.953
2022-03-05 18:08:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5692 updates
2022-03-05 18:08:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:08:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:08:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 117 @ 5692 updates, score 13.106) (writing took 1.6698230868205428 seconds)
2022-03-05 18:08:25 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-05 18:08:25 | INFO | train | epoch 117 | loss 3.09 | nll_loss 1.279 | ppl 2.43 | wps 27660.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5692 | lr 0.000419148 | gnorm 1.058 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13544
2022-03-05 18:08:25 | INFO | fairseq.trainer | begin training epoch 118
2022-03-05 18:08:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:08:43 | INFO | train_inner | epoch 118:      8 / 49 loss=3.097, nll_loss=1.287, ppl=2.44, wps=27701.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.068, loss_scale=16, train_wall=199, gb_free=21.6, wall=13562
2022-03-05 18:10:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:10:18 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.278 | nll_loss 12.482 | ppl 5722.29 | wps 46495.5 | wpb 510.9 | bsz 1 | num_updates 5741 | best_loss 8.953
2022-03-05 18:10:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5741 updates
2022-03-05 18:10:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:10:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:10:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 118 @ 5741 updates, score 13.278) (writing took 1.6297578867524862 seconds)
2022-03-05 18:10:20 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-05 18:10:20 | INFO | train | epoch 118 | loss 3.071 | nll_loss 1.258 | ppl 2.39 | wps 27653.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5741 | lr 0.000417356 | gnorm 1.066 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 13658
2022-03-05 18:10:20 | INFO | fairseq.trainer | begin training epoch 119
2022-03-05 18:10:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:10:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:12:13 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 13.289 | nll_loss 12.486 | ppl 5737.64 | wps 46462.6 | wpb 510.9 | bsz 1 | num_updates 5789 | best_loss 8.953
2022-03-05 18:12:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5789 updates
2022-03-05 18:12:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:12:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:12:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 119 @ 5789 updates, score 13.289) (writing took 1.6807130705565214 seconds)
2022-03-05 18:12:15 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-05 18:12:15 | INFO | train | epoch 119 | loss 3.046 | nll_loss 1.23 | ppl 2.35 | wps 27089.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5789 | lr 0.000415622 | gnorm 1.016 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13773
2022-03-05 18:12:15 | INFO | fairseq.trainer | begin training epoch 120
2022-03-05 18:12:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:12:39 | INFO | train_inner | epoch 120:     11 / 49 loss=3.053, nll_loss=1.238, ppl=2.36, wps=27421.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.039, loss_scale=8, train_wall=201, gb_free=21.6, wall=13798
2022-03-05 18:14:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:14:08 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 13.287 | nll_loss 12.498 | ppl 5785.6 | wps 46252.7 | wpb 510.9 | bsz 1 | num_updates 5838 | best_loss 8.953
2022-03-05 18:14:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5838 updates
2022-03-05 18:14:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 120 @ 5838 updates, score 13.287) (writing took 1.639843923971057 seconds)
2022-03-05 18:14:10 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-05 18:14:10 | INFO | train | epoch 120 | loss 3.036 | nll_loss 1.218 | ppl 2.33 | wps 27665.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5838 | lr 0.000413874 | gnorm 1.081 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 13888
2022-03-05 18:14:10 | INFO | fairseq.trainer | begin training epoch 121
2022-03-05 18:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:15:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:16:03 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 13.302 | nll_loss 12.519 | ppl 5871.14 | wps 46236.7 | wpb 510.9 | bsz 1 | num_updates 5887 | best_loss 8.953
2022-03-05 18:16:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5887 updates
2022-03-05 18:16:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:16:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:16:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 121 @ 5887 updates, score 13.302) (writing took 1.714944184757769 seconds)
2022-03-05 18:16:05 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-05 18:16:05 | INFO | train | epoch 121 | loss 3.015 | nll_loss 1.195 | ppl 2.29 | wps 27637.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5887 | lr 0.000412148 | gnorm 1.018 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14003
2022-03-05 18:16:05 | INFO | fairseq.trainer | begin training epoch 122
2022-03-05 18:16:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:16:34 | INFO | train_inner | epoch 122:     13 / 49 loss=3.02, nll_loss=1.201, ppl=2.3, wps=27693.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=1.041, loss_scale=16, train_wall=199, gb_free=21.6, wall=14032
2022-03-05 18:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:17:58 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 13.325 | nll_loss 12.546 | ppl 5979.72 | wps 46302.8 | wpb 510.9 | bsz 1 | num_updates 5936 | best_loss 8.953
2022-03-05 18:17:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5936 updates
2022-03-05 18:17:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:18:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 122 @ 5936 updates, score 13.325) (writing took 1.6543153803795576 seconds)
2022-03-05 18:18:00 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-05 18:18:00 | INFO | train | epoch 122 | loss 2.997 | nll_loss 1.175 | ppl 2.26 | wps 27654 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 5936 | lr 0.000410443 | gnorm 1.012 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 14118
2022-03-05 18:18:00 | INFO | fairseq.trainer | begin training epoch 123
2022-03-05 18:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:18:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:19:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:19:53 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 13.478 | nll_loss 12.714 | ppl 6718.27 | wps 46483.8 | wpb 510.9 | bsz 1 | num_updates 5984 | best_loss 8.953
2022-03-05 18:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5984 updates
2022-03-05 18:19:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:19:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:19:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 123 @ 5984 updates, score 13.478) (writing took 1.6740969493985176 seconds)
2022-03-05 18:19:54 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-05 18:19:54 | INFO | train | epoch 123 | loss 2.982 | nll_loss 1.158 | ppl 2.23 | wps 27099.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 5984 | lr 0.000408794 | gnorm 1.017 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14233
2022-03-05 18:19:54 | INFO | fairseq.trainer | begin training epoch 124
2022-03-05 18:19:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:20:30 | INFO | train_inner | epoch 124:     16 / 49 loss=2.986, nll_loss=1.162, ppl=2.24, wps=27428.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=1.017, loss_scale=8, train_wall=201, gb_free=21.6, wall=14269
2022-03-05 18:21:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:21:48 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.348 | nll_loss 12.559 | ppl 6032.58 | wps 46095 | wpb 510.9 | bsz 1 | num_updates 6033 | best_loss 8.953
2022-03-05 18:21:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6033 updates
2022-03-05 18:21:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:21:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:21:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 124 @ 6033 updates, score 13.348) (writing took 1.6412524105980992 seconds)
2022-03-05 18:21:49 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-05 18:21:49 | INFO | train | epoch 124 | loss 2.966 | nll_loss 1.141 | ppl 2.2 | wps 27647.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6033 | lr 0.00040713 | gnorm 0.997 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14348
2022-03-05 18:21:49 | INFO | fairseq.trainer | begin training epoch 125
2022-03-05 18:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:23:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:23:43 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.432 | nll_loss 12.661 | ppl 6476.72 | wps 46343.4 | wpb 510.9 | bsz 1 | num_updates 6082 | best_loss 8.953
2022-03-05 18:23:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6082 updates
2022-03-05 18:23:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:23:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:23:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 125 @ 6082 updates, score 13.432) (writing took 1.6643226547166705 seconds)
2022-03-05 18:23:44 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-05 18:23:44 | INFO | train | epoch 125 | loss 2.951 | nll_loss 1.125 | ppl 2.18 | wps 27677.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6082 | lr 0.000405487 | gnorm 1.001 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14463
2022-03-05 18:23:44 | INFO | fairseq.trainer | begin training epoch 126
2022-03-05 18:23:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:24:25 | INFO | train_inner | epoch 126:     18 / 49 loss=2.953, nll_loss=1.126, ppl=2.18, wps=27673.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=1.002, loss_scale=16, train_wall=199, gb_free=21.6, wall=14503
2022-03-05 18:25:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:25:38 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.383 | nll_loss 12.613 | ppl 6263.67 | wps 46252.2 | wpb 510.9 | bsz 1 | num_updates 6131 | best_loss 8.953
2022-03-05 18:25:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6131 updates
2022-03-05 18:25:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:25:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:25:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 126 @ 6131 updates, score 13.383) (writing took 1.6422337237745523 seconds)
2022-03-05 18:25:39 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-05 18:25:39 | INFO | train | epoch 126 | loss 2.936 | nll_loss 1.108 | ppl 2.16 | wps 27609.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6131 | lr 0.000403863 | gnorm 0.993 | loss_scale 16 | train_wall 98 | gb_free 21.6 | wall 14578
2022-03-05 18:25:39 | INFO | fairseq.trainer | begin training epoch 127
2022-03-05 18:25:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:27:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:27:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:27:33 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.378 | nll_loss 12.599 | ppl 6202.85 | wps 46478.6 | wpb 510.9 | bsz 1 | num_updates 6179 | best_loss 8.953
2022-03-05 18:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6179 updates
2022-03-05 18:27:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:27:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:27:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 127 @ 6179 updates, score 13.378) (writing took 1.7098519410938025 seconds)
2022-03-05 18:27:34 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-05 18:27:34 | INFO | train | epoch 127 | loss 2.923 | nll_loss 1.094 | ppl 2.13 | wps 27070.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6179 | lr 0.000402292 | gnorm 1.005 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14693
2022-03-05 18:27:34 | INFO | fairseq.trainer | begin training epoch 128
2022-03-05 18:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:28:21 | INFO | train_inner | epoch 128:     21 / 49 loss=2.923, nll_loss=1.094, ppl=2.13, wps=27411.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.986, loss_scale=8, train_wall=201, gb_free=21.6, wall=14740
2022-03-05 18:29:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:29:28 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.395 | nll_loss 12.616 | ppl 6277.63 | wps 46447.6 | wpb 510.9 | bsz 1 | num_updates 6228 | best_loss 8.953
2022-03-05 18:29:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6228 updates
2022-03-05 18:29:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:29:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:29:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 128 @ 6228 updates, score 13.395) (writing took 1.6726618111133575 seconds)
2022-03-05 18:29:29 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-05 18:29:29 | INFO | train | epoch 128 | loss 2.909 | nll_loss 1.078 | ppl 2.11 | wps 27637 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6228 | lr 0.000400706 | gnorm 0.986 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14808
2022-03-05 18:29:29 | INFO | fairseq.trainer | begin training epoch 129
2022-03-05 18:29:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:31:23 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.501 | nll_loss 12.753 | ppl 6902.89 | wps 46334.2 | wpb 510.9 | bsz 1 | num_updates 6277 | best_loss 8.953
2022-03-05 18:31:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6277 updates
2022-03-05 18:31:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:31:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:31:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 129 @ 6277 updates, score 13.501) (writing took 1.6461146138608456 seconds)
2022-03-05 18:31:24 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-05 18:31:24 | INFO | train | epoch 129 | loss 2.895 | nll_loss 1.063 | ppl 2.09 | wps 27644 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6277 | lr 0.000399139 | gnorm 0.979 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 14923
2022-03-05 18:31:24 | INFO | fairseq.trainer | begin training epoch 130
2022-03-05 18:31:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:32:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:32:18 | INFO | train_inner | epoch 130:     24 / 49 loss=2.896, nll_loss=1.064, ppl=2.09, wps=27410.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.979, loss_scale=8, train_wall=201, gb_free=21.6, wall=14977
2022-03-05 18:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:33:18 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.319 | nll_loss 12.544 | ppl 5971.18 | wps 46271 | wpb 510.9 | bsz 1 | num_updates 6325 | best_loss 8.953
2022-03-05 18:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6325 updates
2022-03-05 18:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:33:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:33:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 130 @ 6325 updates, score 13.319) (writing took 1.6504972819238901 seconds)
2022-03-05 18:33:19 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-05 18:33:19 | INFO | train | epoch 130 | loss 2.879 | nll_loss 1.046 | ppl 2.06 | wps 27080.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6325 | lr 0.000397621 | gnorm 0.964 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15038
2022-03-05 18:33:19 | INFO | fairseq.trainer | begin training epoch 131
2022-03-05 18:33:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:35:13 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.441 | nll_loss 12.685 | ppl 6583.14 | wps 46414 | wpb 510.9 | bsz 1 | num_updates 6374 | best_loss 8.953
2022-03-05 18:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6374 updates
2022-03-05 18:35:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 131 @ 6374 updates, score 13.441) (writing took 1.6369830230250955 seconds)
2022-03-05 18:35:14 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-05 18:35:14 | INFO | train | epoch 131 | loss 2.866 | nll_loss 1.033 | ppl 2.05 | wps 27633.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6374 | lr 0.00039609 | gnorm 0.934 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15153
2022-03-05 18:35:14 | INFO | fairseq.trainer | begin training epoch 132
2022-03-05 18:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:36:12 | INFO | train_inner | epoch 132:     26 / 49 loss=2.866, nll_loss=1.032, ppl=2.05, wps=27672.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.945, loss_scale=8, train_wall=199, gb_free=21.6, wall=15211
2022-03-05 18:37:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:37:07 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.468 | nll_loss 12.705 | ppl 6679.02 | wps 46227.6 | wpb 510.9 | bsz 1 | num_updates 6423 | best_loss 8.953
2022-03-05 18:37:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6423 updates
2022-03-05 18:37:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:37:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:37:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 132 @ 6423 updates, score 13.468) (writing took 1.6663570366799831 seconds)
2022-03-05 18:37:09 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-05 18:37:09 | INFO | train | epoch 132 | loss 2.856 | nll_loss 1.022 | ppl 2.03 | wps 27634.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6423 | lr 0.000394576 | gnorm 0.947 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15268
2022-03-05 18:37:09 | INFO | fairseq.trainer | begin training epoch 133
2022-03-05 18:37:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:37:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:39:02 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.387 | nll_loss 12.61 | ppl 6252.59 | wps 46488.7 | wpb 510.9 | bsz 1 | num_updates 6471 | best_loss 8.953
2022-03-05 18:39:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6471 updates
2022-03-05 18:39:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:39:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:39:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 133 @ 6471 updates, score 13.387) (writing took 1.7268393971025944 seconds)
2022-03-05 18:39:04 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-05 18:39:04 | INFO | train | epoch 133 | loss 2.843 | nll_loss 1.008 | ppl 2.01 | wps 27076.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6471 | lr 0.00039311 | gnorm 0.948 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15383
2022-03-05 18:39:04 | INFO | fairseq.trainer | begin training epoch 134
2022-03-05 18:39:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:40:09 | INFO | train_inner | epoch 134:     29 / 49 loss=2.844, nll_loss=1.009, ppl=2.01, wps=27418.1, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.949, loss_scale=8, train_wall=201, gb_free=21.6, wall=15448
2022-03-05 18:40:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:40:57 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.472 | nll_loss 12.716 | ppl 6727.58 | wps 46426.1 | wpb 510.9 | bsz 1 | num_updates 6520 | best_loss 8.953
2022-03-05 18:40:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6520 updates
2022-03-05 18:40:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:40:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:40:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 134 @ 6520 updates, score 13.472) (writing took 1.6591212693601847 seconds)
2022-03-05 18:40:59 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-05 18:40:59 | INFO | train | epoch 134 | loss 2.833 | nll_loss 0.996 | ppl 2 | wps 27642.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6520 | lr 0.00039163 | gnorm 0.942 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15498
2022-03-05 18:40:59 | INFO | fairseq.trainer | begin training epoch 135
2022-03-05 18:40:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:42:52 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.422 | nll_loss 12.654 | ppl 6444.27 | wps 46310.7 | wpb 510.9 | bsz 1 | num_updates 6569 | best_loss 8.953
2022-03-05 18:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6569 updates
2022-03-05 18:42:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:42:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:42:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 135 @ 6569 updates, score 13.422) (writing took 1.636059483513236 seconds)
2022-03-05 18:42:54 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-05 18:42:54 | INFO | train | epoch 135 | loss 2.82 | nll_loss 0.983 | ppl 1.98 | wps 27667.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6569 | lr 0.000390167 | gnorm 0.911 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15613
2022-03-05 18:42:54 | INFO | fairseq.trainer | begin training epoch 136
2022-03-05 18:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:43:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:44:06 | INFO | train_inner | epoch 136:     32 / 49 loss=2.82, nll_loss=0.984, ppl=1.98, wps=27423.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.923, loss_scale=8, train_wall=201, gb_free=21.6, wall=15684
2022-03-05 18:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:44:47 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.517 | nll_loss 12.773 | ppl 7001.71 | wps 46514.2 | wpb 510.9 | bsz 1 | num_updates 6617 | best_loss 8.953
2022-03-05 18:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6617 updates
2022-03-05 18:44:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:44:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:44:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 136 @ 6617 updates, score 13.517) (writing took 1.6419699247926474 seconds)
2022-03-05 18:44:49 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-05 18:44:49 | INFO | train | epoch 136 | loss 2.809 | nll_loss 0.972 | ppl 1.96 | wps 27090.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6617 | lr 0.000388749 | gnorm 0.924 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15727
2022-03-05 18:44:49 | INFO | fairseq.trainer | begin training epoch 137
2022-03-05 18:44:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:46:42 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.45 | nll_loss 12.701 | ppl 6658.8 | wps 46582.8 | wpb 510.9 | bsz 1 | num_updates 6666 | best_loss 8.953
2022-03-05 18:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6666 updates
2022-03-05 18:46:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:46:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:46:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 137 @ 6666 updates, score 13.45) (writing took 1.63426923006773 seconds)
2022-03-05 18:46:44 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-05 18:46:44 | INFO | train | epoch 137 | loss 2.799 | nll_loss 0.961 | ppl 1.95 | wps 27650 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6666 | lr 0.000387318 | gnorm 0.931 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 15842
2022-03-05 18:46:44 | INFO | fairseq.trainer | begin training epoch 138
2022-03-05 18:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:48:00 | INFO | train_inner | epoch 138:     34 / 49 loss=2.797, nll_loss=0.959, ppl=1.94, wps=27700.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.916, loss_scale=8, train_wall=199, gb_free=21.6, wall=15918
2022-03-05 18:48:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:48:37 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.476 | nll_loss 12.723 | ppl 6762.89 | wps 46455.4 | wpb 510.9 | bsz 1 | num_updates 6715 | best_loss 8.953
2022-03-05 18:48:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6715 updates
2022-03-05 18:48:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:48:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:48:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 138 @ 6715 updates, score 13.476) (writing took 1.6441374635323882 seconds)
2022-03-05 18:48:39 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-05 18:48:39 | INFO | train | epoch 138 | loss 2.787 | nll_loss 0.949 | ppl 1.93 | wps 27675.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6715 | lr 0.000385902 | gnorm 0.911 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 15957
2022-03-05 18:48:39 | INFO | fairseq.trainer | begin training epoch 139
2022-03-05 18:48:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:50:32 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.551 | nll_loss 12.817 | ppl 7216.02 | wps 46500.4 | wpb 510.9 | bsz 1 | num_updates 6764 | best_loss 8.953
2022-03-05 18:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6764 updates
2022-03-05 18:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 139 @ 6764 updates, score 13.551) (writing took 1.6594431633129716 seconds)
2022-03-05 18:50:33 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-05 18:50:33 | INFO | train | epoch 139 | loss 2.777 | nll_loss 0.938 | ppl 1.92 | wps 27680.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6764 | lr 0.000384502 | gnorm 0.917 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16072
2022-03-05 18:50:33 | INFO | fairseq.trainer | begin training epoch 140
2022-03-05 18:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:51:54 | INFO | train_inner | epoch 140:     36 / 49 loss=2.775, nll_loss=0.936, ppl=1.91, wps=27697, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.915, loss_scale=16, train_wall=199, gb_free=21.6, wall=16153
2022-03-05 18:52:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:52:27 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.419 | nll_loss 12.665 | ppl 6496.72 | wps 46289.7 | wpb 510.9 | bsz 1 | num_updates 6813 | best_loss 8.953
2022-03-05 18:52:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6813 updates
2022-03-05 18:52:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 140 @ 6813 updates, score 13.419) (writing took 1.6475161472335458 seconds)
2022-03-05 18:52:28 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-05 18:52:28 | INFO | train | epoch 140 | loss 2.768 | nll_loss 0.928 | ppl 1.9 | wps 27652 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6813 | lr 0.000383116 | gnorm 0.908 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16187
2022-03-05 18:52:28 | INFO | fairseq.trainer | begin training epoch 141
2022-03-05 18:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:52:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 18:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:54:22 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.637 | nll_loss 12.907 | ppl 7681.39 | wps 46071.7 | wpb 510.9 | bsz 1 | num_updates 6861 | best_loss 8.953
2022-03-05 18:54:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6861 updates
2022-03-05 18:54:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:54:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:54:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 141 @ 6861 updates, score 13.637) (writing took 1.711447280831635 seconds)
2022-03-05 18:54:23 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-05 18:54:23 | INFO | train | epoch 141 | loss 2.754 | nll_loss 0.915 | ppl 1.89 | wps 27063.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 6861 | lr 0.000381774 | gnorm 0.881 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16302
2022-03-05 18:54:23 | INFO | fairseq.trainer | begin training epoch 142
2022-03-05 18:54:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:55:51 | INFO | train_inner | epoch 142:     39 / 49 loss=2.753, nll_loss=0.914, ppl=1.88, wps=27398.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.89, loss_scale=8, train_wall=201, gb_free=21.6, wall=16389
2022-03-05 18:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:56:17 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.463 | nll_loss 12.71 | ppl 6701.85 | wps 46396.5 | wpb 510.9 | bsz 1 | num_updates 6910 | best_loss 8.953
2022-03-05 18:56:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6910 updates
2022-03-05 18:56:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:56:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:56:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 142 @ 6910 updates, score 13.463) (writing took 1.705073269084096 seconds)
2022-03-05 18:56:18 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-05 18:56:18 | INFO | train | epoch 142 | loss 2.746 | nll_loss 0.906 | ppl 1.87 | wps 27624.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 6910 | lr 0.000380418 | gnorm 0.877 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16417
2022-03-05 18:56:18 | INFO | fairseq.trainer | begin training epoch 143
2022-03-05 18:56:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 18:58:12 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.557 | nll_loss 12.834 | ppl 7301.37 | wps 46376.5 | wpb 510.9 | bsz 1 | num_updates 6959 | best_loss 8.953
2022-03-05 18:58:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6959 updates
2022-03-05 18:58:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:58:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 18:58:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 143 @ 6959 updates, score 13.557) (writing took 3.0098567754030228 seconds)
2022-03-05 18:58:15 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-05 18:58:15 | INFO | train | epoch 143 | loss 2.74 | nll_loss 0.9 | ppl 1.87 | wps 27337.3 | ups 0.42 | wpb 64858.2 | bsz 126.7 | num_updates 6959 | lr 0.000379076 | gnorm 0.887 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16533
2022-03-05 18:58:15 | INFO | fairseq.trainer | begin training epoch 144
2022-03-05 18:58:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 18:59:46 | INFO | train_inner | epoch 144:     41 / 49 loss=2.736, nll_loss=0.896, ppl=1.86, wps=27523.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.868, loss_scale=16, train_wall=199, gb_free=21.6, wall=16625
2022-03-05 19:00:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:00:08 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.651 | nll_loss 12.936 | ppl 7836.37 | wps 46365.5 | wpb 510.9 | bsz 1 | num_updates 7008 | best_loss 8.953
2022-03-05 19:00:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7008 updates
2022-03-05 19:00:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 144 @ 7008 updates, score 13.651) (writing took 1.715182950720191 seconds)
2022-03-05 19:00:10 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-05 19:00:10 | INFO | train | epoch 144 | loss 2.728 | nll_loss 0.888 | ppl 1.85 | wps 27637 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7008 | lr 0.000377749 | gnorm 0.854 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16648
2022-03-05 19:00:10 | INFO | fairseq.trainer | begin training epoch 145
2022-03-05 19:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:02:03 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.545 | nll_loss 12.814 | ppl 7201.32 | wps 46253.3 | wpb 510.9 | bsz 1 | num_updates 7057 | best_loss 8.953
2022-03-05 19:02:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7057 updates
2022-03-05 19:02:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:02:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 145 @ 7057 updates, score 13.545) (writing took 1.6753852106630802 seconds)
2022-03-05 19:02:05 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-05 19:02:05 | INFO | train | epoch 145 | loss 2.719 | nll_loss 0.878 | ppl 1.84 | wps 27644.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7057 | lr 0.000376435 | gnorm 0.879 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 16763
2022-03-05 19:02:05 | INFO | fairseq.trainer | begin training epoch 146
2022-03-05 19:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:03:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:03:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:03:45 | INFO | train_inner | epoch 146:     45 / 49 loss=2.716, nll_loss=0.875, ppl=1.83, wps=27160.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.866, loss_scale=8, train_wall=203, gb_free=21.6, wall=16864
2022-03-05 19:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:03:58 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.42 | nll_loss 12.68 | ppl 6564.44 | wps 46312.2 | wpb 510.9 | bsz 1 | num_updates 7104 | best_loss 8.953
2022-03-05 19:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7104 updates
2022-03-05 19:03:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:04:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 146 @ 7104 updates, score 13.42) (writing took 1.6730645885691047 seconds)
2022-03-05 19:04:00 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-05 19:04:00 | INFO | train | epoch 146 | loss 2.707 | nll_loss 0.866 | ppl 1.82 | wps 26513.1 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 7104 | lr 0.000375188 | gnorm 0.849 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 16878
2022-03-05 19:04:00 | INFO | fairseq.trainer | begin training epoch 147
2022-03-05 19:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:05:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:05:53 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.51 | nll_loss 12.772 | ppl 6995.34 | wps 46288.1 | wpb 510.9 | bsz 1 | num_updates 7153 | best_loss 8.953
2022-03-05 19:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7153 updates
2022-03-05 19:05:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:05:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:05:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 147 @ 7153 updates, score 13.51) (writing took 1.6873424611985683 seconds)
2022-03-05 19:05:55 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-05 19:05:55 | INFO | train | epoch 147 | loss 2.701 | nll_loss 0.86 | ppl 1.81 | wps 27610.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7153 | lr 0.0003739 | gnorm 0.849 | loss_scale 8 | train_wall 98 | gb_free 21.6 | wall 16993
2022-03-05 19:05:55 | INFO | fairseq.trainer | begin training epoch 148
2022-03-05 19:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:07:40 | INFO | train_inner | epoch 148:     47 / 49 loss=2.698, nll_loss=0.857, ppl=1.81, wps=27678.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.853, loss_scale=8, train_wall=199, gb_free=21.6, wall=17098
2022-03-05 19:07:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:07:48 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.473 | nll_loss 12.727 | ppl 6778.52 | wps 46468.8 | wpb 510.9 | bsz 1 | num_updates 7202 | best_loss 8.953
2022-03-05 19:07:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7202 updates
2022-03-05 19:07:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 148 @ 7202 updates, score 13.473) (writing took 1.6392066702246666 seconds)
2022-03-05 19:07:49 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-05 19:07:49 | INFO | train | epoch 148 | loss 2.694 | nll_loss 0.853 | ppl 1.81 | wps 27695.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7202 | lr 0.000372626 | gnorm 0.857 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 17108
2022-03-05 19:07:49 | INFO | fairseq.trainer | begin training epoch 149
2022-03-05 19:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:09:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:09:43 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.467 | nll_loss 12.73 | ppl 6792.52 | wps 46275.3 | wpb 510.9 | bsz 1 | num_updates 7251 | best_loss 8.953
2022-03-05 19:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7251 updates
2022-03-05 19:09:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:09:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:09:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 149 @ 7251 updates, score 13.467) (writing took 1.6888194605708122 seconds)
2022-03-05 19:09:44 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-05 19:09:44 | INFO | train | epoch 149 | loss 2.687 | nll_loss 0.846 | ppl 1.8 | wps 27656.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7251 | lr 0.000371365 | gnorm 0.857 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17223
2022-03-05 19:09:44 | INFO | fairseq.trainer | begin training epoch 150
2022-03-05 19:09:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:11:33 | INFO | train_inner | epoch 150:     49 / 49 loss=2.683, nll_loss=0.842, ppl=1.79, wps=27675, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.852, loss_scale=16, train_wall=198, gb_free=21.6, wall=17332
2022-03-05 19:11:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:11:38 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.538 | nll_loss 12.815 | ppl 7207.88 | wps 46131.9 | wpb 510.9 | bsz 1 | num_updates 7300 | best_loss 8.953
2022-03-05 19:11:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7300 updates
2022-03-05 19:11:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:11:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:11:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 150 @ 7300 updates, score 13.538) (writing took 1.7149200104176998 seconds)
2022-03-05 19:11:39 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-05 19:11:39 | INFO | train | epoch 150 | loss 2.677 | nll_loss 0.836 | ppl 1.79 | wps 27621.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7300 | lr 0.000370117 | gnorm 0.844 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17338
2022-03-05 19:11:39 | INFO | fairseq.trainer | begin training epoch 151
2022-03-05 19:11:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:13:33 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.501 | nll_loss 12.76 | ppl 6938.8 | wps 46438.2 | wpb 510.9 | bsz 1 | num_updates 7349 | best_loss 8.953
2022-03-05 19:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7349 updates
2022-03-05 19:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 151 @ 7349 updates, score 13.501) (writing took 1.6633805530145764 seconds)
2022-03-05 19:13:34 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-05 19:13:34 | INFO | train | epoch 151 | loss 2.667 | nll_loss 0.826 | ppl 1.77 | wps 27649.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7349 | lr 0.000368881 | gnorm 0.826 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 17453
2022-03-05 19:13:34 | INFO | fairseq.trainer | begin training epoch 152
2022-03-05 19:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:13:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:15:28 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.489 | nll_loss 12.752 | ppl 6896.91 | wps 46429.7 | wpb 510.9 | bsz 1 | num_updates 7397 | best_loss 8.953
2022-03-05 19:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7397 updates
2022-03-05 19:15:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:15:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:15:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 152 @ 7397 updates, score 13.489) (writing took 1.6872801827266812 seconds)
2022-03-05 19:15:29 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-05 19:15:29 | INFO | train | epoch 152 | loss 2.661 | nll_loss 0.82 | ppl 1.76 | wps 27083.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7397 | lr 0.000367682 | gnorm 0.823 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17568
2022-03-05 19:15:29 | INFO | fairseq.trainer | begin training epoch 153
2022-03-05 19:15:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:15:36 | INFO | train_inner | epoch 153:      3 / 49 loss=2.663, nll_loss=0.822, ppl=1.77, wps=26680.6, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.826, loss_scale=16, train_wall=201, gb_free=21.6, wall=17575
2022-03-05 19:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:17:23 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.49 | nll_loss 12.766 | ppl 6963.47 | wps 46215.9 | wpb 510.9 | bsz 1 | num_updates 7446 | best_loss 8.953
2022-03-05 19:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7446 updates
2022-03-05 19:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:17:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:17:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 153 @ 7446 updates, score 13.49) (writing took 1.6264698887243867 seconds)
2022-03-05 19:17:24 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-05 19:17:24 | INFO | train | epoch 153 | loss 2.655 | nll_loss 0.814 | ppl 1.76 | wps 27640.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7446 | lr 0.00036647 | gnorm 0.833 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17683
2022-03-05 19:17:24 | INFO | fairseq.trainer | begin training epoch 154
2022-03-05 19:17:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:18:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:19:18 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.57 | nll_loss 12.857 | ppl 7417.49 | wps 46481.1 | wpb 510.9 | bsz 1 | num_updates 7494 | best_loss 8.953
2022-03-05 19:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7494 updates
2022-03-05 19:19:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 154 @ 7494 updates, score 13.57) (writing took 1.6169845908880234 seconds)
2022-03-05 19:19:19 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-05 19:19:19 | INFO | train | epoch 154 | loss 2.647 | nll_loss 0.806 | ppl 1.75 | wps 27071.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7494 | lr 0.000365295 | gnorm 0.822 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17798
2022-03-05 19:19:19 | INFO | fairseq.trainer | begin training epoch 155
2022-03-05 19:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:19:33 | INFO | train_inner | epoch 155:      6 / 49 loss=2.65, nll_loss=0.808, ppl=1.75, wps=27413.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.826, loss_scale=16, train_wall=201, gb_free=21.6, wall=17811
2022-03-05 19:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:21:12 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.544 | nll_loss 12.818 | ppl 7219.57 | wps 46324.9 | wpb 510.9 | bsz 1 | num_updates 7543 | best_loss 8.953
2022-03-05 19:21:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7543 updates
2022-03-05 19:21:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 155 @ 7543 updates, score 13.544) (writing took 1.6587490271776915 seconds)
2022-03-05 19:21:14 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-05 19:21:14 | INFO | train | epoch 155 | loss 2.64 | nll_loss 0.8 | ppl 1.74 | wps 27691.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7543 | lr 0.000364106 | gnorm 0.809 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 17913
2022-03-05 19:21:14 | INFO | fairseq.trainer | begin training epoch 156
2022-03-05 19:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:23:07 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.528 | nll_loss 12.805 | ppl 7156.06 | wps 46349.9 | wpb 510.9 | bsz 1 | num_updates 7592 | best_loss 8.953
2022-03-05 19:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7592 updates
2022-03-05 19:23:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 156 @ 7592 updates, score 13.528) (writing took 1.6778237093240023 seconds)
2022-03-05 19:23:09 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-05 19:23:09 | INFO | train | epoch 156 | loss 2.634 | nll_loss 0.793 | ppl 1.73 | wps 27637.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7592 | lr 0.000362929 | gnorm 0.802 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18028
2022-03-05 19:23:09 | INFO | fairseq.trainer | begin training epoch 157
2022-03-05 19:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:23:27 | INFO | train_inner | epoch 157:      8 / 49 loss=2.636, nll_loss=0.795, ppl=1.73, wps=27694.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.803, loss_scale=16, train_wall=199, gb_free=21.6, wall=18046
2022-03-05 19:24:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:25:02 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.521 | nll_loss 12.802 | ppl 7139.27 | wps 46016.6 | wpb 510.9 | bsz 1 | num_updates 7640 | best_loss 8.953
2022-03-05 19:25:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7640 updates
2022-03-05 19:25:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:25:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 157 @ 7640 updates, score 13.521) (writing took 1.7083377270027995 seconds)
2022-03-05 19:25:04 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-05 19:25:04 | INFO | train | epoch 157 | loss 2.625 | nll_loss 0.784 | ppl 1.72 | wps 27067.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7640 | lr 0.000361787 | gnorm 0.792 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18143
2022-03-05 19:25:04 | INFO | fairseq.trainer | begin training epoch 158
2022-03-05 19:25:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:26:57 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.492 | nll_loss 12.766 | ppl 6966.15 | wps 46420.2 | wpb 510.9 | bsz 1 | num_updates 7689 | best_loss 8.953
2022-03-05 19:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7689 updates
2022-03-05 19:26:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 158 @ 7689 updates, score 13.492) (writing took 1.690169868990779 seconds)
2022-03-05 19:26:59 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-05 19:26:59 | INFO | train | epoch 158 | loss 2.62 | nll_loss 0.78 | ppl 1.72 | wps 27639.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7689 | lr 0.000360633 | gnorm 0.808 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18258
2022-03-05 19:26:59 | INFO | fairseq.trainer | begin training epoch 159
2022-03-05 19:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:27:24 | INFO | train_inner | epoch 159:     11 / 49 loss=2.621, nll_loss=0.78, ppl=1.72, wps=27410.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.804, loss_scale=16, train_wall=201, gb_free=21.6, wall=18282
2022-03-05 19:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:28:52 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.491 | nll_loss 12.771 | ppl 6988.47 | wps 46256.7 | wpb 510.9 | bsz 1 | num_updates 7738 | best_loss 8.953
2022-03-05 19:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7738 updates
2022-03-05 19:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 159 @ 7738 updates, score 13.491) (writing took 1.6880491888150573 seconds)
2022-03-05 19:28:54 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-05 19:28:54 | INFO | train | epoch 159 | loss 2.614 | nll_loss 0.774 | ppl 1.71 | wps 27638 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7738 | lr 0.000359489 | gnorm 0.811 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18373
2022-03-05 19:28:54 | INFO | fairseq.trainer | begin training epoch 160
2022-03-05 19:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:30:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:30:47 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.542 | nll_loss 12.827 | ppl 7265.64 | wps 46621.6 | wpb 510.9 | bsz 1 | num_updates 7786 | best_loss 8.953
2022-03-05 19:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7786 updates
2022-03-05 19:30:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 160 @ 7786 updates, score 13.542) (writing took 1.6580345127731562 seconds)
2022-03-05 19:30:49 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-05 19:30:49 | INFO | train | epoch 160 | loss 2.607 | nll_loss 0.766 | ppl 1.7 | wps 27094.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7786 | lr 0.000358379 | gnorm 0.802 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18487
2022-03-05 19:30:49 | INFO | fairseq.trainer | begin training epoch 161
2022-03-05 19:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:31:20 | INFO | train_inner | epoch 161:     14 / 49 loss=2.608, nll_loss=0.768, ppl=1.7, wps=27424.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.796, loss_scale=16, train_wall=201, gb_free=21.6, wall=18519
2022-03-05 19:32:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:32:42 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.584 | nll_loss 12.883 | ppl 7551.65 | wps 46329.1 | wpb 510.9 | bsz 1 | num_updates 7835 | best_loss 8.953
2022-03-05 19:32:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7835 updates
2022-03-05 19:32:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:32:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 161 @ 7835 updates, score 13.584) (writing took 1.6473941840231419 seconds)
2022-03-05 19:32:44 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-05 19:32:44 | INFO | train | epoch 161 | loss 2.601 | nll_loss 0.76 | ppl 1.69 | wps 27668.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7835 | lr 0.000357257 | gnorm 0.783 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18602
2022-03-05 19:32:44 | INFO | fairseq.trainer | begin training epoch 162
2022-03-05 19:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:34:37 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.629 | nll_loss 12.925 | ppl 7777.8 | wps 46374.8 | wpb 510.9 | bsz 1 | num_updates 7884 | best_loss 8.953
2022-03-05 19:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7884 updates
2022-03-05 19:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:34:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 162 @ 7884 updates, score 13.629) (writing took 1.6329394970089197 seconds)
2022-03-05 19:34:39 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-05 19:34:39 | INFO | train | epoch 162 | loss 2.594 | nll_loss 0.754 | ppl 1.69 | wps 27668 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7884 | lr 0.000356145 | gnorm 0.79 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18717
2022-03-05 19:34:39 | INFO | fairseq.trainer | begin training epoch 163
2022-03-05 19:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:35:14 | INFO | train_inner | epoch 163:     16 / 49 loss=2.596, nll_loss=0.755, ppl=1.69, wps=27697.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.793, loss_scale=32, train_wall=199, gb_free=21.6, wall=18753
2022-03-05 19:35:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:36:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:36:32 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.382 | nll_loss 12.65 | ppl 6425.1 | wps 46404.2 | wpb 510.9 | bsz 1 | num_updates 7932 | best_loss 8.953
2022-03-05 19:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7932 updates
2022-03-05 19:36:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:36:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:36:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 163 @ 7932 updates, score 13.382) (writing took 1.7149264542385936 seconds)
2022-03-05 19:36:33 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-05 19:36:33 | INFO | train | epoch 163 | loss 2.59 | nll_loss 0.749 | ppl 1.68 | wps 27072.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 7932 | lr 0.000355066 | gnorm 0.796 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18832
2022-03-05 19:36:33 | INFO | fairseq.trainer | begin training epoch 164
2022-03-05 19:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:38:27 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.507 | nll_loss 12.787 | ppl 7065.33 | wps 46443.1 | wpb 510.9 | bsz 1 | num_updates 7981 | best_loss 8.953
2022-03-05 19:38:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7981 updates
2022-03-05 19:38:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:38:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 164 @ 7981 updates, score 13.507) (writing took 1.652689902111888 seconds)
2022-03-05 19:38:28 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-05 19:38:28 | INFO | train | epoch 164 | loss 2.582 | nll_loss 0.742 | ppl 1.67 | wps 27658.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 7981 | lr 0.000353974 | gnorm 0.784 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 18947
2022-03-05 19:38:28 | INFO | fairseq.trainer | begin training epoch 165
2022-03-05 19:38:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:39:11 | INFO | train_inner | epoch 165:     19 / 49 loss=2.582, nll_loss=0.742, ppl=1.67, wps=27417.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.781, loss_scale=16, train_wall=201, gb_free=21.6, wall=18990
2022-03-05 19:40:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:40:22 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.515 | nll_loss 12.807 | ppl 7167.71 | wps 46405.2 | wpb 510.9 | bsz 1 | num_updates 8029 | best_loss 8.953
2022-03-05 19:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8029 updates
2022-03-05 19:40:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 165 @ 8029 updates, score 13.515) (writing took 1.6758972750976682 seconds)
2022-03-05 19:40:23 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-05 19:40:23 | INFO | train | epoch 165 | loss 2.574 | nll_loss 0.734 | ppl 1.66 | wps 27099.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8029 | lr 0.000352914 | gnorm 0.769 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19062
2022-03-05 19:40:23 | INFO | fairseq.trainer | begin training epoch 166
2022-03-05 19:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:42:17 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.613 | nll_loss 12.917 | ppl 7731.95 | wps 46484.6 | wpb 510.9 | bsz 1 | num_updates 8078 | best_loss 8.953
2022-03-05 19:42:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8078 updates
2022-03-05 19:42:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:42:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:42:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 166 @ 8078 updates, score 13.613) (writing took 1.641966206021607 seconds)
2022-03-05 19:42:18 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-05 19:42:18 | INFO | train | epoch 166 | loss 2.571 | nll_loss 0.731 | ppl 1.66 | wps 27656.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8078 | lr 0.000351842 | gnorm 0.773 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19177
2022-03-05 19:42:18 | INFO | fairseq.trainer | begin training epoch 167
2022-03-05 19:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:43:07 | INFO | train_inner | epoch 167:     22 / 49 loss=2.571, nll_loss=0.731, ppl=1.66, wps=27438.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.771, loss_scale=8, train_wall=201, gb_free=21.6, wall=19226
2022-03-05 19:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:44:11 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.521 | nll_loss 12.82 | ppl 7229.82 | wps 46344.3 | wpb 510.9 | bsz 1 | num_updates 8127 | best_loss 8.953
2022-03-05 19:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8127 updates
2022-03-05 19:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 167 @ 8127 updates, score 13.521) (writing took 1.617443174123764 seconds)
2022-03-05 19:44:13 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-05 19:44:13 | INFO | train | epoch 167 | loss 2.566 | nll_loss 0.727 | ppl 1.66 | wps 27678.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8127 | lr 0.00035078 | gnorm 0.775 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19292
2022-03-05 19:44:13 | INFO | fairseq.trainer | begin training epoch 168
2022-03-05 19:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:46:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:46:06 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.501 | nll_loss 12.796 | ppl 7113.05 | wps 46409 | wpb 510.9 | bsz 1 | num_updates 8176 | best_loss 8.953
2022-03-05 19:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8176 updates
2022-03-05 19:46:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:46:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:46:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 168 @ 8176 updates, score 13.501) (writing took 1.6489601386711001 seconds)
2022-03-05 19:46:08 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-05 19:46:08 | INFO | train | epoch 168 | loss 2.559 | nll_loss 0.719 | ppl 1.65 | wps 27648.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8176 | lr 0.000349727 | gnorm 0.751 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19407
2022-03-05 19:46:08 | INFO | fairseq.trainer | begin training epoch 169
2022-03-05 19:46:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:47:02 | INFO | train_inner | epoch 169:     24 / 49 loss=2.56, nll_loss=0.721, ppl=1.65, wps=27694.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.761, loss_scale=16, train_wall=199, gb_free=21.6, wall=19460
2022-03-05 19:47:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:48:01 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.503 | nll_loss 12.796 | ppl 7110.7 | wps 46449.8 | wpb 510.9 | bsz 1 | num_updates 8225 | best_loss 8.953
2022-03-05 19:48:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8225 updates
2022-03-05 19:48:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:48:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:48:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 169 @ 8225 updates, score 13.503) (writing took 1.6246532574295998 seconds)
2022-03-05 19:48:03 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-05 19:48:03 | INFO | train | epoch 169 | loss 2.555 | nll_loss 0.717 | ppl 1.64 | wps 27663.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8225 | lr 0.000348684 | gnorm 0.765 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19521
2022-03-05 19:48:03 | INFO | fairseq.trainer | begin training epoch 170
2022-03-05 19:48:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:49:56 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.615 | nll_loss 12.924 | ppl 7770.9 | wps 46353.5 | wpb 510.9 | bsz 1 | num_updates 8274 | best_loss 8.953
2022-03-05 19:49:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8274 updates
2022-03-05 19:49:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:49:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:49:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 170 @ 8274 updates, score 13.615) (writing took 1.6722411988303065 seconds)
2022-03-05 19:49:58 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-05 19:49:58 | INFO | train | epoch 170 | loss 2.55 | nll_loss 0.711 | ppl 1.64 | wps 27650.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8274 | lr 0.00034765 | gnorm 0.759 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19636
2022-03-05 19:49:58 | INFO | fairseq.trainer | begin training epoch 171
2022-03-05 19:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:50:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 19:50:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 19:51:00 | INFO | train_inner | epoch 171:     28 / 49 loss=2.55, nll_loss=0.711, ppl=1.64, wps=27175.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.762, loss_scale=8, train_wall=203, gb_free=21.6, wall=19699
2022-03-05 19:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:51:51 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.452 | nll_loss 12.742 | ppl 6851.59 | wps 46428.8 | wpb 510.9 | bsz 1 | num_updates 8321 | best_loss 8.953
2022-03-05 19:51:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8321 updates
2022-03-05 19:51:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:51:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 171 @ 8321 updates, score 13.452) (writing took 1.6826994102448225 seconds)
2022-03-05 19:51:53 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-05 19:51:53 | INFO | train | epoch 171 | loss 2.543 | nll_loss 0.705 | ppl 1.63 | wps 26526.8 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 8321 | lr 0.000346667 | gnorm 0.764 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19751
2022-03-05 19:51:53 | INFO | fairseq.trainer | begin training epoch 172
2022-03-05 19:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:53:46 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.559 | nll_loss 12.875 | ppl 7510.41 | wps 46248.3 | wpb 510.9 | bsz 1 | num_updates 8370 | best_loss 8.953
2022-03-05 19:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8370 updates
2022-03-05 19:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 172 @ 8370 updates, score 13.559) (writing took 1.6717638662084937 seconds)
2022-03-05 19:53:48 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-05 19:53:48 | INFO | train | epoch 172 | loss 2.539 | nll_loss 0.701 | ppl 1.63 | wps 27627.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8370 | lr 0.000345651 | gnorm 0.745 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 19866
2022-03-05 19:53:48 | INFO | fairseq.trainer | begin training epoch 173
2022-03-05 19:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:54:55 | INFO | train_inner | epoch 173:     30 / 49 loss=2.538, nll_loss=0.7, ppl=1.62, wps=27666.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.748, loss_scale=8, train_wall=199, gb_free=21.6, wall=19933
2022-03-05 19:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:55:41 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.573 | nll_loss 12.881 | ppl 7542.66 | wps 46415.4 | wpb 510.9 | bsz 1 | num_updates 8419 | best_loss 8.953
2022-03-05 19:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8419 updates
2022-03-05 19:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:55:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 173 @ 8419 updates, score 13.573) (writing took 1.6664419090375304 seconds)
2022-03-05 19:55:43 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-05 19:55:43 | INFO | train | epoch 173 | loss 2.533 | nll_loss 0.696 | ppl 1.62 | wps 27638.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8419 | lr 0.000344643 | gnorm 0.746 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 19981
2022-03-05 19:55:43 | INFO | fairseq.trainer | begin training epoch 174
2022-03-05 19:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:57:36 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.604 | nll_loss 12.908 | ppl 7687.68 | wps 46314.3 | wpb 510.9 | bsz 1 | num_updates 8468 | best_loss 8.953
2022-03-05 19:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8468 updates
2022-03-05 19:57:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:57:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:57:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 174 @ 8468 updates, score 13.604) (writing took 1.6680199289694428 seconds)
2022-03-05 19:57:37 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-05 19:57:37 | INFO | train | epoch 174 | loss 2.529 | nll_loss 0.692 | ppl 1.62 | wps 27684.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8468 | lr 0.000343645 | gnorm 0.745 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20096
2022-03-05 19:57:37 | INFO | fairseq.trainer | begin training epoch 175
2022-03-05 19:57:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 19:58:49 | INFO | train_inner | epoch 175:     32 / 49 loss=2.528, nll_loss=0.691, ppl=1.61, wps=27687.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.747, loss_scale=16, train_wall=199, gb_free=21.6, wall=20168
2022-03-05 19:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 19:59:31 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.541 | nll_loss 12.839 | ppl 7325.14 | wps 46269.7 | wpb 510.9 | bsz 1 | num_updates 8517 | best_loss 8.953
2022-03-05 19:59:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8517 updates
2022-03-05 19:59:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:59:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 19:59:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 175 @ 8517 updates, score 13.541) (writing took 1.6641066949814558 seconds)
2022-03-05 19:59:32 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-05 19:59:32 | INFO | train | epoch 175 | loss 2.525 | nll_loss 0.687 | ppl 1.61 | wps 27633.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8517 | lr 0.000342655 | gnorm 0.748 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20211
2022-03-05 19:59:32 | INFO | fairseq.trainer | begin training epoch 176
2022-03-05 19:59:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:00:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:01:26 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.478 | nll_loss 12.784 | ppl 7052.28 | wps 46488 | wpb 510.9 | bsz 1 | num_updates 8565 | best_loss 8.953
2022-03-05 20:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8565 updates
2022-03-05 20:01:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:01:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 176 @ 8565 updates, score 13.478) (writing took 1.6242079455405474 seconds)
2022-03-05 20:01:27 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-05 20:01:27 | INFO | train | epoch 176 | loss 2.519 | nll_loss 0.682 | ppl 1.6 | wps 27086.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8565 | lr 0.000341693 | gnorm 0.732 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20326
2022-03-05 20:01:27 | INFO | fairseq.trainer | begin training epoch 177
2022-03-05 20:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:02:46 | INFO | train_inner | epoch 177:     35 / 49 loss=2.518, nll_loss=0.681, ppl=1.6, wps=27415.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.738, loss_scale=16, train_wall=201, gb_free=21.6, wall=20404
2022-03-05 20:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:03:21 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.545 | nll_loss 12.853 | ppl 7400.2 | wps 46520.7 | wpb 510.9 | bsz 1 | num_updates 8614 | best_loss 8.953
2022-03-05 20:03:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8614 updates
2022-03-05 20:03:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:03:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:03:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 177 @ 8614 updates, score 13.545) (writing took 1.6592247942462564 seconds)
2022-03-05 20:03:22 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-05 20:03:22 | INFO | train | epoch 177 | loss 2.513 | nll_loss 0.676 | ppl 1.6 | wps 27644.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8614 | lr 0.00034072 | gnorm 0.732 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20441
2022-03-05 20:03:22 | INFO | fairseq.trainer | begin training epoch 178
2022-03-05 20:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:05:16 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.559 | nll_loss 12.868 | ppl 7476.28 | wps 46320.8 | wpb 510.9 | bsz 1 | num_updates 8663 | best_loss 8.953
2022-03-05 20:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8663 updates
2022-03-05 20:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 178 @ 8663 updates, score 13.559) (writing took 1.7044374365359545 seconds)
2022-03-05 20:05:17 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-05 20:05:17 | INFO | train | epoch 178 | loss 2.509 | nll_loss 0.672 | ppl 1.59 | wps 27624.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8663 | lr 0.000339755 | gnorm 0.72 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20556
2022-03-05 20:05:17 | INFO | fairseq.trainer | begin training epoch 179
2022-03-05 20:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:06:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:06:42 | INFO | train_inner | epoch 179:     38 / 49 loss=2.508, nll_loss=0.671, ppl=1.59, wps=27401, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.716, loss_scale=16, train_wall=201, gb_free=21.6, wall=20641
2022-03-05 20:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:07:11 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.582 | nll_loss 12.895 | ppl 7619.51 | wps 46636.8 | wpb 510.9 | bsz 1 | num_updates 8711 | best_loss 8.953
2022-03-05 20:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8711 updates
2022-03-05 20:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 179 @ 8711 updates, score 13.582) (writing took 1.687614412046969 seconds)
2022-03-05 20:07:12 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-05 20:07:12 | INFO | train | epoch 179 | loss 2.503 | nll_loss 0.667 | ppl 1.59 | wps 27067 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8711 | lr 0.000338818 | gnorm 0.709 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20671
2022-03-05 20:07:12 | INFO | fairseq.trainer | begin training epoch 180
2022-03-05 20:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:09:06 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.557 | nll_loss 12.87 | ppl 7488.19 | wps 46396.6 | wpb 510.9 | bsz 1 | num_updates 8760 | best_loss 8.953
2022-03-05 20:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8760 updates
2022-03-05 20:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 180 @ 8760 updates, score 13.557) (writing took 1.623834847472608 seconds)
2022-03-05 20:09:07 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-05 20:09:07 | INFO | train | epoch 180 | loss 2.502 | nll_loss 0.666 | ppl 1.59 | wps 27647.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8760 | lr 0.000337869 | gnorm 0.731 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20786
2022-03-05 20:09:07 | INFO | fairseq.trainer | begin training epoch 181
2022-03-05 20:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:10:37 | INFO | train_inner | epoch 181:     40 / 49 loss=2.501, nll_loss=0.665, ppl=1.59, wps=27682.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.724, loss_scale=16, train_wall=199, gb_free=21.6, wall=20875
2022-03-05 20:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:11:01 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.521 | nll_loss 12.825 | ppl 7254.34 | wps 46528.5 | wpb 510.9 | bsz 1 | num_updates 8809 | best_loss 8.953
2022-03-05 20:11:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8809 updates
2022-03-05 20:11:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:11:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:11:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 181 @ 8809 updates, score 13.521) (writing took 1.7147143753245473 seconds)
2022-03-05 20:11:02 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-05 20:11:02 | INFO | train | epoch 181 | loss 2.498 | nll_loss 0.662 | ppl 1.58 | wps 27636.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8809 | lr 0.000336928 | gnorm 0.716 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 20901
2022-03-05 20:11:02 | INFO | fairseq.trainer | begin training epoch 182
2022-03-05 20:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:12:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:12:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:12:56 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.519 | nll_loss 12.845 | ppl 7357.65 | wps 46262 | wpb 510.9 | bsz 1 | num_updates 8857 | best_loss 8.953
2022-03-05 20:12:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8857 updates
2022-03-05 20:12:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 182 @ 8857 updates, score 13.519) (writing took 1.653075022622943 seconds)
2022-03-05 20:12:57 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-05 20:12:57 | INFO | train | epoch 182 | loss 2.491 | nll_loss 0.656 | ppl 1.58 | wps 27046.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 8857 | lr 0.000336013 | gnorm 0.703 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21016
2022-03-05 20:12:57 | INFO | fairseq.trainer | begin training epoch 183
2022-03-05 20:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:14:34 | INFO | train_inner | epoch 183:     43 / 49 loss=2.491, nll_loss=0.656, ppl=1.58, wps=27396.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.705, loss_scale=16, train_wall=201, gb_free=21.6, wall=21112
2022-03-05 20:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:14:51 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.54 | nll_loss 12.859 | ppl 7427.2 | wps 46353.8 | wpb 510.9 | bsz 1 | num_updates 8906 | best_loss 8.953
2022-03-05 20:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8906 updates
2022-03-05 20:14:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 183 @ 8906 updates, score 13.54) (writing took 1.6697967033833265 seconds)
2022-03-05 20:14:52 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-05 20:14:52 | INFO | train | epoch 183 | loss 2.489 | nll_loss 0.654 | ppl 1.57 | wps 27638.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8906 | lr 0.000335088 | gnorm 0.71 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21131
2022-03-05 20:14:52 | INFO | fairseq.trainer | begin training epoch 184
2022-03-05 20:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:16:46 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.571 | nll_loss 12.892 | ppl 7599.11 | wps 46319.8 | wpb 510.9 | bsz 1 | num_updates 8955 | best_loss 8.953
2022-03-05 20:16:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8955 updates
2022-03-05 20:16:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 184 @ 8955 updates, score 13.571) (writing took 1.6490970151498914 seconds)
2022-03-05 20:16:47 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-05 20:16:47 | INFO | train | epoch 184 | loss 2.485 | nll_loss 0.65 | ppl 1.57 | wps 27644.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 8955 | lr 0.00033417 | gnorm 0.723 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21246
2022-03-05 20:16:47 | INFO | fairseq.trainer | begin training epoch 185
2022-03-05 20:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:17:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:18:30 | INFO | train_inner | epoch 185:     46 / 49 loss=2.484, nll_loss=0.649, ppl=1.57, wps=27426.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.723, loss_scale=16, train_wall=201, gb_free=21.6, wall=21349
2022-03-05 20:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:18:41 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.603 | nll_loss 12.931 | ppl 7810.04 | wps 46336.3 | wpb 510.9 | bsz 1 | num_updates 9003 | best_loss 8.953
2022-03-05 20:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9003 updates
2022-03-05 20:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 185 @ 9003 updates, score 13.603) (writing took 1.6352952951565385 seconds)
2022-03-05 20:18:42 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-05 20:18:42 | INFO | train | epoch 185 | loss 2.479 | nll_loss 0.645 | ppl 1.56 | wps 27099.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9003 | lr 0.000333278 | gnorm 0.717 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21361
2022-03-05 20:18:42 | INFO | fairseq.trainer | begin training epoch 186
2022-03-05 20:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:20:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:20:35 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.504 | nll_loss 12.819 | ppl 7225.93 | wps 46286.5 | wpb 510.9 | bsz 1 | num_updates 9052 | best_loss 8.953
2022-03-05 20:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9052 updates
2022-03-05 20:20:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 186 @ 9052 updates, score 13.504) (writing took 1.681812853552401 seconds)
2022-03-05 20:20:37 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-05 20:20:37 | INFO | train | epoch 186 | loss 2.474 | nll_loss 0.64 | ppl 1.56 | wps 27672.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9052 | lr 0.000332375 | gnorm 0.705 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21476
2022-03-05 20:20:37 | INFO | fairseq.trainer | begin training epoch 187
2022-03-05 20:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:22:24 | INFO | train_inner | epoch 187:     48 / 49 loss=2.473, nll_loss=0.639, ppl=1.56, wps=27685.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.704, loss_scale=16, train_wall=199, gb_free=21.6, wall=21583
2022-03-05 20:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:22:30 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.531 | nll_loss 12.855 | ppl 7407.32 | wps 46299.7 | wpb 510.9 | bsz 1 | num_updates 9101 | best_loss 8.953
2022-03-05 20:22:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9101 updates
2022-03-05 20:22:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:22:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 187 @ 9101 updates, score 13.531) (writing took 1.6114783575758338 seconds)
2022-03-05 20:22:32 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-05 20:22:32 | INFO | train | epoch 187 | loss 2.471 | nll_loss 0.637 | ppl 1.55 | wps 27648.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9101 | lr 0.000331479 | gnorm 0.703 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21591
2022-03-05 20:22:32 | INFO | fairseq.trainer | begin training epoch 188
2022-03-05 20:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:23:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:23:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-05 20:24:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:24:25 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.569 | nll_loss 12.889 | ppl 7583.64 | wps 46478.1 | wpb 510.9 | bsz 1 | num_updates 9148 | best_loss 8.953
2022-03-05 20:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9148 updates
2022-03-05 20:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:24:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:24:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 188 @ 9148 updates, score 13.569) (writing took 1.6618098178878427 seconds)
2022-03-05 20:24:27 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-05 20:24:27 | INFO | train | epoch 188 | loss 2.468 | nll_loss 0.635 | ppl 1.55 | wps 26526.9 | ups 0.41 | wpb 64829.4 | bsz 126.6 | num_updates 9148 | lr 0.000330626 | gnorm 0.707 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 21705
2022-03-05 20:24:27 | INFO | fairseq.trainer | begin training epoch 189
2022-03-05 20:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:26:20 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.503 | nll_loss 12.824 | ppl 7250.95 | wps 46321.9 | wpb 510.9 | bsz 1 | num_updates 9197 | best_loss 8.953
2022-03-05 20:26:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9197 updates
2022-03-05 20:26:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 189 @ 9197 updates, score 13.503) (writing took 1.6984971119090915 seconds)
2022-03-05 20:26:22 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-05 20:26:22 | INFO | train | epoch 189 | loss 2.465 | nll_loss 0.632 | ppl 1.55 | wps 27650.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9197 | lr 0.000329744 | gnorm 0.706 | loss_scale 8 | train_wall 97 | gb_free 21.6 | wall 21820
2022-03-05 20:26:22 | INFO | fairseq.trainer | begin training epoch 190
2022-03-05 20:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:26:29 | INFO | train_inner | epoch 190:      3 / 49 loss=2.466, nll_loss=0.632, ppl=1.55, wps=26442.5, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=9200, lr=0.00032969, gnorm=0.706, loss_scale=8, train_wall=202, gb_free=21.6, wall=21827
2022-03-05 20:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:28:15 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.457 | nll_loss 12.768 | ppl 6976.14 | wps 46399.3 | wpb 510.9 | bsz 1 | num_updates 9246 | best_loss 8.953
2022-03-05 20:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9246 updates
2022-03-05 20:28:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 190 @ 9246 updates, score 13.457) (writing took 1.64948889054358 seconds)
2022-03-05 20:28:17 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-05 20:28:17 | INFO | train | epoch 190 | loss 2.46 | nll_loss 0.627 | ppl 1.54 | wps 27665.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9246 | lr 0.000328869 | gnorm 0.688 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 21935
2022-03-05 20:28:17 | INFO | fairseq.trainer | begin training epoch 191
2022-03-05 20:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:30:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:30:10 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.486 | nll_loss 12.812 | ppl 7193.29 | wps 46270.8 | wpb 510.9 | bsz 1 | num_updates 9295 | best_loss 8.953
2022-03-05 20:30:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9295 updates
2022-03-05 20:30:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:30:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 191 @ 9295 updates, score 13.486) (writing took 1.650578973814845 seconds)
2022-03-05 20:30:12 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-05 20:30:12 | INFO | train | epoch 191 | loss 2.456 | nll_loss 0.623 | ppl 1.54 | wps 27635.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9295 | lr 0.000328001 | gnorm 0.682 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22050
2022-03-05 20:30:12 | INFO | fairseq.trainer | begin training epoch 192
2022-03-05 20:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:30:23 | INFO | train_inner | epoch 192:      5 / 49 loss=2.457, nll_loss=0.624, ppl=1.54, wps=27683.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.684, loss_scale=16, train_wall=199, gb_free=21.6, wall=22061
2022-03-05 20:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:32:05 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.549 | nll_loss 12.868 | ppl 7477.07 | wps 46242.5 | wpb 510.9 | bsz 1 | num_updates 9344 | best_loss 8.953
2022-03-05 20:32:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9344 updates
2022-03-05 20:32:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:32:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:32:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 192 @ 9344 updates, score 13.549) (writing took 1.655508179217577 seconds)
2022-03-05 20:32:06 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-05 20:32:06 | INFO | train | epoch 192 | loss 2.452 | nll_loss 0.62 | ppl 1.54 | wps 27673.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9344 | lr 0.00032714 | gnorm 0.68 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22165
2022-03-05 20:32:06 | INFO | fairseq.trainer | begin training epoch 193
2022-03-05 20:32:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:33:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:34:00 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.464 | nll_loss 12.78 | ppl 7032.37 | wps 46417.5 | wpb 510.9 | bsz 1 | num_updates 9393 | best_loss 8.953
2022-03-05 20:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9393 updates
2022-03-05 20:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:34:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 193 @ 9393 updates, score 13.464) (writing took 1.6558060571551323 seconds)
2022-03-05 20:34:02 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-05 20:34:02 | INFO | train | epoch 193 | loss 2.451 | nll_loss 0.619 | ppl 1.54 | wps 27619.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9393 | lr 0.000326286 | gnorm 0.681 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 22280
2022-03-05 20:34:02 | INFO | fairseq.trainer | begin training epoch 194
2022-03-05 20:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:34:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:34:19 | INFO | train_inner | epoch 194:      8 / 49 loss=2.451, nll_loss=0.619, ppl=1.54, wps=27416, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.683, loss_scale=16, train_wall=201, gb_free=21.6, wall=22298
2022-03-05 20:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:35:55 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.483 | nll_loss 12.796 | ppl 7113.33 | wps 46279.7 | wpb 510.9 | bsz 1 | num_updates 9441 | best_loss 8.953
2022-03-05 20:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9441 updates
2022-03-05 20:35:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:35:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:35:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 194 @ 9441 updates, score 13.483) (writing took 1.639443987980485 seconds)
2022-03-05 20:35:56 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-05 20:35:56 | INFO | train | epoch 194 | loss 2.447 | nll_loss 0.615 | ppl 1.53 | wps 27073.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9441 | lr 0.000325455 | gnorm 0.69 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22395
2022-03-05 20:35:57 | INFO | fairseq.trainer | begin training epoch 195
2022-03-05 20:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:37:50 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.564 | nll_loss 12.889 | ppl 7583.6 | wps 46439.4 | wpb 510.9 | bsz 1 | num_updates 9490 | best_loss 8.953
2022-03-05 20:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9490 updates
2022-03-05 20:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 195 @ 9490 updates, score 13.564) (writing took 1.6772625958546996 seconds)
2022-03-05 20:37:51 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-05 20:37:51 | INFO | train | epoch 195 | loss 2.443 | nll_loss 0.611 | ppl 1.53 | wps 27648.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9490 | lr 0.000324614 | gnorm 0.684 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22510
2022-03-05 20:37:51 | INFO | fairseq.trainer | begin training epoch 196
2022-03-05 20:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:38:14 | INFO | train_inner | epoch 196:     10 / 49 loss=2.443, nll_loss=0.612, ppl=1.53, wps=27670.7, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.683, loss_scale=16, train_wall=199, gb_free=21.6, wall=22533
2022-03-05 20:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:39:45 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.532 | nll_loss 12.85 | ppl 7380.61 | wps 46406.5 | wpb 510.9 | bsz 1 | num_updates 9539 | best_loss 8.953
2022-03-05 20:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9539 updates
2022-03-05 20:39:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:39:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:39:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 196 @ 9539 updates, score 13.532) (writing took 1.701926033012569 seconds)
2022-03-05 20:39:46 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-05 20:39:46 | INFO | train | epoch 196 | loss 2.439 | nll_loss 0.608 | ppl 1.52 | wps 27623.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9539 | lr 0.000323779 | gnorm 0.672 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 22625
2022-03-05 20:39:47 | INFO | fairseq.trainer | begin training epoch 197
2022-03-05 20:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:40:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:41:40 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.548 | nll_loss 12.872 | ppl 7498.05 | wps 46227.8 | wpb 510.9 | bsz 1 | num_updates 9587 | best_loss 8.953
2022-03-05 20:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9587 updates
2022-03-05 20:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:41:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 197 @ 9587 updates, score 13.548) (writing took 1.6839305628091097 seconds)
2022-03-05 20:41:41 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-05 20:41:41 | INFO | train | epoch 197 | loss 2.436 | nll_loss 0.605 | ppl 1.52 | wps 27066.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9587 | lr 0.000322967 | gnorm 0.69 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22740
2022-03-05 20:41:42 | INFO | fairseq.trainer | begin training epoch 198
2022-03-05 20:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:42:11 | INFO | train_inner | epoch 198:     13 / 49 loss=2.437, nll_loss=0.606, ppl=1.52, wps=27409.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.68, loss_scale=16, train_wall=201, gb_free=21.6, wall=22769
2022-03-05 20:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:43:35 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.505 | nll_loss 12.834 | ppl 7299.44 | wps 46457.6 | wpb 510.9 | bsz 1 | num_updates 9636 | best_loss 8.953
2022-03-05 20:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9636 updates
2022-03-05 20:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 198 @ 9636 updates, score 13.505) (writing took 1.6763618448749185 seconds)
2022-03-05 20:43:36 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-05 20:43:36 | INFO | train | epoch 198 | loss 2.432 | nll_loss 0.602 | ppl 1.52 | wps 27644.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9636 | lr 0.000322145 | gnorm 0.679 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 22855
2022-03-05 20:43:36 | INFO | fairseq.trainer | begin training epoch 199
2022-03-05 20:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:45:30 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.553 | nll_loss 12.884 | ppl 7556.57 | wps 46353 | wpb 510.9 | bsz 1 | num_updates 9685 | best_loss 8.953
2022-03-05 20:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9685 updates
2022-03-05 20:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:45:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:45:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 199 @ 9685 updates, score 13.553) (writing took 1.6266994941979647 seconds)
2022-03-05 20:45:31 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-05 20:45:31 | INFO | train | epoch 199 | loss 2.428 | nll_loss 0.598 | ppl 1.51 | wps 27663.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9685 | lr 0.000321329 | gnorm 0.673 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 22970
2022-03-05 20:45:31 | INFO | fairseq.trainer | begin training epoch 200
2022-03-05 20:45:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:45:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:46:07 | INFO | train_inner | epoch 200:     16 / 49 loss=2.429, nll_loss=0.599, ppl=1.51, wps=27419, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.677, loss_scale=16, train_wall=201, gb_free=21.6, wall=23006
2022-03-05 20:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:47:25 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.516 | nll_loss 12.847 | ppl 7369.64 | wps 46368.7 | wpb 510.9 | bsz 1 | num_updates 9733 | best_loss 8.953
2022-03-05 20:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9733 updates
2022-03-05 20:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 200 @ 9733 updates, score 13.516) (writing took 1.6142483185976744 seconds)
2022-03-05 20:47:26 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-05 20:47:26 | INFO | train | epoch 200 | loss 2.424 | nll_loss 0.594 | ppl 1.51 | wps 27090.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9733 | lr 0.000320536 | gnorm 0.674 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23085
2022-03-05 20:47:26 | INFO | fairseq.trainer | begin training epoch 201
2022-03-05 20:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:49:20 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.478 | nll_loss 12.806 | ppl 7160.13 | wps 46533.2 | wpb 510.9 | bsz 1 | num_updates 9782 | best_loss 8.953
2022-03-05 20:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9782 updates
2022-03-05 20:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 201 @ 9782 updates, score 13.478) (writing took 1.6732095815241337 seconds)
2022-03-05 20:49:21 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-05 20:49:21 | INFO | train | epoch 201 | loss 2.422 | nll_loss 0.593 | ppl 1.51 | wps 27631.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9782 | lr 0.000319732 | gnorm 0.664 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23200
2022-03-05 20:49:21 | INFO | fairseq.trainer | begin training epoch 202
2022-03-05 20:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:50:02 | INFO | train_inner | epoch 202:     18 / 49 loss=2.422, nll_loss=0.592, ppl=1.51, wps=27686.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.666, loss_scale=16, train_wall=199, gb_free=21.6, wall=23240
2022-03-05 20:51:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:51:14 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.518 | nll_loss 12.851 | ppl 7388.18 | wps 46282.2 | wpb 510.9 | bsz 1 | num_updates 9831 | best_loss 8.953
2022-03-05 20:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9831 updates
2022-03-05 20:51:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:51:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 202 @ 9831 updates, score 13.518) (writing took 1.6864926498383284 seconds)
2022-03-05 20:51:16 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-05 20:51:16 | INFO | train | epoch 202 | loss 2.418 | nll_loss 0.589 | ppl 1.5 | wps 27657.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9831 | lr 0.000318934 | gnorm 0.669 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 23315
2022-03-05 20:51:16 | INFO | fairseq.trainer | begin training epoch 203
2022-03-05 20:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:51:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:53:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:53:09 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.561 | nll_loss 12.893 | ppl 7606.93 | wps 46271.3 | wpb 510.9 | bsz 1 | num_updates 9879 | best_loss 8.953
2022-03-05 20:53:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9879 updates
2022-03-05 20:53:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 203 @ 9879 updates, score 13.561) (writing took 1.6321645937860012 seconds)
2022-03-05 20:53:11 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-05 20:53:11 | INFO | train | epoch 203 | loss 2.416 | nll_loss 0.587 | ppl 1.5 | wps 27106.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9879 | lr 0.000318158 | gnorm 0.672 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23430
2022-03-05 20:53:11 | INFO | fairseq.trainer | begin training epoch 204
2022-03-05 20:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:53:58 | INFO | train_inner | epoch 204:     21 / 49 loss=2.416, nll_loss=0.587, ppl=1.5, wps=27432.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.669, loss_scale=16, train_wall=201, gb_free=21.6, wall=23477
2022-03-05 20:55:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:55:04 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.527 | nll_loss 12.86 | ppl 7433.52 | wps 46379.1 | wpb 510.9 | bsz 1 | num_updates 9928 | best_loss 8.953
2022-03-05 20:55:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9928 updates
2022-03-05 20:55:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 204 @ 9928 updates, score 13.527) (writing took 1.6477309511974454 seconds)
2022-03-05 20:55:06 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-05 20:55:06 | INFO | train | epoch 204 | loss 2.412 | nll_loss 0.583 | ppl 1.5 | wps 27638.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 9928 | lr 0.000317372 | gnorm 0.655 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23545
2022-03-05 20:55:06 | INFO | fairseq.trainer | begin training epoch 205
2022-03-05 20:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:56:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 20:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:56:59 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.579 | nll_loss 12.922 | ppl 7762.78 | wps 46702.4 | wpb 510.9 | bsz 1 | num_updates 9976 | best_loss 8.953
2022-03-05 20:56:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9976 updates
2022-03-05 20:56:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:57:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:57:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 205 @ 9976 updates, score 13.579) (writing took 1.6363639207556844 seconds)
2022-03-05 20:57:01 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-05 20:57:01 | INFO | train | epoch 205 | loss 2.409 | nll_loss 0.581 | ppl 1.5 | wps 27111.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 9976 | lr 0.000316608 | gnorm 0.644 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23659
2022-03-05 20:57:01 | INFO | fairseq.trainer | begin training epoch 206
2022-03-05 20:57:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 20:57:55 | INFO | train_inner | epoch 206:     24 / 49 loss=2.41, nll_loss=0.582, ppl=1.5, wps=27425.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.649, loss_scale=16, train_wall=201, gb_free=21.6, wall=23713
2022-03-05 20:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 20:58:54 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.545 | nll_loss 12.879 | ppl 7532 | wps 46669.5 | wpb 510.9 | bsz 1 | num_updates 10025 | best_loss 8.953
2022-03-05 20:58:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10025 updates
2022-03-05 20:58:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:58:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 20:58:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 206 @ 10025 updates, score 13.545) (writing took 1.6694841897115111 seconds)
2022-03-05 20:58:56 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-05 20:58:56 | INFO | train | epoch 206 | loss 2.408 | nll_loss 0.58 | ppl 1.5 | wps 27653.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10025 | lr 0.000315833 | gnorm 0.65 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23774
2022-03-05 20:58:56 | INFO | fairseq.trainer | begin training epoch 207
2022-03-05 20:58:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:00:49 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.478 | nll_loss 12.811 | ppl 7188.46 | wps 46223 | wpb 510.9 | bsz 1 | num_updates 10074 | best_loss 8.953
2022-03-05 21:00:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10074 updates
2022-03-05 21:00:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:00:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:00:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 207 @ 10074 updates, score 13.478) (writing took 1.626345282420516 seconds)
2022-03-05 21:00:51 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-05 21:00:51 | INFO | train | epoch 207 | loss 2.404 | nll_loss 0.577 | ppl 1.49 | wps 27667.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10074 | lr 0.000315064 | gnorm 0.65 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 23889
2022-03-05 21:00:51 | INFO | fairseq.trainer | begin training epoch 208
2022-03-05 21:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:01:49 | INFO | train_inner | epoch 208:     26 / 49 loss=2.405, nll_loss=0.577, ppl=1.49, wps=27704.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.649, loss_scale=32, train_wall=199, gb_free=21.6, wall=23947
2022-03-05 21:02:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:02:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:02:44 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.556 | nll_loss 12.884 | ppl 7560.32 | wps 46365.4 | wpb 510.9 | bsz 1 | num_updates 10122 | best_loss 8.953
2022-03-05 21:02:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10122 updates
2022-03-05 21:02:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 208 @ 10122 updates, score 13.556) (writing took 1.6931546805426478 seconds)
2022-03-05 21:02:45 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-05 21:02:45 | INFO | train | epoch 208 | loss 2.401 | nll_loss 0.575 | ppl 1.49 | wps 27081.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10122 | lr 0.000314316 | gnorm 0.647 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24004
2022-03-05 21:02:46 | INFO | fairseq.trainer | begin training epoch 209
2022-03-05 21:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:04:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:04:39 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.492 | nll_loss 12.826 | ppl 7259.98 | wps 46502.8 | wpb 510.9 | bsz 1 | num_updates 10171 | best_loss 8.953
2022-03-05 21:04:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10171 updates
2022-03-05 21:04:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 209 @ 10171 updates, score 13.492) (writing took 1.6222294587641954 seconds)
2022-03-05 21:04:40 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-05 21:04:40 | INFO | train | epoch 209 | loss 2.398 | nll_loss 0.571 | ppl 1.49 | wps 27682.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10171 | lr 0.000313558 | gnorm 0.644 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24119
2022-03-05 21:04:40 | INFO | fairseq.trainer | begin training epoch 210
2022-03-05 21:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:05:45 | INFO | train_inner | epoch 210:     29 / 49 loss=2.398, nll_loss=0.571, ppl=1.49, wps=27439.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.642, loss_scale=16, train_wall=201, gb_free=21.6, wall=24184
2022-03-05 21:06:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:06:34 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.609 | nll_loss 12.952 | ppl 7921.34 | wps 46523.3 | wpb 510.9 | bsz 1 | num_updates 10220 | best_loss 8.953
2022-03-05 21:06:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10220 updates
2022-03-05 21:06:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:06:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:06:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 210 @ 10220 updates, score 13.609) (writing took 1.6135650873184204 seconds)
2022-03-05 21:06:35 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-05 21:06:35 | INFO | train | epoch 210 | loss 2.395 | nll_loss 0.569 | ppl 1.48 | wps 27672.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10220 | lr 0.000312806 | gnorm 0.643 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24234
2022-03-05 21:06:35 | INFO | fairseq.trainer | begin training epoch 211
2022-03-05 21:06:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:08:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:08:28 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.522 | nll_loss 12.859 | ppl 7429.14 | wps 46427.2 | wpb 510.9 | bsz 1 | num_updates 10268 | best_loss 8.953
2022-03-05 21:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10268 updates
2022-03-05 21:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:08:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:08:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 211 @ 10268 updates, score 13.522) (writing took 1.6668707141652703 seconds)
2022-03-05 21:08:30 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-05 21:08:30 | INFO | train | epoch 211 | loss 2.392 | nll_loss 0.566 | ppl 1.48 | wps 27095.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10268 | lr 0.000312074 | gnorm 0.645 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24349
2022-03-05 21:08:30 | INFO | fairseq.trainer | begin training epoch 212
2022-03-05 21:08:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:09:42 | INFO | train_inner | epoch 212:     32 / 49 loss=2.393, nll_loss=0.566, ppl=1.48, wps=27418.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.646, loss_scale=16, train_wall=201, gb_free=21.6, wall=24420
2022-03-05 21:10:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:10:23 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.484 | nll_loss 12.821 | ppl 7234.38 | wps 46440.5 | wpb 510.9 | bsz 1 | num_updates 10317 | best_loss 8.953
2022-03-05 21:10:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10317 updates
2022-03-05 21:10:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:10:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:10:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 212 @ 10317 updates, score 13.484) (writing took 1.6149991685524583 seconds)
2022-03-05 21:10:25 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-05 21:10:25 | INFO | train | epoch 212 | loss 2.391 | nll_loss 0.565 | ppl 1.48 | wps 27652.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10317 | lr 0.000311332 | gnorm 0.652 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24464
2022-03-05 21:10:25 | INFO | fairseq.trainer | begin training epoch 213
2022-03-05 21:10:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:12:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:12:18 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.555 | nll_loss 12.897 | ppl 7629.98 | wps 46325.5 | wpb 510.9 | bsz 1 | num_updates 10366 | best_loss 8.953
2022-03-05 21:12:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10366 updates
2022-03-05 21:12:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:12:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 213 @ 10366 updates, score 13.555) (writing took 1.6258338997140527 seconds)
2022-03-05 21:12:20 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-05 21:12:20 | INFO | train | epoch 213 | loss 2.387 | nll_loss 0.561 | ppl 1.48 | wps 27642.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10366 | lr 0.000310595 | gnorm 0.648 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24579
2022-03-05 21:12:20 | INFO | fairseq.trainer | begin training epoch 214
2022-03-05 21:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:13:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:13:38 | INFO | train_inner | epoch 214:     35 / 49 loss=2.387, nll_loss=0.561, ppl=1.48, wps=27435.4, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.648, loss_scale=16, train_wall=201, gb_free=21.6, wall=24657
2022-03-05 21:14:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:14:13 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.517 | nll_loss 12.854 | ppl 7402.72 | wps 46592.6 | wpb 510.9 | bsz 1 | num_updates 10414 | best_loss 8.953
2022-03-05 21:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10414 updates
2022-03-05 21:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:14:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:14:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 214 @ 10414 updates, score 13.517) (writing took 1.6306253764778376 seconds)
2022-03-05 21:14:15 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-05 21:14:15 | INFO | train | epoch 214 | loss 2.383 | nll_loss 0.557 | ppl 1.47 | wps 27114 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10414 | lr 0.000309878 | gnorm 0.637 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24693
2022-03-05 21:14:15 | INFO | fairseq.trainer | begin training epoch 215
2022-03-05 21:14:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:16:08 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.579 | nll_loss 12.918 | ppl 7739.28 | wps 46519.4 | wpb 510.9 | bsz 1 | num_updates 10463 | best_loss 8.953
2022-03-05 21:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10463 updates
2022-03-05 21:16:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 215 @ 10463 updates, score 13.579) (writing took 1.6313390927389264 seconds)
2022-03-05 21:16:10 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-05 21:16:10 | INFO | train | epoch 215 | loss 2.382 | nll_loss 0.557 | ppl 1.47 | wps 27677.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10463 | lr 0.000309152 | gnorm 0.64 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24808
2022-03-05 21:16:10 | INFO | fairseq.trainer | begin training epoch 216
2022-03-05 21:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:17:32 | INFO | train_inner | epoch 216:     37 / 49 loss=2.38, nll_loss=0.555, ppl=1.47, wps=27703.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.633, loss_scale=16, train_wall=199, gb_free=21.6, wall=24891
2022-03-05 21:17:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:18:03 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.602 | nll_loss 12.952 | ppl 7925.17 | wps 46456.7 | wpb 510.9 | bsz 1 | num_updates 10512 | best_loss 8.953
2022-03-05 21:18:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10512 updates
2022-03-05 21:18:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:18:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:18:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 216 @ 10512 updates, score 13.602) (writing took 1.695271324366331 seconds)
2022-03-05 21:18:04 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-05 21:18:04 | INFO | train | epoch 216 | loss 2.379 | nll_loss 0.554 | ppl 1.47 | wps 27647.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10512 | lr 0.000308431 | gnorm 0.631 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 24923
2022-03-05 21:18:04 | INFO | fairseq.trainer | begin training epoch 217
2022-03-05 21:18:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:19:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:19:58 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.601 | nll_loss 12.95 | ppl 7910.67 | wps 46444.7 | wpb 510.9 | bsz 1 | num_updates 10561 | best_loss 8.953
2022-03-05 21:19:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10561 updates
2022-03-05 21:19:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:19:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 217 @ 10561 updates, score 13.601) (writing took 1.6455634292215109 seconds)
2022-03-05 21:19:59 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-05 21:19:59 | INFO | train | epoch 217 | loss 2.376 | nll_loss 0.552 | ppl 1.47 | wps 27649.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10561 | lr 0.000307714 | gnorm 0.633 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25038
2022-03-05 21:19:59 | INFO | fairseq.trainer | begin training epoch 218
2022-03-05 21:19:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:21:27 | INFO | train_inner | epoch 218:     39 / 49 loss=2.376, nll_loss=0.552, ppl=1.47, wps=27679.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.63, loss_scale=32, train_wall=199, gb_free=21.6, wall=25125
2022-03-05 21:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:21:53 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.476 | nll_loss 12.809 | ppl 7178.39 | wps 46646.3 | wpb 510.9 | bsz 1 | num_updates 10610 | best_loss 8.953
2022-03-05 21:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10610 updates
2022-03-05 21:21:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:21:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 218 @ 10610 updates, score 13.476) (writing took 1.6019034869968891 seconds)
2022-03-05 21:21:54 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-05 21:21:54 | INFO | train | epoch 218 | loss 2.374 | nll_loss 0.55 | ppl 1.46 | wps 27684.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10610 | lr 0.000307003 | gnorm 0.623 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25153
2022-03-05 21:21:54 | INFO | fairseq.trainer | begin training epoch 219
2022-03-05 21:21:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:21:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:23:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:23:47 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.598 | nll_loss 12.954 | ppl 7932.19 | wps 46443.7 | wpb 510.9 | bsz 1 | num_updates 10658 | best_loss 8.953
2022-03-05 21:23:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10658 updates
2022-03-05 21:23:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:23:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:23:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 219 @ 10658 updates, score 13.598) (writing took 1.6698031881824136 seconds)
2022-03-05 21:23:49 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-05 21:23:49 | INFO | train | epoch 219 | loss 2.373 | nll_loss 0.549 | ppl 1.46 | wps 27097.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10658 | lr 0.000306311 | gnorm 0.642 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25268
2022-03-05 21:23:49 | INFO | fairseq.trainer | begin training epoch 220
2022-03-05 21:23:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:25:23 | INFO | train_inner | epoch 220:     42 / 49 loss=2.371, nll_loss=0.548, ppl=1.46, wps=27436, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.629, loss_scale=16, train_wall=201, gb_free=21.6, wall=25362
2022-03-05 21:25:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:25:42 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.505 | nll_loss 12.851 | ppl 7385.98 | wps 46393.9 | wpb 510.9 | bsz 1 | num_updates 10707 | best_loss 8.953
2022-03-05 21:25:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10707 updates
2022-03-05 21:25:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:25:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:25:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 220 @ 10707 updates, score 13.505) (writing took 1.603824008256197 seconds)
2022-03-05 21:25:44 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-05 21:25:44 | INFO | train | epoch 220 | loss 2.367 | nll_loss 0.544 | ppl 1.46 | wps 27650.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10707 | lr 0.000305609 | gnorm 0.617 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 25383
2022-03-05 21:25:44 | INFO | fairseq.trainer | begin training epoch 221
2022-03-05 21:25:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:27:37 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.592 | nll_loss 12.95 | ppl 7915.25 | wps 46301.4 | wpb 510.9 | bsz 1 | num_updates 10756 | best_loss 8.953
2022-03-05 21:27:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10756 updates
2022-03-05 21:27:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:27:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:27:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 221 @ 10756 updates, score 13.592) (writing took 1.6500831982120872 seconds)
2022-03-05 21:27:39 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-05 21:27:39 | INFO | train | epoch 221 | loss 2.366 | nll_loss 0.543 | ppl 1.46 | wps 27648 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10756 | lr 0.000304912 | gnorm 0.62 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25498
2022-03-05 21:27:39 | INFO | fairseq.trainer | begin training epoch 222
2022-03-05 21:27:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:29:17 | INFO | train_inner | epoch 222:     44 / 49 loss=2.365, nll_loss=0.542, ppl=1.46, wps=27689.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.619, loss_scale=32, train_wall=199, gb_free=21.6, wall=25596
2022-03-05 21:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:29:32 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.479 | nll_loss 12.82 | ppl 7228.71 | wps 46487.6 | wpb 510.9 | bsz 1 | num_updates 10805 | best_loss 8.953
2022-03-05 21:29:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10805 updates
2022-03-05 21:29:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:29:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:29:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 222 @ 10805 updates, score 13.479) (writing took 1.6795179657638073 seconds)
2022-03-05 21:29:34 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-05 21:29:34 | INFO | train | epoch 222 | loss 2.364 | nll_loss 0.541 | ppl 1.46 | wps 27652.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10805 | lr 0.00030422 | gnorm 0.619 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25613
2022-03-05 21:29:34 | INFO | fairseq.trainer | begin training epoch 223
2022-03-05 21:29:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:31:27 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.6 | nll_loss 12.95 | ppl 7913.69 | wps 46183.3 | wpb 510.9 | bsz 1 | num_updates 10854 | best_loss 8.953
2022-03-05 21:31:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10854 updates
2022-03-05 21:31:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 223 @ 10854 updates, score 13.6) (writing took 1.6783275995403528 seconds)
2022-03-05 21:31:29 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-05 21:31:29 | INFO | train | epoch 223 | loss 2.361 | nll_loss 0.539 | ppl 1.45 | wps 27611.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10854 | lr 0.000303532 | gnorm 0.615 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25728
2022-03-05 21:31:29 | INFO | fairseq.trainer | begin training epoch 224
2022-03-05 21:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:31:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:33:14 | INFO | train_inner | epoch 224:     47 / 49 loss=2.36, nll_loss=0.538, ppl=1.45, wps=27411.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.619, loss_scale=32, train_wall=201, gb_free=21.6, wall=25833
2022-03-05 21:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:33:22 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.488 | nll_loss 12.827 | ppl 7266.87 | wps 46608.7 | wpb 510.9 | bsz 1 | num_updates 10902 | best_loss 8.953
2022-03-05 21:33:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10902 updates
2022-03-05 21:33:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:33:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:33:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 224 @ 10902 updates, score 13.488) (writing took 1.616636399179697 seconds)
2022-03-05 21:33:24 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-05 21:33:24 | INFO | train | epoch 224 | loss 2.358 | nll_loss 0.536 | ppl 1.45 | wps 27116.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10902 | lr 0.000302863 | gnorm 0.62 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25842
2022-03-05 21:33:24 | INFO | fairseq.trainer | begin training epoch 225
2022-03-05 21:33:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:35:17 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.562 | nll_loss 12.91 | ppl 7697.4 | wps 46485.4 | wpb 510.9 | bsz 1 | num_updates 10951 | best_loss 8.953
2022-03-05 21:35:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10951 updates
2022-03-05 21:35:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:35:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 225 @ 10951 updates, score 13.562) (writing took 1.5981747014448047 seconds)
2022-03-05 21:35:19 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-05 21:35:19 | INFO | train | epoch 225 | loss 2.355 | nll_loss 0.534 | ppl 1.45 | wps 27670.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 10951 | lr 0.000302185 | gnorm 0.607 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 25957
2022-03-05 21:35:19 | INFO | fairseq.trainer | begin training epoch 226
2022-03-05 21:35:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:36:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:37:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:37:12 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.465 | nll_loss 12.805 | ppl 7155.51 | wps 46404.8 | wpb 510.9 | bsz 1 | num_updates 10999 | best_loss 8.953
2022-03-05 21:37:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 10999 updates
2022-03-05 21:37:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:37:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 226 @ 10999 updates, score 13.465) (writing took 1.6720205340534449 seconds)
2022-03-05 21:37:14 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-05 21:37:14 | INFO | train | epoch 226 | loss 2.354 | nll_loss 0.532 | ppl 1.45 | wps 27089.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 10999 | lr 0.000301525 | gnorm 0.617 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26072
2022-03-05 21:37:14 | INFO | fairseq.trainer | begin training epoch 227
2022-03-05 21:37:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:37:16 | INFO | train_inner | epoch 227:      1 / 49 loss=2.355, nll_loss=0.533, ppl=1.45, wps=26695.6, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=11000, lr=0.000301511, gnorm=0.614, loss_scale=32, train_wall=200, gb_free=21.6, wall=26074
2022-03-05 21:37:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:39:07 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.548 | nll_loss 12.899 | ppl 7638.82 | wps 46341.8 | wpb 510.9 | bsz 1 | num_updates 11047 | best_loss 8.953
2022-03-05 21:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11047 updates
2022-03-05 21:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:39:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:39:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 227 @ 11047 updates, score 13.548) (writing took 1.6203186782076955 seconds)
2022-03-05 21:39:08 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-05 21:39:08 | INFO | train | epoch 227 | loss 2.352 | nll_loss 0.531 | ppl 1.44 | wps 27122.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11047 | lr 0.000300869 | gnorm 0.62 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26187
2022-03-05 21:39:08 | INFO | fairseq.trainer | begin training epoch 228
2022-03-05 21:39:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:40:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:41:01 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.605 | nll_loss 12.968 | ppl 8010.12 | wps 46390.1 | wpb 510.9 | bsz 1 | num_updates 11096 | best_loss 8.953
2022-03-05 21:41:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11096 updates
2022-03-05 21:41:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 228 @ 11096 updates, score 13.605) (writing took 1.6669591469690204 seconds)
2022-03-05 21:41:03 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-05 21:41:03 | INFO | train | epoch 228 | loss 2.349 | nll_loss 0.528 | ppl 1.44 | wps 27669.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11096 | lr 0.000300204 | gnorm 0.605 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26302
2022-03-05 21:41:03 | INFO | fairseq.trainer | begin training epoch 229
2022-03-05 21:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:41:12 | INFO | train_inner | epoch 229:      4 / 49 loss=2.35, nll_loss=0.529, ppl=1.44, wps=27452, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11100, lr=0.00030015, gnorm=0.611, loss_scale=16, train_wall=201, gb_free=21.6, wall=26311
2022-03-05 21:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:42:56 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.582 | nll_loss 12.936 | ppl 7837.23 | wps 46309 | wpb 510.9 | bsz 1 | num_updates 11145 | best_loss 8.953
2022-03-05 21:42:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11145 updates
2022-03-05 21:42:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 229 @ 11145 updates, score 13.582) (writing took 1.6349172526970506 seconds)
2022-03-05 21:42:58 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-05 21:42:58 | INFO | train | epoch 229 | loss 2.347 | nll_loss 0.527 | ppl 1.44 | wps 27650 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11145 | lr 0.000299544 | gnorm 0.605 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26417
2022-03-05 21:42:58 | INFO | fairseq.trainer | begin training epoch 230
2022-03-05 21:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:44:51 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.673 | nll_loss 13.041 | ppl 8426.6 | wps 46456.6 | wpb 510.9 | bsz 1 | num_updates 11194 | best_loss 8.953
2022-03-05 21:44:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11194 updates
2022-03-05 21:44:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:44:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:44:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 230 @ 11194 updates, score 13.673) (writing took 1.6315505169332027 seconds)
2022-03-05 21:44:53 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-05 21:44:53 | INFO | train | epoch 230 | loss 2.346 | nll_loss 0.526 | ppl 1.44 | wps 27686.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11194 | lr 0.000298887 | gnorm 0.616 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26531
2022-03-05 21:44:53 | INFO | fairseq.trainer | begin training epoch 231
2022-03-05 21:44:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:45:06 | INFO | train_inner | epoch 231:      6 / 49 loss=2.346, nll_loss=0.526, ppl=1.44, wps=27700.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.612, loss_scale=32, train_wall=199, gb_free=21.6, wall=26545
2022-03-05 21:46:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:46:46 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.587 | nll_loss 12.938 | ppl 7848.11 | wps 46471 | wpb 510.9 | bsz 1 | num_updates 11243 | best_loss 8.953
2022-03-05 21:46:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11243 updates
2022-03-05 21:46:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:46:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:46:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 231 @ 11243 updates, score 13.587) (writing took 1.6703598806634545 seconds)
2022-03-05 21:46:48 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-05 21:46:48 | INFO | train | epoch 231 | loss 2.343 | nll_loss 0.524 | ppl 1.44 | wps 27665.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11243 | lr 0.000298235 | gnorm 0.609 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26646
2022-03-05 21:46:48 | INFO | fairseq.trainer | begin training epoch 232
2022-03-05 21:46:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:47:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 21:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:48:41 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.536 | nll_loss 12.88 | ppl 7539.07 | wps 46310.1 | wpb 510.9 | bsz 1 | num_updates 11291 | best_loss 8.953
2022-03-05 21:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11291 updates
2022-03-05 21:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 232 @ 11291 updates, score 13.536) (writing took 1.686758317053318 seconds)
2022-03-05 21:48:43 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-05 21:48:43 | INFO | train | epoch 232 | loss 2.34 | nll_loss 0.52 | ppl 1.43 | wps 27089.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11291 | lr 0.000297601 | gnorm 0.595 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 26761
2022-03-05 21:48:43 | INFO | fairseq.trainer | begin training epoch 233
2022-03-05 21:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:48:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:49:05 | INFO | train_inner | epoch 233:     10 / 49 loss=2.341, nll_loss=0.521, ppl=1.44, wps=27176.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.603, loss_scale=16, train_wall=203, gb_free=21.6, wall=26784
2022-03-05 21:50:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:50:36 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.479 | nll_loss 12.818 | ppl 7221.61 | wps 46544.8 | wpb 510.9 | bsz 1 | num_updates 11339 | best_loss 8.953
2022-03-05 21:50:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11339 updates
2022-03-05 21:50:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:50:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 233 @ 11339 updates, score 13.479) (writing took 1.636643654666841 seconds)
2022-03-05 21:50:38 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-05 21:50:38 | INFO | train | epoch 233 | loss 2.339 | nll_loss 0.519 | ppl 1.43 | wps 27090.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11339 | lr 0.00029697 | gnorm 0.609 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26876
2022-03-05 21:50:38 | INFO | fairseq.trainer | begin training epoch 234
2022-03-05 21:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:52:31 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.522 | nll_loss 12.877 | ppl 7522.95 | wps 46256 | wpb 510.9 | bsz 1 | num_updates 11388 | best_loss 8.953
2022-03-05 21:52:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11388 updates
2022-03-05 21:52:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:52:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:52:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 234 @ 11388 updates, score 13.522) (writing took 1.6165922041982412 seconds)
2022-03-05 21:52:32 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-05 21:52:32 | INFO | train | epoch 234 | loss 2.336 | nll_loss 0.517 | ppl 1.43 | wps 27660.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11388 | lr 0.00029633 | gnorm 0.61 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 26991
2022-03-05 21:52:32 | INFO | fairseq.trainer | begin training epoch 235
2022-03-05 21:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:52:59 | INFO | train_inner | epoch 235:     12 / 49 loss=2.336, nll_loss=0.517, ppl=1.43, wps=27687.8, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.604, loss_scale=16, train_wall=199, gb_free=21.6, wall=27018
2022-03-05 21:54:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:54:26 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.576 | nll_loss 12.933 | ppl 7821.17 | wps 46162.2 | wpb 510.9 | bsz 1 | num_updates 11437 | best_loss 8.953
2022-03-05 21:54:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11437 updates
2022-03-05 21:54:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 235 @ 11437 updates, score 13.576) (writing took 1.6100589511916041 seconds)
2022-03-05 21:54:27 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-05 21:54:27 | INFO | train | epoch 235 | loss 2.333 | nll_loss 0.514 | ppl 1.43 | wps 27653.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11437 | lr 0.000295695 | gnorm 0.59 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27106
2022-03-05 21:54:27 | INFO | fairseq.trainer | begin training epoch 236
2022-03-05 21:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:56:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:56:21 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.619 | nll_loss 12.974 | ppl 8048.31 | wps 46276.4 | wpb 510.9 | bsz 1 | num_updates 11486 | best_loss 8.953
2022-03-05 21:56:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11486 updates
2022-03-05 21:56:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:56:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:56:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 236 @ 11486 updates, score 13.619) (writing took 1.6167948208749294 seconds)
2022-03-05 21:56:22 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-05 21:56:22 | INFO | train | epoch 236 | loss 2.333 | nll_loss 0.515 | ppl 1.43 | wps 27652.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11486 | lr 0.000295064 | gnorm 0.608 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27221
2022-03-05 21:56:22 | INFO | fairseq.trainer | begin training epoch 237
2022-03-05 21:56:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 21:56:54 | INFO | train_inner | epoch 237:     14 / 49 loss=2.333, nll_loss=0.514, ppl=1.43, wps=27685.4, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.599, loss_scale=32, train_wall=199, gb_free=21.6, wall=27252
2022-03-05 21:57:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 21:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 21:58:16 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.479 | nll_loss 12.826 | ppl 7262.11 | wps 46593.9 | wpb 510.9 | bsz 1 | num_updates 11534 | best_loss 8.953
2022-03-05 21:58:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11534 updates
2022-03-05 21:58:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:58:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 21:58:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 237 @ 11534 updates, score 13.479) (writing took 1.604251017794013 seconds)
2022-03-05 21:58:17 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-05 21:58:17 | INFO | train | epoch 237 | loss 2.329 | nll_loss 0.511 | ppl 1.42 | wps 27091.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11534 | lr 0.000294449 | gnorm 0.594 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27336
2022-03-05 21:58:17 | INFO | fairseq.trainer | begin training epoch 238
2022-03-05 21:58:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:00:10 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.644 | nll_loss 13.008 | ppl 8239.19 | wps 46345.8 | wpb 510.9 | bsz 1 | num_updates 11583 | best_loss 8.953
2022-03-05 22:00:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11583 updates
2022-03-05 22:00:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:00:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:00:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 238 @ 11583 updates, score 13.644) (writing took 1.680138242430985 seconds)
2022-03-05 22:00:12 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-05 22:00:12 | INFO | train | epoch 238 | loss 2.327 | nll_loss 0.51 | ppl 1.42 | wps 27655.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11583 | lr 0.000293825 | gnorm 0.596 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27451
2022-03-05 22:00:12 | INFO | fairseq.trainer | begin training epoch 239
2022-03-05 22:00:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:00:50 | INFO | train_inner | epoch 239:     17 / 49 loss=2.327, nll_loss=0.509, ppl=1.42, wps=27430.2, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.598, loss_scale=16, train_wall=201, gb_free=21.6, wall=27489
2022-03-05 22:02:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:02:05 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.539 | nll_loss 12.892 | ppl 7600.97 | wps 46405.9 | wpb 510.9 | bsz 1 | num_updates 11632 | best_loss 8.953
2022-03-05 22:02:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11632 updates
2022-03-05 22:02:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:02:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:02:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 239 @ 11632 updates, score 13.539) (writing took 1.6433407813310623 seconds)
2022-03-05 22:02:07 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-05 22:02:07 | INFO | train | epoch 239 | loss 2.325 | nll_loss 0.508 | ppl 1.42 | wps 27629.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11632 | lr 0.000293206 | gnorm 0.594 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 27566
2022-03-05 22:02:07 | INFO | fairseq.trainer | begin training epoch 240
2022-03-05 22:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:04:00 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.589 | nll_loss 12.941 | ppl 7864.29 | wps 46405.9 | wpb 510.9 | bsz 1 | num_updates 11681 | best_loss 8.953
2022-03-05 22:04:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11681 updates
2022-03-05 22:04:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:04:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 240 @ 11681 updates, score 13.589) (writing took 1.6311211669817567 seconds)
2022-03-05 22:04:02 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-05 22:04:02 | INFO | train | epoch 240 | loss 2.323 | nll_loss 0.506 | ppl 1.42 | wps 27681 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11681 | lr 0.00029259 | gnorm 0.58 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27681
2022-03-05 22:04:02 | INFO | fairseq.trainer | begin training epoch 241
2022-03-05 22:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:04:44 | INFO | train_inner | epoch 241:     19 / 49 loss=2.323, nll_loss=0.506, ppl=1.42, wps=27690.2, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.583, loss_scale=32, train_wall=199, gb_free=21.6, wall=27723
2022-03-05 22:05:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:05:55 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.493 | nll_loss 12.844 | ppl 7353.26 | wps 46525.8 | wpb 510.9 | bsz 1 | num_updates 11730 | best_loss 8.953
2022-03-05 22:05:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11730 updates
2022-03-05 22:05:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:05:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:05:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 241 @ 11730 updates, score 13.493) (writing took 1.5987847046926618 seconds)
2022-03-05 22:05:57 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-05 22:05:57 | INFO | train | epoch 241 | loss 2.322 | nll_loss 0.505 | ppl 1.42 | wps 27691.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11730 | lr 0.000291979 | gnorm 0.592 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27795
2022-03-05 22:05:57 | INFO | fairseq.trainer | begin training epoch 242
2022-03-05 22:05:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:07:50 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.573 | nll_loss 12.926 | ppl 7780.13 | wps 46526.1 | wpb 510.9 | bsz 1 | num_updates 11779 | best_loss 8.953
2022-03-05 22:07:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11779 updates
2022-03-05 22:07:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:07:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:07:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 242 @ 11779 updates, score 13.573) (writing took 1.6041633794084191 seconds)
2022-03-05 22:07:51 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-05 22:07:51 | INFO | train | epoch 242 | loss 2.32 | nll_loss 0.504 | ppl 1.42 | wps 27684.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11779 | lr 0.000291371 | gnorm 0.587 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 27910
2022-03-05 22:07:51 | INFO | fairseq.trainer | begin training epoch 243
2022-03-05 22:07:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:08:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:08:41 | INFO | train_inner | epoch 243:     22 / 49 loss=2.32, nll_loss=0.504, ppl=1.42, wps=27465, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.588, loss_scale=32, train_wall=201, gb_free=21.6, wall=27959
2022-03-05 22:09:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:09:45 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.575 | nll_loss 12.932 | ppl 7817.45 | wps 46325.4 | wpb 510.9 | bsz 1 | num_updates 11827 | best_loss 8.953
2022-03-05 22:09:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11827 updates
2022-03-05 22:09:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:09:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:09:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 243 @ 11827 updates, score 13.575) (writing took 1.6481421906501055 seconds)
2022-03-05 22:09:46 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-05 22:09:46 | INFO | train | epoch 243 | loss 2.318 | nll_loss 0.501 | ppl 1.42 | wps 27097.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11827 | lr 0.000290779 | gnorm 0.58 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28025
2022-03-05 22:09:46 | INFO | fairseq.trainer | begin training epoch 244
2022-03-05 22:09:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:11:39 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.563 | nll_loss 12.926 | ppl 7783.64 | wps 46469.7 | wpb 510.9 | bsz 1 | num_updates 11875 | best_loss 8.953
2022-03-05 22:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11875 updates
2022-03-05 22:11:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:11:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 244 @ 11875 updates, score 13.563) (writing took 1.6354219987988472 seconds)
2022-03-05 22:11:41 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-05 22:11:41 | INFO | train | epoch 244 | loss 2.316 | nll_loss 0.5 | ppl 1.41 | wps 27128.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 11875 | lr 0.000290191 | gnorm 0.592 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28140
2022-03-05 22:11:41 | INFO | fairseq.trainer | begin training epoch 245
2022-03-05 22:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:12:37 | INFO | train_inner | epoch 245:     25 / 49 loss=2.316, nll_loss=0.5, ppl=1.41, wps=27438.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.588, loss_scale=16, train_wall=201, gb_free=21.6, wall=28196
2022-03-05 22:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:13:34 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.662 | nll_loss 13.034 | ppl 8384.64 | wps 46349 | wpb 510.9 | bsz 1 | num_updates 11924 | best_loss 8.953
2022-03-05 22:13:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11924 updates
2022-03-05 22:13:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 245 @ 11924 updates, score 13.662) (writing took 1.6256671426817775 seconds)
2022-03-05 22:13:36 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-05 22:13:36 | INFO | train | epoch 245 | loss 2.315 | nll_loss 0.499 | ppl 1.41 | wps 27635.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11924 | lr 0.000289594 | gnorm 0.594 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28255
2022-03-05 22:13:36 | INFO | fairseq.trainer | begin training epoch 246
2022-03-05 22:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:15:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:15:29 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.557 | nll_loss 12.915 | ppl 7724.33 | wps 46507.4 | wpb 510.9 | bsz 1 | num_updates 11973 | best_loss 8.953
2022-03-05 22:15:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11973 updates
2022-03-05 22:15:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:15:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:15:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 246 @ 11973 updates, score 13.557) (writing took 1.6757482877001166 seconds)
2022-03-05 22:15:31 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-05 22:15:31 | INFO | train | epoch 246 | loss 2.312 | nll_loss 0.497 | ppl 1.41 | wps 27668.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 11973 | lr 0.000289 | gnorm 0.584 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28370
2022-03-05 22:15:31 | INFO | fairseq.trainer | begin training epoch 247
2022-03-05 22:15:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:16:31 | INFO | train_inner | epoch 247:     27 / 49 loss=2.312, nll_loss=0.497, ppl=1.41, wps=27682.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.585, loss_scale=32, train_wall=199, gb_free=21.6, wall=28430
2022-03-05 22:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:17:24 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.669 | nll_loss 13.038 | ppl 8410.34 | wps 46423.4 | wpb 510.9 | bsz 1 | num_updates 12022 | best_loss 8.953
2022-03-05 22:17:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12022 updates
2022-03-05 22:17:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:17:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:17:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 247 @ 12022 updates, score 13.669) (writing took 1.6406027767807245 seconds)
2022-03-05 22:17:26 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-05 22:17:26 | INFO | train | epoch 247 | loss 2.31 | nll_loss 0.495 | ppl 1.41 | wps 27642.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12022 | lr 0.000288411 | gnorm 0.582 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28485
2022-03-05 22:17:26 | INFO | fairseq.trainer | begin training epoch 248
2022-03-05 22:17:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:19:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:19:19 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.574 | nll_loss 12.933 | ppl 7820.72 | wps 46333.2 | wpb 510.9 | bsz 1 | num_updates 12071 | best_loss 8.953
2022-03-05 22:19:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12071 updates
2022-03-05 22:19:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:19:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 248 @ 12071 updates, score 13.574) (writing took 1.7146362597122788 seconds)
2022-03-05 22:19:21 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-05 22:19:21 | INFO | train | epoch 248 | loss 2.309 | nll_loss 0.494 | ppl 1.41 | wps 27633.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12071 | lr 0.000287825 | gnorm 0.583 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28600
2022-03-05 22:19:21 | INFO | fairseq.trainer | begin training epoch 249
2022-03-05 22:19:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:20:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:20:28 | INFO | train_inner | epoch 249:     30 / 49 loss=2.308, nll_loss=0.493, ppl=1.41, wps=27411.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.581, loss_scale=32, train_wall=201, gb_free=21.6, wall=28667
2022-03-05 22:21:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:21:14 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.673 | nll_loss 13.041 | ppl 8430.04 | wps 46384.4 | wpb 510.9 | bsz 1 | num_updates 12119 | best_loss 8.953
2022-03-05 22:21:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12119 updates
2022-03-05 22:21:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:21:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:21:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 249 @ 12119 updates, score 13.673) (writing took 1.6246664691716433 seconds)
2022-03-05 22:21:16 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-05 22:21:16 | INFO | train | epoch 249 | loss 2.306 | nll_loss 0.492 | ppl 1.41 | wps 27082.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12119 | lr 0.000287254 | gnorm 0.574 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 28714
2022-03-05 22:21:16 | INFO | fairseq.trainer | begin training epoch 250
2022-03-05 22:21:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:22:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:23:09 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.533 | nll_loss 12.89 | ppl 7591.38 | wps 46406.7 | wpb 510.9 | bsz 1 | num_updates 12167 | best_loss 8.953
2022-03-05 22:23:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12167 updates
2022-03-05 22:23:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:23:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:23:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 250 @ 12167 updates, score 13.533) (writing took 1.651851906441152 seconds)
2022-03-05 22:23:11 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-05 22:23:11 | INFO | train | epoch 250 | loss 2.305 | nll_loss 0.491 | ppl 1.41 | wps 27084.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12167 | lr 0.000286687 | gnorm 0.597 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28829
2022-03-05 22:23:11 | INFO | fairseq.trainer | begin training epoch 251
2022-03-05 22:23:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:24:25 | INFO | train_inner | epoch 251:     33 / 49 loss=2.305, nll_loss=0.491, ppl=1.41, wps=27416.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.59, loss_scale=16, train_wall=201, gb_free=21.6, wall=28903
2022-03-05 22:24:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:25:04 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.507 | nll_loss 12.864 | ppl 7454.2 | wps 45971.4 | wpb 510.9 | bsz 1 | num_updates 12216 | best_loss 8.953
2022-03-05 22:25:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12216 updates
2022-03-05 22:25:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:25:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:25:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 251 @ 12216 updates, score 13.507) (writing took 1.6862381203100085 seconds)
2022-03-05 22:25:06 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-05 22:25:06 | INFO | train | epoch 251 | loss 2.302 | nll_loss 0.488 | ppl 1.4 | wps 27614.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12216 | lr 0.000286112 | gnorm 0.576 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 28944
2022-03-05 22:25:06 | INFO | fairseq.trainer | begin training epoch 252
2022-03-05 22:25:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:26:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:26:59 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.511 | nll_loss 12.865 | ppl 7459.03 | wps 46323.2 | wpb 510.9 | bsz 1 | num_updates 12265 | best_loss 8.953
2022-03-05 22:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12265 updates
2022-03-05 22:26:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:27:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:27:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 252 @ 12265 updates, score 13.511) (writing took 1.648189114406705 seconds)
2022-03-05 22:27:01 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-05 22:27:01 | INFO | train | epoch 252 | loss 2.301 | nll_loss 0.488 | ppl 1.4 | wps 27643 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12265 | lr 0.00028554 | gnorm 0.582 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29059
2022-03-05 22:27:01 | INFO | fairseq.trainer | begin training epoch 253
2022-03-05 22:27:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:28:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-05 22:28:21 | INFO | train_inner | epoch 253:     36 / 49 loss=2.301, nll_loss=0.488, ppl=1.4, wps=27403.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.578, loss_scale=16, train_wall=201, gb_free=21.6, wall=29140
2022-03-05 22:28:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:28:54 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.518 | nll_loss 12.877 | ppl 7521.85 | wps 46304.9 | wpb 510.9 | bsz 1 | num_updates 12313 | best_loss 8.953
2022-03-05 22:28:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12313 updates
2022-03-05 22:28:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:28:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:28:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 253 @ 12313 updates, score 13.518) (writing took 1.640914068557322 seconds)
2022-03-05 22:28:56 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-05 22:28:56 | INFO | train | epoch 253 | loss 2.299 | nll_loss 0.485 | ppl 1.4 | wps 27073.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12313 | lr 0.000284982 | gnorm 0.579 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29174
2022-03-05 22:28:56 | INFO | fairseq.trainer | begin training epoch 254
2022-03-05 22:28:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:30:49 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.483 | nll_loss 12.833 | ppl 7294.47 | wps 46463.6 | wpb 510.9 | bsz 1 | num_updates 12362 | best_loss 8.953
2022-03-05 22:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12362 updates
2022-03-05 22:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:30:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:30:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 254 @ 12362 updates, score 13.483) (writing took 1.6759186293929815 seconds)
2022-03-05 22:30:51 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-05 22:30:51 | INFO | train | epoch 254 | loss 2.298 | nll_loss 0.485 | ppl 1.4 | wps 27677.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12362 | lr 0.000284417 | gnorm 0.574 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29289
2022-03-05 22:30:51 | INFO | fairseq.trainer | begin training epoch 255
2022-03-05 22:30:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:32:16 | INFO | train_inner | epoch 255:     38 / 49 loss=2.297, nll_loss=0.485, ppl=1.4, wps=27685.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.578, loss_scale=16, train_wall=199, gb_free=21.6, wall=29374
2022-03-05 22:32:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:32:44 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.626 | nll_loss 12.998 | ppl 8179.26 | wps 46483.2 | wpb 510.9 | bsz 1 | num_updates 12411 | best_loss 8.953
2022-03-05 22:32:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12411 updates
2022-03-05 22:32:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:32:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:32:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 255 @ 12411 updates, score 13.626) (writing took 1.6873923586681485 seconds)
2022-03-05 22:32:46 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-05 22:32:46 | INFO | train | epoch 255 | loss 2.297 | nll_loss 0.484 | ppl 1.4 | wps 27629 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12411 | lr 0.000283855 | gnorm 0.581 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 29404
2022-03-05 22:32:46 | INFO | fairseq.trainer | begin training epoch 256
2022-03-05 22:32:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:34:39 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.487 | nll_loss 12.841 | ppl 7337.4 | wps 46451.9 | wpb 510.9 | bsz 1 | num_updates 12460 | best_loss 8.953
2022-03-05 22:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12460 updates
2022-03-05 22:34:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 256 @ 12460 updates, score 13.487) (writing took 1.6700558178126812 seconds)
2022-03-05 22:34:41 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-05 22:34:41 | INFO | train | epoch 256 | loss 2.294 | nll_loss 0.482 | ppl 1.4 | wps 27653.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12460 | lr 0.000283296 | gnorm 0.569 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29519
2022-03-05 22:34:41 | INFO | fairseq.trainer | begin training epoch 257
2022-03-05 22:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:36:10 | INFO | train_inner | epoch 257:     40 / 49 loss=2.294, nll_loss=0.481, ppl=1.4, wps=27695.7, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.574, loss_scale=32, train_wall=199, gb_free=21.6, wall=29609
2022-03-05 22:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:36:34 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.47 | nll_loss 12.833 | ppl 7294.45 | wps 46355.7 | wpb 510.9 | bsz 1 | num_updates 12509 | best_loss 8.953
2022-03-05 22:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12509 updates
2022-03-05 22:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:36:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:36:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 257 @ 12509 updates, score 13.47) (writing took 1.6455404106527567 seconds)
2022-03-05 22:36:35 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-05 22:36:35 | INFO | train | epoch 257 | loss 2.293 | nll_loss 0.481 | ppl 1.4 | wps 27678.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12509 | lr 0.000282741 | gnorm 0.581 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29634
2022-03-05 22:36:35 | INFO | fairseq.trainer | begin training epoch 258
2022-03-05 22:36:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:38:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:38:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:38:29 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.574 | nll_loss 12.94 | ppl 7860.52 | wps 46446 | wpb 510.9 | bsz 1 | num_updates 12557 | best_loss 8.953
2022-03-05 22:38:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12557 updates
2022-03-05 22:38:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:38:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:38:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 258 @ 12557 updates, score 13.574) (writing took 1.6479641702026129 seconds)
2022-03-05 22:38:30 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-05 22:38:30 | INFO | train | epoch 258 | loss 2.29 | nll_loss 0.479 | ppl 1.39 | wps 27061.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12557 | lr 0.0002822 | gnorm 0.567 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29749
2022-03-05 22:38:30 | INFO | fairseq.trainer | begin training epoch 259
2022-03-05 22:38:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:40:07 | INFO | train_inner | epoch 259:     43 / 49 loss=2.291, nll_loss=0.479, ppl=1.39, wps=27419.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.564, loss_scale=32, train_wall=201, gb_free=21.6, wall=29845
2022-03-05 22:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:40:24 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.537 | nll_loss 12.895 | ppl 7619.32 | wps 46053.5 | wpb 510.9 | bsz 1 | num_updates 12606 | best_loss 8.953
2022-03-05 22:40:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12606 updates
2022-03-05 22:40:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:40:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:40:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 259 @ 12606 updates, score 13.537) (writing took 1.707197462208569 seconds)
2022-03-05 22:40:25 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-05 22:40:25 | INFO | train | epoch 259 | loss 2.289 | nll_loss 0.477 | ppl 1.39 | wps 27647.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12606 | lr 0.000281651 | gnorm 0.558 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29864
2022-03-05 22:40:25 | INFO | fairseq.trainer | begin training epoch 260
2022-03-05 22:40:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:42:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:42:19 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.558 | nll_loss 12.924 | ppl 7771.79 | wps 46385.5 | wpb 510.9 | bsz 1 | num_updates 12655 | best_loss 8.953
2022-03-05 22:42:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12655 updates
2022-03-05 22:42:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:42:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:42:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 260 @ 12655 updates, score 13.558) (writing took 1.6432496942579746 seconds)
2022-03-05 22:42:20 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-05 22:42:20 | INFO | train | epoch 260 | loss 2.288 | nll_loss 0.477 | ppl 1.39 | wps 27652.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12655 | lr 0.000281105 | gnorm 0.572 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 29979
2022-03-05 22:42:20 | INFO | fairseq.trainer | begin training epoch 261
2022-03-05 22:42:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:43:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:44:03 | INFO | train_inner | epoch 261:     46 / 49 loss=2.288, nll_loss=0.477, ppl=1.39, wps=27410.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.572, loss_scale=32, train_wall=201, gb_free=21.6, wall=30082
2022-03-05 22:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:44:14 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.559 | nll_loss 12.916 | ppl 7729.58 | wps 46253.8 | wpb 510.9 | bsz 1 | num_updates 12703 | best_loss 8.953
2022-03-05 22:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12703 updates
2022-03-05 22:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:44:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 261 @ 12703 updates, score 13.559) (writing took 1.656453494913876 seconds)
2022-03-05 22:44:15 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-05 22:44:15 | INFO | train | epoch 261 | loss 2.287 | nll_loss 0.476 | ppl 1.39 | wps 27070.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12703 | lr 0.000280574 | gnorm 0.573 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30094
2022-03-05 22:44:15 | INFO | fairseq.trainer | begin training epoch 262
2022-03-05 22:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:46:09 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.529 | nll_loss 12.889 | ppl 7585.58 | wps 46481.4 | wpb 510.9 | bsz 1 | num_updates 12752 | best_loss 8.953
2022-03-05 22:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12752 updates
2022-03-05 22:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:46:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:46:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 262 @ 12752 updates, score 13.529) (writing took 1.6198985325172544 seconds)
2022-03-05 22:46:10 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-05 22:46:10 | INFO | train | epoch 262 | loss 2.283 | nll_loss 0.472 | ppl 1.39 | wps 27667.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12752 | lr 0.000280034 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30209
2022-03-05 22:46:10 | INFO | fairseq.trainer | begin training epoch 263
2022-03-05 22:46:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:47:58 | INFO | train_inner | epoch 263:     48 / 49 loss=2.283, nll_loss=0.472, ppl=1.39, wps=27674.2, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.56, loss_scale=32, train_wall=199, gb_free=21.6, wall=30316
2022-03-05 22:47:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:48:04 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.606 | nll_loss 12.981 | ppl 8087.47 | wps 46325.5 | wpb 510.9 | bsz 1 | num_updates 12801 | best_loss 8.953
2022-03-05 22:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12801 updates
2022-03-05 22:48:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:48:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:48:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 263 @ 12801 updates, score 13.606) (writing took 1.6506454916670918 seconds)
2022-03-05 22:48:05 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-05 22:48:05 | INFO | train | epoch 263 | loss 2.283 | nll_loss 0.472 | ppl 1.39 | wps 27619.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12801 | lr 0.000279498 | gnorm 0.566 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 30324
2022-03-05 22:48:05 | INFO | fairseq.trainer | begin training epoch 264
2022-03-05 22:48:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:48:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:49:58 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.456 | nll_loss 12.808 | ppl 7173.37 | wps 46392.7 | wpb 510.9 | bsz 1 | num_updates 12849 | best_loss 8.953
2022-03-05 22:49:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12849 updates
2022-03-05 22:49:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 264 @ 12849 updates, score 13.456) (writing took 1.6583293480798602 seconds)
2022-03-05 22:50:00 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-05 22:50:00 | INFO | train | epoch 264 | loss 2.28 | nll_loss 0.47 | ppl 1.39 | wps 27076.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12849 | lr 0.000278975 | gnorm 0.558 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30439
2022-03-05 22:50:00 | INFO | fairseq.trainer | begin training epoch 265
2022-03-05 22:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:51:53 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.531 | nll_loss 12.892 | ppl 7601.2 | wps 46342.4 | wpb 510.9 | bsz 1 | num_updates 12898 | best_loss 8.953
2022-03-05 22:51:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12898 updates
2022-03-05 22:51:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 265 @ 12898 updates, score 13.531) (writing took 1.6103111999109387 seconds)
2022-03-05 22:51:55 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-05 22:51:55 | INFO | train | epoch 265 | loss 2.278 | nll_loss 0.468 | ppl 1.38 | wps 27669.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12898 | lr 0.000278445 | gnorm 0.552 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30554
2022-03-05 22:51:55 | INFO | fairseq.trainer | begin training epoch 266
2022-03-05 22:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:52:00 | INFO | train_inner | epoch 266:      2 / 49 loss=2.279, nll_loss=0.469, ppl=1.38, wps=26680.8, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=12900, lr=0.000278423, gnorm=0.557, loss_scale=32, train_wall=200, gb_free=21.6, wall=30558
2022-03-05 22:53:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:53:48 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.625 | nll_loss 13.002 | ppl 8202.05 | wps 46624.7 | wpb 510.9 | bsz 1 | num_updates 12946 | best_loss 8.953
2022-03-05 22:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12946 updates
2022-03-05 22:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 266 @ 12946 updates, score 13.625) (writing took 1.6414032187312841 seconds)
2022-03-05 22:53:50 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-05 22:53:50 | INFO | train | epoch 266 | loss 2.279 | nll_loss 0.469 | ppl 1.38 | wps 27103.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 12946 | lr 0.000277928 | gnorm 0.562 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30668
2022-03-05 22:53:50 | INFO | fairseq.trainer | begin training epoch 267
2022-03-05 22:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:55:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:55:43 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.628 | nll_loss 13.008 | ppl 8237.12 | wps 46536.5 | wpb 510.9 | bsz 1 | num_updates 12995 | best_loss 8.953
2022-03-05 22:55:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12995 updates
2022-03-05 22:55:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:55:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:55:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 267 @ 12995 updates, score 13.628) (writing took 1.631496226415038 seconds)
2022-03-05 22:55:45 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-05 22:55:45 | INFO | train | epoch 267 | loss 2.277 | nll_loss 0.468 | ppl 1.38 | wps 27655.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 12995 | lr 0.000277403 | gnorm 0.569 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30783
2022-03-05 22:55:45 | INFO | fairseq.trainer | begin training epoch 268
2022-03-05 22:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:55:56 | INFO | train_inner | epoch 268:      5 / 49 loss=2.278, nll_loss=0.468, ppl=1.38, wps=27433.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.566, loss_scale=32, train_wall=201, gb_free=21.6, wall=30795
2022-03-05 22:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:57:38 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.666 | nll_loss 13.048 | ppl 8468.95 | wps 46428.6 | wpb 510.9 | bsz 1 | num_updates 13044 | best_loss 8.953
2022-03-05 22:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13044 updates
2022-03-05 22:57:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 268 @ 13044 updates, score 13.666) (writing took 1.6815567687153816 seconds)
2022-03-05 22:57:40 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-05 22:57:40 | INFO | train | epoch 268 | loss 2.275 | nll_loss 0.466 | ppl 1.38 | wps 27650.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13044 | lr 0.000276882 | gnorm 0.561 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 30898
2022-03-05 22:57:40 | INFO | fairseq.trainer | begin training epoch 269
2022-03-05 22:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:58:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 22:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 22:59:33 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.532 | nll_loss 12.903 | ppl 7659.97 | wps 46389.2 | wpb 510.9 | bsz 1 | num_updates 13092 | best_loss 8.953
2022-03-05 22:59:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13092 updates
2022-03-05 22:59:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:59:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 22:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 269 @ 13092 updates, score 13.532) (writing took 1.6508847614750266 seconds)
2022-03-05 22:59:35 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-05 22:59:35 | INFO | train | epoch 269 | loss 2.273 | nll_loss 0.464 | ppl 1.38 | wps 27070.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13092 | lr 0.000276374 | gnorm 0.555 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31013
2022-03-05 22:59:35 | INFO | fairseq.trainer | begin training epoch 270
2022-03-05 22:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 22:59:53 | INFO | train_inner | epoch 270:      8 / 49 loss=2.273, nll_loss=0.464, ppl=1.38, wps=27416.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.555, loss_scale=32, train_wall=201, gb_free=21.6, wall=31031
2022-03-05 23:01:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:01:28 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.641 | nll_loss 13.011 | ppl 8253.35 | wps 46220.1 | wpb 510.9 | bsz 1 | num_updates 13141 | best_loss 8.953
2022-03-05 23:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13141 updates
2022-03-05 23:01:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:01:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 270 @ 13141 updates, score 13.641) (writing took 1.6441288441419601 seconds)
2022-03-05 23:01:30 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-05 23:01:30 | INFO | train | epoch 270 | loss 2.271 | nll_loss 0.463 | ppl 1.38 | wps 27637.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13141 | lr 0.000275858 | gnorm 0.553 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31128
2022-03-05 23:01:30 | INFO | fairseq.trainer | begin training epoch 271
2022-03-05 23:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:03:23 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.566 | nll_loss 12.942 | ppl 7870.02 | wps 46394.8 | wpb 510.9 | bsz 1 | num_updates 13190 | best_loss 8.953
2022-03-05 23:03:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13190 updates
2022-03-05 23:03:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:03:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:03:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 271 @ 13190 updates, score 13.566) (writing took 1.6328199366107583 seconds)
2022-03-05 23:03:25 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-05 23:03:25 | INFO | train | epoch 271 | loss 2.271 | nll_loss 0.462 | ppl 1.38 | wps 27650 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13190 | lr 0.000275345 | gnorm 0.553 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31243
2022-03-05 23:03:25 | INFO | fairseq.trainer | begin training epoch 272
2022-03-05 23:03:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:03:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:03:49 | INFO | train_inner | epoch 272:     11 / 49 loss=2.271, nll_loss=0.462, ppl=1.38, wps=27418, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.554, loss_scale=32, train_wall=201, gb_free=21.6, wall=31268
2022-03-05 23:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:05:18 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.545 | nll_loss 12.915 | ppl 7724.9 | wps 46401.2 | wpb 510.9 | bsz 1 | num_updates 13238 | best_loss 8.953
2022-03-05 23:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13238 updates
2022-03-05 23:05:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:05:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:05:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 272 @ 13238 updates, score 13.545) (writing took 1.6901582749560475 seconds)
2022-03-05 23:05:20 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-05 23:05:20 | INFO | train | epoch 272 | loss 2.269 | nll_loss 0.461 | ppl 1.38 | wps 27079.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13238 | lr 0.000274846 | gnorm 0.545 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31358
2022-03-05 23:05:20 | INFO | fairseq.trainer | begin training epoch 273
2022-03-05 23:05:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:07:13 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.492 | nll_loss 12.857 | ppl 7420.14 | wps 46316.4 | wpb 510.9 | bsz 1 | num_updates 13287 | best_loss 8.953
2022-03-05 23:07:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13287 updates
2022-03-05 23:07:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 273 @ 13287 updates, score 13.492) (writing took 1.6626615142449737 seconds)
2022-03-05 23:07:14 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-05 23:07:14 | INFO | train | epoch 273 | loss 2.268 | nll_loss 0.46 | ppl 1.38 | wps 27649.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13287 | lr 0.000274338 | gnorm 0.545 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31473
2022-03-05 23:07:14 | INFO | fairseq.trainer | begin training epoch 274
2022-03-05 23:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:07:44 | INFO | train_inner | epoch 274:     13 / 49 loss=2.268, nll_loss=0.46, ppl=1.38, wps=27681.9, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.546, loss_scale=32, train_wall=199, gb_free=21.6, wall=31502
2022-03-05 23:08:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:09:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:09:08 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.525 | nll_loss 12.891 | ppl 7594.71 | wps 46381.7 | wpb 510.9 | bsz 1 | num_updates 13335 | best_loss 8.953
2022-03-05 23:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13335 updates
2022-03-05 23:09:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 274 @ 13335 updates, score 13.525) (writing took 1.6550542712211609 seconds)
2022-03-05 23:09:09 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-05 23:09:09 | INFO | train | epoch 274 | loss 2.267 | nll_loss 0.459 | ppl 1.37 | wps 27081 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13335 | lr 0.000273844 | gnorm 0.553 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31588
2022-03-05 23:09:09 | INFO | fairseq.trainer | begin training epoch 275
2022-03-05 23:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:11:03 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.524 | nll_loss 12.887 | ppl 7575.47 | wps 46227.5 | wpb 510.9 | bsz 1 | num_updates 13384 | best_loss 8.953
2022-03-05 23:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13384 updates
2022-03-05 23:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 275 @ 13384 updates, score 13.524) (writing took 1.689862153492868 seconds)
2022-03-05 23:11:04 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-05 23:11:04 | INFO | train | epoch 275 | loss 2.265 | nll_loss 0.457 | ppl 1.37 | wps 27629.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13384 | lr 0.000273342 | gnorm 0.549 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31703
2022-03-05 23:11:04 | INFO | fairseq.trainer | begin training epoch 276
2022-03-05 23:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:11:40 | INFO | train_inner | epoch 276:     16 / 49 loss=2.265, nll_loss=0.458, ppl=1.37, wps=27408.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.551, loss_scale=32, train_wall=201, gb_free=21.6, wall=31739
2022-03-05 23:12:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:12:58 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.545 | nll_loss 12.915 | ppl 7723.39 | wps 46636.8 | wpb 510.9 | bsz 1 | num_updates 13433 | best_loss 8.953
2022-03-05 23:12:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13433 updates
2022-03-05 23:12:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 276 @ 13433 updates, score 13.545) (writing took 1.6461505265906453 seconds)
2022-03-05 23:12:59 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-05 23:12:59 | INFO | train | epoch 276 | loss 2.263 | nll_loss 0.456 | ppl 1.37 | wps 27671 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13433 | lr 0.000272843 | gnorm 0.538 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31818
2022-03-05 23:12:59 | INFO | fairseq.trainer | begin training epoch 277
2022-03-05 23:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:13:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:14:53 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.526 | nll_loss 12.892 | ppl 7599.29 | wps 46346.1 | wpb 510.9 | bsz 1 | num_updates 13481 | best_loss 8.953
2022-03-05 23:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13481 updates
2022-03-05 23:14:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:14:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:14:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 277 @ 13481 updates, score 13.526) (writing took 1.6745397876948118 seconds)
2022-03-05 23:14:54 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-05 23:14:54 | INFO | train | epoch 277 | loss 2.263 | nll_loss 0.456 | ppl 1.37 | wps 27059 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13481 | lr 0.000272357 | gnorm 0.543 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 31933
2022-03-05 23:14:54 | INFO | fairseq.trainer | begin training epoch 278
2022-03-05 23:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:15:37 | INFO | train_inner | epoch 278:     19 / 49 loss=2.262, nll_loss=0.455, ppl=1.37, wps=27421, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.536, loss_scale=32, train_wall=201, gb_free=21.6, wall=31975
2022-03-05 23:16:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:16:48 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.551 | nll_loss 12.92 | ppl 7751.5 | wps 46453.6 | wpb 510.9 | bsz 1 | num_updates 13530 | best_loss 8.953
2022-03-05 23:16:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13530 updates
2022-03-05 23:16:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:16:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 278 @ 13530 updates, score 13.551) (writing took 1.6606097938492894 seconds)
2022-03-05 23:16:49 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-05 23:16:49 | INFO | train | epoch 278 | loss 2.261 | nll_loss 0.454 | ppl 1.37 | wps 27648.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13530 | lr 0.000271864 | gnorm 0.543 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32048
2022-03-05 23:16:49 | INFO | fairseq.trainer | begin training epoch 279
2022-03-05 23:16:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:18:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:18:43 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.54 | nll_loss 12.908 | ppl 7684.49 | wps 46322.3 | wpb 510.9 | bsz 1 | num_updates 13579 | best_loss 8.953
2022-03-05 23:18:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13579 updates
2022-03-05 23:18:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:18:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:18:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 279 @ 13579 updates, score 13.54) (writing took 1.6507304310798645 seconds)
2022-03-05 23:18:44 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-05 23:18:44 | INFO | train | epoch 279 | loss 2.26 | nll_loss 0.453 | ppl 1.37 | wps 27637.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13579 | lr 0.000271373 | gnorm 0.547 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 32163
2022-03-05 23:18:44 | INFO | fairseq.trainer | begin training epoch 280
2022-03-05 23:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:18:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:19:33 | INFO | train_inner | epoch 280:     22 / 49 loss=2.26, nll_loss=0.453, ppl=1.37, wps=27418.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.549, loss_scale=32, train_wall=201, gb_free=21.6, wall=32212
2022-03-05 23:20:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:20:37 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.502 | nll_loss 12.875 | ppl 7513.52 | wps 46295.1 | wpb 510.9 | bsz 1 | num_updates 13627 | best_loss 8.953
2022-03-05 23:20:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13627 updates
2022-03-05 23:20:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:20:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:20:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 280 @ 13627 updates, score 13.502) (writing took 1.6355415722355247 seconds)
2022-03-05 23:20:39 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-05 23:20:39 | INFO | train | epoch 280 | loss 2.258 | nll_loss 0.452 | ppl 1.37 | wps 27109.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13627 | lr 0.000270894 | gnorm 0.548 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32278
2022-03-05 23:20:39 | INFO | fairseq.trainer | begin training epoch 281
2022-03-05 23:20:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:22:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:22:32 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.534 | nll_loss 12.904 | ppl 7664.21 | wps 46366.4 | wpb 510.9 | bsz 1 | num_updates 13676 | best_loss 8.953
2022-03-05 23:22:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13676 updates
2022-03-05 23:22:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:22:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:22:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 281 @ 13676 updates, score 13.534) (writing took 1.6507102753967047 seconds)
2022-03-05 23:22:34 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-05 23:22:34 | INFO | train | epoch 281 | loss 2.256 | nll_loss 0.451 | ppl 1.37 | wps 27643.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13676 | lr 0.000270409 | gnorm 0.548 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32393
2022-03-05 23:22:34 | INFO | fairseq.trainer | begin training epoch 282
2022-03-05 23:22:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:23:28 | INFO | train_inner | epoch 282:     24 / 49 loss=2.257, nll_loss=0.451, ppl=1.37, wps=27689.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.547, loss_scale=32, train_wall=199, gb_free=21.6, wall=32446
2022-03-05 23:23:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:24:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:24:27 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.582 | nll_loss 12.954 | ppl 7936.89 | wps 46236.9 | wpb 510.9 | bsz 1 | num_updates 13724 | best_loss 8.953
2022-03-05 23:24:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13724 updates
2022-03-05 23:24:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:24:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:24:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 282 @ 13724 updates, score 13.582) (writing took 1.6777973733842373 seconds)
2022-03-05 23:24:29 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-05 23:24:29 | INFO | train | epoch 282 | loss 2.256 | nll_loss 0.45 | ppl 1.37 | wps 27073 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13724 | lr 0.000269935 | gnorm 0.549 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32508
2022-03-05 23:24:29 | INFO | fairseq.trainer | begin training epoch 283
2022-03-05 23:24:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:26:22 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.611 | nll_loss 12.998 | ppl 8181.26 | wps 46274.7 | wpb 510.9 | bsz 1 | num_updates 13773 | best_loss 8.953
2022-03-05 23:26:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13773 updates
2022-03-05 23:26:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:26:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:26:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 283 @ 13773 updates, score 13.611) (writing took 1.662592215463519 seconds)
2022-03-05 23:26:24 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-05 23:26:24 | INFO | train | epoch 283 | loss 2.255 | nll_loss 0.449 | ppl 1.36 | wps 27649.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13773 | lr 0.000269455 | gnorm 0.54 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32623
2022-03-05 23:26:24 | INFO | fairseq.trainer | begin training epoch 284
2022-03-05 23:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:27:24 | INFO | train_inner | epoch 284:     27 / 49 loss=2.255, nll_loss=0.449, ppl=1.37, wps=27402.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.542, loss_scale=32, train_wall=201, gb_free=21.6, wall=32683
2022-03-05 23:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:28:17 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.497 | nll_loss 12.863 | ppl 7451.33 | wps 46318.9 | wpb 510.9 | bsz 1 | num_updates 13822 | best_loss 8.953
2022-03-05 23:28:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13822 updates
2022-03-05 23:28:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:28:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:28:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 284 @ 13822 updates, score 13.497) (writing took 1.6595225716009736 seconds)
2022-03-05 23:28:19 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-05 23:28:19 | INFO | train | epoch 284 | loss 2.253 | nll_loss 0.448 | ppl 1.36 | wps 27639.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13822 | lr 0.000268977 | gnorm 0.537 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32738
2022-03-05 23:28:19 | INFO | fairseq.trainer | begin training epoch 285
2022-03-05 23:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:29:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:30:12 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.573 | nll_loss 12.949 | ppl 7906.71 | wps 46475.5 | wpb 510.9 | bsz 1 | num_updates 13870 | best_loss 8.953
2022-03-05 23:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13870 updates
2022-03-05 23:30:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:30:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 285 @ 13870 updates, score 13.573) (writing took 1.6531512532383204 seconds)
2022-03-05 23:30:14 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-05 23:30:14 | INFO | train | epoch 285 | loss 2.251 | nll_loss 0.446 | ppl 1.36 | wps 27091.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 13870 | lr 0.000268511 | gnorm 0.532 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32852
2022-03-05 23:30:14 | INFO | fairseq.trainer | begin training epoch 286
2022-03-05 23:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:31:21 | INFO | train_inner | epoch 286:     30 / 49 loss=2.251, nll_loss=0.446, ppl=1.36, wps=27424.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.534, loss_scale=32, train_wall=201, gb_free=21.6, wall=32920
2022-03-05 23:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:32:07 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.697 | nll_loss 13.09 | ppl 8722.08 | wps 46375.7 | wpb 510.9 | bsz 1 | num_updates 13919 | best_loss 8.953
2022-03-05 23:32:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13919 updates
2022-03-05 23:32:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:32:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:32:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 286 @ 13919 updates, score 13.697) (writing took 1.6660982463508844 seconds)
2022-03-05 23:32:09 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-05 23:32:09 | INFO | train | epoch 286 | loss 2.25 | nll_loss 0.445 | ppl 1.36 | wps 27644 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13919 | lr 0.000268038 | gnorm 0.543 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 32967
2022-03-05 23:32:09 | INFO | fairseq.trainer | begin training epoch 287
2022-03-05 23:32:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:34:02 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.536 | nll_loss 12.912 | ppl 7705.92 | wps 46424.8 | wpb 510.9 | bsz 1 | num_updates 13968 | best_loss 8.953
2022-03-05 23:34:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13968 updates
2022-03-05 23:34:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:34:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 287 @ 13968 updates, score 13.536) (writing took 1.6804682528600097 seconds)
2022-03-05 23:34:04 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-05 23:34:04 | INFO | train | epoch 287 | loss 2.25 | nll_loss 0.446 | ppl 1.36 | wps 27641.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 13968 | lr 0.000267567 | gnorm 0.541 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33082
2022-03-05 23:34:04 | INFO | fairseq.trainer | begin training epoch 288
2022-03-05 23:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:34:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:35:18 | INFO | train_inner | epoch 288:     33 / 49 loss=2.249, nll_loss=0.445, ppl=1.36, wps=27419.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.539, loss_scale=32, train_wall=201, gb_free=21.6, wall=33156
2022-03-05 23:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:35:57 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.554 | nll_loss 12.933 | ppl 7822.68 | wps 46275.7 | wpb 510.9 | bsz 1 | num_updates 14016 | best_loss 8.953
2022-03-05 23:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14016 updates
2022-03-05 23:35:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:35:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:35:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 288 @ 14016 updates, score 13.554) (writing took 1.6604717867448926 seconds)
2022-03-05 23:35:59 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-05 23:35:59 | INFO | train | epoch 288 | loss 2.247 | nll_loss 0.442 | ppl 1.36 | wps 27092.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14016 | lr 0.000267109 | gnorm 0.534 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33197
2022-03-05 23:35:59 | INFO | fairseq.trainer | begin training epoch 289
2022-03-05 23:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:37:52 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.595 | nll_loss 12.974 | ppl 8045.2 | wps 46217 | wpb 510.9 | bsz 1 | num_updates 14065 | best_loss 8.953
2022-03-05 23:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14065 updates
2022-03-05 23:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:37:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:37:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 289 @ 14065 updates, score 13.595) (writing took 1.6869466872885823 seconds)
2022-03-05 23:37:54 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-05 23:37:54 | INFO | train | epoch 289 | loss 2.246 | nll_loss 0.442 | ppl 1.36 | wps 27638.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14065 | lr 0.000266643 | gnorm 0.539 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33312
2022-03-05 23:37:54 | INFO | fairseq.trainer | begin training epoch 290
2022-03-05 23:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:39:12 | INFO | train_inner | epoch 290:     35 / 49 loss=2.247, nll_loss=0.443, ppl=1.36, wps=27670.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.54, loss_scale=32, train_wall=199, gb_free=21.6, wall=33391
2022-03-05 23:39:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:39:47 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.481 | nll_loss 12.847 | ppl 7369.34 | wps 46365.2 | wpb 510.9 | bsz 1 | num_updates 14113 | best_loss 8.953
2022-03-05 23:39:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14113 updates
2022-03-05 23:39:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:39:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:39:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 290 @ 14113 updates, score 13.481) (writing took 1.658797218464315 seconds)
2022-03-05 23:39:49 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-05 23:39:49 | INFO | train | epoch 290 | loss 2.245 | nll_loss 0.441 | ppl 1.36 | wps 27061 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14113 | lr 0.000266189 | gnorm 0.535 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33427
2022-03-05 23:39:49 | INFO | fairseq.trainer | begin training epoch 291
2022-03-05 23:39:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:41:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:41:42 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.541 | nll_loss 12.911 | ppl 7700.19 | wps 46442.2 | wpb 510.9 | bsz 1 | num_updates 14162 | best_loss 8.953
2022-03-05 23:41:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14162 updates
2022-03-05 23:41:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:41:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:41:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 291 @ 14162 updates, score 13.541) (writing took 1.676282119937241 seconds)
2022-03-05 23:41:44 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-05 23:41:44 | INFO | train | epoch 291 | loss 2.244 | nll_loss 0.44 | ppl 1.36 | wps 27649 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14162 | lr 0.000265728 | gnorm 0.532 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33542
2022-03-05 23:41:44 | INFO | fairseq.trainer | begin training epoch 292
2022-03-05 23:41:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:43:09 | INFO | train_inner | epoch 292:     38 / 49 loss=2.243, nll_loss=0.439, ppl=1.36, wps=27419, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.527, loss_scale=32, train_wall=201, gb_free=21.6, wall=33627
2022-03-05 23:43:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:43:37 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.515 | nll_loss 12.888 | ppl 7582.33 | wps 46350.2 | wpb 510.9 | bsz 1 | num_updates 14211 | best_loss 8.953
2022-03-05 23:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14211 updates
2022-03-05 23:43:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 292 @ 14211 updates, score 13.515) (writing took 1.6862028669565916 seconds)
2022-03-05 23:43:39 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-05 23:43:39 | INFO | train | epoch 292 | loss 2.242 | nll_loss 0.438 | ppl 1.35 | wps 27635.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14211 | lr 0.00026527 | gnorm 0.525 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33657
2022-03-05 23:43:39 | INFO | fairseq.trainer | begin training epoch 293
2022-03-05 23:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:44:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:45:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:45:32 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.517 | nll_loss 12.891 | ppl 7594.17 | wps 46495.8 | wpb 510.9 | bsz 1 | num_updates 14259 | best_loss 8.953
2022-03-05 23:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14259 updates
2022-03-05 23:45:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:45:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 293 @ 14259 updates, score 13.517) (writing took 1.6585498061031103 seconds)
2022-03-05 23:45:33 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-05 23:45:33 | INFO | train | epoch 293 | loss 2.241 | nll_loss 0.438 | ppl 1.35 | wps 27106.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14259 | lr 0.000264823 | gnorm 0.528 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33772
2022-03-05 23:45:33 | INFO | fairseq.trainer | begin training epoch 294
2022-03-05 23:45:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:47:05 | INFO | train_inner | epoch 294:     41 / 49 loss=2.241, nll_loss=0.438, ppl=1.35, wps=27425.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.528, loss_scale=32, train_wall=201, gb_free=21.6, wall=33864
2022-03-05 23:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:47:27 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.53 | nll_loss 12.902 | ppl 7654.9 | wps 46601.2 | wpb 510.9 | bsz 1 | num_updates 14308 | best_loss 8.953
2022-03-05 23:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14308 updates
2022-03-05 23:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:47:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 294 @ 14308 updates, score 13.53) (writing took 1.6503019845113158 seconds)
2022-03-05 23:47:28 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-05 23:47:28 | INFO | train | epoch 294 | loss 2.24 | nll_loss 0.437 | ppl 1.35 | wps 27661.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14308 | lr 0.000264369 | gnorm 0.528 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 33887
2022-03-05 23:47:28 | INFO | fairseq.trainer | begin training epoch 295
2022-03-05 23:47:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:49:22 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.468 | nll_loss 12.834 | ppl 7302.1 | wps 45888.5 | wpb 510.9 | bsz 1 | num_updates 14357 | best_loss 8.953
2022-03-05 23:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14357 updates
2022-03-05 23:49:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:49:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:49:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 295 @ 14357 updates, score 13.468) (writing took 1.6102830795571208 seconds)
2022-03-05 23:49:23 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-05 23:49:23 | INFO | train | epoch 295 | loss 2.239 | nll_loss 0.436 | ppl 1.35 | wps 27645.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14357 | lr 0.000263917 | gnorm 0.526 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34002
2022-03-05 23:49:23 | INFO | fairseq.trainer | begin training epoch 296
2022-03-05 23:49:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:49:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:51:02 | INFO | train_inner | epoch 296:     44 / 49 loss=2.239, nll_loss=0.436, ppl=1.35, wps=27426.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.529, loss_scale=32, train_wall=201, gb_free=21.6, wall=34100
2022-03-05 23:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:51:17 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.529 | nll_loss 12.898 | ppl 7634.67 | wps 46406.3 | wpb 510.9 | bsz 1 | num_updates 14405 | best_loss 8.953
2022-03-05 23:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14405 updates
2022-03-05 23:51:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:51:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:51:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 296 @ 14405 updates, score 13.529) (writing took 1.6647986015304923 seconds)
2022-03-05 23:51:18 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-05 23:51:18 | INFO | train | epoch 296 | loss 2.237 | nll_loss 0.435 | ppl 1.35 | wps 27085.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14405 | lr 0.000263477 | gnorm 0.532 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34117
2022-03-05 23:51:18 | INFO | fairseq.trainer | begin training epoch 297
2022-03-05 23:51:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:53:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:53:11 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.53 | nll_loss 12.907 | ppl 7683.16 | wps 46428 | wpb 510.9 | bsz 1 | num_updates 14454 | best_loss 8.953
2022-03-05 23:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14454 updates
2022-03-05 23:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:53:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 297 @ 14454 updates, score 13.53) (writing took 1.6395157296210527 seconds)
2022-03-05 23:53:13 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-05 23:53:13 | INFO | train | epoch 297 | loss 2.237 | nll_loss 0.434 | ppl 1.35 | wps 27650.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14454 | lr 0.00026303 | gnorm 0.522 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34232
2022-03-05 23:53:13 | INFO | fairseq.trainer | begin training epoch 298
2022-03-05 23:53:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:54:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-05 23:54:58 | INFO | train_inner | epoch 298:     47 / 49 loss=2.236, nll_loss=0.434, ppl=1.35, wps=27420.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.525, loss_scale=32, train_wall=201, gb_free=21.6, wall=34337
2022-03-05 23:55:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:55:06 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.614 | nll_loss 12.996 | ppl 8171.61 | wps 46350.8 | wpb 510.9 | bsz 1 | num_updates 14502 | best_loss 8.953
2022-03-05 23:55:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14502 updates
2022-03-05 23:55:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:55:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:55:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 298 @ 14502 updates, score 13.614) (writing took 1.6476752739399672 seconds)
2022-03-05 23:55:08 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-05 23:55:08 | INFO | train | epoch 298 | loss 2.235 | nll_loss 0.433 | ppl 1.35 | wps 27081.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14502 | lr 0.000262595 | gnorm 0.526 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34347
2022-03-05 23:55:08 | INFO | fairseq.trainer | begin training epoch 299
2022-03-05 23:55:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:56:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:57:01 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.554 | nll_loss 12.933 | ppl 7819.04 | wps 46300.7 | wpb 510.9 | bsz 1 | num_updates 14551 | best_loss 8.953
2022-03-05 23:57:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14551 updates
2022-03-05 23:57:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:57:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:57:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 299 @ 14551 updates, score 13.554) (writing took 1.6692061368376017 seconds)
2022-03-05 23:57:03 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-05 23:57:03 | INFO | train | epoch 299 | loss 2.234 | nll_loss 0.432 | ppl 1.35 | wps 27675.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14551 | lr 0.000262152 | gnorm 0.515 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34462
2022-03-05 23:57:03 | INFO | fairseq.trainer | begin training epoch 300
2022-03-05 23:57:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:58:51 | INFO | train_inner | epoch 300:     49 / 49 loss=2.234, nll_loss=0.432, ppl=1.35, wps=27686.6, ups=0.43, wpb=64544.1, bsz=126.1, num_updates=14600, lr=0.000261712, gnorm=0.52, loss_scale=32, train_wall=198, gb_free=21.6, wall=34570
2022-03-05 23:58:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-05 23:58:56 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.594 | nll_loss 12.978 | ppl 8066.86 | wps 46499.9 | wpb 510.9 | bsz 1 | num_updates 14600 | best_loss 8.953
2022-03-05 23:58:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14600 updates
2022-03-05 23:58:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:58:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-05 23:58:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 300 @ 14600 updates, score 13.594) (writing took 1.629552310332656 seconds)
2022-03-05 23:58:58 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-05 23:58:58 | INFO | train | epoch 300 | loss 2.234 | nll_loss 0.432 | ppl 1.35 | wps 27662.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14600 | lr 0.000261712 | gnorm 0.521 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34576
2022-03-05 23:58:58 | INFO | fairseq.trainer | begin training epoch 301
2022-03-05 23:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-05 23:59:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:00:51 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.527 | nll_loss 12.902 | ppl 7651.59 | wps 46366.7 | wpb 510.9 | bsz 1 | num_updates 14648 | best_loss 8.953
2022-03-06 00:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14648 updates
2022-03-06 00:00:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 301 @ 14648 updates, score 13.527) (writing took 1.6768927229568362 seconds)
2022-03-06 00:00:53 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-06 00:00:53 | INFO | train | epoch 301 | loss 2.232 | nll_loss 0.43 | ppl 1.35 | wps 27089.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14648 | lr 0.000261283 | gnorm 0.534 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 34691
2022-03-06 00:00:53 | INFO | fairseq.trainer | begin training epoch 302
2022-03-06 00:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:02:46 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.5 | nll_loss 12.872 | ppl 7496.57 | wps 46438.2 | wpb 510.9 | bsz 1 | num_updates 14697 | best_loss 8.953
2022-03-06 00:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14697 updates
2022-03-06 00:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:02:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:02:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 302 @ 14697 updates, score 13.5) (writing took 1.6479077292606235 seconds)
2022-03-06 00:02:48 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-06 00:02:48 | INFO | train | epoch 302 | loss 2.231 | nll_loss 0.43 | ppl 1.35 | wps 27660.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14697 | lr 0.000260847 | gnorm 0.519 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 34806
2022-03-06 00:02:48 | INFO | fairseq.trainer | begin training epoch 303
2022-03-06 00:02:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:02:54 | INFO | train_inner | epoch 303:      3 / 49 loss=2.231, nll_loss=0.43, ppl=1.35, wps=26701.4, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=14700, lr=0.00026082, gnorm=0.526, loss_scale=16, train_wall=201, gb_free=21.6, wall=34813
2022-03-06 00:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:04:41 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.615 | nll_loss 12.998 | ppl 8179.59 | wps 46453.6 | wpb 510.9 | bsz 1 | num_updates 14746 | best_loss 8.953
2022-03-06 00:04:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14746 updates
2022-03-06 00:04:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:04:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 303 @ 14746 updates, score 13.615) (writing took 1.6578002152964473 seconds)
2022-03-06 00:04:43 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-06 00:04:43 | INFO | train | epoch 303 | loss 2.23 | nll_loss 0.429 | ppl 1.35 | wps 27635 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14746 | lr 0.000260413 | gnorm 0.517 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 34921
2022-03-06 00:04:43 | INFO | fairseq.trainer | begin training epoch 304
2022-03-06 00:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:06:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:06:36 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.609 | nll_loss 13.001 | ppl 8197.69 | wps 46455.6 | wpb 510.9 | bsz 1 | num_updates 14795 | best_loss 8.953
2022-03-06 00:06:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14795 updates
2022-03-06 00:06:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:06:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:06:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 304 @ 14795 updates, score 13.609) (writing took 1.651660087518394 seconds)
2022-03-06 00:06:37 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-06 00:06:37 | INFO | train | epoch 304 | loss 2.229 | nll_loss 0.428 | ppl 1.35 | wps 27670.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14795 | lr 0.000259982 | gnorm 0.522 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35036
2022-03-06 00:06:37 | INFO | fairseq.trainer | begin training epoch 305
2022-03-06 00:06:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:06:49 | INFO | train_inner | epoch 305:      5 / 49 loss=2.229, nll_loss=0.428, ppl=1.35, wps=27683.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.52, loss_scale=32, train_wall=199, gb_free=21.6, wall=35047
2022-03-06 00:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:08:31 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.477 | nll_loss 12.853 | ppl 7397.15 | wps 46559.9 | wpb 510.9 | bsz 1 | num_updates 14844 | best_loss 8.953
2022-03-06 00:08:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14844 updates
2022-03-06 00:08:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:08:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:08:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 305 @ 14844 updates, score 13.477) (writing took 1.6512502003461123 seconds)
2022-03-06 00:08:32 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-06 00:08:32 | INFO | train | epoch 305 | loss 2.228 | nll_loss 0.427 | ppl 1.34 | wps 27660.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14844 | lr 0.000259552 | gnorm 0.524 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35151
2022-03-06 00:08:32 | INFO | fairseq.trainer | begin training epoch 306
2022-03-06 00:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:09:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:10:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:10:25 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.588 | nll_loss 12.971 | ppl 8027.72 | wps 46514.1 | wpb 510.9 | bsz 1 | num_updates 14892 | best_loss 8.953
2022-03-06 00:10:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14892 updates
2022-03-06 00:10:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:10:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:10:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 306 @ 14892 updates, score 13.588) (writing took 1.642837181687355 seconds)
2022-03-06 00:10:27 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-06 00:10:27 | INFO | train | epoch 306 | loss 2.226 | nll_loss 0.426 | ppl 1.34 | wps 27112.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 14892 | lr 0.000259133 | gnorm 0.522 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35266
2022-03-06 00:10:27 | INFO | fairseq.trainer | begin training epoch 307
2022-03-06 00:10:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:10:45 | INFO | train_inner | epoch 307:      8 / 49 loss=2.227, nll_loss=0.426, ppl=1.34, wps=27443.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.523, loss_scale=32, train_wall=201, gb_free=21.6, wall=35284
2022-03-06 00:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:12:20 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.57 | nll_loss 12.951 | ppl 7920.51 | wps 46388.7 | wpb 510.9 | bsz 1 | num_updates 14941 | best_loss 8.953
2022-03-06 00:12:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14941 updates
2022-03-06 00:12:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:12:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:12:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 307 @ 14941 updates, score 13.57) (writing took 1.6672515198588371 seconds)
2022-03-06 00:12:22 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-06 00:12:22 | INFO | train | epoch 307 | loss 2.226 | nll_loss 0.426 | ppl 1.34 | wps 27657.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14941 | lr 0.000258708 | gnorm 0.527 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35381
2022-03-06 00:12:22 | INFO | fairseq.trainer | begin training epoch 308
2022-03-06 00:12:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:14:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:14:15 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.491 | nll_loss 12.861 | ppl 7438.55 | wps 46328.4 | wpb 510.9 | bsz 1 | num_updates 14990 | best_loss 8.953
2022-03-06 00:14:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14990 updates
2022-03-06 00:14:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:14:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:14:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 308 @ 14990 updates, score 13.491) (writing took 1.6625407738611102 seconds)
2022-03-06 00:14:17 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-06 00:14:17 | INFO | train | epoch 308 | loss 2.224 | nll_loss 0.424 | ppl 1.34 | wps 27671.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 14990 | lr 0.000258285 | gnorm 0.523 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35496
2022-03-06 00:14:17 | INFO | fairseq.trainer | begin training epoch 309
2022-03-06 00:14:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:14:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:14:42 | INFO | train_inner | epoch 309:     11 / 49 loss=2.225, nll_loss=0.425, ppl=1.34, wps=27432.1, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.524, loss_scale=32, train_wall=201, gb_free=21.6, wall=35520
2022-03-06 00:16:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:16:10 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.428 | nll_loss 12.797 | ppl 7118.93 | wps 46303.7 | wpb 510.9 | bsz 1 | num_updates 15038 | best_loss 8.953
2022-03-06 00:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15038 updates
2022-03-06 00:16:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:16:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:16:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 309 @ 15038 updates, score 13.428) (writing took 1.758835886605084 seconds)
2022-03-06 00:16:12 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-06 00:16:12 | INFO | train | epoch 309 | loss 2.223 | nll_loss 0.423 | ppl 1.34 | wps 27067.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15038 | lr 0.000257872 | gnorm 0.524 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35610
2022-03-06 00:16:12 | INFO | fairseq.trainer | begin training epoch 310
2022-03-06 00:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:18:05 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.597 | nll_loss 12.983 | ppl 8098.23 | wps 46322.5 | wpb 510.9 | bsz 1 | num_updates 15087 | best_loss 8.953
2022-03-06 00:18:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15087 updates
2022-03-06 00:18:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:18:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:18:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 310 @ 15087 updates, score 13.597) (writing took 1.6211841935291886 seconds)
2022-03-06 00:18:07 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-06 00:18:07 | INFO | train | epoch 310 | loss 2.222 | nll_loss 0.423 | ppl 1.34 | wps 27651.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15087 | lr 0.000257453 | gnorm 0.518 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35725
2022-03-06 00:18:07 | INFO | fairseq.trainer | begin training epoch 311
2022-03-06 00:18:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:18:36 | INFO | train_inner | epoch 311:     13 / 49 loss=2.222, nll_loss=0.422, ppl=1.34, wps=27679, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.519, loss_scale=32, train_wall=199, gb_free=21.6, wall=35755
2022-03-06 00:19:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:19:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:20:00 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.534 | nll_loss 12.916 | ppl 7730.12 | wps 46292.8 | wpb 510.9 | bsz 1 | num_updates 15135 | best_loss 8.953
2022-03-06 00:20:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15135 updates
2022-03-06 00:20:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:20:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:20:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 311 @ 15135 updates, score 13.534) (writing took 1.66436330601573 seconds)
2022-03-06 00:20:02 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-06 00:20:02 | INFO | train | epoch 311 | loss 2.22 | nll_loss 0.42 | ppl 1.34 | wps 27039.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15135 | lr 0.000257045 | gnorm 0.516 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 35841
2022-03-06 00:20:02 | INFO | fairseq.trainer | begin training epoch 312
2022-03-06 00:20:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:21:55 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.469 | nll_loss 12.845 | ppl 7358.86 | wps 46332.6 | wpb 510.9 | bsz 1 | num_updates 15184 | best_loss 8.953
2022-03-06 00:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15184 updates
2022-03-06 00:21:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 312 @ 15184 updates, score 13.469) (writing took 1.6676722317934036 seconds)
2022-03-06 00:21:57 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-06 00:21:57 | INFO | train | epoch 312 | loss 2.218 | nll_loss 0.419 | ppl 1.34 | wps 27665.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15184 | lr 0.00025663 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 35955
2022-03-06 00:21:57 | INFO | fairseq.trainer | begin training epoch 313
2022-03-06 00:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:22:33 | INFO | train_inner | epoch 313:     16 / 49 loss=2.219, nll_loss=0.42, ppl=1.34, wps=27402, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.515, loss_scale=32, train_wall=201, gb_free=21.6, wall=35991
2022-03-06 00:23:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:23:50 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.543 | nll_loss 12.92 | ppl 7751 | wps 46332.8 | wpb 510.9 | bsz 1 | num_updates 15233 | best_loss 8.953
2022-03-06 00:23:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15233 updates
2022-03-06 00:23:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:23:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 313 @ 15233 updates, score 13.543) (writing took 1.6800003973767161 seconds)
2022-03-06 00:23:52 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-06 00:23:52 | INFO | train | epoch 313 | loss 2.219 | nll_loss 0.42 | ppl 1.34 | wps 27619.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15233 | lr 0.000256217 | gnorm 0.523 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36070
2022-03-06 00:23:52 | INFO | fairseq.trainer | begin training epoch 314
2022-03-06 00:23:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:24:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:25:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:25:45 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.573 | nll_loss 12.957 | ppl 7951.57 | wps 46303.9 | wpb 510.9 | bsz 1 | num_updates 15281 | best_loss 8.953
2022-03-06 00:25:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15281 updates
2022-03-06 00:25:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 314 @ 15281 updates, score 13.573) (writing took 1.6147110387682915 seconds)
2022-03-06 00:25:47 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-06 00:25:47 | INFO | train | epoch 314 | loss 2.217 | nll_loss 0.419 | ppl 1.34 | wps 27094.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15281 | lr 0.000255814 | gnorm 0.52 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36185
2022-03-06 00:25:47 | INFO | fairseq.trainer | begin training epoch 315
2022-03-06 00:25:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:26:29 | INFO | train_inner | epoch 315:     19 / 49 loss=2.217, nll_loss=0.419, ppl=1.34, wps=27422, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.516, loss_scale=32, train_wall=201, gb_free=21.6, wall=36228
2022-03-06 00:27:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:27:40 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.525 | nll_loss 12.902 | ppl 7652.1 | wps 46323.7 | wpb 510.9 | bsz 1 | num_updates 15330 | best_loss 8.953
2022-03-06 00:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15330 updates
2022-03-06 00:27:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 315 @ 15330 updates, score 13.525) (writing took 1.6617121435701847 seconds)
2022-03-06 00:27:42 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-06 00:27:42 | INFO | train | epoch 315 | loss 2.216 | nll_loss 0.418 | ppl 1.34 | wps 27670.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15330 | lr 0.000255405 | gnorm 0.503 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36300
2022-03-06 00:27:42 | INFO | fairseq.trainer | begin training epoch 316
2022-03-06 00:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:29:35 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.658 | nll_loss 13.046 | ppl 8457.26 | wps 46473 | wpb 510.9 | bsz 1 | num_updates 15379 | best_loss 8.953
2022-03-06 00:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15379 updates
2022-03-06 00:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 316 @ 15379 updates, score 13.658) (writing took 1.6988860154524446 seconds)
2022-03-06 00:29:37 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-06 00:29:37 | INFO | train | epoch 316 | loss 2.216 | nll_loss 0.417 | ppl 1.34 | wps 27626.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15379 | lr 0.000254998 | gnorm 0.515 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36415
2022-03-06 00:29:37 | INFO | fairseq.trainer | begin training epoch 317
2022-03-06 00:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:29:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:30:26 | INFO | train_inner | epoch 317:     22 / 49 loss=2.216, nll_loss=0.418, ppl=1.34, wps=27412.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.513, loss_scale=32, train_wall=201, gb_free=21.6, wall=36464
2022-03-06 00:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:31:30 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.418 | nll_loss 12.79 | ppl 7080.16 | wps 46189.4 | wpb 510.9 | bsz 1 | num_updates 15427 | best_loss 8.953
2022-03-06 00:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15427 updates
2022-03-06 00:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 317 @ 15427 updates, score 13.418) (writing took 1.6124622449278831 seconds)
2022-03-06 00:31:32 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-06 00:31:32 | INFO | train | epoch 317 | loss 2.214 | nll_loss 0.415 | ppl 1.33 | wps 27074.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15427 | lr 0.000254601 | gnorm 0.512 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36530
2022-03-06 00:31:32 | INFO | fairseq.trainer | begin training epoch 318
2022-03-06 00:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:33:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:33:25 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.55 | nll_loss 12.932 | ppl 7813.69 | wps 46463.4 | wpb 510.9 | bsz 1 | num_updates 15476 | best_loss 8.953
2022-03-06 00:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15476 updates
2022-03-06 00:33:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:33:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:33:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 318 @ 15476 updates, score 13.55) (writing took 1.6908102286979556 seconds)
2022-03-06 00:33:26 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-06 00:33:26 | INFO | train | epoch 318 | loss 2.214 | nll_loss 0.416 | ppl 1.33 | wps 27673.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15476 | lr 0.000254197 | gnorm 0.508 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36645
2022-03-06 00:33:26 | INFO | fairseq.trainer | begin training epoch 319
2022-03-06 00:33:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:34:20 | INFO | train_inner | epoch 319:     24 / 49 loss=2.213, nll_loss=0.415, ppl=1.33, wps=27684.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.507, loss_scale=32, train_wall=199, gb_free=21.6, wall=36699
2022-03-06 00:34:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:35:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:35:20 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.56 | nll_loss 12.949 | ppl 7906.27 | wps 46471 | wpb 510.9 | bsz 1 | num_updates 15524 | best_loss 8.953
2022-03-06 00:35:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15524 updates
2022-03-06 00:35:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:35:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:35:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 319 @ 15524 updates, score 13.56) (writing took 1.6964979134500027 seconds)
2022-03-06 00:35:21 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-06 00:35:21 | INFO | train | epoch 319 | loss 2.213 | nll_loss 0.415 | ppl 1.33 | wps 27101.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15524 | lr 0.000253804 | gnorm 0.508 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36760
2022-03-06 00:35:21 | INFO | fairseq.trainer | begin training epoch 320
2022-03-06 00:35:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:37:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:37:14 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.572 | nll_loss 12.956 | ppl 7946.56 | wps 46497 | wpb 510.9 | bsz 1 | num_updates 15573 | best_loss 8.953
2022-03-06 00:37:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15573 updates
2022-03-06 00:37:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:37:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 320 @ 15573 updates, score 13.572) (writing took 1.645548620261252 seconds)
2022-03-06 00:37:16 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-06 00:37:16 | INFO | train | epoch 320 | loss 2.211 | nll_loss 0.414 | ppl 1.33 | wps 27689.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15573 | lr 0.000253404 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36875
2022-03-06 00:37:16 | INFO | fairseq.trainer | begin training epoch 321
2022-03-06 00:37:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:38:17 | INFO | train_inner | epoch 321:     27 / 49 loss=2.211, nll_loss=0.414, ppl=1.33, wps=27450.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.507, loss_scale=32, train_wall=201, gb_free=21.6, wall=36935
2022-03-06 00:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:39:09 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.523 | nll_loss 12.903 | ppl 7659.77 | wps 45801.5 | wpb 510.9 | bsz 1 | num_updates 15622 | best_loss 8.953
2022-03-06 00:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15622 updates
2022-03-06 00:39:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:39:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:39:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 321 @ 15622 updates, score 13.523) (writing took 1.6893451707437634 seconds)
2022-03-06 00:39:11 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-06 00:39:11 | INFO | train | epoch 321 | loss 2.21 | nll_loss 0.413 | ppl 1.33 | wps 27633.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15622 | lr 0.000253007 | gnorm 0.512 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 36990
2022-03-06 00:39:11 | INFO | fairseq.trainer | begin training epoch 322
2022-03-06 00:39:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:40:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:41:04 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.496 | nll_loss 12.878 | ppl 7526.71 | wps 46231.2 | wpb 510.9 | bsz 1 | num_updates 15670 | best_loss 8.953
2022-03-06 00:41:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15670 updates
2022-03-06 00:41:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:41:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:41:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 322 @ 15670 updates, score 13.496) (writing took 1.6490623373538256 seconds)
2022-03-06 00:41:06 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-06 00:41:06 | INFO | train | epoch 322 | loss 2.209 | nll_loss 0.412 | ppl 1.33 | wps 27079.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15670 | lr 0.000252619 | gnorm 0.503 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37105
2022-03-06 00:41:06 | INFO | fairseq.trainer | begin training epoch 323
2022-03-06 00:41:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:42:13 | INFO | train_inner | epoch 323:     30 / 49 loss=2.21, nll_loss=0.413, ppl=1.33, wps=27413.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.504, loss_scale=32, train_wall=201, gb_free=21.6, wall=37172
2022-03-06 00:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:42:59 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.677 | nll_loss 13.074 | ppl 8625.67 | wps 46317.4 | wpb 510.9 | bsz 1 | num_updates 15719 | best_loss 8.953
2022-03-06 00:42:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15719 updates
2022-03-06 00:42:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:43:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:43:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 323 @ 15719 updates, score 13.677) (writing took 1.6872516619041562 seconds)
2022-03-06 00:43:01 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-06 00:43:01 | INFO | train | epoch 323 | loss 2.208 | nll_loss 0.412 | ppl 1.33 | wps 27645.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15719 | lr 0.000252225 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37220
2022-03-06 00:43:01 | INFO | fairseq.trainer | begin training epoch 324
2022-03-06 00:43:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:44:54 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.557 | nll_loss 12.942 | ppl 7871.03 | wps 46391.2 | wpb 510.9 | bsz 1 | num_updates 15768 | best_loss 8.953
2022-03-06 00:44:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15768 updates
2022-03-06 00:44:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:44:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:44:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 324 @ 15768 updates, score 13.557) (writing took 1.6351611940190196 seconds)
2022-03-06 00:44:56 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-06 00:44:56 | INFO | train | epoch 324 | loss 2.208 | nll_loss 0.411 | ppl 1.33 | wps 27660.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15768 | lr 0.000251832 | gnorm 0.514 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37334
2022-03-06 00:44:56 | INFO | fairseq.trainer | begin training epoch 325
2022-03-06 00:44:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:45:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:46:10 | INFO | train_inner | epoch 325:     33 / 49 loss=2.207, nll_loss=0.41, ppl=1.33, wps=27434.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.506, loss_scale=32, train_wall=201, gb_free=21.6, wall=37408
2022-03-06 00:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:46:49 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.53 | nll_loss 12.912 | ppl 7705.31 | wps 46364.2 | wpb 510.9 | bsz 1 | num_updates 15816 | best_loss 8.953
2022-03-06 00:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15816 updates
2022-03-06 00:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 325 @ 15816 updates, score 13.53) (writing took 1.6619019517675042 seconds)
2022-03-06 00:46:51 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-06 00:46:51 | INFO | train | epoch 325 | loss 2.206 | nll_loss 0.41 | ppl 1.33 | wps 27107.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15816 | lr 0.00025145 | gnorm 0.499 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37449
2022-03-06 00:46:51 | INFO | fairseq.trainer | begin training epoch 326
2022-03-06 00:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:48:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:48:44 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.515 | nll_loss 12.896 | ppl 7624.54 | wps 46366.3 | wpb 510.9 | bsz 1 | num_updates 15865 | best_loss 8.953
2022-03-06 00:48:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15865 updates
2022-03-06 00:48:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 326 @ 15865 updates, score 13.515) (writing took 1.648000136949122 seconds)
2022-03-06 00:48:46 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-06 00:48:46 | INFO | train | epoch 326 | loss 2.206 | nll_loss 0.41 | ppl 1.33 | wps 27641.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15865 | lr 0.000251061 | gnorm 0.503 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37564
2022-03-06 00:48:46 | INFO | fairseq.trainer | begin training epoch 327
2022-03-06 00:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:50:04 | INFO | train_inner | epoch 327:     35 / 49 loss=2.206, nll_loss=0.41, ppl=1.33, wps=27682, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.501, loss_scale=32, train_wall=199, gb_free=21.6, wall=37643
2022-03-06 00:50:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 00:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:50:39 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.551 | nll_loss 12.928 | ppl 7794.04 | wps 46446.3 | wpb 510.9 | bsz 1 | num_updates 15913 | best_loss 8.953
2022-03-06 00:50:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15913 updates
2022-03-06 00:50:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:50:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:50:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 327 @ 15913 updates, score 13.551) (writing took 1.63310965616256 seconds)
2022-03-06 00:50:40 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-06 00:50:40 | INFO | train | epoch 327 | loss 2.205 | nll_loss 0.409 | ppl 1.33 | wps 27098.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 15913 | lr 0.000250682 | gnorm 0.501 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37679
2022-03-06 00:50:41 | INFO | fairseq.trainer | begin training epoch 328
2022-03-06 00:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:52:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:52:34 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.616 | nll_loss 13.007 | ppl 8231.09 | wps 46362.7 | wpb 510.9 | bsz 1 | num_updates 15962 | best_loss 8.953
2022-03-06 00:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15962 updates
2022-03-06 00:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:52:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 328 @ 15962 updates, score 13.616) (writing took 1.6546289790421724 seconds)
2022-03-06 00:52:35 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-06 00:52:35 | INFO | train | epoch 328 | loss 2.203 | nll_loss 0.407 | ppl 1.33 | wps 27660.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 15962 | lr 0.000250297 | gnorm 0.5 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 37794
2022-03-06 00:52:35 | INFO | fairseq.trainer | begin training epoch 329
2022-03-06 00:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:53:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 00:54:03 | INFO | train_inner | epoch 329:     39 / 49 loss=2.203, nll_loss=0.407, ppl=1.33, wps=27167.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.5, loss_scale=16, train_wall=203, gb_free=21.6, wall=37881
2022-03-06 00:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:54:29 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.486 | nll_loss 12.864 | ppl 7457.25 | wps 46425.4 | wpb 510.9 | bsz 1 | num_updates 16010 | best_loss 8.953
2022-03-06 00:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16010 updates
2022-03-06 00:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:54:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:54:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 329 @ 16010 updates, score 13.486) (writing took 1.6487299166619778 seconds)
2022-03-06 00:54:30 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-06 00:54:30 | INFO | train | epoch 329 | loss 2.202 | nll_loss 0.407 | ppl 1.33 | wps 27064.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16010 | lr 0.000249922 | gnorm 0.498 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 37909
2022-03-06 00:54:30 | INFO | fairseq.trainer | begin training epoch 330
2022-03-06 00:54:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:56:24 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.583 | nll_loss 12.973 | ppl 8039.13 | wps 45672 | wpb 510.9 | bsz 1 | num_updates 16059 | best_loss 8.953
2022-03-06 00:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16059 updates
2022-03-06 00:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:56:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:56:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 330 @ 16059 updates, score 13.583) (writing took 1.6566290920600295 seconds)
2022-03-06 00:56:25 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-06 00:56:25 | INFO | train | epoch 330 | loss 2.202 | nll_loss 0.407 | ppl 1.33 | wps 27616.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16059 | lr 0.00024954 | gnorm 0.51 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 38024
2022-03-06 00:56:25 | INFO | fairseq.trainer | begin training epoch 331
2022-03-06 00:56:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 00:57:57 | INFO | train_inner | epoch 331:     41 / 49 loss=2.202, nll_loss=0.407, ppl=1.33, wps=27663.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.505, loss_scale=16, train_wall=199, gb_free=21.6, wall=38116
2022-03-06 00:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 00:58:19 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.545 | nll_loss 12.929 | ppl 7799.66 | wps 46532 | wpb 510.9 | bsz 1 | num_updates 16108 | best_loss 8.953
2022-03-06 00:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16108 updates
2022-03-06 00:58:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 00:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 331 @ 16108 updates, score 13.545) (writing took 1.682409324683249 seconds)
2022-03-06 00:58:20 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-06 00:58:20 | INFO | train | epoch 331 | loss 2.201 | nll_loss 0.406 | ppl 1.32 | wps 27638.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16108 | lr 0.00024916 | gnorm 0.499 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 38139
2022-03-06 00:58:20 | INFO | fairseq.trainer | begin training epoch 332
2022-03-06 00:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:00:14 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.589 | nll_loss 12.978 | ppl 8066.58 | wps 46329.8 | wpb 510.9 | bsz 1 | num_updates 16157 | best_loss 8.953
2022-03-06 01:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16157 updates
2022-03-06 01:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 332 @ 16157 updates, score 13.589) (writing took 1.6690132161602378 seconds)
2022-03-06 01:00:15 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-06 01:00:15 | INFO | train | epoch 332 | loss 2.199 | nll_loss 0.404 | ppl 1.32 | wps 27657.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16157 | lr 0.000248782 | gnorm 0.488 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38254
2022-03-06 01:00:15 | INFO | fairseq.trainer | begin training epoch 333
2022-03-06 01:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:01:52 | INFO | train_inner | epoch 333:     43 / 49 loss=2.199, nll_loss=0.404, ppl=1.32, wps=27694.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.488, loss_scale=32, train_wall=199, gb_free=21.6, wall=38350
2022-03-06 01:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:02:09 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.566 | nll_loss 12.956 | ppl 7944.84 | wps 46441.6 | wpb 510.9 | bsz 1 | num_updates 16206 | best_loss 8.953
2022-03-06 01:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16206 updates
2022-03-06 01:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 333 @ 16206 updates, score 13.566) (writing took 1.649489157833159 seconds)
2022-03-06 01:02:10 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-06 01:02:10 | INFO | train | epoch 333 | loss 2.198 | nll_loss 0.404 | ppl 1.32 | wps 27673.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16206 | lr 0.000248406 | gnorm 0.488 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38369
2022-03-06 01:02:10 | INFO | fairseq.trainer | begin training epoch 334
2022-03-06 01:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:03:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:03:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:04:03 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.428 | nll_loss 12.808 | ppl 7170.31 | wps 46403.7 | wpb 510.9 | bsz 1 | num_updates 16254 | best_loss 8.953
2022-03-06 01:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16254 updates
2022-03-06 01:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 334 @ 16254 updates, score 13.428) (writing took 1.665837493725121 seconds)
2022-03-06 01:04:05 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-06 01:04:05 | INFO | train | epoch 334 | loss 2.198 | nll_loss 0.404 | ppl 1.32 | wps 27083.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16254 | lr 0.000248039 | gnorm 0.503 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38484
2022-03-06 01:04:05 | INFO | fairseq.trainer | begin training epoch 335
2022-03-06 01:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:05:48 | INFO | train_inner | epoch 335:     46 / 49 loss=2.198, nll_loss=0.404, ppl=1.32, wps=27418.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.505, loss_scale=32, train_wall=201, gb_free=21.6, wall=38587
2022-03-06 01:05:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:05:58 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.605 | nll_loss 12.996 | ppl 8168.69 | wps 46303.1 | wpb 510.9 | bsz 1 | num_updates 16303 | best_loss 8.953
2022-03-06 01:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16303 updates
2022-03-06 01:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:06:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:06:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 335 @ 16303 updates, score 13.605) (writing took 1.6494970498606563 seconds)
2022-03-06 01:06:00 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-06 01:06:00 | INFO | train | epoch 335 | loss 2.197 | nll_loss 0.403 | ppl 1.32 | wps 27638.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16303 | lr 0.000247666 | gnorm 0.507 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38599
2022-03-06 01:06:00 | INFO | fairseq.trainer | begin training epoch 336
2022-03-06 01:06:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:07:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:07:53 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.517 | nll_loss 12.899 | ppl 7640.67 | wps 46292.4 | wpb 510.9 | bsz 1 | num_updates 16352 | best_loss 8.953
2022-03-06 01:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16352 updates
2022-03-06 01:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 336 @ 16352 updates, score 13.517) (writing took 1.6524100564420223 seconds)
2022-03-06 01:07:55 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-06 01:07:55 | INFO | train | epoch 336 | loss 2.197 | nll_loss 0.402 | ppl 1.32 | wps 27673.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16352 | lr 0.000247295 | gnorm 0.497 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38714
2022-03-06 01:07:55 | INFO | fairseq.trainer | begin training epoch 337
2022-03-06 01:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:09:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:09:43 | INFO | train_inner | epoch 337:     49 / 49 loss=2.196, nll_loss=0.402, ppl=1.32, wps=27430.4, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=16400, lr=0.000246932, gnorm=0.496, loss_scale=32, train_wall=200, gb_free=21.6, wall=38822
2022-03-06 01:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:09:48 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.602 | nll_loss 12.991 | ppl 8142.07 | wps 46591.5 | wpb 510.9 | bsz 1 | num_updates 16400 | best_loss 8.953
2022-03-06 01:09:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16400 updates
2022-03-06 01:09:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:09:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:09:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 337 @ 16400 updates, score 13.602) (writing took 1.6822111597284675 seconds)
2022-03-06 01:09:50 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-06 01:09:50 | INFO | train | epoch 337 | loss 2.194 | nll_loss 0.4 | ppl 1.32 | wps 27099.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16400 | lr 0.000246932 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38828
2022-03-06 01:09:50 | INFO | fairseq.trainer | begin training epoch 338
2022-03-06 01:09:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:11:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:11:43 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.493 | nll_loss 12.88 | ppl 7536.54 | wps 46661.5 | wpb 510.9 | bsz 1 | num_updates 16449 | best_loss 8.953
2022-03-06 01:11:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16449 updates
2022-03-06 01:11:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:11:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:11:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 338 @ 16449 updates, score 13.493) (writing took 1.6587211890146136 seconds)
2022-03-06 01:11:45 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-06 01:11:45 | INFO | train | epoch 338 | loss 2.195 | nll_loss 0.401 | ppl 1.32 | wps 27670 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16449 | lr 0.000246564 | gnorm 0.498 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 38943
2022-03-06 01:11:45 | INFO | fairseq.trainer | begin training epoch 339
2022-03-06 01:11:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:13:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:13:38 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.658 | nll_loss 13.054 | ppl 8505.65 | wps 46302.3 | wpb 510.9 | bsz 1 | num_updates 16498 | best_loss 8.953
2022-03-06 01:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16498 updates
2022-03-06 01:13:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 339 @ 16498 updates, score 13.658) (writing took 1.6665305336937308 seconds)
2022-03-06 01:13:40 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-06 01:13:40 | INFO | train | epoch 339 | loss 2.194 | nll_loss 0.401 | ppl 1.32 | wps 27666 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16498 | lr 0.000246198 | gnorm 0.499 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39058
2022-03-06 01:13:40 | INFO | fairseq.trainer | begin training epoch 340
2022-03-06 01:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:13:44 | INFO | train_inner | epoch 340:      2 / 49 loss=2.194, nll_loss=0.401, ppl=1.32, wps=26951.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16500, lr=0.000246183, gnorm=0.498, loss_scale=32, train_wall=199, gb_free=21.6, wall=39063
2022-03-06 01:14:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:15:33 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.574 | nll_loss 12.963 | ppl 7982.14 | wps 46341.4 | wpb 510.9 | bsz 1 | num_updates 16546 | best_loss 8.953
2022-03-06 01:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16546 updates
2022-03-06 01:15:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 340 @ 16546 updates, score 13.574) (writing took 1.6685830662027001 seconds)
2022-03-06 01:15:34 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-06 01:15:34 | INFO | train | epoch 340 | loss 2.193 | nll_loss 0.4 | ppl 1.32 | wps 27090.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16546 | lr 0.000245841 | gnorm 0.502 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39173
2022-03-06 01:15:34 | INFO | fairseq.trainer | begin training epoch 341
2022-03-06 01:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:17:28 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.449 | nll_loss 12.83 | ppl 7282.17 | wps 46407.2 | wpb 510.9 | bsz 1 | num_updates 16595 | best_loss 8.953
2022-03-06 01:17:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16595 updates
2022-03-06 01:17:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:17:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 341 @ 16595 updates, score 13.449) (writing took 1.6568556306883693 seconds)
2022-03-06 01:17:29 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-06 01:17:29 | INFO | train | epoch 341 | loss 2.191 | nll_loss 0.398 | ppl 1.32 | wps 27687.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16595 | lr 0.000245477 | gnorm 0.483 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39288
2022-03-06 01:17:29 | INFO | fairseq.trainer | begin training epoch 342
2022-03-06 01:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:17:40 | INFO | train_inner | epoch 342:      5 / 49 loss=2.191, nll_loss=0.398, ppl=1.32, wps=27446.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.492, loss_scale=32, train_wall=201, gb_free=21.6, wall=39299
2022-03-06 01:19:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:19:23 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.585 | nll_loss 12.971 | ppl 8029.71 | wps 46405.1 | wpb 510.9 | bsz 1 | num_updates 16643 | best_loss 8.953
2022-03-06 01:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16643 updates
2022-03-06 01:19:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:19:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:19:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 342 @ 16643 updates, score 13.585) (writing took 1.645423885434866 seconds)
2022-03-06 01:19:24 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-06 01:19:24 | INFO | train | epoch 342 | loss 2.192 | nll_loss 0.399 | ppl 1.32 | wps 27069.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16643 | lr 0.000245123 | gnorm 0.5 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39403
2022-03-06 01:19:24 | INFO | fairseq.trainer | begin training epoch 343
2022-03-06 01:19:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:21:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:21:17 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.577 | nll_loss 12.965 | ppl 7997.08 | wps 46388.1 | wpb 510.9 | bsz 1 | num_updates 16692 | best_loss 8.953
2022-03-06 01:21:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16692 updates
2022-03-06 01:21:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:21:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:21:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 343 @ 16692 updates, score 13.577) (writing took 1.6861882479861379 seconds)
2022-03-06 01:21:19 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-06 01:21:19 | INFO | train | epoch 343 | loss 2.19 | nll_loss 0.397 | ppl 1.32 | wps 27644.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16692 | lr 0.000244763 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39518
2022-03-06 01:21:19 | INFO | fairseq.trainer | begin training epoch 344
2022-03-06 01:21:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:21:37 | INFO | train_inner | epoch 344:      8 / 49 loss=2.191, nll_loss=0.398, ppl=1.32, wps=27412.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.497, loss_scale=32, train_wall=201, gb_free=21.6, wall=39536
2022-03-06 01:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:23:12 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.526 | nll_loss 12.915 | ppl 7721.06 | wps 46367.4 | wpb 510.9 | bsz 1 | num_updates 16741 | best_loss 8.953
2022-03-06 01:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16741 updates
2022-03-06 01:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 344 @ 16741 updates, score 13.526) (writing took 1.6529921917244792 seconds)
2022-03-06 01:23:14 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-06 01:23:14 | INFO | train | epoch 344 | loss 2.189 | nll_loss 0.397 | ppl 1.32 | wps 27674.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16741 | lr 0.000244405 | gnorm 0.494 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39633
2022-03-06 01:23:14 | INFO | fairseq.trainer | begin training epoch 345
2022-03-06 01:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:24:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:25:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:25:07 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.628 | nll_loss 13.021 | ppl 8312.83 | wps 46439.1 | wpb 510.9 | bsz 1 | num_updates 16789 | best_loss 8.953
2022-03-06 01:25:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16789 updates
2022-03-06 01:25:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:25:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 345 @ 16789 updates, score 13.628) (writing took 1.6399252591654658 seconds)
2022-03-06 01:25:09 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-06 01:25:09 | INFO | train | epoch 345 | loss 2.189 | nll_loss 0.397 | ppl 1.32 | wps 27080.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16789 | lr 0.000244055 | gnorm 0.5 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39748
2022-03-06 01:25:09 | INFO | fairseq.trainer | begin training epoch 346
2022-03-06 01:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:25:34 | INFO | train_inner | epoch 346:     11 / 49 loss=2.188, nll_loss=0.396, ppl=1.32, wps=27434.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.496, loss_scale=32, train_wall=201, gb_free=21.6, wall=39772
2022-03-06 01:26:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:27:02 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.554 | nll_loss 12.946 | ppl 7890.62 | wps 46252.7 | wpb 510.9 | bsz 1 | num_updates 16838 | best_loss 8.953
2022-03-06 01:27:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16838 updates
2022-03-06 01:27:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:27:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:27:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 346 @ 16838 updates, score 13.554) (writing took 1.6639000782743096 seconds)
2022-03-06 01:27:04 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-06 01:27:04 | INFO | train | epoch 346 | loss 2.187 | nll_loss 0.395 | ppl 1.32 | wps 27660.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16838 | lr 0.0002437 | gnorm 0.489 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39862
2022-03-06 01:27:04 | INFO | fairseq.trainer | begin training epoch 347
2022-03-06 01:27:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:28:57 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.591 | nll_loss 12.981 | ppl 8087.12 | wps 46349.2 | wpb 510.9 | bsz 1 | num_updates 16887 | best_loss 8.953
2022-03-06 01:28:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16887 updates
2022-03-06 01:28:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 347 @ 16887 updates, score 13.591) (writing took 1.6912046251818538 seconds)
2022-03-06 01:28:59 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-06 01:28:59 | INFO | train | epoch 347 | loss 2.185 | nll_loss 0.394 | ppl 1.31 | wps 27675.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 16887 | lr 0.000243346 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 39977
2022-03-06 01:28:59 | INFO | fairseq.trainer | begin training epoch 348
2022-03-06 01:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:29:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:29:30 | INFO | train_inner | epoch 348:     14 / 49 loss=2.186, nll_loss=0.394, ppl=1.31, wps=27440.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.482, loss_scale=32, train_wall=201, gb_free=21.6, wall=40009
2022-03-06 01:30:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:30:52 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.421 | nll_loss 12.8 | ppl 7132.17 | wps 46426.2 | wpb 510.9 | bsz 1 | num_updates 16935 | best_loss 8.953
2022-03-06 01:30:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16935 updates
2022-03-06 01:30:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:30:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:30:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 348 @ 16935 updates, score 13.421) (writing took 1.6301995851099491 seconds)
2022-03-06 01:30:54 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-06 01:30:54 | INFO | train | epoch 348 | loss 2.187 | nll_loss 0.395 | ppl 1.32 | wps 27088.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16935 | lr 0.000243001 | gnorm 0.493 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40092
2022-03-06 01:30:54 | INFO | fairseq.trainer | begin training epoch 349
2022-03-06 01:30:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:32:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 01:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:32:47 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.46 | nll_loss 12.839 | ppl 7326.16 | wps 46480 | wpb 510.9 | bsz 1 | num_updates 16983 | best_loss 8.953
2022-03-06 01:32:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16983 updates
2022-03-06 01:32:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:32:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:32:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 349 @ 16983 updates, score 13.46) (writing took 1.6296804090961814 seconds)
2022-03-06 01:32:48 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-06 01:32:48 | INFO | train | epoch 349 | loss 2.185 | nll_loss 0.393 | ppl 1.31 | wps 27085.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 16983 | lr 0.000242657 | gnorm 0.493 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 40207
2022-03-06 01:32:48 | INFO | fairseq.trainer | begin training epoch 350
2022-03-06 01:32:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:33:27 | INFO | train_inner | epoch 350:     17 / 49 loss=2.185, nll_loss=0.394, ppl=1.31, wps=27422.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.493, loss_scale=16, train_wall=201, gb_free=21.6, wall=40245
2022-03-06 01:34:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:34:42 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.659 | nll_loss 13.057 | ppl 8522.48 | wps 46404.9 | wpb 510.9 | bsz 1 | num_updates 17032 | best_loss 8.953
2022-03-06 01:34:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17032 updates
2022-03-06 01:34:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:34:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:34:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 350 @ 17032 updates, score 13.659) (writing took 1.65698710270226 seconds)
2022-03-06 01:34:43 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-06 01:34:43 | INFO | train | epoch 350 | loss 2.185 | nll_loss 0.393 | ppl 1.31 | wps 27646.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17032 | lr 0.000242308 | gnorm 0.499 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 40322
2022-03-06 01:34:43 | INFO | fairseq.trainer | begin training epoch 351
2022-03-06 01:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:36:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:36:37 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.532 | nll_loss 12.922 | ppl 7760.51 | wps 46502.7 | wpb 510.9 | bsz 1 | num_updates 17081 | best_loss 8.953
2022-03-06 01:36:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17081 updates
2022-03-06 01:36:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 351 @ 17081 updates, score 13.532) (writing took 1.7002649549394846 seconds)
2022-03-06 01:36:38 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-06 01:36:38 | INFO | train | epoch 351 | loss 2.184 | nll_loss 0.393 | ppl 1.31 | wps 27629.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17081 | lr 0.00024196 | gnorm 0.495 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 40437
2022-03-06 01:36:38 | INFO | fairseq.trainer | begin training epoch 352
2022-03-06 01:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:37:21 | INFO | train_inner | epoch 352:     19 / 49 loss=2.184, nll_loss=0.393, ppl=1.31, wps=27670.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.495, loss_scale=16, train_wall=199, gb_free=21.6, wall=40480
2022-03-06 01:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:38:32 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.601 | nll_loss 12.997 | ppl 8176.56 | wps 46514.5 | wpb 510.9 | bsz 1 | num_updates 17130 | best_loss 8.953
2022-03-06 01:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17130 updates
2022-03-06 01:38:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:38:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:38:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 352 @ 17130 updates, score 13.601) (writing took 1.6315479222685099 seconds)
2022-03-06 01:38:33 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-06 01:38:33 | INFO | train | epoch 352 | loss 2.182 | nll_loss 0.391 | ppl 1.31 | wps 27684.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17130 | lr 0.000241614 | gnorm 0.486 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40552
2022-03-06 01:38:33 | INFO | fairseq.trainer | begin training epoch 353
2022-03-06 01:38:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:40:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:40:27 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.592 | nll_loss 12.985 | ppl 8107.43 | wps 46089.6 | wpb 510.9 | bsz 1 | num_updates 17179 | best_loss 8.953
2022-03-06 01:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17179 updates
2022-03-06 01:40:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:40:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:40:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 353 @ 17179 updates, score 13.592) (writing took 1.6534057408571243 seconds)
2022-03-06 01:40:28 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-06 01:40:28 | INFO | train | epoch 353 | loss 2.181 | nll_loss 0.39 | ppl 1.31 | wps 27644.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17179 | lr 0.000241269 | gnorm 0.484 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40667
2022-03-06 01:40:28 | INFO | fairseq.trainer | begin training epoch 354
2022-03-06 01:40:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:41:15 | INFO | train_inner | epoch 354:     21 / 49 loss=2.181, nll_loss=0.39, ppl=1.31, wps=27685.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.486, loss_scale=32, train_wall=199, gb_free=21.6, wall=40714
2022-03-06 01:42:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:42:21 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.522 | nll_loss 12.916 | ppl 7726.24 | wps 46270.5 | wpb 510.9 | bsz 1 | num_updates 17228 | best_loss 8.953
2022-03-06 01:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17228 updates
2022-03-06 01:42:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 354 @ 17228 updates, score 13.522) (writing took 1.6414264980703592 seconds)
2022-03-06 01:42:23 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-06 01:42:23 | INFO | train | epoch 354 | loss 2.181 | nll_loss 0.39 | ppl 1.31 | wps 27658.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17228 | lr 0.000240925 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40782
2022-03-06 01:42:23 | INFO | fairseq.trainer | begin training epoch 355
2022-03-06 01:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:42:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:44:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:44:16 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.548 | nll_loss 12.939 | ppl 7851.89 | wps 46498.9 | wpb 510.9 | bsz 1 | num_updates 17276 | best_loss 8.953
2022-03-06 01:44:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17276 updates
2022-03-06 01:44:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:44:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:44:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 355 @ 17276 updates, score 13.548) (writing took 1.6259444719180465 seconds)
2022-03-06 01:44:18 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-06 01:44:18 | INFO | train | epoch 355 | loss 2.18 | nll_loss 0.39 | ppl 1.31 | wps 27091.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17276 | lr 0.00024059 | gnorm 0.481 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 40897
2022-03-06 01:44:18 | INFO | fairseq.trainer | begin training epoch 356
2022-03-06 01:44:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:45:12 | INFO | train_inner | epoch 356:     24 / 49 loss=2.18, nll_loss=0.39, ppl=1.31, wps=27431.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.478, loss_scale=32, train_wall=201, gb_free=21.6, wall=40950
2022-03-06 01:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:46:11 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.616 | nll_loss 13.017 | ppl 8286.39 | wps 46382 | wpb 510.9 | bsz 1 | num_updates 17325 | best_loss 8.953
2022-03-06 01:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17325 updates
2022-03-06 01:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:46:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 356 @ 17325 updates, score 13.616) (writing took 1.6222071973606944 seconds)
2022-03-06 01:46:13 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-06 01:46:13 | INFO | train | epoch 356 | loss 2.18 | nll_loss 0.39 | ppl 1.31 | wps 27656.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17325 | lr 0.00024025 | gnorm 0.49 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41012
2022-03-06 01:46:13 | INFO | fairseq.trainer | begin training epoch 357
2022-03-06 01:46:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:47:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:48:06 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.526 | nll_loss 12.918 | ppl 7737.89 | wps 46372.6 | wpb 510.9 | bsz 1 | num_updates 17373 | best_loss 8.953
2022-03-06 01:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17373 updates
2022-03-06 01:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:48:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:48:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 357 @ 17373 updates, score 13.526) (writing took 1.6860222751274705 seconds)
2022-03-06 01:48:08 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-06 01:48:08 | INFO | train | epoch 357 | loss 2.179 | nll_loss 0.388 | ppl 1.31 | wps 27072.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17373 | lr 0.000239918 | gnorm 0.492 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41127
2022-03-06 01:48:08 | INFO | fairseq.trainer | begin training epoch 358
2022-03-06 01:48:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:49:08 | INFO | train_inner | epoch 358:     27 / 49 loss=2.179, nll_loss=0.389, ppl=1.31, wps=27414.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.49, loss_scale=32, train_wall=201, gb_free=21.6, wall=41187
2022-03-06 01:49:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:50:01 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.496 | nll_loss 12.882 | ppl 7548.8 | wps 46535.9 | wpb 510.9 | bsz 1 | num_updates 17422 | best_loss 8.953
2022-03-06 01:50:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17422 updates
2022-03-06 01:50:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 358 @ 17422 updates, score 13.496) (writing took 1.6821022033691406 seconds)
2022-03-06 01:50:03 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-06 01:50:03 | INFO | train | epoch 358 | loss 2.177 | nll_loss 0.387 | ppl 1.31 | wps 27643.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17422 | lr 0.00023958 | gnorm 0.479 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41241
2022-03-06 01:50:03 | INFO | fairseq.trainer | begin training epoch 359
2022-03-06 01:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:51:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:51:56 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.605 | nll_loss 12.997 | ppl 8172.43 | wps 45959.2 | wpb 510.9 | bsz 1 | num_updates 17471 | best_loss 8.953
2022-03-06 01:51:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17471 updates
2022-03-06 01:51:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:51:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 359 @ 17471 updates, score 13.605) (writing took 1.635551517829299 seconds)
2022-03-06 01:51:58 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-06 01:51:58 | INFO | train | epoch 359 | loss 2.175 | nll_loss 0.385 | ppl 1.31 | wps 27638.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17471 | lr 0.000239244 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41356
2022-03-06 01:51:58 | INFO | fairseq.trainer | begin training epoch 360
2022-03-06 01:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:52:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:53:05 | INFO | train_inner | epoch 360:     30 / 49 loss=2.176, nll_loss=0.386, ppl=1.31, wps=27425.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.479, loss_scale=32, train_wall=201, gb_free=21.6, wall=41424
2022-03-06 01:53:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:53:51 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.506 | nll_loss 12.895 | ppl 7616.82 | wps 46338.4 | wpb 510.9 | bsz 1 | num_updates 17519 | best_loss 8.953
2022-03-06 01:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17519 updates
2022-03-06 01:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:53:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:53:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 360 @ 17519 updates, score 13.506) (writing took 1.6672820718958974 seconds)
2022-03-06 01:53:53 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-06 01:53:53 | INFO | train | epoch 360 | loss 2.176 | nll_loss 0.386 | ppl 1.31 | wps 27103.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17519 | lr 0.000238916 | gnorm 0.49 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41471
2022-03-06 01:53:53 | INFO | fairseq.trainer | begin training epoch 361
2022-03-06 01:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:55:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:55:46 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.522 | nll_loss 12.914 | ppl 7715.79 | wps 46277.8 | wpb 510.9 | bsz 1 | num_updates 17568 | best_loss 8.953
2022-03-06 01:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17568 updates
2022-03-06 01:55:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:55:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:55:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 361 @ 17568 updates, score 13.522) (writing took 1.6729216976091266 seconds)
2022-03-06 01:55:48 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-06 01:55:48 | INFO | train | epoch 361 | loss 2.175 | nll_loss 0.386 | ppl 1.31 | wps 27624.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17568 | lr 0.000238583 | gnorm 0.481 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41586
2022-03-06 01:55:48 | INFO | fairseq.trainer | begin training epoch 362
2022-03-06 01:55:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:56:59 | INFO | train_inner | epoch 362:     32 / 49 loss=2.175, nll_loss=0.386, ppl=1.31, wps=27669.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.48, loss_scale=32, train_wall=199, gb_free=21.6, wall=41658
2022-03-06 01:57:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:57:41 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.508 | nll_loss 12.898 | ppl 7633.94 | wps 46584.5 | wpb 510.9 | bsz 1 | num_updates 17617 | best_loss 8.953
2022-03-06 01:57:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17617 updates
2022-03-06 01:57:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:57:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:57:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 362 @ 17617 updates, score 13.508) (writing took 1.633883967064321 seconds)
2022-03-06 01:57:43 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-06 01:57:43 | INFO | train | epoch 362 | loss 2.175 | nll_loss 0.386 | ppl 1.31 | wps 27655.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17617 | lr 0.000238251 | gnorm 0.48 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41701
2022-03-06 01:57:43 | INFO | fairseq.trainer | begin training epoch 363
2022-03-06 01:57:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 01:58:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 01:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 01:59:36 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.483 | nll_loss 12.866 | ppl 7463.32 | wps 46487.9 | wpb 510.9 | bsz 1 | num_updates 17665 | best_loss 8.953
2022-03-06 01:59:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17665 updates
2022-03-06 01:59:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:59:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 01:59:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 363 @ 17665 updates, score 13.483) (writing took 1.6420021597296 seconds)
2022-03-06 01:59:38 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-06 01:59:38 | INFO | train | epoch 363 | loss 2.174 | nll_loss 0.385 | ppl 1.31 | wps 27074.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17665 | lr 0.000237927 | gnorm 0.476 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41816
2022-03-06 01:59:38 | INFO | fairseq.trainer | begin training epoch 364
2022-03-06 01:59:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:00:56 | INFO | train_inner | epoch 364:     35 / 49 loss=2.173, nll_loss=0.384, ppl=1.31, wps=27422.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.476, loss_scale=32, train_wall=201, gb_free=21.6, wall=41895
2022-03-06 02:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:01:31 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.552 | nll_loss 12.942 | ppl 7870.8 | wps 46427.6 | wpb 510.9 | bsz 1 | num_updates 17714 | best_loss 8.953
2022-03-06 02:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17714 updates
2022-03-06 02:01:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 364 @ 17714 updates, score 13.552) (writing took 1.645113236270845 seconds)
2022-03-06 02:01:33 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-06 02:01:33 | INFO | train | epoch 364 | loss 2.171 | nll_loss 0.383 | ppl 1.3 | wps 27643.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17714 | lr 0.000237597 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 41931
2022-03-06 02:01:33 | INFO | fairseq.trainer | begin training epoch 365
2022-03-06 02:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:03:26 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.607 | nll_loss 13.01 | ppl 8249.08 | wps 46397.8 | wpb 510.9 | bsz 1 | num_updates 17763 | best_loss 8.953
2022-03-06 02:03:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17763 updates
2022-03-06 02:03:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:03:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:03:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 365 @ 17763 updates, score 13.607) (writing took 1.6754529969766736 seconds)
2022-03-06 02:03:28 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-06 02:03:28 | INFO | train | epoch 365 | loss 2.172 | nll_loss 0.383 | ppl 1.3 | wps 27644.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17763 | lr 0.000237269 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42046
2022-03-06 02:03:28 | INFO | fairseq.trainer | begin training epoch 366
2022-03-06 02:03:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:03:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:04:52 | INFO | train_inner | epoch 366:     38 / 49 loss=2.172, nll_loss=0.384, ppl=1.3, wps=27429.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.476, loss_scale=32, train_wall=201, gb_free=21.6, wall=42131
2022-03-06 02:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:05:21 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.53 | nll_loss 12.914 | ppl 7716.69 | wps 46222.8 | wpb 510.9 | bsz 1 | num_updates 17811 | best_loss 8.953
2022-03-06 02:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17811 updates
2022-03-06 02:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:05:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 366 @ 17811 updates, score 13.53) (writing took 1.6554963188245893 seconds)
2022-03-06 02:05:22 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-06 02:05:22 | INFO | train | epoch 366 | loss 2.172 | nll_loss 0.384 | ppl 1.3 | wps 27099.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17811 | lr 0.00023695 | gnorm 0.479 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42161
2022-03-06 02:05:22 | INFO | fairseq.trainer | begin training epoch 367
2022-03-06 02:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:07:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:07:16 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.677 | nll_loss 13.084 | ppl 8680.19 | wps 46126.1 | wpb 510.9 | bsz 1 | num_updates 17860 | best_loss 8.953
2022-03-06 02:07:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17860 updates
2022-03-06 02:07:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 367 @ 17860 updates, score 13.677) (writing took 1.6709839897230268 seconds)
2022-03-06 02:07:17 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-06 02:07:17 | INFO | train | epoch 367 | loss 2.17 | nll_loss 0.382 | ppl 1.3 | wps 27624.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17860 | lr 0.000236624 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42276
2022-03-06 02:07:17 | INFO | fairseq.trainer | begin training epoch 368
2022-03-06 02:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:08:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:08:49 | INFO | train_inner | epoch 368:     41 / 49 loss=2.17, nll_loss=0.382, ppl=1.3, wps=27416, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.473, loss_scale=32, train_wall=201, gb_free=21.6, wall=42368
2022-03-06 02:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:09:11 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.526 | nll_loss 12.917 | ppl 7735.26 | wps 46515.1 | wpb 510.9 | bsz 1 | num_updates 17908 | best_loss 8.953
2022-03-06 02:09:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17908 updates
2022-03-06 02:09:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:09:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:09:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 368 @ 17908 updates, score 13.526) (writing took 1.6246143216267228 seconds)
2022-03-06 02:09:12 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-06 02:09:12 | INFO | train | epoch 368 | loss 2.169 | nll_loss 0.381 | ppl 1.3 | wps 27122.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 17908 | lr 0.000236307 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42391
2022-03-06 02:09:12 | INFO | fairseq.trainer | begin training epoch 369
2022-03-06 02:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:11:05 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.472 | nll_loss 12.861 | ppl 7439.97 | wps 46367.2 | wpb 510.9 | bsz 1 | num_updates 17957 | best_loss 8.953
2022-03-06 02:11:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17957 updates
2022-03-06 02:11:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:11:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:11:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 369 @ 17957 updates, score 13.472) (writing took 1.6751794200390577 seconds)
2022-03-06 02:11:07 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-06 02:11:07 | INFO | train | epoch 369 | loss 2.17 | nll_loss 0.382 | ppl 1.3 | wps 27681.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 17957 | lr 0.000235984 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42506
2022-03-06 02:11:07 | INFO | fairseq.trainer | begin training epoch 370
2022-03-06 02:11:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:12:43 | INFO | train_inner | epoch 370:     43 / 49 loss=2.169, nll_loss=0.381, ppl=1.3, wps=27712.2, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.476, loss_scale=32, train_wall=199, gb_free=21.6, wall=42602
2022-03-06 02:12:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:13:00 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.555 | nll_loss 12.948 | ppl 7901.43 | wps 46555.6 | wpb 510.9 | bsz 1 | num_updates 18006 | best_loss 8.953
2022-03-06 02:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18006 updates
2022-03-06 02:13:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:13:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:13:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 370 @ 18006 updates, score 13.555) (writing took 1.6572463111951947 seconds)
2022-03-06 02:13:02 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-06 02:13:02 | INFO | train | epoch 370 | loss 2.168 | nll_loss 0.381 | ppl 1.3 | wps 27661.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18006 | lr 0.000235663 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42621
2022-03-06 02:13:02 | INFO | fairseq.trainer | begin training epoch 371
2022-03-06 02:13:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:13:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:14:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:14:55 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.533 | nll_loss 12.931 | ppl 7809.53 | wps 46600.7 | wpb 510.9 | bsz 1 | num_updates 18054 | best_loss 8.953
2022-03-06 02:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18054 updates
2022-03-06 02:14:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:14:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:14:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 371 @ 18054 updates, score 13.533) (writing took 1.6932322680950165 seconds)
2022-03-06 02:14:57 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-06 02:14:57 | INFO | train | epoch 371 | loss 2.168 | nll_loss 0.38 | ppl 1.3 | wps 27070.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18054 | lr 0.00023535 | gnorm 0.48 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42735
2022-03-06 02:14:57 | INFO | fairseq.trainer | begin training epoch 372
2022-03-06 02:14:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:16:40 | INFO | train_inner | epoch 372:     46 / 49 loss=2.168, nll_loss=0.381, ppl=1.3, wps=27418.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.48, loss_scale=32, train_wall=201, gb_free=21.6, wall=42838
2022-03-06 02:16:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:16:50 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.538 | nll_loss 12.931 | ppl 7809.88 | wps 46338.2 | wpb 510.9 | bsz 1 | num_updates 18103 | best_loss 8.953
2022-03-06 02:16:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18103 updates
2022-03-06 02:16:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:16:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:16:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 372 @ 18103 updates, score 13.538) (writing took 1.7092992337420583 seconds)
2022-03-06 02:16:52 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-06 02:16:52 | INFO | train | epoch 372 | loss 2.168 | nll_loss 0.38 | ppl 1.3 | wps 27639.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18103 | lr 0.000235031 | gnorm 0.478 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 42850
2022-03-06 02:16:52 | INFO | fairseq.trainer | begin training epoch 373
2022-03-06 02:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:18:45 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.532 | nll_loss 12.925 | ppl 7774.44 | wps 46468.9 | wpb 510.9 | bsz 1 | num_updates 18152 | best_loss 8.953
2022-03-06 02:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18152 updates
2022-03-06 02:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:18:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:18:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 373 @ 18152 updates, score 13.532) (writing took 1.6707866908982396 seconds)
2022-03-06 02:18:47 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-06 02:18:47 | INFO | train | epoch 373 | loss 2.166 | nll_loss 0.379 | ppl 1.3 | wps 27651 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18152 | lr 0.000234713 | gnorm 0.482 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 42965
2022-03-06 02:18:47 | INFO | fairseq.trainer | begin training epoch 374
2022-03-06 02:18:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:18:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:20:35 | INFO | train_inner | epoch 374:     49 / 49 loss=2.166, nll_loss=0.378, ppl=1.3, wps=27396.8, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=18200, lr=0.000234404, gnorm=0.479, loss_scale=32, train_wall=200, gb_free=21.6, wall=43074
2022-03-06 02:20:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:20:40 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.565 | nll_loss 12.965 | ppl 7993.36 | wps 46386.6 | wpb 510.9 | bsz 1 | num_updates 18200 | best_loss 8.953
2022-03-06 02:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18200 updates
2022-03-06 02:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:20:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:20:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 374 @ 18200 updates, score 13.565) (writing took 1.6475924784317613 seconds)
2022-03-06 02:20:42 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-06 02:20:42 | INFO | train | epoch 374 | loss 2.165 | nll_loss 0.377 | ppl 1.3 | wps 27070.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18200 | lr 0.000234404 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43080
2022-03-06 02:20:42 | INFO | fairseq.trainer | begin training epoch 375
2022-03-06 02:20:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:20:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 02:22:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:22:35 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.506 | nll_loss 12.896 | ppl 7622.68 | wps 46282.1 | wpb 510.9 | bsz 1 | num_updates 18248 | best_loss 8.953
2022-03-06 02:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18248 updates
2022-03-06 02:22:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 375 @ 18248 updates, score 13.506) (writing took 1.6193914581090212 seconds)
2022-03-06 02:22:37 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-06 02:22:37 | INFO | train | epoch 375 | loss 2.165 | nll_loss 0.379 | ppl 1.3 | wps 27086.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18248 | lr 0.000234095 | gnorm 0.477 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 43195
2022-03-06 02:22:37 | INFO | fairseq.trainer | begin training epoch 376
2022-03-06 02:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:24:30 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.525 | nll_loss 12.92 | ppl 7749.05 | wps 46395.5 | wpb 510.9 | bsz 1 | num_updates 18297 | best_loss 8.953
2022-03-06 02:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18297 updates
2022-03-06 02:24:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:24:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 376 @ 18297 updates, score 13.525) (writing took 1.6353222839534283 seconds)
2022-03-06 02:24:32 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-06 02:24:32 | INFO | train | epoch 376 | loss 2.164 | nll_loss 0.377 | ppl 1.3 | wps 27672.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18297 | lr 0.000233781 | gnorm 0.468 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 43310
2022-03-06 02:24:32 | INFO | fairseq.trainer | begin training epoch 377
2022-03-06 02:24:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:24:38 | INFO | train_inner | epoch 377:      3 / 49 loss=2.164, nll_loss=0.377, ppl=1.3, wps=26702.5, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=18300, lr=0.000233762, gnorm=0.473, loss_scale=16, train_wall=201, gb_free=21.6, wall=43317
2022-03-06 02:26:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:26:25 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.538 | nll_loss 12.927 | ppl 7786.34 | wps 46566.9 | wpb 510.9 | bsz 1 | num_updates 18346 | best_loss 8.953
2022-03-06 02:26:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18346 updates
2022-03-06 02:26:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:26:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:26:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 377 @ 18346 updates, score 13.538) (writing took 1.648091965354979 seconds)
2022-03-06 02:26:27 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-06 02:26:27 | INFO | train | epoch 377 | loss 2.164 | nll_loss 0.377 | ppl 1.3 | wps 27615.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18346 | lr 0.000233469 | gnorm 0.482 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 43425
2022-03-06 02:26:27 | INFO | fairseq.trainer | begin training epoch 378
2022-03-06 02:26:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:28:20 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.659 | nll_loss 13.067 | ppl 8583.39 | wps 46306.5 | wpb 510.9 | bsz 1 | num_updates 18395 | best_loss 8.953
2022-03-06 02:28:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18395 updates
2022-03-06 02:28:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:28:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:28:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 378 @ 18395 updates, score 13.659) (writing took 1.7024988261982799 seconds)
2022-03-06 02:28:22 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-06 02:28:22 | INFO | train | epoch 378 | loss 2.162 | nll_loss 0.376 | ppl 1.3 | wps 27633.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18395 | lr 0.000233158 | gnorm 0.469 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43540
2022-03-06 02:28:22 | INFO | fairseq.trainer | begin training epoch 379
2022-03-06 02:28:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:28:33 | INFO | train_inner | epoch 379:      5 / 49 loss=2.163, nll_loss=0.376, ppl=1.3, wps=27657.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.476, loss_scale=32, train_wall=199, gb_free=21.6, wall=43551
2022-03-06 02:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:30:15 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.59 | nll_loss 12.989 | ppl 8129.43 | wps 46586.3 | wpb 510.9 | bsz 1 | num_updates 18444 | best_loss 8.953
2022-03-06 02:30:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18444 updates
2022-03-06 02:30:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:30:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:30:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 379 @ 18444 updates, score 13.59) (writing took 1.6460833866149187 seconds)
2022-03-06 02:30:17 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-06 02:30:17 | INFO | train | epoch 379 | loss 2.162 | nll_loss 0.375 | ppl 1.3 | wps 27644.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18444 | lr 0.000232848 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43655
2022-03-06 02:30:17 | INFO | fairseq.trainer | begin training epoch 380
2022-03-06 02:30:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:31:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:32:10 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.629 | nll_loss 13.03 | ppl 8363.85 | wps 46296.2 | wpb 510.9 | bsz 1 | num_updates 18492 | best_loss 8.953
2022-03-06 02:32:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18492 updates
2022-03-06 02:32:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:32:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:32:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 380 @ 18492 updates, score 13.629) (writing took 1.677437860518694 seconds)
2022-03-06 02:32:12 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-06 02:32:12 | INFO | train | epoch 380 | loss 2.161 | nll_loss 0.375 | ppl 1.3 | wps 27074.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18492 | lr 0.000232546 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43770
2022-03-06 02:32:12 | INFO | fairseq.trainer | begin training epoch 381
2022-03-06 02:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:32:30 | INFO | train_inner | epoch 381:      8 / 49 loss=2.161, nll_loss=0.375, ppl=1.3, wps=27414.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.471, loss_scale=32, train_wall=201, gb_free=21.6, wall=43788
2022-03-06 02:34:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:34:05 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.6 | nll_loss 12.997 | ppl 8177.45 | wps 46241.2 | wpb 510.9 | bsz 1 | num_updates 18541 | best_loss 8.953
2022-03-06 02:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18541 updates
2022-03-06 02:34:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:34:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:34:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 381 @ 18541 updates, score 13.6) (writing took 1.6702550547197461 seconds)
2022-03-06 02:34:07 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-06 02:34:07 | INFO | train | epoch 381 | loss 2.161 | nll_loss 0.375 | ppl 1.3 | wps 27632.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18541 | lr 0.000232238 | gnorm 0.477 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 43885
2022-03-06 02:34:07 | INFO | fairseq.trainer | begin training epoch 382
2022-03-06 02:34:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:36:00 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.562 | nll_loss 12.954 | ppl 7936.24 | wps 46363.5 | wpb 510.9 | bsz 1 | num_updates 18590 | best_loss 8.953
2022-03-06 02:36:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18590 updates
2022-03-06 02:36:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:36:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 382 @ 18590 updates, score 13.562) (writing took 1.6561794187873602 seconds)
2022-03-06 02:36:01 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-06 02:36:01 | INFO | train | epoch 382 | loss 2.16 | nll_loss 0.375 | ppl 1.3 | wps 27667.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18590 | lr 0.000231932 | gnorm 0.47 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44000
2022-03-06 02:36:01 | INFO | fairseq.trainer | begin training epoch 383
2022-03-06 02:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:36:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:36:26 | INFO | train_inner | epoch 383:     11 / 49 loss=2.16, nll_loss=0.374, ppl=1.3, wps=27422.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.473, loss_scale=32, train_wall=201, gb_free=21.6, wall=44025
2022-03-06 02:37:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:37:55 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.599 | nll_loss 12.996 | ppl 8166.51 | wps 46412.9 | wpb 510.9 | bsz 1 | num_updates 18638 | best_loss 8.953
2022-03-06 02:37:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18638 updates
2022-03-06 02:37:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:37:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 383 @ 18638 updates, score 13.599) (writing took 1.6647468786686659 seconds)
2022-03-06 02:37:56 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-06 02:37:56 | INFO | train | epoch 383 | loss 2.159 | nll_loss 0.373 | ppl 1.3 | wps 27098.2 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 18638 | lr 0.000231633 | gnorm 0.473 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44115
2022-03-06 02:37:56 | INFO | fairseq.trainer | begin training epoch 384
2022-03-06 02:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:39:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:39:50 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.567 | nll_loss 12.964 | ppl 7991.14 | wps 46446.5 | wpb 510.9 | bsz 1 | num_updates 18687 | best_loss 8.953
2022-03-06 02:39:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18687 updates
2022-03-06 02:39:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:39:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:39:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 384 @ 18687 updates, score 13.567) (writing took 1.6704054726287723 seconds)
2022-03-06 02:39:51 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-06 02:39:51 | INFO | train | epoch 384 | loss 2.159 | nll_loss 0.373 | ppl 1.3 | wps 27644.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18687 | lr 0.000231329 | gnorm 0.472 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44230
2022-03-06 02:39:51 | INFO | fairseq.trainer | begin training epoch 385
2022-03-06 02:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:40:20 | INFO | train_inner | epoch 385:     13 / 49 loss=2.159, nll_loss=0.373, ppl=1.3, wps=27694.5, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.473, loss_scale=32, train_wall=199, gb_free=21.6, wall=44259
2022-03-06 02:41:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:41:44 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.56 | nll_loss 12.95 | ppl 7915.3 | wps 46586.3 | wpb 510.9 | bsz 1 | num_updates 18735 | best_loss 8.953
2022-03-06 02:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18735 updates
2022-03-06 02:41:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:41:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 385 @ 18735 updates, score 13.56) (writing took 1.6726710824295878 seconds)
2022-03-06 02:41:46 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-06 02:41:46 | INFO | train | epoch 385 | loss 2.158 | nll_loss 0.373 | ppl 1.29 | wps 27126.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18735 | lr 0.000231033 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44345
2022-03-06 02:41:46 | INFO | fairseq.trainer | begin training epoch 386
2022-03-06 02:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:43:39 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.525 | nll_loss 12.921 | ppl 7757.37 | wps 46411.7 | wpb 510.9 | bsz 1 | num_updates 18784 | best_loss 8.953
2022-03-06 02:43:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18784 updates
2022-03-06 02:43:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:43:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:43:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 386 @ 18784 updates, score 13.525) (writing took 1.6719177151098847 seconds)
2022-03-06 02:43:41 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-06 02:43:41 | INFO | train | epoch 386 | loss 2.157 | nll_loss 0.372 | ppl 1.29 | wps 27651.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18784 | lr 0.000230731 | gnorm 0.474 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44460
2022-03-06 02:43:41 | INFO | fairseq.trainer | begin training epoch 387
2022-03-06 02:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:44:17 | INFO | train_inner | epoch 387:     16 / 49 loss=2.157, nll_loss=0.372, ppl=1.29, wps=27439.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.47, loss_scale=32, train_wall=201, gb_free=21.6, wall=44495
2022-03-06 02:45:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:45:34 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.606 | nll_loss 13.006 | ppl 8226.6 | wps 46426.1 | wpb 510.9 | bsz 1 | num_updates 18833 | best_loss 8.953
2022-03-06 02:45:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18833 updates
2022-03-06 02:45:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:45:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 387 @ 18833 updates, score 13.606) (writing took 1.6724068727344275 seconds)
2022-03-06 02:45:36 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-06 02:45:36 | INFO | train | epoch 387 | loss 2.156 | nll_loss 0.371 | ppl 1.29 | wps 27654 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18833 | lr 0.000230431 | gnorm 0.466 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44574
2022-03-06 02:45:36 | INFO | fairseq.trainer | begin training epoch 388
2022-03-06 02:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:46:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:47:29 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.609 | nll_loss 13.014 | ppl 8271.17 | wps 46423.8 | wpb 510.9 | bsz 1 | num_updates 18881 | best_loss 8.953
2022-03-06 02:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18881 updates
2022-03-06 02:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 388 @ 18881 updates, score 13.609) (writing took 1.6987218307331204 seconds)
2022-03-06 02:47:31 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-06 02:47:31 | INFO | train | epoch 388 | loss 2.156 | nll_loss 0.371 | ppl 1.29 | wps 27089 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18881 | lr 0.000230138 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44689
2022-03-06 02:47:31 | INFO | fairseq.trainer | begin training epoch 389
2022-03-06 02:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:48:13 | INFO | train_inner | epoch 389:     19 / 49 loss=2.156, nll_loss=0.371, ppl=1.29, wps=27421.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.466, loss_scale=32, train_wall=201, gb_free=21.6, wall=44732
2022-03-06 02:49:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:49:24 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.583 | nll_loss 12.984 | ppl 8099.47 | wps 46395.8 | wpb 510.9 | bsz 1 | num_updates 18930 | best_loss 8.953
2022-03-06 02:49:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18930 updates
2022-03-06 02:49:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 389 @ 18930 updates, score 13.583) (writing took 1.6248901290819049 seconds)
2022-03-06 02:49:26 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-06 02:49:26 | INFO | train | epoch 389 | loss 2.155 | nll_loss 0.371 | ppl 1.29 | wps 27686.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 18930 | lr 0.00022984 | gnorm 0.466 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44804
2022-03-06 02:49:26 | INFO | fairseq.trainer | begin training epoch 390
2022-03-06 02:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:51:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 02:51:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:51:19 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.552 | nll_loss 12.948 | ppl 7901.87 | wps 46273.2 | wpb 510.9 | bsz 1 | num_updates 18978 | best_loss 8.953
2022-03-06 02:51:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18978 updates
2022-03-06 02:51:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 390 @ 18978 updates, score 13.552) (writing took 1.6867250660434365 seconds)
2022-03-06 02:51:20 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-06 02:51:20 | INFO | train | epoch 390 | loss 2.154 | nll_loss 0.37 | ppl 1.29 | wps 27103.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 18978 | lr 0.000229549 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 44919
2022-03-06 02:51:20 | INFO | fairseq.trainer | begin training epoch 391
2022-03-06 02:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:52:10 | INFO | train_inner | epoch 391:     22 / 49 loss=2.154, nll_loss=0.37, ppl=1.29, wps=27452.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.467, loss_scale=32, train_wall=201, gb_free=21.6, wall=44968
2022-03-06 02:53:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:53:14 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.486 | nll_loss 12.881 | ppl 7543.92 | wps 46581.4 | wpb 510.9 | bsz 1 | num_updates 19027 | best_loss 8.953
2022-03-06 02:53:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19027 updates
2022-03-06 02:53:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:53:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:53:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 391 @ 19027 updates, score 13.486) (writing took 1.6488988790661097 seconds)
2022-03-06 02:53:15 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-06 02:53:15 | INFO | train | epoch 391 | loss 2.154 | nll_loss 0.37 | ppl 1.29 | wps 27673.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19027 | lr 0.000229253 | gnorm 0.471 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45034
2022-03-06 02:53:15 | INFO | fairseq.trainer | begin training epoch 392
2022-03-06 02:53:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:53:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 02:55:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:55:08 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.616 | nll_loss 13.017 | ppl 8289.38 | wps 46322.3 | wpb 510.9 | bsz 1 | num_updates 19075 | best_loss 8.953
2022-03-06 02:55:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19075 updates
2022-03-06 02:55:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:55:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 392 @ 19075 updates, score 13.616) (writing took 1.6306281620636582 seconds)
2022-03-06 02:55:10 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-06 02:55:10 | INFO | train | epoch 392 | loss 2.153 | nll_loss 0.369 | ppl 1.29 | wps 27120.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19075 | lr 0.000228964 | gnorm 0.468 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 45149
2022-03-06 02:55:10 | INFO | fairseq.trainer | begin training epoch 393
2022-03-06 02:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:56:06 | INFO | train_inner | epoch 393:     25 / 49 loss=2.154, nll_loss=0.369, ppl=1.29, wps=27451.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.47, loss_scale=16, train_wall=201, gb_free=21.6, wall=45205
2022-03-06 02:56:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:57:03 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.506 | nll_loss 12.904 | ppl 7663.06 | wps 46307.4 | wpb 510.9 | bsz 1 | num_updates 19124 | best_loss 8.953
2022-03-06 02:57:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19124 updates
2022-03-06 02:57:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:57:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:57:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 393 @ 19124 updates, score 13.506) (writing took 1.6824324950575829 seconds)
2022-03-06 02:57:05 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-06 02:57:05 | INFO | train | epoch 393 | loss 2.152 | nll_loss 0.368 | ppl 1.29 | wps 27652.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19124 | lr 0.000228671 | gnorm 0.465 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 45264
2022-03-06 02:57:05 | INFO | fairseq.trainer | begin training epoch 394
2022-03-06 02:57:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:58:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 02:58:58 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.555 | nll_loss 12.952 | ppl 7922.8 | wps 46536.6 | wpb 510.9 | bsz 1 | num_updates 19173 | best_loss 8.953
2022-03-06 02:58:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19173 updates
2022-03-06 02:58:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:59:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 02:59:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 394 @ 19173 updates, score 13.555) (writing took 1.6306724408641458 seconds)
2022-03-06 02:59:00 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-06 02:59:00 | INFO | train | epoch 394 | loss 2.152 | nll_loss 0.368 | ppl 1.29 | wps 27690.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19173 | lr 0.000228378 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45378
2022-03-06 02:59:00 | INFO | fairseq.trainer | begin training epoch 395
2022-03-06 02:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 02:59:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 03:00:02 | INFO | train_inner | epoch 395:     28 / 49 loss=2.152, nll_loss=0.368, ppl=1.29, wps=27444.7, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.465, loss_scale=16, train_wall=201, gb_free=21.6, wall=45441
2022-03-06 03:00:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:00:53 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.504 | nll_loss 12.901 | ppl 7647.79 | wps 46473.8 | wpb 510.9 | bsz 1 | num_updates 19221 | best_loss 8.953
2022-03-06 03:00:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19221 updates
2022-03-06 03:00:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:00:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:00:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 395 @ 19221 updates, score 13.504) (writing took 1.6737800240516663 seconds)
2022-03-06 03:00:54 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-06 03:00:54 | INFO | train | epoch 395 | loss 2.151 | nll_loss 0.367 | ppl 1.29 | wps 27114.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19221 | lr 0.000228093 | gnorm 0.467 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 45493
2022-03-06 03:00:54 | INFO | fairseq.trainer | begin training epoch 396
2022-03-06 03:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:02:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:02:48 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.49 | nll_loss 12.884 | ppl 7560.91 | wps 46377.4 | wpb 510.9 | bsz 1 | num_updates 19270 | best_loss 8.953
2022-03-06 03:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19270 updates
2022-03-06 03:02:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 396 @ 19270 updates, score 13.49) (writing took 1.6535816546529531 seconds)
2022-03-06 03:02:49 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-06 03:02:49 | INFO | train | epoch 396 | loss 2.151 | nll_loss 0.368 | ppl 1.29 | wps 27657.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19270 | lr 0.000227803 | gnorm 0.46 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 45608
2022-03-06 03:02:49 | INFO | fairseq.trainer | begin training epoch 397
2022-03-06 03:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:03:56 | INFO | train_inner | epoch 397:     30 / 49 loss=2.151, nll_loss=0.367, ppl=1.29, wps=27699.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.462, loss_scale=16, train_wall=199, gb_free=21.6, wall=45675
2022-03-06 03:04:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:04:43 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.544 | nll_loss 12.949 | ppl 7907.15 | wps 46394.8 | wpb 510.9 | bsz 1 | num_updates 19319 | best_loss 8.953
2022-03-06 03:04:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19319 updates
2022-03-06 03:04:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:04:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:04:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 397 @ 19319 updates, score 13.544) (writing took 1.6507616685703397 seconds)
2022-03-06 03:04:44 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-06 03:04:44 | INFO | train | epoch 397 | loss 2.149 | nll_loss 0.366 | ppl 1.29 | wps 27667.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19319 | lr 0.000227514 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45723
2022-03-06 03:04:44 | INFO | fairseq.trainer | begin training epoch 398
2022-03-06 03:04:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:06:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:06:37 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.514 | nll_loss 12.91 | ppl 7695.25 | wps 46286.8 | wpb 510.9 | bsz 1 | num_updates 19368 | best_loss 8.953
2022-03-06 03:06:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19368 updates
2022-03-06 03:06:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:06:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 398 @ 19368 updates, score 13.514) (writing took 1.6258954722434282 seconds)
2022-03-06 03:06:39 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-06 03:06:39 | INFO | train | epoch 398 | loss 2.151 | nll_loss 0.367 | ppl 1.29 | wps 27672.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19368 | lr 0.000227226 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45838
2022-03-06 03:06:39 | INFO | fairseq.trainer | begin training epoch 399
2022-03-06 03:06:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:07:51 | INFO | train_inner | epoch 399:     32 / 49 loss=2.15, nll_loss=0.366, ppl=1.29, wps=27698.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.463, loss_scale=32, train_wall=199, gb_free=21.6, wall=45909
2022-03-06 03:08:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:08:32 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.538 | nll_loss 12.938 | ppl 7845.19 | wps 46426.4 | wpb 510.9 | bsz 1 | num_updates 19417 | best_loss 8.953
2022-03-06 03:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19417 updates
2022-03-06 03:08:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:08:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:08:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 399 @ 19417 updates, score 13.538) (writing took 1.6191284637898207 seconds)
2022-03-06 03:08:34 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-06 03:08:34 | INFO | train | epoch 399 | loss 2.149 | nll_loss 0.366 | ppl 1.29 | wps 27669 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19417 | lr 0.000226939 | gnorm 0.465 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 45953
2022-03-06 03:08:34 | INFO | fairseq.trainer | begin training epoch 400
2022-03-06 03:08:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:09:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:10:27 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.644 | nll_loss 13.057 | ppl 8521.4 | wps 46464.4 | wpb 510.9 | bsz 1 | num_updates 19465 | best_loss 8.953
2022-03-06 03:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19465 updates
2022-03-06 03:10:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:10:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:10:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 400 @ 19465 updates, score 13.644) (writing took 1.6112816231325269 seconds)
2022-03-06 03:10:29 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-06 03:10:29 | INFO | train | epoch 400 | loss 2.148 | nll_loss 0.366 | ppl 1.29 | wps 27115.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19465 | lr 0.000226659 | gnorm 0.467 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46067
2022-03-06 03:10:29 | INFO | fairseq.trainer | begin training epoch 401
2022-03-06 03:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:11:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 03:11:49 | INFO | train_inner | epoch 401:     36 / 49 loss=2.148, nll_loss=0.365, ppl=1.29, wps=27201.9, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.469, loss_scale=16, train_wall=203, gb_free=21.6, wall=46148
2022-03-06 03:12:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:12:22 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.603 | nll_loss 12.999 | ppl 8188.77 | wps 46588.9 | wpb 510.9 | bsz 1 | num_updates 19513 | best_loss 8.953
2022-03-06 03:12:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19513 updates
2022-03-06 03:12:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:12:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:12:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 401 @ 19513 updates, score 13.603) (writing took 1.6566259860992432 seconds)
2022-03-06 03:12:23 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-06 03:12:23 | INFO | train | epoch 401 | loss 2.147 | nll_loss 0.365 | ppl 1.29 | wps 27124.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19513 | lr 0.00022638 | gnorm 0.472 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 46182
2022-03-06 03:12:24 | INFO | fairseq.trainer | begin training epoch 402
2022-03-06 03:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:14:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:14:17 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.467 | nll_loss 12.857 | ppl 7420.45 | wps 46170.6 | wpb 510.9 | bsz 1 | num_updates 19562 | best_loss 8.953
2022-03-06 03:14:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19562 updates
2022-03-06 03:14:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:14:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 402 @ 19562 updates, score 13.467) (writing took 1.6160339713096619 seconds)
2022-03-06 03:14:18 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-06 03:14:18 | INFO | train | epoch 402 | loss 2.148 | nll_loss 0.365 | ppl 1.29 | wps 27680.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19562 | lr 0.000226096 | gnorm 0.467 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 46297
2022-03-06 03:14:18 | INFO | fairseq.trainer | begin training epoch 403
2022-03-06 03:14:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:15:43 | INFO | train_inner | epoch 403:     38 / 49 loss=2.147, nll_loss=0.365, ppl=1.29, wps=27714.1, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.467, loss_scale=16, train_wall=199, gb_free=21.6, wall=46382
2022-03-06 03:16:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:16:11 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.464 | nll_loss 12.852 | ppl 7394.58 | wps 46449.4 | wpb 510.9 | bsz 1 | num_updates 19611 | best_loss 8.953
2022-03-06 03:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19611 updates
2022-03-06 03:16:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 403 @ 19611 updates, score 13.464) (writing took 1.6523025445640087 seconds)
2022-03-06 03:16:13 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-06 03:16:13 | INFO | train | epoch 403 | loss 2.146 | nll_loss 0.364 | ppl 1.29 | wps 27672.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19611 | lr 0.000225814 | gnorm 0.471 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 46412
2022-03-06 03:16:13 | INFO | fairseq.trainer | begin training epoch 404
2022-03-06 03:16:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:18:06 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.595 | nll_loss 12.997 | ppl 8174.53 | wps 46429.4 | wpb 510.9 | bsz 1 | num_updates 19660 | best_loss 8.953
2022-03-06 03:18:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19660 updates
2022-03-06 03:18:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:18:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:18:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 404 @ 19660 updates, score 13.595) (writing took 1.61731016356498 seconds)
2022-03-06 03:18:08 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-06 03:18:08 | INFO | train | epoch 404 | loss 2.145 | nll_loss 0.363 | ppl 1.29 | wps 27685 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19660 | lr 0.000225532 | gnorm 0.455 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46527
2022-03-06 03:18:08 | INFO | fairseq.trainer | begin training epoch 405
2022-03-06 03:18:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:19:37 | INFO | train_inner | epoch 405:     40 / 49 loss=2.145, nll_loss=0.363, ppl=1.29, wps=27695.9, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.458, loss_scale=32, train_wall=199, gb_free=21.6, wall=46616
2022-03-06 03:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:20:01 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.47 | nll_loss 12.865 | ppl 7460.42 | wps 46505.9 | wpb 510.9 | bsz 1 | num_updates 19709 | best_loss 8.953
2022-03-06 03:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19709 updates
2022-03-06 03:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 405 @ 19709 updates, score 13.47) (writing took 1.6444291695952415 seconds)
2022-03-06 03:20:03 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-06 03:20:03 | INFO | train | epoch 405 | loss 2.145 | nll_loss 0.363 | ppl 1.29 | wps 27650.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19709 | lr 0.000225252 | gnorm 0.455 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46642
2022-03-06 03:20:03 | INFO | fairseq.trainer | begin training epoch 406
2022-03-06 03:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:21:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:21:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:21:56 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.432 | nll_loss 12.819 | ppl 7227.73 | wps 46473.7 | wpb 510.9 | bsz 1 | num_updates 19757 | best_loss 8.953
2022-03-06 03:21:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19757 updates
2022-03-06 03:21:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:21:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:21:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 406 @ 19757 updates, score 13.432) (writing took 1.6483275024220347 seconds)
2022-03-06 03:21:58 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-06 03:21:58 | INFO | train | epoch 406 | loss 2.145 | nll_loss 0.363 | ppl 1.29 | wps 27093.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19757 | lr 0.000224978 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46756
2022-03-06 03:21:58 | INFO | fairseq.trainer | begin training epoch 407
2022-03-06 03:21:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:23:34 | INFO | train_inner | epoch 407:     43 / 49 loss=2.145, nll_loss=0.363, ppl=1.29, wps=27446.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.461, loss_scale=32, train_wall=201, gb_free=21.6, wall=46852
2022-03-06 03:23:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:23:51 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.586 | nll_loss 12.988 | ppl 8125.9 | wps 46380.5 | wpb 510.9 | bsz 1 | num_updates 19806 | best_loss 8.953
2022-03-06 03:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19806 updates
2022-03-06 03:23:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:23:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 407 @ 19806 updates, score 13.586) (writing took 1.6101077171042562 seconds)
2022-03-06 03:23:53 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-06 03:23:53 | INFO | train | epoch 407 | loss 2.144 | nll_loss 0.362 | ppl 1.29 | wps 27696.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19806 | lr 0.000224699 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46871
2022-03-06 03:23:53 | INFO | fairseq.trainer | begin training epoch 408
2022-03-06 03:23:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:25:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:25:46 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.567 | nll_loss 12.966 | ppl 8001.92 | wps 46375.2 | wpb 510.9 | bsz 1 | num_updates 19855 | best_loss 8.953
2022-03-06 03:25:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19855 updates
2022-03-06 03:25:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:25:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:25:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 408 @ 19855 updates, score 13.567) (writing took 1.6257786946371198 seconds)
2022-03-06 03:25:47 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-06 03:25:47 | INFO | train | epoch 408 | loss 2.144 | nll_loss 0.362 | ppl 1.29 | wps 27667.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19855 | lr 0.000224422 | gnorm 0.459 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 46986
2022-03-06 03:25:47 | INFO | fairseq.trainer | begin training epoch 409
2022-03-06 03:25:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:26:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:27:30 | INFO | train_inner | epoch 409:     46 / 49 loss=2.143, nll_loss=0.362, ppl=1.28, wps=27453.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.458, loss_scale=32, train_wall=201, gb_free=21.6, wall=47089
2022-03-06 03:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:27:40 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.582 | nll_loss 12.983 | ppl 8096.33 | wps 46605.3 | wpb 510.9 | bsz 1 | num_updates 19903 | best_loss 8.953
2022-03-06 03:27:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19903 updates
2022-03-06 03:27:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 409 @ 19903 updates, score 13.582) (writing took 1.6414396027103066 seconds)
2022-03-06 03:27:42 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-06 03:27:42 | INFO | train | epoch 409 | loss 2.143 | nll_loss 0.361 | ppl 1.28 | wps 27123.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 19903 | lr 0.000224151 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47101
2022-03-06 03:27:42 | INFO | fairseq.trainer | begin training epoch 410
2022-03-06 03:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:29:35 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.548 | nll_loss 12.948 | ppl 7901.35 | wps 46415.2 | wpb 510.9 | bsz 1 | num_updates 19952 | best_loss 8.953
2022-03-06 03:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19952 updates
2022-03-06 03:29:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:29:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:29:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 410 @ 19952 updates, score 13.548) (writing took 1.6873813131824136 seconds)
2022-03-06 03:29:37 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-06 03:29:37 | INFO | train | epoch 410 | loss 2.142 | nll_loss 0.361 | ppl 1.28 | wps 27645.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 19952 | lr 0.000223876 | gnorm 0.456 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47216
2022-03-06 03:29:37 | INFO | fairseq.trainer | begin training epoch 411
2022-03-06 03:29:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:31:24 | INFO | train_inner | epoch 411:     48 / 49 loss=2.142, nll_loss=0.361, ppl=1.28, wps=27695.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20000, lr=0.000223607, gnorm=0.456, loss_scale=64, train_wall=199, gb_free=21.6, wall=47323
2022-03-06 03:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:31:30 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.542 | nll_loss 12.943 | ppl 7873.2 | wps 46557.3 | wpb 510.9 | bsz 1 | num_updates 20001 | best_loss 8.953
2022-03-06 03:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20001 updates
2022-03-06 03:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 411 @ 20001 updates, score 13.542) (writing took 1.696530720219016 seconds)
2022-03-06 03:31:32 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-06 03:31:32 | INFO | train | epoch 411 | loss 2.142 | nll_loss 0.361 | ppl 1.28 | wps 27667.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20001 | lr 0.000223601 | gnorm 0.456 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 47331
2022-03-06 03:31:32 | INFO | fairseq.trainer | begin training epoch 412
2022-03-06 03:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:32:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:33:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:33:25 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.577 | nll_loss 12.98 | ppl 8077.79 | wps 46350.9 | wpb 510.9 | bsz 1 | num_updates 20049 | best_loss 8.953
2022-03-06 03:33:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20049 updates
2022-03-06 03:33:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:33:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:33:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 412 @ 20049 updates, score 13.577) (writing took 1.6515969457104802 seconds)
2022-03-06 03:33:27 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-06 03:33:27 | INFO | train | epoch 412 | loss 2.141 | nll_loss 0.36 | ppl 1.28 | wps 27093.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20049 | lr 0.000223333 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47445
2022-03-06 03:33:27 | INFO | fairseq.trainer | begin training epoch 413
2022-03-06 03:33:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:35:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:35:20 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.444 | nll_loss 12.834 | ppl 7299.37 | wps 46339.2 | wpb 510.9 | bsz 1 | num_updates 20098 | best_loss 8.953
2022-03-06 03:35:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20098 updates
2022-03-06 03:35:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:35:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:35:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 413 @ 20098 updates, score 13.444) (writing took 1.6905164867639542 seconds)
2022-03-06 03:35:22 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-06 03:35:22 | INFO | train | epoch 413 | loss 2.141 | nll_loss 0.36 | ppl 1.28 | wps 27668.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20098 | lr 0.000223061 | gnorm 0.463 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47560
2022-03-06 03:35:22 | INFO | fairseq.trainer | begin training epoch 414
2022-03-06 03:35:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:35:26 | INFO | train_inner | epoch 414:      2 / 49 loss=2.141, nll_loss=0.36, ppl=1.28, wps=26686.9, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=20100, lr=0.00022305, gnorm=0.462, loss_scale=32, train_wall=200, gb_free=21.6, wall=47565
2022-03-06 03:37:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:37:15 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.502 | nll_loss 12.895 | ppl 7619.24 | wps 46246.7 | wpb 510.9 | bsz 1 | num_updates 20147 | best_loss 8.953
2022-03-06 03:37:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20147 updates
2022-03-06 03:37:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:37:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:37:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 414 @ 20147 updates, score 13.502) (writing took 1.665717520751059 seconds)
2022-03-06 03:37:17 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-06 03:37:17 | INFO | train | epoch 414 | loss 2.14 | nll_loss 0.359 | ppl 1.28 | wps 27635.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20147 | lr 0.00022279 | gnorm 0.457 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 47675
2022-03-06 03:37:17 | INFO | fairseq.trainer | begin training epoch 415
2022-03-06 03:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:37:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:39:10 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.525 | nll_loss 12.927 | ppl 7790.34 | wps 46321.9 | wpb 510.9 | bsz 1 | num_updates 20195 | best_loss 8.953
2022-03-06 03:39:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20195 updates
2022-03-06 03:39:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:39:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:39:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 415 @ 20195 updates, score 13.525) (writing took 1.6438572406768799 seconds)
2022-03-06 03:39:12 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-06 03:39:12 | INFO | train | epoch 415 | loss 2.139 | nll_loss 0.358 | ppl 1.28 | wps 27095.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20195 | lr 0.000222525 | gnorm 0.45 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47790
2022-03-06 03:39:12 | INFO | fairseq.trainer | begin training epoch 416
2022-03-06 03:39:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:39:23 | INFO | train_inner | epoch 416:      5 / 49 loss=2.139, nll_loss=0.358, ppl=1.28, wps=27422.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.454, loss_scale=32, train_wall=201, gb_free=21.6, wall=47801
2022-03-06 03:41:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:41:05 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.496 | nll_loss 12.897 | ppl 7627.32 | wps 46431.7 | wpb 510.9 | bsz 1 | num_updates 20244 | best_loss 8.953
2022-03-06 03:41:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20244 updates
2022-03-06 03:41:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:41:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:41:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 416 @ 20244 updates, score 13.496) (writing took 1.6820710049942136 seconds)
2022-03-06 03:41:06 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-06 03:41:06 | INFO | train | epoch 416 | loss 2.139 | nll_loss 0.358 | ppl 1.28 | wps 27652.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20244 | lr 0.000222255 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 47905
2022-03-06 03:41:07 | INFO | fairseq.trainer | begin training epoch 417
2022-03-06 03:41:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:42:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:43:00 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.456 | nll_loss 12.854 | ppl 7403.6 | wps 46589.6 | wpb 510.9 | bsz 1 | num_updates 20292 | best_loss 8.953
2022-03-06 03:43:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20292 updates
2022-03-06 03:43:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:43:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:43:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 417 @ 20292 updates, score 13.456) (writing took 1.6392595507204533 seconds)
2022-03-06 03:43:01 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-06 03:43:01 | INFO | train | epoch 417 | loss 2.138 | nll_loss 0.357 | ppl 1.28 | wps 27090.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20292 | lr 0.000221992 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48020
2022-03-06 03:43:01 | INFO | fairseq.trainer | begin training epoch 418
2022-03-06 03:43:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:43:19 | INFO | train_inner | epoch 418:      8 / 49 loss=2.138, nll_loss=0.358, ppl=1.28, wps=27428.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.453, loss_scale=32, train_wall=201, gb_free=21.6, wall=48038
2022-03-06 03:44:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:44:55 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.573 | nll_loss 12.979 | ppl 8073.8 | wps 46103.5 | wpb 510.9 | bsz 1 | num_updates 20341 | best_loss 8.953
2022-03-06 03:44:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20341 updates
2022-03-06 03:44:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:44:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:44:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 418 @ 20341 updates, score 13.573) (writing took 1.6276852004230022 seconds)
2022-03-06 03:44:56 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-06 03:44:56 | INFO | train | epoch 418 | loss 2.138 | nll_loss 0.357 | ppl 1.28 | wps 27654.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20341 | lr 0.000221725 | gnorm 0.46 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48135
2022-03-06 03:44:56 | INFO | fairseq.trainer | begin training epoch 419
2022-03-06 03:44:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:46:50 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.457 | nll_loss 12.85 | ppl 7383.85 | wps 46447.9 | wpb 510.9 | bsz 1 | num_updates 20390 | best_loss 8.953
2022-03-06 03:46:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20390 updates
2022-03-06 03:46:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:46:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:46:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 419 @ 20390 updates, score 13.457) (writing took 1.6578013226389885 seconds)
2022-03-06 03:46:51 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-06 03:46:51 | INFO | train | epoch 419 | loss 2.137 | nll_loss 0.357 | ppl 1.28 | wps 27641.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20390 | lr 0.000221458 | gnorm 0.458 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48250
2022-03-06 03:46:51 | INFO | fairseq.trainer | begin training epoch 420
2022-03-06 03:46:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:47:14 | INFO | train_inner | epoch 420:     10 / 49 loss=2.138, nll_loss=0.357, ppl=1.28, wps=27679.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.459, loss_scale=32, train_wall=199, gb_free=21.6, wall=48272
2022-03-06 03:47:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:48:45 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.537 | nll_loss 12.943 | ppl 7875.61 | wps 46109.5 | wpb 510.9 | bsz 1 | num_updates 20438 | best_loss 8.953
2022-03-06 03:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20438 updates
2022-03-06 03:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:48:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 420 @ 20438 updates, score 13.537) (writing took 1.6447374634444714 seconds)
2022-03-06 03:48:46 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-06 03:48:46 | INFO | train | epoch 420 | loss 2.137 | nll_loss 0.356 | ppl 1.28 | wps 27098.2 | ups 0.42 | wpb 64853.3 | bsz 126.7 | num_updates 20438 | lr 0.000221198 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48365
2022-03-06 03:48:46 | INFO | fairseq.trainer | begin training epoch 421
2022-03-06 03:48:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:50:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:50:39 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.577 | nll_loss 12.98 | ppl 8076.49 | wps 46475 | wpb 510.9 | bsz 1 | num_updates 20487 | best_loss 8.953
2022-03-06 03:50:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20487 updates
2022-03-06 03:50:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:50:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 421 @ 20487 updates, score 13.577) (writing took 1.69145985879004 seconds)
2022-03-06 03:50:41 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-06 03:50:41 | INFO | train | epoch 421 | loss 2.136 | nll_loss 0.356 | ppl 1.28 | wps 27636.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20487 | lr 0.000220933 | gnorm 0.459 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48480
2022-03-06 03:50:41 | INFO | fairseq.trainer | begin training epoch 422
2022-03-06 03:50:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:51:10 | INFO | train_inner | epoch 422:     13 / 49 loss=2.136, nll_loss=0.356, ppl=1.28, wps=27416.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.455, loss_scale=32, train_wall=201, gb_free=21.6, wall=48509
2022-03-06 03:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:52:34 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.564 | nll_loss 12.961 | ppl 7973.57 | wps 46512.9 | wpb 510.9 | bsz 1 | num_updates 20536 | best_loss 8.953
2022-03-06 03:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20536 updates
2022-03-06 03:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 422 @ 20536 updates, score 13.564) (writing took 1.6399045642465353 seconds)
2022-03-06 03:52:36 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-06 03:52:36 | INFO | train | epoch 422 | loss 2.136 | nll_loss 0.356 | ppl 1.28 | wps 27644 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20536 | lr 0.000220669 | gnorm 0.45 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 48595
2022-03-06 03:52:36 | INFO | fairseq.trainer | begin training epoch 423
2022-03-06 03:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:52:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:54:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:54:29 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.546 | nll_loss 12.946 | ppl 7889.65 | wps 46626.6 | wpb 510.9 | bsz 1 | num_updates 20584 | best_loss 8.953
2022-03-06 03:54:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20584 updates
2022-03-06 03:54:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:54:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 423 @ 20584 updates, score 13.546) (writing took 1.6557813817635179 seconds)
2022-03-06 03:54:31 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-06 03:54:31 | INFO | train | epoch 423 | loss 2.135 | nll_loss 0.355 | ppl 1.28 | wps 27116.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20584 | lr 0.000220412 | gnorm 0.457 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48710
2022-03-06 03:54:31 | INFO | fairseq.trainer | begin training epoch 424
2022-03-06 03:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:55:07 | INFO | train_inner | epoch 424:     16 / 49 loss=2.135, nll_loss=0.355, ppl=1.28, wps=27430.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.455, loss_scale=32, train_wall=201, gb_free=21.6, wall=48745
2022-03-06 03:56:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:56:24 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.624 | nll_loss 13.03 | ppl 8365.31 | wps 46627.9 | wpb 510.9 | bsz 1 | num_updates 20633 | best_loss 8.953
2022-03-06 03:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20633 updates
2022-03-06 03:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 424 @ 20633 updates, score 13.624) (writing took 1.6586152203381062 seconds)
2022-03-06 03:56:26 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-06 03:56:26 | INFO | train | epoch 424 | loss 2.134 | nll_loss 0.355 | ppl 1.28 | wps 27666.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20633 | lr 0.00022015 | gnorm 0.459 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48824
2022-03-06 03:56:26 | INFO | fairseq.trainer | begin training epoch 425
2022-03-06 03:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:57:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 03:58:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 03:58:19 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.522 | nll_loss 12.922 | ppl 7761.51 | wps 46476.8 | wpb 510.9 | bsz 1 | num_updates 20681 | best_loss 8.953
2022-03-06 03:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20681 updates
2022-03-06 03:58:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:58:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 03:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 425 @ 20681 updates, score 13.522) (writing took 1.6481520477682352 seconds)
2022-03-06 03:58:21 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-06 03:58:21 | INFO | train | epoch 425 | loss 2.134 | nll_loss 0.354 | ppl 1.28 | wps 27116.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20681 | lr 0.000219894 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 48939
2022-03-06 03:58:21 | INFO | fairseq.trainer | begin training epoch 426
2022-03-06 03:58:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 03:59:03 | INFO | train_inner | epoch 426:     19 / 49 loss=2.134, nll_loss=0.355, ppl=1.28, wps=27460.7, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.457, loss_scale=32, train_wall=201, gb_free=21.6, wall=48982
2022-03-06 04:00:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:00:14 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.561 | nll_loss 12.969 | ppl 8017.34 | wps 46720.2 | wpb 510.9 | bsz 1 | num_updates 20730 | best_loss 8.953
2022-03-06 04:00:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20730 updates
2022-03-06 04:00:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 426 @ 20730 updates, score 13.561) (writing took 1.6311974748969078 seconds)
2022-03-06 04:00:15 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-06 04:00:15 | INFO | train | epoch 426 | loss 2.134 | nll_loss 0.354 | ppl 1.28 | wps 27721.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20730 | lr 0.000219634 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49054
2022-03-06 04:00:15 | INFO | fairseq.trainer | begin training epoch 427
2022-03-06 04:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:02:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:02:08 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.541 | nll_loss 12.947 | ppl 7894.74 | wps 46579.4 | wpb 510.9 | bsz 1 | num_updates 20779 | best_loss 8.953
2022-03-06 04:02:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20779 updates
2022-03-06 04:02:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 427 @ 20779 updates, score 13.541) (writing took 1.5934857921674848 seconds)
2022-03-06 04:02:10 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-06 04:02:10 | INFO | train | epoch 427 | loss 2.132 | nll_loss 0.353 | ppl 1.28 | wps 27687.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20779 | lr 0.000219375 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49169
2022-03-06 04:02:10 | INFO | fairseq.trainer | begin training epoch 428
2022-03-06 04:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:02:59 | INFO | train_inner | epoch 428:     22 / 49 loss=2.132, nll_loss=0.353, ppl=1.28, wps=27472.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.449, loss_scale=32, train_wall=201, gb_free=21.6, wall=49218
2022-03-06 04:03:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:04:03 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.569 | nll_loss 12.976 | ppl 8056.94 | wps 46546.1 | wpb 510.9 | bsz 1 | num_updates 20827 | best_loss 8.953
2022-03-06 04:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20827 updates
2022-03-06 04:04:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:04:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 428 @ 20827 updates, score 13.569) (writing took 1.6282786624506116 seconds)
2022-03-06 04:04:05 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-06 04:04:05 | INFO | train | epoch 428 | loss 2.132 | nll_loss 0.353 | ppl 1.28 | wps 27123.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20827 | lr 0.000219122 | gnorm 0.452 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49283
2022-03-06 04:04:05 | INFO | fairseq.trainer | begin training epoch 429
2022-03-06 04:04:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:05:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:05:58 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.515 | nll_loss 12.919 | ppl 7742.21 | wps 46689 | wpb 510.9 | bsz 1 | num_updates 20876 | best_loss 8.953
2022-03-06 04:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20876 updates
2022-03-06 04:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 429 @ 20876 updates, score 13.515) (writing took 1.6106384927406907 seconds)
2022-03-06 04:05:59 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-06 04:05:59 | INFO | train | epoch 429 | loss 2.132 | nll_loss 0.353 | ppl 1.28 | wps 27705.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20876 | lr 0.000218865 | gnorm 0.453 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49398
2022-03-06 04:05:59 | INFO | fairseq.trainer | begin training epoch 430
2022-03-06 04:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:06:53 | INFO | train_inner | epoch 430:     24 / 49 loss=2.132, nll_loss=0.353, ppl=1.28, wps=27732.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.456, loss_scale=32, train_wall=199, gb_free=21.6, wall=49452
2022-03-06 04:07:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:07:53 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.485 | nll_loss 12.887 | ppl 7575.45 | wps 46517.1 | wpb 510.9 | bsz 1 | num_updates 20925 | best_loss 8.953
2022-03-06 04:07:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20925 updates
2022-03-06 04:07:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:07:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 430 @ 20925 updates, score 13.485) (writing took 1.5973450215533376 seconds)
2022-03-06 04:07:54 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-06 04:07:54 | INFO | train | epoch 430 | loss 2.132 | nll_loss 0.353 | ppl 1.28 | wps 27697.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 20925 | lr 0.000218609 | gnorm 0.457 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 49513
2022-03-06 04:07:54 | INFO | fairseq.trainer | begin training epoch 431
2022-03-06 04:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:08:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:09:47 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.557 | nll_loss 12.963 | ppl 7986.78 | wps 46418.8 | wpb 510.9 | bsz 1 | num_updates 20973 | best_loss 8.953
2022-03-06 04:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20973 updates
2022-03-06 04:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:09:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:09:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 431 @ 20973 updates, score 13.557) (writing took 1.6581588741391897 seconds)
2022-03-06 04:09:49 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-06 04:09:49 | INFO | train | epoch 431 | loss 2.131 | nll_loss 0.352 | ppl 1.28 | wps 27112.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 20973 | lr 0.000218358 | gnorm 0.447 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49628
2022-03-06 04:09:49 | INFO | fairseq.trainer | begin training epoch 432
2022-03-06 04:09:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:10:49 | INFO | train_inner | epoch 432:     27 / 49 loss=2.131, nll_loss=0.352, ppl=1.28, wps=27458.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.45, loss_scale=32, train_wall=201, gb_free=21.6, wall=49688
2022-03-06 04:11:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:11:42 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.497 | nll_loss 12.901 | ppl 7648.76 | wps 46491.5 | wpb 510.9 | bsz 1 | num_updates 21022 | best_loss 8.953
2022-03-06 04:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21022 updates
2022-03-06 04:11:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 432 @ 21022 updates, score 13.497) (writing took 1.6534287948161364 seconds)
2022-03-06 04:11:44 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-06 04:11:44 | INFO | train | epoch 432 | loss 2.13 | nll_loss 0.352 | ppl 1.28 | wps 27688.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21022 | lr 0.000218104 | gnorm 0.45 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 49742
2022-03-06 04:11:44 | INFO | fairseq.trainer | begin training epoch 433
2022-03-06 04:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:11:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:13:37 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.615 | nll_loss 13.028 | ppl 8351.08 | wps 45843.5 | wpb 510.9 | bsz 1 | num_updates 21070 | best_loss 8.953
2022-03-06 04:13:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21070 updates
2022-03-06 04:13:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:13:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:13:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 433 @ 21070 updates, score 13.615) (writing took 1.6135150780901313 seconds)
2022-03-06 04:13:39 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-06 04:13:39 | INFO | train | epoch 433 | loss 2.129 | nll_loss 0.351 | ppl 1.28 | wps 27101.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21070 | lr 0.000217855 | gnorm 0.45 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49857
2022-03-06 04:13:39 | INFO | fairseq.trainer | begin training epoch 434
2022-03-06 04:13:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:14:46 | INFO | train_inner | epoch 434:     30 / 49 loss=2.13, nll_loss=0.352, ppl=1.28, wps=27456.5, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.453, loss_scale=16, train_wall=201, gb_free=21.6, wall=49924
2022-03-06 04:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:15:32 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.558 | nll_loss 12.963 | ppl 7986.48 | wps 46458.6 | wpb 510.9 | bsz 1 | num_updates 21119 | best_loss 8.953
2022-03-06 04:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21119 updates
2022-03-06 04:15:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 434 @ 21119 updates, score 13.558) (writing took 1.6527797868475318 seconds)
2022-03-06 04:15:33 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-06 04:15:33 | INFO | train | epoch 434 | loss 2.13 | nll_loss 0.351 | ppl 1.28 | wps 27694.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21119 | lr 0.000217602 | gnorm 0.459 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 49972
2022-03-06 04:15:33 | INFO | fairseq.trainer | begin training epoch 435
2022-03-06 04:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:17:26 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.576 | nll_loss 12.983 | ppl 8093.47 | wps 46135 | wpb 510.9 | bsz 1 | num_updates 21168 | best_loss 8.953
2022-03-06 04:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21168 updates
2022-03-06 04:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:17:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:17:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 435 @ 21168 updates, score 13.576) (writing took 1.6153853479772806 seconds)
2022-03-06 04:17:28 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-06 04:17:28 | INFO | train | epoch 435 | loss 2.129 | nll_loss 0.351 | ppl 1.28 | wps 27702.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21168 | lr 0.00021735 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50087
2022-03-06 04:17:28 | INFO | fairseq.trainer | begin training epoch 436
2022-03-06 04:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:18:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:18:42 | INFO | train_inner | epoch 436:     33 / 49 loss=2.129, nll_loss=0.35, ppl=1.28, wps=27460.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.45, loss_scale=16, train_wall=201, gb_free=21.6, wall=50161
2022-03-06 04:19:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:19:21 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.613 | nll_loss 13.023 | ppl 8323.43 | wps 46055.3 | wpb 510.9 | bsz 1 | num_updates 21216 | best_loss 8.953
2022-03-06 04:19:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21216 updates
2022-03-06 04:19:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:19:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 436 @ 21216 updates, score 13.613) (writing took 1.6457564188167453 seconds)
2022-03-06 04:19:23 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-06 04:19:23 | INFO | train | epoch 436 | loss 2.128 | nll_loss 0.35 | ppl 1.27 | wps 27116.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21216 | lr 0.000217104 | gnorm 0.452 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 50201
2022-03-06 04:19:23 | INFO | fairseq.trainer | begin training epoch 437
2022-03-06 04:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:21:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:21:16 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.43 | nll_loss 12.827 | ppl 7265.52 | wps 46369.4 | wpb 510.9 | bsz 1 | num_updates 21265 | best_loss 8.953
2022-03-06 04:21:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21265 updates
2022-03-06 04:21:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:21:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 437 @ 21265 updates, score 13.43) (writing took 1.655700364150107 seconds)
2022-03-06 04:21:18 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-06 04:21:18 | INFO | train | epoch 437 | loss 2.128 | nll_loss 0.35 | ppl 1.27 | wps 27681.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21265 | lr 0.000216854 | gnorm 0.454 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 50316
2022-03-06 04:21:18 | INFO | fairseq.trainer | begin training epoch 438
2022-03-06 04:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:22:36 | INFO | train_inner | epoch 438:     35 / 49 loss=2.128, nll_loss=0.35, ppl=1.27, wps=27703.1, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.454, loss_scale=16, train_wall=199, gb_free=21.6, wall=50395
2022-03-06 04:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:23:11 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.553 | nll_loss 12.959 | ppl 7963.12 | wps 46564.2 | wpb 510.9 | bsz 1 | num_updates 21314 | best_loss 8.953
2022-03-06 04:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21314 updates
2022-03-06 04:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:23:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 438 @ 21314 updates, score 13.553) (writing took 1.6631453391164541 seconds)
2022-03-06 04:23:13 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-06 04:23:13 | INFO | train | epoch 438 | loss 2.127 | nll_loss 0.35 | ppl 1.27 | wps 27655.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21314 | lr 0.000216605 | gnorm 0.451 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 50431
2022-03-06 04:23:13 | INFO | fairseq.trainer | begin training epoch 439
2022-03-06 04:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:25:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:25:06 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.648 | nll_loss 13.062 | ppl 8553.29 | wps 46420.6 | wpb 510.9 | bsz 1 | num_updates 21363 | best_loss 8.953
2022-03-06 04:25:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21363 updates
2022-03-06 04:25:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:25:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:25:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 439 @ 21363 updates, score 13.648) (writing took 1.700747886672616 seconds)
2022-03-06 04:25:08 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-06 04:25:08 | INFO | train | epoch 439 | loss 2.126 | nll_loss 0.348 | ppl 1.27 | wps 27655.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21363 | lr 0.000216356 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50546
2022-03-06 04:25:08 | INFO | fairseq.trainer | begin training epoch 440
2022-03-06 04:25:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:26:30 | INFO | train_inner | epoch 440:     37 / 49 loss=2.127, nll_loss=0.349, ppl=1.27, wps=27694.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.452, loss_scale=32, train_wall=199, gb_free=21.6, wall=50629
2022-03-06 04:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:27:01 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.45 | nll_loss 12.845 | ppl 7355.97 | wps 46455 | wpb 510.9 | bsz 1 | num_updates 21412 | best_loss 8.953
2022-03-06 04:27:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21412 updates
2022-03-06 04:27:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:27:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:27:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 440 @ 21412 updates, score 13.45) (writing took 1.6964060356840491 seconds)
2022-03-06 04:27:02 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-06 04:27:02 | INFO | train | epoch 440 | loss 2.127 | nll_loss 0.349 | ppl 1.27 | wps 27657.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21412 | lr 0.000216108 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50661
2022-03-06 04:27:02 | INFO | fairseq.trainer | begin training epoch 441
2022-03-06 04:27:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:28:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:28:56 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.526 | nll_loss 12.927 | ppl 7785.46 | wps 46463 | wpb 510.9 | bsz 1 | num_updates 21460 | best_loss 8.953
2022-03-06 04:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21460 updates
2022-03-06 04:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:28:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:28:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 441 @ 21460 updates, score 13.526) (writing took 1.6670957496389747 seconds)
2022-03-06 04:28:57 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-06 04:28:57 | INFO | train | epoch 441 | loss 2.125 | nll_loss 0.348 | ppl 1.27 | wps 27096.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21460 | lr 0.000215866 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50776
2022-03-06 04:28:57 | INFO | fairseq.trainer | begin training epoch 442
2022-03-06 04:28:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:30:27 | INFO | train_inner | epoch 442:     40 / 49 loss=2.125, nll_loss=0.348, ppl=1.27, wps=27433.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.444, loss_scale=32, train_wall=201, gb_free=21.6, wall=50865
2022-03-06 04:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:30:50 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.744 | nll_loss 13.166 | ppl 9189.79 | wps 46319.6 | wpb 510.9 | bsz 1 | num_updates 21509 | best_loss 8.953
2022-03-06 04:30:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21509 updates
2022-03-06 04:30:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 442 @ 21509 updates, score 13.744) (writing took 1.6665302123874426 seconds)
2022-03-06 04:30:52 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-06 04:30:52 | INFO | train | epoch 442 | loss 2.126 | nll_loss 0.348 | ppl 1.27 | wps 27668.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21509 | lr 0.00021562 | gnorm 0.449 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 50891
2022-03-06 04:30:52 | INFO | fairseq.trainer | begin training epoch 443
2022-03-06 04:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:32:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:32:45 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.545 | nll_loss 12.954 | ppl 7935.41 | wps 46339.9 | wpb 510.9 | bsz 1 | num_updates 21558 | best_loss 8.953
2022-03-06 04:32:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21558 updates
2022-03-06 04:32:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 443 @ 21558 updates, score 13.545) (writing took 1.6728380331769586 seconds)
2022-03-06 04:32:47 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-06 04:32:47 | INFO | train | epoch 443 | loss 2.125 | nll_loss 0.348 | ppl 1.27 | wps 27675.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21558 | lr 0.000215375 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51006
2022-03-06 04:32:47 | INFO | fairseq.trainer | begin training epoch 444
2022-03-06 04:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:33:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:34:23 | INFO | train_inner | epoch 444:     43 / 49 loss=2.125, nll_loss=0.348, ppl=1.27, wps=27451.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.442, loss_scale=32, train_wall=201, gb_free=21.6, wall=51102
2022-03-06 04:34:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:34:40 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.538 | nll_loss 12.942 | ppl 7867.87 | wps 46454.1 | wpb 510.9 | bsz 1 | num_updates 21606 | best_loss 8.953
2022-03-06 04:34:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21606 updates
2022-03-06 04:34:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 444 @ 21606 updates, score 13.538) (writing took 1.6352460952475667 seconds)
2022-03-06 04:34:42 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-06 04:34:42 | INFO | train | epoch 444 | loss 2.124 | nll_loss 0.347 | ppl 1.27 | wps 27121.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21606 | lr 0.000215136 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51120
2022-03-06 04:34:42 | INFO | fairseq.trainer | begin training epoch 445
2022-03-06 04:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:36:35 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.501 | nll_loss 12.9 | ppl 7641.81 | wps 46451.6 | wpb 510.9 | bsz 1 | num_updates 21655 | best_loss 8.953
2022-03-06 04:36:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21655 updates
2022-03-06 04:36:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 445 @ 21655 updates, score 13.501) (writing took 1.6753121204674244 seconds)
2022-03-06 04:36:37 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-06 04:36:37 | INFO | train | epoch 445 | loss 2.123 | nll_loss 0.346 | ppl 1.27 | wps 27663.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21655 | lr 0.000214892 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51235
2022-03-06 04:36:37 | INFO | fairseq.trainer | begin training epoch 446
2022-03-06 04:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:38:17 | INFO | train_inner | epoch 446:     45 / 49 loss=2.124, nll_loss=0.347, ppl=1.27, wps=27709.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.445, loss_scale=32, train_wall=199, gb_free=21.6, wall=51336
2022-03-06 04:38:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:38:30 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.487 | nll_loss 12.888 | ppl 7579.2 | wps 46370.8 | wpb 510.9 | bsz 1 | num_updates 21704 | best_loss 8.953
2022-03-06 04:38:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21704 updates
2022-03-06 04:38:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:38:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:38:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 446 @ 21704 updates, score 13.487) (writing took 1.6593579445034266 seconds)
2022-03-06 04:38:31 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-06 04:38:31 | INFO | train | epoch 446 | loss 2.124 | nll_loss 0.347 | ppl 1.27 | wps 27669.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21704 | lr 0.00021465 | gnorm 0.448 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51350
2022-03-06 04:38:31 | INFO | fairseq.trainer | begin training epoch 447
2022-03-06 04:38:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:38:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:40:25 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.558 | nll_loss 12.968 | ppl 8013.61 | wps 46431.2 | wpb 510.9 | bsz 1 | num_updates 21752 | best_loss 8.953
2022-03-06 04:40:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21752 updates
2022-03-06 04:40:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:40:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 447 @ 21752 updates, score 13.558) (writing took 1.690345061942935 seconds)
2022-03-06 04:40:26 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-06 04:40:26 | INFO | train | epoch 447 | loss 2.123 | nll_loss 0.346 | ppl 1.27 | wps 27097.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21752 | lr 0.000214413 | gnorm 0.454 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51465
2022-03-06 04:40:26 | INFO | fairseq.trainer | begin training epoch 448
2022-03-06 04:40:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:41:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:42:15 | INFO | train_inner | epoch 448:     49 / 49 loss=2.123, nll_loss=0.346, ppl=1.27, wps=27160.4, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.451, loss_scale=16, train_wall=202, gb_free=21.6, wall=51573
2022-03-06 04:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:42:20 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.478 | nll_loss 12.881 | ppl 7545.91 | wps 46324.6 | wpb 510.9 | bsz 1 | num_updates 21800 | best_loss 8.953
2022-03-06 04:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21800 updates
2022-03-06 04:42:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:42:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:42:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 448 @ 21800 updates, score 13.478) (writing took 1.659889061935246 seconds)
2022-03-06 04:42:21 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-06 04:42:21 | INFO | train | epoch 448 | loss 2.122 | nll_loss 0.346 | ppl 1.27 | wps 27091.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 21800 | lr 0.000214176 | gnorm 0.444 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 51580
2022-03-06 04:42:21 | INFO | fairseq.trainer | begin training epoch 449
2022-03-06 04:42:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:44:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:44:14 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.536 | nll_loss 12.942 | ppl 7866.52 | wps 46507 | wpb 510.9 | bsz 1 | num_updates 21849 | best_loss 8.953
2022-03-06 04:44:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21849 updates
2022-03-06 04:44:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:44:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:44:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 449 @ 21849 updates, score 13.536) (writing took 1.6770396148785949 seconds)
2022-03-06 04:44:16 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-06 04:44:16 | INFO | train | epoch 449 | loss 2.121 | nll_loss 0.345 | ppl 1.27 | wps 27672.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21849 | lr 0.000213936 | gnorm 0.443 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 51695
2022-03-06 04:44:16 | INFO | fairseq.trainer | begin training epoch 450
2022-03-06 04:44:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:46:09 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.581 | nll_loss 12.987 | ppl 8118.99 | wps 46400.3 | wpb 510.9 | bsz 1 | num_updates 21898 | best_loss 8.953
2022-03-06 04:46:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21898 updates
2022-03-06 04:46:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:46:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:46:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 450 @ 21898 updates, score 13.581) (writing took 1.6391171989962459 seconds)
2022-03-06 04:46:11 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-06 04:46:11 | INFO | train | epoch 450 | loss 2.121 | nll_loss 0.345 | ppl 1.27 | wps 27708.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21898 | lr 0.000213697 | gnorm 0.442 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 51809
2022-03-06 04:46:11 | INFO | fairseq.trainer | begin training epoch 451
2022-03-06 04:46:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:46:15 | INFO | train_inner | epoch 451:      2 / 49 loss=2.121, nll_loss=0.345, ppl=1.27, wps=26973.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.443, loss_scale=16, train_wall=199, gb_free=21.6, wall=51814
2022-03-06 04:47:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:48:04 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.465 | nll_loss 12.866 | ppl 7465.69 | wps 46372.8 | wpb 510.9 | bsz 1 | num_updates 21947 | best_loss 8.953
2022-03-06 04:48:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21947 updates
2022-03-06 04:48:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:48:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 451 @ 21947 updates, score 13.465) (writing took 1.6771829137578607 seconds)
2022-03-06 04:48:06 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-06 04:48:06 | INFO | train | epoch 451 | loss 2.121 | nll_loss 0.345 | ppl 1.27 | wps 27678.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21947 | lr 0.000213458 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 51924
2022-03-06 04:48:06 | INFO | fairseq.trainer | begin training epoch 452
2022-03-06 04:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:49:59 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.442 | nll_loss 12.839 | ppl 7329.42 | wps 46327.2 | wpb 510.9 | bsz 1 | num_updates 21996 | best_loss 8.953
2022-03-06 04:49:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21996 updates
2022-03-06 04:49:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:50:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:50:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 452 @ 21996 updates, score 13.442) (writing took 1.6712815258651972 seconds)
2022-03-06 04:50:00 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-06 04:50:00 | INFO | train | epoch 452 | loss 2.12 | nll_loss 0.344 | ppl 1.27 | wps 27670.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 21996 | lr 0.00021322 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52039
2022-03-06 04:50:00 | INFO | fairseq.trainer | begin training epoch 453
2022-03-06 04:50:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:50:09 | INFO | train_inner | epoch 453:      4 / 49 loss=2.12, nll_loss=0.344, ppl=1.27, wps=27705.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.443, loss_scale=32, train_wall=199, gb_free=21.6, wall=52048
2022-03-06 04:51:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:51:54 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.527 | nll_loss 12.934 | ppl 7827.9 | wps 46473 | wpb 510.9 | bsz 1 | num_updates 22044 | best_loss 8.953
2022-03-06 04:51:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22044 updates
2022-03-06 04:51:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:51:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:51:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 453 @ 22044 updates, score 13.527) (writing took 1.674403545446694 seconds)
2022-03-06 04:51:55 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-06 04:51:55 | INFO | train | epoch 453 | loss 2.12 | nll_loss 0.344 | ppl 1.27 | wps 27102.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22044 | lr 0.000212988 | gnorm 0.446 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52154
2022-03-06 04:51:55 | INFO | fairseq.trainer | begin training epoch 454
2022-03-06 04:51:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:53:48 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.448 | nll_loss 12.848 | ppl 7373.12 | wps 46254.9 | wpb 510.9 | bsz 1 | num_updates 22093 | best_loss 8.953
2022-03-06 04:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22093 updates
2022-03-06 04:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 454 @ 22093 updates, score 13.448) (writing took 1.68461899086833 seconds)
2022-03-06 04:53:50 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-06 04:53:50 | INFO | train | epoch 454 | loss 2.12 | nll_loss 0.344 | ppl 1.27 | wps 27662.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22093 | lr 0.000212752 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52269
2022-03-06 04:53:50 | INFO | fairseq.trainer | begin training epoch 455
2022-03-06 04:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:54:06 | INFO | train_inner | epoch 455:      7 / 49 loss=2.12, nll_loss=0.344, ppl=1.27, wps=27440.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.445, loss_scale=32, train_wall=201, gb_free=21.6, wall=52285
2022-03-06 04:55:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:55:43 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.468 | nll_loss 12.866 | ppl 7463.3 | wps 46311.8 | wpb 510.9 | bsz 1 | num_updates 22142 | best_loss 8.953
2022-03-06 04:55:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22142 updates
2022-03-06 04:55:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:55:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:55:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 455 @ 22142 updates, score 13.468) (writing took 1.6321877120062709 seconds)
2022-03-06 04:55:45 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-06 04:55:45 | INFO | train | epoch 455 | loss 2.119 | nll_loss 0.343 | ppl 1.27 | wps 27687.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22142 | lr 0.000212516 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52384
2022-03-06 04:55:45 | INFO | fairseq.trainer | begin training epoch 456
2022-03-06 04:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:56:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 04:57:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:57:38 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.449 | nll_loss 12.847 | ppl 7368.8 | wps 46358.6 | wpb 510.9 | bsz 1 | num_updates 22190 | best_loss 8.953
2022-03-06 04:57:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22190 updates
2022-03-06 04:57:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:57:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:57:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 456 @ 22190 updates, score 13.449) (writing took 1.6822271794080734 seconds)
2022-03-06 04:57:40 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-06 04:57:40 | INFO | train | epoch 456 | loss 2.118 | nll_loss 0.343 | ppl 1.27 | wps 27082.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22190 | lr 0.000212286 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52499
2022-03-06 04:57:40 | INFO | fairseq.trainer | begin training epoch 457
2022-03-06 04:57:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 04:58:02 | INFO | train_inner | epoch 457:     10 / 49 loss=2.118, nll_loss=0.342, ppl=1.27, wps=27435.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.443, loss_scale=32, train_wall=201, gb_free=21.6, wall=52521
2022-03-06 04:59:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 04:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 04:59:33 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.527 | nll_loss 12.933 | ppl 7821.37 | wps 46300.1 | wpb 510.9 | bsz 1 | num_updates 22238 | best_loss 8.953
2022-03-06 04:59:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22238 updates
2022-03-06 04:59:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:59:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 04:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 457 @ 22238 updates, score 13.527) (writing took 1.6576177403330803 seconds)
2022-03-06 04:59:35 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-06 04:59:35 | INFO | train | epoch 457 | loss 2.118 | nll_loss 0.342 | ppl 1.27 | wps 27099.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22238 | lr 0.000212057 | gnorm 0.443 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 52613
2022-03-06 04:59:35 | INFO | fairseq.trainer | begin training epoch 458
2022-03-06 04:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:01:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:01:28 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.519 | nll_loss 12.921 | ppl 7755.96 | wps 46475.5 | wpb 510.9 | bsz 1 | num_updates 22287 | best_loss 8.953
2022-03-06 05:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22287 updates
2022-03-06 05:01:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:01:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 458 @ 22287 updates, score 13.519) (writing took 1.6752354502677917 seconds)
2022-03-06 05:01:30 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-06 05:01:30 | INFO | train | epoch 458 | loss 2.117 | nll_loss 0.342 | ppl 1.27 | wps 27676.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22287 | lr 0.000211824 | gnorm 0.444 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 52728
2022-03-06 05:01:30 | INFO | fairseq.trainer | begin training epoch 459
2022-03-06 05:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:01:59 | INFO | train_inner | epoch 459:     13 / 49 loss=2.118, nll_loss=0.342, ppl=1.27, wps=27441.8, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.445, loss_scale=16, train_wall=201, gb_free=21.6, wall=52757
2022-03-06 05:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:03:23 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.417 | nll_loss 12.81 | ppl 7181.27 | wps 46351.9 | wpb 510.9 | bsz 1 | num_updates 22336 | best_loss 8.953
2022-03-06 05:03:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22336 updates
2022-03-06 05:03:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:03:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 459 @ 22336 updates, score 13.417) (writing took 1.6840927824378014 seconds)
2022-03-06 05:03:24 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-06 05:03:24 | INFO | train | epoch 459 | loss 2.117 | nll_loss 0.342 | ppl 1.27 | wps 27682.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22336 | lr 0.000211591 | gnorm 0.439 | loss_scale 16 | train_wall 97 | gb_free 21.6 | wall 52843
2022-03-06 05:03:24 | INFO | fairseq.trainer | begin training epoch 460
2022-03-06 05:03:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:05:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:05:18 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.508 | nll_loss 12.911 | ppl 7701.2 | wps 46490.4 | wpb 510.9 | bsz 1 | num_updates 22385 | best_loss 8.953
2022-03-06 05:05:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22385 updates
2022-03-06 05:05:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:05:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:05:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 460 @ 22385 updates, score 13.508) (writing took 1.6636100020259619 seconds)
2022-03-06 05:05:19 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-06 05:05:19 | INFO | train | epoch 460 | loss 2.117 | nll_loss 0.342 | ppl 1.27 | wps 27679.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22385 | lr 0.000211359 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 52958
2022-03-06 05:05:19 | INFO | fairseq.trainer | begin training epoch 461
2022-03-06 05:05:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:05:53 | INFO | train_inner | epoch 461:     15 / 49 loss=2.116, nll_loss=0.341, ppl=1.27, wps=27711.4, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.439, loss_scale=32, train_wall=199, gb_free=21.6, wall=52991
2022-03-06 05:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:07:12 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.621 | nll_loss 13.034 | ppl 8384.88 | wps 45891.8 | wpb 510.9 | bsz 1 | num_updates 22434 | best_loss 8.953
2022-03-06 05:07:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22434 updates
2022-03-06 05:07:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:07:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 461 @ 22434 updates, score 13.621) (writing took 1.629030268639326 seconds)
2022-03-06 05:07:14 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-06 05:07:14 | INFO | train | epoch 461 | loss 2.116 | nll_loss 0.341 | ppl 1.27 | wps 27667.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22434 | lr 0.000211128 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53073
2022-03-06 05:07:14 | INFO | fairseq.trainer | begin training epoch 462
2022-03-06 05:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:09:07 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.456 | nll_loss 12.854 | ppl 7405.39 | wps 46398.7 | wpb 510.9 | bsz 1 | num_updates 22483 | best_loss 8.953
2022-03-06 05:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22483 updates
2022-03-06 05:09:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 462 @ 22483 updates, score 13.456) (writing took 1.6573294987902045 seconds)
2022-03-06 05:09:09 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-06 05:09:09 | INFO | train | epoch 462 | loss 2.116 | nll_loss 0.341 | ppl 1.27 | wps 27675.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22483 | lr 0.000210898 | gnorm 0.444 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 53188
2022-03-06 05:09:09 | INFO | fairseq.trainer | begin training epoch 463
2022-03-06 05:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:09:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:09:49 | INFO | train_inner | epoch 463:     18 / 49 loss=2.116, nll_loss=0.341, ppl=1.27, wps=27439.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.443, loss_scale=32, train_wall=201, gb_free=21.6, wall=53228
2022-03-06 05:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:11:02 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.481 | nll_loss 12.882 | ppl 7546.14 | wps 46415 | wpb 510.9 | bsz 1 | num_updates 22531 | best_loss 8.953
2022-03-06 05:11:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22531 updates
2022-03-06 05:11:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 463 @ 22531 updates, score 13.481) (writing took 1.6428974494338036 seconds)
2022-03-06 05:11:04 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-06 05:11:04 | INFO | train | epoch 463 | loss 2.116 | nll_loss 0.341 | ppl 1.27 | wps 27109.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22531 | lr 0.000210673 | gnorm 0.445 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53302
2022-03-06 05:11:04 | INFO | fairseq.trainer | begin training epoch 464
2022-03-06 05:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:12:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:12:57 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.564 | nll_loss 12.972 | ppl 8032.47 | wps 46331.7 | wpb 510.9 | bsz 1 | num_updates 22580 | best_loss 8.953
2022-03-06 05:12:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22580 updates
2022-03-06 05:12:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:12:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:12:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 464 @ 22580 updates, score 13.564) (writing took 1.6868401784449816 seconds)
2022-03-06 05:12:59 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-06 05:12:59 | INFO | train | epoch 464 | loss 2.115 | nll_loss 0.34 | ppl 1.27 | wps 27658.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22580 | lr 0.000210445 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53417
2022-03-06 05:12:59 | INFO | fairseq.trainer | begin training epoch 465
2022-03-06 05:12:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:13:43 | INFO | train_inner | epoch 465:     20 / 49 loss=2.115, nll_loss=0.34, ppl=1.27, wps=27707.5, ups=0.43, wpb=64876.2, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.44, loss_scale=32, train_wall=199, gb_free=21.6, wall=53462
2022-03-06 05:14:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:14:52 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.502 | nll_loss 12.903 | ppl 7659.21 | wps 46240.1 | wpb 510.9 | bsz 1 | num_updates 22628 | best_loss 8.953
2022-03-06 05:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22628 updates
2022-03-06 05:14:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:14:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 465 @ 22628 updates, score 13.502) (writing took 1.680108267813921 seconds)
2022-03-06 05:14:53 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-06 05:14:53 | INFO | train | epoch 465 | loss 2.114 | nll_loss 0.34 | ppl 1.27 | wps 27109.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22628 | lr 0.000210221 | gnorm 0.442 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53532
2022-03-06 05:14:53 | INFO | fairseq.trainer | begin training epoch 466
2022-03-06 05:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:16:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:16:47 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.538 | nll_loss 12.941 | ppl 7864.59 | wps 46401 | wpb 510.9 | bsz 1 | num_updates 22677 | best_loss 8.953
2022-03-06 05:16:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22677 updates
2022-03-06 05:16:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:16:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:16:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 466 @ 22677 updates, score 13.538) (writing took 1.6410211827605963 seconds)
2022-03-06 05:16:48 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-06 05:16:48 | INFO | train | epoch 466 | loss 2.113 | nll_loss 0.339 | ppl 1.26 | wps 27678.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22677 | lr 0.000209994 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53647
2022-03-06 05:16:48 | INFO | fairseq.trainer | begin training epoch 467
2022-03-06 05:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:17:40 | INFO | train_inner | epoch 467:     23 / 49 loss=2.113, nll_loss=0.339, ppl=1.27, wps=27451.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.436, loss_scale=32, train_wall=200, gb_free=21.6, wall=53698
2022-03-06 05:18:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:18:41 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.554 | nll_loss 12.959 | ppl 7960.21 | wps 46531.1 | wpb 510.9 | bsz 1 | num_updates 22726 | best_loss 8.953
2022-03-06 05:18:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22726 updates
2022-03-06 05:18:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:18:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 467 @ 22726 updates, score 13.554) (writing took 1.6773992329835892 seconds)
2022-03-06 05:18:43 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-06 05:18:43 | INFO | train | epoch 467 | loss 2.113 | nll_loss 0.339 | ppl 1.26 | wps 27680 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22726 | lr 0.000209768 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53762
2022-03-06 05:18:43 | INFO | fairseq.trainer | begin training epoch 468
2022-03-06 05:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:19:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:20:36 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.51 | nll_loss 12.917 | ppl 7731.52 | wps 46443.6 | wpb 510.9 | bsz 1 | num_updates 22774 | best_loss 8.953
2022-03-06 05:20:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22774 updates
2022-03-06 05:20:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:20:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 468 @ 22774 updates, score 13.51) (writing took 1.6257511982694268 seconds)
2022-03-06 05:20:38 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-06 05:20:38 | INFO | train | epoch 468 | loss 2.112 | nll_loss 0.338 | ppl 1.26 | wps 27107.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22774 | lr 0.000209546 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53877
2022-03-06 05:20:38 | INFO | fairseq.trainer | begin training epoch 469
2022-03-06 05:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:21:36 | INFO | train_inner | epoch 469:     26 / 49 loss=2.113, nll_loss=0.338, ppl=1.26, wps=27439.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.432, loss_scale=32, train_wall=201, gb_free=21.6, wall=53935
2022-03-06 05:22:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:22:31 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.52 | nll_loss 12.928 | ppl 7793.23 | wps 46482.6 | wpb 510.9 | bsz 1 | num_updates 22823 | best_loss 8.953
2022-03-06 05:22:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22823 updates
2022-03-06 05:22:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:22:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:22:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 469 @ 22823 updates, score 13.52) (writing took 1.6618718290701509 seconds)
2022-03-06 05:22:33 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-06 05:22:33 | INFO | train | epoch 469 | loss 2.113 | nll_loss 0.339 | ppl 1.26 | wps 27668.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22823 | lr 0.000209321 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 53991
2022-03-06 05:22:33 | INFO | fairseq.trainer | begin training epoch 470
2022-03-06 05:22:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:24:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:24:26 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.455 | nll_loss 12.853 | ppl 7399 | wps 46393.5 | wpb 510.9 | bsz 1 | num_updates 22872 | best_loss 8.953
2022-03-06 05:24:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22872 updates
2022-03-06 05:24:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:24:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:24:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 470 @ 22872 updates, score 13.455) (writing took 1.6763289151713252 seconds)
2022-03-06 05:24:28 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-06 05:24:28 | INFO | train | epoch 470 | loss 2.113 | nll_loss 0.34 | ppl 1.27 | wps 27677.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22872 | lr 0.000209097 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54106
2022-03-06 05:24:28 | INFO | fairseq.trainer | begin training epoch 471
2022-03-06 05:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:24:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:25:32 | INFO | train_inner | epoch 471:     29 / 49 loss=2.113, nll_loss=0.339, ppl=1.27, wps=27447.6, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.44, loss_scale=32, train_wall=201, gb_free=21.6, wall=54171
2022-03-06 05:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:26:21 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.566 | nll_loss 12.974 | ppl 8042.98 | wps 46474.4 | wpb 510.9 | bsz 1 | num_updates 22920 | best_loss 8.953
2022-03-06 05:26:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22920 updates
2022-03-06 05:26:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 471 @ 22920 updates, score 13.566) (writing took 1.6368188615888357 seconds)
2022-03-06 05:26:22 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-06 05:26:22 | INFO | train | epoch 471 | loss 2.112 | nll_loss 0.338 | ppl 1.26 | wps 27103 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 22920 | lr 0.000208878 | gnorm 0.439 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54221
2022-03-06 05:26:22 | INFO | fairseq.trainer | begin training epoch 472
2022-03-06 05:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:28:16 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.48 | nll_loss 12.888 | ppl 7578.62 | wps 46484.2 | wpb 510.9 | bsz 1 | num_updates 22969 | best_loss 8.953
2022-03-06 05:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22969 updates
2022-03-06 05:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 472 @ 22969 updates, score 13.48) (writing took 1.6980711510404944 seconds)
2022-03-06 05:28:17 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-06 05:28:17 | INFO | train | epoch 472 | loss 2.111 | nll_loss 0.338 | ppl 1.26 | wps 27650.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 22969 | lr 0.000208655 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54336
2022-03-06 05:28:17 | INFO | fairseq.trainer | begin training epoch 473
2022-03-06 05:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:29:27 | INFO | train_inner | epoch 473:     31 / 49 loss=2.111, nll_loss=0.337, ppl=1.26, wps=27690.8, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.435, loss_scale=32, train_wall=199, gb_free=21.6, wall=54405
2022-03-06 05:29:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:30:11 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.579 | nll_loss 12.989 | ppl 8132.13 | wps 46347.9 | wpb 510.9 | bsz 1 | num_updates 23017 | best_loss 8.953
2022-03-06 05:30:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23017 updates
2022-03-06 05:30:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:30:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 473 @ 23017 updates, score 13.579) (writing took 1.679237736389041 seconds)
2022-03-06 05:30:12 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-06 05:30:12 | INFO | train | epoch 473 | loss 2.111 | nll_loss 0.337 | ppl 1.26 | wps 27082.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23017 | lr 0.000208437 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54451
2022-03-06 05:30:12 | INFO | fairseq.trainer | begin training epoch 474
2022-03-06 05:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:32:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:32:06 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.504 | nll_loss 12.906 | ppl 7674.09 | wps 46443.6 | wpb 510.9 | bsz 1 | num_updates 23066 | best_loss 8.953
2022-03-06 05:32:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23066 updates
2022-03-06 05:32:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 474 @ 23066 updates, score 13.504) (writing took 1.702196029946208 seconds)
2022-03-06 05:32:07 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-06 05:32:07 | INFO | train | epoch 474 | loss 2.111 | nll_loss 0.338 | ppl 1.26 | wps 27638.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23066 | lr 0.000208216 | gnorm 0.443 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54566
2022-03-06 05:32:07 | INFO | fairseq.trainer | begin training epoch 475
2022-03-06 05:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:33:23 | INFO | train_inner | epoch 475:     34 / 49 loss=2.111, nll_loss=0.337, ppl=1.26, wps=27420.3, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.443, loss_scale=32, train_wall=201, gb_free=21.6, wall=54642
2022-03-06 05:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:34:00 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.472 | nll_loss 12.879 | ppl 7532.38 | wps 46474.2 | wpb 510.9 | bsz 1 | num_updates 23115 | best_loss 8.953
2022-03-06 05:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23115 updates
2022-03-06 05:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 475 @ 23115 updates, score 13.472) (writing took 1.6564444657415152 seconds)
2022-03-06 05:34:02 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-06 05:34:02 | INFO | train | epoch 475 | loss 2.11 | nll_loss 0.336 | ppl 1.26 | wps 27674.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23115 | lr 0.000207995 | gnorm 0.438 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54681
2022-03-06 05:34:02 | INFO | fairseq.trainer | begin training epoch 476
2022-03-06 05:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:34:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:35:55 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.575 | nll_loss 12.984 | ppl 8100.03 | wps 46492.8 | wpb 510.9 | bsz 1 | num_updates 23163 | best_loss 8.953
2022-03-06 05:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23163 updates
2022-03-06 05:35:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:35:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:35:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 476 @ 23163 updates, score 13.575) (writing took 1.6834374107420444 seconds)
2022-03-06 05:35:57 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-06 05:35:57 | INFO | train | epoch 476 | loss 2.11 | nll_loss 0.337 | ppl 1.26 | wps 27118.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23163 | lr 0.000207779 | gnorm 0.437 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54796
2022-03-06 05:35:57 | INFO | fairseq.trainer | begin training epoch 477
2022-03-06 05:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:37:20 | INFO | train_inner | epoch 477:     37 / 49 loss=2.109, nll_loss=0.336, ppl=1.26, wps=27450.5, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.436, loss_scale=32, train_wall=201, gb_free=21.6, wall=54878
2022-03-06 05:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:37:50 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.473 | nll_loss 12.881 | ppl 7545.88 | wps 46538 | wpb 510.9 | bsz 1 | num_updates 23212 | best_loss 8.953
2022-03-06 05:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23212 updates
2022-03-06 05:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:37:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:37:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 477 @ 23212 updates, score 13.473) (writing took 1.6981726540252566 seconds)
2022-03-06 05:37:52 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-06 05:37:52 | INFO | train | epoch 477 | loss 2.108 | nll_loss 0.335 | ppl 1.26 | wps 27673.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23212 | lr 0.00020756 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 54910
2022-03-06 05:37:52 | INFO | fairseq.trainer | begin training epoch 478
2022-03-06 05:37:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:39:45 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.653 | nll_loss 13.068 | ppl 8588.35 | wps 46308.6 | wpb 510.9 | bsz 1 | num_updates 23261 | best_loss 8.953
2022-03-06 05:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23261 updates
2022-03-06 05:39:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:39:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:39:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 478 @ 23261 updates, score 13.653) (writing took 1.6835698084905744 seconds)
2022-03-06 05:39:47 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-06 05:39:47 | INFO | train | epoch 478 | loss 2.109 | nll_loss 0.337 | ppl 1.26 | wps 27653.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23261 | lr 0.000207341 | gnorm 0.444 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55025
2022-03-06 05:39:47 | INFO | fairseq.trainer | begin training epoch 479
2022-03-06 05:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:39:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:41:16 | INFO | train_inner | epoch 479:     40 / 49 loss=2.109, nll_loss=0.336, ppl=1.26, wps=27437.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.44, loss_scale=32, train_wall=201, gb_free=21.6, wall=55115
2022-03-06 05:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:41:40 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.458 | nll_loss 12.86 | ppl 7433.18 | wps 46400 | wpb 510.9 | bsz 1 | num_updates 23309 | best_loss 8.953
2022-03-06 05:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23309 updates
2022-03-06 05:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 479 @ 23309 updates, score 13.458) (writing took 1.681883180513978 seconds)
2022-03-06 05:41:42 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-06 05:41:42 | INFO | train | epoch 479 | loss 2.109 | nll_loss 0.336 | ppl 1.26 | wps 27092.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23309 | lr 0.000207128 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55140
2022-03-06 05:41:42 | INFO | fairseq.trainer | begin training epoch 480
2022-03-06 05:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:43:35 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.47 | nll_loss 12.875 | ppl 7510.04 | wps 46493.1 | wpb 510.9 | bsz 1 | num_updates 23358 | best_loss 8.953
2022-03-06 05:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23358 updates
2022-03-06 05:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 480 @ 23358 updates, score 13.47) (writing took 1.6797478459775448 seconds)
2022-03-06 05:43:36 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-06 05:43:36 | INFO | train | epoch 480 | loss 2.108 | nll_loss 0.335 | ppl 1.26 | wps 27679.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23358 | lr 0.00020691 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55255
2022-03-06 05:43:36 | INFO | fairseq.trainer | begin training epoch 481
2022-03-06 05:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:45:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:45:13 | INFO | train_inner | epoch 481:     43 / 49 loss=2.108, nll_loss=0.335, ppl=1.26, wps=27432.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.436, loss_scale=32, train_wall=201, gb_free=21.6, wall=55351
2022-03-06 05:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:45:30 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.571 | nll_loss 12.981 | ppl 8083.51 | wps 46484.6 | wpb 510.9 | bsz 1 | num_updates 23406 | best_loss 8.953
2022-03-06 05:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23406 updates
2022-03-06 05:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:45:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:45:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 481 @ 23406 updates, score 13.571) (writing took 1.645609512925148 seconds)
2022-03-06 05:45:31 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-06 05:45:31 | INFO | train | epoch 481 | loss 2.107 | nll_loss 0.335 | ppl 1.26 | wps 27094.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23406 | lr 0.000206698 | gnorm 0.438 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55370
2022-03-06 05:45:31 | INFO | fairseq.trainer | begin training epoch 482
2022-03-06 05:45:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:47:24 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.477 | nll_loss 12.882 | ppl 7551.04 | wps 46474 | wpb 510.9 | bsz 1 | num_updates 23455 | best_loss 8.953
2022-03-06 05:47:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23455 updates
2022-03-06 05:47:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 482 @ 23455 updates, score 13.477) (writing took 1.6776655530557036 seconds)
2022-03-06 05:47:26 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-06 05:47:26 | INFO | train | epoch 482 | loss 2.107 | nll_loss 0.334 | ppl 1.26 | wps 27689 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23455 | lr 0.000206482 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55485
2022-03-06 05:47:26 | INFO | fairseq.trainer | begin training epoch 483
2022-03-06 05:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:49:06 | INFO | train_inner | epoch 483:     45 / 49 loss=2.107, nll_loss=0.334, ppl=1.26, wps=27728.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.432, loss_scale=32, train_wall=199, gb_free=21.6, wall=55585
2022-03-06 05:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:49:19 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.571 | nll_loss 12.984 | ppl 8100.91 | wps 46512.6 | wpb 510.9 | bsz 1 | num_updates 23504 | best_loss 8.953
2022-03-06 05:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23504 updates
2022-03-06 05:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 483 @ 23504 updates, score 13.571) (writing took 1.6741877123713493 seconds)
2022-03-06 05:49:21 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-06 05:49:21 | INFO | train | epoch 483 | loss 2.106 | nll_loss 0.334 | ppl 1.26 | wps 27690 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23504 | lr 0.000206267 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55599
2022-03-06 05:49:21 | INFO | fairseq.trainer | begin training epoch 484
2022-03-06 05:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:50:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:51:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:51:14 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.534 | nll_loss 12.942 | ppl 7871.56 | wps 46385.8 | wpb 510.9 | bsz 1 | num_updates 23552 | best_loss 8.953
2022-03-06 05:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23552 updates
2022-03-06 05:51:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 484 @ 23552 updates, score 13.534) (writing took 1.6262120408937335 seconds)
2022-03-06 05:51:16 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-06 05:51:16 | INFO | train | epoch 484 | loss 2.106 | nll_loss 0.333 | ppl 1.26 | wps 27124.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23552 | lr 0.000206056 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55714
2022-03-06 05:51:16 | INFO | fairseq.trainer | begin training epoch 485
2022-03-06 05:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:53:03 | INFO | train_inner | epoch 485:     48 / 49 loss=2.106, nll_loss=0.334, ppl=1.26, wps=27456.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23600, lr=0.000205847, gnorm=0.435, loss_scale=32, train_wall=201, gb_free=21.6, wall=55821
2022-03-06 05:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:53:09 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.553 | nll_loss 12.964 | ppl 7987.56 | wps 46492 | wpb 510.9 | bsz 1 | num_updates 23601 | best_loss 8.953
2022-03-06 05:53:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23601 updates
2022-03-06 05:53:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:53:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:53:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 485 @ 23601 updates, score 13.553) (writing took 1.6157208178192377 seconds)
2022-03-06 05:53:10 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-06 05:53:10 | INFO | train | epoch 485 | loss 2.106 | nll_loss 0.334 | ppl 1.26 | wps 27701.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23601 | lr 0.000205842 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55829
2022-03-06 05:53:10 | INFO | fairseq.trainer | begin training epoch 486
2022-03-06 05:53:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:55:03 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.524 | nll_loss 12.928 | ppl 7791.2 | wps 46221.9 | wpb 510.9 | bsz 1 | num_updates 23650 | best_loss 8.953
2022-03-06 05:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23650 updates
2022-03-06 05:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:55:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:55:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 486 @ 23650 updates, score 13.524) (writing took 1.701282475143671 seconds)
2022-03-06 05:55:05 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-06 05:55:05 | INFO | train | epoch 486 | loss 2.105 | nll_loss 0.333 | ppl 1.26 | wps 27659.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23650 | lr 0.000205629 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 55944
2022-03-06 05:55:05 | INFO | fairseq.trainer | begin training epoch 487
2022-03-06 05:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:55:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 05:56:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:56:58 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.516 | nll_loss 12.925 | ppl 7778.55 | wps 46338.5 | wpb 510.9 | bsz 1 | num_updates 23698 | best_loss 8.953
2022-03-06 05:56:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23698 updates
2022-03-06 05:56:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:57:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:57:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 487 @ 23698 updates, score 13.516) (writing took 1.7030400605872273 seconds)
2022-03-06 05:57:00 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-06 05:57:00 | INFO | train | epoch 487 | loss 2.104 | nll_loss 0.332 | ppl 1.26 | wps 27106.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23698 | lr 0.000205421 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56059
2022-03-06 05:57:00 | INFO | fairseq.trainer | begin training epoch 488
2022-03-06 05:57:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 05:57:05 | INFO | train_inner | epoch 488:      2 / 49 loss=2.105, nll_loss=0.333, ppl=1.26, wps=26697.2, ups=0.41, wpb=64544.1, bsz=126.1, num_updates=23700, lr=0.000205412, gnorm=0.433, loss_scale=32, train_wall=200, gb_free=21.6, wall=56063
2022-03-06 05:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 05:58:53 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.48 | nll_loss 12.885 | ppl 7565.27 | wps 46302.5 | wpb 510.9 | bsz 1 | num_updates 23747 | best_loss 8.953
2022-03-06 05:58:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23747 updates
2022-03-06 05:58:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:58:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 05:58:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 488 @ 23747 updates, score 13.48) (writing took 1.6929949158802629 seconds)
2022-03-06 05:58:55 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-06 05:58:55 | INFO | train | epoch 488 | loss 2.104 | nll_loss 0.332 | ppl 1.26 | wps 27657 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23747 | lr 0.000205209 | gnorm 0.433 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56174
2022-03-06 05:58:55 | INFO | fairseq.trainer | begin training epoch 489
2022-03-06 05:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:00:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:00:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:00:48 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.497 | nll_loss 12.904 | ppl 7663.25 | wps 46412.4 | wpb 510.9 | bsz 1 | num_updates 23795 | best_loss 8.953
2022-03-06 06:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23795 updates
2022-03-06 06:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 489 @ 23795 updates, score 13.497) (writing took 1.6287080831825733 seconds)
2022-03-06 06:00:50 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-06 06:00:50 | INFO | train | epoch 489 | loss 2.104 | nll_loss 0.332 | ppl 1.26 | wps 27103.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23795 | lr 0.000205002 | gnorm 0.436 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56288
2022-03-06 06:00:50 | INFO | fairseq.trainer | begin training epoch 490
2022-03-06 06:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:01:01 | INFO | train_inner | epoch 490:      5 / 49 loss=2.104, nll_loss=0.332, ppl=1.26, wps=27434.9, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.434, loss_scale=32, train_wall=201, gb_free=21.6, wall=56300
2022-03-06 06:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:02:43 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.591 | nll_loss 13.002 | ppl 8202.34 | wps 46340.6 | wpb 510.9 | bsz 1 | num_updates 23844 | best_loss 8.953
2022-03-06 06:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23844 updates
2022-03-06 06:02:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:02:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:02:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 490 @ 23844 updates, score 13.591) (writing took 1.711438074707985 seconds)
2022-03-06 06:02:45 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-06 06:02:45 | INFO | train | epoch 490 | loss 2.104 | nll_loss 0.332 | ppl 1.26 | wps 27631.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23844 | lr 0.000204791 | gnorm 0.435 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56403
2022-03-06 06:02:45 | INFO | fairseq.trainer | begin training epoch 491
2022-03-06 06:02:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:04:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:04:38 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.61 | nll_loss 13.022 | ppl 8316.21 | wps 46395.9 | wpb 510.9 | bsz 1 | num_updates 23893 | best_loss 8.953
2022-03-06 06:04:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23893 updates
2022-03-06 06:04:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 491 @ 23893 updates, score 13.61) (writing took 1.7494476046413183 seconds)
2022-03-06 06:04:40 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-06 06:04:40 | INFO | train | epoch 491 | loss 2.104 | nll_loss 0.332 | ppl 1.26 | wps 27666.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23893 | lr 0.000204581 | gnorm 0.44 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56518
2022-03-06 06:04:40 | INFO | fairseq.trainer | begin training epoch 492
2022-03-06 06:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:04:55 | INFO | train_inner | epoch 492:      7 / 49 loss=2.104, nll_loss=0.332, ppl=1.26, wps=27681.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.437, loss_scale=32, train_wall=199, gb_free=21.6, wall=56534
2022-03-06 06:05:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:06:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:06:33 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.533 | nll_loss 12.945 | ppl 7885.72 | wps 46342.1 | wpb 510.9 | bsz 1 | num_updates 23941 | best_loss 8.953
2022-03-06 06:06:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23941 updates
2022-03-06 06:06:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 492 @ 23941 updates, score 13.533) (writing took 1.65231282543391 seconds)
2022-03-06 06:06:34 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-06 06:06:34 | INFO | train | epoch 492 | loss 2.102 | nll_loss 0.331 | ppl 1.26 | wps 27109.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 23941 | lr 0.000204376 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56633
2022-03-06 06:06:34 | INFO | fairseq.trainer | begin training epoch 493
2022-03-06 06:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:08:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:08:28 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.471 | nll_loss 12.872 | ppl 7494.12 | wps 46346.5 | wpb 510.9 | bsz 1 | num_updates 23990 | best_loss 8.953
2022-03-06 06:08:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23990 updates
2022-03-06 06:08:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:08:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:08:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 493 @ 23990 updates, score 13.471) (writing took 1.6547885462641716 seconds)
2022-03-06 06:08:29 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-06 06:08:29 | INFO | train | epoch 493 | loss 2.102 | nll_loss 0.331 | ppl 1.26 | wps 27662.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 23990 | lr 0.000204167 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56748
2022-03-06 06:08:29 | INFO | fairseq.trainer | begin training epoch 494
2022-03-06 06:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:08:52 | INFO | train_inner | epoch 494:     10 / 49 loss=2.102, nll_loss=0.331, ppl=1.26, wps=27439.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.43, loss_scale=32, train_wall=201, gb_free=21.6, wall=56770
2022-03-06 06:10:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:10:22 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.51 | nll_loss 12.917 | ppl 7736.6 | wps 46490.7 | wpb 510.9 | bsz 1 | num_updates 24039 | best_loss 8.953
2022-03-06 06:10:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24039 updates
2022-03-06 06:10:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:10:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 494 @ 24039 updates, score 13.51) (writing took 1.6218058802187443 seconds)
2022-03-06 06:10:24 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-06 06:10:24 | INFO | train | epoch 494 | loss 2.102 | nll_loss 0.331 | ppl 1.26 | wps 27700.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24039 | lr 0.000203958 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56863
2022-03-06 06:10:24 | INFO | fairseq.trainer | begin training epoch 495
2022-03-06 06:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:10:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:12:17 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.531 | nll_loss 12.944 | ppl 7877.57 | wps 46266.5 | wpb 510.9 | bsz 1 | num_updates 24087 | best_loss 8.953
2022-03-06 06:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24087 updates
2022-03-06 06:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:12:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 495 @ 24087 updates, score 13.531) (writing took 1.6519347969442606 seconds)
2022-03-06 06:12:19 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-06 06:12:19 | INFO | train | epoch 495 | loss 2.101 | nll_loss 0.33 | ppl 1.26 | wps 27075.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24087 | lr 0.000203755 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 56978
2022-03-06 06:12:19 | INFO | fairseq.trainer | begin training epoch 496
2022-03-06 06:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:12:48 | INFO | train_inner | epoch 496:     13 / 49 loss=2.101, nll_loss=0.33, ppl=1.26, wps=27444, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.428, loss_scale=32, train_wall=201, gb_free=21.6, wall=57007
2022-03-06 06:14:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:14:12 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.462 | nll_loss 12.864 | ppl 7453.09 | wps 46096.2 | wpb 510.9 | bsz 1 | num_updates 24136 | best_loss 8.953
2022-03-06 06:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24136 updates
2022-03-06 06:14:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:14:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:14:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 496 @ 24136 updates, score 13.462) (writing took 1.7086177356541157 seconds)
2022-03-06 06:14:14 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-06 06:14:14 | INFO | train | epoch 496 | loss 2.101 | nll_loss 0.331 | ppl 1.26 | wps 27652.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24136 | lr 0.000203548 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57093
2022-03-06 06:14:14 | INFO | fairseq.trainer | begin training epoch 497
2022-03-06 06:14:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:16:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:16:07 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.579 | nll_loss 12.99 | ppl 8135.77 | wps 46504.5 | wpb 510.9 | bsz 1 | num_updates 24185 | best_loss 8.953
2022-03-06 06:16:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24185 updates
2022-03-06 06:16:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 497 @ 24185 updates, score 13.579) (writing took 1.6447218274697661 seconds)
2022-03-06 06:16:09 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-06 06:16:09 | INFO | train | epoch 497 | loss 2.101 | nll_loss 0.33 | ppl 1.26 | wps 27683.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24185 | lr 0.000203342 | gnorm 0.429 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 57207
2022-03-06 06:16:09 | INFO | fairseq.trainer | begin training epoch 498
2022-03-06 06:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:16:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:16:45 | INFO | train_inner | epoch 498:     16 / 49 loss=2.102, nll_loss=0.331, ppl=1.26, wps=27436.2, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.431, loss_scale=32, train_wall=201, gb_free=21.6, wall=57243
2022-03-06 06:17:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:18:02 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.607 | nll_loss 13.021 | ppl 8314.36 | wps 46255.9 | wpb 510.9 | bsz 1 | num_updates 24233 | best_loss 8.953
2022-03-06 06:18:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24233 updates
2022-03-06 06:18:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:18:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:18:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 498 @ 24233 updates, score 13.607) (writing took 1.6315216943621635 seconds)
2022-03-06 06:18:04 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-06 06:18:04 | INFO | train | epoch 498 | loss 2.101 | nll_loss 0.33 | ppl 1.26 | wps 27099.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24233 | lr 0.00020314 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57322
2022-03-06 06:18:04 | INFO | fairseq.trainer | begin training epoch 499
2022-03-06 06:18:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:19:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:19:57 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.463 | nll_loss 12.868 | ppl 7475.19 | wps 46371.1 | wpb 510.9 | bsz 1 | num_updates 24282 | best_loss 8.953
2022-03-06 06:19:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24282 updates
2022-03-06 06:19:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:19:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 499 @ 24282 updates, score 13.463) (writing took 1.6452724011614919 seconds)
2022-03-06 06:19:58 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-06 06:19:58 | INFO | train | epoch 499 | loss 2.101 | nll_loss 0.33 | ppl 1.26 | wps 27684.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24282 | lr 0.000202935 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57437
2022-03-06 06:19:58 | INFO | fairseq.trainer | begin training epoch 500
2022-03-06 06:19:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:20:39 | INFO | train_inner | epoch 500:     18 / 49 loss=2.101, nll_loss=0.33, ppl=1.26, wps=27707.5, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.43, loss_scale=32, train_wall=199, gb_free=21.6, wall=57477
2022-03-06 06:21:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:21:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:21:52 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.479 | nll_loss 12.885 | ppl 7564.25 | wps 46377.1 | wpb 510.9 | bsz 1 | num_updates 24330 | best_loss 8.953
2022-03-06 06:21:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24330 updates
2022-03-06 06:21:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:21:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:21:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 500 @ 24330 updates, score 13.479) (writing took 1.684624744579196 seconds)
2022-03-06 06:21:53 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-06 06:21:53 | INFO | train | epoch 500 | loss 2.1 | nll_loss 0.33 | ppl 1.26 | wps 27094.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24330 | lr 0.000202735 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57552
2022-03-06 06:21:53 | INFO | fairseq.trainer | begin training epoch 501
2022-03-06 06:21:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:23:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:23:46 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.557 | nll_loss 12.97 | ppl 8024.73 | wps 46371.4 | wpb 510.9 | bsz 1 | num_updates 24379 | best_loss 8.953
2022-03-06 06:23:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24379 updates
2022-03-06 06:23:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:23:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:23:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 501 @ 24379 updates, score 13.557) (writing took 1.6530953394249082 seconds)
2022-03-06 06:23:48 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-06 06:23:48 | INFO | train | epoch 501 | loss 2.098 | nll_loss 0.328 | ppl 1.26 | wps 27674.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24379 | lr 0.000202531 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57667
2022-03-06 06:23:48 | INFO | fairseq.trainer | begin training epoch 502
2022-03-06 06:23:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:24:35 | INFO | train_inner | epoch 502:     21 / 49 loss=2.099, nll_loss=0.329, ppl=1.26, wps=27441.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.427, loss_scale=32, train_wall=201, gb_free=21.6, wall=57714
2022-03-06 06:25:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:25:41 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.567 | nll_loss 12.981 | ppl 8086.88 | wps 46382.6 | wpb 510.9 | bsz 1 | num_updates 24428 | best_loss 8.953
2022-03-06 06:25:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24428 updates
2022-03-06 06:25:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:25:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:25:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 502 @ 24428 updates, score 13.567) (writing took 1.649045861326158 seconds)
2022-03-06 06:25:43 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-06 06:25:43 | INFO | train | epoch 502 | loss 2.099 | nll_loss 0.329 | ppl 1.26 | wps 27675.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24428 | lr 0.000202328 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57782
2022-03-06 06:25:43 | INFO | fairseq.trainer | begin training epoch 503
2022-03-06 06:25:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:26:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:27:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:27:36 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.51 | nll_loss 12.917 | ppl 7732.21 | wps 46381.4 | wpb 510.9 | bsz 1 | num_updates 24476 | best_loss 8.953
2022-03-06 06:27:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24476 updates
2022-03-06 06:27:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:27:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:27:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 503 @ 24476 updates, score 13.51) (writing took 1.6596307726576924 seconds)
2022-03-06 06:27:38 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-06 06:27:38 | INFO | train | epoch 503 | loss 2.098 | nll_loss 0.328 | ppl 1.26 | wps 27109.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24476 | lr 0.00020213 | gnorm 0.434 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 57896
2022-03-06 06:27:38 | INFO | fairseq.trainer | begin training epoch 504
2022-03-06 06:27:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:28:31 | INFO | train_inner | epoch 504:     24 / 49 loss=2.098, nll_loss=0.328, ppl=1.26, wps=27457, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.432, loss_scale=32, train_wall=200, gb_free=21.6, wall=57950
2022-03-06 06:29:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:29:31 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.624 | nll_loss 13.038 | ppl 8411.76 | wps 46598.7 | wpb 510.9 | bsz 1 | num_updates 24525 | best_loss 8.953
2022-03-06 06:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24525 updates
2022-03-06 06:29:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 504 @ 24525 updates, score 13.624) (writing took 1.6773278694599867 seconds)
2022-03-06 06:29:32 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-06 06:29:32 | INFO | train | epoch 504 | loss 2.098 | nll_loss 0.328 | ppl 1.26 | wps 27721.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24525 | lr 0.000201928 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58011
2022-03-06 06:29:32 | INFO | fairseq.trainer | begin training epoch 505
2022-03-06 06:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:31:26 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.541 | nll_loss 12.952 | ppl 7921.55 | wps 46377.2 | wpb 510.9 | bsz 1 | num_updates 24574 | best_loss 8.953
2022-03-06 06:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24574 updates
2022-03-06 06:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:31:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 505 @ 24574 updates, score 13.541) (writing took 1.6654252409934998 seconds)
2022-03-06 06:31:27 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-06 06:31:27 | INFO | train | epoch 505 | loss 2.097 | nll_loss 0.327 | ppl 1.25 | wps 27656.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24574 | lr 0.000201726 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58126
2022-03-06 06:31:27 | INFO | fairseq.trainer | begin training epoch 506
2022-03-06 06:31:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:32:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:32:28 | INFO | train_inner | epoch 506:     27 / 49 loss=2.098, nll_loss=0.328, ppl=1.25, wps=27457.8, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.425, loss_scale=32, train_wall=201, gb_free=21.6, wall=58186
2022-03-06 06:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:33:20 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.536 | nll_loss 12.946 | ppl 7890.15 | wps 45596.8 | wpb 510.9 | bsz 1 | num_updates 24622 | best_loss 8.953
2022-03-06 06:33:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24622 updates
2022-03-06 06:33:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 506 @ 24622 updates, score 13.536) (writing took 1.629087958484888 seconds)
2022-03-06 06:33:22 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-06 06:33:22 | INFO | train | epoch 506 | loss 2.097 | nll_loss 0.327 | ppl 1.25 | wps 27102.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24622 | lr 0.000201529 | gnorm 0.421 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58241
2022-03-06 06:33:22 | INFO | fairseq.trainer | begin training epoch 507
2022-03-06 06:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:35:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:35:15 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.491 | nll_loss 12.893 | ppl 7607.25 | wps 46345.8 | wpb 510.9 | bsz 1 | num_updates 24671 | best_loss 8.953
2022-03-06 06:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24671 updates
2022-03-06 06:35:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:35:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:35:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 507 @ 24671 updates, score 13.491) (writing took 1.6733408262953162 seconds)
2022-03-06 06:35:17 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-06 06:35:17 | INFO | train | epoch 507 | loss 2.098 | nll_loss 0.328 | ppl 1.26 | wps 27671.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24671 | lr 0.000201329 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58356
2022-03-06 06:35:17 | INFO | fairseq.trainer | begin training epoch 508
2022-03-06 06:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:36:22 | INFO | train_inner | epoch 508:     29 / 49 loss=2.097, nll_loss=0.327, ppl=1.25, wps=27692, ups=0.43, wpb=64867.4, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.427, loss_scale=32, train_wall=199, gb_free=21.6, wall=58421
2022-03-06 06:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:37:10 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.606 | nll_loss 13.019 | ppl 8302.01 | wps 46454.4 | wpb 510.9 | bsz 1 | num_updates 24720 | best_loss 8.953
2022-03-06 06:37:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24720 updates
2022-03-06 06:37:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:37:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:37:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 508 @ 24720 updates, score 13.606) (writing took 1.6853201109915972 seconds)
2022-03-06 06:37:12 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-06 06:37:12 | INFO | train | epoch 508 | loss 2.097 | nll_loss 0.327 | ppl 1.25 | wps 27662.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24720 | lr 0.000201129 | gnorm 0.434 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 58470
2022-03-06 06:37:12 | INFO | fairseq.trainer | begin training epoch 509
2022-03-06 06:37:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:37:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:39:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:39:05 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.495 | nll_loss 12.904 | ppl 7665.34 | wps 46382.7 | wpb 510.9 | bsz 1 | num_updates 24768 | best_loss 8.953
2022-03-06 06:39:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24768 updates
2022-03-06 06:39:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:39:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 509 @ 24768 updates, score 13.495) (writing took 1.737755541689694 seconds)
2022-03-06 06:39:07 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-06 06:39:07 | INFO | train | epoch 509 | loss 2.095 | nll_loss 0.326 | ppl 1.25 | wps 27074.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24768 | lr 0.000200935 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58585
2022-03-06 06:39:07 | INFO | fairseq.trainer | begin training epoch 510
2022-03-06 06:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:40:18 | INFO | train_inner | epoch 510:     32 / 49 loss=2.096, nll_loss=0.326, ppl=1.25, wps=27434.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.427, loss_scale=32, train_wall=201, gb_free=21.6, wall=58657
2022-03-06 06:40:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:41:00 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.614 | nll_loss 13.028 | ppl 8352.92 | wps 46541.2 | wpb 510.9 | bsz 1 | num_updates 24817 | best_loss 8.953
2022-03-06 06:41:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24817 updates
2022-03-06 06:41:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:41:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:41:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 510 @ 24817 updates, score 13.614) (writing took 1.6816576840355992 seconds)
2022-03-06 06:41:02 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-06 06:41:02 | INFO | train | epoch 510 | loss 2.096 | nll_loss 0.327 | ppl 1.25 | wps 27695.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24817 | lr 0.000200736 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58700
2022-03-06 06:41:02 | INFO | fairseq.trainer | begin training epoch 511
2022-03-06 06:41:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:42:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:42:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:42:55 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.526 | nll_loss 12.934 | ppl 7823.49 | wps 46275.7 | wpb 510.9 | bsz 1 | num_updates 24865 | best_loss 8.953
2022-03-06 06:42:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24865 updates
2022-03-06 06:42:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:42:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 511 @ 24865 updates, score 13.526) (writing took 1.6599978534504771 seconds)
2022-03-06 06:42:56 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-06 06:42:56 | INFO | train | epoch 511 | loss 2.096 | nll_loss 0.326 | ppl 1.25 | wps 27098.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 24865 | lr 0.000200542 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58815
2022-03-06 06:42:56 | INFO | fairseq.trainer | begin training epoch 512
2022-03-06 06:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:44:15 | INFO | train_inner | epoch 512:     35 / 49 loss=2.096, nll_loss=0.326, ppl=1.25, wps=27444.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.427, loss_scale=32, train_wall=201, gb_free=21.6, wall=58893
2022-03-06 06:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:44:50 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.588 | nll_loss 13.003 | ppl 8207.97 | wps 46530.8 | wpb 510.9 | bsz 1 | num_updates 24914 | best_loss 8.953
2022-03-06 06:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24914 updates
2022-03-06 06:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:44:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:44:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 512 @ 24914 updates, score 13.588) (writing took 1.636415339075029 seconds)
2022-03-06 06:44:51 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-06 06:44:51 | INFO | train | epoch 512 | loss 2.095 | nll_loss 0.325 | ppl 1.25 | wps 27687 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24914 | lr 0.000200345 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 58930
2022-03-06 06:44:51 | INFO | fairseq.trainer | begin training epoch 513
2022-03-06 06:44:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:46:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:46:44 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.492 | nll_loss 12.902 | ppl 7652.41 | wps 46481.2 | wpb 510.9 | bsz 1 | num_updates 24963 | best_loss 8.953
2022-03-06 06:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24963 updates
2022-03-06 06:46:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:46:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 513 @ 24963 updates, score 13.492) (writing took 1.705150787718594 seconds)
2022-03-06 06:46:46 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-06 06:46:46 | INFO | train | epoch 513 | loss 2.095 | nll_loss 0.326 | ppl 1.25 | wps 27701.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 24963 | lr 0.000200148 | gnorm 0.429 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59045
2022-03-06 06:46:46 | INFO | fairseq.trainer | begin training epoch 514
2022-03-06 06:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:47:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:48:11 | INFO | train_inner | epoch 514:     38 / 49 loss=2.095, nll_loss=0.326, ppl=1.25, wps=27458.4, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.426, loss_scale=32, train_wall=201, gb_free=21.6, wall=59130
2022-03-06 06:48:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:48:39 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.601 | nll_loss 13.016 | ppl 8283.47 | wps 46422.3 | wpb 510.9 | bsz 1 | num_updates 25011 | best_loss 8.953
2022-03-06 06:48:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25011 updates
2022-03-06 06:48:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:48:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:48:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 514 @ 25011 updates, score 13.601) (writing took 1.6455528791993856 seconds)
2022-03-06 06:48:41 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-06 06:48:41 | INFO | train | epoch 514 | loss 2.094 | nll_loss 0.325 | ppl 1.25 | wps 27093.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25011 | lr 0.000199956 | gnorm 0.424 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59159
2022-03-06 06:48:41 | INFO | fairseq.trainer | begin training epoch 515
2022-03-06 06:48:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:50:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:50:34 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.473 | nll_loss 12.88 | ppl 7539.34 | wps 46444.7 | wpb 510.9 | bsz 1 | num_updates 25060 | best_loss 8.953
2022-03-06 06:50:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25060 updates
2022-03-06 06:50:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:50:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:50:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 515 @ 25060 updates, score 13.473) (writing took 1.6906045423820615 seconds)
2022-03-06 06:50:36 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-06 06:50:36 | INFO | train | epoch 515 | loss 2.095 | nll_loss 0.326 | ppl 1.25 | wps 27645.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25060 | lr 0.00019976 | gnorm 0.428 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59274
2022-03-06 06:50:36 | INFO | fairseq.trainer | begin training epoch 516
2022-03-06 06:50:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:52:05 | INFO | train_inner | epoch 516:     40 / 49 loss=2.094, nll_loss=0.325, ppl=1.25, wps=27695.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.43, loss_scale=32, train_wall=199, gb_free=21.6, wall=59364
2022-03-06 06:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:52:29 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.569 | nll_loss 12.985 | ppl 8107.22 | wps 46391.5 | wpb 510.9 | bsz 1 | num_updates 25109 | best_loss 8.953
2022-03-06 06:52:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25109 updates
2022-03-06 06:52:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:52:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:52:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 516 @ 25109 updates, score 13.569) (writing took 1.698149487376213 seconds)
2022-03-06 06:52:31 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-06 06:52:31 | INFO | train | epoch 516 | loss 2.093 | nll_loss 0.325 | ppl 1.25 | wps 27668.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25109 | lr 0.000199565 | gnorm 0.43 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59389
2022-03-06 06:52:31 | INFO | fairseq.trainer | begin training epoch 517
2022-03-06 06:52:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:53:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:54:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:54:24 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.521 | nll_loss 12.93 | ppl 7806.35 | wps 46398.6 | wpb 510.9 | bsz 1 | num_updates 25157 | best_loss 8.953
2022-03-06 06:54:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25157 updates
2022-03-06 06:54:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:54:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:54:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 517 @ 25157 updates, score 13.521) (writing took 1.6988890068605542 seconds)
2022-03-06 06:54:26 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-06 06:54:26 | INFO | train | epoch 517 | loss 2.093 | nll_loss 0.324 | ppl 1.25 | wps 27072.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25157 | lr 0.000199375 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59504
2022-03-06 06:54:26 | INFO | fairseq.trainer | begin training epoch 518
2022-03-06 06:54:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:56:02 | INFO | train_inner | epoch 518:     43 / 49 loss=2.093, nll_loss=0.324, ppl=1.25, wps=27417.7, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.428, loss_scale=32, train_wall=201, gb_free=21.6, wall=59600
2022-03-06 06:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:56:19 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.609 | nll_loss 13.022 | ppl 8318.78 | wps 46403.8 | wpb 510.9 | bsz 1 | num_updates 25206 | best_loss 8.953
2022-03-06 06:56:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25206 updates
2022-03-06 06:56:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:56:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:56:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 518 @ 25206 updates, score 13.609) (writing took 1.6717044599354267 seconds)
2022-03-06 06:56:21 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-06 06:56:21 | INFO | train | epoch 518 | loss 2.093 | nll_loss 0.325 | ppl 1.25 | wps 27652.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25206 | lr 0.000199181 | gnorm 0.432 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59619
2022-03-06 06:56:21 | INFO | fairseq.trainer | begin training epoch 519
2022-03-06 06:56:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:58:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 06:58:14 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.574 | nll_loss 12.99 | ppl 8137.27 | wps 46437.2 | wpb 510.9 | bsz 1 | num_updates 25255 | best_loss 8.953
2022-03-06 06:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25255 updates
2022-03-06 06:58:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:58:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 06:58:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 519 @ 25255 updates, score 13.574) (writing took 1.6974710868671536 seconds)
2022-03-06 06:58:15 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-06 06:58:15 | INFO | train | epoch 519 | loss 2.092 | nll_loss 0.323 | ppl 1.25 | wps 27677.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25255 | lr 0.000198988 | gnorm 0.419 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 59734
2022-03-06 06:58:15 | INFO | fairseq.trainer | begin training epoch 520
2022-03-06 06:58:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 06:58:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 06:59:58 | INFO | train_inner | epoch 520:     46 / 49 loss=2.092, nll_loss=0.324, ppl=1.25, wps=27435.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.421, loss_scale=32, train_wall=201, gb_free=21.6, wall=59837
2022-03-06 07:00:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:00:09 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.605 | nll_loss 13.028 | ppl 8352.45 | wps 46288.6 | wpb 510.9 | bsz 1 | num_updates 25303 | best_loss 8.953
2022-03-06 07:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25303 updates
2022-03-06 07:00:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:00:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 520 @ 25303 updates, score 13.605) (writing took 1.6815848154947162 seconds)
2022-03-06 07:00:10 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-06 07:00:10 | INFO | train | epoch 520 | loss 2.092 | nll_loss 0.324 | ppl 1.25 | wps 27079.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25303 | lr 0.000198799 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59849
2022-03-06 07:00:10 | INFO | fairseq.trainer | begin training epoch 521
2022-03-06 07:00:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:01:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:02:04 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.512 | nll_loss 12.92 | ppl 7752.2 | wps 46297.9 | wpb 510.9 | bsz 1 | num_updates 25352 | best_loss 8.953
2022-03-06 07:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25352 updates
2022-03-06 07:02:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:02:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 521 @ 25352 updates, score 13.512) (writing took 1.626916740089655 seconds)
2022-03-06 07:02:05 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-06 07:02:05 | INFO | train | epoch 521 | loss 2.092 | nll_loss 0.324 | ppl 1.25 | wps 27653.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25352 | lr 0.000198607 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 59964
2022-03-06 07:02:05 | INFO | fairseq.trainer | begin training epoch 522
2022-03-06 07:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:03:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:03:54 | INFO | train_inner | epoch 522:     49 / 49 loss=2.092, nll_loss=0.324, ppl=1.25, wps=27412.9, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=25400, lr=0.000198419, gnorm=0.425, loss_scale=32, train_wall=200, gb_free=21.6, wall=60072
2022-03-06 07:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:03:58 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.439 | nll_loss 12.841 | ppl 7334.63 | wps 46526.5 | wpb 510.9 | bsz 1 | num_updates 25400 | best_loss 8.953
2022-03-06 07:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25400 updates
2022-03-06 07:03:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:04:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:04:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 522 @ 25400 updates, score 13.439) (writing took 1.7174617061391473 seconds)
2022-03-06 07:04:00 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-06 07:04:00 | INFO | train | epoch 522 | loss 2.092 | nll_loss 0.324 | ppl 1.25 | wps 27079.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25400 | lr 0.000198419 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60079
2022-03-06 07:04:00 | INFO | fairseq.trainer | begin training epoch 523
2022-03-06 07:04:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:05:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:05:53 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.455 | nll_loss 12.864 | ppl 7456.52 | wps 46320.5 | wpb 510.9 | bsz 1 | num_updates 25449 | best_loss 8.953
2022-03-06 07:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25449 updates
2022-03-06 07:05:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:05:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:05:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 523 @ 25449 updates, score 13.455) (writing took 1.6544940806925297 seconds)
2022-03-06 07:05:55 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-06 07:05:55 | INFO | train | epoch 523 | loss 2.092 | nll_loss 0.323 | ppl 1.25 | wps 27658.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25449 | lr 0.000198228 | gnorm 0.426 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60194
2022-03-06 07:05:55 | INFO | fairseq.trainer | begin training epoch 524
2022-03-06 07:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:07:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:07:48 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.494 | nll_loss 12.901 | ppl 7647.68 | wps 46460.4 | wpb 510.9 | bsz 1 | num_updates 25498 | best_loss 8.953
2022-03-06 07:07:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25498 updates
2022-03-06 07:07:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:07:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:07:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 524 @ 25498 updates, score 13.494) (writing took 1.690168710425496 seconds)
2022-03-06 07:07:50 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-06 07:07:50 | INFO | train | epoch 524 | loss 2.091 | nll_loss 0.323 | ppl 1.25 | wps 27655.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25498 | lr 0.000198037 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60309
2022-03-06 07:07:50 | INFO | fairseq.trainer | begin training epoch 525
2022-03-06 07:07:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:07:55 | INFO | train_inner | epoch 525:      2 / 49 loss=2.091, nll_loss=0.323, ppl=1.25, wps=26937.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.422, loss_scale=32, train_wall=199, gb_free=21.6, wall=60313
2022-03-06 07:08:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:09:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:09:43 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.548 | nll_loss 12.959 | ppl 7961.07 | wps 46178.1 | wpb 510.9 | bsz 1 | num_updates 25546 | best_loss 8.953
2022-03-06 07:09:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25546 updates
2022-03-06 07:09:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:09:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:09:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 525 @ 25546 updates, score 13.548) (writing took 1.6697384910658002 seconds)
2022-03-06 07:09:45 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-06 07:09:45 | INFO | train | epoch 525 | loss 2.091 | nll_loss 0.323 | ppl 1.25 | wps 27084.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25546 | lr 0.000197851 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60424
2022-03-06 07:09:45 | INFO | fairseq.trainer | begin training epoch 526
2022-03-06 07:09:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:11:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:11:38 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.566 | nll_loss 12.977 | ppl 8061.41 | wps 46237.6 | wpb 510.9 | bsz 1 | num_updates 25595 | best_loss 8.953
2022-03-06 07:11:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25595 updates
2022-03-06 07:11:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:11:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 526 @ 25595 updates, score 13.566) (writing took 1.700289024040103 seconds)
2022-03-06 07:11:40 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-06 07:11:40 | INFO | train | epoch 526 | loss 2.09 | nll_loss 0.322 | ppl 1.25 | wps 27637.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25595 | lr 0.000197662 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60539
2022-03-06 07:11:40 | INFO | fairseq.trainer | begin training epoch 527
2022-03-06 07:11:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:11:51 | INFO | train_inner | epoch 527:      5 / 49 loss=2.09, nll_loss=0.322, ppl=1.25, wps=27414.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.426, loss_scale=32, train_wall=201, gb_free=21.6, wall=60550
2022-03-06 07:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:13:33 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.516 | nll_loss 12.931 | ppl 7808.56 | wps 46364 | wpb 510.9 | bsz 1 | num_updates 25644 | best_loss 8.953
2022-03-06 07:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25644 updates
2022-03-06 07:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:13:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:13:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 527 @ 25644 updates, score 13.516) (writing took 1.6998373474925756 seconds)
2022-03-06 07:13:35 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-06 07:13:35 | INFO | train | epoch 527 | loss 2.09 | nll_loss 0.322 | ppl 1.25 | wps 27662.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25644 | lr 0.000197473 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60653
2022-03-06 07:13:35 | INFO | fairseq.trainer | begin training epoch 528
2022-03-06 07:13:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:14:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:15:28 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.529 | nll_loss 12.942 | ppl 7867.94 | wps 46120.3 | wpb 510.9 | bsz 1 | num_updates 25692 | best_loss 8.953
2022-03-06 07:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25692 updates
2022-03-06 07:15:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 528 @ 25692 updates, score 13.529) (writing took 1.6837380565702915 seconds)
2022-03-06 07:15:30 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-06 07:15:30 | INFO | train | epoch 528 | loss 2.089 | nll_loss 0.321 | ppl 1.25 | wps 27070.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25692 | lr 0.000197288 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60768
2022-03-06 07:15:30 | INFO | fairseq.trainer | begin training epoch 529
2022-03-06 07:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:15:48 | INFO | train_inner | epoch 529:      8 / 49 loss=2.089, nll_loss=0.322, ppl=1.25, wps=27419.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.423, loss_scale=32, train_wall=201, gb_free=21.6, wall=60786
2022-03-06 07:17:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:17:23 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.533 | nll_loss 12.947 | ppl 7897 | wps 46280.7 | wpb 510.9 | bsz 1 | num_updates 25741 | best_loss 8.953
2022-03-06 07:17:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25741 updates
2022-03-06 07:17:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 529 @ 25741 updates, score 13.533) (writing took 1.6566637391224504 seconds)
2022-03-06 07:17:25 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-06 07:17:25 | INFO | train | epoch 529 | loss 2.089 | nll_loss 0.321 | ppl 1.25 | wps 27675.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25741 | lr 0.0001971 | gnorm 0.421 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 60883
2022-03-06 07:17:25 | INFO | fairseq.trainer | begin training epoch 530
2022-03-06 07:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:19:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:19:18 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.427 | nll_loss 12.83 | ppl 7283.27 | wps 46248.1 | wpb 510.9 | bsz 1 | num_updates 25790 | best_loss 8.953
2022-03-06 07:19:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25790 updates
2022-03-06 07:19:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:19:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 530 @ 25790 updates, score 13.427) (writing took 1.6676761573180556 seconds)
2022-03-06 07:19:20 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-06 07:19:20 | INFO | train | epoch 530 | loss 2.089 | nll_loss 0.322 | ppl 1.25 | wps 27653.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25790 | lr 0.000196913 | gnorm 0.428 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 60998
2022-03-06 07:19:20 | INFO | fairseq.trainer | begin training epoch 531
2022-03-06 07:19:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:19:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:19:44 | INFO | train_inner | epoch 531:     11 / 49 loss=2.089, nll_loss=0.321, ppl=1.25, wps=27438.8, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.425, loss_scale=32, train_wall=201, gb_free=21.6, wall=61023
2022-03-06 07:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:21:13 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.362 | nll_loss 12.765 | ppl 6959.19 | wps 46495.9 | wpb 510.9 | bsz 1 | num_updates 25838 | best_loss 8.953
2022-03-06 07:21:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25838 updates
2022-03-06 07:21:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:21:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:21:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 531 @ 25838 updates, score 13.362) (writing took 1.6403195597231388 seconds)
2022-03-06 07:21:14 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-06 07:21:14 | INFO | train | epoch 531 | loss 2.089 | nll_loss 0.321 | ppl 1.25 | wps 27117.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25838 | lr 0.00019673 | gnorm 0.425 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61113
2022-03-06 07:21:14 | INFO | fairseq.trainer | begin training epoch 532
2022-03-06 07:21:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:23:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:23:07 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.591 | nll_loss 13.014 | ppl 8269.89 | wps 46397.3 | wpb 510.9 | bsz 1 | num_updates 25887 | best_loss 8.953
2022-03-06 07:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25887 updates
2022-03-06 07:23:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 532 @ 25887 updates, score 13.591) (writing took 1.723751038312912 seconds)
2022-03-06 07:23:09 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-06 07:23:09 | INFO | train | epoch 532 | loss 2.088 | nll_loss 0.321 | ppl 1.25 | wps 27670.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25887 | lr 0.000196544 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61228
2022-03-06 07:23:09 | INFO | fairseq.trainer | begin training epoch 533
2022-03-06 07:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:23:38 | INFO | train_inner | epoch 533:     13 / 49 loss=2.088, nll_loss=0.321, ppl=1.25, wps=27711.3, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.42, loss_scale=32, train_wall=199, gb_free=21.6, wall=61257
2022-03-06 07:24:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:25:02 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.531 | nll_loss 12.946 | ppl 7893.13 | wps 46474.4 | wpb 510.9 | bsz 1 | num_updates 25935 | best_loss 8.953
2022-03-06 07:25:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25935 updates
2022-03-06 07:25:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:25:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:25:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 533 @ 25935 updates, score 13.531) (writing took 1.6816798225045204 seconds)
2022-03-06 07:25:04 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-06 07:25:04 | INFO | train | epoch 533 | loss 2.088 | nll_loss 0.321 | ppl 1.25 | wps 27124.9 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 25935 | lr 0.000196362 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61343
2022-03-06 07:25:04 | INFO | fairseq.trainer | begin training epoch 534
2022-03-06 07:25:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:26:57 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.476 | nll_loss 12.885 | ppl 7561.89 | wps 46414.7 | wpb 510.9 | bsz 1 | num_updates 25984 | best_loss 8.953
2022-03-06 07:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25984 updates
2022-03-06 07:26:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 534 @ 25984 updates, score 13.476) (writing took 1.6971578486263752 seconds)
2022-03-06 07:26:59 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-06 07:26:59 | INFO | train | epoch 534 | loss 2.088 | nll_loss 0.321 | ppl 1.25 | wps 27665.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 25984 | lr 0.000196177 | gnorm 0.431 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61457
2022-03-06 07:26:59 | INFO | fairseq.trainer | begin training epoch 535
2022-03-06 07:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:27:35 | INFO | train_inner | epoch 535:     16 / 49 loss=2.088, nll_loss=0.321, ppl=1.25, wps=27446.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.43, loss_scale=32, train_wall=201, gb_free=21.6, wall=61493
2022-03-06 07:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:28:52 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.552 | nll_loss 12.965 | ppl 7995.94 | wps 46407.1 | wpb 510.9 | bsz 1 | num_updates 26033 | best_loss 8.953
2022-03-06 07:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26033 updates
2022-03-06 07:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 535 @ 26033 updates, score 13.552) (writing took 1.6772614754736423 seconds)
2022-03-06 07:28:54 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-06 07:28:54 | INFO | train | epoch 535 | loss 2.086 | nll_loss 0.319 | ppl 1.25 | wps 27641.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26033 | lr 0.000195992 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61572
2022-03-06 07:28:54 | INFO | fairseq.trainer | begin training epoch 536
2022-03-06 07:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:30:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:30:47 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.561 | nll_loss 12.978 | ppl 8066.53 | wps 46334.4 | wpb 510.9 | bsz 1 | num_updates 26081 | best_loss 8.953
2022-03-06 07:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26081 updates
2022-03-06 07:30:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 536 @ 26081 updates, score 13.561) (writing took 1.7499489253386855 seconds)
2022-03-06 07:30:49 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-06 07:30:49 | INFO | train | epoch 536 | loss 2.086 | nll_loss 0.319 | ppl 1.25 | wps 27098 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26081 | lr 0.000195811 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61687
2022-03-06 07:30:49 | INFO | fairseq.trainer | begin training epoch 537
2022-03-06 07:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:31:31 | INFO | train_inner | epoch 537:     19 / 49 loss=2.086, nll_loss=0.319, ppl=1.25, wps=27422.2, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.417, loss_scale=32, train_wall=201, gb_free=21.6, wall=61730
2022-03-06 07:32:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:32:42 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.465 | nll_loss 12.876 | ppl 7515.27 | wps 46444.1 | wpb 510.9 | bsz 1 | num_updates 26130 | best_loss 8.953
2022-03-06 07:32:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26130 updates
2022-03-06 07:32:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:32:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:32:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 537 @ 26130 updates, score 13.465) (writing took 1.7012301925569773 seconds)
2022-03-06 07:32:44 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-06 07:32:44 | INFO | train | epoch 537 | loss 2.086 | nll_loss 0.319 | ppl 1.25 | wps 27649.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26130 | lr 0.000195628 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61802
2022-03-06 07:32:44 | INFO | fairseq.trainer | begin training epoch 538
2022-03-06 07:32:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:34:37 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.512 | nll_loss 12.925 | ppl 7777.67 | wps 46365.6 | wpb 510.9 | bsz 1 | num_updates 26179 | best_loss 8.953
2022-03-06 07:34:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26179 updates
2022-03-06 07:34:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:34:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:34:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 538 @ 26179 updates, score 13.512) (writing took 1.6936438493430614 seconds)
2022-03-06 07:34:39 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-06 07:34:39 | INFO | train | epoch 538 | loss 2.086 | nll_loss 0.319 | ppl 1.25 | wps 27645.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26179 | lr 0.000195445 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 61917
2022-03-06 07:34:39 | INFO | fairseq.trainer | begin training epoch 539
2022-03-06 07:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:35:26 | INFO | train_inner | epoch 539:     21 / 49 loss=2.086, nll_loss=0.319, ppl=1.25, wps=27683.8, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.417, loss_scale=64, train_wall=199, gb_free=21.6, wall=61964
2022-03-06 07:35:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:36:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:36:32 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.532 | nll_loss 12.944 | ppl 7881.28 | wps 46437.1 | wpb 510.9 | bsz 1 | num_updates 26227 | best_loss 8.953
2022-03-06 07:36:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26227 updates
2022-03-06 07:36:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:36:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:36:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 539 @ 26227 updates, score 13.532) (writing took 1.6980407685041428 seconds)
2022-03-06 07:36:33 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-06 07:36:33 | INFO | train | epoch 539 | loss 2.086 | nll_loss 0.32 | ppl 1.25 | wps 27100.2 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26227 | lr 0.000195266 | gnorm 0.423 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62032
2022-03-06 07:36:33 | INFO | fairseq.trainer | begin training epoch 540
2022-03-06 07:36:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:38:27 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.574 | nll_loss 12.984 | ppl 8102.69 | wps 46339.8 | wpb 510.9 | bsz 1 | num_updates 26276 | best_loss 8.953
2022-03-06 07:38:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26276 updates
2022-03-06 07:38:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:38:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 540 @ 26276 updates, score 13.574) (writing took 1.717781743966043 seconds)
2022-03-06 07:38:28 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-06 07:38:28 | INFO | train | epoch 540 | loss 2.085 | nll_loss 0.319 | ppl 1.25 | wps 27660.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26276 | lr 0.000195083 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62147
2022-03-06 07:38:28 | INFO | fairseq.trainer | begin training epoch 541
2022-03-06 07:38:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:39:22 | INFO | train_inner | epoch 541:     24 / 49 loss=2.086, nll_loss=0.319, ppl=1.25, wps=27436.6, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.419, loss_scale=32, train_wall=201, gb_free=21.6, wall=62201
2022-03-06 07:40:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:40:21 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.475 | nll_loss 12.883 | ppl 7554.18 | wps 46416.9 | wpb 510.9 | bsz 1 | num_updates 26325 | best_loss 8.953
2022-03-06 07:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26325 updates
2022-03-06 07:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:40:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:40:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 541 @ 26325 updates, score 13.475) (writing took 1.6901061171665788 seconds)
2022-03-06 07:40:23 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-06 07:40:23 | INFO | train | epoch 541 | loss 2.085 | nll_loss 0.319 | ppl 1.25 | wps 27658.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26325 | lr 0.000194902 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62262
2022-03-06 07:40:23 | INFO | fairseq.trainer | begin training epoch 542
2022-03-06 07:40:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:40:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:42:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:42:16 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.492 | nll_loss 12.904 | ppl 7665.4 | wps 46509.1 | wpb 510.9 | bsz 1 | num_updates 26373 | best_loss 8.953
2022-03-06 07:42:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26373 updates
2022-03-06 07:42:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:42:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:42:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 542 @ 26373 updates, score 13.492) (writing took 1.7020836900919676 seconds)
2022-03-06 07:42:18 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-06 07:42:18 | INFO | train | epoch 542 | loss 2.084 | nll_loss 0.318 | ppl 1.25 | wps 27077 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26373 | lr 0.000194724 | gnorm 0.421 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62377
2022-03-06 07:42:18 | INFO | fairseq.trainer | begin training epoch 543
2022-03-06 07:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:43:19 | INFO | train_inner | epoch 543:     27 / 49 loss=2.085, nll_loss=0.318, ppl=1.25, wps=27427, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.42, loss_scale=32, train_wall=201, gb_free=21.6, wall=62437
2022-03-06 07:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:44:11 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.614 | nll_loss 13.032 | ppl 8376.83 | wps 46296.5 | wpb 510.9 | bsz 1 | num_updates 26422 | best_loss 8.953
2022-03-06 07:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26422 updates
2022-03-06 07:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:44:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:44:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 543 @ 26422 updates, score 13.614) (writing took 1.7243900429457426 seconds)
2022-03-06 07:44:13 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-06 07:44:13 | INFO | train | epoch 543 | loss 2.085 | nll_loss 0.319 | ppl 1.25 | wps 27671.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26422 | lr 0.000194544 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62492
2022-03-06 07:44:13 | INFO | fairseq.trainer | begin training epoch 544
2022-03-06 07:44:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:46:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:46:06 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.427 | nll_loss 12.831 | ppl 7287.63 | wps 46703.2 | wpb 510.9 | bsz 1 | num_updates 26471 | best_loss 8.953
2022-03-06 07:46:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26471 updates
2022-03-06 07:46:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:46:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:46:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 544 @ 26471 updates, score 13.427) (writing took 1.7730711791664362 seconds)
2022-03-06 07:46:08 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-06 07:46:08 | INFO | train | epoch 544 | loss 2.084 | nll_loss 0.318 | ppl 1.25 | wps 27626.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26471 | lr 0.000194364 | gnorm 0.418 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 62607
2022-03-06 07:46:08 | INFO | fairseq.trainer | begin training epoch 545
2022-03-06 07:46:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:46:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:47:15 | INFO | train_inner | epoch 545:     30 / 49 loss=2.085, nll_loss=0.318, ppl=1.25, wps=27420.4, ups=0.42, wpb=64876.2, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.419, loss_scale=32, train_wall=201, gb_free=21.6, wall=62674
2022-03-06 07:47:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:48:01 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.629 | nll_loss 13.052 | ppl 8492.27 | wps 46344.5 | wpb 510.9 | bsz 1 | num_updates 26519 | best_loss 8.953
2022-03-06 07:48:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26519 updates
2022-03-06 07:48:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:48:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:48:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 545 @ 26519 updates, score 13.629) (writing took 1.7193742766976357 seconds)
2022-03-06 07:48:03 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-06 07:48:03 | INFO | train | epoch 545 | loss 2.084 | nll_loss 0.317 | ppl 1.25 | wps 27025.7 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26519 | lr 0.000194188 | gnorm 0.417 | loss_scale 32 | train_wall 98 | gb_free 21.6 | wall 62722
2022-03-06 07:48:03 | INFO | fairseq.trainer | begin training epoch 546
2022-03-06 07:48:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:49:56 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.489 | nll_loss 12.898 | ppl 7633.09 | wps 46567.4 | wpb 510.9 | bsz 1 | num_updates 26568 | best_loss 8.953
2022-03-06 07:49:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26568 updates
2022-03-06 07:49:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:49:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:49:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 546 @ 26568 updates, score 13.489) (writing took 1.745122934691608 seconds)
2022-03-06 07:49:58 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-06 07:49:58 | INFO | train | epoch 546 | loss 2.084 | nll_loss 0.318 | ppl 1.25 | wps 27671.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26568 | lr 0.000194008 | gnorm 0.422 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62837
2022-03-06 07:49:58 | INFO | fairseq.trainer | begin training epoch 547
2022-03-06 07:49:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:51:10 | INFO | train_inner | epoch 547:     32 / 49 loss=2.084, nll_loss=0.317, ppl=1.25, wps=27661, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.418, loss_scale=32, train_wall=199, gb_free=21.6, wall=62908
2022-03-06 07:51:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:51:51 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.517 | nll_loss 12.931 | ppl 7806.8 | wps 46415.2 | wpb 510.9 | bsz 1 | num_updates 26616 | best_loss 8.953
2022-03-06 07:51:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26616 updates
2022-03-06 07:51:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:51:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 547 @ 26616 updates, score 13.517) (writing took 1.6750388694927096 seconds)
2022-03-06 07:51:53 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-06 07:51:53 | INFO | train | epoch 547 | loss 2.083 | nll_loss 0.317 | ppl 1.25 | wps 27092.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26616 | lr 0.000193833 | gnorm 0.412 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 62952
2022-03-06 07:51:53 | INFO | fairseq.trainer | begin training epoch 548
2022-03-06 07:51:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:53:46 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.502 | nll_loss 12.912 | ppl 7706 | wps 46339.3 | wpb 510.9 | bsz 1 | num_updates 26665 | best_loss 8.953
2022-03-06 07:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26665 updates
2022-03-06 07:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 548 @ 26665 updates, score 13.502) (writing took 1.7347437953576446 seconds)
2022-03-06 07:53:48 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-06 07:53:48 | INFO | train | epoch 548 | loss 2.083 | nll_loss 0.317 | ppl 1.25 | wps 27646.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26665 | lr 0.000193655 | gnorm 0.421 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63066
2022-03-06 07:53:48 | INFO | fairseq.trainer | begin training epoch 549
2022-03-06 07:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:55:06 | INFO | train_inner | epoch 549:     35 / 49 loss=2.083, nll_loss=0.317, ppl=1.25, wps=27421.9, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.419, loss_scale=32, train_wall=201, gb_free=21.6, wall=63145
2022-03-06 07:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:55:41 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.664 | nll_loss 13.088 | ppl 8706.51 | wps 46577.6 | wpb 510.9 | bsz 1 | num_updates 26714 | best_loss 8.953
2022-03-06 07:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26714 updates
2022-03-06 07:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:55:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 549 @ 26714 updates, score 13.664) (writing took 1.7040722025558352 seconds)
2022-03-06 07:55:43 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-06 07:55:43 | INFO | train | epoch 549 | loss 2.083 | nll_loss 0.317 | ppl 1.25 | wps 27662.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26714 | lr 0.000193478 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63181
2022-03-06 07:55:43 | INFO | fairseq.trainer | begin training epoch 550
2022-03-06 07:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:56:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 07:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:57:36 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.531 | nll_loss 12.942 | ppl 7867.97 | wps 46193.9 | wpb 510.9 | bsz 1 | num_updates 26762 | best_loss 8.953
2022-03-06 07:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26762 updates
2022-03-06 07:57:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 550 @ 26762 updates, score 13.531) (writing took 1.7140717636793852 seconds)
2022-03-06 07:57:38 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-06 07:57:38 | INFO | train | epoch 550 | loss 2.082 | nll_loss 0.316 | ppl 1.25 | wps 27072.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26762 | lr 0.000193304 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63296
2022-03-06 07:57:38 | INFO | fairseq.trainer | begin training epoch 551
2022-03-06 07:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 07:59:03 | INFO | train_inner | epoch 551:     38 / 49 loss=2.082, nll_loss=0.317, ppl=1.25, wps=27433.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.42, loss_scale=32, train_wall=201, gb_free=21.6, wall=63381
2022-03-06 07:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 07:59:31 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.526 | nll_loss 12.942 | ppl 7867.85 | wps 46286.6 | wpb 510.9 | bsz 1 | num_updates 26811 | best_loss 8.953
2022-03-06 07:59:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26811 updates
2022-03-06 07:59:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:59:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 07:59:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 551 @ 26811 updates, score 13.526) (writing took 1.7443806575611234 seconds)
2022-03-06 07:59:33 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-06 07:59:33 | INFO | train | epoch 551 | loss 2.082 | nll_loss 0.317 | ppl 1.25 | wps 27643.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26811 | lr 0.000193127 | gnorm 0.427 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63411
2022-03-06 07:59:33 | INFO | fairseq.trainer | begin training epoch 552
2022-03-06 07:59:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:01:26 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.488 | nll_loss 12.897 | ppl 7626.35 | wps 46332.4 | wpb 510.9 | bsz 1 | num_updates 26860 | best_loss 8.953
2022-03-06 08:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26860 updates
2022-03-06 08:01:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:01:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 552 @ 26860 updates, score 13.488) (writing took 1.7111666463315487 seconds)
2022-03-06 08:01:28 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-06 08:01:28 | INFO | train | epoch 552 | loss 2.082 | nll_loss 0.316 | ppl 1.25 | wps 27649.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26860 | lr 0.000192951 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63526
2022-03-06 08:01:28 | INFO | fairseq.trainer | begin training epoch 553
2022-03-06 08:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:01:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:02:59 | INFO | train_inner | epoch 553:     41 / 49 loss=2.082, nll_loss=0.317, ppl=1.25, wps=27414.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.419, loss_scale=32, train_wall=201, gb_free=21.6, wall=63618
2022-03-06 08:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:03:21 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.457 | nll_loss 12.865 | ppl 7460.6 | wps 46499.1 | wpb 510.9 | bsz 1 | num_updates 26908 | best_loss 8.953
2022-03-06 08:03:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26908 updates
2022-03-06 08:03:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:03:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:03:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 553 @ 26908 updates, score 13.457) (writing took 1.7607754888013005 seconds)
2022-03-06 08:03:23 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-06 08:03:23 | INFO | train | epoch 553 | loss 2.082 | nll_loss 0.316 | ppl 1.25 | wps 27084 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 26908 | lr 0.000192779 | gnorm 0.42 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63641
2022-03-06 08:03:23 | INFO | fairseq.trainer | begin training epoch 554
2022-03-06 08:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:05:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:05:16 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.506 | nll_loss 12.919 | ppl 7743.71 | wps 46335.5 | wpb 510.9 | bsz 1 | num_updates 26957 | best_loss 8.953
2022-03-06 08:05:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26957 updates
2022-03-06 08:05:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:05:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:05:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 554 @ 26957 updates, score 13.506) (writing took 1.759493663907051 seconds)
2022-03-06 08:05:17 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-06 08:05:17 | INFO | train | epoch 554 | loss 2.081 | nll_loss 0.315 | ppl 1.24 | wps 27655.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 26957 | lr 0.000192604 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63756
2022-03-06 08:05:17 | INFO | fairseq.trainer | begin training epoch 555
2022-03-06 08:05:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:06:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:06:56 | INFO | train_inner | epoch 555:     44 / 49 loss=2.081, nll_loss=0.315, ppl=1.24, wps=27419.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.416, loss_scale=32, train_wall=201, gb_free=21.6, wall=63855
2022-03-06 08:07:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:07:11 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.663 | nll_loss 13.087 | ppl 8701.16 | wps 46304.2 | wpb 510.9 | bsz 1 | num_updates 27005 | best_loss 8.953
2022-03-06 08:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27005 updates
2022-03-06 08:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:07:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 555 @ 27005 updates, score 13.663) (writing took 1.7389166122302413 seconds)
2022-03-06 08:07:12 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-06 08:07:12 | INFO | train | epoch 555 | loss 2.081 | nll_loss 0.316 | ppl 1.24 | wps 27071.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27005 | lr 0.000192432 | gnorm 0.417 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63871
2022-03-06 08:07:12 | INFO | fairseq.trainer | begin training epoch 556
2022-03-06 08:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:09:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:09:06 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.414 | nll_loss 12.817 | ppl 7217.15 | wps 46445.8 | wpb 510.9 | bsz 1 | num_updates 27054 | best_loss 8.953
2022-03-06 08:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27054 updates
2022-03-06 08:09:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 556 @ 27054 updates, score 13.414) (writing took 1.7302722819149494 seconds)
2022-03-06 08:09:07 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-06 08:09:07 | INFO | train | epoch 556 | loss 2.08 | nll_loss 0.315 | ppl 1.24 | wps 27651.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27054 | lr 0.000192258 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 63986
2022-03-06 08:09:07 | INFO | fairseq.trainer | begin training epoch 557
2022-03-06 08:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:10:50 | INFO | train_inner | epoch 557:     46 / 49 loss=2.08, nll_loss=0.315, ppl=1.24, wps=27679.6, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27100, lr=0.000192095, gnorm=0.415, loss_scale=32, train_wall=199, gb_free=21.6, wall=64089
2022-03-06 08:10:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:11:01 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.534 | nll_loss 12.951 | ppl 7918.74 | wps 46543.5 | wpb 510.9 | bsz 1 | num_updates 27103 | best_loss 8.953
2022-03-06 08:11:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27103 updates
2022-03-06 08:11:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:11:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:11:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 557 @ 27103 updates, score 13.534) (writing took 1.6979389302432537 seconds)
2022-03-06 08:11:02 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-06 08:11:02 | INFO | train | epoch 557 | loss 2.079 | nll_loss 0.314 | ppl 1.24 | wps 27657.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27103 | lr 0.000192084 | gnorm 0.409 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64101
2022-03-06 08:11:02 | INFO | fairseq.trainer | begin training epoch 558
2022-03-06 08:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:12:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:12:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:12:55 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.547 | nll_loss 12.965 | ppl 7997.56 | wps 46538.3 | wpb 510.9 | bsz 1 | num_updates 27151 | best_loss 8.953
2022-03-06 08:12:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27151 updates
2022-03-06 08:12:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 558 @ 27151 updates, score 13.547) (writing took 1.773764006793499 seconds)
2022-03-06 08:12:57 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-06 08:12:57 | INFO | train | epoch 558 | loss 2.08 | nll_loss 0.315 | ppl 1.24 | wps 27109.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27151 | lr 0.000191914 | gnorm 0.415 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64216
2022-03-06 08:12:57 | INFO | fairseq.trainer | begin training epoch 559
2022-03-06 08:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:14:46 | INFO | train_inner | epoch 559:     49 / 49 loss=2.08, nll_loss=0.315, ppl=1.24, wps=27425, ups=0.42, wpb=64544.1, bsz=126.1, num_updates=27200, lr=0.000191741, gnorm=0.415, loss_scale=32, train_wall=200, gb_free=21.6, wall=64324
2022-03-06 08:14:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:14:50 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.614 | nll_loss 13.037 | ppl 8406.29 | wps 46469.2 | wpb 510.9 | bsz 1 | num_updates 27200 | best_loss 8.953
2022-03-06 08:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27200 updates
2022-03-06 08:14:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 559 @ 27200 updates, score 13.614) (writing took 1.739350350573659 seconds)
2022-03-06 08:14:52 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-06 08:14:52 | INFO | train | epoch 559 | loss 2.079 | nll_loss 0.314 | ppl 1.24 | wps 27639.3 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27200 | lr 0.000191741 | gnorm 0.413 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64331
2022-03-06 08:14:52 | INFO | fairseq.trainer | begin training epoch 560
2022-03-06 08:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:16:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:16:45 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.595 | nll_loss 13.012 | ppl 8262.3 | wps 46149.5 | wpb 510.9 | bsz 1 | num_updates 27249 | best_loss 8.953
2022-03-06 08:16:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27249 updates
2022-03-06 08:16:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 560 @ 27249 updates, score 13.595) (writing took 1.7116218116134405 seconds)
2022-03-06 08:16:47 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-06 08:16:47 | INFO | train | epoch 560 | loss 2.079 | nll_loss 0.315 | ppl 1.24 | wps 27634.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27249 | lr 0.000191569 | gnorm 0.413 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64446
2022-03-06 08:16:47 | INFO | fairseq.trainer | begin training epoch 561
2022-03-06 08:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:17:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:18:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:18:40 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.595 | nll_loss 13.015 | ppl 8279.75 | wps 46139.7 | wpb 510.9 | bsz 1 | num_updates 27297 | best_loss 8.953
2022-03-06 08:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27297 updates
2022-03-06 08:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 561 @ 27297 updates, score 13.595) (writing took 1.6924695828929543 seconds)
2022-03-06 08:18:42 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-06 08:18:42 | INFO | train | epoch 561 | loss 2.079 | nll_loss 0.314 | ppl 1.24 | wps 27083.4 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27297 | lr 0.0001914 | gnorm 0.419 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64561
2022-03-06 08:18:42 | INFO | fairseq.trainer | begin training epoch 562
2022-03-06 08:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:18:49 | INFO | train_inner | epoch 562:      3 / 49 loss=2.079, nll_loss=0.314, ppl=1.24, wps=26666.3, ups=0.41, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.416, loss_scale=32, train_wall=201, gb_free=21.6, wall=64567
2022-03-06 08:20:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:20:35 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.485 | nll_loss 12.899 | ppl 7636.63 | wps 46399.9 | wpb 510.9 | bsz 1 | num_updates 27346 | best_loss 8.953
2022-03-06 08:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27346 updates
2022-03-06 08:20:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 562 @ 27346 updates, score 13.485) (writing took 1.6906719291582704 seconds)
2022-03-06 08:20:37 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-06 08:20:37 | INFO | train | epoch 562 | loss 2.078 | nll_loss 0.313 | ppl 1.24 | wps 27642.7 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27346 | lr 0.000191229 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64676
2022-03-06 08:20:37 | INFO | fairseq.trainer | begin training epoch 563
2022-03-06 08:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:22:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:22:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:22:30 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.516 | nll_loss 12.929 | ppl 7797.66 | wps 46355.3 | wpb 510.9 | bsz 1 | num_updates 27394 | best_loss 8.953
2022-03-06 08:22:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27394 updates
2022-03-06 08:22:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:22:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:22:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 563 @ 27394 updates, score 13.516) (writing took 1.7142655244097114 seconds)
2022-03-06 08:22:32 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-06 08:22:32 | INFO | train | epoch 563 | loss 2.078 | nll_loss 0.314 | ppl 1.24 | wps 27091.3 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27394 | lr 0.000191061 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64790
2022-03-06 08:22:32 | INFO | fairseq.trainer | begin training epoch 564
2022-03-06 08:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:22:45 | INFO | train_inner | epoch 564:      6 / 49 loss=2.078, nll_loss=0.314, ppl=1.24, wps=27422.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.41, loss_scale=32, train_wall=201, gb_free=21.6, wall=64804
2022-03-06 08:24:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:24:25 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.519 | nll_loss 12.93 | ppl 7804.77 | wps 46359.2 | wpb 510.9 | bsz 1 | num_updates 27443 | best_loss 8.953
2022-03-06 08:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27443 updates
2022-03-06 08:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:24:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:24:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 564 @ 27443 updates, score 13.519) (writing took 1.7054128367453814 seconds)
2022-03-06 08:24:27 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-06 08:24:27 | INFO | train | epoch 564 | loss 2.078 | nll_loss 0.313 | ppl 1.24 | wps 27656.5 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27443 | lr 0.00019089 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 64905
2022-03-06 08:24:27 | INFO | fairseq.trainer | begin training epoch 565
2022-03-06 08:24:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:26:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:26:20 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.515 | nll_loss 12.929 | ppl 7798.06 | wps 46251.6 | wpb 510.9 | bsz 1 | num_updates 27492 | best_loss 8.953
2022-03-06 08:26:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27492 updates
2022-03-06 08:26:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:26:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:26:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 565 @ 27492 updates, score 13.515) (writing took 1.7093866458162665 seconds)
2022-03-06 08:26:22 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-06 08:26:22 | INFO | train | epoch 565 | loss 2.078 | nll_loss 0.313 | ppl 1.24 | wps 27627.6 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27492 | lr 0.00019072 | gnorm 0.405 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65020
2022-03-06 08:26:22 | INFO | fairseq.trainer | begin training epoch 566
2022-03-06 08:26:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:26:40 | INFO | train_inner | epoch 566:      8 / 49 loss=2.078, nll_loss=0.313, ppl=1.24, wps=27673.7, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.409, loss_scale=32, train_wall=199, gb_free=21.6, wall=65038
2022-03-06 08:27:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:28:15 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.459 | nll_loss 12.869 | ppl 7481.48 | wps 46186.3 | wpb 510.9 | bsz 1 | num_updates 27540 | best_loss 8.953
2022-03-06 08:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27540 updates
2022-03-06 08:28:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:28:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 566 @ 27540 updates, score 13.459) (writing took 1.7173116086050868 seconds)
2022-03-06 08:28:17 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-06 08:28:17 | INFO | train | epoch 566 | loss 2.077 | nll_loss 0.313 | ppl 1.24 | wps 27047.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27540 | lr 0.000190554 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65136
2022-03-06 08:28:17 | INFO | fairseq.trainer | begin training epoch 567
2022-03-06 08:28:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:30:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:30:10 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.505 | nll_loss 12.915 | ppl 7723.58 | wps 46323.2 | wpb 510.9 | bsz 1 | num_updates 27589 | best_loss 8.953
2022-03-06 08:30:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27589 updates
2022-03-06 08:30:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:30:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:30:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 567 @ 27589 updates, score 13.505) (writing took 1.7657115245237947 seconds)
2022-03-06 08:30:12 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-06 08:30:12 | INFO | train | epoch 567 | loss 2.077 | nll_loss 0.313 | ppl 1.24 | wps 27633.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27589 | lr 0.000190385 | gnorm 0.412 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65251
2022-03-06 08:30:12 | INFO | fairseq.trainer | begin training epoch 568
2022-03-06 08:30:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:30:37 | INFO | train_inner | epoch 568:     11 / 49 loss=2.077, nll_loss=0.313, ppl=1.24, wps=27394.6, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.411, loss_scale=32, train_wall=201, gb_free=21.6, wall=65275
2022-03-06 08:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:32:05 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.536 | nll_loss 12.953 | ppl 7929.92 | wps 46411.8 | wpb 510.9 | bsz 1 | num_updates 27638 | best_loss 8.953
2022-03-06 08:32:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27638 updates
2022-03-06 08:32:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:32:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:32:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 568 @ 27638 updates, score 13.536) (writing took 1.7471440229564905 seconds)
2022-03-06 08:32:07 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-06 08:32:07 | INFO | train | epoch 568 | loss 2.077 | nll_loss 0.313 | ppl 1.24 | wps 27642.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27638 | lr 0.000190216 | gnorm 0.408 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65365
2022-03-06 08:32:07 | INFO | fairseq.trainer | begin training epoch 569
2022-03-06 08:32:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:33:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:33:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:34:00 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.591 | nll_loss 13.012 | ppl 8261.92 | wps 46439.6 | wpb 510.9 | bsz 1 | num_updates 27686 | best_loss 8.953
2022-03-06 08:34:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27686 updates
2022-03-06 08:34:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 569 @ 27686 updates, score 13.591) (writing took 1.6917053265497088 seconds)
2022-03-06 08:34:02 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-06 08:34:02 | INFO | train | epoch 569 | loss 2.077 | nll_loss 0.313 | ppl 1.24 | wps 27099.5 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27686 | lr 0.000190051 | gnorm 0.416 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65480
2022-03-06 08:34:02 | INFO | fairseq.trainer | begin training epoch 570
2022-03-06 08:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:34:33 | INFO | train_inner | epoch 570:     14 / 49 loss=2.077, nll_loss=0.313, ppl=1.24, wps=27435, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.413, loss_scale=32, train_wall=201, gb_free=21.6, wall=65512
2022-03-06 08:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:35:55 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.488 | nll_loss 12.904 | ppl 7664.8 | wps 45840.8 | wpb 510.9 | bsz 1 | num_updates 27735 | best_loss 8.953
2022-03-06 08:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27735 updates
2022-03-06 08:35:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:35:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:35:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 570 @ 27735 updates, score 13.488) (writing took 1.7103390377014875 seconds)
2022-03-06 08:35:57 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-06 08:35:57 | INFO | train | epoch 570 | loss 2.076 | nll_loss 0.312 | ppl 1.24 | wps 27645.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27735 | lr 0.000189883 | gnorm 0.41 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65595
2022-03-06 08:35:57 | INFO | fairseq.trainer | begin training epoch 571
2022-03-06 08:35:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:37:50 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.549 | nll_loss 12.965 | ppl 7993.49 | wps 46225.3 | wpb 510.9 | bsz 1 | num_updates 27784 | best_loss 8.953
2022-03-06 08:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27784 updates
2022-03-06 08:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:37:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:37:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 571 @ 27784 updates, score 13.549) (writing took 1.728178900666535 seconds)
2022-03-06 08:37:52 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-06 08:37:52 | INFO | train | epoch 571 | loss 2.076 | nll_loss 0.312 | ppl 1.24 | wps 27650.2 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27784 | lr 0.000189715 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65710
2022-03-06 08:37:52 | INFO | fairseq.trainer | begin training epoch 572
2022-03-06 08:37:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:38:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:38:30 | INFO | train_inner | epoch 572:     17 / 49 loss=2.075, nll_loss=0.312, ppl=1.24, wps=27412.1, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.408, loss_scale=32, train_wall=201, gb_free=21.6, wall=65748
2022-03-06 08:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:39:45 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.5 | nll_loss 12.915 | ppl 7721.63 | wps 46192.6 | wpb 510.9 | bsz 1 | num_updates 27832 | best_loss 8.953
2022-03-06 08:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27832 updates
2022-03-06 08:39:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:39:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:39:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 572 @ 27832 updates, score 13.5) (writing took 1.7348437877371907 seconds)
2022-03-06 08:39:47 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-06 08:39:47 | INFO | train | epoch 572 | loss 2.076 | nll_loss 0.312 | ppl 1.24 | wps 27062.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27832 | lr 0.000189552 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65825
2022-03-06 08:39:47 | INFO | fairseq.trainer | begin training epoch 573
2022-03-06 08:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:41:40 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.498 | nll_loss 12.913 | ppl 7714.99 | wps 46422 | wpb 510.9 | bsz 1 | num_updates 27881 | best_loss 8.953
2022-03-06 08:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27881 updates
2022-03-06 08:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:41:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 573 @ 27881 updates, score 13.498) (writing took 1.7433148054406047 seconds)
2022-03-06 08:41:42 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-06 08:41:42 | INFO | train | epoch 573 | loss 2.076 | nll_loss 0.312 | ppl 1.24 | wps 27641.1 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27881 | lr 0.000189385 | gnorm 0.414 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 65940
2022-03-06 08:41:42 | INFO | fairseq.trainer | begin training epoch 574
2022-03-06 08:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:42:24 | INFO | train_inner | epoch 574:     19 / 49 loss=2.076, nll_loss=0.312, ppl=1.24, wps=27679.9, ups=0.43, wpb=64871.8, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.413, loss_scale=32, train_wall=199, gb_free=21.6, wall=65983
2022-03-06 08:43:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:43:35 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.545 | nll_loss 12.961 | ppl 7971.07 | wps 46344.6 | wpb 510.9 | bsz 1 | num_updates 27930 | best_loss 8.953
2022-03-06 08:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27930 updates
2022-03-06 08:43:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 574 @ 27930 updates, score 13.545) (writing took 1.7208553925156593 seconds)
2022-03-06 08:43:36 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-06 08:43:36 | INFO | train | epoch 574 | loss 2.075 | nll_loss 0.312 | ppl 1.24 | wps 27668.4 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 27930 | lr 0.000189219 | gnorm 0.409 | loss_scale 64 | train_wall 97 | gb_free 21.6 | wall 66055
2022-03-06 08:43:36 | INFO | fairseq.trainer | begin training epoch 575
2022-03-06 08:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:43:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:45:30 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.53 | nll_loss 12.949 | ppl 7904.86 | wps 46240.1 | wpb 510.9 | bsz 1 | num_updates 27978 | best_loss 8.953
2022-03-06 08:45:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27978 updates
2022-03-06 08:45:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:45:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:45:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 575 @ 27978 updates, score 13.53) (writing took 1.7298235092312098 seconds)
2022-03-06 08:45:31 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-06 08:45:31 | INFO | train | epoch 575 | loss 2.075 | nll_loss 0.312 | ppl 1.24 | wps 27070.8 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 27978 | lr 0.000189057 | gnorm 0.418 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66170
2022-03-06 08:45:31 | INFO | fairseq.trainer | begin training epoch 576
2022-03-06 08:45:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:46:21 | INFO | train_inner | epoch 576:     22 / 49 loss=2.075, nll_loss=0.312, ppl=1.24, wps=27422.5, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.415, loss_scale=32, train_wall=201, gb_free=21.6, wall=66219
2022-03-06 08:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:47:25 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.662 | nll_loss 13.09 | ppl 8716.37 | wps 46283.2 | wpb 510.9 | bsz 1 | num_updates 28027 | best_loss 8.953
2022-03-06 08:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28027 updates
2022-03-06 08:47:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:47:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 576 @ 28027 updates, score 13.662) (writing took 1.6945521431043744 seconds)
2022-03-06 08:47:26 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-06 08:47:26 | INFO | train | epoch 576 | loss 2.074 | nll_loss 0.311 | ppl 1.24 | wps 27648.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28027 | lr 0.000188891 | gnorm 0.413 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66285
2022-03-06 08:47:26 | INFO | fairseq.trainer | begin training epoch 577
2022-03-06 08:47:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:48:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:49:20 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.464 | nll_loss 12.87 | ppl 7487.68 | wps 46312.4 | wpb 510.9 | bsz 1 | num_updates 28075 | best_loss 8.953
2022-03-06 08:49:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28075 updates
2022-03-06 08:49:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 577 @ 28075 updates, score 13.464) (writing took 1.706180365756154 seconds)
2022-03-06 08:49:21 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-06 08:49:21 | INFO | train | epoch 577 | loss 2.074 | nll_loss 0.311 | ppl 1.24 | wps 27078.6 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28075 | lr 0.00018873 | gnorm 0.407 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66400
2022-03-06 08:49:21 | INFO | fairseq.trainer | begin training epoch 578
2022-03-06 08:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:50:17 | INFO | train_inner | epoch 578:     25 / 49 loss=2.073, nll_loss=0.31, ppl=1.24, wps=27415.3, ups=0.42, wpb=64871.8, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.407, loss_scale=32, train_wall=201, gb_free=21.6, wall=66456
2022-03-06 08:51:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:51:15 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.623 | nll_loss 13.047 | ppl 8464.74 | wps 46235.3 | wpb 510.9 | bsz 1 | num_updates 28124 | best_loss 8.953
2022-03-06 08:51:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28124 updates
2022-03-06 08:51:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:51:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 578 @ 28124 updates, score 13.623) (writing took 1.7077142857015133 seconds)
2022-03-06 08:51:16 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-06 08:51:16 | INFO | train | epoch 578 | loss 2.073 | nll_loss 0.31 | ppl 1.24 | wps 27654.9 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28124 | lr 0.000188565 | gnorm 0.406 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66515
2022-03-06 08:51:16 | INFO | fairseq.trainer | begin training epoch 579
2022-03-06 08:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:53:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:53:10 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 13.519 | nll_loss 12.935 | ppl 7829.38 | wps 46161.5 | wpb 510.9 | bsz 1 | num_updates 28173 | best_loss 8.953
2022-03-06 08:53:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28173 updates
2022-03-06 08:53:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 579 @ 28173 updates, score 13.519) (writing took 1.6997475884854794 seconds)
2022-03-06 08:53:11 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-06 08:53:11 | INFO | train | epoch 579 | loss 2.074 | nll_loss 0.31 | ppl 1.24 | wps 27622.8 | ups 0.43 | wpb 64858.2 | bsz 126.7 | num_updates 28173 | lr 0.000188401 | gnorm 0.412 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66630
2022-03-06 08:53:11 | INFO | fairseq.trainer | begin training epoch 580
2022-03-06 08:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 08:54:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 08:54:14 | INFO | train_inner | epoch 580:     28 / 49 loss=2.073, nll_loss=0.31, ppl=1.24, wps=27412.3, ups=0.42, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.411, loss_scale=32, train_wall=201, gb_free=21.6, wall=66693
2022-03-06 08:55:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 08:55:05 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 13.484 | nll_loss 12.899 | ppl 7638.6 | wps 46230.3 | wpb 510.9 | bsz 1 | num_updates 28221 | best_loss 8.953
2022-03-06 08:55:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28221 updates
2022-03-06 08:55:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt
2022-03-06 08:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#1/checkpoint_last.pt (epoch 580 @ 28221 updates, score 13.484) (writing took 1.754171290434897 seconds)
2022-03-06 08:55:06 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-06 08:55:06 | INFO | train | epoch 580 | loss 2.073 | nll_loss 0.31 | ppl 1.24 | wps 27063.1 | ups 0.42 | wpb 64844.1 | bsz 126.7 | num_updates 28221 | lr 0.000188241 | gnorm 0.411 | loss_scale 32 | train_wall 97 | gb_free 21.6 | wall 66745
2022-03-06 08:55:06 | INFO | fairseq.trainer | begin training epoch 581
2022-03-06 08:55:06 | INFO | fairseq_cli.train | Start iterating over samples
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 328, in train
    log_output = trainer.train_step(samples)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/trainer.py", line 754, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/tasks/fairseq_task.py", line 492, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/fairseq_model.py", line 496, in forward
    return self.decoder(src_tokens, **kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 216, in forward
    x, extra = self.extract_features(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 238, in extract_features
    return self.extract_features_scriptable(
  File "/cluster/home/andriusb/fq/fairseq/fairseq/models/transformer/transformer_decoder.py", line 340, in extract_features_scriptable
    x, layer_attn, _ = layer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/transformer_layer.py", line 368, in forward
    x, attn = self.self_attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/modules/multihead_attention.py", line 170, in forward
    return F.multi_head_attention_forward(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/functional.py", line 4134, in multi_head_attention_forward
    tgt_len, bsz, embed_dim = query.size()
KeyboardInterrupt
