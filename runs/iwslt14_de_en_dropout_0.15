Sender: LSF System <lsfadmin@eu-g3-061>
Subject: Job 208118117: <iwslt14_de_en_dropout_0.15> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.15> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 07:20:06 2022
Job was executed on host(s) <eu-g3-061>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Mon Mar 14 07:20:35 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 07:20:35 2022
Terminated at Mon Mar 14 08:15:44 2022
Results reported at Mon Mar 14 08:15:44 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.15 --weight-decay 0.0001 --criterion cross_entropy --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3300.55 sec.
    Max Memory :                                 4811 MB
    Average Memory :                             3491.64 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15189.00 MB
    Max Swap :                                   26 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3308 sec.
    Turnaround time :                            3338 sec.

The output (if any) follows:

2022-03-14 07:20:43 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.15, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 07:20:43 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-14 07:20:43 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-14 07:20:43 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-14 07:20:43 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-14 07:20:43 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-14 07:20:43 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-14 07:20:43 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-14 07:20:43 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 07:20:43 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-14 07:20:43 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-14 07:20:43 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-14 07:20:46 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 07:20:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:20:46 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-14 07:20:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:20:46 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 07:20:46 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-14 07:20:46 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:20:46 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:20:46 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 07:20:46 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-14 07:20:46 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-14 07:20:46 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-14 07:20:47 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 07:20:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 07:20:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 07:20:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:20:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 07:20:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-14 07:21:23 | INFO | train_inner | epoch 001:    105 / 157 loss=11.734, ppl=3405.71, wps=82017.6, ups=3.25, wpb=25186.5, bsz=962.7, num_updates=100, lr=1.25e-05, gnorm=4.067, loss_scale=4, train_wall=35, gb_free=14.3, wall=37
2022-03-14 07:21:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:21:42 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-14 07:21:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:21:45 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the.......
2022-03-14 07:21:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:21:49 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,......
2022-03-14 07:21:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:21:53 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,........
2022-03-14 07:21:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:21:58 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:21:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:22:03 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:22:08 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:22:14 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:22:21 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:22:24 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:22:24 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.961 | ppl 996.54 | bleu 0.01 | wps 3968.9 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-14 07:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-14 07:22:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:22:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.01) (writing took 2.0397870671004057 seconds)
2022-03-14 07:22:26 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 07:22:26 | INFO | train | epoch 001 | loss 11.255 | ppl 2444.48 | wps 40751.9 | ups 1.62 | wpb 25082.4 | bsz 995.7 | num_updates 152 | lr 1.9e-05 | gnorm 3.242 | loss_scale 4 | train_wall 51 | gb_free 22.4 | wall 99
2022-03-14 07:22:26 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 07:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:22:41 | INFO | train_inner | epoch 002:     48 / 157 loss=10.037, ppl=1050.84, wps=32445.4, ups=1.28, wpb=25339.2, bsz=1116.9, num_updates=200, lr=2.5e-05, gnorm=2.024, loss_scale=4, train_wall=30, gb_free=14.6, wall=115
2022-03-14 07:23:12 | INFO | train_inner | epoch 002:    148 / 157 loss=9.254, ppl=610.74, wps=80352.4, ups=3.22, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.696, loss_scale=4, train_wall=31, gb_free=20.2, wall=146
2022-03-14 07:23:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:23:18 | INFO | fairseq.tasks.translation | example hypothesis: we we we.
2022-03-14 07:23:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:23:22 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the.
2022-03-14 07:23:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:23:25 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the.
2022-03-14 07:23:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:23:29 | INFO | fairseq.tasks.translation | example hypothesis: and and it,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:23:34 | INFO | fairseq.tasks.translation | example hypothesis: and and we we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:23:39 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-14 07:23:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:23:44 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:23:50 | INFO | fairseq.tasks.translation | example hypothesis: and we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-14 07:23:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:23:57 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-14 07:23:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:23:59 | INFO | fairseq.tasks.translation | example hypothesis: and we,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:23:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.851 | ppl 461.82 | bleu 0.02 | wps 4021.7 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.02
2022-03-14 07:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-14 07:23:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:24:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.02) (writing took 2.4657954850699753 seconds)
2022-03-14 07:24:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 07:24:01 | INFO | train | epoch 002 | loss 9.389 | ppl 670.24 | wps 41213.9 | ups 1.64 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 1.907 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 195
2022-03-14 07:24:02 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 07:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:24:30 | INFO | train_inner | epoch 003:     91 / 157 loss=8.847, ppl=460.34, wps=31868.3, ups=1.28, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=1.574, loss_scale=4, train_wall=30, gb_free=13.8, wall=224
2022-03-14 07:24:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example hypothesis: we to to to the the.
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:24:58 | INFO | fairseq.tasks.translation | example hypothesis: this is is the the the the the.
2022-03-14 07:24:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:25:02 | INFO | fairseq.tasks.translation | example hypothesis: this is a.
2022-03-14 07:25:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:25:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's, and it's.
2022-03-14 07:25:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:25:10 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's that's not not not not not not not not that that that that's that's.
2022-03-14 07:25:10 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:25:15 | INFO | fairseq.tasks.translation | example hypothesis: and it's the the the the of the of the of the of the of the.
2022-03-14 07:25:15 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:25:19 | INFO | fairseq.tasks.translation | example hypothesis: but it's, but it's, but it's, but it's a, but it's to the the the the the the the the the the the the the the to to to to to to to to to the.
2022-03-14 07:25:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:25:25 | INFO | fairseq.tasks.translation | example hypothesis: and we're the the the the the, and the, and the the the the the, and the, and we we we the the the the the the the the the the the the the the the the the the of the of the of the of the of the of the of the.
2022-03-14 07:25:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:25:32 | INFO | fairseq.tasks.translation | example hypothesis: it's a, "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-14 07:25:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:25:34 | INFO | fairseq.tasks.translation | example hypothesis: and the, the, the, the, the, the, the, it's's a, the the, the, the, the, we's's's's a, the a a, the a, the a, and the a, but the the the the a a a a, the the, but the the, but the the a, the a, the a a a a a a a a a a a a a a, and the, and the the, and the, and the a a a a a a a a, the the the the the the the the the the a, the the a a a, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the, and the a a, the the the the the the the, the the, the the the the the the the the the the, and the, and the to to to to to to to to to to to to to to to to to to to to to a
2022-03-14 07:25:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:25:34 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.413 | ppl 340.75 | bleu 0.27 | wps 4053 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.27
2022-03-14 07:25:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-14 07:25:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:25:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:25:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.27) (writing took 2.246473917970434 seconds)
2022-03-14 07:25:37 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 07:25:37 | INFO | train | epoch 003 | loss 8.719 | ppl 421.29 | wps 41414.4 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.787 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 290
2022-03-14 07:25:37 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 07:25:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:25:48 | INFO | train_inner | epoch 004:     34 / 157 loss=8.486, ppl=358.55, wps=32648.7, ups=1.28, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=1.915, loss_scale=4, train_wall=31, gb_free=13.9, wall=302
2022-03-14 07:26:19 | INFO | train_inner | epoch 004:    134 / 157 loss=8.147, ppl=283.38, wps=80979.2, ups=3.21, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=2.059, loss_scale=4, train_wall=31, gb_free=14.6, wall=333
2022-03-14 07:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:26:30 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be the world.
2022-03-14 07:26:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:26:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the world.
2022-03-14 07:26:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:26:38 | INFO | fairseq.tasks.translation | example hypothesis: so you're going to be be two two two two.
2022-03-14 07:26:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:26:42 | INFO | fairseq.tasks.translation | example hypothesis: there's a lot of the world, and there's a lot of the world.
2022-03-14 07:26:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:26:46 | INFO | fairseq.tasks.translation | example hypothesis: it's not not that we're not not not not not not not not not not not going to do it.
2022-03-14 07:26:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:26:51 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world of the world, and the world, and the world, and people people are the world.
2022-03-14 07:26:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:26:55 | INFO | fairseq.tasks.translation | example hypothesis: now, you're going to be the same of the world, but they're going to have to be be be be be be be be be be the world.
2022-03-14 07:26:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:27:01 | INFO | fairseq.tasks.translation | example hypothesis: so, we're going to be the world of the world of the world, and we have the world of the world of the world, and we have the world, and we're going to have to have to be the world, and we have the world of the world.
2022-03-14 07:27:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:27:07 | INFO | fairseq.tasks.translation | example hypothesis: so, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-14 07:27:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:27:09 | INFO | fairseq.tasks.translation | example hypothesis: so, we have to be the world of the world of the world, and we have the world, which is the world, which is the world, which is the world, which is the world, we have to be be the world, which is the world, which is the world, which is the world, we have to be be be be be be be be be be be be be be be be be be be be be be be be be to be the world, and we have to be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be, and we have to have to be be be, and we have to be be be be be be, and we have to be be be be be be, and we have to be be be be be be be be be be be be be be be be be be be be be be be be
2022-03-14 07:27:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:27:09 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.764 | ppl 217.32 | bleu 1.61 | wps 4153.2 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 1.61
2022-03-14 07:27:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-14 07:27:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:27:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:27:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 4 @ 623 updates, score 1.61) (writing took 2.2899660100229084 seconds)
2022-03-14 07:27:12 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 07:27:12 | INFO | train | epoch 004 | loss 8.167 | ppl 287.32 | wps 41619.3 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 2.022 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 385
2022-03-14 07:27:12 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 07:27:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:27:36 | INFO | train_inner | epoch 005:     77 / 157 loss=7.861, ppl=232.56, wps=31771.3, ups=1.3, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=2.559, loss_scale=4, train_wall=30, gb_free=15.5, wall=410
2022-03-14 07:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:28:05 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the future.
2022-03-14 07:28:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:28:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most of the most of the most.
2022-03-14 07:28:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:28:12 | INFO | fairseq.tasks.translation | example hypothesis: so these are new new new new new new new new new new new new new s.
2022-03-14 07:28:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:28:16 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the way, and there's going to be a lot of the world.
2022-03-14 07:28:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:28:19 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of what we're going to do that we're going to do.
2022-03-14 07:28:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:28:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the way of people, for the way of the people, and people in the people.
2022-03-14 07:28:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:28:27 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to have a lot of the way, but they're going to have a lot of the way, but they're going to be a lot of the way.
2022-03-14 07:28:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:28:31 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to get a lot of the world, and we're going to get a lot of a lot of the world, and we can see the way of the world, and we're going to get a lot of the world.
2022-03-14 07:28:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:28:37 | INFO | fairseq.tasks.translation | example hypothesis: and so, "this is a lot of a lot of the time," and we said, "that we said," that's going to say, "and then," "that's a lot of the time," "" and then we've been a lot of the first time. "" ""
2022-03-14 07:28:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:28:39 | INFO | fairseq.tasks.translation | example hypothesis: so, we had a lot of a lot of the world, and we've got a lot of a lot of the way, and we had a lot of the way that we've been been been been been been been a lot of a lot of a lot of the way, and we had a lot of the world, and we had a little little little little little little little little little little little little little little little little little little little little little little bit of the way that we had to do that we had a lot of the world, and we've been been been been been been been a lot of the way that we've been been been been been been been been been been been been been a lot of a lot of a lot of a lot of a lot of a lot of the world, and we had a lot of the world, and then that we had a lot of the way, and we had to do that we had a lot of the way, and then that we've been been been been been been been been been been been been been been
2022-03-14 07:28:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:28:39 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.301 | ppl 157.7 | bleu 2.41 | wps 4820.3 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 2.41
2022-03-14 07:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-14 07:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:28:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 5 @ 780 updates, score 2.41) (writing took 2.130737792002037 seconds)
2022-03-14 07:28:41 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 07:28:41 | INFO | train | epoch 005 | loss 7.633 | ppl 198.52 | wps 44213.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 2.106 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 475
2022-03-14 07:28:41 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 07:28:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:28:48 | INFO | train_inner | epoch 006:     20 / 157 loss=7.475, ppl=177.91, wps=35584.9, ups=1.4, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.855, loss_scale=4, train_wall=30, gb_free=13, wall=481
2022-03-14 07:29:19 | INFO | train_inner | epoch 006:    120 / 157 loss=7.172, ppl=144.2, wps=81013.5, ups=3.2, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.795, loss_scale=4, train_wall=31, gb_free=14.5, wall=512
2022-03-14 07:29:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:29:34 | INFO | fairseq.tasks.translation | example hypothesis: we've got to be in the future.
2022-03-14 07:29:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:29:38 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most most most most of the most most of the most most most most of the most of the most most most of the
2022-03-14 07:29:38 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:29:43 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-14 07:29:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:29:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a lot of example, and it's going to be a lot of example, and it's going to be a lot of the world.
2022-03-14 07:29:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:29:53 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're going to do what we're going to do that we're going to do it, and what we're going to do it's going to do.
2022-03-14 07:29:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:29:59 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as as as as as as as the people, for the people, for the people, for the people, for the people, for the people, for the people, for the people, for the people, for the most people, for the people, for the people,
2022-03-14 07:29:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:30:05 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of some of some of some of them, but if you don't know, but they're going to go to be a lot of the way, but they're going to be able to be able to be able, but they're going to be able, but they're going to be able to go
2022-03-14 07:30:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:30:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the idea of the world, we're going to take the world, and we're going to be a lot of the world, we're going to get a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, we're going to see that we're going to see that we're going to see that are going to be a lot of the
2022-03-14 07:30:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:30:18 | INFO | fairseq.tasks.translation | example hypothesis: one: one: one: one of the world, and it's going to say, "you know," you know, and then, "you know," you know, "this is that we know," this is the first first time, "it's a first," that's a first, and then we're going to say, "you know," it's going to say, "that we're going to say," that we're going to say, "that we're going to say, and then it's going to say," the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first, "and then it's going to say, and then we're going to say," ""
2022-03-14 07:30:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:30:21 | INFO | fairseq.tasks.translation | example hypothesis: so, this is a lot of fact, if we're going to be a lot of the world, and then we're going to be a lot of the world that we're going to be a lot of fact that we're going to be able to be a lot of the world that we're going to be able to be able to be a lot of the world that we're going to be a lot of the world, and then that we're going to be a lot of the world, and then that that we're going to be able to be able to be a lot of fact that we're going to be able to be a lot of fact that we're going to be able to be a lot of the world that we're going to be able to be a lot of the world, and the world, and then that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:30:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:30:21 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.781 | ppl 109.98 | bleu 2.71 | wps 3499.2 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 2.71
2022-03-14 07:30:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-14 07:30:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:30:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:30:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 6 @ 937 updates, score 2.71) (writing took 2.266023676842451 seconds)
2022-03-14 07:30:23 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 07:30:23 | INFO | train | epoch 006 | loss 7.152 | ppl 142.18 | wps 38648.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.885 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 577
2022-03-14 07:30:24 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 07:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:30:43 | INFO | train_inner | epoch 007:     63 / 157 loss=6.847, ppl=115.1, wps=29804.3, ups=1.19, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.713, loss_scale=4, train_wall=30, gb_free=15.3, wall=597
2022-03-14 07:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:31:16 | INFO | fairseq.tasks.translation | example hypothesis: we've got this.
2022-03-14 07:31:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:31:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the point of the most most most most of the most.
2022-03-14 07:31:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:31:24 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new york.
2022-03-14 07:31:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:31:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an example.
2022-03-14 07:31:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:31:33 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know, we're not a few few of the world, and what's going to understand what's going to do.
2022-03-14 07:31:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:31:38 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamay people who are the people for the people, for the people, for the people, and the most people who is a lot of the people.
2022-03-14 07:31:38 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:31:43 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some kinds of the bottom, but if you don't know, if you don't know, but they're going to do it, if you don't know, you don't know, you don't know, you don't know, if you don't know, there's the same time, but they don't know,
2022-03-14 07:31:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:31:49 | INFO | fairseq.tasks.translation | example hypothesis: so, if we're going to use these kinds of this, we can see that's going to get a lot of the world, and we can get a lot of the world, and we can create a lot of the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world.
2022-03-14 07:31:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:31:56 | INFO | fairseq.tasks.translation | example hypothesis: well, one of the one, and the one of you know, and it's going to say, "you know," you know, "you know," you know, "you know," you know, "you know," you know, you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know, you're going to know, you know," you know, you know, you know, you know, you know, "you're
2022-03-14 07:31:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:31:59 | INFO | fairseq.tasks.translation | example hypothesis: and so, it's still still still, and then we've been been been a lot of the world, and if we've been been been been been been a lot of the world that we've been been been been been been been been been been able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get to get to be able to be able to be able to be able to be able to be able to be able to be able to be able to do that we've been able to be able to be able to do that we've been able to do that we've been able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able
2022-03-14 07:31:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:31:59 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.325 | ppl 80.19 | bleu 4.78 | wps 3822.4 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 4.78
2022-03-14 07:31:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-14 07:31:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:32:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 7 @ 1094 updates, score 4.78) (writing took 2.462162157986313 seconds)
2022-03-14 07:32:01 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 07:32:01 | INFO | train | epoch 007 | loss 6.689 | ppl 103.15 | wps 40213.4 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.707 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 675
2022-03-14 07:32:02 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 07:32:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:32:04 | INFO | train_inner | epoch 008:      6 / 157 loss=6.587, ppl=96.13, wps=31085.3, ups=1.24, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.708, loss_scale=4, train_wall=30, gb_free=14.8, wall=677
2022-03-14 07:32:35 | INFO | train_inner | epoch 008:    106 / 157 loss=6.245, ppl=75.85, wps=81676.6, ups=3.24, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.781, loss_scale=4, train_wall=30, gb_free=15.1, wall=708
2022-03-14 07:32:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:32:54 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppppon.
2022-03-14 07:32:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:32:58 | INFO | fairseq.tasks.translation | example hypothesis: that's the car.
2022-03-14 07:32:58 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:33:01 | INFO | fairseq.tasks.translation | example hypothesis: will be able to be new york.
2022-03-14 07:33:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:33:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's your own food, where you're going to get up, and you're going to be in your body.
2022-03-14 07:33:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:33:09 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just a few few of his head, and what's going to understand what's going on.
2022-03-14 07:33:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:33:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamay of people who are used to make a lot of people, and the number of the number of the number of the number.
2022-03-14 07:33:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:33:19 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of them are in the bottom, but if you don't have to be able to use the same energy, if you don't have the same energy, and they don't have the energy, you need to use the same energy, you need to use the same energy, there are so they need to have the energy.
2022-03-14 07:33:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:33:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information that we can see this.
2022-03-14 07:33:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:33:31 | INFO | fairseq.tasks.translation | example hypothesis: rb: one of the other reasons it's interesting, and it's going to make me that he said that he said, "oh," oh, "oh," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, "you know," is that, "you know," you know, "you know," you know, "you know," you know, "you know, if you know," oh, you know, "you know," that, "you know," you know, you know, you know, you know, you know, "that," you know, "you know," you know, you know, you know, "you know,
2022-03-14 07:33:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:33:33 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's always always always always be a lot of the world, and if we're going to see that it was a little bit of the same system that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a new new new york, which is a new new new york, which is that that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:33:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:33:33 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.926 | ppl 60.78 | bleu 7.24 | wps 4202.4 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 7.24
2022-03-14 07:33:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-14 07:33:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:33:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 8 @ 1251 updates, score 7.24) (writing took 2.2840224341489375 seconds)
2022-03-14 07:33:35 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 07:33:35 | INFO | train | epoch 008 | loss 6.288 | ppl 78.16 | wps 41944.3 | ups 1.67 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.749 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 769
2022-03-14 07:33:36 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 07:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:33:51 | INFO | train_inner | epoch 009:     49 / 157 loss=6.149, ppl=70.97, wps=33465.9, ups=1.3, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.748, loss_scale=4, train_wall=31, gb_free=15.3, wall=785
2022-03-14 07:34:22 | INFO | train_inner | epoch 009:    149 / 157 loss=5.926, ppl=60.82, wps=80597.3, ups=3.25, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.785, loss_scale=4, train_wall=30, gb_free=14.8, wall=816
2022-03-14 07:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:34:29 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppppppat the end of the night.
2022-03-14 07:34:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:34:33 | INFO | fairseq.tasks.translation | example hypothesis: that's the car of the ha ha ha, most most most most most.
2022-03-14 07:34:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:34:37 | INFO | fairseq.tasks.translation | example hypothesis: new stars will be new york, the new york new new new new york are two new york.
2022-03-14 07:34:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:34:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese, where they're going to come up with pppppppg.
2022-03-14 07:34:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:34:46 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we're not just just a few few of his head on his head, and what's going on.
2022-03-14 07:34:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:34:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamated people like the most people for the number of the number of animals, and that's a number of animals.
2022-03-14 07:34:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:34:54 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of the bbbdddds in the bottom, but if you don't need to see the energy energy, and if you need to have the energy energy, you need to do it.
2022-03-14 07:34:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:34:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information of information, we can go from this structure, we can create a single single single single single piece of the world, which is all the structure of the structure of the structure, which is all the structure of the structure, and the structure of the structure, which is all the structure of the structure, which is all the structure that we all the structure of the structure of the structure that are all the structure of the structure of the structure
2022-03-14 07:34:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:35:05 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to do me, "oh," oh, "oh," you know, "you know," you know, "you know," you know, if you know, you know, you know, you know, you know, "you know," you know, you know, "you know," is that, "you know, you know," is that one of this is, "is," is, "you know, you know, you know," you know, "is," is a long long long long long time, "is," is, "is," is, "is," is that, "is," is, "oh, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-14 07:35:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:35:07 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still still still at the mother, and we have a little bit of the work on our work that we had to have a little bit of the world that we had had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see that the most of a new new new new new york, which which which which is that we had a little bit of a little bit of a little bit of a little bit of a little bit of the most of the most of the most of the most of the most of the most of the most of the most of the most of the web, which is, which is that we had had had had
2022-03-14 07:35:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:35:07 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.48 | ppl 44.64 | bleu 9.89 | wps 4296.1 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 9.89
2022-03-14 07:35:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-14 07:35:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:35:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 9 @ 1408 updates, score 9.89) (writing took 2.1946304829325527 seconds)
2022-03-14 07:35:09 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 07:35:09 | INFO | train | epoch 009 | loss 5.922 | ppl 60.64 | wps 42193.8 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.784 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 863
2022-03-14 07:35:09 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 07:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:35:39 | INFO | train_inner | epoch 010:     92 / 157 loss=5.593, ppl=48.27, wps=32881.3, ups=1.31, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.559, loss_scale=4, train_wall=31, gb_free=14.7, wall=892
2022-03-14 07:35:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:36:02 | INFO | fairseq.tasks.translation | example hypothesis: we've got this ppppon the clinics.
2022-03-14 07:36:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:36:06 | INFO | fairseq.tasks.translation | example hypothesis: that's the bottom of doha, most of most of most of most of you know.
2022-03-14 07:36:06 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:36:10 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new dididies of the new ways of two new new york.
2022-03-14 07:36:10 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:36:14 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french, where food, where they are in the legs and pppppppisisisisisy.
2022-03-14 07:36:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:36:19 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we just just just a few ways on his head on his head, and what's going on.
2022-03-14 07:36:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:36:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamay of people like the responsibility for the responsibility, the number of animals, the number of animals, and this is a lot of reviiiiiiiiiiiiiiiiiiiiiiiiiii
2022-03-14 07:36:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:36:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of some of the bbototes in the lines, but it doesn't go, but if they don't have the energy energy, if they need to go to the energy, and they need their energy.
2022-03-14 07:36:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:36:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information of this reflection, we can go to a design, we can start with a traditional traditional source of the world, and we can go through the shape of the structure of the structure, and there's all the structure of the structure of the structure.
2022-03-14 07:36:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:36:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and interesting for me to make tedtedtedwomen for me, "oh," oh, "yes," yes, "yes," okay, "okay," okay, "okay," there's one of you know, "there's one of you know," '' "'' '' '' '' '' ''" '' '' '' '' '' '' '' '"there's a good," there's a very much, "' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''"
2022-03-14 07:36:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:36:40 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother, and the invention of the design part of the design, we have a little bit on our work on the world that we had to create a little bit of the world, and we had to get a global global global system that there, or to be a global global global global global system that it, or to make it, or to be a little bit of a global global global global global global global system that there is, or to be a little bit of a little bit of a global global global global global global global global global system that there is, or to be able to be a little bit of a global global global global global global global system that there, or to be able to be able to make it, or to be able to be able to be a little bit that there is, to be able to be able to be able to be able to be a little bit of a global system that there, or to be a little bit of a little bit, or to be able to be able to be a
2022-03-14 07:36:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:36:40 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.131 | ppl 35.04 | bleu 12.56 | wps 4362.7 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 12.56
2022-03-14 07:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-14 07:36:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:36:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:36:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 10 @ 1565 updates, score 12.56) (writing took 2.247436322970316 seconds)
2022-03-14 07:36:42 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 07:36:42 | INFO | train | epoch 010 | loss 5.501 | ppl 45.29 | wps 42380.6 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.642 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 956
2022-03-14 07:36:43 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 07:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:36:54 | INFO | train_inner | epoch 011:     35 / 157 loss=5.4, ppl=42.24, wps=33041.5, ups=1.33, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.723, loss_scale=4, train_wall=30, gb_free=13.8, wall=967
2022-03-14 07:37:25 | INFO | train_inner | epoch 011:    135 / 157 loss=5.066, ppl=33.49, wps=81962.8, ups=3.21, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.621, loss_scale=4, train_wall=31, gb_free=13.7, wall=999
2022-03-14 07:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:37:36 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppist in the clinics.
2022-03-14 07:37:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:37:40 | INFO | fairseq.tasks.translation | example hypothesis: that's the line of doha, most of most of most of you know here.
2022-03-14 07:37:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:37:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new dididials that are two new york.
2022-03-14 07:37:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:37:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese, where the legs are going to be in pppace.
2022-03-14 07:37:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:37:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just just get a couple of electroelectrodes on his head and understand what all the thoughts are in your mind.
2022-03-14 07:37:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:37:56 | INFO | fairseq.tasks.translation | example hypothesis: and in mamamamamamated people who grew up for the number of animals, and this is a number of animals.
2022-03-14 07:37:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:38:00 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some bbbel in the lines, but if you don't have to move it, if you don't need your energy energy, and you need to get the energy energy.
2022-03-14 07:38:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:38:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that goes from this reflection, we can start with a traditional form of the traditional, and we're going to go through the shape of the structure, which is all the structure of the structure and all the structure.
2022-03-14 07:38:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:38:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and for me to be here for tedwomen, "yes, it's the best thing that we said," you know, "you're going to say," you know, you're going to say, "you know, you know, you know, you know, you know, you know, you're going to say," you know, "you're going to go to say," you know, you know, you know, you know, "you know, you know, you know, you know, you know, you know, you know, you're going to be a long long long time to say, you know, you know, you know, you know, you know, you know, you know, you know, you're going to say, you know, you know, you know, you know, for a
2022-03-14 07:38:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:38:12 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still the mother, and a big part of our work that we had to solve the plane that we had to solve it, to be a unique system that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-14 07:38:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:38:12 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.863 | ppl 29.1 | bleu 13.54 | wps 4517.4 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 13.54
2022-03-14 07:38:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-14 07:38:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:38:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 11 @ 1722 updates, score 13.54) (writing took 2.144599369028583 seconds)
2022-03-14 07:38:14 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 07:38:14 | INFO | train | epoch 011 | loss 5.147 | ppl 35.42 | wps 42978.1 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.64 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 1048
2022-03-14 07:38:15 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 07:38:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:38:39 | INFO | train_inner | epoch 012:     78 / 157 loss=4.958, ppl=31.09, wps=33670.2, ups=1.35, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.587, loss_scale=4, train_wall=30, gb_free=14.4, wall=1073
2022-03-14 07:39:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:39:07 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppink in the clinics.
2022-03-14 07:39:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:39:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know, most of you know.
2022-03-14 07:39:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:39:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-14 07:39:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:39:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food food food, where they're going to be shake, and they're going to be picking.
2022-03-14 07:39:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:39:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head on his head, and what all of the thoughts are on the thoughts.
2022-03-14 07:39:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:39:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mab of the responsibility for responsibility, the number of life grew up to the number of animals, and this is a prosperity for conservabia.
2022-03-14 07:39:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:39:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magic lines in the lines, but it doesn't go to alalalalalalalalalty, if you don't need to move your energy.
2022-03-14 07:39:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:39:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information, the reflection of this reflection, we can start with a traditional face of the traditional face, and we start able to start with the shape of the shape, and all the shape of the structure and all the structure.
2022-03-14 07:39:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:39:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for tedwomen -- yeah, yeah, it's the best thing when we said, "hey," hey, and then we're going to say, "hey, and then we're going to support them."
2022-03-14 07:39:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:39:40 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, if you're going to do the best invention, and a big work on our airplane, we've had to solve a very unique result that we had to solve that there were a unique result of the ground that we had to solve.
2022-03-14 07:39:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:39:40 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.481 | ppl 22.34 | bleu 13.97 | wps 4965.1 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 13.97
2022-03-14 07:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-14 07:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:39:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 12 @ 1879 updates, score 13.97) (writing took 2.5915897970553488 seconds)
2022-03-14 07:39:43 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 07:39:43 | INFO | train | epoch 012 | loss 4.799 | ppl 27.84 | wps 44532.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.512 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 1136
2022-03-14 07:39:43 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 07:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:39:50 | INFO | train_inner | epoch 013:     21 / 157 loss=4.639, ppl=24.92, wps=35534.9, ups=1.42, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.537, loss_scale=4, train_wall=30, gb_free=14.3, wall=1143
2022-03-14 07:40:21 | INFO | train_inner | epoch 013:    121 / 157 loss=4.535, ppl=23.18, wps=81765.9, ups=3.23, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.45, loss_scale=4, train_wall=31, gb_free=14, wall=1174
2022-03-14 07:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:40:36 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppilled clinic in the clinic.
2022-03-14 07:40:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:40:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha ha, most of you know.
2022-03-14 07:40:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:40:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golsticks of the two new york reduced.
2022-03-14 07:40:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:40:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food food, where happy legs are going to be done with salz.
2022-03-14 07:40:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:40:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a couple of electrodes on his head, and understand what all the thoughts are.
2022-03-14 07:40:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:40:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the mab of people like the responsibility of life was growing for the number of animals, and again, this is a number of conservation for conservation, and that has become become become become a namibia in namibia.
2022-03-14 07:40:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:40:59 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the magle lines of magnetic lines, but the superconductor, if you don't have to move their energy energy energy, and if you don't need their energy energy.
2022-03-14 07:40:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:41:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflect reflection of this reflection, we can begin to start with a traditional facial face of the face of the information, and there's the whole shape of the whole shape of the information and the entire information that gives you a whole structure, and the whole structure of the entire structure of the entire structure and the whole structure of information, which is all the entire information that gives you all the entire information through the whole structure
2022-03-14 07:41:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:41:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons we have interesting, and it's interesting for tedwomen, for tedwomen.
2022-03-14 07:41:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:41:12 | INFO | fairseq.tasks.translation | example hypothesis: luck is still the mother of the invention, and a big part of work that we had to solve the plane on our airplane.
2022-03-14 07:41:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:41:12 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.262 | ppl 19.18 | bleu 16.76 | wps 4493.3 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 16.76
2022-03-14 07:41:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-14 07:41:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:41:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 13 @ 2036 updates, score 16.76) (writing took 2.31891076406464 seconds)
2022-03-14 07:41:15 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 07:41:15 | INFO | train | epoch 013 | loss 4.509 | ppl 22.77 | wps 43064.3 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.501 | loss_scale 4 | train_wall 47 | gb_free 13.9 | wall 1228
2022-03-14 07:41:15 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 07:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:41:35 | INFO | train_inner | epoch 014:     64 / 157 loss=4.336, ppl=20.19, wps=33619.8, ups=1.35, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.39, loss_scale=4, train_wall=30, gb_free=14.4, wall=1249
2022-03-14 07:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:42:07 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic clinic.
2022-03-14 07:42:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:42:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyskyline of doha, which probably most of you know.
2022-03-14 07:42:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:42:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to be able to be able to get two new york.
2022-03-14 07:42:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:42:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food, where happy legs are frog with salsales and feeding.
2022-03-14 07:42:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:42:24 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a few electrodes on his head on his head and understand what all the thoughts are.
2022-03-14 07:42:24 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:42:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamammals like the responsibility for life, the number of wildlife grew up to the number of animals, and it has become a very conservaiibia in the maibia.
2022-03-14 07:42:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:42:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the bols of magnetic magnetic lines, but the susulungs of the superconductor, if you don't need energy.
2022-03-14 07:42:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:42:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information to reflect the reflection of this reflection, we can start able to start with a traditional face of the whole information, and through the whole structure.
2022-03-14 07:42:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:42:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedwomen, "oh, the best men said," when the men told you about a table, "and if you're going to support them."
2022-03-14 07:42:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:42:41 | INFO | fairseq.tasks.translation | example hypothesis: luily, it's still the mother of the invention of invention, and one part of the design design that we had to solve the most unique problems that were connected to the ground.
2022-03-14 07:42:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:42:41 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.085 | ppl 16.98 | bleu 19.04 | wps 4831.7 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 19.04
2022-03-14 07:42:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-14 07:42:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:42:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 14 @ 2193 updates, score 19.04) (writing took 2.202232150826603 seconds)
2022-03-14 07:42:44 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 07:42:44 | INFO | train | epoch 014 | loss 4.173 | ppl 18.04 | wps 44328 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.292 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1317
2022-03-14 07:42:44 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 07:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:42:47 | INFO | train_inner | epoch 015:      7 / 157 loss=4.077, ppl=16.87, wps=35710.9, ups=1.4, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.249, loss_scale=4, train_wall=30, gb_free=14.3, wall=1320
2022-03-14 07:43:18 | INFO | train_inner | epoch 015:    107 / 157 loss=3.895, ppl=14.88, wps=81040.4, ups=3.22, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.295, loss_scale=4, train_wall=31, gb_free=14.3, wall=1351
2022-03-14 07:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:43:37 | INFO | fairseq.tasks.translation | example hypothesis: we made these pink in the clinic.
2022-03-14 07:43:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:43:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, probably most of the most familiar here.
2022-03-14 07:43:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:43:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks for the two new pigs.
2022-03-14 07:43:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:43:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food food, where happy legs are and fat.
2022-03-14 07:43:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:43:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a couple of electrodes on his head and understand what all its thoughts are on the way.
2022-03-14 07:43:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:43:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the mastery of people like responsibility for the wild, grew up the number of animals, and this is a basis for conservation in conservation.
2022-03-14 07:43:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:44:01 | INFO | fairseq.tasks.translation | example hypothesis: first of magbbols are some of magnetic magnetic field, but the suide of the superconductor, if you're not moving, you need to move, your energy, and the super-conductor.
2022-03-14 07:44:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:44:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use information that comes from this reflection, we can begin to start with a traditional facial facial, which is the big, and we start looking at the shape of the face, and the whole shape of the information, and the whole structure, and all the structure of the structure.
2022-03-14 07:44:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:44:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to measure, and measure it for me to be here for tedwomen, and then, "yes, when someone was the best one of the best," the men who said, "when we say," when we're talking about to you know, "the truth is a candy for women," and then we're going to support for example, "and then we've been working on this time."
2022-03-14 07:44:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:44:13 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of the invention, and a big part of the design work on our airplane, which was a result that we had to solve a unique result that we had to solve the unique problems that were connected to a replacement -- everything that allows us to be able to be able to be able to be able to be able to be able to be able to be able to use the propheartwork with a restore, or to use the propheartwork with the propheal system, or the propheal system, if you can be able to use, if you can actually be able to use the propheartwork on the car system, or to use, if you can be able to use, if you can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use a market,
2022-03-14 07:44:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:44:13 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.716 | ppl 13.14 | bleu 21.18 | wps 4582.2 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 21.18
2022-03-14 07:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-14 07:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:44:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 15 @ 2350 updates, score 21.18) (writing took 2.305582543136552 seconds)
2022-03-14 07:44:15 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 07:44:15 | INFO | train | epoch 015 | loss 3.937 | ppl 15.32 | wps 43182.4 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.296 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1409
2022-03-14 07:44:15 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 07:44:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:44:32 | INFO | train_inner | epoch 016:     50 / 157 loss=3.932, ppl=15.26, wps=34340.5, ups=1.35, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.297, loss_scale=4, train_wall=31, gb_free=14.7, wall=1425
2022-03-14 07:45:02 | INFO | train_inner | epoch 016:    150 / 157 loss=3.65, ppl=12.56, wps=80450.9, ups=3.26, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.144, loss_scale=4, train_wall=30, gb_free=14.9, wall=1456
2022-03-14 07:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:45:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these little posters in the clinic.
2022-03-14 07:45:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:45:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha who are most familiar here.
2022-03-14 07:45:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:45:16 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldidates of the two new pigs.
2022-03-14 07:45:16 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:45:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs and fat.
2022-03-14 07:45:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:45:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all its thoughts are on the way.
2022-03-14 07:45:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:45:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mastery of people were growing up for the wild animals, and this is a foundation for conservation protection.
2022-03-14 07:45:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:45:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloose of magnetic lines are in the inner field, but the sulalaley doesn't like it if you're moving, your energy, and the sulength of superconductor.
2022-03-14 07:45:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:45:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, the big constructions of the face and reform it through information, which is the whole structure of information that all the structure and the structure of the structure.
2022-03-14 07:45:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:45:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me at tedwomen is that... "
2022-03-14 07:45:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:45:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of design work on our airplane, was a result that we had to solve, is that we had to solve the unique problems that were interconnected to the ground -- everything that you can use of a continuous system, and you can use it to use a low-cost system that allows us to be able to be able to use the engine to use of a low-cost system, to use of the engine, and make it to use of a very specific system, if you can be able to be able to use it to use of the engine, if you can be able to use of a very specific system, you can be able to use of the engine, or a very specific system, you can be able to use of the engine, or a very specific system that we can be able to use of the air, if you can be able to use of the air.
2022-03-14 07:45:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:45:42 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.607 | ppl 12.18 | bleu 20.08 | wps 4976.5 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 21.18
2022-03-14 07:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-14 07:45:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 16 @ 2507 updates, score 20.08) (writing took 1.067674851976335 seconds)
2022-03-14 07:45:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 07:45:43 | INFO | train | epoch 016 | loss 3.701 | ppl 13 | wps 45127 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.205 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1496
2022-03-14 07:45:43 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 07:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:46:12 | INFO | train_inner | epoch 017:     93 / 157 loss=3.545, ppl=11.67, wps=36239.4, ups=1.43, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.175, loss_scale=4, train_wall=30, gb_free=15.3, wall=1526
2022-03-14 07:46:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:46:36 | INFO | fairseq.tasks.translation | example hypothesis: and we put them in the clinic clinic on the clinic.
2022-03-14 07:46:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:46:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you know.
2022-03-14 07:46:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:46:44 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be created two new pigs.
2022-03-14 07:46:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:46:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are serving with salz and pills.
2022-03-14 07:46:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:46:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a few electrodes on his head and understand what all its thoughts are on the road.
2022-03-14 07:46:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:46:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the mature, as people took responsibility for wildlife, the number of wildlife animals, and that's a foundation for conservation in nambia.
2022-03-14 07:46:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:47:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodl of magnetic field, but the sulaluminum may not be able to move their energy, and so the soup of the supermovements, and so the soup of the superconductor of magnetic field is going on in the inside the inside the inner, but the inside the inside the inside the
2022-03-14 07:47:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:47:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, the gross of the face of the face and reform it through the information, which is the whole information, and the information, and the whole structure, and the information that all the information that we can fold and fold it.
2022-03-14 07:47:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:47:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, "yes, when somebody said," you know, you know, you know, you know, you know, the men and you say, "well, if we're going to support you," the truth is that we've been working with you guys, "you've got a silent truth for example, you guys,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] [is, you guys, you guys, you guys, you guys, we've got a long time, you guys, you're in this is that we've got a birthday, you guys, you guys, you guys, you guys, you guys, you guys, you've got a grain of the truth, you're
2022-03-14 07:47:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:47:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we have to solve in our plane, was that we had to solve the unique problems that we had to solve on the ground -- everything that it was connected to a refriction system, and that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the propelled by a major, or a high-tech, or a high-the-the-the-the-the-the-ground, or the propellellent, or a very, or a very, or a major, which is that if you, if you can be able to be able to be able to be able to be able to be able to see,
2022-03-14 07:47:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:47:13 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.493 | ppl 11.26 | bleu 23.09 | wps 4402.2 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 23.09
2022-03-14 07:47:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-14 07:47:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 17 @ 2664 updates, score 23.09) (writing took 2.183383945841342 seconds)
2022-03-14 07:47:15 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 07:47:15 | INFO | train | epoch 017 | loss 3.55 | ppl 11.72 | wps 42509.8 | ups 1.69 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.183 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1589
2022-03-14 07:47:16 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 07:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:47:28 | INFO | train_inner | epoch 018:     36 / 157 loss=3.487, ppl=11.21, wps=33375.7, ups=1.32, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.145, loss_scale=4, train_wall=30, gb_free=14.7, wall=1601
2022-03-14 07:47:59 | INFO | train_inner | epoch 018:    136 / 157 loss=3.334, ppl=10.08, wps=80467.1, ups=3.24, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.052, loss_scale=4, train_wall=30, gb_free=14.5, wall=1632
2022-03-14 07:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:48:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these little posters in the clinic.
2022-03-14 07:48:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:48:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of the most familiar here.
2022-03-14 07:48:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:48:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create two new pigs.
2022-03-14 07:48:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:48:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are being served with salt legs and fat.
2022-03-14 07:48:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:48:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all the thoughts are on the track.
2022-03-14 07:48:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:48:29 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, people like the responsibility for the wildlife survivors, grew the number of wildwildlife again, and that's a foundation for conservation.
2022-03-14 07:48:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:48:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic fields are caught in the inner field, but the superconductor doesn't like it if you're moving, you don't need your energy movements, and your energy energy.
2022-03-14 07:48:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:48:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big configuration of the face of the face and the basic constructions of the face, and the fundamental information, which is the whole structure, and all the structure.
2022-03-14 07:48:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:48:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measuring it to me here for me here in tedwomen, is that if we have a silent, "and then women," oh, you know, you know, "silent, you know, you know," silent, you know, "and then you have a silent truth," you know, "you know," you know, you know, you know, you know, you know, you know, you know, you're already, "silent," silent, "you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-14 07:48:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:48:45 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of design work that we're going to use in the plane until we're an aircraft, that we were a result of it, that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable system, and that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:48:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:48:45 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.22 | ppl 9.32 | bleu 25.49 | wps 4594.7 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 25.49
2022-03-14 07:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-14 07:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:48:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 18 @ 2821 updates, score 25.49) (writing took 2.1825213711708784 seconds)
2022-03-14 07:48:47 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 07:48:47 | INFO | train | epoch 018 | loss 3.331 | ppl 10.06 | wps 43086.3 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.016 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1681
2022-03-14 07:48:47 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 07:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:49:13 | INFO | train_inner | epoch 019:     79 / 157 loss=3.239, ppl=9.44, wps=34631.2, ups=1.35, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=1.003, loss_scale=4, train_wall=31, gb_free=14.3, wall=1706
2022-03-14 07:49:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:49:41 | INFO | fairseq.tasks.translation | example hypothesis: we made these little pure in the clinic.
2022-03-14 07:49:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:49:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most familiar here.
2022-03-14 07:49:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:49:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks, the two new pigs.
2022-03-14 07:49:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:49:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are salt legs and ppet.
2022-03-14 07:49:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:49:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:49:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:50:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the case, as humans took responsibility for wildlife, the number of wildwildlife has become again. and this is a foundation for conservation.
2022-03-14 07:50:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:50:05 | INFO | fairseq.tasks.translation | example hypothesis: first of all, there are some bament of magnetic field in the inner, but the supralongs don't like it when they move their energy, and so the superconductor of magnetic field.
2022-03-14 07:50:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:50:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can start with a traditional face of the face and restored it through the actual information that puts the entire structure and fold up.
2022-03-14 07:50:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:50:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me here is that, when a four-year, it was best summarized as somebody said, "washing you on your table, 'men in a table,' if we support you. '' '' em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt; / em & gt;
2022-03-14 07:50:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:50:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we were at our aircraft, was a result that we had to solve the unique problems so that it was connected to operations -- everything from a continuous variable and cooling system, and that allows us to use a refrigeration to make a refricicicible, and that allows us to use a refrigerator to use the cooler to make a refriction of the surface of the wall of the wall of the wall of the car car car car car car car car car, or a refricicicipiter to make it to make it to make it to make it, or a refriction.
2022-03-14 07:50:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:50:16 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.251 | ppl 9.52 | bleu 24.77 | wps 4725.1 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 25.49
2022-03-14 07:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-14 07:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:50:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:50:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 19 @ 2978 updates, score 24.77) (writing took 1.0552008470986038 seconds)
2022-03-14 07:50:17 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 07:50:17 | INFO | train | epoch 019 | loss 3.188 | ppl 9.12 | wps 44133.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.029 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1770
2022-03-14 07:50:17 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 07:50:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:50:24 | INFO | train_inner | epoch 020:     22 / 157 loss=3.113, ppl=8.65, wps=34670.9, ups=1.4, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.997, loss_scale=4, train_wall=30, gb_free=15.1, wall=1778
2022-03-14 07:50:56 | INFO | train_inner | epoch 020:    122 / 157 loss=3.02, ppl=8.11, wps=82100.7, ups=3.17, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.849, loss_scale=4, train_wall=31, gb_free=14.1, wall=1809
2022-03-14 07:51:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:51:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-14 07:51:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:51:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-14 07:51:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:51:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create the two new pigs.
2022-03-14 07:51:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:51:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frogs are being served with salz, and pinnacle.
2022-03-14 07:51:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:51:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-14 07:51:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:51:31 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation of how people took responsibility for wildlife, the number of wildwildlife has become a foundation for conservation in namibia.
2022-03-14 07:51:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:51:35 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some dramatic field are caught in the inside of the inner, but the superconductor doesn't like it if they're moving, and so the supermovements need energy, and so the supermovements of supermovements.
2022-03-14 07:51:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:51:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the groundings of the face, and the basic shape restored it through the one information that pulls the entire portion, and all the structure and fold it together.
2022-03-14 07:51:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:51:44 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to me here in tedwomen is that, in tedwomen is that -- yes, when the strip dinner was best summarized when somebody said, "turn you on the men in a table, and say," if the revolution starts to support you, "and say," the revolution, "we're going to help you know,"
2022-03-14 07:51:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:51:47 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a big part of the design work that we were at the aircraft, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous varied to a continuum, everything from a continued to a continuum, and a refrigerator system, and a liquid system that allows us to see the aircraft, or to see that if you could either see the most sophisticated, or an airplane, or the most sophisticated, or the most sophisticated, or the most sophisticated, or the most sophisticated, or the most sophisticated, or the most sophisticated, or a constant, or a constant, or a constant, or a constant, or a constant, or the most sophisticated, or the most sophisticated, or the most sophisticated, or a constant, or a constant system, or a constant, or a major major, or a constant,
2022-03-14 07:51:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:51:47 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.121 | ppl 8.7 | bleu 26.53 | wps 4482.7 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 26.53
2022-03-14 07:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-14 07:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:51:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:51:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 20 @ 3135 updates, score 26.53) (writing took 2.189757604151964 seconds)
2022-03-14 07:51:49 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 07:51:49 | INFO | train | epoch 020 | loss 3.013 | ppl 8.07 | wps 42851.6 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.921 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 1862
2022-03-14 07:51:49 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 07:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:52:10 | INFO | train_inner | epoch 021:     65 / 157 loss=2.928, ppl=7.61, wps=33610.7, ups=1.35, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=1.017, loss_scale=4, train_wall=30, gb_free=14.3, wall=1883
2022-03-14 07:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:52:42 | INFO | fairseq.tasks.translation | example hypothesis: we put these piebias in the clinic.
2022-03-14 07:52:42 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:52:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, the most familiar here.
2022-03-14 07:52:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:52:50 | INFO | fairseq.tasks.translation | example hypothesis: stars will be created new goldicks for the two new pigs.
2022-03-14 07:52:50 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:52:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salce and pcase.
2022-03-14 07:52:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:52:58 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-14 07:52:58 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:53:02 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildwildwildlife. and that's a foundation for conservaibia.
2022-03-14 07:53:02 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:53:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs are caught in magnetic field, but the superconductor doesn't like it, if you move, your energy will use, and so the superconductive disorder.
2022-03-14 07:53:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:53:10 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the groundings of the face, and the basic shape is repeating it through that whole structure and fold it all together.
2022-03-14 07:53:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:53:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me to be here at tedwomen, is that... yes, when it was best summarized when someone said, "turn you on the men in your table and tell them," if the revolution starts to support you. "
2022-03-14 07:53:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:53:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our aircraft, was a result of it that we had to solve the unique problems to operate on the ground -- everything from a continuous variation and a system of refrigeration system.
2022-03-14 07:53:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:53:16 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 2.992 | ppl 7.95 | bleu 27.14 | wps 4840.6 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 27.14
2022-03-14 07:53:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-14 07:53:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:53:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:53:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 21 @ 3292 updates, score 27.14) (writing took 2.3596354690380394 seconds)
2022-03-14 07:53:18 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 07:53:18 | INFO | train | epoch 021 | loss 2.927 | ppl 7.61 | wps 44268.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.938 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 1952
2022-03-14 07:53:18 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 07:53:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:53:21 | INFO | train_inner | epoch 022:      8 / 157 loss=2.946, ppl=7.71, wps=34680.6, ups=1.4, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.901, loss_scale=4, train_wall=30, gb_free=14.3, wall=1955
2022-03-14 07:53:52 | INFO | train_inner | epoch 022:    108 / 157 loss=2.818, ppl=7.05, wps=79739.6, ups=3.24, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.897, loss_scale=4, train_wall=30, gb_free=14.2, wall=1986
2022-03-14 07:54:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:54:11 | INFO | fairseq.tasks.translation | example hypothesis: we put these piebias in the clinic.
2022-03-14 07:54:11 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:54:15 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-14 07:54:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:54:19 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to be new goldilocks that are going to write two new pigs.
2022-03-14 07:54:19 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:54:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where happy legs are served with salz and pin.
2022-03-14 07:54:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:54:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on your head and understanding exactly what they're thinking about.
2022-03-14 07:54:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:54:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew again. and this is a foundation for conservation in namibia.
2022-03-14 07:54:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:54:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field are caught inside, but the superconductor doesn't like they're going to move, and the superconducting disorder.
2022-03-14 07:54:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:54:38 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constructures of the face and the basic shape regards it through the diechief of information, and reconstructing it through the tune of the information that pulls the entire ports of the information.
2022-03-14 07:54:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:54:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me here for women, "you know, you know," hire for your time. "
2022-03-14 07:54:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:54:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design, which allows us to solve a weapon or a refrigerator.
2022-03-14 07:54:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:54:43 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.028 | ppl 8.16 | bleu 25.13 | wps 5083.6 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 27.14
2022-03-14 07:54:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-14 07:54:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:54:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:54:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 22 @ 3449 updates, score 25.13) (writing took 1.065476925112307 seconds)
2022-03-14 07:54:44 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 07:54:44 | INFO | train | epoch 022 | loss 2.801 | ppl 6.97 | wps 45769.7 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.847 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 2038
2022-03-14 07:54:45 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 07:54:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:55:01 | INFO | train_inner | epoch 023:     51 / 157 loss=2.754, ppl=6.75, wps=37071.7, ups=1.45, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.752, loss_scale=4, train_wall=31, gb_free=14.2, wall=2054
2022-03-14 07:55:32 | INFO | train_inner | epoch 023:    151 / 157 loss=2.664, ppl=6.34, wps=82001.6, ups=3.23, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.834, loss_scale=4, train_wall=31, gb_free=14.2, wall=2085
2022-03-14 07:55:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:55:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietaller in the clinic.
2022-03-14 07:55:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:55:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know.
2022-03-14 07:55:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:55:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are making new goldicks that create two new pigs.
2022-03-14 07:55:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:55:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and ppepper.
2022-03-14 07:55:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:55:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and just understanding exactly what all his thoughts are on track.
2022-03-14 07:55:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:55:58 | INFO | fairseq.tasks.translation | example hypothesis: and it's a foundation for wildwildwildwildlife. and this is a foundation for conservation protection.
2022-03-14 07:55:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:56:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines are trapped inside, but the superconductor doesn't like the superconductor, if they're moving, because your movements are going to move around, because your energy is going to use energy, and so the superconductor.
2022-03-14 07:56:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:56:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial can begin with a traditional constructions that refuse the groundable constructures of the face of face and the fundamental shape, and the fundamental shape of the face of the face of face and the fundamental shape, which refuse it.
2022-03-14 07:56:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:56:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen's truth is that we've already been able to get rid of you. "
2022-03-14 07:56:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:56:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a great part of design work that we're using on our aircraft until the steady store is a result that we had to solve a result of being able to solve the most unique problems that have to solve the most unique problems we had to solve, which have to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to deal with
2022-03-14 07:56:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:56:15 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.095 | ppl 8.54 | bleu 26.59 | wps 4440.6 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.14
2022-03-14 07:56:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-14 07:56:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:56:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:56:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 23 @ 3606 updates, score 26.59) (writing took 1.0174043900333345 seconds)
2022-03-14 07:56:16 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 07:56:16 | INFO | train | epoch 023 | loss 2.689 | ppl 6.45 | wps 42973.6 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.812 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 2130
2022-03-14 07:56:17 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 07:56:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:56:46 | INFO | train_inner | epoch 024:     94 / 157 loss=2.646, ppl=6.26, wps=33607.3, ups=1.35, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.849, loss_scale=4, train_wall=30, gb_free=14.2, wall=2159
2022-03-14 07:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:57:09 | INFO | fairseq.tasks.translation | example hypothesis: we put these piezards in the clinic.
2022-03-14 07:57:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:57:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-14 07:57:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:57:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that create two new pigs.
2022-03-14 07:57:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:57:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pffer.
2022-03-14 07:57:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:57:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:57:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:57:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the name of how people took responsibility for wildlife, the number of wildwildanimals grew again, and that's a foundation for conservation in namibia.
2022-03-14 07:57:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:57:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic fields are caught inside the inside, but the superconductor doesn't like they're moving, because their movements use their energy, and the superconducting disorders.
2022-03-14 07:57:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:57:37 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial contextures that will refuse the big constructures of the face and the fundamental shape, and refuse it through the diech of the information that pulls up the whole porter structure and all the folds.
2022-03-14 07:57:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:57:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are going to be really interesting and appropriate for me to be here at tedwomen is that -- well, when the striking dinner was best summarized as someone said, "turn on the men in your desk and said to them," if the revolution starts to support you. '"the truth is that we've already supported for you."
2022-03-14 07:57:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:57:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big piece of design work that we have on our airplane on the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continually variable system and a refrigerated device that allows us to be able to be able to do with a refrigerator machine that is either of us.
2022-03-14 07:57:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:57:44 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.819 | ppl 7.05 | bleu 28.49 | wps 4754.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 28.49
2022-03-14 07:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-14 07:57:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:57:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 07:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 24 @ 3763 updates, score 28.49) (writing took 2.203942622989416 seconds)
2022-03-14 07:57:46 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 07:57:46 | INFO | train | epoch 024 | loss 2.612 | ppl 6.11 | wps 44018.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.786 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2219
2022-03-14 07:57:46 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 07:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:57:58 | INFO | train_inner | epoch 025:     37 / 157 loss=2.519, ppl=5.73, wps=35362.6, ups=1.39, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.726, loss_scale=4, train_wall=30, gb_free=14.4, wall=2232
2022-03-14 07:58:29 | INFO | train_inner | epoch 025:    137 / 157 loss=2.572, ppl=5.95, wps=80589.3, ups=3.22, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.797, loss_scale=4, train_wall=31, gb_free=14.3, wall=2263
2022-03-14 07:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:58:39 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters in the clinic.
2022-03-14 07:58:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:58:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably most of you here know.
2022-03-14 07:58:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:58:46 | INFO | fairseq.tasks.translation | example hypothesis: stars become new goldilocks that generate two pigs.
2022-03-14 07:58:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:58:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pffer.
2022-03-14 07:58:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:58:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:58:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:58:58 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife grew again. and this is a foundation for conservation in namibia.
2022-03-14 07:58:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:59:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bundle of magnetic field is trapped inside, but the superconductor doesn't like you move, because your movements use energy, and so the superconducting disorders.
2022-03-14 07:59:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:59:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial bubble that has the great constructions of the face and the basic shape repeats it through the dietrich that pulls all the porter structure and fits into a fold.
2022-03-14 07:59:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:59:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when argued dinner was best summarized as someone said, "turning you to the men on your desk and say to you," if the revolution begins to support you. "the truth begins to help you." 'the truth is that we support women here is that... "
2022-03-14 07:59:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:59:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large piece of design work that we're on our airplane at the proud toceest was a result that we had to solve the unique problems that were connected to the ground -- all of a continuous variables and a large part of the refrigerators and a refrigerating system that allows us to be able to make it a refrigerated by the aircraft.
2022-03-14 07:59:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:59:12 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.831 | ppl 7.11 | bleu 27.87 | wps 4958.4 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.49
2022-03-14 07:59:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-14 07:59:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:59:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 07:59:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 25 @ 3920 updates, score 27.87) (writing took 0.9566597661469132 seconds)
2022-03-14 07:59:13 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 07:59:13 | INFO | train | epoch 025 | loss 2.53 | ppl 5.78 | wps 45419.2 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.776 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 2306
2022-03-14 07:59:13 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 07:59:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:59:38 | INFO | train_inner | epoch 026:     80 / 157 loss=2.429, ppl=5.38, wps=36657.3, ups=1.44, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.728, loss_scale=4, train_wall=30, gb_free=14.3, wall=2332
2022-03-14 08:00:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:00:06 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietaller in the clinic.
2022-03-14 08:00:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:00:10 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, most of you know here.
2022-03-14 08:00:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:00:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks beds that create the two new sponsors.
2022-03-14 08:00:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:00:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-14 08:00:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:00:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-14 08:00:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:00:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like the people of responsibility for wildlife, the number of wildlife grew again. and this is a foundation for conservation in namibia.
2022-03-14 08:00:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:00:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field is trapped inside, but the superconductor doesn't like you if you move, because your energy movements use, and so the superconducting disorder.
2022-03-14 08:00:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:00:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we take the information that comes from this reflection, we can start with a traditional face that is the size of the face and the foundations of the face and the basic framework, and refuse it through the thetheft of information that pulls up the entire pordal structure and all the fits.
2022-03-14 08:00:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:00:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me here at tedwomen here is that... well, when the strictly dinner was best summarized as someone said, "turn on the men in your desk, and tell you," if the revolution begins to support you. "
2022-03-14 08:00:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:00:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane on the stest of the day, was a result of being able to solve the unique problems that were linked to operate on the ground -- everything from a continuous variables and a system of refrigeration that allows us to be used to be available in the vehicle, which is something that we have to be used to be driven by a mechanism, which is either propellyielism, which is a device that we have to be connected to be available to be done, which is available to be able to be able to be available to be done by a mechanism.
2022-03-14 08:00:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:00:42 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.727 | ppl 6.62 | bleu 29.91 | wps 4562.1 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.91
2022-03-14 08:00:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-14 08:00:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:00:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:00:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.91) (writing took 2.1436297830659896 seconds)
2022-03-14 08:00:44 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 08:00:44 | INFO | train | epoch 026 | loss 2.434 | ppl 5.4 | wps 43345.4 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.743 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2398
2022-03-14 08:00:44 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 08:00:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:00:52 | INFO | train_inner | epoch 027:     23 / 157 loss=2.394, ppl=5.26, wps=33965.5, ups=1.36, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.737, loss_scale=4, train_wall=30, gb_free=15.2, wall=2405
2022-03-14 08:01:23 | INFO | train_inner | epoch 027:    123 / 157 loss=2.398, ppl=5.27, wps=80839.3, ups=3.23, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.75, loss_scale=4, train_wall=31, gb_free=14, wall=2436
2022-03-14 08:01:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:01:37 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piezards in the clinic.
2022-03-14 08:01:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:01:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-14 08:01:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:01:45 | INFO | fairseq.tasks.translation | example hypothesis: stars become new goldilocks vents that generate two new pigs.
2022-03-14 08:01:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:01:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and psuitcase.
2022-03-14 08:01:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:01:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:01:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:01:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people adopted responsibility for wildlife, the number of wildwildwildlife grew again, and this is a foundation for conservation in namibia.
2022-03-14 08:01:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:02:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field captured inside, but the superconductor doesn't like if you move, because your energy uses energy, and so the superconduction.
2022-03-14 08:02:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:02:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, the larger connotes of the face and the basic shape, and reconcile it through the diech of that information that pulls the whole portion structure and all the fold.
2022-03-14 08:02:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:02:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and appropriate for me to be here at tedwomen, is that... well, when a strict dinner was best than someone said, "turn you to the men in your desk and tell you, 'if the revolution begins to support you.' the truth is that we've been supporting you this topic for a long time."
2022-03-14 08:02:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:02:09 | INFO | fairseq.tasks.translation | example hypothesis: thankfully, the mother of invention, and a large piece of design work that we're at our airplane on the stest toes was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from one continuous variables and cooling system that allows us to use aircraft.
2022-03-14 08:02:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:02:09 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.704 | ppl 6.52 | bleu 29.25 | wps 5100.1 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.91
2022-03-14 08:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-14 08:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 27 @ 4234 updates, score 29.25) (writing took 1.1044082529842854 seconds)
2022-03-14 08:02:10 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 08:02:10 | INFO | train | epoch 027 | loss 2.36 | ppl 5.13 | wps 45765.5 | ups 1.82 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.721 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2484
2022-03-14 08:02:11 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 08:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:02:31 | INFO | train_inner | epoch 028:     66 / 157 loss=2.277, ppl=4.85, wps=36390.1, ups=1.46, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.696, loss_scale=4, train_wall=30, gb_free=15.1, wall=2505
2022-03-14 08:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:03:03 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsters up in the clinic.
2022-03-14 08:03:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:03:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, probably most of you here.
2022-03-14 08:03:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:03:11 | INFO | fairseq.tasks.translation | example hypothesis: stars become new goldilocks that generate two new pigs.
2022-03-14 08:03:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:03:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pin.
2022-03-14 08:03:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:03:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:03:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:03:23 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife, the number of wildlife grew back. and this is a foundation for conservation in namibia.
2022-03-14 08:03:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:03:27 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like if they move, because their movements use energy, and so the superconducting disorder.
2022-03-14 08:03:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:03:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the great contexts of the face, and the basic shape, and then recover it through the diech structure and all the folds.
2022-03-14 08:03:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:03:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when striking dinner was best summarized as someone said, "turn on the men in your desk and say," if the revolution starts to support you. '"'" the truth is that we've been supporting you for a long time. "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-14 08:03:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:03:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane on the stest toes was a result that we had to solve the unique problems that were connected to operate on the ground -- all, from one continuous variables and a cooler system that allows us to use a machine in the fly, to be able to be able to be able to be able to use the car traffic, to be able to be able to be able to be able to be able to do it.
2022-03-14 08:03:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:03:38 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.648 | ppl 6.27 | bleu 30.81 | wps 4723.8 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.81
2022-03-14 08:03:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-14 08:03:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:03:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.81) (writing took 2.2505640930030495 seconds)
2022-03-14 08:03:40 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 08:03:40 | INFO | train | epoch 028 | loss 2.283 | ppl 4.87 | wps 43940.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.721 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 2574
2022-03-14 08:03:40 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 08:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:03:43 | INFO | train_inner | epoch 029:      9 / 157 loss=2.314, ppl=4.97, wps=34984.6, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.746, loss_scale=4, train_wall=30, gb_free=14, wall=2577
2022-03-14 08:04:14 | INFO | train_inner | epoch 029:    109 / 157 loss=2.195, ppl=4.58, wps=80685.6, ups=3.21, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.678, loss_scale=4, train_wall=31, gb_free=14, wall=2608
2022-03-14 08:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsters in the clinic.
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:04:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-14 08:04:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:04:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be able to cross two new sponsors.
2022-03-14 08:04:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:04:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:04:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:04:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly exactly what all of his thoughts are on the track.
2022-03-14 08:04:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:04:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew again, and this has become a basis for conservation in namibia.
2022-03-14 08:04:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:04:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like when they move, because their energy use, and so the superconducting disorder.
2022-03-14 08:04:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:05:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that resembles the larger constructions of the face and the basic shape, and refuses it through the diek structure and all the fits.
2022-03-14 08:05:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:05:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men at your desk and tell you," if the revolution begins, "the truth is that we've been supporting you on this topic for a long time."
2022-03-14 08:05:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:05:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large piece of design work that we have on our airplane on the stumest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a cooling system that allows us to have a refrigeration machine in the till we can see that we can use to the contract, or to the contractors of a specific vehicle, or when you can see the power of a mechanism, or when you can see the power to the power of a mechanism.
2022-03-14 08:05:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:05:08 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.646 | ppl 6.26 | bleu 30.61 | wps 4705.3 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.81
2022-03-14 08:05:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-14 08:05:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:05:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 29 @ 4548 updates, score 30.61) (writing took 1.0593946818262339 seconds)
2022-03-14 08:05:10 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 08:05:10 | INFO | train | epoch 029 | loss 2.195 | ppl 4.58 | wps 44152.4 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.676 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2663
2022-03-14 08:05:10 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 08:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:05:26 | INFO | train_inner | epoch 030:     52 / 157 loss=2.144, ppl=4.42, wps=34854.5, ups=1.39, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.64, loss_scale=4, train_wall=30, gb_free=14.3, wall=2680
2022-03-14 08:05:57 | INFO | train_inner | epoch 030:    152 / 157 loss=2.1, ppl=4.29, wps=82199.1, ups=3.25, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.597, loss_scale=4, train_wall=30, gb_free=15.1, wall=2711
2022-03-14 08:05:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:06:03 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piezards in the clinic.
2022-03-14 08:06:03 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:06:07 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline from doha that probably most of you here know.
2022-03-14 08:06:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:06:11 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks bricks that will generate the two new pigs transcend.
2022-03-14 08:06:11 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:06:14 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-14 08:06:14 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:06:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on its head and understanding exactly what all its thoughts are on the track.
2022-03-14 08:06:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:06:23 | INFO | fairseq.tasks.translation | example hypothesis: and in the dimensions of how people took responsibility for wildlife, the number of wildlife grew again, and this is a foundation for conservation in namibia.
2022-03-14 08:06:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:06:27 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are trapped inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconducting disorder.
2022-03-14 08:06:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:06:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the big contours of the face, and the basic shape replicating it through the diek information that pulls the whole portion and all the fine folds.
2022-03-14 08:06:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:06:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when striped dinner, it was best summarized as someone said, "turn to men on your desk and tell you, 'if the revolution begins, then we will support you.'" the truth is that we have you on this topic for a long time. "
2022-03-14 08:06:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:06:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from one continuous variables and a refrigerating system, that allows us to use an aircraft to be able to create a constructive traffic, or to make sure that we're going to make it's reliable, or when you're going to be able to make a more propellant.
2022-03-14 08:06:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:06:38 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.607 | ppl 6.09 | bleu 31.3 | wps 4641 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 31.3
2022-03-14 08:06:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-14 08:06:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:06:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 30 @ 4705 updates, score 31.3) (writing took 2.152920436114073 seconds)
2022-03-14 08:06:40 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 08:06:40 | INFO | train | epoch 030 | loss 2.093 | ppl 4.27 | wps 43573 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.612 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2754
2022-03-14 08:06:41 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 08:06:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:07:11 | INFO | train_inner | epoch 031:     95 / 157 loss=2.089, ppl=4.25, wps=34796.1, ups=1.36, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.727, loss_scale=4, train_wall=31, gb_free=14, wall=2784
2022-03-14 08:07:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:07:33 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piezards in the clinic.
2022-03-14 08:07:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:07:37 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that i think most of you here.
2022-03-14 08:07:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:07:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks functions that create the two new pigs headed.
2022-03-14 08:07:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:07:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-14 08:07:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:07:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-14 08:07:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:07:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the sense of how people took responsibility for wildlife, the number of wildlife grew back. and that's become a foundation for conservation in namibia.
2022-03-14 08:07:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:07:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it if they move around, because their movements use their energy, and so the superconduction.
2022-03-14 08:07:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:08:02 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the big contextures of the face and the basic shape replicating it through the diechest information that pulls the whole porter structure and all the fits into a fold.
2022-03-14 08:08:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:08:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... well, when strictly dinner, it was best known as someone said, "turn your men on your desk and say to you," if the revolution begins, we support you. '"the truth is that we've been supporting you this issue for a long time."
2022-03-14 08:08:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:08:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big piece of design work that we're at our aircraft on the proud toes was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable drive and a cooling system of refrigeration, that allows us to use an aircraft, until you can see a flying space, or when you're getting rid of a flying, or propelled by propelled by propelled by a fluid, or aggressive storm, which is either propelled by a steady, you can see the soil, or when you can see the soil, you can see the stairs, you can see the motor motor motor motor motor motor motor motor motor motor motor motor motor motor motor motor system, you can see as well.
2022-03-14 08:08:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:08:08 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.594 | ppl 6.04 | bleu 31.47 | wps 4656.6 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 31.47
2022-03-14 08:08:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-14 08:08:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:08:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:08:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 31 @ 4862 updates, score 31.47) (writing took 2.1987357169855386 seconds)
2022-03-14 08:08:11 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 08:08:11 | INFO | train | epoch 031 | loss 2.078 | ppl 4.22 | wps 43694.5 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.686 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2844
2022-03-14 08:08:11 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 08:08:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:08:23 | INFO | train_inner | epoch 032:     38 / 157 loss=1.986, ppl=3.96, wps=34343.4, ups=1.38, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.588, loss_scale=4, train_wall=30, gb_free=14.7, wall=2857
2022-03-14 08:08:54 | INFO | train_inner | epoch 032:    138 / 157 loss=1.998, ppl=3.99, wps=81086.4, ups=3.21, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.648, loss_scale=4, train_wall=31, gb_free=14.8, wall=2888
2022-03-14 08:09:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:09:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieples in the clinic.
2022-03-14 08:09:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:09:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of us know.
2022-03-14 08:09:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:09:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks overwhelmed two new pigs.
2022-03-14 08:09:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:09:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:09:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:09:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on its head and understanding exactly what all its thoughts are on the track.
2022-03-14 08:09:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:09:23 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as humans took responsibility for wildlife, the wildlife population grew back. and this is a basis for conservation in namibia.
2022-03-14 08:09:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:09:27 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like moving, because their movements use energy, and so the superconduction.
2022-03-14 08:09:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:09:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from that mirror reflection, we can start with a traditional facial can, which is the larger contextures of the face, and the basic shape, and then adding it through the one information that includes the whole porter structure and all the fits.
2022-03-14 08:09:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:09:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and appropriate for me to be here at tedwomen is that -- well, when strict dinner, it was best, than somebody said, "turn you to the men on your desk," and tell them, "if the revolution begins, then we support you. '" the truth, love is that we've been supporting you in this topic for a long time. "by carrimp," and then carpins, "and then, by the way," and then, "and then," and then, by the way, "and then," and then, "by the way," and then, "and then," and then, "by the way," and then, "by the way," and then, "by the way," by the way, "by the way,"
2022-03-14 08:09:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:09:38 | INFO | fairseq.tasks.translation | example hypothesis: luckily, mother is still the invention, and a large part of the design work that we're on on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable system and a refrigeration system, that allows us to use an aircraft, to use a gateway to a mess, to a specialist traffic, to a pure force force, to a propulsion system, to a propulsion force force force force force force, to which is either, which is propelled by propelled by propelled by the land.
2022-03-14 08:09:38 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:09:38 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.631 | ppl 6.19 | bleu 30.46 | wps 4748.6 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 31.47
2022-03-14 08:09:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-14 08:09:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:09:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:09:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 32 @ 5019 updates, score 30.46) (writing took 0.8950866949744523 seconds)
2022-03-14 08:09:39 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 08:09:39 | INFO | train | epoch 032 | loss 1.972 | ppl 3.92 | wps 44624.2 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.623 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 2933
2022-03-14 08:09:39 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 08:09:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:10:05 | INFO | train_inner | epoch 033:     81 / 157 loss=1.884, ppl=3.69, wps=35522.6, ups=1.42, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.611, loss_scale=4, train_wall=30, gb_free=14.4, wall=2958
2022-03-14 08:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:10:32 | INFO | fairseq.tasks.translation | example hypothesis: we put these pieples in the clinic.
2022-03-14 08:10:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:10:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here know.
2022-03-14 08:10:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:10:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks comments that create the two new pigs.
2022-03-14 08:10:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:10:45 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:10:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:10:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-14 08:10:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:10:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back up again, and this is a basis for conservation in namibia.
2022-03-14 08:10:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:10:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like when they move, because their movements use, and so the superconducting disorder.
2022-03-14 08:10:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:11:01 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this reflection, we can start with a traditional facial can, which is the size of the face and the basic form, and we can add it through the dieture of that information that pulls the whole porter structure and all the fits.
2022-03-14 08:11:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:11:06 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been very interesting and measured to me here at tedwomen is that... well, while striking dinner was best summarized, when someone said, "turn on the men in your desk and tell them, 'if the revolution begins, then we will support you.'" the truth, women, we have been supporting you this topic for a long time. "
2022-03-14 08:11:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:11:08 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work that we're on on on our airplane the proud toes was a product of the fact that we had to solve the unique problems associated with it, to operate on the ground -- everything from a continuously variables and a cooling system of refrigeration, that allows us to see a flying machine in the go-and-traffic, all the way down to the propelled, except for propelled, or when you can see the trajectory.
2022-03-14 08:11:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:11:08 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.575 | ppl 5.96 | bleu 32.16 | wps 4617.5 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 32.16
2022-03-14 08:11:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-14 08:11:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:11:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt
2022-03-14 08:11:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_best.pt (epoch 33 @ 5176 updates, score 32.16) (writing took 2.1101919000502676 seconds)
2022-03-14 08:11:10 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 08:11:10 | INFO | train | epoch 033 | loss 1.914 | ppl 3.77 | wps 43253.3 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.615 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 3024
2022-03-14 08:11:11 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 08:11:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:11:19 | INFO | train_inner | epoch 034:     24 / 157 loss=1.933, ppl=3.82, wps=33847.9, ups=1.35, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.622, loss_scale=4, train_wall=30, gb_free=14.2, wall=3033
2022-03-14 08:11:50 | INFO | train_inner | epoch 034:    124 / 157 loss=1.838, ppl=3.58, wps=81015.2, ups=3.22, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.618, loss_scale=4, train_wall=31, gb_free=14.1, wall=3064
2022-03-14 08:12:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:12:05 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep up in the clinic.
2022-03-14 08:12:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:12:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here know.
2022-03-14 08:12:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:12:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks conditions that will transcend the two new pigs.
2022-03-14 08:12:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:12:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:12:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:12:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring up some electrodes on its head and understand exactly what all of its thoughts are on the track.
2022-03-14 08:12:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:12:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew again, and this is a foundation for conservation in namibia.
2022-03-14 08:12:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:12:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like if they move, because their movements use their energy, and so the superconducting disorder.
2022-03-14 08:12:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:12:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which is the great constraints of the face, and the basic shape, and then advances it through the diech of the information that pulls the entire porter structure and all the fits into a folder.
2022-03-14 08:12:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:12:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that is highly interesting and appropriate for me to be here at tedwomen is that -- well, while striking dinner, it's best summoned, when somebody said, "turn you to men in your desk and tell you, 'if the revolution begins, then we will support you.'" the truth of the women is that we've already been supporting you for a long time. "
2022-03-14 08:12:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:12:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work that we're on on on our airplane on the trigger was a result that we had to solve the unique problems associated with it to operate on the ground -- everything from a continuous variables, and a cooling system with a refrigeration that allows us to use a gourmet machine in the golish traffic, until one of the most specifications that would be able to make it possible for the land, or when you see the land, or the land, which is either of the land, which is a dear, which is a gust, which is the land, and the land, all the land, which is the land, which is the earth, except for a stable, which is the land, which is the land, which is the land, which is the land, except for the land that allows you can be able, except for the land, which is either, to be able, which is a single, and the
2022-03-14 08:12:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:12:41 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.597 | ppl 6.05 | bleu 32.01 | wps 4542.4 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 32.16
2022-03-14 08:12:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-14 08:12:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:12:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 34 @ 5333 updates, score 32.01) (writing took 1.0427990059833974 seconds)
2022-03-14 08:12:42 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 08:12:42 | INFO | train | epoch 034 | loss 1.853 | ppl 3.61 | wps 43200.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.624 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3115
2022-03-14 08:12:42 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 08:12:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:13:03 | INFO | train_inner | epoch 035:     67 / 157 loss=1.837, ppl=3.57, wps=34477.3, ups=1.37, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.637, loss_scale=4, train_wall=30, gb_free=15.1, wall=3137
2022-03-14 08:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:13:35 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep beep in the clinic.
2022-03-14 08:13:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:13:39 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here know.
2022-03-14 08:13:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:13:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks beds that generate two new pigs overwhelmed.
2022-03-14 08:13:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:13:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salt and pepper.
2022-03-14 08:13:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:13:50 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on its head and understanding exactly what all its thoughts are on the track.
2022-03-14 08:13:50 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:13:54 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of humans taking responsibility for wildlife, wildlife grew up again, and this is a basis for conservation in namibia.
2022-03-14 08:13:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:13:59 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like, if you move, because your movements use energy, and so the superconducting disorder.
2022-03-14 08:13:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:14:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we take advantage of the information coming from this mirror reflection, we can start with a traditional facial control, which is the big contours of the face, and the basic shape, and then you add it through that one information that includes the whole porter structure, and all the folding folds.
2022-03-14 08:14:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:14:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that... yes, when dinner was best summarized, when somebody said, "turn on the men on your desk and tell them, 'if the revolution begins, we will support you.'" the truth, women is that we've been supporting you for a long time. "& lt; em & gt; & lt; / em & gt;"
2022-03-14 08:14:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:14:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a lot of the design work we're at the proud airplane was a result of the fact that we had to solve the unique problems associated with it -- everything from a continuous variable system and a cooling system of refrigeration, that allows us to use an aircraft in the go-style transport to a particular vehicle, or when you're crummy car system, or when you're going to be able to get rid of it, if you see it's reliable, or when you see it's reliable, you're going to do it's reliable, you're either propelled to do it, and you're going to be able, you're going to move it's reliable, you're going to be able, and you're going to be able, and you're going to be able, and you're going to be able, you're going to be able to do it, and you can see it -- everything from one, and you can see it's
2022-03-14 08:14:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:14:10 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.601 | ppl 6.07 | bleu 31.66 | wps 4668.2 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 32.16
2022-03-14 08:14:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-14 08:14:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:14:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 35 @ 5490 updates, score 31.66) (writing took 1.0328873659018427 seconds)
2022-03-14 08:14:11 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 08:14:11 | INFO | train | epoch 035 | loss 1.793 | ppl 3.47 | wps 44280.1 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.614 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 3205
2022-03-14 08:14:11 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 08:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:14:15 | INFO | train_inner | epoch 036:     10 / 157 loss=1.784, ppl=3.44, wps=34833.4, ups=1.4, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.6, loss_scale=4, train_wall=30, gb_free=15.1, wall=3208
2022-03-14 08:14:46 | INFO | train_inner | epoch 036:    110 / 157 loss=1.726, ppl=3.31, wps=81016.6, ups=3.2, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.605, loss_scale=4, train_wall=31, gb_free=15.1, wall=3239
2022-03-14 08:15:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:15:04 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepans in the clinic.
2022-03-14 08:15:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:15:08 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here know.
2022-03-14 08:15:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:15:12 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks conditions that will generate these two new pigs.
2022-03-14 08:15:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:15:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:15:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:15:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-14 08:15:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:15:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, wildlife grew up again, and that's a basis for conservation in the wildlife of conservation in namibia.
2022-03-14 08:15:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:15:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like moving, because their movements use their energy, and so the superconductivity.
2022-03-14 08:15:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:15:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this reflection, we can start with a traditional facial can, which is the size of the face, and then recover it through the one that pulls the entire porter structure, and all the folds into it.
2022-03-14 08:15:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:15:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's been highly interesting and attached to me here at tedwomen is that... well, in the controversial dinner, it's best summarized when somebody said, "turn on the men on your desk and tell them, 'if the revolution begins, we're going to support you.' '"' the truth of the truth is that we've been supporting you for a long time.
2022-03-14 08:15:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:15:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a lot of the design work that we're on on on on on our plane at the proud toes was a result that we had to solve the unique problems associated with operating on the ground -- everything from one continuous variables and a cool-cooling system of the design, that allows us to use aircraft till one of the most proud traffic, to the most vulnerable, to be driven by the most reliable, to the propellant, to which is either by the most vulnerable, to the country, which is the most reliable, to be driven by a continuous storm, to the most vulnerable, to the country, to the most vulnerable, all, all, to the vehicle vehicle system, to the most, to the point where you had to the point where you would be driven by a continuously variant, to the most ungest, to the country, to the most unleasm, to be able, to be able, to be able in the
2022-03-14 08:15:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:15:40 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.609 | ppl 6.1 | bleu 31.91 | wps 4577.9 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 32.16
2022-03-14 08:15:40 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 08:15:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-14 08:15:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:15:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt
2022-03-14 08:15:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.15/checkpoint_last.pt (epoch 36 @ 5647 updates, score 31.91) (writing took 0.9834785819984972 seconds)
2022-03-14 08:15:41 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 08:15:41 | INFO | train | epoch 036 | loss 1.74 | ppl 3.34 | wps 43928.5 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.613 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3294
2022-03-14 08:15:41 | INFO | fairseq_cli.train | done training in 3294.0 seconds
