Sender: LSF System <lsfadmin@eu-g3-074>
Subject: Job 208123762: <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.015_0.06_0.925_#1> in cluster <euler> Exited

Job <wikitext-103-cleaned-bpe-size0.0625_jelinek_0.015_0.06_0.925_#1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 10:24:52 2022
Job was executed on host(s) <eu-g3-074>, in queue <gpuhe.120h>, as user <andriusb> in cluster <euler> at Mon Mar 14 16:39:06 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 16:39:06 2022
Terminated at Tue Mar 15 06:20:18 2022
Results reported at Tue Mar 15 06:20:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.015, 0.06, 0.925)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --no-epoch-checkpoints --seed 1321671 --no-epoch-checkpoints --fp16 --max-update 50000
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   49160.97 sec.
    Max Memory :                                 5104 MB
    Average Memory :                             3475.80 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14896.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   49264 sec.
    Turnaround time :                            71726 sec.

The output (if any) follows:

2022-03-14 16:40:28 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1321671, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1321671, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.015, 0.06, 0.925)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 16:40:28 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-14 16:40:29 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
Calculating frequency stats:
  0%|          | 0/112584 [00:00<?, ?it/s]  1%|          | 658/112584 [00:00<00:17, 6544.49it/s]  1%|          | 1313/112584 [00:00<00:19, 5808.94it/s]  2%|▏         | 1900/112584 [00:00<00:19, 5686.29it/s]  2%|▏         | 2472/112584 [00:00<00:19, 5605.17it/s]  3%|▎         | 3196/112584 [00:00<00:17, 6161.82it/s]  3%|▎         | 3816/112584 [00:00<00:17, 6077.85it/s]  4%|▍         | 4533/112584 [00:00<00:16, 6422.96it/s]  5%|▍         | 5249/112584 [00:00<00:16, 6650.37it/s]  5%|▌         | 5935/112584 [00:00<00:15, 6705.55it/s]  6%|▌         | 6608/112584 [00:01<00:17, 6145.26it/s]  6%|▋         | 7233/112584 [00:01<00:17, 6159.20it/s]  7%|▋         | 7856/112584 [00:01<00:17, 6097.88it/s]  8%|▊         | 8471/112584 [00:01<00:17, 5940.98it/s]  8%|▊         | 9131/112584 [00:01<00:16, 6128.18it/s]  9%|▊         | 9748/112584 [00:01<00:17, 6032.10it/s]  9%|▉         | 10399/112584 [00:01<00:16, 6169.95it/s] 10%|▉         | 11019/112584 [00:01<00:16, 6147.48it/s] 10%|█         | 11636/112584 [00:01<00:16, 5978.19it/s] 11%|█         | 12275/112584 [00:02<00:16, 6093.42it/s] 11%|█▏        | 12891/112584 [00:02<00:16, 6110.28it/s] 12%|█▏        | 13595/112584 [00:02<00:15, 6377.97it/s] 13%|█▎        | 14235/112584 [00:02<00:15, 6226.83it/s] 13%|█▎        | 14878/112584 [00:02<00:15, 6284.79it/s] 14%|█▍        | 15508/112584 [00:02<00:15, 6137.68it/s] 14%|█▍        | 16124/112584 [00:02<00:16, 5755.46it/s] 15%|█▍        | 16706/112584 [00:02<00:16, 5768.75it/s] 15%|█▌        | 17383/112584 [00:02<00:15, 6052.68it/s] 16%|█▌        | 17993/112584 [00:02<00:15, 6050.48it/s] 17%|█▋        | 18601/112584 [00:03<00:15, 5928.46it/s] 17%|█▋        | 19440/112584 [00:03<00:14, 6635.96it/s] 18%|█▊        | 20108/112584 [00:03<00:14, 6301.00it/s] 18%|█▊        | 20744/112584 [00:03<00:14, 6220.02it/s] 19%|█▉        | 21370/112584 [00:03<00:15, 5908.58it/s] 20%|█▉        | 22010/112584 [00:03<00:14, 6043.56it/s] 20%|██        | 22655/112584 [00:03<00:14, 6156.61it/s] 21%|██        | 23294/112584 [00:03<00:14, 6222.44it/s] 21%|██▏       | 24068/112584 [00:03<00:13, 6665.49it/s] 22%|██▏       | 24788/112584 [00:03<00:12, 6820.49it/s] 23%|██▎       | 25473/112584 [00:04<00:12, 6714.81it/s] 23%|██▎       | 26147/112584 [00:04<00:13, 6422.21it/s] 24%|██▍       | 26793/112584 [00:04<00:14, 6030.35it/s] 24%|██▍       | 27403/112584 [00:04<00:14, 5900.77it/s] 25%|██▍       | 28001/112584 [00:04<00:14, 5918.31it/s] 26%|██▌       | 28747/112584 [00:04<00:13, 6347.94it/s] 26%|██▌       | 29387/112584 [00:04<00:13, 6035.97it/s] 27%|██▋       | 30083/112584 [00:04<00:13, 6286.72it/s] 27%|██▋       | 30718/112584 [00:04<00:13, 5901.47it/s] 28%|██▊       | 31316/112584 [00:05<00:13, 5842.31it/s] 28%|██▊       | 31916/112584 [00:05<00:13, 5883.63it/s] 29%|██▉       | 32509/112584 [00:05<00:13, 5877.50it/s] 29%|██▉       | 33100/112584 [00:05<00:13, 5684.04it/s] 30%|██▉       | 33694/112584 [00:05<00:13, 5756.35it/s] 30%|███       | 34282/112584 [00:05<00:13, 5787.84it/s] 31%|███       | 35001/112584 [00:05<00:12, 6192.52it/s] 32%|███▏      | 35623/112584 [00:05<00:12, 6035.56it/s] 32%|███▏      | 36239/112584 [00:05<00:12, 6071.24it/s] 33%|███▎      | 36848/112584 [00:06<00:12, 6008.66it/s] 33%|███▎      | 37451/112584 [00:06<00:13, 5685.46it/s] 34%|███▍      | 38024/112584 [00:06<00:13, 5677.28it/s] 34%|███▍      | 38631/112584 [00:06<00:12, 5789.09it/s] 35%|███▍      | 39280/112584 [00:06<00:12, 5992.93it/s] 35%|███▌      | 39882/112584 [00:06<00:12, 5983.80it/s] 36%|███▌      | 40567/112584 [00:06<00:11, 6237.37it/s] 37%|███▋      | 41193/112584 [00:06<00:11, 6197.70it/s] 37%|███▋      | 41814/112584 [00:06<00:12, 5884.92it/s] 38%|███▊      | 42407/112584 [00:06<00:12, 5711.89it/s] 38%|███▊      | 42989/112584 [00:07<00:12, 5736.80it/s] 39%|███▊      | 43605/112584 [00:07<00:11, 5854.78it/s] 39%|███▉      | 44216/112584 [00:07<00:11, 5928.90it/s] 40%|███▉      | 44887/112584 [00:07<00:10, 6158.06it/s] 40%|████      | 45519/112584 [00:07<00:10, 6201.84it/s] 41%|████      | 46206/112584 [00:07<00:10, 6400.00it/s] 42%|████▏     | 46848/112584 [00:07<00:10, 6232.01it/s] 43%|████▎     | 47852/112584 [00:07<00:08, 7346.53it/s] 43%|████▎     | 48591/112584 [00:07<00:08, 7138.22it/s] 44%|████▍     | 49316/112584 [00:08<00:08, 7164.33it/s] 44%|████▍     | 50036/112584 [00:08<00:09, 6836.58it/s] 45%|████▌     | 50725/112584 [00:08<00:09, 6325.01it/s] 46%|████▌     | 51367/112584 [00:08<00:09, 6164.53it/s] 46%|████▋     | 52081/112584 [00:08<00:09, 6423.38it/s] 47%|████▋     | 52843/112584 [00:08<00:08, 6757.94it/s] 48%|████▊     | 53526/112584 [00:08<00:09, 6434.60it/s] 48%|████▊     | 54177/112584 [00:08<00:09, 6287.19it/s] 49%|████▊     | 54811/112584 [00:08<00:09, 6089.87it/s] 49%|████▉     | 55426/112584 [00:09<00:09, 6101.86it/s] 50%|████▉     | 56145/112584 [00:09<00:08, 6411.62it/s] 50%|█████     | 56790/112584 [00:09<00:09, 6050.81it/s] 51%|█████     | 57401/112584 [00:09<00:09, 5793.39it/s] 52%|█████▏    | 58046/112584 [00:09<00:09, 5974.28it/s] 52%|█████▏    | 58797/112584 [00:09<00:08, 6404.02it/s] 53%|█████▎    | 59444/112584 [00:09<00:08, 6072.05it/s] 53%|█████▎    | 60059/112584 [00:09<00:08, 6010.53it/s] 54%|█████▍    | 60694/112584 [00:09<00:08, 6106.36it/s] 55%|█████▍    | 61469/112584 [00:09<00:07, 6576.49it/s] 55%|█████▌    | 62132/112584 [00:10<00:08, 6295.37it/s] 56%|█████▌    | 62767/112584 [00:10<00:07, 6241.63it/s] 56%|█████▋    | 63395/112584 [00:10<00:08, 6098.06it/s] 57%|█████▋    | 64023/112584 [00:10<00:07, 6149.94it/s] 57%|█████▋    | 64641/112584 [00:10<00:07, 6108.48it/s] 58%|█████▊    | 65254/112584 [00:10<00:07, 6054.21it/s] 59%|█████▊    | 65917/112584 [00:10<00:07, 6216.21it/s] 59%|█████▉    | 66540/112584 [00:10<00:07, 5956.02it/s] 60%|█████▉    | 67139/112584 [00:10<00:07, 5932.54it/s] 60%|██████    | 67735/112584 [00:11<00:07, 5737.89it/s] 61%|██████    | 68372/112584 [00:11<00:07, 5908.82it/s] 61%|██████▏   | 69083/112584 [00:11<00:06, 6253.67it/s] 62%|██████▏   | 69773/112584 [00:11<00:06, 6442.54it/s] 63%|██████▎   | 70420/112584 [00:11<00:06, 6450.05it/s] 63%|██████▎   | 71067/112584 [00:11<00:06, 6121.12it/s] 64%|██████▎   | 71700/112584 [00:11<00:06, 6180.75it/s] 64%|██████▍   | 72322/112584 [00:11<00:06, 6188.49it/s] 65%|██████▍   | 73096/112584 [00:11<00:05, 6630.97it/s] 66%|██████▌   | 73793/112584 [00:11<00:05, 6728.62it/s] 66%|██████▌   | 74585/112584 [00:12<00:05, 7073.95it/s] 67%|██████▋   | 75295/112584 [00:12<00:05, 6779.33it/s] 67%|██████▋   | 75977/112584 [00:12<00:05, 6625.00it/s] 68%|██████▊   | 76643/112584 [00:12<00:05, 6564.99it/s] 69%|██████▊   | 77302/112584 [00:12<00:05, 6364.84it/s] 69%|██████▉   | 78003/112584 [00:12<00:05, 6546.72it/s] 70%|██████▉   | 78661/112584 [00:12<00:05, 6130.23it/s] 70%|███████   | 79281/112584 [00:12<00:05, 5739.43it/s] 71%|███████   | 79866/112584 [00:12<00:05, 5767.19it/s] 71%|███████▏  | 80473/112584 [00:13<00:05, 5847.83it/s] 72%|███████▏  | 81172/112584 [00:13<00:05, 6168.42it/s] 73%|███████▎  | 81794/112584 [00:13<00:04, 6165.48it/s] 73%|███████▎  | 82420/112584 [00:13<00:04, 6185.62it/s] 74%|███████▍  | 83042/112584 [00:13<00:04, 6180.51it/s] 74%|███████▍  | 83740/112584 [00:13<00:04, 6413.93it/s] 75%|███████▍  | 84383/112584 [00:13<00:04, 6139.61it/s] 76%|███████▌  | 85063/112584 [00:13<00:04, 6324.40it/s] 76%|███████▌  | 85699/112584 [00:13<00:04, 6285.77it/s] 77%|███████▋  | 86330/112584 [00:13<00:04, 6230.58it/s] 77%|███████▋  | 87047/112584 [00:14<00:03, 6498.51it/s] 78%|███████▊  | 87699/112584 [00:14<00:03, 6453.54it/s] 78%|███████▊  | 88346/112584 [00:14<00:03, 6410.30it/s] 79%|███████▉  | 88988/112584 [00:14<00:03, 5933.85it/s] 80%|███████▉  | 89605/112584 [00:14<00:03, 5995.43it/s] 80%|████████  | 90210/112584 [00:14<00:03, 5839.56it/s] 81%|████████  | 90799/112584 [00:14<00:03, 5757.26it/s] 81%|████████▏ | 91517/112584 [00:14<00:03, 6154.00it/s] 82%|████████▏ | 92137/112584 [00:14<00:03, 6132.26it/s] 82%|████████▏ | 92817/112584 [00:15<00:03, 6319.98it/s] 83%|████████▎ | 93452/112584 [00:15<00:03, 6167.42it/s] 84%|████████▎ | 94071/112584 [00:15<00:03, 5986.97it/s] 84%|████████▍ | 94794/112584 [00:15<00:02, 6343.00it/s] 85%|████████▍ | 95432/112584 [00:15<00:02, 6214.66it/s] 85%|████████▌ | 96056/112584 [00:15<00:02, 6186.60it/s] 86%|████████▌ | 96906/112584 [00:15<00:02, 6856.68it/s] 87%|████████▋ | 97595/112584 [00:15<00:02, 6369.03it/s] 87%|████████▋ | 98281/112584 [00:15<00:02, 6502.82it/s] 88%|████████▊ | 98939/112584 [00:15<00:02, 6242.14it/s] 88%|████████▊ | 99570/112584 [00:16<00:02, 6067.75it/s] 89%|████████▉ | 100182/112584 [00:16<00:02, 5948.75it/s] 90%|████████▉ | 100780/112584 [00:16<00:01, 5950.66it/s] 90%|█████████ | 101397/112584 [00:16<00:01, 6010.06it/s] 91%|█████████ | 102103/112584 [00:16<00:01, 6311.55it/s] 91%|█████████▏| 102737/112584 [00:16<00:01, 6211.42it/s] 92%|█████████▏| 103360/112584 [00:16<00:01, 6090.84it/s] 92%|█████████▏| 103971/112584 [00:16<00:01, 5673.65it/s] 93%|█████████▎| 104634/112584 [00:16<00:01, 5938.56it/s] 93%|█████████▎| 105234/112584 [00:17<00:01, 5843.81it/s] 94%|█████████▍| 105937/112584 [00:17<00:01, 6180.62it/s] 95%|█████████▍| 106560/112584 [00:17<00:01, 5989.82it/s] 95%|█████████▌| 107164/112584 [00:17<00:00, 5843.22it/s] 96%|█████████▌| 107797/112584 [00:17<00:00, 5970.76it/s] 96%|█████████▋| 108432/112584 [00:17<00:00, 6075.18it/s] 97%|█████████▋| 109042/112584 [00:17<00:00, 5784.83it/s] 97%|█████████▋| 109634/112584 [00:17<00:00, 5816.24it/s] 98%|█████████▊| 110269/112584 [00:17<00:00, 5966.02it/s] 99%|█████████▊| 110958/112584 [00:17<00:00, 6230.03it/s] 99%|█████████▉| 111592/112584 [00:18<00:00, 6262.28it/s]100%|█████████▉| 112221/112584 [00:18<00:00, 6218.92it/s]100%|██████████| 112584/112584 [00:18<00:00, 6169.13it/s]

gathering stats for n=1
  0%|          | 0/112584 [00:00<?, ?it/s]  2%|▏         | 1799/112584 [00:00<00:06, 17982.13it/s]  3%|▎         | 3770/112584 [00:00<00:05, 18993.58it/s]  5%|▌         | 6021/112584 [00:00<00:05, 20595.61it/s]  7%|▋         | 8081/112584 [00:00<00:05, 19518.78it/s]  9%|▉         | 10067/112584 [00:00<00:05, 19636.39it/s] 11%|█         | 12037/112584 [00:00<00:05, 19584.73it/s] 12%|█▏        | 14015/112584 [00:00<00:05, 19636.89it/s] 14%|█▍        | 15982/112584 [00:00<00:04, 19485.20it/s] 16%|█▌        | 17958/112584 [00:00<00:04, 19567.60it/s] 18%|█▊        | 20047/112584 [00:01<00:04, 19967.46it/s] 20%|█▉        | 22046/112584 [00:01<00:04, 19627.69it/s] 22%|██▏       | 24217/112584 [00:01<00:04, 20247.42it/s] 23%|██▎       | 26267/112584 [00:01<00:04, 20317.07it/s] 25%|██▌       | 28301/112584 [00:01<00:04, 19882.88it/s] 27%|██▋       | 30294/112584 [00:01<00:04, 19896.52it/s] 29%|██▊       | 32286/112584 [00:01<00:04, 19275.05it/s] 30%|███       | 34219/112584 [00:01<00:04, 19154.22it/s] 32%|███▏      | 36244/112584 [00:01<00:03, 19473.63it/s] 34%|███▍      | 38195/112584 [00:01<00:03, 19107.34it/s] 36%|███▌      | 40128/112584 [00:02<00:03, 19171.71it/s] 37%|███▋      | 42048/112584 [00:02<00:03, 19014.27it/s] 39%|███▉      | 43999/112584 [00:02<00:03, 19157.64it/s] 41%|████      | 46047/112584 [00:02<00:03, 19542.61it/s] 43%|████▎     | 48452/112584 [00:02<00:03, 20876.44it/s] 45%|████▍     | 50542/112584 [00:02<00:02, 20736.52it/s] 47%|████▋     | 52691/112584 [00:02<00:02, 20948.01it/s] 49%|████▊     | 54788/112584 [00:02<00:02, 20230.96it/s] 50%|█████     | 56817/112584 [00:02<00:02, 20100.29it/s] 52%|█████▏    | 58861/112584 [00:02<00:02, 20196.16it/s] 54%|█████▍    | 60884/112584 [00:03<00:02, 20036.78it/s] 56%|█████▌    | 62909/112584 [00:03<00:02, 20094.63it/s] 58%|█████▊    | 64921/112584 [00:03<00:02, 19947.89it/s] 59%|█████▉    | 66944/112584 [00:03<00:02, 20026.57it/s] 61%|██████    | 68948/112584 [00:03<00:02, 19871.94it/s] 63%|██████▎   | 70936/112584 [00:03<00:02, 19772.04it/s] 65%|██████▍   | 73094/112584 [00:03<00:01, 20298.18it/s] 67%|██████▋   | 75305/112584 [00:03<00:01, 20835.95it/s] 69%|██████▊   | 77390/112584 [00:03<00:01, 20687.31it/s] 71%|███████   | 79460/112584 [00:04<00:01, 19741.79it/s] 72%|███████▏  | 81465/112584 [00:04<00:01, 19825.11it/s] 74%|███████▍  | 83526/112584 [00:04<00:01, 20053.52it/s] 76%|███████▌  | 85537/112584 [00:04<00:01, 19883.98it/s] 78%|███████▊  | 87646/112584 [00:04<00:01, 20233.03it/s] 80%|███████▉  | 89673/112584 [00:04<00:01, 19799.79it/s] 81%|████████▏ | 91657/112584 [00:04<00:01, 19618.38it/s] 83%|████████▎ | 93689/112584 [00:04<00:00, 19812.82it/s] 85%|████████▍ | 95673/112584 [00:04<00:00, 19554.77it/s] 87%|████████▋ | 97826/112584 [00:04<00:00, 20134.08it/s] 89%|████████▊ | 99843/112584 [00:05<00:00, 19913.74it/s] 90%|█████████ | 101837/112584 [00:05<00:00, 19736.05it/s] 92%|█████████▏| 103813/112584 [00:05<00:00, 19729.44it/s] 94%|█████████▍| 105848/112584 [00:05<00:00, 19905.77it/s] 96%|█████████▌| 107840/112584 [00:05<00:00, 19551.06it/s] 98%|█████████▊| 109797/112584 [00:05<00:00, 19254.87it/s] 99%|█████████▉| 111834/112584 [00:05<00:00, 19576.24it/s]100%|██████████| 112584/112584 [00:05<00:00, 19842.99it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 593.51it/s]2022-03-14 16:40:56 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-14 16:40:56 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-14 16:40:56 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-14 16:40:56 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-14 16:40:56 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-14 16:40:56 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 16:40:56 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-14 16:40:56 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 16:40:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:40:57 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = NVIDIA TITAN RTX                        
2022-03-14 16:40:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 16:40:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 16:40:57 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-14 16:40:57 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 16:40:57 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 16:40:57 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 16:40:57 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-14 16:40:57 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 16:40:57 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-14 16:41:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 16:41:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 16:41:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 16:41:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 16:41:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-14 16:43:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:43:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.961 | ppl 7971.29 | wps 66301.6 | wpb 2040.3 | bsz 4 | num_updates 98
2022-03-14 16:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 98 updates
2022-03-14 16:43:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:43:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:43:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 1 @ 98 updates, score 12.961) (writing took 2.080317398533225 seconds)
2022-03-14 16:43:50 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 16:43:50 | INFO | train | epoch 001 | loss 14.301 | ppl 20180.7 | wps 39617.5 | ups 0.61 | wpb 65306.1 | bsz 127.6 | num_updates 98 | lr 1.23476e-05 | gnorm 3.012 | loss_scale 4 | train_wall 162 | gb_free 20.8 | wall 174
KL Stats: Epoch 1 Divergences: Uniform: 0.5677875869543336 Unigram: 2.5014850002301445
2022-03-14 16:43:50 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 16:43:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:43:53 | INFO | train_inner | epoch 002:      2 / 103 loss=14.275, ppl=19827.1, wps=39630.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=2.979, loss_scale=4, train_wall=165, gb_free=20.8, wall=177
2022-03-14 16:46:31 | INFO | train_inner | epoch 002:    102 / 103 loss=12.399, ppl=5401.62, wps=41478.7, ups=0.63, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.127, loss_scale=4, train_wall=153, gb_free=20.8, wall=335
2022-03-14 16:46:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:46:36 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.627 | ppl 3163.64 | wps 66171.4 | wpb 2040.3 | bsz 4 | num_updates 201 | best_loss 11.627
2022-03-14 16:46:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 201 updates
2022-03-14 16:46:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:46:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:46:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 2 @ 201 updates, score 11.627) (writing took 2.255636046640575 seconds)
2022-03-14 16:46:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 16:46:38 | INFO | train | epoch 002 | loss 12.407 | ppl 5430.64 | wps 40007.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 201 | lr 2.522e-05 | gnorm 1.129 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 342
KL Stats: Epoch 2 Divergences: Uniform: 0.5477510647635199 Unigram: 1.192305163681266
2022-03-14 16:46:38 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 16:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:49:15 | INFO | train_inner | epoch 003:     99 / 103 loss=11.155, ppl=2280.5, wps=39948.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.67, loss_scale=4, train_wall=153, gb_free=20.8, wall=498
2022-03-14 16:49:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:49:24 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.666 | ppl 1624.95 | wps 66466 | wpb 2040.3 | bsz 4 | num_updates 304 | best_loss 10.666
2022-03-14 16:49:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 304 updates
2022-03-14 16:49:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:49:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:49:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 3 @ 304 updates, score 10.666) (writing took 2.1069842157885432 seconds)
2022-03-14 16:49:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 16:49:26 | INFO | train | epoch 003 | loss 11.136 | ppl 2251.16 | wps 40026.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 304 | lr 3.80924e-05 | gnorm 0.66 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 510
KL Stats: Epoch 3 Divergences: Uniform: 0.7766053717291588 Unigram: 0.5501570891965702
2022-03-14 16:49:26 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 16:49:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:51:58 | INFO | train_inner | epoch 004:     96 / 103 loss=10.508, ppl=1456.61, wps=39998.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.416, loss_scale=4, train_wall=153, gb_free=20.8, wall=662
2022-03-14 16:52:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:52:12 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.3 | ppl 1260.99 | wps 66091.4 | wpb 2040.3 | bsz 4 | num_updates 407 | best_loss 10.3
2022-03-14 16:52:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 407 updates
2022-03-14 16:52:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:52:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 4 @ 407 updates, score 10.3) (writing took 2.0531625784933567 seconds)
2022-03-14 16:52:14 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 16:52:14 | INFO | train | epoch 004 | loss 10.489 | ppl 1437.22 | wps 40042.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 407 | lr 5.09648e-05 | gnorm 0.413 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 678
KL Stats: Epoch 4 Divergences: Uniform: 1.2354097612731025 Unigram: 0.3866578682681663
2022-03-14 16:52:14 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 16:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:54:41 | INFO | train_inner | epoch 005:     93 / 103 loss=10.202, ppl=1178.07, wps=40021.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.462, loss_scale=4, train_wall=153, gb_free=20.8, wall=825
2022-03-14 16:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:55:00 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 10.01 | ppl 1030.87 | wps 66336.3 | wpb 2040.3 | bsz 4 | num_updates 510 | best_loss 10.01
2022-03-14 16:55:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 510 updates
2022-03-14 16:55:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:55:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:55:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 5 @ 510 updates, score 10.01) (writing took 2.102165725082159 seconds)
2022-03-14 16:55:02 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 16:55:02 | INFO | train | epoch 005 | loss 10.177 | ppl 1157.91 | wps 40045.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 510 | lr 6.38373e-05 | gnorm 0.463 | loss_scale 4 | train_wall 157 | gb_free 20.8 | wall 846
KL Stats: Epoch 5 Divergences: Uniform: 1.5098533519535828 Unigram: 0.5263672387350039
2022-03-14 16:55:02 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 16:55:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 16:57:25 | INFO | train_inner | epoch 006:     90 / 103 loss=9.927, ppl=973.27, wps=39985.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.518, loss_scale=8, train_wall=153, gb_free=20.8, wall=988
2022-03-14 16:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 16:57:48 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.738 | ppl 853.82 | wps 66511.3 | wpb 2040.3 | bsz 4 | num_updates 613 | best_loss 9.738
2022-03-14 16:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 613 updates
2022-03-14 16:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 16:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 6 @ 613 updates, score 9.738) (writing took 2.0634018080309033 seconds)
2022-03-14 16:57:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 16:57:50 | INFO | train | epoch 006 | loss 9.901 | ppl 955.79 | wps 40034.2 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 613 | lr 7.67097e-05 | gnorm 0.528 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1014
KL Stats: Epoch 6 Divergences: Uniform: 1.6414333237581018 Unigram: 0.7002522699006036
2022-03-14 16:57:50 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 16:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:00:08 | INFO | train_inner | epoch 007:     87 / 103 loss=9.667, ppl=812.94, wps=39993.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.607, loss_scale=8, train_wall=153, gb_free=20.8, wall=1152
2022-03-14 17:00:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:00:36 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.483 | ppl 715.4 | wps 65783.4 | wpb 2040.3 | bsz 4 | num_updates 716 | best_loss 9.483
2022-03-14 17:00:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 716 updates
2022-03-14 17:00:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:00:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:00:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 7 @ 716 updates, score 9.483) (writing took 2.0875291507691145 seconds)
2022-03-14 17:00:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 17:00:38 | INFO | train | epoch 007 | loss 9.632 | ppl 793.4 | wps 40021.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 716 | lr 8.95821e-05 | gnorm 0.641 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1182
KL Stats: Epoch 7 Divergences: Uniform: 1.7815819662780874 Unigram: 0.8587942684955042
2022-03-14 17:00:38 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 17:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:02:51 | INFO | train_inner | epoch 008:     84 / 103 loss=9.414, ppl=682.23, wps=39986, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.736, loss_scale=8, train_wall=153, gb_free=20.8, wall=1315
2022-03-14 17:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:03:24 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.24 | ppl 604.52 | wps 66470.4 | wpb 2040.3 | bsz 4 | num_updates 819 | best_loss 9.24
2022-03-14 17:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 819 updates
2022-03-14 17:03:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:03:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 8 @ 819 updates, score 9.24) (writing took 2.127653891220689 seconds)
2022-03-14 17:03:27 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 17:03:27 | INFO | train | epoch 008 | loss 9.374 | ppl 663.36 | wps 40017.1 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 819 | lr 0.000102455 | gnorm 0.741 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1350
KL Stats: Epoch 8 Divergences: Uniform: 1.944552032804612 Unigram: 1.0086594675778904
2022-03-14 17:03:27 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 17:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:05:35 | INFO | train_inner | epoch 009:     81 / 103 loss=9.192, ppl=584.99, wps=39982, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.742, loss_scale=8, train_wall=153, gb_free=20.8, wall=1478
2022-03-14 17:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:06:13 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 9.044 | ppl 527.85 | wps 66344.5 | wpb 2040.3 | bsz 4 | num_updates 922 | best_loss 9.044
2022-03-14 17:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 922 updates
2022-03-14 17:06:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:06:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:06:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 9 @ 922 updates, score 9.044) (writing took 2.098886533640325 seconds)
2022-03-14 17:06:15 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 17:06:15 | INFO | train | epoch 009 | loss 9.149 | ppl 567.63 | wps 40030 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 922 | lr 0.000115327 | gnorm 0.754 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1518
KL Stats: Epoch 9 Divergences: Uniform: 2.0738473144775367 Unigram: 1.1438737194605635
2022-03-14 17:06:15 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 17:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:08:18 | INFO | train_inner | epoch 010:     78 / 103 loss=8.993, ppl=509.5, wps=39986.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.746, loss_scale=8, train_wall=153, gb_free=20.8, wall=1642
2022-03-14 17:08:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:09:01 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.877 | ppl 470.25 | wps 65999.2 | wpb 2040.3 | bsz 4 | num_updates 1025 | best_loss 8.877
2022-03-14 17:09:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1025 updates
2022-03-14 17:09:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:09:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:09:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 10 @ 1025 updates, score 8.877) (writing took 2.1393846161663532 seconds)
2022-03-14 17:09:03 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 17:09:03 | INFO | train | epoch 010 | loss 8.954 | ppl 496 | wps 39996.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1025 | lr 0.000128199 | gnorm 0.742 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 1686
KL Stats: Epoch 10 Divergences: Uniform: 2.18951089461966 Unigram: 1.2601759567204622
2022-03-14 17:09:03 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 17:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:11:01 | INFO | train_inner | epoch 011:     75 / 103 loss=8.822, ppl=452.53, wps=39968.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.803, loss_scale=16, train_wall=153, gb_free=20.8, wall=1805
2022-03-14 17:11:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:11:49 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.725 | ppl 423.19 | wps 66589.6 | wpb 2040.3 | bsz 4 | num_updates 1128 | best_loss 8.725
2022-03-14 17:11:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1128 updates
2022-03-14 17:11:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:11:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:11:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 11 @ 1128 updates, score 8.725) (writing took 2.1620298139750957 seconds)
2022-03-14 17:11:51 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 17:11:51 | INFO | train | epoch 011 | loss 8.783 | ppl 440.52 | wps 40011.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1128 | lr 0.000141072 | gnorm 0.801 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 1854
KL Stats: Epoch 11 Divergences: Uniform: 2.2989244791110153 Unigram: 1.3592206269601286
2022-03-14 17:11:51 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 17:11:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:13:45 | INFO | train_inner | epoch 012:     72 / 103 loss=8.673, ppl=408.08, wps=39959.6, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.779, loss_scale=16, train_wall=153, gb_free=20.8, wall=1968
2022-03-14 17:14:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:14:37 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.594 | ppl 386.42 | wps 66661.6 | wpb 2040.3 | bsz 4 | num_updates 1231 | best_loss 8.594
2022-03-14 17:14:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1231 updates
2022-03-14 17:14:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:14:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 12 @ 1231 updates, score 8.594) (writing took 2.135757547803223 seconds)
2022-03-14 17:14:39 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 17:14:39 | INFO | train | epoch 012 | loss 8.625 | ppl 394.71 | wps 40013.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1231 | lr 0.000153944 | gnorm 0.803 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 2023
KL Stats: Epoch 12 Divergences: Uniform: 2.406314777424775 Unigram: 1.445165549625847
2022-03-14 17:14:39 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 17:14:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:16:28 | INFO | train_inner | epoch 013:     69 / 103 loss=8.518, ppl=366.46, wps=39982.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.815, loss_scale=16, train_wall=153, gb_free=20.8, wall=2132
2022-03-14 17:17:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:17:25 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.468 | ppl 354.2 | wps 66422.9 | wpb 2040.3 | bsz 4 | num_updates 1334 | best_loss 8.468
2022-03-14 17:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1334 updates
2022-03-14 17:17:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:17:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 13 @ 1334 updates, score 8.468) (writing took 2.151137531735003 seconds)
2022-03-14 17:17:27 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 17:17:27 | INFO | train | epoch 013 | loss 8.474 | ppl 355.68 | wps 39999.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1334 | lr 0.000166817 | gnorm 0.806 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 2191
KL Stats: Epoch 13 Divergences: Uniform: 2.5132450439071516 Unigram: 1.5265020071999822
2022-03-14 17:17:27 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 17:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:19:12 | INFO | train_inner | epoch 014:     66 / 103 loss=8.377, ppl=332.35, wps=39968.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.834, loss_scale=16, train_wall=153, gb_free=20.8, wall=2295
2022-03-14 17:20:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:20:13 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.359 | ppl 328.4 | wps 66436.1 | wpb 2040.3 | bsz 4 | num_updates 1437 | best_loss 8.359
2022-03-14 17:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1437 updates
2022-03-14 17:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:20:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:20:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 14 @ 1437 updates, score 8.359) (writing took 2.1492336969822645 seconds)
2022-03-14 17:20:15 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 17:20:15 | INFO | train | epoch 014 | loss 8.329 | ppl 321.57 | wps 40011.9 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1437 | lr 0.000179689 | gnorm 0.855 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 2359
KL Stats: Epoch 14 Divergences: Uniform: 2.6125954700594836 Unigram: 1.6014818414952572
2022-03-14 17:20:15 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 17:20:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:21:55 | INFO | train_inner | epoch 015:     63 / 103 loss=8.238, ppl=301.95, wps=39968, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.847, loss_scale=16, train_wall=153, gb_free=20.8, wall=2459
2022-03-14 17:22:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:23:01 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.245 | ppl 303.45 | wps 65967.2 | wpb 2040.3 | bsz 4 | num_updates 1540 | best_loss 8.245
2022-03-14 17:23:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1540 updates
2022-03-14 17:23:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:23:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 15 @ 1540 updates, score 8.245) (writing took 2.194022069685161 seconds)
2022-03-14 17:23:04 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 17:23:04 | INFO | train | epoch 015 | loss 8.184 | ppl 290.79 | wps 40002.5 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1540 | lr 0.000192562 | gnorm 0.831 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2527
KL Stats: Epoch 15 Divergences: Uniform: 2.708113379020733 Unigram: 1.6728216935887674
2022-03-14 17:23:04 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 17:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:24:39 | INFO | train_inner | epoch 016:     60 / 103 loss=8.097, ppl=273.73, wps=39961.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.831, loss_scale=32, train_wall=153, gb_free=20.8, wall=2622
2022-03-14 17:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:25:50 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 8.124 | ppl 278.91 | wps 66236 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 8.124
2022-03-14 17:25:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-14 17:25:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:25:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:25:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 16 @ 1643 updates, score 8.124) (writing took 2.2882196391001344 seconds)
2022-03-14 17:25:52 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 17:25:52 | INFO | train | epoch 016 | loss 8.039 | ppl 262.95 | wps 39982.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.835 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2695
KL Stats: Epoch 16 Divergences: Uniform: 2.8030789765683815 Unigram: 1.737565439911001
2022-03-14 17:25:52 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 17:25:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:27:22 | INFO | train_inner | epoch 017:     57 / 103 loss=7.957, ppl=248.48, wps=39924.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.851, loss_scale=32, train_wall=153, gb_free=20.8, wall=2786
2022-03-14 17:28:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:28:38 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 8.027 | ppl 260.92 | wps 66242.6 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 8.027
2022-03-14 17:28:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-14 17:28:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:28:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 17 @ 1746 updates, score 8.027) (writing took 2.2553588021546602 seconds)
2022-03-14 17:28:40 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 17:28:40 | INFO | train | epoch 017 | loss 7.896 | ppl 238.17 | wps 39963.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.865 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 2864
KL Stats: Epoch 17 Divergences: Uniform: 2.901437971950586 Unigram: 1.8017878999601353
2022-03-14 17:28:40 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 17:28:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:30:06 | INFO | train_inner | epoch 018:     54 / 103 loss=7.818, ppl=225.73, wps=39908.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.882, loss_scale=32, train_wall=153, gb_free=20.8, wall=2949
2022-03-14 17:31:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:31:26 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.944 | ppl 246.19 | wps 66202 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 7.944
2022-03-14 17:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-14 17:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:31:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 18 @ 1849 updates, score 7.944) (writing took 2.326650310307741 seconds)
2022-03-14 17:31:29 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 17:31:29 | INFO | train | epoch 018 | loss 7.756 | ppl 216.21 | wps 39927.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.865 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3032
KL Stats: Epoch 18 Divergences: Uniform: 2.99433096275035 Unigram: 1.8625040633751215
2022-03-14 17:31:29 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 17:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:32:49 | INFO | train_inner | epoch 019:     51 / 103 loss=7.687, ppl=206.03, wps=39899.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.864, loss_scale=32, train_wall=153, gb_free=20.8, wall=3113
2022-03-14 17:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:34:15 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.848 | ppl 230.34 | wps 65762.6 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 7.848
2022-03-14 17:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-14 17:34:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:34:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:34:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 19 @ 1952 updates, score 7.848) (writing took 2.2843212261795998 seconds)
2022-03-14 17:34:17 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 17:34:17 | INFO | train | epoch 019 | loss 7.621 | ppl 196.79 | wps 39935.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.862 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3201
KL Stats: Epoch 19 Divergences: Uniform: 3.0886289449244924 Unigram: 1.920125807326872
2022-03-14 17:34:17 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 17:34:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:35:33 | INFO | train_inner | epoch 020:     48 / 103 loss=7.559, ppl=188.62, wps=39893.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.851, loss_scale=32, train_wall=153, gb_free=20.8, wall=3277
2022-03-14 17:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:37:03 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.77 | ppl 218.26 | wps 66081.6 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 7.77
2022-03-14 17:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-14 17:37:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:37:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 20 @ 2055 updates, score 7.77) (writing took 2.42074045073241 seconds)
2022-03-14 17:37:06 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 17:37:06 | INFO | train | epoch 020 | loss 7.489 | ppl 179.66 | wps 39917.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.83 | loss_scale 64 | train_wall 157 | gb_free 20.8 | wall 3369
KL Stats: Epoch 20 Divergences: Uniform: 3.181286150394621 Unigram: 1.9747722181689875
2022-03-14 17:37:06 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 17:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:37:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 17:38:18 | INFO | train_inner | epoch 021:     46 / 103 loss=7.428, ppl=172.18, wps=39494.3, ups=0.6, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.843, loss_scale=32, train_wall=154, gb_free=20.8, wall=3442
2022-03-14 17:39:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:39:52 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.705 | ppl 208.6 | wps 65739.9 | wpb 2040.3 | bsz 4 | num_updates 2157 | best_loss 7.705
2022-03-14 17:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2157 updates
2022-03-14 17:39:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:39:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:39:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 21 @ 2157 updates, score 7.705) (writing took 2.3213621703907847 seconds)
2022-03-14 17:39:54 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 17:39:54 | INFO | train | epoch 021 | loss 7.369 | ppl 165.33 | wps 39528.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2157 | lr 0.000269671 | gnorm 0.862 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 3538
KL Stats: Epoch 21 Divergences: Uniform: 3.2792712951329053 Unigram: 2.0275846568658626
2022-03-14 17:39:54 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 17:39:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:41:02 | INFO | train_inner | epoch 022:     43 / 103 loss=7.318, ppl=159.6, wps=39866.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.845, loss_scale=32, train_wall=153, gb_free=20.8, wall=3606
2022-03-14 17:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:42:40 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.637 | ppl 199.04 | wps 66603.6 | wpb 2040.3 | bsz 4 | num_updates 2260 | best_loss 7.637
2022-03-14 17:42:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2260 updates
2022-03-14 17:42:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:42:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:42:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 22 @ 2260 updates, score 7.637) (writing took 2.232019416987896 seconds)
2022-03-14 17:42:42 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 17:42:42 | INFO | train | epoch 022 | loss 7.256 | ppl 152.8 | wps 39970.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2260 | lr 0.000282544 | gnorm 0.849 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3706
KL Stats: Epoch 22 Divergences: Uniform: 3.365913643017987 Unigram: 2.074076784617237
2022-03-14 17:42:42 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 17:42:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:43:46 | INFO | train_inner | epoch 023:     40 / 103 loss=7.21, ppl=148.01, wps=39936.7, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.849, loss_scale=32, train_wall=153, gb_free=20.8, wall=3769
2022-03-14 17:45:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:45:28 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.586 | ppl 192.18 | wps 66470.7 | wpb 2040.3 | bsz 4 | num_updates 2363 | best_loss 7.586
2022-03-14 17:45:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2363 updates
2022-03-14 17:45:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:45:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:45:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 23 @ 2363 updates, score 7.586) (writing took 2.108814355917275 seconds)
2022-03-14 17:45:31 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 17:45:31 | INFO | train | epoch 023 | loss 7.147 | ppl 141.73 | wps 40007 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2363 | lr 0.000295416 | gnorm 0.844 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 3874
KL Stats: Epoch 23 Divergences: Uniform: 3.4544509181295875 Unigram: 2.1210447067984677
2022-03-14 17:45:31 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 17:45:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:46:29 | INFO | train_inner | epoch 024:     37 / 103 loss=7.107, ppl=137.83, wps=39962.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.841, loss_scale=32, train_wall=153, gb_free=20.8, wall=3933
2022-03-14 17:48:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:48:17 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.549 | ppl 187.21 | wps 66103.1 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.549
2022-03-14 17:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-14 17:48:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:48:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.549) (writing took 2.3097733641043305 seconds)
2022-03-14 17:48:19 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 17:48:19 | INFO | train | epoch 024 | loss 7.045 | ppl 132.03 | wps 39947.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.833 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 4043
KL Stats: Epoch 24 Divergences: Uniform: 3.5387918986481486 Unigram: 2.1641016277945977
2022-03-14 17:48:19 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 17:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:49:13 | INFO | train_inner | epoch 025:     34 / 103 loss=7.006, ppl=128.54, wps=39907.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.842, loss_scale=32, train_wall=153, gb_free=20.8, wall=4096
2022-03-14 17:49:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 17:51:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:51:05 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.502 | ppl 181.26 | wps 66284.3 | wpb 2040.3 | bsz 4 | num_updates 2568 | best_loss 7.502
2022-03-14 17:51:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2568 updates
2022-03-14 17:51:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:51:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:51:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 25 @ 2568 updates, score 7.502) (writing took 2.1512280460447073 seconds)
2022-03-14 17:51:07 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 17:51:07 | INFO | train | epoch 025 | loss 6.948 | ppl 123.47 | wps 39608.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 2568 | lr 0.000321036 | gnorm 0.827 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4211
KL Stats: Epoch 25 Divergences: Uniform: 3.621094136099554 Unigram: 2.206092662642922
2022-03-14 17:51:07 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 17:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:51:58 | INFO | train_inner | epoch 026:     32 / 103 loss=6.925, ppl=121.49, wps=39575.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.827, loss_scale=16, train_wall=154, gb_free=20.8, wall=4261
2022-03-14 17:53:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:53:53 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.454 | ppl 175.32 | wps 66003.2 | wpb 2040.3 | bsz 4 | num_updates 2671 | best_loss 7.454
2022-03-14 17:53:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2671 updates
2022-03-14 17:53:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:53:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:53:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 26 @ 2671 updates, score 7.454) (writing took 2.191701851785183 seconds)
2022-03-14 17:53:55 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 17:53:55 | INFO | train | epoch 026 | loss 6.857 | ppl 115.95 | wps 39984.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2671 | lr 0.000333908 | gnorm 0.835 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4379
KL Stats: Epoch 26 Divergences: Uniform: 3.694359166607255 Unigram: 2.244726775542214
2022-03-14 17:53:55 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 17:53:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:54:41 | INFO | train_inner | epoch 027:     29 / 103 loss=6.828, ppl=113.63, wps=39935.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.82, loss_scale=16, train_wall=153, gb_free=20.8, wall=4425
2022-03-14 17:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:56:42 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.422 | ppl 171.44 | wps 66414.8 | wpb 2040.3 | bsz 4 | num_updates 2774 | best_loss 7.422
2022-03-14 17:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2774 updates
2022-03-14 17:56:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:56:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 27 @ 2774 updates, score 7.422) (writing took 2.191948446445167 seconds)
2022-03-14 17:56:44 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 17:56:44 | INFO | train | epoch 027 | loss 6.769 | ppl 109.09 | wps 39969.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2774 | lr 0.000346781 | gnorm 0.828 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 4547
KL Stats: Epoch 27 Divergences: Uniform: 3.7626306040666697 Unigram: 2.2823220602683
2022-03-14 17:56:44 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 17:56:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 17:57:25 | INFO | train_inner | epoch 028:     26 / 103 loss=6.745, ppl=107.29, wps=39930.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.813, loss_scale=16, train_wall=153, gb_free=20.8, wall=4588
2022-03-14 17:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 17:59:30 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 7.39 | ppl 167.78 | wps 65889.8 | wpb 2040.3 | bsz 4 | num_updates 2877 | best_loss 7.39
2022-03-14 17:59:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2877 updates
2022-03-14 17:59:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 17:59:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 28 @ 2877 updates, score 7.39) (writing took 2.1600173357874155 seconds)
2022-03-14 17:59:32 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 17:59:32 | INFO | train | epoch 028 | loss 6.685 | ppl 102.92 | wps 39978.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2877 | lr 0.000359653 | gnorm 0.824 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 4716
KL Stats: Epoch 28 Divergences: Uniform: 3.8334493108863734 Unigram: 2.318039563632529
2022-03-14 17:59:32 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 17:59:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:00:09 | INFO | train_inner | epoch 029:     23 / 103 loss=6.67, ppl=101.84, wps=39921.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.834, loss_scale=16, train_wall=153, gb_free=20.8, wall=4752
2022-03-14 18:02:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:02:18 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 7.364 | ppl 164.79 | wps 66484.3 | wpb 2040.3 | bsz 4 | num_updates 2980 | best_loss 7.364
2022-03-14 18:02:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2980 updates
2022-03-14 18:02:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:02:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:02:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 29 @ 2980 updates, score 7.364) (writing took 2.206767464056611 seconds)
2022-03-14 18:02:20 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 18:02:20 | INFO | train | epoch 029 | loss 6.604 | ppl 97.24 | wps 39942.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 2980 | lr 0.000372526 | gnorm 0.809 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 4884
KL Stats: Epoch 29 Divergences: Uniform: 3.9007377933868375 Unigram: 2.3557130703815603
2022-03-14 18:02:20 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 18:02:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:02:52 | INFO | train_inner | epoch 030:     20 / 103 loss=6.59, ppl=96.35, wps=39894, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.861, loss_scale=16, train_wall=153, gb_free=20.8, wall=4916
2022-03-14 18:05:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:05:07 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 7.348 | ppl 162.97 | wps 66635.2 | wpb 2040.3 | bsz 4 | num_updates 3083 | best_loss 7.348
2022-03-14 18:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3083 updates
2022-03-14 18:05:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:05:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:05:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 30 @ 3083 updates, score 7.348) (writing took 2.1529023684561253 seconds)
2022-03-14 18:05:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 18:05:09 | INFO | train | epoch 030 | loss 6.528 | ppl 92.29 | wps 39958.4 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3083 | lr 0.000385398 | gnorm 0.832 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 5052
KL Stats: Epoch 30 Divergences: Uniform: 3.9676319527775106 Unigram: 2.389844445245763
2022-03-14 18:05:09 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 18:05:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:05:36 | INFO | train_inner | epoch 031:     17 / 103 loss=6.513, ppl=91.31, wps=39937.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.793, loss_scale=32, train_wall=153, gb_free=20.8, wall=5079
2022-03-14 18:05:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:07:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:07:55 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 7.332 | ppl 161.17 | wps 66297.7 | wpb 2040.3 | bsz 4 | num_updates 3185 | best_loss 7.332
2022-03-14 18:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3185 updates
2022-03-14 18:07:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:07:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:07:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 31 @ 3185 updates, score 7.332) (writing took 2.174670702777803 seconds)
2022-03-14 18:07:57 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 18:07:57 | INFO | train | epoch 031 | loss 6.45 | ppl 87.45 | wps 39609 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 3185 | lr 0.000398145 | gnorm 0.823 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5220
KL Stats: Epoch 31 Divergences: Uniform: 4.031926164069391 Unigram: 2.4240498359346265
2022-03-14 18:07:57 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 18:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:08:21 | INFO | train_inner | epoch 032:     15 / 103 loss=6.438, ppl=86.68, wps=39577.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.812, loss_scale=16, train_wall=154, gb_free=20.8, wall=5244
2022-03-14 18:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:10:43 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 7.323 | ppl 160.13 | wps 66077.3 | wpb 2040.3 | bsz 4 | num_updates 3288 | best_loss 7.323
2022-03-14 18:10:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3288 updates
2022-03-14 18:10:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 32 @ 3288 updates, score 7.323) (writing took 2.235705272294581 seconds)
2022-03-14 18:10:45 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 18:10:45 | INFO | train | epoch 032 | loss 6.379 | ppl 83.25 | wps 39991.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3288 | lr 0.000411018 | gnorm 0.837 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5389
KL Stats: Epoch 32 Divergences: Uniform: 4.095462847475008 Unigram: 2.459306720847284
2022-03-14 18:10:45 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 18:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:11:04 | INFO | train_inner | epoch 033:     12 / 103 loss=6.373, ppl=82.9, wps=39938, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.832, loss_scale=16, train_wall=153, gb_free=20.8, wall=5408
2022-03-14 18:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:13:31 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 7.33 | ppl 160.89 | wps 66664.4 | wpb 2040.3 | bsz 4 | num_updates 3391 | best_loss 7.323
2022-03-14 18:13:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3391 updates
2022-03-14 18:13:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:13:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 33 @ 3391 updates, score 7.33) (writing took 0.964166346937418 seconds)
2022-03-14 18:13:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 18:13:32 | INFO | train | epoch 033 | loss 6.307 | ppl 79.2 | wps 40284 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3391 | lr 0.00042389 | gnorm 0.832 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5556
KL Stats: Epoch 33 Divergences: Uniform: 4.159598514322587 Unigram: 2.4942430186859164
2022-03-14 18:13:32 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 18:13:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:13:46 | INFO | train_inner | epoch 034:      9 / 103 loss=6.301, ppl=78.83, wps=40260.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.836, loss_scale=16, train_wall=153, gb_free=20.8, wall=5570
2022-03-14 18:16:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:16:18 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 7.309 | ppl 158.59 | wps 66418 | wpb 2040.3 | bsz 4 | num_updates 3494 | best_loss 7.309
2022-03-14 18:16:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3494 updates
2022-03-14 18:16:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt
2022-03-14 18:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_best.pt (epoch 34 @ 3494 updates, score 7.309) (writing took 2.2334302067756653 seconds)
2022-03-14 18:16:20 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 18:16:20 | INFO | train | epoch 034 | loss 6.236 | ppl 75.39 | wps 39991.6 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 3494 | lr 0.000436763 | gnorm 0.809 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5724
KL Stats: Epoch 34 Divergences: Uniform: 4.218058527335826 Unigram: 2.5289548659245726
2022-03-14 18:16:20 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 18:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:16:30 | INFO | train_inner | epoch 035:      6 / 103 loss=6.236, ppl=75.36, wps=39947.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.812, loss_scale=16, train_wall=153, gb_free=20.8, wall=5733
2022-03-14 18:19:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:19:06 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 7.325 | ppl 160.35 | wps 66215.4 | wpb 2040.3 | bsz 4 | num_updates 3597 | best_loss 7.309
2022-03-14 18:19:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3597 updates
2022-03-14 18:19:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:19:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 35 @ 3597 updates, score 7.325) (writing took 0.9119877861812711 seconds)
2022-03-14 18:19:07 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 18:19:07 | INFO | train | epoch 035 | loss 6.171 | ppl 72.07 | wps 40283.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3597 | lr 0.000449635 | gnorm 0.837 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 5891
KL Stats: Epoch 35 Divergences: Uniform: 4.272804967916025 Unigram: 2.5630998255795263
2022-03-14 18:19:07 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 18:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:19:12 | INFO | train_inner | epoch 036:      3 / 103 loss=6.17, ppl=71.99, wps=40249.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.844, loss_scale=16, train_wall=153, gb_free=20.8, wall=5896
2022-03-14 18:20:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:21:53 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 7.321 | ppl 159.87 | wps 66280.4 | wpb 2040.3 | bsz 4 | num_updates 3699 | best_loss 7.309
2022-03-14 18:21:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3699 updates
2022-03-14 18:21:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:21:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 36 @ 3699 updates, score 7.321) (writing took 1.0862657213583589 seconds)
2022-03-14 18:21:54 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 18:21:54 | INFO | train | epoch 036 | loss 6.106 | ppl 68.87 | wps 39865 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 3699 | lr 0.000462383 | gnorm 0.841 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6058
KL Stats: Epoch 36 Divergences: Uniform: 4.339036532419927 Unigram: 2.598026031095695
2022-03-14 18:21:55 | INFO | fairseq.trainer | begin training epoch 37
2022-03-14 18:21:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:21:56 | INFO | train_inner | epoch 037:      1 / 103 loss=6.106, ppl=68.9, wps=39835.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.837, loss_scale=16, train_wall=154, gb_free=20.8, wall=6060
2022-03-14 18:24:34 | INFO | train_inner | epoch 037:    101 / 103 loss=6.043, ppl=65.93, wps=41452.4, ups=0.63, wpb=65530.9, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.825, loss_scale=16, train_wall=153, gb_free=20.8, wall=6218
2022-03-14 18:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:24:40 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 7.32 | ppl 159.81 | wps 66063.2 | wpb 2040.3 | bsz 4 | num_updates 3802 | best_loss 7.309
2022-03-14 18:24:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3802 updates
2022-03-14 18:24:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 37 @ 3802 updates, score 7.32) (writing took 0.9613768309354782 seconds)
2022-03-14 18:24:41 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-14 18:24:41 | INFO | train | epoch 037 | loss 6.042 | ppl 65.91 | wps 40294.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3802 | lr 0.000475255 | gnorm 0.822 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6225
KL Stats: Epoch 37 Divergences: Uniform: 4.398641897764834 Unigram: 2.6314531249130155
2022-03-14 18:24:41 | INFO | fairseq.trainer | begin training epoch 38
2022-03-14 18:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:27:16 | INFO | train_inner | epoch 038:     98 / 103 loss=5.985, ppl=63.34, wps=40261.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=3900, lr=0.000487503, gnorm=0.872, loss_scale=16, train_wall=153, gb_free=20.8, wall=6380
2022-03-14 18:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:27:27 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 7.338 | ppl 161.76 | wps 66721.4 | wpb 2040.3 | bsz 4 | num_updates 3905 | best_loss 7.309
2022-03-14 18:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3905 updates
2022-03-14 18:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 38 @ 3905 updates, score 7.338) (writing took 1.013887801207602 seconds)
2022-03-14 18:27:28 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-14 18:27:28 | INFO | train | epoch 038 | loss 5.985 | ppl 63.36 | wps 40288.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 3905 | lr 0.000488127 | gnorm 0.867 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6392
KL Stats: Epoch 38 Divergences: Uniform: 4.45768594794433 Unigram: 2.6659866187799586
2022-03-14 18:27:28 | INFO | fairseq.trainer | begin training epoch 39
2022-03-14 18:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:29:59 | INFO | train_inner | epoch 039:     95 / 103 loss=5.921, ppl=60.6, wps=40234.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.836, loss_scale=16, train_wall=153, gb_free=20.8, wall=6542
2022-03-14 18:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:30:14 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 7.352 | ppl 163.34 | wps 66096.2 | wpb 2040.3 | bsz 4 | num_updates 4008 | best_loss 7.309
2022-03-14 18:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4008 updates
2022-03-14 18:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:30:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:30:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 39 @ 4008 updates, score 7.352) (writing took 0.9974940922111273 seconds)
2022-03-14 18:30:15 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-14 18:30:15 | INFO | train | epoch 039 | loss 5.922 | ppl 60.61 | wps 40275.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4008 | lr 0.000499501 | gnorm 0.845 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6559
KL Stats: Epoch 39 Divergences: Uniform: 4.519231156506667 Unigram: 2.7002637432444923
2022-03-14 18:30:15 | INFO | fairseq.trainer | begin training epoch 40
2022-03-14 18:30:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:32:41 | INFO | train_inner | epoch 040:     92 / 103 loss=5.861, ppl=58.13, wps=40274, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.817, loss_scale=16, train_wall=153, gb_free=20.8, wall=6704
2022-03-14 18:32:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:33:01 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 7.359 | ppl 164.18 | wps 66106.1 | wpb 2040.3 | bsz 4 | num_updates 4111 | best_loss 7.309
2022-03-14 18:33:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4111 updates
2022-03-14 18:33:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 40 @ 4111 updates, score 7.359) (writing took 0.9938361123204231 seconds)
2022-03-14 18:33:02 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-14 18:33:02 | INFO | train | epoch 040 | loss 5.858 | ppl 58.01 | wps 40296.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4111 | lr 0.000493204 | gnorm 0.817 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 6726
KL Stats: Epoch 40 Divergences: Uniform: 4.583392376354311 Unigram: 2.7337372673570606
2022-03-14 18:33:02 | INFO | fairseq.trainer | begin training epoch 41
2022-03-14 18:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:35:23 | INFO | train_inner | epoch 041:     89 / 103 loss=5.798, ppl=55.65, wps=40258.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.832, loss_scale=32, train_wall=153, gb_free=20.8, wall=6867
2022-03-14 18:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:35:48 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 7.382 | ppl 166.82 | wps 66182.4 | wpb 2040.3 | bsz 4 | num_updates 4214 | best_loss 7.309
2022-03-14 18:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4214 updates
2022-03-14 18:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:35:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 41 @ 4214 updates, score 7.382) (writing took 0.9583125337958336 seconds)
2022-03-14 18:35:49 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-14 18:35:49 | INFO | train | epoch 041 | loss 5.793 | ppl 55.45 | wps 40308.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4214 | lr 0.000487139 | gnorm 0.82 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 6893
KL Stats: Epoch 41 Divergences: Uniform: 4.640379874484422 Unigram: 2.770452074427603
2022-03-14 18:35:49 | INFO | fairseq.trainer | begin training epoch 42
2022-03-14 18:35:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:36:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:38:07 | INFO | train_inner | epoch 042:     87 / 103 loss=5.738, ppl=53.38, wps=39863.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.812, loss_scale=16, train_wall=154, gb_free=20.8, wall=7030
2022-03-14 18:38:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:38:35 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 7.381 | ppl 166.72 | wps 66502.7 | wpb 2040.3 | bsz 4 | num_updates 4316 | best_loss 7.309
2022-03-14 18:38:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4316 updates
2022-03-14 18:38:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:38:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 42 @ 4316 updates, score 7.381) (writing took 0.9472154257819057 seconds)
2022-03-14 18:38:36 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-14 18:38:36 | INFO | train | epoch 042 | loss 5.731 | ppl 53.11 | wps 39880.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4316 | lr 0.000481348 | gnorm 0.815 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7060
KL Stats: Epoch 42 Divergences: Uniform: 4.705571912658175 Unigram: 2.805473015474107
2022-03-14 18:38:36 | INFO | fairseq.trainer | begin training epoch 43
2022-03-14 18:38:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:40:49 | INFO | train_inner | epoch 043:     84 / 103 loss=5.682, ppl=51.36, wps=40242.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.81, loss_scale=16, train_wall=153, gb_free=20.8, wall=7193
2022-03-14 18:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:41:22 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 7.408 | ppl 169.87 | wps 66047.5 | wpb 2040.3 | bsz 4 | num_updates 4419 | best_loss 7.309
2022-03-14 18:41:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4419 updates
2022-03-14 18:41:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:41:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:41:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 43 @ 4419 updates, score 7.408) (writing took 0.9599160170182586 seconds)
2022-03-14 18:41:23 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-14 18:41:23 | INFO | train | epoch 043 | loss 5.672 | ppl 50.98 | wps 40286.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4419 | lr 0.000475705 | gnorm 0.803 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7227
KL Stats: Epoch 43 Divergences: Uniform: 4.770653889380031 Unigram: 2.840924791151568
2022-03-14 18:41:23 | INFO | fairseq.trainer | begin training epoch 44
2022-03-14 18:41:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:43:32 | INFO | train_inner | epoch 044:     81 / 103 loss=5.621, ppl=49.22, wps=40227.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.807, loss_scale=16, train_wall=153, gb_free=20.8, wall=7355
2022-03-14 18:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:44:09 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 7.414 | ppl 170.53 | wps 66245.9 | wpb 2040.3 | bsz 4 | num_updates 4522 | best_loss 7.309
2022-03-14 18:44:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4522 updates
2022-03-14 18:44:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:44:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:44:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 44 @ 4522 updates, score 7.414) (writing took 0.995881293900311 seconds)
2022-03-14 18:44:10 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-14 18:44:10 | INFO | train | epoch 044 | loss 5.617 | ppl 49.09 | wps 40251.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4522 | lr 0.000470256 | gnorm 0.828 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7394
KL Stats: Epoch 44 Divergences: Uniform: 4.8312718231128216 Unigram: 2.8773713718314697
2022-03-14 18:44:10 | INFO | fairseq.trainer | begin training epoch 45
2022-03-14 18:44:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:46:14 | INFO | train_inner | epoch 045:     78 / 103 loss=5.573, ppl=47.61, wps=40242.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.815, loss_scale=16, train_wall=153, gb_free=20.8, wall=7517
2022-03-14 18:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:46:57 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 7.459 | ppl 175.98 | wps 65677.5 | wpb 2040.3 | bsz 4 | num_updates 4625 | best_loss 7.309
2022-03-14 18:46:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4625 updates
2022-03-14 18:46:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:46:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 45 @ 4625 updates, score 7.459) (writing took 1.0180273316800594 seconds)
2022-03-14 18:46:58 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-14 18:46:58 | INFO | train | epoch 045 | loss 5.56 | ppl 47.18 | wps 40259.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4625 | lr 0.000464991 | gnorm 0.8 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7561
KL Stats: Epoch 45 Divergences: Uniform: 4.883920317127583 Unigram: 2.9123419243608075
2022-03-14 18:46:58 | INFO | fairseq.trainer | begin training epoch 46
2022-03-14 18:46:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:48:56 | INFO | train_inner | epoch 046:     75 / 103 loss=5.521, ppl=45.93, wps=40195.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.808, loss_scale=16, train_wall=153, gb_free=20.8, wall=7680
2022-03-14 18:49:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:49:44 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 7.461 | ppl 176.16 | wps 66040.5 | wpb 2040.3 | bsz 4 | num_updates 4728 | best_loss 7.309
2022-03-14 18:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4728 updates
2022-03-14 18:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:49:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 46 @ 4728 updates, score 7.461) (writing took 0.9902049768716097 seconds)
2022-03-14 18:49:45 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-14 18:49:45 | INFO | train | epoch 046 | loss 5.509 | ppl 45.53 | wps 40238.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4728 | lr 0.000459898 | gnorm 0.812 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 7728
KL Stats: Epoch 46 Divergences: Uniform: 4.94657478493862 Unigram: 2.9467522187985318
2022-03-14 18:49:45 | INFO | fairseq.trainer | begin training epoch 47
2022-03-14 18:49:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:50:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 18:51:40 | INFO | train_inner | epoch 047:     73 / 103 loss=5.467, ppl=44.25, wps=39854.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.817, loss_scale=16, train_wall=154, gb_free=20.8, wall=7844
2022-03-14 18:52:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:52:31 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 7.485 | ppl 179.19 | wps 65979.1 | wpb 2040.3 | bsz 4 | num_updates 4830 | best_loss 7.309
2022-03-14 18:52:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4830 updates
2022-03-14 18:52:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:52:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:52:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 47 @ 4830 updates, score 7.485) (writing took 1.0185541221871972 seconds)
2022-03-14 18:52:32 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-14 18:52:32 | INFO | train | epoch 047 | loss 5.457 | ppl 43.93 | wps 39887.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 4830 | lr 0.000455016 | gnorm 0.81 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 7895
KL Stats: Epoch 47 Divergences: Uniform: 5.0034293760136235 Unigram: 2.9798323995008675
2022-03-14 18:52:32 | INFO | fairseq.trainer | begin training epoch 48
2022-03-14 18:52:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:54:22 | INFO | train_inner | epoch 048:     70 / 103 loss=5.424, ppl=42.94, wps=40246.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.8, loss_scale=16, train_wall=153, gb_free=20.8, wall=8006
2022-03-14 18:55:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:55:18 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 7.503 | ppl 181.39 | wps 66237.6 | wpb 2040.3 | bsz 4 | num_updates 4933 | best_loss 7.309
2022-03-14 18:55:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4933 updates
2022-03-14 18:55:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:55:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:55:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 48 @ 4933 updates, score 7.503) (writing took 1.0079243732616305 seconds)
2022-03-14 18:55:19 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-14 18:55:19 | INFO | train | epoch 048 | loss 5.409 | ppl 42.49 | wps 40284.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 4933 | lr 0.00045024 | gnorm 0.812 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8062
KL Stats: Epoch 48 Divergences: Uniform: 5.060891873541015 Unigram: 3.0114976607249386
2022-03-14 18:55:19 | INFO | fairseq.trainer | begin training epoch 49
2022-03-14 18:55:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:57:05 | INFO | train_inner | epoch 049:     67 / 103 loss=5.376, ppl=41.52, wps=40223.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.794, loss_scale=16, train_wall=153, gb_free=20.8, wall=8168
2022-03-14 18:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 18:58:05 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 7.536 | ppl 185.55 | wps 65545.8 | wpb 2040.3 | bsz 4 | num_updates 5036 | best_loss 7.309
2022-03-14 18:58:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5036 updates
2022-03-14 18:58:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:58:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 18:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 49 @ 5036 updates, score 7.536) (writing took 0.9701958559453487 seconds)
2022-03-14 18:58:06 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-14 18:58:06 | INFO | train | epoch 049 | loss 5.364 | ppl 41.18 | wps 40225.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5036 | lr 0.000445612 | gnorm 0.798 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8229
KL Stats: Epoch 49 Divergences: Uniform: 5.116441151042684 Unigram: 3.04409210405704
2022-03-14 18:58:06 | INFO | fairseq.trainer | begin training epoch 50
2022-03-14 18:58:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 18:59:47 | INFO | train_inner | epoch 050:     64 / 103 loss=5.334, ppl=40.35, wps=40166.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.807, loss_scale=16, train_wall=153, gb_free=20.8, wall=8331
2022-03-14 19:00:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:00:52 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 7.563 | ppl 189.11 | wps 66455.1 | wpb 2040.3 | bsz 4 | num_updates 5139 | best_loss 7.309
2022-03-14 19:00:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5139 updates
2022-03-14 19:00:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 50 @ 5139 updates, score 7.563) (writing took 0.9322262359783053 seconds)
2022-03-14 19:00:53 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-14 19:00:53 | INFO | train | epoch 050 | loss 5.319 | ppl 39.91 | wps 40256.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5139 | lr 0.000441124 | gnorm 0.81 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 8397
KL Stats: Epoch 50 Divergences: Uniform: 5.177603787769066 Unigram: 3.076059390605044
2022-03-14 19:00:53 | INFO | fairseq.trainer | begin training epoch 51
2022-03-14 19:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:02:30 | INFO | train_inner | epoch 051:     61 / 103 loss=5.29, ppl=39.12, wps=40282, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.818, loss_scale=16, train_wall=153, gb_free=20.8, wall=8493
2022-03-14 19:03:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:03:39 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 7.594 | ppl 193.18 | wps 66262.7 | wpb 2040.3 | bsz 4 | num_updates 5242 | best_loss 7.309
2022-03-14 19:03:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5242 updates
2022-03-14 19:03:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:03:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 51 @ 5242 updates, score 7.594) (writing took 0.9772682217881083 seconds)
2022-03-14 19:03:40 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-14 19:03:40 | INFO | train | epoch 051 | loss 5.275 | ppl 38.73 | wps 40297.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5242 | lr 0.000436769 | gnorm 0.816 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8564
KL Stats: Epoch 51 Divergences: Uniform: 5.234719545589558 Unigram: 3.1071846058106503
2022-03-14 19:03:40 | INFO | fairseq.trainer | begin training epoch 52
2022-03-14 19:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:04:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 19:05:13 | INFO | train_inner | epoch 052:     59 / 103 loss=5.253, ppl=38.13, wps=39854.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.811, loss_scale=16, train_wall=154, gb_free=20.8, wall=8657
2022-03-14 19:06:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:06:26 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 7.606 | ppl 194.76 | wps 65959.2 | wpb 2040.3 | bsz 4 | num_updates 5344 | best_loss 7.309
2022-03-14 19:06:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5344 updates
2022-03-14 19:06:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:06:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:06:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 52 @ 5344 updates, score 7.606) (writing took 0.9665867956355214 seconds)
2022-03-14 19:06:27 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-14 19:06:27 | INFO | train | epoch 052 | loss 5.234 | ppl 37.63 | wps 39886.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5344 | lr 0.00043258 | gnorm 0.801 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 8731
KL Stats: Epoch 52 Divergences: Uniform: 5.280065196697745 Unigram: 3.136782807872417
2022-03-14 19:06:27 | INFO | fairseq.trainer | begin training epoch 53
2022-03-14 19:06:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:07:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:07:57 | INFO | train_inner | epoch 053:     57 / 103 loss=5.209, ppl=36.98, wps=39863.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.803, loss_scale=8, train_wall=154, gb_free=20.8, wall=8821
2022-03-14 19:09:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:09:13 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 7.627 | ppl 197.69 | wps 66257.2 | wpb 2040.3 | bsz 4 | num_updates 5446 | best_loss 7.309
2022-03-14 19:09:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5446 updates
2022-03-14 19:09:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:09:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:09:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 53 @ 5446 updates, score 7.627) (writing took 0.9924193220213056 seconds)
2022-03-14 19:09:14 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-14 19:09:14 | INFO | train | epoch 053 | loss 5.194 | ppl 36.61 | wps 39897.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 5446 | lr 0.00042851 | gnorm 0.805 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 8897
KL Stats: Epoch 53 Divergences: Uniform: 5.336262068024187 Unigram: 3.1653819962080982
2022-03-14 19:09:14 | INFO | fairseq.trainer | begin training epoch 54
2022-03-14 19:09:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:10:40 | INFO | train_inner | epoch 054:     54 / 103 loss=5.175, ppl=36.12, wps=40231.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.821, loss_scale=8, train_wall=153, gb_free=20.8, wall=8983
2022-03-14 19:11:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:12:00 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 7.66 | ppl 202.23 | wps 65998.9 | wpb 2040.3 | bsz 4 | num_updates 5549 | best_loss 7.309
2022-03-14 19:12:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5549 updates
2022-03-14 19:12:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:12:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:12:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 54 @ 5549 updates, score 7.66) (writing took 0.9880962120369077 seconds)
2022-03-14 19:12:01 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-14 19:12:01 | INFO | train | epoch 054 | loss 5.157 | ppl 35.67 | wps 40248.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5549 | lr 0.000424515 | gnorm 0.827 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 9065
KL Stats: Epoch 54 Divergences: Uniform: 5.3899767788336 Unigram: 3.1937040368262877
2022-03-14 19:12:01 | INFO | fairseq.trainer | begin training epoch 55
2022-03-14 19:12:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:13:22 | INFO | train_inner | epoch 055:     51 / 103 loss=5.14, ppl=35.25, wps=40240.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.82, loss_scale=8, train_wall=153, gb_free=20.8, wall=9145
2022-03-14 19:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:14:47 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 7.669 | ppl 203.53 | wps 66707.3 | wpb 2040.3 | bsz 4 | num_updates 5652 | best_loss 7.309
2022-03-14 19:14:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5652 updates
2022-03-14 19:14:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:14:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 55 @ 5652 updates, score 7.669) (writing took 0.9571043392643332 seconds)
2022-03-14 19:14:48 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-14 19:14:48 | INFO | train | epoch 055 | loss 5.12 | ppl 34.77 | wps 40290 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5652 | lr 0.000420629 | gnorm 0.831 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9232
KL Stats: Epoch 55 Divergences: Uniform: 5.435335067126101 Unigram: 3.221418887282523
2022-03-14 19:14:48 | INFO | fairseq.trainer | begin training epoch 56
2022-03-14 19:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:16:04 | INFO | train_inner | epoch 056:     48 / 103 loss=5.097, ppl=34.22, wps=40258.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.828, loss_scale=8, train_wall=153, gb_free=20.8, wall=9308
2022-03-14 19:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:17:34 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 7.683 | ppl 205.54 | wps 65764.5 | wpb 2040.3 | bsz 4 | num_updates 5755 | best_loss 7.309
2022-03-14 19:17:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5755 updates
2022-03-14 19:17:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:17:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 56 @ 5755 updates, score 7.683) (writing took 1.0531094623729587 seconds)
2022-03-14 19:17:35 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-14 19:17:35 | INFO | train | epoch 056 | loss 5.083 | ppl 33.88 | wps 40267.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5755 | lr 0.000416848 | gnorm 0.816 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9399
KL Stats: Epoch 56 Divergences: Uniform: 5.480716401858118 Unigram: 3.2475252488905473
2022-03-14 19:17:35 | INFO | fairseq.trainer | begin training epoch 57
2022-03-14 19:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:18:46 | INFO | train_inner | epoch 057:     45 / 103 loss=5.068, ppl=33.55, wps=40243.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.811, loss_scale=8, train_wall=153, gb_free=20.8, wall=9470
2022-03-14 19:20:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:20:21 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 7.721 | ppl 210.91 | wps 66135.8 | wpb 2040.3 | bsz 4 | num_updates 5858 | best_loss 7.309
2022-03-14 19:20:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5858 updates
2022-03-14 19:20:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:20:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:20:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 57 @ 5858 updates, score 7.721) (writing took 0.9684130623936653 seconds)
2022-03-14 19:20:22 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-14 19:20:22 | INFO | train | epoch 057 | loss 5.048 | ppl 33.08 | wps 40295.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5858 | lr 0.000413167 | gnorm 0.82 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9566
KL Stats: Epoch 57 Divergences: Uniform: 5.5339665351522545 Unigram: 3.2764863812164946
2022-03-14 19:20:22 | INFO | fairseq.trainer | begin training epoch 58
2022-03-14 19:20:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:21:29 | INFO | train_inner | epoch 058:     42 / 103 loss=5.036, ppl=32.82, wps=40243.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.832, loss_scale=16, train_wall=153, gb_free=20.8, wall=9632
2022-03-14 19:23:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:23:08 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 7.744 | ppl 214.31 | wps 66333.7 | wpb 2040.3 | bsz 4 | num_updates 5961 | best_loss 7.309
2022-03-14 19:23:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5961 updates
2022-03-14 19:23:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:23:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:23:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 58 @ 5961 updates, score 7.744) (writing took 0.993430595844984 seconds)
2022-03-14 19:23:09 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-14 19:23:09 | INFO | train | epoch 058 | loss 5.015 | ppl 32.33 | wps 40275.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 5961 | lr 0.000409582 | gnorm 0.818 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 9733
KL Stats: Epoch 58 Divergences: Uniform: 5.5776037723363086 Unigram: 3.3016665570566697
2022-03-14 19:23:09 | INFO | fairseq.trainer | begin training epoch 59
2022-03-14 19:23:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:23:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:24:12 | INFO | train_inner | epoch 059:     40 / 103 loss=5.001, ppl=32.03, wps=39852.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.826, loss_scale=8, train_wall=154, gb_free=20.8, wall=9796
2022-03-14 19:25:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:25:55 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 7.777 | ppl 219.26 | wps 66033.2 | wpb 2040.3 | bsz 4 | num_updates 6063 | best_loss 7.309
2022-03-14 19:25:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6063 updates
2022-03-14 19:25:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:25:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:25:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 59 @ 6063 updates, score 7.777) (writing took 0.9939831271767616 seconds)
2022-03-14 19:25:56 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-14 19:25:56 | INFO | train | epoch 059 | loss 4.983 | ppl 31.63 | wps 39862 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6063 | lr 0.000406122 | gnorm 0.835 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 9900
KL Stats: Epoch 59 Divergences: Uniform: 5.625829630575009 Unigram: 3.3263094682823255
2022-03-14 19:25:56 | INFO | fairseq.trainer | begin training epoch 60
2022-03-14 19:25:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:26:55 | INFO | train_inner | epoch 060:     37 / 103 loss=4.974, ppl=31.42, wps=40211.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.825, loss_scale=8, train_wall=153, gb_free=20.8, wall=9958
2022-03-14 19:28:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:28:43 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 7.789 | ppl 221.19 | wps 66624.9 | wpb 2040.3 | bsz 4 | num_updates 6166 | best_loss 7.309
2022-03-14 19:28:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6166 updates
2022-03-14 19:28:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:28:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:28:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 60 @ 6166 updates, score 7.789) (writing took 1.0140765309333801 seconds)
2022-03-14 19:28:44 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-14 19:28:44 | INFO | train | epoch 060 | loss 4.952 | ppl 30.94 | wps 40208.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6166 | lr 0.000402715 | gnorm 0.825 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10067
KL Stats: Epoch 60 Divergences: Uniform: 5.664869300615003 Unigram: 3.34939788714539
2022-03-14 19:28:44 | INFO | fairseq.trainer | begin training epoch 61
2022-03-14 19:28:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:29:37 | INFO | train_inner | epoch 061:     34 / 103 loss=4.943, ppl=30.76, wps=40168.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6200, lr=0.00040161, gnorm=0.827, loss_scale=8, train_wall=153, gb_free=20.8, wall=10121
2022-03-14 19:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:31:30 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 7.817 | ppl 225.48 | wps 64877.7 | wpb 2040.3 | bsz 4 | num_updates 6269 | best_loss 7.309
2022-03-14 19:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 6269 updates
2022-03-14 19:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:31:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:31:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 61 @ 6269 updates, score 7.817) (writing took 0.964896003715694 seconds)
2022-03-14 19:31:31 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-14 19:31:31 | INFO | train | epoch 061 | loss 4.922 | ppl 30.32 | wps 40242.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6269 | lr 0.000399393 | gnorm 0.829 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 10234
KL Stats: Epoch 61 Divergences: Uniform: 5.712451243567178 Unigram: 3.375361322962041
2022-03-14 19:31:31 | INFO | fairseq.trainer | begin training epoch 62
2022-03-14 19:31:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:32:20 | INFO | train_inner | epoch 062:     31 / 103 loss=4.909, ppl=30.04, wps=40098.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6300, lr=0.00039841, gnorm=0.838, loss_scale=8, train_wall=153, gb_free=20.8, wall=10284
2022-03-14 19:34:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:34:18 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 7.842 | ppl 229.52 | wps 66784.5 | wpb 2040.3 | bsz 4 | num_updates 6372 | best_loss 7.309
2022-03-14 19:34:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 6372 updates
2022-03-14 19:34:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 62 @ 6372 updates, score 7.842) (writing took 0.9381525199860334 seconds)
2022-03-14 19:34:19 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-14 19:34:19 | INFO | train | epoch 062 | loss 4.892 | ppl 29.7 | wps 39981.3 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 6372 | lr 0.000396152 | gnorm 0.841 | loss_scale 8 | train_wall 159 | gb_free 20.8 | wall 10402
KL Stats: Epoch 62 Divergences: Uniform: 5.748282098998126 Unigram: 3.3984208994728977
2022-03-14 19:34:19 | INFO | fairseq.trainer | begin training epoch 63
2022-03-14 19:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:35:03 | INFO | train_inner | epoch 063:     28 / 103 loss=4.888, ppl=29.6, wps=40049.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=6400, lr=0.000395285, gnorm=0.842, loss_scale=8, train_wall=154, gb_free=20.8, wall=10447
2022-03-14 19:37:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:37:05 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 7.86 | ppl 232.31 | wps 65901.8 | wpb 2040.3 | bsz 4 | num_updates 6475 | best_loss 7.309
2022-03-14 19:37:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 6475 updates
2022-03-14 19:37:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:37:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 63 @ 6475 updates, score 7.86) (writing took 0.9619122771546245 seconds)
2022-03-14 19:37:06 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-14 19:37:06 | INFO | train | epoch 063 | loss 4.865 | ppl 29.13 | wps 40215.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6475 | lr 0.000392989 | gnorm 0.841 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 10570
KL Stats: Epoch 63 Divergences: Uniform: 5.791737679428544 Unigram: 3.421254120630655
2022-03-14 19:37:06 | INFO | fairseq.trainer | begin training epoch 64
2022-03-14 19:37:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:37:46 | INFO | train_inner | epoch 064:     25 / 103 loss=4.86, ppl=29.05, wps=40191.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6500, lr=0.000392232, gnorm=0.839, loss_scale=16, train_wall=153, gb_free=20.8, wall=10609
2022-03-14 19:39:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:39:52 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 7.875 | ppl 234.82 | wps 66024.5 | wpb 2040.3 | bsz 4 | num_updates 6578 | best_loss 7.309
2022-03-14 19:39:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 6578 updates
2022-03-14 19:39:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:39:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:39:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 64 @ 6578 updates, score 7.875) (writing took 0.9710050085559487 seconds)
2022-03-14 19:39:53 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-14 19:39:53 | INFO | train | epoch 064 | loss 4.838 | ppl 28.6 | wps 40278 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6578 | lr 0.0003899 | gnorm 0.84 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 10737
KL Stats: Epoch 64 Divergences: Uniform: 5.830762242621996 Unigram: 3.443694883025977
2022-03-14 19:39:53 | INFO | fairseq.trainer | begin training epoch 65
2022-03-14 19:39:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:40:28 | INFO | train_inner | epoch 065:     22 / 103 loss=4.834, ppl=28.52, wps=40245.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=6600, lr=0.000389249, gnorm=0.834, loss_scale=16, train_wall=153, gb_free=20.8, wall=10772
2022-03-14 19:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:42:39 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 7.907 | ppl 240.07 | wps 66260.2 | wpb 2040.3 | bsz 4 | num_updates 6681 | best_loss 7.309
2022-03-14 19:42:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 6681 updates
2022-03-14 19:42:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:42:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:42:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 65 @ 6681 updates, score 7.907) (writing took 0.9825782952830195 seconds)
2022-03-14 19:42:40 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-14 19:42:40 | INFO | train | epoch 065 | loss 4.81 | ppl 28.06 | wps 40292.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6681 | lr 0.000386883 | gnorm 0.848 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 10904
KL Stats: Epoch 65 Divergences: Uniform: 5.870308016362809 Unigram: 3.4656289992590255
2022-03-14 19:42:40 | INFO | fairseq.trainer | begin training epoch 66
2022-03-14 19:42:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:42:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 19:43:12 | INFO | train_inner | epoch 066:     20 / 103 loss=4.807, ppl=27.99, wps=39873.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=6700, lr=0.000386334, gnorm=0.852, loss_scale=8, train_wall=154, gb_free=20.8, wall=10935
2022-03-14 19:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:45:26 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 7.92 | ppl 242.11 | wps 66244.7 | wpb 2040.3 | bsz 4 | num_updates 6783 | best_loss 7.309
2022-03-14 19:45:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 6783 updates
2022-03-14 19:45:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 66 @ 6783 updates, score 7.92) (writing took 1.0710832616314292 seconds)
2022-03-14 19:45:27 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-14 19:45:27 | INFO | train | epoch 066 | loss 4.785 | ppl 27.56 | wps 39879.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 6783 | lr 0.000383963 | gnorm 0.835 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11071
KL Stats: Epoch 66 Divergences: Uniform: 5.9091295944500075 Unigram: 3.4859141700186242
2022-03-14 19:45:27 | INFO | fairseq.trainer | begin training epoch 67
2022-03-14 19:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:45:54 | INFO | train_inner | epoch 067:     17 / 103 loss=4.78, ppl=27.48, wps=40235.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=6800, lr=0.000383482, gnorm=0.837, loss_scale=8, train_wall=153, gb_free=20.8, wall=11098
2022-03-14 19:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:48:13 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 7.92 | ppl 242.26 | wps 66133.6 | wpb 2040.3 | bsz 4 | num_updates 6886 | best_loss 7.309
2022-03-14 19:48:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 6886 updates
2022-03-14 19:48:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:48:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:48:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 67 @ 6886 updates, score 7.92) (writing took 1.0047630313783884 seconds)
2022-03-14 19:48:14 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-14 19:48:14 | INFO | train | epoch 067 | loss 4.762 | ppl 27.13 | wps 40243 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6886 | lr 0.00038108 | gnorm 0.851 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 11238
KL Stats: Epoch 67 Divergences: Uniform: 5.943963028043892 Unigram: 3.506148119383149
2022-03-14 19:48:14 | INFO | fairseq.trainer | begin training epoch 68
2022-03-14 19:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:48:37 | INFO | train_inner | epoch 068:     14 / 103 loss=4.762, ppl=27.14, wps=40204.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=6900, lr=0.000380693, gnorm=0.849, loss_scale=8, train_wall=153, gb_free=20.8, wall=11260
2022-03-14 19:50:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:51:01 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 7.959 | ppl 248.79 | wps 66221.9 | wpb 2040.3 | bsz 4 | num_updates 6989 | best_loss 7.309
2022-03-14 19:51:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 6989 updates
2022-03-14 19:51:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:51:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:51:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 68 @ 6989 updates, score 7.959) (writing took 0.957515268586576 seconds)
2022-03-14 19:51:01 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-14 19:51:01 | INFO | train | epoch 068 | loss 4.735 | ppl 26.64 | wps 40272.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 6989 | lr 0.000378262 | gnorm 0.838 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11405
KL Stats: Epoch 68 Divergences: Uniform: 5.9827792672384925 Unigram: 3.527156402697323
2022-03-14 19:51:01 | INFO | fairseq.trainer | begin training epoch 69
2022-03-14 19:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:51:19 | INFO | train_inner | epoch 069:     11 / 103 loss=4.733, ppl=26.59, wps=40232.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=7000, lr=0.000377964, gnorm=0.841, loss_scale=8, train_wall=153, gb_free=20.8, wall=11423
2022-03-14 19:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:53:48 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 7.982 | ppl 252.86 | wps 66183.3 | wpb 2040.3 | bsz 4 | num_updates 7092 | best_loss 7.309
2022-03-14 19:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 7092 updates
2022-03-14 19:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:53:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 69 @ 7092 updates, score 7.982) (writing took 1.03922522906214 seconds)
2022-03-14 19:53:49 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-14 19:53:49 | INFO | train | epoch 069 | loss 4.713 | ppl 26.23 | wps 40267.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7092 | lr 0.000375505 | gnorm 0.855 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 11572
KL Stats: Epoch 69 Divergences: Uniform: 6.018962619216094 Unigram: 3.5468436093486466
2022-03-14 19:53:49 | INFO | fairseq.trainer | begin training epoch 70
2022-03-14 19:53:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:54:01 | INFO | train_inner | epoch 070:      8 / 103 loss=4.714, ppl=26.25, wps=40243, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7100, lr=0.000375293, gnorm=0.856, loss_scale=8, train_wall=153, gb_free=20.8, wall=11585
2022-03-14 19:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:56:35 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 7.987 | ppl 253.73 | wps 65776.5 | wpb 2040.3 | bsz 4 | num_updates 7195 | best_loss 7.309
2022-03-14 19:56:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 7195 updates
2022-03-14 19:56:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:56:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 70 @ 7195 updates, score 7.987) (writing took 1.012386036105454 seconds)
2022-03-14 19:56:36 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-14 19:56:36 | INFO | train | epoch 070 | loss 4.691 | ppl 25.83 | wps 40277.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7195 | lr 0.000372807 | gnorm 0.861 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 11739
KL Stats: Epoch 70 Divergences: Uniform: 6.052144882634265 Unigram: 3.5657102578525466
2022-03-14 19:56:36 | INFO | fairseq.trainer | begin training epoch 71
2022-03-14 19:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:56:44 | INFO | train_inner | epoch 071:      5 / 103 loss=4.695, ppl=25.91, wps=40238, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=7200, lr=0.000372678, gnorm=0.862, loss_scale=16, train_wall=153, gb_free=20.8, wall=11747
2022-03-14 19:59:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 19:59:21 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 8.027 | ppl 260.76 | wps 66072 | wpb 2040.3 | bsz 4 | num_updates 7298 | best_loss 7.309
2022-03-14 19:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 7298 updates
2022-03-14 19:59:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 19:59:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 71 @ 7298 updates, score 8.027) (writing took 1.0140610132366419 seconds)
2022-03-14 19:59:23 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-14 19:59:23 | INFO | train | epoch 071 | loss 4.669 | ppl 25.45 | wps 40298.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7298 | lr 0.000370167 | gnorm 0.85 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 11906
KL Stats: Epoch 71 Divergences: Uniform: 6.079464170589917 Unigram: 3.5820564267213575
2022-03-14 19:59:23 | INFO | fairseq.trainer | begin training epoch 72
2022-03-14 19:59:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 19:59:26 | INFO | train_inner | epoch 072:      2 / 103 loss=4.671, ppl=25.47, wps=40271.2, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=7300, lr=0.000370117, gnorm=0.849, loss_scale=16, train_wall=153, gb_free=20.8, wall=11909
2022-03-14 20:02:04 | INFO | train_inner | epoch 072:    102 / 103 loss=4.648, ppl=25.07, wps=41415.5, ups=0.63, wpb=65530.9, bsz=128, num_updates=7400, lr=0.000367607, gnorm=0.852, loss_scale=16, train_wall=153, gb_free=20.8, wall=12067
2022-03-14 20:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:02:09 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 8.044 | ppl 263.85 | wps 66076 | wpb 2040.3 | bsz 4 | num_updates 7401 | best_loss 7.309
2022-03-14 20:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 7401 updates
2022-03-14 20:02:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 72 @ 7401 updates, score 8.044) (writing took 0.9956350112333894 seconds)
2022-03-14 20:02:10 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-14 20:02:10 | INFO | train | epoch 072 | loss 4.647 | ppl 25.06 | wps 40249.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7401 | lr 0.000367582 | gnorm 0.853 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 12073
KL Stats: Epoch 72 Divergences: Uniform: 6.117824648583185 Unigram: 3.6015787932047645
2022-03-14 20:02:10 | INFO | fairseq.trainer | begin training epoch 73
2022-03-14 20:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:04:46 | INFO | train_inner | epoch 073:     99 / 103 loss=4.622, ppl=24.63, wps=40238.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7500, lr=0.000365148, gnorm=0.864, loss_scale=16, train_wall=153, gb_free=20.8, wall=12230
2022-03-14 20:04:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:04:56 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 8.056 | ppl 266.14 | wps 66163.6 | wpb 2040.3 | bsz 4 | num_updates 7504 | best_loss 7.309
2022-03-14 20:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 7504 updates
2022-03-14 20:04:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 73 @ 7504 updates, score 8.056) (writing took 1.000710640102625 seconds)
2022-03-14 20:04:57 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-14 20:04:57 | INFO | train | epoch 073 | loss 4.626 | ppl 24.69 | wps 40262.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7504 | lr 0.000365051 | gnorm 0.865 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 12240
KL Stats: Epoch 73 Divergences: Uniform: 6.145918542455776 Unigram: 3.6192925177150106
2022-03-14 20:04:57 | INFO | fairseq.trainer | begin training epoch 74
2022-03-14 20:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:05:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:07:30 | INFO | train_inner | epoch 074:     97 / 103 loss=4.605, ppl=24.33, wps=39809.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=7600, lr=0.000362738, gnorm=0.862, loss_scale=8, train_wall=155, gb_free=20.8, wall=12394
2022-03-14 20:07:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:07:43 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 8.099 | ppl 274.26 | wps 66752.9 | wpb 2040.3 | bsz 4 | num_updates 7606 | best_loss 7.309
2022-03-14 20:07:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 7606 updates
2022-03-14 20:07:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:07:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 74 @ 7606 updates, score 8.099) (writing took 0.9749648906290531 seconds)
2022-03-14 20:07:44 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-14 20:07:44 | INFO | train | epoch 074 | loss 4.604 | ppl 24.32 | wps 39864.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 7606 | lr 0.000362595 | gnorm 0.859 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 12407
KL Stats: Epoch 74 Divergences: Uniform: 6.179603786124776 Unigram: 3.6393156926392543
2022-03-14 20:07:44 | INFO | fairseq.trainer | begin training epoch 75
2022-03-14 20:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:10:12 | INFO | train_inner | epoch 075:     94 / 103 loss=4.584, ppl=23.99, wps=40271.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7700, lr=0.000360375, gnorm=0.863, loss_scale=8, train_wall=153, gb_free=20.8, wall=12556
2022-03-14 20:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:10:30 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 8.089 | ppl 272.26 | wps 65823.8 | wpb 2040.3 | bsz 4 | num_updates 7709 | best_loss 7.309
2022-03-14 20:10:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 7709 updates
2022-03-14 20:10:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 75 @ 7709 updates, score 8.089) (writing took 0.9816066948696971 seconds)
2022-03-14 20:10:31 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-14 20:10:31 | INFO | train | epoch 075 | loss 4.586 | ppl 24.01 | wps 40299.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7709 | lr 0.000360165 | gnorm 0.87 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12574
KL Stats: Epoch 75 Divergences: Uniform: 6.2044726858247765 Unigram: 3.655062441319041
2022-03-14 20:10:31 | INFO | fairseq.trainer | begin training epoch 76
2022-03-14 20:10:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:12:55 | INFO | train_inner | epoch 076:     91 / 103 loss=4.564, ppl=23.66, wps=40248.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7800, lr=0.000358057, gnorm=0.861, loss_scale=8, train_wall=153, gb_free=20.8, wall=12718
2022-03-14 20:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:13:17 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 8.114 | ppl 277.12 | wps 66267.2 | wpb 2040.3 | bsz 4 | num_updates 7812 | best_loss 7.309
2022-03-14 20:13:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 7812 updates
2022-03-14 20:13:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 76 @ 7812 updates, score 8.114) (writing took 1.007035955786705 seconds)
2022-03-14 20:13:18 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-14 20:13:18 | INFO | train | epoch 076 | loss 4.566 | ppl 23.69 | wps 40276.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7812 | lr 0.000357782 | gnorm 0.858 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12741
KL Stats: Epoch 76 Divergences: Uniform: 6.230493150874507 Unigram: 3.670546966460138
2022-03-14 20:13:18 | INFO | fairseq.trainer | begin training epoch 77
2022-03-14 20:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:15:37 | INFO | train_inner | epoch 077:     88 / 103 loss=4.549, ppl=23.42, wps=40240.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=7900, lr=0.000355784, gnorm=0.859, loss_scale=8, train_wall=153, gb_free=20.8, wall=12881
2022-03-14 20:16:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:16:04 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 8.128 | ppl 279.67 | wps 66253 | wpb 2040.3 | bsz 4 | num_updates 7915 | best_loss 7.309
2022-03-14 20:16:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 7915 updates
2022-03-14 20:16:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:16:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:16:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 77 @ 7915 updates, score 8.128) (writing took 0.981635301373899 seconds)
2022-03-14 20:16:05 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-14 20:16:05 | INFO | train | epoch 077 | loss 4.547 | ppl 23.38 | wps 40281.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 7915 | lr 0.000355447 | gnorm 0.856 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 12908
KL Stats: Epoch 77 Divergences: Uniform: 6.261776542733723 Unigram: 3.6863181625231527
2022-03-14 20:16:05 | INFO | fairseq.trainer | begin training epoch 78
2022-03-14 20:16:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:18:19 | INFO | train_inner | epoch 078:     85 / 103 loss=4.531, ppl=23.12, wps=40269.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8000, lr=0.000353553, gnorm=0.876, loss_scale=8, train_wall=153, gb_free=20.8, wall=13043
2022-03-14 20:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:18:51 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 8.164 | ppl 286.79 | wps 65963.7 | wpb 2040.3 | bsz 4 | num_updates 8018 | best_loss 7.309
2022-03-14 20:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 8018 updates
2022-03-14 20:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 78 @ 8018 updates, score 8.164) (writing took 1.0733259301632643 seconds)
2022-03-14 20:18:52 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-14 20:18:52 | INFO | train | epoch 078 | loss 4.53 | ppl 23.1 | wps 40279.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8018 | lr 0.000353156 | gnorm 0.877 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 13075
KL Stats: Epoch 78 Divergences: Uniform: 6.29407543380193 Unigram: 3.7021865058357375
2022-03-14 20:18:52 | INFO | fairseq.trainer | begin training epoch 79
2022-03-14 20:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:21:02 | INFO | train_inner | epoch 079:     82 / 103 loss=4.513, ppl=22.83, wps=40236.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8100, lr=0.000351364, gnorm=0.866, loss_scale=16, train_wall=153, gb_free=20.8, wall=13205
2022-03-14 20:21:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:21:38 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 8.174 | ppl 288.75 | wps 66087.8 | wpb 2040.3 | bsz 4 | num_updates 8121 | best_loss 7.309
2022-03-14 20:21:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 8121 updates
2022-03-14 20:21:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:21:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 79 @ 8121 updates, score 8.174) (writing took 0.9269886594265699 seconds)
2022-03-14 20:21:39 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-14 20:21:39 | INFO | train | epoch 079 | loss 4.513 | ppl 22.83 | wps 40306.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8121 | lr 0.00035091 | gnorm 0.863 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13242
KL Stats: Epoch 79 Divergences: Uniform: 6.317526660959876 Unigram: 3.7179986836586685
2022-03-14 20:21:39 | INFO | fairseq.trainer | begin training epoch 80
2022-03-14 20:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:23:44 | INFO | train_inner | epoch 080:     79 / 103 loss=4.497, ppl=22.57, wps=40270, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8200, lr=0.000349215, gnorm=0.869, loss_scale=16, train_wall=153, gb_free=20.8, wall=13367
2022-03-14 20:24:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:24:25 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 8.172 | ppl 288.5 | wps 66243.9 | wpb 2040.3 | bsz 4 | num_updates 8224 | best_loss 7.309
2022-03-14 20:24:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 8224 updates
2022-03-14 20:24:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:24:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:24:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 80 @ 8224 updates, score 8.172) (writing took 0.9611772894859314 seconds)
2022-03-14 20:24:26 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-14 20:24:26 | INFO | train | epoch 080 | loss 4.496 | ppl 22.57 | wps 40283.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8224 | lr 0.000348705 | gnorm 0.88 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 13409
KL Stats: Epoch 80 Divergences: Uniform: 6.34314469410769 Unigram: 3.7319830676657877
2022-03-14 20:24:26 | INFO | fairseq.trainer | begin training epoch 81
2022-03-14 20:24:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:25:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:26:28 | INFO | train_inner | epoch 081:     77 / 103 loss=4.483, ppl=22.37, wps=39846, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=8300, lr=0.000347105, gnorm=0.888, loss_scale=8, train_wall=154, gb_free=20.8, wall=13531
2022-03-14 20:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:27:12 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 8.201 | ppl 294.37 | wps 66435.3 | wpb 2040.3 | bsz 4 | num_updates 8326 | best_loss 7.309
2022-03-14 20:27:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 8326 updates
2022-03-14 20:27:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:27:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:27:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 81 @ 8326 updates, score 8.201) (writing took 0.9104353720322251 seconds)
2022-03-14 20:27:13 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-14 20:27:13 | INFO | train | epoch 081 | loss 4.477 | ppl 22.27 | wps 39868.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 8326 | lr 0.000346563 | gnorm 0.881 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13576
KL Stats: Epoch 81 Divergences: Uniform: 6.372642461251318 Unigram: 3.7465042894313596
2022-03-14 20:27:13 | INFO | fairseq.trainer | begin training epoch 82
2022-03-14 20:27:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:29:10 | INFO | train_inner | epoch 082:     74 / 103 loss=4.464, ppl=22.07, wps=40213.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8400, lr=0.000345033, gnorm=0.873, loss_scale=8, train_wall=153, gb_free=20.8, wall=13693
2022-03-14 20:29:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:29:59 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 8.215 | ppl 297.09 | wps 66071.6 | wpb 2040.3 | bsz 4 | num_updates 8429 | best_loss 7.309
2022-03-14 20:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 8429 updates
2022-03-14 20:29:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 82 @ 8429 updates, score 8.215) (writing took 0.9526191027835011 seconds)
2022-03-14 20:30:00 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-14 20:30:00 | INFO | train | epoch 082 | loss 4.461 | ppl 22.02 | wps 40260.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8429 | lr 0.000344439 | gnorm 0.877 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 13743
KL Stats: Epoch 82 Divergences: Uniform: 6.395008952234457 Unigram: 3.763255443201209
2022-03-14 20:30:00 | INFO | fairseq.trainer | begin training epoch 83
2022-03-14 20:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:31:52 | INFO | train_inner | epoch 083:     71 / 103 loss=4.445, ppl=21.78, wps=40254.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8500, lr=0.000342997, gnorm=0.865, loss_scale=8, train_wall=153, gb_free=20.8, wall=13856
2022-03-14 20:32:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:32:46 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 8.224 | ppl 298.98 | wps 66077.1 | wpb 2040.3 | bsz 4 | num_updates 8532 | best_loss 7.309
2022-03-14 20:32:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 8532 updates
2022-03-14 20:32:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:32:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:32:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 83 @ 8532 updates, score 8.224) (writing took 1.0078094135969877 seconds)
2022-03-14 20:32:47 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-14 20:32:47 | INFO | train | epoch 083 | loss 4.446 | ppl 21.8 | wps 40278.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8532 | lr 0.000342353 | gnorm 0.868 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 13910
KL Stats: Epoch 83 Divergences: Uniform: 6.420495698345896 Unigram: 3.7755390581816335
2022-03-14 20:32:47 | INFO | fairseq.trainer | begin training epoch 84
2022-03-14 20:32:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:34:34 | INFO | train_inner | epoch 084:     68 / 103 loss=4.436, ppl=21.64, wps=40258.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8600, lr=0.000340997, gnorm=0.881, loss_scale=8, train_wall=153, gb_free=20.8, wall=14018
2022-03-14 20:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:35:33 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 8.238 | ppl 301.95 | wps 65951.6 | wpb 2040.3 | bsz 4 | num_updates 8635 | best_loss 7.309
2022-03-14 20:35:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 8635 updates
2022-03-14 20:35:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 84 @ 8635 updates, score 8.238) (writing took 1.0982339959591627 seconds)
2022-03-14 20:35:34 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-14 20:35:34 | INFO | train | epoch 084 | loss 4.43 | ppl 21.56 | wps 40264.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8635 | lr 0.000340305 | gnorm 0.87 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14077
KL Stats: Epoch 84 Divergences: Uniform: 6.44037423956346 Unigram: 3.7892014434382335
2022-03-14 20:35:34 | INFO | fairseq.trainer | begin training epoch 85
2022-03-14 20:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:37:17 | INFO | train_inner | epoch 085:     65 / 103 loss=4.42, ppl=21.41, wps=40214.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=8700, lr=0.000339032, gnorm=0.878, loss_scale=8, train_wall=153, gb_free=20.8, wall=14180
2022-03-14 20:38:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:38:20 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 8.257 | ppl 305.93 | wps 66072.6 | wpb 2040.3 | bsz 4 | num_updates 8738 | best_loss 7.309
2022-03-14 20:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 8738 updates
2022-03-14 20:38:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:38:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:38:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 85 @ 8738 updates, score 8.257) (writing took 0.9609280889853835 seconds)
2022-03-14 20:38:21 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-14 20:38:21 | INFO | train | epoch 085 | loss 4.414 | ppl 21.32 | wps 40275.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8738 | lr 0.000338294 | gnorm 0.882 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 14245
KL Stats: Epoch 85 Divergences: Uniform: 6.464298698085773 Unigram: 3.802593346525966
2022-03-14 20:38:21 | INFO | fairseq.trainer | begin training epoch 86
2022-03-14 20:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:39:59 | INFO | train_inner | epoch 086:     62 / 103 loss=4.406, ppl=21.2, wps=40245.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=8800, lr=0.0003371, gnorm=0.874, loss_scale=16, train_wall=153, gb_free=20.8, wall=14343
2022-03-14 20:41:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:41:07 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 8.265 | ppl 307.66 | wps 65596.7 | wpb 2040.3 | bsz 4 | num_updates 8841 | best_loss 7.309
2022-03-14 20:41:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 8841 updates
2022-03-14 20:41:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:41:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:41:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 86 @ 8841 updates, score 8.265) (writing took 1.0002498663961887 seconds)
2022-03-14 20:41:08 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-14 20:41:08 | INFO | train | epoch 086 | loss 4.4 | ppl 21.11 | wps 40275.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8841 | lr 0.000336317 | gnorm 0.881 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 14412
KL Stats: Epoch 86 Divergences: Uniform: 6.486833047814209 Unigram: 3.815187213963645
2022-03-14 20:41:08 | INFO | fairseq.trainer | begin training epoch 87
2022-03-14 20:41:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:42:41 | INFO | train_inner | epoch 087:     59 / 103 loss=4.388, ppl=20.94, wps=40243.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=8900, lr=0.000335201, gnorm=0.886, loss_scale=16, train_wall=153, gb_free=20.8, wall=14505
2022-03-14 20:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:43:54 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 8.281 | ppl 311 | wps 66233.4 | wpb 2040.3 | bsz 4 | num_updates 8944 | best_loss 7.309
2022-03-14 20:43:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 8944 updates
2022-03-14 20:43:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:43:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:43:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 87 @ 8944 updates, score 8.281) (writing took 1.002717669121921 seconds)
2022-03-14 20:43:55 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-14 20:43:55 | INFO | train | epoch 087 | loss 4.385 | ppl 20.9 | wps 40291.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 8944 | lr 0.000334375 | gnorm 0.888 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 14578
KL Stats: Epoch 87 Divergences: Uniform: 6.506465286417629 Unigram: 3.8273337784037955
2022-03-14 20:43:55 | INFO | fairseq.trainer | begin training epoch 88
2022-03-14 20:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:45:24 | INFO | train_inner | epoch 088:     56 / 103 loss=4.376, ppl=20.77, wps=40204.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9000, lr=0.000333333, gnorm=0.893, loss_scale=16, train_wall=153, gb_free=20.8, wall=14667
2022-03-14 20:46:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:46:41 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 8.298 | ppl 314.66 | wps 66450.8 | wpb 2040.3 | bsz 4 | num_updates 9047 | best_loss 7.309
2022-03-14 20:46:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 9047 updates
2022-03-14 20:46:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:46:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:46:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 88 @ 9047 updates, score 8.298) (writing took 0.9630138725042343 seconds)
2022-03-14 20:46:42 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-14 20:46:42 | INFO | train | epoch 088 | loss 4.37 | ppl 20.68 | wps 40237.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9047 | lr 0.000332466 | gnorm 0.882 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 14746
KL Stats: Epoch 88 Divergences: Uniform: 6.5243093092856315 Unigram: 3.8412566604137246
2022-03-14 20:46:42 | INFO | fairseq.trainer | begin training epoch 89
2022-03-14 20:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:48:06 | INFO | train_inner | epoch 089:     53 / 103 loss=4.365, ppl=20.61, wps=40233.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9100, lr=0.000331497, gnorm=0.871, loss_scale=16, train_wall=153, gb_free=20.8, wall=14830
2022-03-14 20:48:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 20:49:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:49:28 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 8.317 | ppl 319.01 | wps 66381.7 | wpb 2040.3 | bsz 4 | num_updates 9149 | best_loss 7.309
2022-03-14 20:49:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 9149 updates
2022-03-14 20:49:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:49:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 89 @ 9149 updates, score 8.317) (writing took 0.9428314296528697 seconds)
2022-03-14 20:49:29 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-14 20:49:29 | INFO | train | epoch 089 | loss 4.356 | ppl 20.48 | wps 39836.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 9149 | lr 0.000330608 | gnorm 0.885 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 14913
KL Stats: Epoch 89 Divergences: Uniform: 6.547376393061782 Unigram: 3.852897636747483
2022-03-14 20:49:29 | INFO | fairseq.trainer | begin training epoch 90
2022-03-14 20:49:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:50:50 | INFO | train_inner | epoch 090:     51 / 103 loss=4.349, ppl=20.38, wps=39814.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9200, lr=0.00032969, gnorm=0.898, loss_scale=8, train_wall=155, gb_free=20.8, wall=14994
2022-03-14 20:52:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:52:15 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 8.33 | ppl 321.78 | wps 65945.6 | wpb 2040.3 | bsz 4 | num_updates 9252 | best_loss 7.309
2022-03-14 20:52:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 9252 updates
2022-03-14 20:52:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:52:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:52:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 90 @ 9252 updates, score 8.33) (writing took 1.014047896489501 seconds)
2022-03-14 20:52:16 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-14 20:52:16 | INFO | train | epoch 090 | loss 4.343 | ppl 20.29 | wps 40261.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9252 | lr 0.000328762 | gnorm 0.894 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15080
KL Stats: Epoch 90 Divergences: Uniform: 6.567107942868086 Unigram: 3.8656809616369463
2022-03-14 20:52:17 | INFO | fairseq.trainer | begin training epoch 91
2022-03-14 20:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:53:32 | INFO | train_inner | epoch 091:     48 / 103 loss=4.335, ppl=20.19, wps=40232.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9300, lr=0.000327913, gnorm=0.884, loss_scale=8, train_wall=153, gb_free=20.8, wall=15156
2022-03-14 20:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:55:03 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 8.348 | ppl 325.94 | wps 65508.6 | wpb 2040.3 | bsz 4 | num_updates 9355 | best_loss 7.309
2022-03-14 20:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 9355 updates
2022-03-14 20:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:55:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 91 @ 9355 updates, score 8.348) (writing took 0.9994478384032845 seconds)
2022-03-14 20:55:04 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-14 20:55:04 | INFO | train | epoch 091 | loss 4.329 | ppl 20.1 | wps 40272.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9355 | lr 0.000326948 | gnorm 0.889 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15247
KL Stats: Epoch 91 Divergences: Uniform: 6.587351506420162 Unigram: 3.8767030708927495
2022-03-14 20:55:04 | INFO | fairseq.trainer | begin training epoch 92
2022-03-14 20:55:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:56:15 | INFO | train_inner | epoch 092:     45 / 103 loss=4.325, ppl=20.04, wps=40235, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=9400, lr=0.000326164, gnorm=0.904, loss_scale=8, train_wall=153, gb_free=20.8, wall=15318
2022-03-14 20:57:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 20:57:50 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 8.367 | ppl 330.2 | wps 65882.3 | wpb 2040.3 | bsz 4 | num_updates 9458 | best_loss 7.309
2022-03-14 20:57:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 9458 updates
2022-03-14 20:57:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 20:57:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 92 @ 9458 updates, score 8.367) (writing took 0.9816950988024473 seconds)
2022-03-14 20:57:51 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-14 20:57:51 | INFO | train | epoch 092 | loss 4.315 | ppl 19.91 | wps 40288.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9458 | lr 0.000325162 | gnorm 0.902 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15414
KL Stats: Epoch 92 Divergences: Uniform: 6.607097134830409 Unigram: 3.8900289861013366
2022-03-14 20:57:51 | INFO | fairseq.trainer | begin training epoch 93
2022-03-14 20:57:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 20:58:57 | INFO | train_inner | epoch 093:     42 / 103 loss=4.306, ppl=19.78, wps=40258.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=9500, lr=0.000324443, gnorm=0.89, loss_scale=8, train_wall=153, gb_free=20.8, wall=15480
2022-03-14 21:00:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:00:37 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 8.37 | ppl 330.92 | wps 66239 | wpb 2040.3 | bsz 4 | num_updates 9561 | best_loss 7.309
2022-03-14 21:00:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 9561 updates
2022-03-14 21:00:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:00:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:00:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 93 @ 9561 updates, score 8.37) (writing took 0.9533643890172243 seconds)
2022-03-14 21:00:38 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-14 21:00:38 | INFO | train | epoch 093 | loss 4.302 | ppl 19.73 | wps 40257.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9561 | lr 0.000323406 | gnorm 0.883 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 15581
KL Stats: Epoch 93 Divergences: Uniform: 6.622448983285391 Unigram: 3.8996622667807173
2022-03-14 21:00:38 | INFO | fairseq.trainer | begin training epoch 94
2022-03-14 21:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:01:40 | INFO | train_inner | epoch 094:     39 / 103 loss=4.296, ppl=19.64, wps=40159.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=9600, lr=0.000322749, gnorm=0.888, loss_scale=8, train_wall=153, gb_free=20.8, wall=15643
2022-03-14 21:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:03:24 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 8.396 | ppl 336.86 | wps 66440 | wpb 2040.3 | bsz 4 | num_updates 9664 | best_loss 7.309
2022-03-14 21:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 9664 updates
2022-03-14 21:03:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:03:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:03:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 94 @ 9664 updates, score 8.396) (writing took 0.9174101985991001 seconds)
2022-03-14 21:03:25 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-14 21:03:25 | INFO | train | epoch 094 | loss 4.29 | ppl 19.56 | wps 40178.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9664 | lr 0.000321678 | gnorm 0.891 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 15749
KL Stats: Epoch 94 Divergences: Uniform: 6.642956692105314 Unigram: 3.912949786549239
2022-03-14 21:03:25 | INFO | fairseq.trainer | begin training epoch 95
2022-03-14 21:03:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:04:22 | INFO | train_inner | epoch 095:     36 / 103 loss=4.289, ppl=19.55, wps=40194, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9700, lr=0.000321081, gnorm=0.89, loss_scale=16, train_wall=153, gb_free=20.8, wall=15806
2022-03-14 21:05:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:06:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:06:11 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 8.39 | ppl 335.52 | wps 66245.5 | wpb 2040.3 | bsz 4 | num_updates 9766 | best_loss 7.309
2022-03-14 21:06:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 9766 updates
2022-03-14 21:06:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:06:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:06:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 95 @ 9766 updates, score 8.39) (writing took 0.9456156771630049 seconds)
2022-03-14 21:06:12 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-14 21:06:12 | INFO | train | epoch 095 | loss 4.277 | ppl 19.39 | wps 39873.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 9766 | lr 0.000319994 | gnorm 0.893 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 15916
KL Stats: Epoch 95 Divergences: Uniform: 6.659939911489147 Unigram: 3.922762843079758
2022-03-14 21:06:12 | INFO | fairseq.trainer | begin training epoch 96
2022-03-14 21:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:07:06 | INFO | train_inner | epoch 096:     34 / 103 loss=4.275, ppl=19.36, wps=39855.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=9800, lr=0.000319438, gnorm=0.895, loss_scale=8, train_wall=154, gb_free=20.8, wall=15969
2022-03-14 21:08:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:08:58 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 8.427 | ppl 344.11 | wps 66139.2 | wpb 2040.3 | bsz 4 | num_updates 9869 | best_loss 7.309
2022-03-14 21:08:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 9869 updates
2022-03-14 21:08:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:08:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:08:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 96 @ 9869 updates, score 8.427) (writing took 0.9761391896754503 seconds)
2022-03-14 21:08:59 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-14 21:08:59 | INFO | train | epoch 096 | loss 4.266 | ppl 19.24 | wps 40313.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9869 | lr 0.00031832 | gnorm 0.905 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 16082
KL Stats: Epoch 96 Divergences: Uniform: 6.678515663581896 Unigram: 3.9331083866637084
2022-03-14 21:08:59 | INFO | fairseq.trainer | begin training epoch 97
2022-03-14 21:08:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:09:48 | INFO | train_inner | epoch 097:     31 / 103 loss=4.263, ppl=19.2, wps=40282.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=9900, lr=0.000317821, gnorm=0.905, loss_scale=8, train_wall=153, gb_free=20.8, wall=16132
2022-03-14 21:11:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:11:45 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 8.418 | ppl 342.15 | wps 65903.8 | wpb 2040.3 | bsz 4 | num_updates 9972 | best_loss 7.309
2022-03-14 21:11:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 9972 updates
2022-03-14 21:11:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:11:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:11:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 97 @ 9972 updates, score 8.418) (writing took 1.0144079755991697 seconds)
2022-03-14 21:11:46 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-14 21:11:46 | INFO | train | epoch 097 | loss 4.253 | ppl 19.07 | wps 40291.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 9972 | lr 0.000316671 | gnorm 0.887 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 16249
KL Stats: Epoch 97 Divergences: Uniform: 6.69483937231571 Unigram: 3.9444957601274364
2022-03-14 21:11:46 | INFO | fairseq.trainer | begin training epoch 98
2022-03-14 21:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:12:30 | INFO | train_inner | epoch 098:     28 / 103 loss=4.251, ppl=19.04, wps=40256.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10000, lr=0.000316228, gnorm=0.89, loss_scale=8, train_wall=153, gb_free=20.8, wall=16294
2022-03-14 21:14:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:14:32 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 8.419 | ppl 342.25 | wps 66644 | wpb 2040.3 | bsz 4 | num_updates 10075 | best_loss 7.309
2022-03-14 21:14:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 10075 updates
2022-03-14 21:14:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:14:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 98 @ 10075 updates, score 8.419) (writing took 0.9267007559537888 seconds)
2022-03-14 21:14:33 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-14 21:14:33 | INFO | train | epoch 098 | loss 4.243 | ppl 18.93 | wps 40325.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10075 | lr 0.000315049 | gnorm 0.898 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 16416
KL Stats: Epoch 98 Divergences: Uniform: 6.706607973211694 Unigram: 3.9519413898604108
2022-03-14 21:14:33 | INFO | fairseq.trainer | begin training epoch 99
2022-03-14 21:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:15:12 | INFO | train_inner | epoch 099:     25 / 103 loss=4.24, ppl=18.9, wps=40291.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10100, lr=0.000314658, gnorm=0.893, loss_scale=8, train_wall=153, gb_free=20.8, wall=16456
2022-03-14 21:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:17:19 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 8.451 | ppl 350.01 | wps 66458.2 | wpb 2040.3 | bsz 4 | num_updates 10178 | best_loss 7.309
2022-03-14 21:17:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 10178 updates
2022-03-14 21:17:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:17:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:17:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 99 @ 10178 updates, score 8.451) (writing took 0.9571679281070828 seconds)
2022-03-14 21:17:20 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-14 21:17:20 | INFO | train | epoch 099 | loss 4.231 | ppl 18.78 | wps 40319.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10178 | lr 0.00031345 | gnorm 0.902 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 16583
KL Stats: Epoch 99 Divergences: Uniform: 6.727784827492964 Unigram: 3.9630646222652253
2022-03-14 21:17:20 | INFO | fairseq.trainer | begin training epoch 100
2022-03-14 21:17:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:17:54 | INFO | train_inner | epoch 100:     22 / 103 loss=4.231, ppl=18.78, wps=40283.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10200, lr=0.000313112, gnorm=0.908, loss_scale=8, train_wall=153, gb_free=20.8, wall=16618
2022-03-14 21:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:20:06 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 8.455 | ppl 350.89 | wps 66352.4 | wpb 2040.3 | bsz 4 | num_updates 10281 | best_loss 7.309
2022-03-14 21:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 10281 updates
2022-03-14 21:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:20:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 100 @ 10281 updates, score 8.455) (writing took 0.957228752784431 seconds)
2022-03-14 21:20:07 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-14 21:20:07 | INFO | train | epoch 100 | loss 4.22 | ppl 18.64 | wps 40284.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10281 | lr 0.000311876 | gnorm 0.902 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16750
KL Stats: Epoch 100 Divergences: Uniform: 6.742005067960704 Unigram: 3.9718021765312934
2022-03-14 21:20:07 | INFO | fairseq.trainer | begin training epoch 101
2022-03-14 21:20:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:20:37 | INFO | train_inner | epoch 101:     19 / 103 loss=4.219, ppl=18.62, wps=40255, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10300, lr=0.000311588, gnorm=0.898, loss_scale=16, train_wall=153, gb_free=20.8, wall=16780
2022-03-14 21:22:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:22:53 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 8.466 | ppl 353.53 | wps 66548 | wpb 2040.3 | bsz 4 | num_updates 10384 | best_loss 7.309
2022-03-14 21:22:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 10384 updates
2022-03-14 21:22:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:22:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 101 @ 10384 updates, score 8.466) (writing took 0.9227221254259348 seconds)
2022-03-14 21:22:54 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-14 21:22:54 | INFO | train | epoch 101 | loss 4.207 | ppl 18.47 | wps 40286.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10384 | lr 0.000310326 | gnorm 0.884 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 16917
KL Stats: Epoch 101 Divergences: Uniform: 6.76155230391328 Unigram: 3.9834017946159808
2022-03-14 21:22:54 | INFO | fairseq.trainer | begin training epoch 102
2022-03-14 21:22:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:23:19 | INFO | train_inner | epoch 102:     16 / 103 loss=4.209, ppl=18.49, wps=40251.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10400, lr=0.000310087, gnorm=0.889, loss_scale=16, train_wall=153, gb_free=20.8, wall=16942
2022-03-14 21:25:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:25:39 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 8.482 | ppl 357.62 | wps 66441.6 | wpb 2040.3 | bsz 4 | num_updates 10487 | best_loss 7.309
2022-03-14 21:25:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 10487 updates
2022-03-14 21:25:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:25:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:25:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 102 @ 10487 updates, score 8.482) (writing took 0.9699584953486919 seconds)
2022-03-14 21:25:40 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-14 21:25:40 | INFO | train | epoch 102 | loss 4.199 | ppl 18.36 | wps 40316.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10487 | lr 0.000308798 | gnorm 0.912 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 17084
KL Stats: Epoch 102 Divergences: Uniform: 6.772001096859448 Unigram: 3.9920032487190924
2022-03-14 21:25:40 | INFO | fairseq.trainer | begin training epoch 103
2022-03-14 21:25:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:26:01 | INFO | train_inner | epoch 103:     13 / 103 loss=4.2, ppl=18.38, wps=40289.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10500, lr=0.000308607, gnorm=0.913, loss_scale=16, train_wall=153, gb_free=20.8, wall=17105
2022-03-14 21:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:28:27 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 8.486 | ppl 358.53 | wps 66070.5 | wpb 2040.3 | bsz 4 | num_updates 10590 | best_loss 7.309
2022-03-14 21:28:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 10590 updates
2022-03-14 21:28:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:28:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:28:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 103 @ 10590 updates, score 8.486) (writing took 0.9937739660963416 seconds)
2022-03-14 21:28:28 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-14 21:28:28 | INFO | train | epoch 103 | loss 4.188 | ppl 18.22 | wps 40234.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10590 | lr 0.000307293 | gnorm 0.899 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17251
KL Stats: Epoch 103 Divergences: Uniform: 6.78439578806578 Unigram: 4.000986809220197
2022-03-14 21:28:28 | INFO | fairseq.trainer | begin training epoch 104
2022-03-14 21:28:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:28:44 | INFO | train_inner | epoch 104:     10 / 103 loss=4.188, ppl=18.23, wps=40139.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10600, lr=0.000307148, gnorm=0.902, loss_scale=16, train_wall=153, gb_free=20.8, wall=17267
2022-03-14 21:31:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:31:14 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 8.497 | ppl 361.31 | wps 66607.4 | wpb 2040.3 | bsz 4 | num_updates 10693 | best_loss 7.309
2022-03-14 21:31:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 10693 updates
2022-03-14 21:31:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:31:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 104 @ 10693 updates, score 8.497) (writing took 1.0500578880310059 seconds)
2022-03-14 21:31:15 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-14 21:31:15 | INFO | train | epoch 104 | loss 4.177 | ppl 18.09 | wps 40174 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10693 | lr 0.000305809 | gnorm 0.91 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17419
KL Stats: Epoch 104 Divergences: Uniform: 6.801672862741429 Unigram: 4.011475703908311
2022-03-14 21:31:15 | INFO | fairseq.trainer | begin training epoch 105
2022-03-14 21:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:31:26 | INFO | train_inner | epoch 105:      7 / 103 loss=4.177, ppl=18.09, wps=40180.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10700, lr=0.000305709, gnorm=0.904, loss_scale=16, train_wall=153, gb_free=20.8, wall=17430
2022-03-14 21:33:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:33:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:34:01 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 8.518 | ppl 366.7 | wps 66557.3 | wpb 2040.3 | bsz 4 | num_updates 10795 | best_loss 7.309
2022-03-14 21:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 10795 updates
2022-03-14 21:34:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:34:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:34:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 105 @ 10795 updates, score 8.518) (writing took 0.9881101734936237 seconds)
2022-03-14 21:34:02 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-14 21:34:02 | INFO | train | epoch 105 | loss 4.168 | ppl 17.98 | wps 39844.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 10795 | lr 0.000304361 | gnorm 0.909 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 17586
KL Stats: Epoch 105 Divergences: Uniform: 6.814100834270223 Unigram: 4.0182056903313
2022-03-14 21:34:02 | INFO | fairseq.trainer | begin training epoch 106
2022-03-14 21:34:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:34:10 | INFO | train_inner | epoch 106:      5 / 103 loss=4.17, ppl=18.01, wps=39819.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=10800, lr=0.00030429, gnorm=0.913, loss_scale=16, train_wall=155, gb_free=20.8, wall=17594
2022-03-14 21:36:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:36:48 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 8.52 | ppl 367.19 | wps 66503.4 | wpb 2040.3 | bsz 4 | num_updates 10898 | best_loss 7.309
2022-03-14 21:36:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 10898 updates
2022-03-14 21:36:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:36:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 106 @ 10898 updates, score 8.52) (writing took 0.9308026703074574 seconds)
2022-03-14 21:36:49 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-14 21:36:49 | INFO | train | epoch 106 | loss 4.158 | ppl 17.86 | wps 40285.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 10898 | lr 0.000302919 | gnorm 0.912 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 17753
KL Stats: Epoch 106 Divergences: Uniform: 6.825333330463776 Unigram: 4.026366151260427
2022-03-14 21:36:49 | INFO | fairseq.trainer | begin training epoch 107
2022-03-14 21:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:36:53 | INFO | train_inner | epoch 107:      2 / 103 loss=4.161, ppl=17.89, wps=40256.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=10900, lr=0.000302891, gnorm=0.911, loss_scale=16, train_wall=153, gb_free=20.8, wall=17756
2022-03-14 21:39:31 | INFO | train_inner | epoch 107:    102 / 103 loss=4.148, ppl=17.73, wps=41432.8, ups=0.63, wpb=65530.9, bsz=128, num_updates=11000, lr=0.000301511, gnorm=0.912, loss_scale=16, train_wall=153, gb_free=20.8, wall=17914
2022-03-14 21:39:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:39:35 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 8.538 | ppl 371.75 | wps 66379.7 | wpb 2040.3 | bsz 4 | num_updates 11001 | best_loss 7.309
2022-03-14 21:39:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 11001 updates
2022-03-14 21:39:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:39:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:39:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 107 @ 11001 updates, score 8.538) (writing took 0.9960408164188266 seconds)
2022-03-14 21:39:36 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-14 21:39:36 | INFO | train | epoch 107 | loss 4.147 | ppl 17.71 | wps 40275.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11001 | lr 0.000301498 | gnorm 0.914 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 17920
KL Stats: Epoch 107 Divergences: Uniform: 6.841424279109482 Unigram: 4.035473808465349
2022-03-14 21:39:36 | INFO | fairseq.trainer | begin training epoch 108
2022-03-14 21:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:42:13 | INFO | train_inner | epoch 108:     99 / 103 loss=4.135, ppl=17.57, wps=40246.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11100, lr=0.00030015, gnorm=0.923, loss_scale=16, train_wall=153, gb_free=20.8, wall=18076
2022-03-14 21:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:42:22 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 8.54 | ppl 372.34 | wps 66239.1 | wpb 2040.3 | bsz 4 | num_updates 11104 | best_loss 7.309
2022-03-14 21:42:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 11104 updates
2022-03-14 21:42:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 108 @ 11104 updates, score 8.54) (writing took 0.977431382983923 seconds)
2022-03-14 21:42:23 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-14 21:42:23 | INFO | train | epoch 108 | loss 4.137 | ppl 17.6 | wps 40284.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11104 | lr 0.000300096 | gnorm 0.923 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18087
KL Stats: Epoch 108 Divergences: Uniform: 6.8537583249068605 Unigram: 4.044748391996372
2022-03-14 21:42:23 | INFO | fairseq.trainer | begin training epoch 109
2022-03-14 21:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:44:55 | INFO | train_inner | epoch 109:     96 / 103 loss=4.125, ppl=17.44, wps=40229.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11200, lr=0.000298807, gnorm=0.908, loss_scale=16, train_wall=153, gb_free=20.8, wall=18239
2022-03-14 21:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:45:09 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 8.557 | ppl 376.54 | wps 66142.4 | wpb 2040.3 | bsz 4 | num_updates 11207 | best_loss 7.309
2022-03-14 21:45:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 11207 updates
2022-03-14 21:45:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:45:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:45:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 109 @ 11207 updates, score 8.557) (writing took 0.9257305879145861 seconds)
2022-03-14 21:45:10 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-14 21:45:10 | INFO | train | epoch 109 | loss 4.128 | ppl 17.48 | wps 40271.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11207 | lr 0.000298714 | gnorm 0.907 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 18254
KL Stats: Epoch 109 Divergences: Uniform: 6.8652108257331586 Unigram: 4.053326956863656
2022-03-14 21:45:10 | INFO | fairseq.trainer | begin training epoch 110
2022-03-14 21:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:47:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 21:47:39 | INFO | train_inner | epoch 110:     94 / 103 loss=4.118, ppl=17.37, wps=39891.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11300, lr=0.000297482, gnorm=0.912, loss_scale=16, train_wall=154, gb_free=20.8, wall=18402
2022-03-14 21:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:47:56 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 8.559 | ppl 377.19 | wps 66740 | wpb 2040.3 | bsz 4 | num_updates 11309 | best_loss 7.309
2022-03-14 21:47:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 11309 updates
2022-03-14 21:47:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:47:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:47:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 110 @ 11309 updates, score 8.559) (writing took 1.092940284870565 seconds)
2022-03-14 21:47:57 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-14 21:47:57 | INFO | train | epoch 110 | loss 4.119 | ppl 17.38 | wps 39888 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11309 | lr 0.000297364 | gnorm 0.917 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 18421
KL Stats: Epoch 110 Divergences: Uniform: 6.876485236316273 Unigram: 4.060131028313196
2022-03-14 21:47:57 | INFO | fairseq.trainer | begin training epoch 111
2022-03-14 21:47:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:49:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 21:50:23 | INFO | train_inner | epoch 111:     92 / 103 loss=4.109, ppl=17.25, wps=39816.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=11400, lr=0.000296174, gnorm=0.936, loss_scale=8, train_wall=154, gb_free=20.8, wall=18567
2022-03-14 21:50:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:50:43 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 8.557 | ppl 376.71 | wps 66103.4 | wpb 2040.3 | bsz 4 | num_updates 11411 | best_loss 7.309
2022-03-14 21:50:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 11411 updates
2022-03-14 21:50:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:50:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:50:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 111 @ 11411 updates, score 8.557) (writing took 1.0055776229128242 seconds)
2022-03-14 21:50:44 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-14 21:50:44 | INFO | train | epoch 111 | loss 4.108 | ppl 17.25 | wps 39865.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 11411 | lr 0.000296032 | gnorm 0.931 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 18588
KL Stats: Epoch 111 Divergences: Uniform: 6.8884140814345916 Unigram: 4.067844129845078
2022-03-14 21:50:44 | INFO | fairseq.trainer | begin training epoch 112
2022-03-14 21:50:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:53:06 | INFO | train_inner | epoch 112:     89 / 103 loss=4.1, ppl=17.15, wps=40176.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11500, lr=0.000294884, gnorm=0.913, loss_scale=8, train_wall=153, gb_free=20.8, wall=18729
2022-03-14 21:53:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:53:31 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 8.583 | ppl 383.52 | wps 66271.3 | wpb 2040.3 | bsz 4 | num_updates 11514 | best_loss 7.309
2022-03-14 21:53:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 11514 updates
2022-03-14 21:53:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:53:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:53:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 112 @ 11514 updates, score 8.583) (writing took 1.0202845269814134 seconds)
2022-03-14 21:53:32 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-14 21:53:32 | INFO | train | epoch 112 | loss 4.1 | ppl 17.15 | wps 40205.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11514 | lr 0.000294705 | gnorm 0.919 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 18755
KL Stats: Epoch 112 Divergences: Uniform: 6.898275172916481 Unigram: 4.076055059752161
2022-03-14 21:53:32 | INFO | fairseq.trainer | begin training epoch 113
2022-03-14 21:53:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:55:48 | INFO | train_inner | epoch 113:     86 / 103 loss=4.089, ppl=17.02, wps=40240.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11600, lr=0.00029361, gnorm=0.923, loss_scale=8, train_wall=153, gb_free=20.8, wall=18891
2022-03-14 21:56:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:56:18 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 8.6 | ppl 387.92 | wps 66123 | wpb 2040.3 | bsz 4 | num_updates 11617 | best_loss 7.309
2022-03-14 21:56:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 11617 updates
2022-03-14 21:56:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 113 @ 11617 updates, score 8.6) (writing took 0.9837371734902263 seconds)
2022-03-14 21:56:19 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-14 21:56:19 | INFO | train | epoch 113 | loss 4.091 | ppl 17.04 | wps 40284.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11617 | lr 0.000293395 | gnorm 0.916 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 18922
KL Stats: Epoch 113 Divergences: Uniform: 6.913280093665507 Unigram: 4.08552943324727
2022-03-14 21:56:19 | INFO | fairseq.trainer | begin training epoch 114
2022-03-14 21:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 21:58:30 | INFO | train_inner | epoch 114:     83 / 103 loss=4.084, ppl=16.96, wps=40273.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=11700, lr=0.000292353, gnorm=0.91, loss_scale=8, train_wall=153, gb_free=20.8, wall=19054
2022-03-14 21:59:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 21:59:05 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 8.598 | ppl 387.57 | wps 66145.5 | wpb 2040.3 | bsz 4 | num_updates 11720 | best_loss 7.309
2022-03-14 21:59:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 11720 updates
2022-03-14 21:59:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:59:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 21:59:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 114 @ 11720 updates, score 8.598) (writing took 0.99659622926265 seconds)
2022-03-14 21:59:06 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-14 21:59:06 | INFO | train | epoch 114 | loss 4.084 | ppl 16.96 | wps 40309 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11720 | lr 0.000292103 | gnorm 0.915 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 19089
KL Stats: Epoch 114 Divergences: Uniform: 6.920843794732551 Unigram: 4.091814642874973
2022-03-14 21:59:06 | INFO | fairseq.trainer | begin training epoch 115
2022-03-14 21:59:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:01:12 | INFO | train_inner | epoch 115:     80 / 103 loss=4.074, ppl=16.85, wps=40237.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=11800, lr=0.000291111, gnorm=0.918, loss_scale=8, train_wall=153, gb_free=20.8, wall=19216
2022-03-14 22:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:01:52 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 8.606 | ppl 389.7 | wps 65767.9 | wpb 2040.3 | bsz 4 | num_updates 11823 | best_loss 7.309
2022-03-14 22:01:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 11823 updates
2022-03-14 22:01:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 115 @ 11823 updates, score 8.606) (writing took 1.0082172276452184 seconds)
2022-03-14 22:01:53 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-14 22:01:53 | INFO | train | epoch 115 | loss 4.074 | ppl 16.85 | wps 40227.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 11823 | lr 0.000290828 | gnorm 0.92 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 19256
KL Stats: Epoch 115 Divergences: Uniform: 6.93380046548454 Unigram: 4.099358821362421
2022-03-14 22:01:53 | INFO | fairseq.trainer | begin training epoch 116
2022-03-14 22:01:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:03:55 | INFO | train_inner | epoch 116:     77 / 103 loss=4.069, ppl=16.78, wps=40178, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=11900, lr=0.000289886, gnorm=0.936, loss_scale=16, train_wall=153, gb_free=20.8, wall=19378
2022-03-14 22:04:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:04:39 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 8.628 | ppl 395.55 | wps 66254.8 | wpb 2040.3 | bsz 4 | num_updates 11926 | best_loss 7.309
2022-03-14 22:04:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 11926 updates
2022-03-14 22:04:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:04:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:04:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 116 @ 11926 updates, score 8.628) (writing took 4.190728100948036 seconds)
2022-03-14 22:04:43 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-14 22:04:43 | INFO | train | epoch 116 | loss 4.066 | ppl 16.75 | wps 39475.6 | ups 0.6 | wpb 65312.3 | bsz 127.6 | num_updates 11926 | lr 0.000289569 | gnorm 0.934 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19427
KL Stats: Epoch 116 Divergences: Uniform: 6.94815066955948 Unigram: 4.108967628282587
2022-03-14 22:04:43 | INFO | fairseq.trainer | begin training epoch 117
2022-03-14 22:04:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:06:41 | INFO | train_inner | epoch 117:     74 / 103 loss=4.058, ppl=16.66, wps=39406.5, ups=0.6, wpb=65305.6, bsz=127.6, num_updates=12000, lr=0.000288675, gnorm=0.923, loss_scale=16, train_wall=153, gb_free=20.8, wall=19544
2022-03-14 22:07:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:07:29 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 8.647 | ppl 400.95 | wps 65819.9 | wpb 2040.3 | bsz 4 | num_updates 12029 | best_loss 7.309
2022-03-14 22:07:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 12029 updates
2022-03-14 22:07:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:07:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:07:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 117 @ 12029 updates, score 8.647) (writing took 1.0301143219694495 seconds)
2022-03-14 22:07:31 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-14 22:07:31 | INFO | train | epoch 117 | loss 4.059 | ppl 16.67 | wps 40226.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12029 | lr 0.000288327 | gnorm 0.92 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19594
KL Stats: Epoch 117 Divergences: Uniform: 6.956846677998314 Unigram: 4.115066777138466
2022-03-14 22:07:31 | INFO | fairseq.trainer | begin training epoch 118
2022-03-14 22:07:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:09:23 | INFO | train_inner | epoch 118:     71 / 103 loss=4.051, ppl=16.57, wps=40262.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12100, lr=0.00028748, gnorm=0.931, loss_scale=16, train_wall=153, gb_free=20.8, wall=19706
2022-03-14 22:10:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:10:16 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 8.658 | ppl 404.08 | wps 66452.9 | wpb 2040.3 | bsz 4 | num_updates 12132 | best_loss 7.309
2022-03-14 22:10:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 12132 updates
2022-03-14 22:10:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:10:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:10:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 118 @ 12132 updates, score 8.658) (writing took 0.9967754650861025 seconds)
2022-03-14 22:10:17 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-14 22:10:17 | INFO | train | epoch 118 | loss 4.051 | ppl 16.57 | wps 40313.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12132 | lr 0.0002871 | gnorm 0.932 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 19761
KL Stats: Epoch 118 Divergences: Uniform: 6.966317361100012 Unigram: 4.121715245627445
2022-03-14 22:10:17 | INFO | fairseq.trainer | begin training epoch 119
2022-03-14 22:10:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:12:05 | INFO | train_inner | epoch 119:     68 / 103 loss=4.045, ppl=16.5, wps=40203.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12200, lr=0.000286299, gnorm=0.926, loss_scale=16, train_wall=153, gb_free=20.8, wall=19869
2022-03-14 22:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:13:04 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 8.659 | ppl 404.13 | wps 66064.3 | wpb 2040.3 | bsz 4 | num_updates 12235 | best_loss 7.309
2022-03-14 22:13:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 12235 updates
2022-03-14 22:13:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:13:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:13:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 119 @ 12235 updates, score 8.659) (writing took 0.9438585722818971 seconds)
2022-03-14 22:13:05 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-14 22:13:05 | INFO | train | epoch 119 | loss 4.042 | ppl 16.47 | wps 40215 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12235 | lr 0.000285889 | gnorm 0.931 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 19928
KL Stats: Epoch 119 Divergences: Uniform: 6.9782933611517315 Unigram: 4.1288522889395765
2022-03-14 22:13:05 | INFO | fairseq.trainer | begin training epoch 120
2022-03-14 22:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:14:48 | INFO | train_inner | epoch 120:     65 / 103 loss=4.036, ppl=16.4, wps=40226, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12300, lr=0.000285133, gnorm=0.926, loss_scale=16, train_wall=153, gb_free=20.8, wall=20031
2022-03-14 22:15:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:15:51 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 8.666 | ppl 406.26 | wps 66356 | wpb 2040.3 | bsz 4 | num_updates 12338 | best_loss 7.309
2022-03-14 22:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 12338 updates
2022-03-14 22:15:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 120 @ 12338 updates, score 8.666) (writing took 1.0441872365772724 seconds)
2022-03-14 22:15:52 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-14 22:15:52 | INFO | train | epoch 120 | loss 4.035 | ppl 16.39 | wps 40262.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12338 | lr 0.000284694 | gnorm 0.926 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20095
KL Stats: Epoch 120 Divergences: Uniform: 6.985555163233014 Unigram: 4.135563824096994
2022-03-14 22:15:52 | INFO | fairseq.trainer | begin training epoch 121
2022-03-14 22:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:17:30 | INFO | train_inner | epoch 121:     62 / 103 loss=4.032, ppl=16.35, wps=40192.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12400, lr=0.000283981, gnorm=0.938, loss_scale=32, train_wall=153, gb_free=20.8, wall=20194
2022-03-14 22:17:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:18:38 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 8.657 | ppl 403.59 | wps 66073.8 | wpb 2040.3 | bsz 4 | num_updates 12440 | best_loss 7.309
2022-03-14 22:18:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 12440 updates
2022-03-14 22:18:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:18:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:18:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 121 @ 12440 updates, score 8.657) (writing took 0.9962004264816642 seconds)
2022-03-14 22:18:39 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-14 22:18:39 | INFO | train | epoch 121 | loss 4.025 | ppl 16.28 | wps 39857.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12440 | lr 0.000283524 | gnorm 0.939 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20262
KL Stats: Epoch 121 Divergences: Uniform: 6.992488843266163 Unigram: 4.1410420264510295
2022-03-14 22:18:39 | INFO | fairseq.trainer | begin training epoch 122
2022-03-14 22:18:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:20:14 | INFO | train_inner | epoch 122:     60 / 103 loss=4.021, ppl=16.23, wps=39874.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=12500, lr=0.000282843, gnorm=0.927, loss_scale=16, train_wall=154, gb_free=20.8, wall=20357
2022-03-14 22:21:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:21:25 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 8.689 | ppl 412.81 | wps 66085.9 | wpb 2040.3 | bsz 4 | num_updates 12543 | best_loss 7.309
2022-03-14 22:21:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 12543 updates
2022-03-14 22:21:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:21:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:21:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 122 @ 12543 updates, score 8.689) (writing took 0.9642087034881115 seconds)
2022-03-14 22:21:26 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-14 22:21:26 | INFO | train | epoch 122 | loss 4.018 | ppl 16.2 | wps 40286.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12543 | lr 0.000282357 | gnorm 0.935 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20429
KL Stats: Epoch 122 Divergences: Uniform: 7.00314680536515 Unigram: 4.148233886710332
2022-03-14 22:21:26 | INFO | fairseq.trainer | begin training epoch 123
2022-03-14 22:21:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:22:56 | INFO | train_inner | epoch 123:     57 / 103 loss=4.009, ppl=16.1, wps=40240, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=12600, lr=0.000281718, gnorm=0.939, loss_scale=16, train_wall=153, gb_free=20.8, wall=20520
2022-03-14 22:24:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:24:12 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 8.689 | ppl 412.83 | wps 66133.3 | wpb 2040.3 | bsz 4 | num_updates 12646 | best_loss 7.309
2022-03-14 22:24:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 12646 updates
2022-03-14 22:24:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:24:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:24:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 123 @ 12646 updates, score 8.689) (writing took 0.9921221798285842 seconds)
2022-03-14 22:24:13 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-14 22:24:13 | INFO | train | epoch 123 | loss 4.01 | ppl 16.11 | wps 40284.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12646 | lr 0.000281205 | gnorm 0.929 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20596
KL Stats: Epoch 123 Divergences: Uniform: 7.01434827413836 Unigram: 4.155165933115862
2022-03-14 22:24:13 | INFO | fairseq.trainer | begin training epoch 124
2022-03-14 22:24:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:25:38 | INFO | train_inner | epoch 124:     54 / 103 loss=4.008, ppl=16.09, wps=40247.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=12700, lr=0.000280607, gnorm=0.927, loss_scale=16, train_wall=153, gb_free=20.8, wall=20682
2022-03-14 22:26:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:26:59 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 8.702 | ppl 416.4 | wps 66096.5 | wpb 2040.3 | bsz 4 | num_updates 12749 | best_loss 7.309
2022-03-14 22:26:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 12749 updates
2022-03-14 22:26:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:27:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:27:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 124 @ 12749 updates, score 8.702) (writing took 1.0131259271875024 seconds)
2022-03-14 22:27:00 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-14 22:27:00 | INFO | train | epoch 124 | loss 4.004 | ppl 16.04 | wps 40270.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12749 | lr 0.000280067 | gnorm 0.924 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 20763
KL Stats: Epoch 124 Divergences: Uniform: 7.023644330388441 Unigram: 4.162710489846188
2022-03-14 22:27:00 | INFO | fairseq.trainer | begin training epoch 125
2022-03-14 22:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:28:21 | INFO | train_inner | epoch 125:     51 / 103 loss=4.002, ppl=16.02, wps=40232.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12800, lr=0.000279508, gnorm=0.925, loss_scale=16, train_wall=153, gb_free=20.8, wall=20844
2022-03-14 22:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:29:46 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 8.703 | ppl 416.63 | wps 65890.7 | wpb 2040.3 | bsz 4 | num_updates 12852 | best_loss 7.309
2022-03-14 22:29:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 12852 updates
2022-03-14 22:29:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:29:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:29:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 125 @ 12852 updates, score 8.703) (writing took 0.9636499490588903 seconds)
2022-03-14 22:29:47 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-14 22:29:47 | INFO | train | epoch 125 | loss 3.997 | ppl 15.96 | wps 40258.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 12852 | lr 0.000278942 | gnorm 0.929 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 20931
KL Stats: Epoch 125 Divergences: Uniform: 7.0318477080647845 Unigram: 4.167363388409462
2022-03-14 22:29:47 | INFO | fairseq.trainer | begin training epoch 126
2022-03-14 22:29:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:31:03 | INFO | train_inner | epoch 126:     48 / 103 loss=3.993, ppl=15.92, wps=40222.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=12900, lr=0.000278423, gnorm=0.93, loss_scale=16, train_wall=153, gb_free=20.8, wall=21007
2022-03-14 22:31:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:32:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:32:33 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 8.716 | ppl 420.37 | wps 66589.3 | wpb 2040.3 | bsz 4 | num_updates 12954 | best_loss 7.309
2022-03-14 22:32:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 12954 updates
2022-03-14 22:32:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:32:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:32:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 126 @ 12954 updates, score 8.716) (writing took 0.9768356522545218 seconds)
2022-03-14 22:32:34 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-14 22:32:34 | INFO | train | epoch 126 | loss 3.988 | ppl 15.87 | wps 39897.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 12954 | lr 0.000277842 | gnorm 0.938 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21098
KL Stats: Epoch 126 Divergences: Uniform: 7.039969960921562 Unigram: 4.176091691929438
2022-03-14 22:32:34 | INFO | fairseq.trainer | begin training epoch 127
2022-03-14 22:32:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:33:47 | INFO | train_inner | epoch 127:     46 / 103 loss=3.982, ppl=15.8, wps=39871.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13000, lr=0.00027735, gnorm=0.943, loss_scale=16, train_wall=154, gb_free=20.8, wall=21170
2022-03-14 22:35:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:35:20 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 8.715 | ppl 420.31 | wps 66338.6 | wpb 2040.3 | bsz 4 | num_updates 13057 | best_loss 7.309
2022-03-14 22:35:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 13057 updates
2022-03-14 22:35:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:35:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:35:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 127 @ 13057 updates, score 8.715) (writing took 0.99108612164855 seconds)
2022-03-14 22:35:21 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-14 22:35:21 | INFO | train | epoch 127 | loss 3.982 | ppl 15.8 | wps 40284 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13057 | lr 0.000276744 | gnorm 0.939 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21264
KL Stats: Epoch 127 Divergences: Uniform: 7.047883237675298 Unigram: 4.180088681918639
2022-03-14 22:35:21 | INFO | fairseq.trainer | begin training epoch 128
2022-03-14 22:35:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:36:29 | INFO | train_inner | epoch 128:     43 / 103 loss=3.984, ppl=15.82, wps=40269, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13100, lr=0.000276289, gnorm=0.941, loss_scale=16, train_wall=153, gb_free=20.8, wall=21333
2022-03-14 22:38:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:38:08 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 8.716 | ppl 420.63 | wps 64645.4 | wpb 2040.3 | bsz 4 | num_updates 13160 | best_loss 7.309
2022-03-14 22:38:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 13160 updates
2022-03-14 22:38:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:38:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:38:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 128 @ 13160 updates, score 8.716) (writing took 1.0101793939247727 seconds)
2022-03-14 22:38:09 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-14 22:38:09 | INFO | train | epoch 128 | loss 3.975 | ppl 15.73 | wps 40056.8 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 13160 | lr 0.000275659 | gnorm 0.937 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 21432
KL Stats: Epoch 128 Divergences: Uniform: 7.055999736077385 Unigram: 4.185729081089684
2022-03-14 22:38:09 | INFO | fairseq.trainer | begin training epoch 129
2022-03-14 22:38:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:39:12 | INFO | train_inner | epoch 129:     40 / 103 loss=3.972, ppl=15.69, wps=40004.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=13200, lr=0.000275241, gnorm=0.935, loss_scale=16, train_wall=154, gb_free=20.8, wall=21496
2022-03-14 22:40:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:40:55 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 8.737 | ppl 426.74 | wps 66286.2 | wpb 2040.3 | bsz 4 | num_updates 13263 | best_loss 7.309
2022-03-14 22:40:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 13263 updates
2022-03-14 22:40:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:40:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:40:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 129 @ 13263 updates, score 8.737) (writing took 0.9885317562147975 seconds)
2022-03-14 22:40:56 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-14 22:40:56 | INFO | train | epoch 129 | loss 3.969 | ppl 15.66 | wps 40281.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13263 | lr 0.000274586 | gnorm 0.939 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21599
KL Stats: Epoch 129 Divergences: Uniform: 7.06336947206453 Unigram: 4.191863525996712
2022-03-14 22:40:56 | INFO | fairseq.trainer | begin training epoch 130
2022-03-14 22:40:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:41:55 | INFO | train_inner | epoch 130:     37 / 103 loss=3.965, ppl=15.61, wps=40237.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13300, lr=0.000274204, gnorm=0.949, loss_scale=16, train_wall=153, gb_free=20.8, wall=21658
2022-03-14 22:43:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:43:42 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 8.731 | ppl 424.93 | wps 66233 | wpb 2040.3 | bsz 4 | num_updates 13366 | best_loss 7.309
2022-03-14 22:43:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 13366 updates
2022-03-14 22:43:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:43:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:43:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 130 @ 13366 updates, score 8.731) (writing took 1.0068519618362188 seconds)
2022-03-14 22:43:43 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-14 22:43:43 | INFO | train | epoch 130 | loss 3.961 | ppl 15.57 | wps 40258.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13366 | lr 0.000273526 | gnorm 0.944 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21767
KL Stats: Epoch 130 Divergences: Uniform: 7.072340474860026 Unigram: 4.198161065205794
2022-03-14 22:43:43 | INFO | fairseq.trainer | begin training epoch 131
2022-03-14 22:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:44:37 | INFO | train_inner | epoch 131:     34 / 103 loss=3.96, ppl=15.57, wps=40239.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13400, lr=0.000273179, gnorm=0.933, loss_scale=16, train_wall=153, gb_free=20.8, wall=21820
2022-03-14 22:45:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 22:46:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:46:29 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 8.764 | ppl 434.74 | wps 66089.5 | wpb 2040.3 | bsz 4 | num_updates 13468 | best_loss 7.309
2022-03-14 22:46:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 13468 updates
2022-03-14 22:46:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:46:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:46:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 131 @ 13468 updates, score 8.764) (writing took 0.9895542645826936 seconds)
2022-03-14 22:46:30 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-14 22:46:30 | INFO | train | epoch 131 | loss 3.954 | ppl 15.5 | wps 39882.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13468 | lr 0.000272489 | gnorm 0.943 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 21934
KL Stats: Epoch 131 Divergences: Uniform: 7.082049950574768 Unigram: 4.205300801323809
2022-03-14 22:46:30 | INFO | fairseq.trainer | begin training epoch 132
2022-03-14 22:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:47:21 | INFO | train_inner | epoch 132:     32 / 103 loss=3.951, ppl=15.47, wps=39849.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=13500, lr=0.000272166, gnorm=0.947, loss_scale=16, train_wall=154, gb_free=20.8, wall=21984
2022-03-14 22:49:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:49:16 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 8.756 | ppl 432.48 | wps 66618.3 | wpb 2040.3 | bsz 4 | num_updates 13571 | best_loss 7.309
2022-03-14 22:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 13571 updates
2022-03-14 22:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:49:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 132 @ 13571 updates, score 8.756) (writing took 0.9975812053307891 seconds)
2022-03-14 22:49:17 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-14 22:49:17 | INFO | train | epoch 132 | loss 3.947 | ppl 15.42 | wps 40299.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13571 | lr 0.000271453 | gnorm 0.939 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22101
KL Stats: Epoch 132 Divergences: Uniform: 7.089119673599519 Unigram: 4.210000368969192
2022-03-14 22:49:17 | INFO | fairseq.trainer | begin training epoch 133
2022-03-14 22:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:50:03 | INFO | train_inner | epoch 133:     29 / 103 loss=3.948, ppl=15.43, wps=40249.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=13600, lr=0.000271163, gnorm=0.945, loss_scale=16, train_wall=153, gb_free=20.8, wall=22147
2022-03-14 22:52:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:52:03 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 8.771 | ppl 436.83 | wps 66413.2 | wpb 2040.3 | bsz 4 | num_updates 13674 | best_loss 7.309
2022-03-14 22:52:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 13674 updates
2022-03-14 22:52:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:52:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:52:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 133 @ 13674 updates, score 8.771) (writing took 0.9337250562384725 seconds)
2022-03-14 22:52:04 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-14 22:52:04 | INFO | train | epoch 133 | loss 3.941 | ppl 15.36 | wps 40252.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13674 | lr 0.000270428 | gnorm 0.945 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22268
KL Stats: Epoch 133 Divergences: Uniform: 7.09761285069849 Unigram: 4.217484239393755
2022-03-14 22:52:04 | INFO | fairseq.trainer | begin training epoch 134
2022-03-14 22:52:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:52:45 | INFO | train_inner | epoch 134:     26 / 103 loss=3.941, ppl=15.36, wps=40238.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13700, lr=0.000270172, gnorm=0.938, loss_scale=16, train_wall=153, gb_free=20.8, wall=22309
2022-03-14 22:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:54:50 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 8.78 | ppl 439.46 | wps 66399.9 | wpb 2040.3 | bsz 4 | num_updates 13777 | best_loss 7.309
2022-03-14 22:54:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 13777 updates
2022-03-14 22:54:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:54:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:54:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 134 @ 13777 updates, score 8.78) (writing took 0.9895971659570932 seconds)
2022-03-14 22:54:51 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-14 22:54:51 | INFO | train | epoch 134 | loss 3.934 | ppl 15.29 | wps 40290.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13777 | lr 0.000269416 | gnorm 0.944 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22435
KL Stats: Epoch 134 Divergences: Uniform: 7.105350642819841 Unigram: 4.22116648066171
2022-03-14 22:54:51 | INFO | fairseq.trainer | begin training epoch 135
2022-03-14 22:54:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:55:28 | INFO | train_inner | epoch 135:     23 / 103 loss=3.933, ppl=15.28, wps=40239.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13800, lr=0.000269191, gnorm=0.946, loss_scale=16, train_wall=153, gb_free=20.8, wall=22471
2022-03-14 22:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 22:57:37 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 8.744 | ppl 428.61 | wps 65860.7 | wpb 2040.3 | bsz 4 | num_updates 13880 | best_loss 7.309
2022-03-14 22:57:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 13880 updates
2022-03-14 22:57:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:57:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 22:57:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 135 @ 13880 updates, score 8.744) (writing took 0.9971537385135889 seconds)
2022-03-14 22:57:38 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-14 22:57:38 | INFO | train | epoch 135 | loss 3.927 | ppl 15.21 | wps 40234.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 13880 | lr 0.000268414 | gnorm 0.948 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 22602
KL Stats: Epoch 135 Divergences: Uniform: 7.108577114328298 Unigram: 4.225888335735494
2022-03-14 22:57:38 | INFO | fairseq.trainer | begin training epoch 136
2022-03-14 22:57:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 22:58:10 | INFO | train_inner | epoch 136:     20 / 103 loss=3.928, ppl=15.23, wps=40209.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=13900, lr=0.000268221, gnorm=0.944, loss_scale=16, train_wall=153, gb_free=20.8, wall=22634
2022-03-14 22:59:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:00:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:00:24 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 8.795 | ppl 444.3 | wps 66199.4 | wpb 2040.3 | bsz 4 | num_updates 13982 | best_loss 7.309
2022-03-14 23:00:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 13982 updates
2022-03-14 23:00:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:00:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:00:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 136 @ 13982 updates, score 8.795) (writing took 1.1082258755341172 seconds)
2022-03-14 23:00:25 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-14 23:00:25 | INFO | train | epoch 136 | loss 3.922 | ppl 15.16 | wps 39863 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 13982 | lr 0.000267433 | gnorm 0.939 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22769
KL Stats: Epoch 136 Divergences: Uniform: 7.116289565860458 Unigram: 4.231823749058209
2022-03-14 23:00:25 | INFO | fairseq.trainer | begin training epoch 137
2022-03-14 23:00:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:00:54 | INFO | train_inner | epoch 137:     18 / 103 loss=3.923, ppl=15.17, wps=39832.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14000, lr=0.000267261, gnorm=0.944, loss_scale=16, train_wall=154, gb_free=20.8, wall=22797
2022-03-14 23:03:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:03:11 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 8.778 | ppl 439.09 | wps 66639.3 | wpb 2040.3 | bsz 4 | num_updates 14085 | best_loss 7.309
2022-03-14 23:03:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 14085 updates
2022-03-14 23:03:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:03:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:03:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 137 @ 14085 updates, score 8.778) (writing took 1.070549706928432 seconds)
2022-03-14 23:03:12 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-14 23:03:12 | INFO | train | epoch 137 | loss 3.917 | ppl 15.1 | wps 40276.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14085 | lr 0.000266454 | gnorm 0.948 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 22936
KL Stats: Epoch 137 Divergences: Uniform: 7.12574975693125 Unigram: 4.238597376165078
2022-03-14 23:03:12 | INFO | fairseq.trainer | begin training epoch 138
2022-03-14 23:03:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:03:36 | INFO | train_inner | epoch 138:     15 / 103 loss=3.916, ppl=15.1, wps=40244.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14100, lr=0.000266312, gnorm=0.947, loss_scale=16, train_wall=153, gb_free=20.8, wall=22960
2022-03-14 23:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:05:58 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 8.799 | ppl 445.46 | wps 66110.3 | wpb 2040.3 | bsz 4 | num_updates 14188 | best_loss 7.309
2022-03-14 23:05:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 14188 updates
2022-03-14 23:05:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:05:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 138 @ 14188 updates, score 8.799) (writing took 1.0750742992386222 seconds)
2022-03-14 23:05:59 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-14 23:05:59 | INFO | train | epoch 138 | loss 3.911 | ppl 15.04 | wps 40270.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14188 | lr 0.000265485 | gnorm 0.954 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23103
KL Stats: Epoch 138 Divergences: Uniform: 7.130253495429973 Unigram: 4.2413182363478565
2022-03-14 23:05:59 | INFO | fairseq.trainer | begin training epoch 139
2022-03-14 23:05:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:06:19 | INFO | train_inner | epoch 139:     12 / 103 loss=3.913, ppl=15.07, wps=40238.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14200, lr=0.000265372, gnorm=0.957, loss_scale=16, train_wall=153, gb_free=20.8, wall=23122
2022-03-14 23:08:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:08:45 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 8.811 | ppl 449.17 | wps 65826.5 | wpb 2040.3 | bsz 4 | num_updates 14291 | best_loss 7.309
2022-03-14 23:08:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 14291 updates
2022-03-14 23:08:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 139 @ 14291 updates, score 8.811) (writing took 1.0548467319458723 seconds)
2022-03-14 23:08:46 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-14 23:08:46 | INFO | train | epoch 139 | loss 3.904 | ppl 14.97 | wps 40282.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14291 | lr 0.000264526 | gnorm 0.942 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23270
KL Stats: Epoch 139 Divergences: Uniform: 7.140987498938226 Unigram: 4.248413836390449
2022-03-14 23:08:46 | INFO | fairseq.trainer | begin training epoch 140
2022-03-14 23:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:09:01 | INFO | train_inner | epoch 140:      9 / 103 loss=3.906, ppl=14.99, wps=40243.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14300, lr=0.000264443, gnorm=0.943, loss_scale=16, train_wall=153, gb_free=20.8, wall=23284
2022-03-14 23:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:11:33 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 8.798 | ppl 445.24 | wps 66414.9 | wpb 2040.3 | bsz 4 | num_updates 14394 | best_loss 7.309
2022-03-14 23:11:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 14394 updates
2022-03-14 23:11:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:11:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 140 @ 14394 updates, score 8.798) (writing took 1.0473912106826901 seconds)
2022-03-14 23:11:34 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-14 23:11:34 | INFO | train | epoch 140 | loss 3.899 | ppl 14.92 | wps 40218.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14394 | lr 0.000263578 | gnorm 0.952 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23437
KL Stats: Epoch 140 Divergences: Uniform: 7.144148010697247 Unigram: 4.251723899294147
2022-03-14 23:11:34 | INFO | fairseq.trainer | begin training epoch 141
2022-03-14 23:11:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:11:43 | INFO | train_inner | epoch 141:      6 / 103 loss=3.898, ppl=14.91, wps=40185.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14400, lr=0.000263523, gnorm=0.951, loss_scale=16, train_wall=153, gb_free=20.8, wall=23447
2022-03-14 23:14:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:14:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:14:20 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 8.821 | ppl 452.15 | wps 66235.3 | wpb 2040.3 | bsz 4 | num_updates 14496 | best_loss 7.309
2022-03-14 23:14:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 14496 updates
2022-03-14 23:14:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:14:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 141 @ 14496 updates, score 8.821) (writing took 1.1464111413806677 seconds)
2022-03-14 23:14:21 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-14 23:14:21 | INFO | train | epoch 141 | loss 3.891 | ppl 14.84 | wps 39864.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 14496 | lr 0.000262649 | gnorm 0.948 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23604
KL Stats: Epoch 141 Divergences: Uniform: 7.150669763753764 Unigram: 4.257259712205209
2022-03-14 23:14:21 | INFO | fairseq.trainer | begin training epoch 142
2022-03-14 23:14:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:14:27 | INFO | train_inner | epoch 142:      4 / 103 loss=3.894, ppl=14.87, wps=39833.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=14500, lr=0.000262613, gnorm=0.945, loss_scale=16, train_wall=154, gb_free=20.8, wall=23611
2022-03-14 23:17:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:17:07 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 8.831 | ppl 455.51 | wps 66127.7 | wpb 2040.3 | bsz 4 | num_updates 14599 | best_loss 7.309
2022-03-14 23:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 14599 updates
2022-03-14 23:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:17:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:17:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 142 @ 14599 updates, score 8.831) (writing took 0.9920166442170739 seconds)
2022-03-14 23:17:08 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-14 23:17:08 | INFO | train | epoch 142 | loss 3.886 | ppl 14.78 | wps 40252.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14599 | lr 0.000261721 | gnorm 0.956 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 23771
KL Stats: Epoch 142 Divergences: Uniform: 7.1572277861774385 Unigram: 4.2654398158088505
2022-03-14 23:17:08 | INFO | fairseq.trainer | begin training epoch 143
2022-03-14 23:17:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:17:10 | INFO | train_inner | epoch 143:      1 / 103 loss=3.888, ppl=14.8, wps=40217.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14600, lr=0.000261712, gnorm=0.958, loss_scale=16, train_wall=153, gb_free=20.8, wall=23773
2022-03-14 23:19:48 | INFO | train_inner | epoch 143:    101 / 103 loss=3.881, ppl=14.74, wps=41469.3, ups=0.63, wpb=65530.9, bsz=128, num_updates=14700, lr=0.00026082, gnorm=0.963, loss_scale=16, train_wall=153, gb_free=20.8, wall=23931
2022-03-14 23:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:19:54 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 8.822 | ppl 452.48 | wps 66198.4 | wpb 2040.3 | bsz 4 | num_updates 14702 | best_loss 7.309
2022-03-14 23:19:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 14702 updates
2022-03-14 23:19:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 143 @ 14702 updates, score 8.822) (writing took 1.020671185106039 seconds)
2022-03-14 23:19:55 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-14 23:19:55 | INFO | train | epoch 143 | loss 3.881 | ppl 14.74 | wps 40296.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14702 | lr 0.000260803 | gnorm 0.964 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 23938
KL Stats: Epoch 143 Divergences: Uniform: 7.161895122998073 Unigram: 4.265948641637793
2022-03-14 23:19:55 | INFO | fairseq.trainer | begin training epoch 144
2022-03-14 23:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:22:30 | INFO | train_inner | epoch 144:     98 / 103 loss=3.871, ppl=14.63, wps=40250.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14800, lr=0.000259938, gnorm=0.945, loss_scale=16, train_wall=153, gb_free=20.8, wall=24093
2022-03-14 23:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:22:41 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 8.827 | ppl 454.28 | wps 66462.6 | wpb 2040.3 | bsz 4 | num_updates 14805 | best_loss 7.309
2022-03-14 23:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 14805 updates
2022-03-14 23:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:22:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 144 @ 14805 updates, score 8.827) (writing took 1.0243755569681525 seconds)
2022-03-14 23:22:42 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-14 23:22:42 | INFO | train | epoch 144 | loss 3.874 | ppl 14.66 | wps 40287.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14805 | lr 0.000259894 | gnorm 0.945 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24105
KL Stats: Epoch 144 Divergences: Uniform: 7.16655543510771 Unigram: 4.2712669116515105
2022-03-14 23:22:42 | INFO | fairseq.trainer | begin training epoch 145
2022-03-14 23:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:25:12 | INFO | train_inner | epoch 145:     95 / 103 loss=3.868, ppl=14.6, wps=40243.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=14900, lr=0.000259064, gnorm=0.945, loss_scale=16, train_wall=153, gb_free=20.8, wall=24256
2022-03-14 23:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:25:28 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 8.855 | ppl 463.08 | wps 66256.4 | wpb 2040.3 | bsz 4 | num_updates 14908 | best_loss 7.309
2022-03-14 23:25:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 14908 updates
2022-03-14 23:25:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:25:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:25:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 145 @ 14908 updates, score 8.855) (writing took 1.0133954491466284 seconds)
2022-03-14 23:25:29 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-14 23:25:29 | INFO | train | epoch 145 | loss 3.869 | ppl 14.61 | wps 40275.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 14908 | lr 0.000258994 | gnorm 0.945 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24272
KL Stats: Epoch 145 Divergences: Uniform: 7.176460156400399 Unigram: 4.278190833972455
2022-03-14 23:25:29 | INFO | fairseq.trainer | begin training epoch 146
2022-03-14 23:25:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:27:55 | INFO | train_inner | epoch 146:     92 / 103 loss=3.862, ppl=14.54, wps=40235.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15000, lr=0.000258199, gnorm=0.961, loss_scale=16, train_wall=153, gb_free=20.8, wall=24418
2022-03-14 23:27:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:28:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:28:15 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 8.86 | ppl 464.79 | wps 66389.8 | wpb 2040.3 | bsz 4 | num_updates 15010 | best_loss 7.309
2022-03-14 23:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 15010 updates
2022-03-14 23:28:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:28:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 146 @ 15010 updates, score 8.86) (writing took 1.046467112377286 seconds)
2022-03-14 23:28:16 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-14 23:28:16 | INFO | train | epoch 146 | loss 3.863 | ppl 14.55 | wps 39874.5 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15010 | lr 0.000258113 | gnorm 0.964 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24440
KL Stats: Epoch 146 Divergences: Uniform: 7.1820498366529515 Unigram: 4.283515681568074
2022-03-14 23:28:16 | INFO | fairseq.trainer | begin training epoch 147
2022-03-14 23:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:30:39 | INFO | train_inner | epoch 147:     90 / 103 loss=3.856, ppl=14.48, wps=39767.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=15100, lr=0.000257343, gnorm=0.956, loss_scale=16, train_wall=155, gb_free=20.8, wall=24582
2022-03-14 23:30:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:31:02 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 8.876 | ppl 469.89 | wps 66276.5 | wpb 2040.3 | bsz 4 | num_updates 15113 | best_loss 7.309
2022-03-14 23:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 15113 updates
2022-03-14 23:31:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:31:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 147 @ 15113 updates, score 8.876) (writing took 1.0405076183378696 seconds)
2022-03-14 23:31:03 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-14 23:31:03 | INFO | train | epoch 147 | loss 3.858 | ppl 14.5 | wps 40183.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15113 | lr 0.000257232 | gnorm 0.958 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 24607
KL Stats: Epoch 147 Divergences: Uniform: 7.186982291706698 Unigram: 4.287035286115258
2022-03-14 23:31:03 | INFO | fairseq.trainer | begin training epoch 148
2022-03-14 23:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:33:21 | INFO | train_inner | epoch 148:     87 / 103 loss=3.851, ppl=14.43, wps=40247, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15200, lr=0.000256495, gnorm=0.964, loss_scale=16, train_wall=153, gb_free=20.8, wall=24744
2022-03-14 23:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:33:49 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 8.862 | ppl 465.15 | wps 66259.8 | wpb 2040.3 | bsz 4 | num_updates 15216 | best_loss 7.309
2022-03-14 23:33:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 15216 updates
2022-03-14 23:33:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:33:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 148 @ 15216 updates, score 8.862) (writing took 1.0668340539559722 seconds)
2022-03-14 23:33:50 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-14 23:33:50 | INFO | train | epoch 148 | loss 3.853 | ppl 14.45 | wps 40283.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15216 | lr 0.00025636 | gnorm 0.965 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24774
KL Stats: Epoch 148 Divergences: Uniform: 7.192315101132493 Unigram: 4.291803143505842
2022-03-14 23:33:50 | INFO | fairseq.trainer | begin training epoch 149
2022-03-14 23:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:36:03 | INFO | train_inner | epoch 149:     84 / 103 loss=3.848, ppl=14.4, wps=40256, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=15300, lr=0.000255655, gnorm=0.959, loss_scale=16, train_wall=153, gb_free=20.8, wall=24907
2022-03-14 23:36:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:36:36 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 8.879 | ppl 470.69 | wps 65708.8 | wpb 2040.3 | bsz 4 | num_updates 15319 | best_loss 7.309
2022-03-14 23:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 15319 updates
2022-03-14 23:36:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 149 @ 15319 updates, score 8.879) (writing took 1.0599510008469224 seconds)
2022-03-14 23:36:37 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-14 23:36:37 | INFO | train | epoch 149 | loss 3.847 | ppl 14.39 | wps 40285.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15319 | lr 0.000255496 | gnorm 0.951 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 24941
KL Stats: Epoch 149 Divergences: Uniform: 7.199335580470151 Unigram: 4.296747880930758
2022-03-14 23:36:37 | INFO | fairseq.trainer | begin training epoch 150
2022-03-14 23:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:38:46 | INFO | train_inner | epoch 150:     81 / 103 loss=3.84, ppl=14.32, wps=40121.9, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=15400, lr=0.000254824, gnorm=0.949, loss_scale=16, train_wall=153, gb_free=20.8, wall=25069
2022-03-14 23:39:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:39:24 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 8.881 | ppl 471.57 | wps 66106.7 | wpb 2040.3 | bsz 4 | num_updates 15422 | best_loss 7.309
2022-03-14 23:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 15422 updates
2022-03-14 23:39:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:39:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:39:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 150 @ 15422 updates, score 8.881) (writing took 0.9660365665331483 seconds)
2022-03-14 23:39:25 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-14 23:39:25 | INFO | train | epoch 150 | loss 3.842 | ppl 14.34 | wps 40193.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15422 | lr 0.000254642 | gnorm 0.954 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25108
KL Stats: Epoch 150 Divergences: Uniform: 7.204783513503024 Unigram: 4.300315738943142
2022-03-14 23:39:25 | INFO | fairseq.trainer | begin training epoch 151
2022-03-14 23:39:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:41:28 | INFO | train_inner | epoch 151:     78 / 103 loss=3.841, ppl=14.33, wps=40274.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15500, lr=0.000254, gnorm=0.959, loss_scale=16, train_wall=153, gb_free=20.8, wall=25232
2022-03-14 23:41:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:42:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:42:11 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 8.891 | ppl 474.68 | wps 66289.6 | wpb 2040.3 | bsz 4 | num_updates 15524 | best_loss 7.309
2022-03-14 23:42:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 15524 updates
2022-03-14 23:42:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:42:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 151 @ 15524 updates, score 8.891) (writing took 1.0013843020424247 seconds)
2022-03-14 23:42:12 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-14 23:42:12 | INFO | train | epoch 151 | loss 3.837 | ppl 14.29 | wps 39902.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 15524 | lr 0.000253804 | gnorm 0.955 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25275
KL Stats: Epoch 151 Divergences: Uniform: 7.2103332139324205 Unigram: 4.305884766868038
2022-03-14 23:42:12 | INFO | fairseq.trainer | begin training epoch 152
2022-03-14 23:42:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:44:12 | INFO | train_inner | epoch 152:     76 / 103 loss=3.83, ppl=14.22, wps=39872.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=15600, lr=0.000253185, gnorm=0.953, loss_scale=16, train_wall=154, gb_free=20.8, wall=25395
2022-03-14 23:44:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:44:58 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 8.873 | ppl 468.7 | wps 65761.9 | wpb 2040.3 | bsz 4 | num_updates 15627 | best_loss 7.309
2022-03-14 23:44:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 15627 updates
2022-03-14 23:44:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:44:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 152 @ 15627 updates, score 8.873) (writing took 1.0152255184948444 seconds)
2022-03-14 23:44:59 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-14 23:44:59 | INFO | train | epoch 152 | loss 3.833 | ppl 14.25 | wps 40278.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15627 | lr 0.000252966 | gnorm 0.953 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25442
KL Stats: Epoch 152 Divergences: Uniform: 7.216025018779702 Unigram: 4.3086564510523635
2022-03-14 23:44:59 | INFO | fairseq.trainer | begin training epoch 153
2022-03-14 23:44:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:46:54 | INFO | train_inner | epoch 153:     73 / 103 loss=3.831, ppl=14.23, wps=40228.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=15700, lr=0.000252377, gnorm=0.96, loss_scale=16, train_wall=153, gb_free=20.8, wall=25558
2022-03-14 23:47:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:47:45 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 8.893 | ppl 475.38 | wps 66038.8 | wpb 2040.3 | bsz 4 | num_updates 15730 | best_loss 7.309
2022-03-14 23:47:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 15730 updates
2022-03-14 23:47:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:47:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:47:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 153 @ 15730 updates, score 8.893) (writing took 0.979784457013011 seconds)
2022-03-14 23:47:46 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-14 23:47:46 | INFO | train | epoch 153 | loss 3.828 | ppl 14.2 | wps 40280.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15730 | lr 0.000252136 | gnorm 0.962 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25609
KL Stats: Epoch 153 Divergences: Uniform: 7.219777617151135 Unigram: 4.312130233214681
2022-03-14 23:47:46 | INFO | fairseq.trainer | begin training epoch 154
2022-03-14 23:47:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:49:37 | INFO | train_inner | epoch 154:     70 / 103 loss=3.82, ppl=14.12, wps=40231, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15800, lr=0.000251577, gnorm=0.957, loss_scale=16, train_wall=153, gb_free=20.8, wall=25720
2022-03-14 23:50:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:50:32 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 8.901 | ppl 478.11 | wps 66249.2 | wpb 2040.3 | bsz 4 | num_updates 15833 | best_loss 7.309
2022-03-14 23:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 15833 updates
2022-03-14 23:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 154 @ 15833 updates, score 8.901) (writing took 1.0083086751401424 seconds)
2022-03-14 23:50:33 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-14 23:50:33 | INFO | train | epoch 154 | loss 3.822 | ppl 14.15 | wps 40251.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15833 | lr 0.000251315 | gnorm 0.966 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 25776
KL Stats: Epoch 154 Divergences: Uniform: 7.226338336940371 Unigram: 4.31739222115127
2022-03-14 23:50:33 | INFO | fairseq.trainer | begin training epoch 155
2022-03-14 23:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:52:19 | INFO | train_inner | epoch 155:     67 / 103 loss=3.818, ppl=14.1, wps=40215.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=15900, lr=0.000250785, gnorm=0.959, loss_scale=16, train_wall=153, gb_free=20.8, wall=25882
2022-03-14 23:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:53:19 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 8.903 | ppl 478.83 | wps 66312.5 | wpb 2040.3 | bsz 4 | num_updates 15936 | best_loss 7.309
2022-03-14 23:53:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 15936 updates
2022-03-14 23:53:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:53:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:53:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 155 @ 15936 updates, score 8.903) (writing took 0.9704372305423021 seconds)
2022-03-14 23:53:20 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-14 23:53:20 | INFO | train | epoch 155 | loss 3.817 | ppl 14.1 | wps 40247.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 15936 | lr 0.000250502 | gnorm 0.959 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 25944
KL Stats: Epoch 155 Divergences: Uniform: 7.229748374936159 Unigram: 4.321561338235982
2022-03-14 23:53:20 | INFO | fairseq.trainer | begin training epoch 156
2022-03-14 23:53:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:55:01 | INFO | train_inner | epoch 156:     64 / 103 loss=3.815, ppl=14.08, wps=40207, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16000, lr=0.00025, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=26045
2022-03-14 23:56:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:56:06 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 8.926 | ppl 486.37 | wps 66201.6 | wpb 2040.3 | bsz 4 | num_updates 16039 | best_loss 7.309
2022-03-14 23:56:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 16039 updates
2022-03-14 23:56:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:56:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:56:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 156 @ 16039 updates, score 8.926) (writing took 0.9780483199283481 seconds)
2022-03-14 23:56:07 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-14 23:56:07 | INFO | train | epoch 156 | loss 3.813 | ppl 14.06 | wps 40256.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16039 | lr 0.000249696 | gnorm 0.965 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 26111
KL Stats: Epoch 156 Divergences: Uniform: 7.235579330932572 Unigram: 4.326292268262711
2022-03-14 23:56:07 | INFO | fairseq.trainer | begin training epoch 157
2022-03-14 23:56:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 23:57:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 23:57:45 | INFO | train_inner | epoch 157:     62 / 103 loss=3.809, ppl=14.01, wps=39841.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=16100, lr=0.000249222, gnorm=0.954, loss_scale=16, train_wall=154, gb_free=20.8, wall=26209
2022-03-14 23:58:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 23:58:53 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 8.916 | ppl 483.06 | wps 66112.5 | wpb 2040.3 | bsz 4 | num_updates 16141 | best_loss 7.309
2022-03-14 23:58:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 16141 updates
2022-03-14 23:58:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:58:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-14 23:58:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 157 @ 16141 updates, score 8.916) (writing took 0.9835944604128599 seconds)
2022-03-14 23:58:54 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-14 23:58:54 | INFO | train | epoch 157 | loss 3.806 | ppl 13.99 | wps 39851.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16141 | lr 0.000248906 | gnorm 0.952 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26278
KL Stats: Epoch 157 Divergences: Uniform: 7.241721407829641 Unigram: 4.331016806531978
2022-03-14 23:58:54 | INFO | fairseq.trainer | begin training epoch 158
2022-03-14 23:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:00:28 | INFO | train_inner | epoch 158:     59 / 103 loss=3.804, ppl=13.97, wps=40227.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16200, lr=0.000248452, gnorm=0.956, loss_scale=16, train_wall=153, gb_free=20.8, wall=26371
2022-03-15 00:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:01:40 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 8.9 | ppl 477.81 | wps 66458.2 | wpb 2040.3 | bsz 4 | num_updates 16244 | best_loss 7.309
2022-03-15 00:01:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 16244 updates
2022-03-15 00:01:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:01:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:01:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 158 @ 16244 updates, score 8.9) (writing took 0.9880642369389534 seconds)
2022-03-15 00:01:41 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-15 00:01:41 | INFO | train | epoch 158 | loss 3.803 | ppl 13.96 | wps 40292.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16244 | lr 0.000248115 | gnorm 0.956 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26445
KL Stats: Epoch 158 Divergences: Uniform: 7.244627304469982 Unigram: 4.333803471224674
2022-03-15 00:01:41 | INFO | fairseq.trainer | begin training epoch 159
2022-03-15 00:01:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:03:10 | INFO | train_inner | epoch 159:     56 / 103 loss=3.8, ppl=13.93, wps=40225.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16300, lr=0.000247689, gnorm=0.958, loss_scale=16, train_wall=153, gb_free=20.8, wall=26534
2022-03-15 00:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:04:27 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 8.93 | ppl 487.85 | wps 66069.2 | wpb 2040.3 | bsz 4 | num_updates 16347 | best_loss 7.309
2022-03-15 00:04:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 16347 updates
2022-03-15 00:04:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:04:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:04:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 159 @ 16347 updates, score 8.93) (writing took 0.9746741689741611 seconds)
2022-03-15 00:04:28 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-15 00:04:28 | INFO | train | epoch 159 | loss 3.799 | ppl 13.92 | wps 40233.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16347 | lr 0.000247332 | gnorm 0.963 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 26612
KL Stats: Epoch 159 Divergences: Uniform: 7.250753588744848 Unigram: 4.337550304478782
2022-03-15 00:04:28 | INFO | fairseq.trainer | begin training epoch 160
2022-03-15 00:04:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:05:52 | INFO | train_inner | epoch 160:     53 / 103 loss=3.796, ppl=13.89, wps=40226.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=16400, lr=0.000246932, gnorm=0.963, loss_scale=16, train_wall=153, gb_free=20.8, wall=26696
2022-03-15 00:07:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:07:14 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 8.933 | ppl 488.81 | wps 66736.4 | wpb 2040.3 | bsz 4 | num_updates 16450 | best_loss 7.309
2022-03-15 00:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 16450 updates
2022-03-15 00:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:07:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:07:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 160 @ 16450 updates, score 8.933) (writing took 0.9596814662218094 seconds)
2022-03-15 00:07:15 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-15 00:07:15 | INFO | train | epoch 160 | loss 3.793 | ppl 13.86 | wps 40285 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16450 | lr 0.000246557 | gnorm 0.961 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26779
KL Stats: Epoch 160 Divergences: Uniform: 7.255538444897847 Unigram: 4.3431784107563205
2022-03-15 00:07:15 | INFO | fairseq.trainer | begin training epoch 161
2022-03-15 00:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:08:35 | INFO | train_inner | epoch 161:     50 / 103 loss=3.79, ppl=13.83, wps=40259.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16500, lr=0.000246183, gnorm=0.955, loss_scale=16, train_wall=153, gb_free=20.8, wall=26858
2022-03-15 00:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:10:01 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 8.927 | ppl 486.61 | wps 66149 | wpb 2040.3 | bsz 4 | num_updates 16553 | best_loss 7.309
2022-03-15 00:10:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 16553 updates
2022-03-15 00:10:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:10:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 161 @ 16553 updates, score 8.927) (writing took 0.9512406345456839 seconds)
2022-03-15 00:10:02 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-15 00:10:02 | INFO | train | epoch 161 | loss 3.789 | ppl 13.82 | wps 40292.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16553 | lr 0.000245789 | gnorm 0.953 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 26946
KL Stats: Epoch 161 Divergences: Uniform: 7.260762093794087 Unigram: 4.346115030651366
2022-03-15 00:10:02 | INFO | fairseq.trainer | begin training epoch 162
2022-03-15 00:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:11:17 | INFO | train_inner | epoch 162:     47 / 103 loss=3.787, ppl=13.81, wps=40252.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16600, lr=0.00024544, gnorm=0.96, loss_scale=32, train_wall=153, gb_free=20.8, wall=27020
2022-03-15 00:11:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:12:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:12:48 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 8.94 | ppl 491.29 | wps 66218.1 | wpb 2040.3 | bsz 4 | num_updates 16655 | best_loss 7.309
2022-03-15 00:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 16655 updates
2022-03-15 00:12:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:12:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:12:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 162 @ 16655 updates, score 8.94) (writing took 0.9675907697528601 seconds)
2022-03-15 00:12:49 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-15 00:12:49 | INFO | train | epoch 162 | loss 3.783 | ppl 13.76 | wps 39890.7 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 16655 | lr 0.000245035 | gnorm 0.964 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27113
KL Stats: Epoch 162 Divergences: Uniform: 7.267792086024283 Unigram: 4.352645052579801
2022-03-15 00:12:49 | INFO | fairseq.trainer | begin training epoch 163
2022-03-15 00:12:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:14:01 | INFO | train_inner | epoch 163:     45 / 103 loss=3.78, ppl=13.74, wps=39862.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=16700, lr=0.000244704, gnorm=0.968, loss_scale=16, train_wall=154, gb_free=20.8, wall=27184
2022-03-15 00:15:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:15:35 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 8.948 | ppl 493.77 | wps 66396 | wpb 2040.3 | bsz 4 | num_updates 16758 | best_loss 7.309
2022-03-15 00:15:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 16758 updates
2022-03-15 00:15:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:15:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:15:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 163 @ 16758 updates, score 8.948) (writing took 0.9657774129882455 seconds)
2022-03-15 00:15:36 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-15 00:15:36 | INFO | train | epoch 163 | loss 3.779 | ppl 13.73 | wps 40269 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16758 | lr 0.000244281 | gnorm 0.959 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27280
KL Stats: Epoch 163 Divergences: Uniform: 7.269053936390458 Unigram: 4.3545963753843715
2022-03-15 00:15:36 | INFO | fairseq.trainer | begin training epoch 164
2022-03-15 00:15:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:16:43 | INFO | train_inner | epoch 164:     42 / 103 loss=3.778, ppl=13.72, wps=40229.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=16800, lr=0.000243975, gnorm=0.956, loss_scale=16, train_wall=153, gb_free=20.8, wall=27346
2022-03-15 00:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:18:22 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 8.966 | ppl 500.24 | wps 66171.9 | wpb 2040.3 | bsz 4 | num_updates 16861 | best_loss 7.309
2022-03-15 00:18:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 16861 updates
2022-03-15 00:18:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:18:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:18:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 164 @ 16861 updates, score 8.966) (writing took 0.9726029289886355 seconds)
2022-03-15 00:18:23 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-15 00:18:23 | INFO | train | epoch 164 | loss 3.776 | ppl 13.7 | wps 40280.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16861 | lr 0.000243533 | gnorm 0.975 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27447
KL Stats: Epoch 164 Divergences: Uniform: 7.272383271722769 Unigram: 4.358127866873367
2022-03-15 00:18:23 | INFO | fairseq.trainer | begin training epoch 165
2022-03-15 00:18:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:19:25 | INFO | train_inner | epoch 165:     39 / 103 loss=3.774, ppl=13.68, wps=40251.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=16900, lr=0.000243252, gnorm=0.975, loss_scale=16, train_wall=153, gb_free=20.8, wall=27509
2022-03-15 00:21:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:21:10 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 8.957 | ppl 497.07 | wps 66384.5 | wpb 2040.3 | bsz 4 | num_updates 16964 | best_loss 7.309
2022-03-15 00:21:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 16964 updates
2022-03-15 00:21:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:21:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:21:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 165 @ 16964 updates, score 8.957) (writing took 0.9044354120269418 seconds)
2022-03-15 00:21:11 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-15 00:21:11 | INFO | train | epoch 165 | loss 3.772 | ppl 13.66 | wps 40197.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 16964 | lr 0.000242793 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27614
KL Stats: Epoch 165 Divergences: Uniform: 7.277733675334856 Unigram: 4.360788924907139
2022-03-15 00:21:11 | INFO | fairseq.trainer | begin training epoch 166
2022-03-15 00:21:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:22:08 | INFO | train_inner | epoch 166:     36 / 103 loss=3.771, ppl=13.65, wps=40147.9, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=17000, lr=0.000242536, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=27671
2022-03-15 00:23:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:23:57 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 8.962 | ppl 498.86 | wps 65953.4 | wpb 2040.3 | bsz 4 | num_updates 17067 | best_loss 7.309
2022-03-15 00:23:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 17067 updates
2022-03-15 00:23:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:23:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 166 @ 17067 updates, score 8.962) (writing took 0.9742091288790107 seconds)
2022-03-15 00:23:58 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-15 00:23:58 | INFO | train | epoch 166 | loss 3.765 | ppl 13.6 | wps 40273.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17067 | lr 0.000242059 | gnorm 0.965 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 27781
KL Stats: Epoch 166 Divergences: Uniform: 7.280827569768638 Unigram: 4.364699755139367
2022-03-15 00:23:58 | INFO | fairseq.trainer | begin training epoch 167
2022-03-15 00:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:24:50 | INFO | train_inner | epoch 167:     33 / 103 loss=3.764, ppl=13.58, wps=40250.1, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17100, lr=0.000241825, gnorm=0.968, loss_scale=16, train_wall=153, gb_free=20.8, wall=27834
2022-03-15 00:25:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:26:44 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 8.962 | ppl 498.66 | wps 66069.3 | wpb 2040.3 | bsz 4 | num_updates 17169 | best_loss 7.309
2022-03-15 00:26:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 17169 updates
2022-03-15 00:26:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:26:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:26:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 167 @ 17169 updates, score 8.962) (writing took 0.9565770020708442 seconds)
2022-03-15 00:26:45 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-15 00:26:45 | INFO | train | epoch 167 | loss 3.762 | ppl 13.57 | wps 39846.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17169 | lr 0.000241339 | gnorm 0.969 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 27949
KL Stats: Epoch 167 Divergences: Uniform: 7.287904122490443 Unigram: 4.369078281426439
2022-03-15 00:26:45 | INFO | fairseq.trainer | begin training epoch 168
2022-03-15 00:26:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:27:34 | INFO | train_inner | epoch 168:     31 / 103 loss=3.762, ppl=13.57, wps=39801.3, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=17200, lr=0.000241121, gnorm=0.968, loss_scale=16, train_wall=155, gb_free=20.8, wall=27998
2022-03-15 00:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:29:31 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 8.969 | ppl 501.12 | wps 66050.5 | wpb 2040.3 | bsz 4 | num_updates 17272 | best_loss 7.309
2022-03-15 00:29:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 17272 updates
2022-03-15 00:29:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 168 @ 17272 updates, score 8.969) (writing took 0.9939410509541631 seconds)
2022-03-15 00:29:32 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-15 00:29:32 | INFO | train | epoch 168 | loss 3.758 | ppl 13.53 | wps 40236.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17272 | lr 0.000240618 | gnorm 0.97 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28116
KL Stats: Epoch 168 Divergences: Uniform: 7.290320052623573 Unigram: 4.37202452413735
2022-03-15 00:29:32 | INFO | fairseq.trainer | begin training epoch 169
2022-03-15 00:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:30:17 | INFO | train_inner | epoch 169:     28 / 103 loss=3.757, ppl=13.52, wps=40231.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17300, lr=0.000240424, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=28160
2022-03-15 00:32:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:32:18 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 8.996 | ppl 510.7 | wps 65922.2 | wpb 2040.3 | bsz 4 | num_updates 17375 | best_loss 7.309
2022-03-15 00:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 17375 updates
2022-03-15 00:32:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 169 @ 17375 updates, score 8.996) (writing took 0.9814484426751733 seconds)
2022-03-15 00:32:19 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-15 00:32:19 | INFO | train | epoch 169 | loss 3.754 | ppl 13.5 | wps 40270.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17375 | lr 0.000239904 | gnorm 0.975 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28283
KL Stats: Epoch 169 Divergences: Uniform: 7.294660220859944 Unigram: 4.376120988145038
2022-03-15 00:32:19 | INFO | fairseq.trainer | begin training epoch 170
2022-03-15 00:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:32:59 | INFO | train_inner | epoch 170:     25 / 103 loss=3.754, ppl=13.49, wps=40213, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=17400, lr=0.000239732, gnorm=0.971, loss_scale=16, train_wall=153, gb_free=20.8, wall=28322
2022-03-15 00:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:35:05 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 8.983 | ppl 506.01 | wps 66420 | wpb 2040.3 | bsz 4 | num_updates 17478 | best_loss 7.309
2022-03-15 00:35:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 17478 updates
2022-03-15 00:35:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:35:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:35:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 170 @ 17478 updates, score 8.983) (writing took 0.9695272231474519 seconds)
2022-03-15 00:35:06 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-15 00:35:06 | INFO | train | epoch 170 | loss 3.749 | ppl 13.45 | wps 40274.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17478 | lr 0.000239196 | gnorm 0.956 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28450
KL Stats: Epoch 170 Divergences: Uniform: 7.300049324779223 Unigram: 4.3797837416974
2022-03-15 00:35:06 | INFO | fairseq.trainer | begin training epoch 171
2022-03-15 00:35:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:35:41 | INFO | train_inner | epoch 171:     22 / 103 loss=3.752, ppl=13.47, wps=40235.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17500, lr=0.000239046, gnorm=0.964, loss_scale=16, train_wall=153, gb_free=20.8, wall=28485
2022-03-15 00:37:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:37:52 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 8.987 | ppl 507.37 | wps 66143.5 | wpb 2040.3 | bsz 4 | num_updates 17581 | best_loss 7.309
2022-03-15 00:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 17581 updates
2022-03-15 00:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 171 @ 17581 updates, score 8.987) (writing took 1.003399902023375 seconds)
2022-03-15 00:37:53 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-15 00:37:53 | INFO | train | epoch 171 | loss 3.745 | ppl 13.4 | wps 40257.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17581 | lr 0.000238494 | gnorm 0.983 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28617
KL Stats: Epoch 171 Divergences: Uniform: 7.302098735880878 Unigram: 4.383507734749763
2022-03-15 00:37:53 | INFO | fairseq.trainer | begin training epoch 172
2022-03-15 00:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:38:24 | INFO | train_inner | epoch 172:     19 / 103 loss=3.742, ppl=13.38, wps=40241.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17600, lr=0.000238366, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=28647
2022-03-15 00:39:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:40:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:40:39 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 8.994 | ppl 510.01 | wps 66376 | wpb 2040.3 | bsz 4 | num_updates 17683 | best_loss 7.309
2022-03-15 00:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 17683 updates
2022-03-15 00:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 172 @ 17683 updates, score 8.994) (writing took 0.964220984838903 seconds)
2022-03-15 00:40:40 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-15 00:40:40 | INFO | train | epoch 172 | loss 3.74 | ppl 13.36 | wps 39891.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 17683 | lr 0.000237806 | gnorm 0.974 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 28784
KL Stats: Epoch 172 Divergences: Uniform: 7.307201404718846 Unigram: 4.3872726953218155
2022-03-15 00:40:40 | INFO | fairseq.trainer | begin training epoch 173
2022-03-15 00:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:41:07 | INFO | train_inner | epoch 173:     17 / 103 loss=3.742, ppl=13.38, wps=39857.1, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=17700, lr=0.000237691, gnorm=0.972, loss_scale=16, train_wall=154, gb_free=20.8, wall=28811
2022-03-15 00:43:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:43:27 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 9.009 | ppl 515.28 | wps 66389.3 | wpb 2040.3 | bsz 4 | num_updates 17786 | best_loss 7.309
2022-03-15 00:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 17786 updates
2022-03-15 00:43:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:43:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:43:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 173 @ 17786 updates, score 9.009) (writing took 0.9475108506157994 seconds)
2022-03-15 00:43:28 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-15 00:43:28 | INFO | train | epoch 173 | loss 3.736 | ppl 13.33 | wps 40254.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17786 | lr 0.000237116 | gnorm 0.981 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 28951
KL Stats: Epoch 173 Divergences: Uniform: 7.312923045156633 Unigram: 4.391012876706336
2022-03-15 00:43:28 | INFO | fairseq.trainer | begin training epoch 174
2022-03-15 00:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:43:50 | INFO | train_inner | epoch 174:     14 / 103 loss=3.735, ppl=13.31, wps=40224.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=17800, lr=0.000237023, gnorm=0.981, loss_scale=16, train_wall=153, gb_free=20.8, wall=28973
2022-03-15 00:46:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:46:14 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 9.003 | ppl 512.99 | wps 66336.5 | wpb 2040.3 | bsz 4 | num_updates 17889 | best_loss 7.309
2022-03-15 00:46:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 17889 updates
2022-03-15 00:46:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:46:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:46:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 174 @ 17889 updates, score 9.003) (writing took 0.9765631034970284 seconds)
2022-03-15 00:46:15 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-15 00:46:15 | INFO | train | epoch 174 | loss 3.733 | ppl 13.3 | wps 40249.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17889 | lr 0.000236432 | gnorm 0.97 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29118
KL Stats: Epoch 174 Divergences: Uniform: 7.315939017909991 Unigram: 4.394194350219816
2022-03-15 00:46:15 | INFO | fairseq.trainer | begin training epoch 175
2022-03-15 00:46:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:46:32 | INFO | train_inner | epoch 175:     11 / 103 loss=3.735, ppl=13.31, wps=40202.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=17900, lr=0.00023636, gnorm=0.968, loss_scale=16, train_wall=153, gb_free=20.8, wall=29136
2022-03-15 00:48:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:49:01 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 9.018 | ppl 518.44 | wps 66261.9 | wpb 2040.3 | bsz 4 | num_updates 17992 | best_loss 7.309
2022-03-15 00:49:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 17992 updates
2022-03-15 00:49:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:49:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 175 @ 17992 updates, score 9.018) (writing took 0.9978897701948881 seconds)
2022-03-15 00:49:02 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-15 00:49:02 | INFO | train | epoch 175 | loss 3.728 | ppl 13.25 | wps 40235.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 17992 | lr 0.000235755 | gnorm 0.966 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29285
KL Stats: Epoch 175 Divergences: Uniform: 7.317546727333756 Unigram: 4.396128245371587
2022-03-15 00:49:02 | INFO | fairseq.trainer | begin training epoch 176
2022-03-15 00:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:49:15 | INFO | train_inner | epoch 176:      8 / 103 loss=3.731, ppl=13.28, wps=40213.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18000, lr=0.000235702, gnorm=0.97, loss_scale=16, train_wall=153, gb_free=20.8, wall=29298
2022-03-15 00:51:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:51:48 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 9.003 | ppl 513.19 | wps 66061.2 | wpb 2040.3 | bsz 4 | num_updates 18095 | best_loss 7.309
2022-03-15 00:51:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 18095 updates
2022-03-15 00:51:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:51:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:51:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 176 @ 18095 updates, score 9.003) (writing took 1.0093638459220529 seconds)
2022-03-15 00:51:49 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-15 00:51:49 | INFO | train | epoch 176 | loss 3.726 | ppl 13.23 | wps 40257.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18095 | lr 0.000235083 | gnorm 0.976 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 29452
KL Stats: Epoch 176 Divergences: Uniform: 7.320733695189801 Unigram: 4.399124888945871
2022-03-15 00:51:49 | INFO | fairseq.trainer | begin training epoch 177
2022-03-15 00:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:51:57 | INFO | train_inner | epoch 177:      5 / 103 loss=3.728, ppl=13.25, wps=40202, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18100, lr=0.00023505, gnorm=0.975, loss_scale=16, train_wall=153, gb_free=20.8, wall=29461
2022-03-15 00:53:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 00:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:54:35 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 9.015 | ppl 517.23 | wps 65707.4 | wpb 2040.3 | bsz 4 | num_updates 18197 | best_loss 7.309
2022-03-15 00:54:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 18197 updates
2022-03-15 00:54:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:54:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:54:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 177 @ 18197 updates, score 9.015) (writing took 0.975572319701314 seconds)
2022-03-15 00:54:36 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-15 00:54:36 | INFO | train | epoch 177 | loss 3.719 | ppl 13.17 | wps 39827.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18197 | lr 0.000234423 | gnorm 0.968 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29620
KL Stats: Epoch 177 Divergences: Uniform: 7.32357938064289 Unigram: 4.402937013781128
2022-03-15 00:54:36 | INFO | fairseq.trainer | begin training epoch 178
2022-03-15 00:54:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 00:54:41 | INFO | train_inner | epoch 178:      3 / 103 loss=3.721, ppl=13.18, wps=39813.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18200, lr=0.000234404, gnorm=0.968, loss_scale=16, train_wall=154, gb_free=20.8, wall=29625
2022-03-15 00:57:19 | INFO | train_inner | epoch 178:    103 / 103 loss=3.72, ppl=13.17, wps=41412.2, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=18300, lr=0.000233762, gnorm=0.973, loss_scale=16, train_wall=153, gb_free=20.8, wall=29782
2022-03-15 00:57:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 00:57:22 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 9.025 | ppl 521.04 | wps 66714.6 | wpb 2040.3 | bsz 4 | num_updates 18300 | best_loss 7.309
2022-03-15 00:57:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 18300 updates
2022-03-15 00:57:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:57:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 00:57:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 178 @ 18300 updates, score 9.025) (writing took 0.9698446486145258 seconds)
2022-03-15 00:57:23 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-15 00:57:23 | INFO | train | epoch 178 | loss 3.717 | ppl 13.15 | wps 40259.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18300 | lr 0.000233762 | gnorm 0.972 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29787
KL Stats: Epoch 178 Divergences: Uniform: 7.326642051099109 Unigram: 4.404949523684469
2022-03-15 00:57:23 | INFO | fairseq.trainer | begin training epoch 179
2022-03-15 00:57:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:00:02 | INFO | train_inner | epoch 179:    100 / 103 loss=3.712, ppl=13.1, wps=40206.1, ups=0.61, wpb=65530.9, bsz=128, num_updates=18400, lr=0.000233126, gnorm=0.967, loss_scale=16, train_wall=154, gb_free=20.8, wall=29945
2022-03-15 01:00:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:00:10 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 9.033 | ppl 523.9 | wps 65136.3 | wpb 2040.3 | bsz 4 | num_updates 18403 | best_loss 7.309
2022-03-15 01:00:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 18403 updates
2022-03-15 01:00:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:00:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 179 @ 18403 updates, score 9.033) (writing took 0.9902042681351304 seconds)
2022-03-15 01:00:11 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-15 01:00:11 | INFO | train | epoch 179 | loss 3.713 | ppl 13.12 | wps 40217.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18403 | lr 0.000233107 | gnorm 0.97 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 29954
KL Stats: Epoch 179 Divergences: Uniform: 7.330745980984238 Unigram: 4.410460146265286
2022-03-15 01:00:11 | INFO | fairseq.trainer | begin training epoch 180
2022-03-15 01:00:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:02:44 | INFO | train_inner | epoch 180:     97 / 103 loss=3.708, ppl=13.07, wps=40219.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18500, lr=0.000232495, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=30108
2022-03-15 01:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:02:57 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 9.041 | ppl 526.75 | wps 66330.2 | wpb 2040.3 | bsz 4 | num_updates 18506 | best_loss 7.309
2022-03-15 01:02:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 18506 updates
2022-03-15 01:02:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 180 @ 18506 updates, score 9.041) (writing took 1.0002815518528223 seconds)
2022-03-15 01:02:58 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-15 01:02:58 | INFO | train | epoch 180 | loss 3.709 | ppl 13.08 | wps 40268.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18506 | lr 0.000232458 | gnorm 0.977 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30121
KL Stats: Epoch 180 Divergences: Uniform: 7.337416994488384 Unigram: 4.413351495356277
2022-03-15 01:02:58 | INFO | fairseq.trainer | begin training epoch 181
2022-03-15 01:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:05:26 | INFO | train_inner | epoch 181:     94 / 103 loss=3.703, ppl=13.02, wps=40256.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18600, lr=0.000231869, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=30270
2022-03-15 01:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:05:44 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 9.032 | ppl 523.32 | wps 65968.6 | wpb 2040.3 | bsz 4 | num_updates 18609 | best_loss 7.309
2022-03-15 01:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 18609 updates
2022-03-15 01:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:05:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:05:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 181 @ 18609 updates, score 9.032) (writing took 0.9768313961103559 seconds)
2022-03-15 01:05:45 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-15 01:05:45 | INFO | train | epoch 181 | loss 3.705 | ppl 13.04 | wps 40292.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18609 | lr 0.000231813 | gnorm 0.99 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30288
KL Stats: Epoch 181 Divergences: Uniform: 7.337923994271271 Unigram: 4.415185494263324
2022-03-15 01:05:45 | INFO | fairseq.trainer | begin training epoch 182
2022-03-15 01:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:08:10 | INFO | train_inner | epoch 182:     92 / 103 loss=3.698, ppl=12.98, wps=39836.3, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=18700, lr=0.000231249, gnorm=0.96, loss_scale=16, train_wall=154, gb_free=20.8, wall=30434
2022-03-15 01:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:08:31 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 9.036 | ppl 524.92 | wps 66387.6 | wpb 2040.3 | bsz 4 | num_updates 18711 | best_loss 7.309
2022-03-15 01:08:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 18711 updates
2022-03-15 01:08:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:08:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:08:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 182 @ 18711 updates, score 9.036) (writing took 0.9686947343870997 seconds)
2022-03-15 01:08:32 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-15 01:08:32 | INFO | train | epoch 182 | loss 3.701 | ppl 13.01 | wps 39868.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 18711 | lr 0.000231181 | gnorm 0.964 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30455
KL Stats: Epoch 182 Divergences: Uniform: 7.341591419950922 Unigram: 4.419924901153464
2022-03-15 01:08:32 | INFO | fairseq.trainer | begin training epoch 183
2022-03-15 01:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:10:53 | INFO | train_inner | epoch 183:     89 / 103 loss=3.698, ppl=12.98, wps=40225.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18800, lr=0.000230633, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=30596
2022-03-15 01:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:11:18 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 9.037 | ppl 525.15 | wps 66379.2 | wpb 2040.3 | bsz 4 | num_updates 18814 | best_loss 7.309
2022-03-15 01:11:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 18814 updates
2022-03-15 01:11:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:11:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:11:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 183 @ 18814 updates, score 9.037) (writing took 0.92128677200526 seconds)
2022-03-15 01:11:19 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-15 01:11:19 | INFO | train | epoch 183 | loss 3.698 | ppl 12.98 | wps 40274.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18814 | lr 0.000230547 | gnorm 0.983 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30622
KL Stats: Epoch 183 Divergences: Uniform: 7.343482767058103 Unigram: 4.422674048600191
2022-03-15 01:11:19 | INFO | fairseq.trainer | begin training epoch 184
2022-03-15 01:11:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:13:35 | INFO | train_inner | epoch 184:     86 / 103 loss=3.694, ppl=12.94, wps=40268.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=18900, lr=0.000230022, gnorm=0.967, loss_scale=16, train_wall=153, gb_free=20.8, wall=30758
2022-03-15 01:14:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:14:05 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 9.059 | ppl 533.42 | wps 66703.3 | wpb 2040.3 | bsz 4 | num_updates 18917 | best_loss 7.309
2022-03-15 01:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 18917 updates
2022-03-15 01:14:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:14:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 184 @ 18917 updates, score 9.059) (writing took 0.9491291213780642 seconds)
2022-03-15 01:14:06 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-15 01:14:06 | INFO | train | epoch 184 | loss 3.694 | ppl 12.95 | wps 40302 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 18917 | lr 0.000229918 | gnorm 0.965 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30789
KL Stats: Epoch 184 Divergences: Uniform: 7.348392800699047 Unigram: 4.42513949859664
2022-03-15 01:14:06 | INFO | fairseq.trainer | begin training epoch 185
2022-03-15 01:14:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:16:17 | INFO | train_inner | epoch 185:     83 / 103 loss=3.689, ppl=12.89, wps=40268.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19000, lr=0.000229416, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=30920
2022-03-15 01:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:16:52 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 9.054 | ppl 531.62 | wps 66342.9 | wpb 2040.3 | bsz 4 | num_updates 19020 | best_loss 7.309
2022-03-15 01:16:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 19020 updates
2022-03-15 01:16:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:16:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:16:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 185 @ 19020 updates, score 9.054) (writing took 0.9397875554859638 seconds)
2022-03-15 01:16:53 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-15 01:16:53 | INFO | train | epoch 185 | loss 3.69 | ppl 12.91 | wps 40275.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19020 | lr 0.000229295 | gnorm 0.98 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 30956
KL Stats: Epoch 185 Divergences: Uniform: 7.354957840959129 Unigram: 4.42991392241545
2022-03-15 01:16:53 | INFO | fairseq.trainer | begin training epoch 186
2022-03-15 01:16:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:18:59 | INFO | train_inner | epoch 186:     80 / 103 loss=3.687, ppl=12.88, wps=40198.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=19100, lr=0.000228814, gnorm=0.978, loss_scale=16, train_wall=153, gb_free=20.8, wall=31083
2022-03-15 01:19:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:19:39 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 9.057 | ppl 532.58 | wps 66338.5 | wpb 2040.3 | bsz 4 | num_updates 19123 | best_loss 7.309
2022-03-15 01:19:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 19123 updates
2022-03-15 01:19:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:19:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 186 @ 19123 updates, score 9.057) (writing took 0.9881376307457685 seconds)
2022-03-15 01:19:40 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-15 01:19:40 | INFO | train | epoch 186 | loss 3.687 | ppl 12.88 | wps 40229.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19123 | lr 0.000228677 | gnorm 0.979 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31123
KL Stats: Epoch 186 Divergences: Uniform: 7.353778687168807 Unigram: 4.431696852501283
2022-03-15 01:19:40 | INFO | fairseq.trainer | begin training epoch 187
2022-03-15 01:19:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:21:42 | INFO | train_inner | epoch 187:     77 / 103 loss=3.682, ppl=12.84, wps=40206.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19200, lr=0.000228218, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=31245
2022-03-15 01:22:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:22:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:22:26 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 9.062 | ppl 534.46 | wps 66339.5 | wpb 2040.3 | bsz 4 | num_updates 19225 | best_loss 7.309
2022-03-15 01:22:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 19225 updates
2022-03-15 01:22:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:22:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:22:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 187 @ 19225 updates, score 9.062) (writing took 0.9430678924545646 seconds)
2022-03-15 01:22:27 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-15 01:22:27 | INFO | train | epoch 187 | loss 3.683 | ppl 12.84 | wps 39859.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19225 | lr 0.000228069 | gnorm 0.988 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31291
KL Stats: Epoch 187 Divergences: Uniform: 7.3595529711303485 Unigram: 4.434837150994624
2022-03-15 01:22:27 | INFO | fairseq.trainer | begin training epoch 188
2022-03-15 01:22:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:24:26 | INFO | train_inner | epoch 188:     75 / 103 loss=3.682, ppl=12.84, wps=39804.5, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=19300, lr=0.000227626, gnorm=0.98, loss_scale=16, train_wall=155, gb_free=20.8, wall=31409
2022-03-15 01:25:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:25:13 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 9.059 | ppl 533.29 | wps 66063.1 | wpb 2040.3 | bsz 4 | num_updates 19328 | best_loss 7.309
2022-03-15 01:25:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 19328 updates
2022-03-15 01:25:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:25:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:25:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 188 @ 19328 updates, score 9.059) (writing took 0.947443850338459 seconds)
2022-03-15 01:25:14 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-15 01:25:14 | INFO | train | epoch 188 | loss 3.681 | ppl 12.82 | wps 40211.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19328 | lr 0.000227461 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31458
KL Stats: Epoch 188 Divergences: Uniform: 7.360789134371759 Unigram: 4.437436946309108
2022-03-15 01:25:14 | INFO | fairseq.trainer | begin training epoch 189
2022-03-15 01:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:27:08 | INFO | train_inner | epoch 189:     72 / 103 loss=3.674, ppl=12.76, wps=40177.7, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19400, lr=0.000227038, gnorm=0.968, loss_scale=16, train_wall=153, gb_free=20.8, wall=31572
2022-03-15 01:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:28:01 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 9.059 | ppl 533.47 | wps 66417 | wpb 2040.3 | bsz 4 | num_updates 19431 | best_loss 7.309
2022-03-15 01:28:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 19431 updates
2022-03-15 01:28:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:28:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:28:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 189 @ 19431 updates, score 9.059) (writing took 0.9184411903843284 seconds)
2022-03-15 01:28:01 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-15 01:28:01 | INFO | train | epoch 189 | loss 3.677 | ppl 12.79 | wps 40240.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19431 | lr 0.000226857 | gnorm 0.975 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31625
KL Stats: Epoch 189 Divergences: Uniform: 7.363745406200974 Unigram: 4.439600324683349
2022-03-15 01:28:01 | INFO | fairseq.trainer | begin training epoch 190
2022-03-15 01:28:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:29:51 | INFO | train_inner | epoch 190:     69 / 103 loss=3.675, ppl=12.77, wps=40250.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19500, lr=0.000226455, gnorm=0.984, loss_scale=16, train_wall=153, gb_free=20.8, wall=31734
2022-03-15 01:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:30:48 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 9.076 | ppl 539.75 | wps 66373.5 | wpb 2040.3 | bsz 4 | num_updates 19534 | best_loss 7.309
2022-03-15 01:30:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 19534 updates
2022-03-15 01:30:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:30:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 190 @ 19534 updates, score 9.076) (writing took 0.9748852206394076 seconds)
2022-03-15 01:30:49 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-15 01:30:49 | INFO | train | epoch 190 | loss 3.673 | ppl 12.76 | wps 40267.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19534 | lr 0.000226258 | gnorm 0.986 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 31792
KL Stats: Epoch 190 Divergences: Uniform: 7.369867869184578 Unigram: 4.442698435837752
2022-03-15 01:30:49 | INFO | fairseq.trainer | begin training epoch 191
2022-03-15 01:30:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:32:33 | INFO | train_inner | epoch 191:     66 / 103 loss=3.67, ppl=12.73, wps=40197.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19600, lr=0.000225877, gnorm=0.973, loss_scale=16, train_wall=153, gb_free=20.8, wall=31897
2022-03-15 01:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:33:35 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 9.071 | ppl 537.87 | wps 65848.2 | wpb 2040.3 | bsz 4 | num_updates 19637 | best_loss 7.309
2022-03-15 01:33:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 19637 updates
2022-03-15 01:33:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:33:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:33:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 191 @ 19637 updates, score 9.071) (writing took 0.9636143427342176 seconds)
2022-03-15 01:33:36 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-15 01:33:36 | INFO | train | epoch 191 | loss 3.669 | ppl 12.72 | wps 40228.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19637 | lr 0.000225664 | gnorm 0.971 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 31959
KL Stats: Epoch 191 Divergences: Uniform: 7.369933493622264 Unigram: 4.445876004161883
2022-03-15 01:33:36 | INFO | fairseq.trainer | begin training epoch 192
2022-03-15 01:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:35:15 | INFO | train_inner | epoch 192:     63 / 103 loss=3.667, ppl=12.7, wps=40239.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=19700, lr=0.000225303, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=32059
2022-03-15 01:36:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:36:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:36:22 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 9.082 | ppl 541.78 | wps 66764.5 | wpb 2040.3 | bsz 4 | num_updates 19739 | best_loss 7.309
2022-03-15 01:36:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 19739 updates
2022-03-15 01:36:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:36:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:36:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 192 @ 19739 updates, score 9.082) (writing took 0.9609965812414885 seconds)
2022-03-15 01:36:23 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-15 01:36:23 | INFO | train | epoch 192 | loss 3.667 | ppl 12.7 | wps 39910.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 19739 | lr 0.00022508 | gnorm 0.997 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32126
KL Stats: Epoch 192 Divergences: Uniform: 7.372012350286531 Unigram: 4.448715858487533
2022-03-15 01:36:23 | INFO | fairseq.trainer | begin training epoch 193
2022-03-15 01:36:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:37:59 | INFO | train_inner | epoch 193:     61 / 103 loss=3.664, ppl=12.67, wps=39885.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=19800, lr=0.000224733, gnorm=0.979, loss_scale=16, train_wall=154, gb_free=20.8, wall=32223
2022-03-15 01:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:39:09 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 9.099 | ppl 548.47 | wps 66332.6 | wpb 2040.3 | bsz 4 | num_updates 19842 | best_loss 7.309
2022-03-15 01:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 19842 updates
2022-03-15 01:39:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:39:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:39:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 193 @ 19842 updates, score 9.099) (writing took 0.9368019104003906 seconds)
2022-03-15 01:39:10 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-15 01:39:10 | INFO | train | epoch 193 | loss 3.662 | ppl 12.66 | wps 40246.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19842 | lr 0.000224495 | gnorm 0.98 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32293
KL Stats: Epoch 193 Divergences: Uniform: 7.375192591003216 Unigram: 4.452087646111183
2022-03-15 01:39:10 | INFO | fairseq.trainer | begin training epoch 194
2022-03-15 01:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:40:42 | INFO | train_inner | epoch 194:     58 / 103 loss=3.661, ppl=12.65, wps=40213.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=19900, lr=0.000224168, gnorm=0.99, loss_scale=16, train_wall=153, gb_free=20.8, wall=32385
2022-03-15 01:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:41:56 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 9.071 | ppl 537.93 | wps 66363.1 | wpb 2040.3 | bsz 4 | num_updates 19945 | best_loss 7.309
2022-03-15 01:41:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 19945 updates
2022-03-15 01:41:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:41:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 194 @ 19945 updates, score 9.071) (writing took 0.9905243692919612 seconds)
2022-03-15 01:41:57 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-15 01:41:57 | INFO | train | epoch 194 | loss 3.659 | ppl 12.64 | wps 40269 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 19945 | lr 0.000223915 | gnorm 0.991 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32460
KL Stats: Epoch 194 Divergences: Uniform: 7.377691257135883 Unigram: 4.454439940177242
2022-03-15 01:41:57 | INFO | fairseq.trainer | begin training epoch 195
2022-03-15 01:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:43:24 | INFO | train_inner | epoch 195:     55 / 103 loss=3.655, ppl=12.6, wps=40236, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20000, lr=0.000223607, gnorm=0.985, loss_scale=16, train_wall=153, gb_free=20.8, wall=32547
2022-03-15 01:44:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:44:43 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 9.078 | ppl 540.37 | wps 66413.7 | wpb 2040.3 | bsz 4 | num_updates 20048 | best_loss 7.309
2022-03-15 01:44:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 20048 updates
2022-03-15 01:44:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:44:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:44:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 195 @ 20048 updates, score 9.078) (writing took 0.9833255112171173 seconds)
2022-03-15 01:44:44 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-15 01:44:44 | INFO | train | epoch 195 | loss 3.656 | ppl 12.61 | wps 40292.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20048 | lr 0.000223339 | gnorm 0.982 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32627
KL Stats: Epoch 195 Divergences: Uniform: 7.381410141945236 Unigram: 4.457591941190932
2022-03-15 01:44:44 | INFO | fairseq.trainer | begin training epoch 196
2022-03-15 01:44:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:46:06 | INFO | train_inner | epoch 196:     52 / 103 loss=3.656, ppl=12.61, wps=40250.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20100, lr=0.00022305, gnorm=0.99, loss_scale=16, train_wall=153, gb_free=20.8, wall=32710
2022-03-15 01:47:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:47:30 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 9.123 | ppl 557.66 | wps 66715.6 | wpb 2040.3 | bsz 4 | num_updates 20151 | best_loss 7.309
2022-03-15 01:47:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 20151 updates
2022-03-15 01:47:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:47:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:47:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 196 @ 20151 updates, score 9.123) (writing took 0.9626690512523055 seconds)
2022-03-15 01:47:31 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-15 01:47:31 | INFO | train | epoch 196 | loss 3.652 | ppl 12.57 | wps 40304.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20151 | lr 0.000222767 | gnorm 0.983 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 32794
KL Stats: Epoch 196 Divergences: Uniform: 7.386381976628137 Unigram: 4.461567568103809
2022-03-15 01:47:31 | INFO | fairseq.trainer | begin training epoch 197
2022-03-15 01:47:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:48:49 | INFO | train_inner | epoch 197:     49 / 103 loss=3.648, ppl=12.54, wps=40209.8, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=20200, lr=0.000222497, gnorm=0.979, loss_scale=16, train_wall=153, gb_free=20.8, wall=32872
2022-03-15 01:50:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 01:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:50:17 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 9.106 | ppl 551.22 | wps 66225.3 | wpb 2040.3 | bsz 4 | num_updates 20253 | best_loss 7.309
2022-03-15 01:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 20253 updates
2022-03-15 01:50:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:50:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:50:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 197 @ 20253 updates, score 9.106) (writing took 0.9360228003934026 seconds)
2022-03-15 01:50:18 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-15 01:50:18 | INFO | train | epoch 197 | loss 3.649 | ppl 12.55 | wps 39778.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20253 | lr 0.000222206 | gnorm 0.985 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 32962
KL Stats: Epoch 197 Divergences: Uniform: 7.388369171125742 Unigram: 4.463795557474555
2022-03-15 01:50:18 | INFO | fairseq.trainer | begin training epoch 198
2022-03-15 01:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:51:33 | INFO | train_inner | epoch 198:     47 / 103 loss=3.647, ppl=12.53, wps=39811.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=20300, lr=0.000221948, gnorm=0.983, loss_scale=16, train_wall=155, gb_free=20.8, wall=33036
2022-03-15 01:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:53:04 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 9.094 | ppl 546.47 | wps 65662.8 | wpb 2040.3 | bsz 4 | num_updates 20356 | best_loss 7.309
2022-03-15 01:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 20356 updates
2022-03-15 01:53:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:53:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:53:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 198 @ 20356 updates, score 9.094) (writing took 0.9509932296350598 seconds)
2022-03-15 01:53:05 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-15 01:53:05 | INFO | train | epoch 198 | loss 3.646 | ppl 12.52 | wps 40287.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20356 | lr 0.000221643 | gnorm 0.982 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33129
KL Stats: Epoch 198 Divergences: Uniform: 7.390690501256215 Unigram: 4.4653200278610115
2022-03-15 01:53:05 | INFO | fairseq.trainer | begin training epoch 199
2022-03-15 01:53:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:54:15 | INFO | train_inner | epoch 199:     44 / 103 loss=3.647, ppl=12.53, wps=40253, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20400, lr=0.000221404, gnorm=0.981, loss_scale=16, train_wall=153, gb_free=20.8, wall=33198
2022-03-15 01:55:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:55:51 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 9.103 | ppl 549.83 | wps 66397.3 | wpb 2040.3 | bsz 4 | num_updates 20459 | best_loss 7.309
2022-03-15 01:55:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 20459 updates
2022-03-15 01:55:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:55:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:55:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 199 @ 20459 updates, score 9.103) (writing took 0.9660121984779835 seconds)
2022-03-15 01:55:52 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-15 01:55:52 | INFO | train | epoch 199 | loss 3.643 | ppl 12.49 | wps 40291 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20459 | lr 0.000221084 | gnorm 0.99 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33296
KL Stats: Epoch 199 Divergences: Uniform: 7.393693294854846 Unigram: 4.46826029079896
2022-03-15 01:55:52 | INFO | fairseq.trainer | begin training epoch 200
2022-03-15 01:55:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:56:57 | INFO | train_inner | epoch 200:     41 / 103 loss=3.643, ppl=12.49, wps=40255, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=20500, lr=0.000220863, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=33361
2022-03-15 01:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 01:58:39 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 9.114 | ppl 554.18 | wps 66360.3 | wpb 2040.3 | bsz 4 | num_updates 20562 | best_loss 7.309
2022-03-15 01:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 20562 updates
2022-03-15 01:58:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:58:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 01:58:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 200 @ 20562 updates, score 9.114) (writing took 0.9209790527820587 seconds)
2022-03-15 01:58:39 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-15 01:58:39 | INFO | train | epoch 200 | loss 3.639 | ppl 12.46 | wps 40206.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20562 | lr 0.00022053 | gnorm 0.981 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33463
KL Stats: Epoch 200 Divergences: Uniform: 7.398384521585389 Unigram: 4.471104331260308
2022-03-15 01:58:40 | INFO | fairseq.trainer | begin training epoch 201
2022-03-15 01:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 01:59:40 | INFO | train_inner | epoch 201:     38 / 103 loss=3.636, ppl=12.43, wps=40161.9, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=20600, lr=0.000220326, gnorm=0.975, loss_scale=16, train_wall=153, gb_free=20.8, wall=33523
2022-03-15 02:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:01:26 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 9.109 | ppl 552.2 | wps 66076.1 | wpb 2040.3 | bsz 4 | num_updates 20665 | best_loss 7.309
2022-03-15 02:01:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 20665 updates
2022-03-15 02:01:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 201 @ 20665 updates, score 9.109) (writing took 0.9398317709565163 seconds)
2022-03-15 02:01:26 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-15 02:01:26 | INFO | train | epoch 201 | loss 3.638 | ppl 12.45 | wps 40286.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20665 | lr 0.00021998 | gnorm 0.985 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 33630
KL Stats: Epoch 201 Divergences: Uniform: 7.396775198736889 Unigram: 4.47167858784582
2022-03-15 02:01:26 | INFO | fairseq.trainer | begin training epoch 202
2022-03-15 02:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:02:22 | INFO | train_inner | epoch 202:     35 / 103 loss=3.639, ppl=12.46, wps=40274.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20700, lr=0.000219793, gnorm=0.993, loss_scale=16, train_wall=153, gb_free=20.8, wall=33685
2022-03-15 02:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:04:12 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 9.118 | ppl 555.65 | wps 66167.4 | wpb 2040.3 | bsz 4 | num_updates 20768 | best_loss 7.309
2022-03-15 02:04:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 20768 updates
2022-03-15 02:04:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:04:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:04:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 202 @ 20768 updates, score 9.118) (writing took 0.989619835279882 seconds)
2022-03-15 02:04:13 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-15 02:04:13 | INFO | train | epoch 202 | loss 3.633 | ppl 12.41 | wps 40304 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20768 | lr 0.000219433 | gnorm 0.983 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 33797
KL Stats: Epoch 202 Divergences: Uniform: 7.40167850159073 Unigram: 4.476873781120746
2022-03-15 02:04:13 | INFO | fairseq.trainer | begin training epoch 203
2022-03-15 02:04:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:05:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:05:06 | INFO | train_inner | epoch 203:     33 / 103 loss=3.632, ppl=12.39, wps=39755.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=20800, lr=0.000219265, gnorm=0.983, loss_scale=16, train_wall=155, gb_free=20.8, wall=33850
2022-03-15 02:06:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:07:00 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 9.108 | ppl 551.75 | wps 66196 | wpb 2040.3 | bsz 4 | num_updates 20870 | best_loss 7.309
2022-03-15 02:07:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 20870 updates
2022-03-15 02:07:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:07:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:07:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 203 @ 20870 updates, score 9.108) (writing took 0.9039413006976247 seconds)
2022-03-15 02:07:01 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-15 02:07:01 | INFO | train | epoch 203 | loss 3.63 | ppl 12.38 | wps 39794.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 20870 | lr 0.000218896 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 33964
KL Stats: Epoch 203 Divergences: Uniform: 7.407185717460293 Unigram: 4.479077036900747
2022-03-15 02:07:01 | INFO | fairseq.trainer | begin training epoch 204
2022-03-15 02:07:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:07:48 | INFO | train_inner | epoch 204:     30 / 103 loss=3.632, ppl=12.4, wps=40265.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=20900, lr=0.000218739, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=34012
2022-03-15 02:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:09:47 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 9.129 | ppl 559.82 | wps 66316.1 | wpb 2040.3 | bsz 4 | num_updates 20973 | best_loss 7.309
2022-03-15 02:09:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 20973 updates
2022-03-15 02:09:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:09:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 204 @ 20973 updates, score 9.129) (writing took 0.9969177404418588 seconds)
2022-03-15 02:09:48 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-15 02:09:48 | INFO | train | epoch 204 | loss 3.627 | ppl 12.36 | wps 40246 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 20973 | lr 0.000218358 | gnorm 0.999 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34131
KL Stats: Epoch 204 Divergences: Uniform: 7.406470481925871 Unigram: 4.481181399635464
2022-03-15 02:09:48 | INFO | fairseq.trainer | begin training epoch 205
2022-03-15 02:09:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:10:31 | INFO | train_inner | epoch 205:     27 / 103 loss=3.625, ppl=12.34, wps=40214.4, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21000, lr=0.000218218, gnorm=1, loss_scale=16, train_wall=153, gb_free=20.8, wall=34174
2022-03-15 02:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:12:34 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 9.133 | ppl 561.42 | wps 66326.7 | wpb 2040.3 | bsz 4 | num_updates 21076 | best_loss 7.309
2022-03-15 02:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 21076 updates
2022-03-15 02:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:12:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:12:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 205 @ 21076 updates, score 9.133) (writing took 0.9800892425701022 seconds)
2022-03-15 02:12:35 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-15 02:12:35 | INFO | train | epoch 205 | loss 3.624 | ppl 12.33 | wps 40281.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21076 | lr 0.000217824 | gnorm 0.987 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34298
KL Stats: Epoch 205 Divergences: Uniform: 7.410137554616251 Unigram: 4.483505007570918
2022-03-15 02:12:35 | INFO | fairseq.trainer | begin training epoch 206
2022-03-15 02:12:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:13:13 | INFO | train_inner | epoch 206:     24 / 103 loss=3.626, ppl=12.34, wps=40215.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=21100, lr=0.0002177, gnorm=0.979, loss_scale=16, train_wall=153, gb_free=20.8, wall=34337
2022-03-15 02:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:15:21 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 9.145 | ppl 566.21 | wps 66736.9 | wpb 2040.3 | bsz 4 | num_updates 21179 | best_loss 7.309
2022-03-15 02:15:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 21179 updates
2022-03-15 02:15:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:15:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:15:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 206 @ 21179 updates, score 9.145) (writing took 0.951535427942872 seconds)
2022-03-15 02:15:22 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-15 02:15:22 | INFO | train | epoch 206 | loss 3.623 | ppl 12.32 | wps 40217.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21179 | lr 0.000217294 | gnorm 0.983 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34466
KL Stats: Epoch 206 Divergences: Uniform: 7.409050022586824 Unigram: 4.48516331048694
2022-03-15 02:15:22 | INFO | fairseq.trainer | begin training epoch 207
2022-03-15 02:15:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:15:56 | INFO | train_inner | epoch 207:     21 / 103 loss=3.623, ppl=12.32, wps=40208.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=21200, lr=0.000217186, gnorm=0.989, loss_scale=16, train_wall=153, gb_free=20.8, wall=34499
2022-03-15 02:18:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:18:08 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 9.128 | ppl 559.42 | wps 66047.4 | wpb 2040.3 | bsz 4 | num_updates 21282 | best_loss 7.309
2022-03-15 02:18:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 21282 updates
2022-03-15 02:18:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:18:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:18:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 207 @ 21282 updates, score 9.128) (writing took 0.9216295080259442 seconds)
2022-03-15 02:18:09 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-15 02:18:09 | INFO | train | epoch 207 | loss 3.618 | ppl 12.28 | wps 40279.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21282 | lr 0.000216767 | gnorm 0.979 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34633
KL Stats: Epoch 207 Divergences: Uniform: 7.413752729886593 Unigram: 4.488806521326972
2022-03-15 02:18:09 | INFO | fairseq.trainer | begin training epoch 208
2022-03-15 02:18:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:18:38 | INFO | train_inner | epoch 208:     18 / 103 loss=3.618, ppl=12.28, wps=40241.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21300, lr=0.000216676, gnorm=0.982, loss_scale=16, train_wall=153, gb_free=20.8, wall=34661
2022-03-15 02:19:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:20:55 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 9.134 | ppl 562 | wps 66069.3 | wpb 2040.3 | bsz 4 | num_updates 21384 | best_loss 7.309
2022-03-15 02:20:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 21384 updates
2022-03-15 02:20:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:20:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:20:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 208 @ 21384 updates, score 9.134) (writing took 0.9714002711698413 seconds)
2022-03-15 02:20:56 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-15 02:20:56 | INFO | train | epoch 208 | loss 3.615 | ppl 12.25 | wps 39836.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21384 | lr 0.00021625 | gnorm 0.994 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 34800
KL Stats: Epoch 208 Divergences: Uniform: 7.413842099166258 Unigram: 4.49064753463313
2022-03-15 02:20:56 | INFO | fairseq.trainer | begin training epoch 209
2022-03-15 02:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:21:22 | INFO | train_inner | epoch 209:     16 / 103 loss=3.617, ppl=12.27, wps=39810.6, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21400, lr=0.000216169, gnorm=0.991, loss_scale=16, train_wall=155, gb_free=20.8, wall=34825
2022-03-15 02:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:23:42 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 9.15 | ppl 568.23 | wps 65933.8 | wpb 2040.3 | bsz 4 | num_updates 21487 | best_loss 7.309
2022-03-15 02:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 21487 updates
2022-03-15 02:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:23:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:23:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 209 @ 21487 updates, score 9.15) (writing took 0.9868868319317698 seconds)
2022-03-15 02:23:43 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-15 02:23:43 | INFO | train | epoch 209 | loss 3.613 | ppl 12.23 | wps 40281.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21487 | lr 0.000215731 | gnorm 0.995 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 34967
KL Stats: Epoch 209 Divergences: Uniform: 7.4178783496717795 Unigram: 4.492685313924528
2022-03-15 02:23:43 | INFO | fairseq.trainer | begin training epoch 210
2022-03-15 02:23:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:24:04 | INFO | train_inner | epoch 210:     13 / 103 loss=3.613, ppl=12.23, wps=40248.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21500, lr=0.000215666, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=34988
2022-03-15 02:26:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:26:30 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 9.146 | ppl 566.45 | wps 65960.2 | wpb 2040.3 | bsz 4 | num_updates 21590 | best_loss 7.309
2022-03-15 02:26:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 21590 updates
2022-03-15 02:26:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:26:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:26:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 210 @ 21590 updates, score 9.146) (writing took 0.9329513516277075 seconds)
2022-03-15 02:26:31 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-15 02:26:31 | INFO | train | epoch 210 | loss 3.608 | ppl 12.19 | wps 40245 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21590 | lr 0.000215216 | gnorm 0.988 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 35134
KL Stats: Epoch 210 Divergences: Uniform: 7.422638780398157 Unigram: 4.496861531691501
2022-03-15 02:26:31 | INFO | fairseq.trainer | begin training epoch 211
2022-03-15 02:26:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:26:47 | INFO | train_inner | epoch 211:     10 / 103 loss=3.609, ppl=12.2, wps=40209.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21600, lr=0.000215166, gnorm=0.986, loss_scale=16, train_wall=153, gb_free=20.8, wall=35150
2022-03-15 02:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:29:17 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 9.144 | ppl 565.81 | wps 66357.7 | wpb 2040.3 | bsz 4 | num_updates 21693 | best_loss 7.309
2022-03-15 02:29:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 21693 updates
2022-03-15 02:29:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:29:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:29:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 211 @ 21693 updates, score 9.144) (writing took 0.9351555109024048 seconds)
2022-03-15 02:29:18 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-15 02:29:18 | INFO | train | epoch 211 | loss 3.606 | ppl 12.18 | wps 40285.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21693 | lr 0.000214704 | gnorm 0.985 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35301
KL Stats: Epoch 211 Divergences: Uniform: 7.422840129070837 Unigram: 4.498589770396697
2022-03-15 02:29:18 | INFO | fairseq.trainer | begin training epoch 212
2022-03-15 02:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:29:29 | INFO | train_inner | epoch 212:      7 / 103 loss=3.61, ppl=12.21, wps=40249.7, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21700, lr=0.000214669, gnorm=0.988, loss_scale=16, train_wall=153, gb_free=20.8, wall=35312
2022-03-15 02:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:32:04 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 9.157 | ppl 571.02 | wps 66292.6 | wpb 2040.3 | bsz 4 | num_updates 21796 | best_loss 7.309
2022-03-15 02:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 21796 updates
2022-03-15 02:32:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:32:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:32:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 212 @ 21796 updates, score 9.157) (writing took 0.9705021446570754 seconds)
2022-03-15 02:32:05 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-15 02:32:05 | INFO | train | epoch 212 | loss 3.605 | ppl 12.16 | wps 40291.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 21796 | lr 0.000214196 | gnorm 0.991 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35468
KL Stats: Epoch 212 Divergences: Uniform: 7.42503293631225 Unigram: 4.500294200354264
2022-03-15 02:32:05 | INFO | fairseq.trainer | begin training epoch 213
2022-03-15 02:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:32:11 | INFO | train_inner | epoch 213:      4 / 103 loss=3.605, ppl=12.17, wps=40259.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=21800, lr=0.000214176, gnorm=0.99, loss_scale=16, train_wall=153, gb_free=20.8, wall=35474
2022-03-15 02:33:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:34:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:34:51 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 9.158 | ppl 571.28 | wps 66511.6 | wpb 2040.3 | bsz 4 | num_updates 21898 | best_loss 7.309
2022-03-15 02:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 21898 updates
2022-03-15 02:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:34:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:34:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 213 @ 21898 updates, score 9.158) (writing took 0.9711392810568213 seconds)
2022-03-15 02:34:52 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-15 02:34:52 | INFO | train | epoch 213 | loss 3.6 | ppl 12.13 | wps 39896.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 21898 | lr 0.000213697 | gnorm 0.992 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35635
KL Stats: Epoch 213 Divergences: Uniform: 7.427591490386031 Unigram: 4.504142421920232
2022-03-15 02:34:52 | INFO | fairseq.trainer | begin training epoch 214
2022-03-15 02:34:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:34:55 | INFO | train_inner | epoch 214:      2 / 103 loss=3.602, ppl=12.14, wps=39866.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=21900, lr=0.000213687, gnorm=0.994, loss_scale=16, train_wall=154, gb_free=20.8, wall=35638
2022-03-15 02:37:33 | INFO | train_inner | epoch 214:    102 / 103 loss=3.599, ppl=12.12, wps=41416.9, ups=0.63, wpb=65530.9, bsz=128, num_updates=22000, lr=0.000213201, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=35797
2022-03-15 02:37:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:37:38 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 9.156 | ppl 570.3 | wps 66139.7 | wpb 2040.3 | bsz 4 | num_updates 22001 | best_loss 7.309
2022-03-15 02:37:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 22001 updates
2022-03-15 02:37:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:37:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:37:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 214 @ 22001 updates, score 9.156) (writing took 0.9805365595966578 seconds)
2022-03-15 02:37:39 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-15 02:37:39 | INFO | train | epoch 214 | loss 3.599 | ppl 12.12 | wps 40260.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22001 | lr 0.000213196 | gnorm 0.999 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35802
KL Stats: Epoch 214 Divergences: Uniform: 7.426769572261854 Unigram: 4.504786969528956
2022-03-15 02:37:39 | INFO | fairseq.trainer | begin training epoch 215
2022-03-15 02:37:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:40:15 | INFO | train_inner | epoch 215:     99 / 103 loss=3.593, ppl=12.07, wps=40255.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22100, lr=0.000212718, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=35959
2022-03-15 02:40:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:40:25 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 9.155 | ppl 569.91 | wps 65996.3 | wpb 2040.3 | bsz 4 | num_updates 22104 | best_loss 7.309
2022-03-15 02:40:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 22104 updates
2022-03-15 02:40:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:40:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 215 @ 22104 updates, score 9.155) (writing took 0.9601480597630143 seconds)
2022-03-15 02:40:26 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-15 02:40:26 | INFO | train | epoch 215 | loss 3.594 | ppl 12.08 | wps 40292.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22104 | lr 0.000212699 | gnorm 0.998 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 35969
KL Stats: Epoch 215 Divergences: Uniform: 7.433245426892094 Unigram: 4.507789581792676
2022-03-15 02:40:26 | INFO | fairseq.trainer | begin training epoch 216
2022-03-15 02:40:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:42:57 | INFO | train_inner | epoch 216:     96 / 103 loss=3.591, ppl=12.05, wps=40257.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22200, lr=0.000212238, gnorm=0.995, loss_scale=16, train_wall=153, gb_free=20.8, wall=36121
2022-03-15 02:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:43:12 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 9.174 | ppl 577.72 | wps 66700.8 | wpb 2040.3 | bsz 4 | num_updates 22207 | best_loss 7.309
2022-03-15 02:43:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 22207 updates
2022-03-15 02:43:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:43:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:43:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 216 @ 22207 updates, score 9.174) (writing took 0.9310245849192142 seconds)
2022-03-15 02:43:12 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-15 02:43:12 | INFO | train | epoch 216 | loss 3.593 | ppl 12.06 | wps 40306.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22207 | lr 0.000212205 | gnorm 0.997 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 36136
KL Stats: Epoch 216 Divergences: Uniform: 7.435169103383228 Unigram: 4.510521925350637
2022-03-15 02:43:12 | INFO | fairseq.trainer | begin training epoch 217
2022-03-15 02:43:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:45:40 | INFO | train_inner | epoch 217:     93 / 103 loss=3.588, ppl=12.03, wps=40275.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22300, lr=0.000211762, gnorm=0.997, loss_scale=16, train_wall=153, gb_free=20.8, wall=36283
2022-03-15 02:45:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:45:58 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 9.165 | ppl 574.1 | wps 66316.3 | wpb 2040.3 | bsz 4 | num_updates 22310 | best_loss 7.309
2022-03-15 02:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 22310 updates
2022-03-15 02:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 217 @ 22310 updates, score 9.165) (writing took 0.927780388854444 seconds)
2022-03-15 02:45:59 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-15 02:45:59 | INFO | train | epoch 217 | loss 3.589 | ppl 12.04 | wps 40297.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22310 | lr 0.000211714 | gnorm 0.993 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 36303
KL Stats: Epoch 217 Divergences: Uniform: 7.4352122589874545 Unigram: 4.512314760180772
2022-03-15 02:45:59 | INFO | fairseq.trainer | begin training epoch 218
2022-03-15 02:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:47:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 02:48:24 | INFO | train_inner | epoch 218:     91 / 103 loss=3.584, ppl=11.99, wps=39756.2, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=22400, lr=0.000211289, gnorm=0.995, loss_scale=16, train_wall=155, gb_free=20.8, wall=36447
2022-03-15 02:48:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:48:46 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 9.185 | ppl 581.95 | wps 66554.6 | wpb 2040.3 | bsz 4 | num_updates 22412 | best_loss 7.309
2022-03-15 02:48:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 22412 updates
2022-03-15 02:48:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:48:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:48:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 218 @ 22412 updates, score 9.185) (writing took 0.9899117527529597 seconds)
2022-03-15 02:48:47 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-15 02:48:47 | INFO | train | epoch 218 | loss 3.586 | ppl 12.01 | wps 39778.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22412 | lr 0.000211232 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36470
KL Stats: Epoch 218 Divergences: Uniform: 7.439147633127799 Unigram: 4.515506575185615
2022-03-15 02:48:47 | INFO | fairseq.trainer | begin training epoch 219
2022-03-15 02:48:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:51:06 | INFO | train_inner | epoch 219:     88 / 103 loss=3.585, ppl=12, wps=40231, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=22500, lr=0.000210819, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=36610
2022-03-15 02:51:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:51:33 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 9.173 | ppl 577.12 | wps 66050.2 | wpb 2040.3 | bsz 4 | num_updates 22515 | best_loss 7.309
2022-03-15 02:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 22515 updates
2022-03-15 02:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:51:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:51:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 219 @ 22515 updates, score 9.173) (writing took 0.9634995404630899 seconds)
2022-03-15 02:51:34 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-15 02:51:34 | INFO | train | epoch 219 | loss 3.584 | ppl 12 | wps 40260.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22515 | lr 0.000210748 | gnorm 0.998 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 36637
KL Stats: Epoch 219 Divergences: Uniform: 7.43901491842098 Unigram: 4.515403589162374
2022-03-15 02:51:34 | INFO | fairseq.trainer | begin training epoch 220
2022-03-15 02:51:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:53:49 | INFO | train_inner | epoch 220:     85 / 103 loss=3.578, ppl=11.94, wps=40231, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=22600, lr=0.000210352, gnorm=0.982, loss_scale=16, train_wall=153, gb_free=20.8, wall=36772
2022-03-15 02:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:54:20 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 9.2 | ppl 588.03 | wps 66255.1 | wpb 2040.3 | bsz 4 | num_updates 22618 | best_loss 7.309
2022-03-15 02:54:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 22618 updates
2022-03-15 02:54:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:54:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:54:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 220 @ 22618 updates, score 9.2) (writing took 0.9350972408428788 seconds)
2022-03-15 02:54:21 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-15 02:54:21 | INFO | train | epoch 220 | loss 3.58 | ppl 11.96 | wps 40274.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22618 | lr 0.000210268 | gnorm 0.981 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 36805
KL Stats: Epoch 220 Divergences: Uniform: 7.44246628394062 Unigram: 4.519338433608364
2022-03-15 02:54:21 | INFO | fairseq.trainer | begin training epoch 221
2022-03-15 02:54:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:56:31 | INFO | train_inner | epoch 221:     82 / 103 loss=3.579, ppl=11.95, wps=40235.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22700, lr=0.000209888, gnorm=0.983, loss_scale=16, train_wall=153, gb_free=20.8, wall=36934
2022-03-15 02:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:57:07 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 9.186 | ppl 582.26 | wps 66259.7 | wpb 2040.3 | bsz 4 | num_updates 22721 | best_loss 7.309
2022-03-15 02:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 22721 updates
2022-03-15 02:57:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:57:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:57:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 221 @ 22721 updates, score 9.186) (writing took 0.9555629184469581 seconds)
2022-03-15 02:57:08 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-15 02:57:08 | INFO | train | epoch 221 | loss 3.579 | ppl 11.95 | wps 40265.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22721 | lr 0.000209791 | gnorm 0.986 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 36972
KL Stats: Epoch 221 Divergences: Uniform: 7.446098463444992 Unigram: 4.521274354379814
2022-03-15 02:57:08 | INFO | fairseq.trainer | begin training epoch 222
2022-03-15 02:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 02:59:13 | INFO | train_inner | epoch 222:     79 / 103 loss=3.576, ppl=11.93, wps=40241.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=22800, lr=0.000209427, gnorm=1.004, loss_scale=16, train_wall=153, gb_free=20.8, wall=37097
2022-03-15 02:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 02:59:54 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 9.172 | ppl 576.91 | wps 66419.1 | wpb 2040.3 | bsz 4 | num_updates 22824 | best_loss 7.309
2022-03-15 02:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 22824 updates
2022-03-15 02:59:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:59:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 02:59:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 222 @ 22824 updates, score 9.172) (writing took 0.9867057176306844 seconds)
2022-03-15 02:59:55 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-15 02:59:55 | INFO | train | epoch 222 | loss 3.577 | ppl 11.93 | wps 40255.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 22824 | lr 0.000209317 | gnorm 1.001 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37139
KL Stats: Epoch 222 Divergences: Uniform: 7.445500905077964 Unigram: 4.521593487968599
2022-03-15 02:59:55 | INFO | fairseq.trainer | begin training epoch 223
2022-03-15 02:59:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:01:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:01:57 | INFO | train_inner | epoch 223:     77 / 103 loss=3.572, ppl=11.9, wps=39785.2, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=22900, lr=0.000208969, gnorm=0.987, loss_scale=16, train_wall=155, gb_free=20.8, wall=37261
2022-03-15 03:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:02:41 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 9.187 | ppl 582.96 | wps 66098.1 | wpb 2040.3 | bsz 4 | num_updates 22926 | best_loss 7.309
2022-03-15 03:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 22926 updates
2022-03-15 03:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:02:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 223 @ 22926 updates, score 9.187) (writing took 0.9823552258312702 seconds)
2022-03-15 03:02:42 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-15 03:02:42 | INFO | train | epoch 223 | loss 3.573 | ppl 11.9 | wps 39823.6 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 22926 | lr 0.000208851 | gnorm 0.99 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37306
KL Stats: Epoch 223 Divergences: Uniform: 7.4489299461305825 Unigram: 4.524959901414754
2022-03-15 03:02:42 | INFO | fairseq.trainer | begin training epoch 224
2022-03-15 03:02:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:04:40 | INFO | train_inner | epoch 224:     74 / 103 loss=3.571, ppl=11.88, wps=40209.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23000, lr=0.000208514, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=37423
2022-03-15 03:05:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:05:29 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 9.204 | ppl 589.7 | wps 66430.5 | wpb 2040.3 | bsz 4 | num_updates 23029 | best_loss 7.309
2022-03-15 03:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 23029 updates
2022-03-15 03:05:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:05:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:05:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 224 @ 23029 updates, score 9.204) (writing took 0.9842637376859784 seconds)
2022-03-15 03:05:30 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-15 03:05:30 | INFO | train | epoch 224 | loss 3.57 | ppl 11.88 | wps 40256.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23029 | lr 0.000208383 | gnorm 0.998 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37473
KL Stats: Epoch 224 Divergences: Uniform: 7.453832972317156 Unigram: 4.529685424013408
2022-03-15 03:05:30 | INFO | fairseq.trainer | begin training epoch 225
2022-03-15 03:05:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:07:22 | INFO | train_inner | epoch 225:     71 / 103 loss=3.568, ppl=11.86, wps=40235.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23100, lr=0.000208063, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=37585
2022-03-15 03:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:08:16 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 9.206 | ppl 590.74 | wps 66425.4 | wpb 2040.3 | bsz 4 | num_updates 23132 | best_loss 7.309
2022-03-15 03:08:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 23132 updates
2022-03-15 03:08:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 225 @ 23132 updates, score 9.206) (writing took 0.9467225382104516 seconds)
2022-03-15 03:08:17 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-15 03:08:17 | INFO | train | epoch 225 | loss 3.567 | ppl 11.85 | wps 40274.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23132 | lr 0.000207919 | gnorm 0.992 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37640
KL Stats: Epoch 225 Divergences: Uniform: 7.455896517440387 Unigram: 4.5300526528816185
2022-03-15 03:08:17 | INFO | fairseq.trainer | begin training epoch 226
2022-03-15 03:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:10:04 | INFO | train_inner | epoch 226:     68 / 103 loss=3.563, ppl=11.82, wps=40187.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23200, lr=0.000207614, gnorm=0.987, loss_scale=16, train_wall=153, gb_free=20.8, wall=37748
2022-03-15 03:10:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:11:03 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 9.184 | ppl 581.47 | wps 66342.3 | wpb 2040.3 | bsz 4 | num_updates 23235 | best_loss 7.309
2022-03-15 03:11:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 23235 updates
2022-03-15 03:11:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:11:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:11:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 226 @ 23235 updates, score 9.184) (writing took 0.9640428125858307 seconds)
2022-03-15 03:11:04 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-15 03:11:04 | INFO | train | epoch 226 | loss 3.566 | ppl 11.84 | wps 40216.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23235 | lr 0.000207457 | gnorm 0.995 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 37807
KL Stats: Epoch 226 Divergences: Uniform: 7.454986943914506 Unigram: 4.53282326315641
2022-03-15 03:11:04 | INFO | fairseq.trainer | begin training epoch 227
2022-03-15 03:11:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:12:47 | INFO | train_inner | epoch 227:     65 / 103 loss=3.565, ppl=11.83, wps=40259.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23300, lr=0.000207168, gnorm=1.004, loss_scale=16, train_wall=153, gb_free=20.8, wall=37910
2022-03-15 03:13:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:13:50 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 9.211 | ppl 592.59 | wps 66292.3 | wpb 2040.3 | bsz 4 | num_updates 23338 | best_loss 7.309
2022-03-15 03:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 23338 updates
2022-03-15 03:13:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:13:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:13:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 227 @ 23338 updates, score 9.211) (writing took 0.946615569293499 seconds)
2022-03-15 03:13:51 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-15 03:13:51 | INFO | train | epoch 227 | loss 3.563 | ppl 11.82 | wps 40311.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23338 | lr 0.000206999 | gnorm 0.997 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 37974
KL Stats: Epoch 227 Divergences: Uniform: 7.456673660643094 Unigram: 4.5338743976566365
2022-03-15 03:13:51 | INFO | fairseq.trainer | begin training epoch 228
2022-03-15 03:13:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:15:29 | INFO | train_inner | epoch 228:     62 / 103 loss=3.559, ppl=11.79, wps=40286.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23400, lr=0.000206725, gnorm=0.988, loss_scale=32, train_wall=153, gb_free=20.8, wall=38072
2022-03-15 03:15:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:16:37 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 9.208 | ppl 591.54 | wps 66184.3 | wpb 2040.3 | bsz 4 | num_updates 23440 | best_loss 7.309
2022-03-15 03:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 23440 updates
2022-03-15 03:16:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:16:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:16:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 228 @ 23440 updates, score 9.208) (writing took 1.017498499713838 seconds)
2022-03-15 03:16:38 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-15 03:16:38 | INFO | train | epoch 228 | loss 3.559 | ppl 11.79 | wps 39904.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23440 | lr 0.000206548 | gnorm 0.989 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38141
KL Stats: Epoch 228 Divergences: Uniform: 7.460712661546747 Unigram: 4.537048191619121
2022-03-15 03:16:38 | INFO | fairseq.trainer | begin training epoch 229
2022-03-15 03:16:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:18:13 | INFO | train_inner | epoch 229:     60 / 103 loss=3.559, ppl=11.78, wps=39863.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=23500, lr=0.000206284, gnorm=0.986, loss_scale=16, train_wall=154, gb_free=20.8, wall=38236
2022-03-15 03:19:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:19:24 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 9.212 | ppl 592.99 | wps 65884.3 | wpb 2040.3 | bsz 4 | num_updates 23543 | best_loss 7.309
2022-03-15 03:19:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 23543 updates
2022-03-15 03:19:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:19:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:19:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 229 @ 23543 updates, score 9.212) (writing took 0.9630374265834689 seconds)
2022-03-15 03:19:25 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-15 03:19:25 | INFO | train | epoch 229 | loss 3.558 | ppl 11.78 | wps 40298 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23543 | lr 0.000206096 | gnorm 0.994 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38308
KL Stats: Epoch 229 Divergences: Uniform: 7.459159768859706 Unigram: 4.537186126596746
2022-03-15 03:19:25 | INFO | fairseq.trainer | begin training epoch 230
2022-03-15 03:19:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:20:55 | INFO | train_inner | epoch 230:     57 / 103 loss=3.556, ppl=11.77, wps=40225.6, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=23600, lr=0.000205847, gnorm=1.011, loss_scale=16, train_wall=153, gb_free=20.8, wall=38398
2022-03-15 03:22:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:22:11 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 9.208 | ppl 591.59 | wps 66092.8 | wpb 2040.3 | bsz 4 | num_updates 23646 | best_loss 7.309
2022-03-15 03:22:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 23646 updates
2022-03-15 03:22:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:22:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:22:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 230 @ 23646 updates, score 9.208) (writing took 1.0168828191235662 seconds)
2022-03-15 03:22:12 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-15 03:22:12 | INFO | train | epoch 230 | loss 3.555 | ppl 11.75 | wps 40229.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23646 | lr 0.000205646 | gnorm 1.008 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 38475
KL Stats: Epoch 230 Divergences: Uniform: 7.463268357052791 Unigram: 4.540108211078202
2022-03-15 03:22:12 | INFO | fairseq.trainer | begin training epoch 231
2022-03-15 03:22:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:23:37 | INFO | train_inner | epoch 231:     54 / 103 loss=3.552, ppl=11.73, wps=40238.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23700, lr=0.000205412, gnorm=1.003, loss_scale=16, train_wall=153, gb_free=20.8, wall=38561
2022-03-15 03:24:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:24:58 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 9.213 | ppl 593.41 | wps 66428.6 | wpb 2040.3 | bsz 4 | num_updates 23749 | best_loss 7.309
2022-03-15 03:24:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 23749 updates
2022-03-15 03:24:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:24:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:24:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 231 @ 23749 updates, score 9.213) (writing took 0.9840069403871894 seconds)
2022-03-15 03:24:59 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-15 03:24:59 | INFO | train | epoch 231 | loss 3.553 | ppl 11.73 | wps 40297.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23749 | lr 0.0002052 | gnorm 1.004 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38642
KL Stats: Epoch 231 Divergences: Uniform: 7.466806067592653 Unigram: 4.543388479147908
2022-03-15 03:24:59 | INFO | fairseq.trainer | begin training epoch 232
2022-03-15 03:24:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:26:20 | INFO | train_inner | epoch 232:     51 / 103 loss=3.553, ppl=11.74, wps=40253.1, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=23800, lr=0.00020498, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=38723
2022-03-15 03:27:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:27:45 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 9.231 | ppl 601.11 | wps 65829.3 | wpb 2040.3 | bsz 4 | num_updates 23852 | best_loss 7.309
2022-03-15 03:27:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 23852 updates
2022-03-15 03:27:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:27:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:27:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 232 @ 23852 updates, score 9.231) (writing took 0.9998294562101364 seconds)
2022-03-15 03:27:46 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-15 03:27:46 | INFO | train | epoch 232 | loss 3.55 | ppl 11.72 | wps 40279.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 23852 | lr 0.000204756 | gnorm 0.994 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38809
KL Stats: Epoch 232 Divergences: Uniform: 7.465396408720813 Unigram: 4.545191838908783
2022-03-15 03:27:46 | INFO | fairseq.trainer | begin training epoch 233
2022-03-15 03:27:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:29:02 | INFO | train_inner | epoch 233:     48 / 103 loss=3.55, ppl=11.71, wps=40231.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=23900, lr=0.000204551, gnorm=0.999, loss_scale=16, train_wall=153, gb_free=20.8, wall=38885
2022-03-15 03:29:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:30:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:30:32 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 9.207 | ppl 590.9 | wps 66295 | wpb 2040.3 | bsz 4 | num_updates 23954 | best_loss 7.309
2022-03-15 03:30:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 23954 updates
2022-03-15 03:30:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:30:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 233 @ 23954 updates, score 9.207) (writing took 0.9874353557825089 seconds)
2022-03-15 03:30:33 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-15 03:30:33 | INFO | train | epoch 233 | loss 3.547 | ppl 11.69 | wps 39880.1 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 23954 | lr 0.00020432 | gnorm 1.001 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 38976
KL Stats: Epoch 233 Divergences: Uniform: 7.467223946422985 Unigram: 4.546223634198642
2022-03-15 03:30:33 | INFO | fairseq.trainer | begin training epoch 234
2022-03-15 03:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:31:46 | INFO | train_inner | epoch 234:     46 / 103 loss=3.544, ppl=11.66, wps=39872.1, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=24000, lr=0.000204124, gnorm=0.995, loss_scale=16, train_wall=154, gb_free=20.8, wall=39049
2022-03-15 03:33:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:33:19 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 9.239 | ppl 604.36 | wps 66482.7 | wpb 2040.3 | bsz 4 | num_updates 24057 | best_loss 7.309
2022-03-15 03:33:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 24057 updates
2022-03-15 03:33:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 234 @ 24057 updates, score 9.239) (writing took 0.9518076442182064 seconds)
2022-03-15 03:33:20 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-15 03:33:20 | INFO | train | epoch 234 | loss 3.546 | ppl 11.68 | wps 40301.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24057 | lr 0.000203882 | gnorm 0.996 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39143
KL Stats: Epoch 234 Divergences: Uniform: 7.469829943040663 Unigram: 4.548837646871597
2022-03-15 03:33:20 | INFO | fairseq.trainer | begin training epoch 235
2022-03-15 03:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:34:28 | INFO | train_inner | epoch 235:     43 / 103 loss=3.546, ppl=11.68, wps=40246.2, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24100, lr=0.0002037, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=39211
2022-03-15 03:36:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:36:06 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 9.23 | ppl 600.54 | wps 66085.3 | wpb 2040.3 | bsz 4 | num_updates 24160 | best_loss 7.309
2022-03-15 03:36:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 24160 updates
2022-03-15 03:36:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 235 @ 24160 updates, score 9.23) (writing took 0.9623062256723642 seconds)
2022-03-15 03:36:07 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-15 03:36:07 | INFO | train | epoch 235 | loss 3.544 | ppl 11.66 | wps 40274.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24160 | lr 0.000203447 | gnorm 1.007 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39310
KL Stats: Epoch 235 Divergences: Uniform: 7.469066438748583 Unigram: 4.549923146757496
2022-03-15 03:36:07 | INFO | fairseq.trainer | begin training epoch 236
2022-03-15 03:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:37:10 | INFO | train_inner | epoch 236:     40 / 103 loss=3.542, ppl=11.65, wps=40213.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24200, lr=0.000203279, gnorm=1.003, loss_scale=16, train_wall=153, gb_free=20.8, wall=39374
2022-03-15 03:38:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:38:53 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 9.231 | ppl 600.72 | wps 66253.8 | wpb 2040.3 | bsz 4 | num_updates 24263 | best_loss 7.309
2022-03-15 03:38:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 24263 updates
2022-03-15 03:38:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:38:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:38:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 236 @ 24263 updates, score 9.231) (writing took 0.9483467396348715 seconds)
2022-03-15 03:38:54 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-15 03:38:54 | INFO | train | epoch 236 | loss 3.542 | ppl 11.65 | wps 40245.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24263 | lr 0.000203015 | gnorm 1.013 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39477
KL Stats: Epoch 236 Divergences: Uniform: 7.472821241338799 Unigram: 4.551239670826785
2022-03-15 03:38:54 | INFO | fairseq.trainer | begin training epoch 237
2022-03-15 03:38:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:39:53 | INFO | train_inner | epoch 237:     37 / 103 loss=3.541, ppl=11.64, wps=40237, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=24300, lr=0.00020286, gnorm=1.014, loss_scale=16, train_wall=153, gb_free=20.8, wall=39536
2022-03-15 03:41:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:41:40 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 9.236 | ppl 602.9 | wps 65996.1 | wpb 2040.3 | bsz 4 | num_updates 24366 | best_loss 7.309
2022-03-15 03:41:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 24366 updates
2022-03-15 03:41:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:41:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:41:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 237 @ 24366 updates, score 9.236) (writing took 0.9501805985346437 seconds)
2022-03-15 03:41:41 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-15 03:41:41 | INFO | train | epoch 237 | loss 3.539 | ppl 11.62 | wps 40213 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24366 | lr 0.000202585 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39645
KL Stats: Epoch 237 Divergences: Uniform: 7.473915260738641 Unigram: 4.554143227580366
2022-03-15 03:41:41 | INFO | fairseq.trainer | begin training epoch 238
2022-03-15 03:41:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:42:35 | INFO | train_inner | epoch 238:     34 / 103 loss=3.541, ppl=11.64, wps=40190.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=24400, lr=0.000202444, gnorm=0.999, loss_scale=16, train_wall=153, gb_free=20.8, wall=39699
2022-03-15 03:44:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:44:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:44:27 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 9.239 | ppl 604.35 | wps 66063.5 | wpb 2040.3 | bsz 4 | num_updates 24468 | best_loss 7.309
2022-03-15 03:44:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 24468 updates
2022-03-15 03:44:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 238 @ 24468 updates, score 9.239) (writing took 0.9511593133211136 seconds)
2022-03-15 03:44:28 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-15 03:44:28 | INFO | train | epoch 238 | loss 3.535 | ppl 11.59 | wps 39885.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24468 | lr 0.000202163 | gnorm 0.992 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 39812
KL Stats: Epoch 238 Divergences: Uniform: 7.477029006890665 Unigram: 4.558107984500056
2022-03-15 03:44:28 | INFO | fairseq.trainer | begin training epoch 239
2022-03-15 03:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:45:19 | INFO | train_inner | epoch 239:     32 / 103 loss=3.533, ppl=11.57, wps=39826.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=24500, lr=0.000202031, gnorm=0.998, loss_scale=16, train_wall=155, gb_free=20.8, wall=39863
2022-03-15 03:47:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:47:14 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 9.23 | ppl 600.3 | wps 66200.4 | wpb 2040.3 | bsz 4 | num_updates 24571 | best_loss 7.309
2022-03-15 03:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 24571 updates
2022-03-15 03:47:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:47:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 239 @ 24571 updates, score 9.23) (writing took 0.970927756279707 seconds)
2022-03-15 03:47:15 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-15 03:47:15 | INFO | train | epoch 239 | loss 3.533 | ppl 11.58 | wps 40256.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24571 | lr 0.000201738 | gnorm 1.011 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 39979
KL Stats: Epoch 239 Divergences: Uniform: 7.478017845308136 Unigram: 4.558288527078688
2022-03-15 03:47:15 | INFO | fairseq.trainer | begin training epoch 240
2022-03-15 03:47:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:48:01 | INFO | train_inner | epoch 240:     29 / 103 loss=3.535, ppl=11.59, wps=40247.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24600, lr=0.000201619, gnorm=1.005, loss_scale=16, train_wall=153, gb_free=20.8, wall=40025
2022-03-15 03:49:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:50:02 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 9.241 | ppl 604.97 | wps 66739.4 | wpb 2040.3 | bsz 4 | num_updates 24674 | best_loss 7.309
2022-03-15 03:50:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 24674 updates
2022-03-15 03:50:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:50:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:50:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 240 @ 24674 updates, score 9.241) (writing took 0.9599734451621771 seconds)
2022-03-15 03:50:03 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-15 03:50:03 | INFO | train | epoch 240 | loss 3.53 | ppl 11.55 | wps 40240.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24674 | lr 0.000201317 | gnorm 0.992 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40146
KL Stats: Epoch 240 Divergences: Uniform: 7.482250216569301 Unigram: 4.5614540112724455
2022-03-15 03:50:03 | INFO | fairseq.trainer | begin training epoch 241
2022-03-15 03:50:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:50:44 | INFO | train_inner | epoch 241:     26 / 103 loss=3.532, ppl=11.57, wps=40193, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24700, lr=0.000201211, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=40187
2022-03-15 03:52:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:52:49 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 9.233 | ppl 601.56 | wps 66211.3 | wpb 2040.3 | bsz 4 | num_updates 24777 | best_loss 7.309
2022-03-15 03:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 24777 updates
2022-03-15 03:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:52:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:52:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 241 @ 24777 updates, score 9.233) (writing took 0.899703374132514 seconds)
2022-03-15 03:52:50 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-15 03:52:50 | INFO | train | epoch 241 | loss 3.53 | ppl 11.55 | wps 40223.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24777 | lr 0.000200898 | gnorm 1.003 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40313
KL Stats: Epoch 241 Divergences: Uniform: 7.479694729265197 Unigram: 4.560597535905351
2022-03-15 03:52:50 | INFO | fairseq.trainer | begin training epoch 242
2022-03-15 03:52:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:53:26 | INFO | train_inner | epoch 242:     23 / 103 loss=3.529, ppl=11.54, wps=40204.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24800, lr=0.000200805, gnorm=1.005, loss_scale=16, train_wall=153, gb_free=20.8, wall=40350
2022-03-15 03:55:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:55:36 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 9.25 | ppl 608.81 | wps 66200.4 | wpb 2040.3 | bsz 4 | num_updates 24880 | best_loss 7.309
2022-03-15 03:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 24880 updates
2022-03-15 03:55:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:55:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:55:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 242 @ 24880 updates, score 9.25) (writing took 0.9858808536082506 seconds)
2022-03-15 03:55:37 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-15 03:55:37 | INFO | train | epoch 242 | loss 3.527 | ppl 11.53 | wps 40262.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 24880 | lr 0.000200482 | gnorm 1.002 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 40480
KL Stats: Epoch 242 Divergences: Uniform: 7.482201287149287 Unigram: 4.563252252829167
2022-03-15 03:55:37 | INFO | fairseq.trainer | begin training epoch 243
2022-03-15 03:55:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:56:09 | INFO | train_inner | epoch 243:     20 / 103 loss=3.53, ppl=11.55, wps=40229.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=24900, lr=0.000200401, gnorm=0.998, loss_scale=16, train_wall=153, gb_free=20.8, wall=40512
2022-03-15 03:57:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 03:58:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 03:58:23 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 9.225 | ppl 598.36 | wps 66366.3 | wpb 2040.3 | bsz 4 | num_updates 24982 | best_loss 7.309
2022-03-15 03:58:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 24982 updates
2022-03-15 03:58:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:58:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 03:58:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 243 @ 24982 updates, score 9.225) (writing took 0.975864889100194 seconds)
2022-03-15 03:58:24 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-15 03:58:24 | INFO | train | epoch 243 | loss 3.524 | ppl 11.5 | wps 39838 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 24982 | lr 0.000200072 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40648
KL Stats: Epoch 243 Divergences: Uniform: 7.48357159852017 Unigram: 4.564767887259985
2022-03-15 03:58:24 | INFO | fairseq.trainer | begin training epoch 244
2022-03-15 03:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 03:58:53 | INFO | train_inner | epoch 244:     18 / 103 loss=3.523, ppl=11.49, wps=39796.7, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=25000, lr=0.0002, gnorm=1.011, loss_scale=16, train_wall=155, gb_free=20.8, wall=40676
2022-03-15 04:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:01:10 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 9.239 | ppl 604.06 | wps 66191.7 | wpb 2040.3 | bsz 4 | num_updates 25085 | best_loss 7.309
2022-03-15 04:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 25085 updates
2022-03-15 04:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:01:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:01:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 244 @ 25085 updates, score 9.239) (writing took 0.9109309297055006 seconds)
2022-03-15 04:01:11 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-15 04:01:11 | INFO | train | epoch 244 | loss 3.521 | ppl 11.48 | wps 40207 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25085 | lr 0.000199661 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40815
KL Stats: Epoch 244 Divergences: Uniform: 7.487966020899075 Unigram: 4.567460655192761
2022-03-15 04:01:11 | INFO | fairseq.trainer | begin training epoch 245
2022-03-15 04:01:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:01:35 | INFO | train_inner | epoch 245:     15 / 103 loss=3.522, ppl=11.49, wps=40178.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25100, lr=0.000199601, gnorm=0.994, loss_scale=16, train_wall=153, gb_free=20.8, wall=40839
2022-03-15 04:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:03:58 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 9.24 | ppl 604.85 | wps 65884.7 | wpb 2040.3 | bsz 4 | num_updates 25188 | best_loss 7.309
2022-03-15 04:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 25188 updates
2022-03-15 04:03:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:03:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:03:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 245 @ 25188 updates, score 9.24) (writing took 0.9507612697780132 seconds)
2022-03-15 04:03:59 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-15 04:03:59 | INFO | train | epoch 245 | loss 3.52 | ppl 11.47 | wps 40171.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25188 | lr 0.000199252 | gnorm 1.001 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 40982
KL Stats: Epoch 245 Divergences: Uniform: 7.487167383371446 Unigram: 4.567798479184722
2022-03-15 04:03:59 | INFO | fairseq.trainer | begin training epoch 246
2022-03-15 04:03:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:04:18 | INFO | train_inner | epoch 246:     12 / 103 loss=3.523, ppl=11.49, wps=40135.7, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=25200, lr=0.000199205, gnorm=1.004, loss_scale=16, train_wall=153, gb_free=20.8, wall=41001
2022-03-15 04:06:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:06:45 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 9.263 | ppl 614.21 | wps 66136.3 | wpb 2040.3 | bsz 4 | num_updates 25291 | best_loss 7.309
2022-03-15 04:06:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 25291 updates
2022-03-15 04:06:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:06:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:06:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 246 @ 25291 updates, score 9.263) (writing took 0.9120647348463535 seconds)
2022-03-15 04:06:46 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-15 04:06:46 | INFO | train | epoch 246 | loss 3.517 | ppl 11.45 | wps 40287.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25291 | lr 0.000198846 | gnorm 0.999 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41149
KL Stats: Epoch 246 Divergences: Uniform: 7.490264406025344 Unigram: 4.571375495627243
2022-03-15 04:06:46 | INFO | fairseq.trainer | begin training epoch 247
2022-03-15 04:06:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:07:00 | INFO | train_inner | epoch 247:      9 / 103 loss=3.519, ppl=11.47, wps=40253.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25300, lr=0.000198811, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=41164
2022-03-15 04:09:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:09:32 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 9.243 | ppl 605.98 | wps 66057 | wpb 2040.3 | bsz 4 | num_updates 25394 | best_loss 7.309
2022-03-15 04:09:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 25394 updates
2022-03-15 04:09:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 247 @ 25394 updates, score 9.243) (writing took 0.9455314353108406 seconds)
2022-03-15 04:09:33 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-15 04:09:33 | INFO | train | epoch 247 | loss 3.516 | ppl 11.44 | wps 40257.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25394 | lr 0.000198442 | gnorm 0.998 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41316
KL Stats: Epoch 247 Divergences: Uniform: 7.489030722407305 Unigram: 4.572133092750474
2022-03-15 04:09:33 | INFO | fairseq.trainer | begin training epoch 248
2022-03-15 04:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:09:43 | INFO | train_inner | epoch 248:      6 / 103 loss=3.515, ppl=11.43, wps=40226.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25400, lr=0.000198419, gnorm=1, loss_scale=16, train_wall=153, gb_free=20.8, wall=41326
2022-03-15 04:12:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:12:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:12:19 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 9.259 | ppl 612.87 | wps 66423.6 | wpb 2040.3 | bsz 4 | num_updates 25496 | best_loss 7.309
2022-03-15 04:12:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 25496 updates
2022-03-15 04:12:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:12:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:12:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 248 @ 25496 updates, score 9.259) (writing took 0.9308714149519801 seconds)
2022-03-15 04:12:20 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-15 04:12:20 | INFO | train | epoch 248 | loss 3.513 | ppl 11.41 | wps 39866.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 25496 | lr 0.000198045 | gnorm 1.008 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41484
KL Stats: Epoch 248 Divergences: Uniform: 7.491843893002745 Unigram: 4.5743057380752035
2022-03-15 04:12:20 | INFO | fairseq.trainer | begin training epoch 249
2022-03-15 04:12:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:12:26 | INFO | train_inner | epoch 249:      4 / 103 loss=3.515, ppl=11.43, wps=39833.5, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=25500, lr=0.00019803, gnorm=1.01, loss_scale=16, train_wall=154, gb_free=20.8, wall=41490
2022-03-15 04:15:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:15:06 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 9.26 | ppl 613.11 | wps 66117.9 | wpb 2040.3 | bsz 4 | num_updates 25599 | best_loss 7.309
2022-03-15 04:15:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 25599 updates
2022-03-15 04:15:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:15:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 249 @ 25599 updates, score 9.26) (writing took 0.9509009495377541 seconds)
2022-03-15 04:15:07 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-15 04:15:07 | INFO | train | epoch 249 | loss 3.511 | ppl 11.4 | wps 40268.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25599 | lr 0.000197646 | gnorm 1.009 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 41651
KL Stats: Epoch 249 Divergences: Uniform: 7.492965205516303 Unigram: 4.57552081462696
2022-03-15 04:15:07 | INFO | fairseq.trainer | begin training epoch 250
2022-03-15 04:15:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:15:09 | INFO | train_inner | epoch 250:      1 / 103 loss=3.512, ppl=11.41, wps=40235.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25600, lr=0.000197642, gnorm=1.008, loss_scale=16, train_wall=153, gb_free=20.8, wall=41652
2022-03-15 04:17:47 | INFO | train_inner | epoch 250:    101 / 103 loss=3.51, ppl=11.39, wps=41375.8, ups=0.63, wpb=65530.9, bsz=128, num_updates=25700, lr=0.000197257, gnorm=1.002, loss_scale=16, train_wall=154, gb_free=20.8, wall=41811
2022-03-15 04:17:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:17:53 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 9.267 | ppl 616.23 | wps 66386.9 | wpb 2040.3 | bsz 4 | num_updates 25702 | best_loss 7.309
2022-03-15 04:17:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 25702 updates
2022-03-15 04:17:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:17:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:17:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 250 @ 25702 updates, score 9.267) (writing took 0.9613844119012356 seconds)
2022-03-15 04:17:54 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-15 04:17:54 | INFO | train | epoch 250 | loss 3.509 | ppl 11.39 | wps 40231.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25702 | lr 0.00019725 | gnorm 1.003 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41818
KL Stats: Epoch 250 Divergences: Uniform: 7.4952730935739655 Unigram: 4.577093132526921
2022-03-15 04:17:54 | INFO | fairseq.trainer | begin training epoch 251
2022-03-15 04:17:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:20:30 | INFO | train_inner | epoch 251:     98 / 103 loss=3.506, ppl=11.36, wps=40225.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25800, lr=0.000196875, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=41973
2022-03-15 04:20:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:20:40 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 9.269 | ppl 617.02 | wps 65872.3 | wpb 2040.3 | bsz 4 | num_updates 25805 | best_loss 7.309
2022-03-15 04:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 25805 updates
2022-03-15 04:20:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:20:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:20:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 251 @ 25805 updates, score 9.269) (writing took 0.9521015407517552 seconds)
2022-03-15 04:20:41 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-15 04:20:41 | INFO | train | epoch 251 | loss 3.508 | ppl 11.37 | wps 40257.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25805 | lr 0.000196856 | gnorm 0.997 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 41985
KL Stats: Epoch 251 Divergences: Uniform: 7.495598115321247 Unigram: 4.579554983183232
2022-03-15 04:20:41 | INFO | fairseq.trainer | begin training epoch 252
2022-03-15 04:20:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:23:12 | INFO | train_inner | epoch 252:     95 / 103 loss=3.503, ppl=11.34, wps=40237.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=25900, lr=0.000196494, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=42135
2022-03-15 04:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:23:28 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 9.268 | ppl 616.65 | wps 65696.6 | wpb 2040.3 | bsz 4 | num_updates 25908 | best_loss 7.309
2022-03-15 04:23:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 25908 updates
2022-03-15 04:23:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:23:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 252 @ 25908 updates, score 9.268) (writing took 0.9736951105296612 seconds)
2022-03-15 04:23:29 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-15 04:23:29 | INFO | train | epoch 252 | loss 3.505 | ppl 11.35 | wps 40250.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 25908 | lr 0.000196464 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42152
KL Stats: Epoch 252 Divergences: Uniform: 7.497748575354376 Unigram: 4.581400672685315
2022-03-15 04:23:29 | INFO | fairseq.trainer | begin training epoch 253
2022-03-15 04:23:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:25:54 | INFO | train_inner | epoch 253:     92 / 103 loss=3.5, ppl=11.31, wps=40212.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26000, lr=0.000196116, gnorm=1.011, loss_scale=32, train_wall=153, gb_free=20.8, wall=42298
2022-03-15 04:26:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:26:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:26:15 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 9.266 | ppl 615.85 | wps 66274.8 | wpb 2040.3 | bsz 4 | num_updates 26010 | best_loss 7.309
2022-03-15 04:26:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 26010 updates
2022-03-15 04:26:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:26:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 253 @ 26010 updates, score 9.266) (writing took 0.998202140443027 seconds)
2022-03-15 04:26:16 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-15 04:26:16 | INFO | train | epoch 253 | loss 3.502 | ppl 11.33 | wps 39872.8 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26010 | lr 0.000196078 | gnorm 1.012 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42319
KL Stats: Epoch 253 Divergences: Uniform: 7.500061660182963 Unigram: 4.582552687829801
2022-03-15 04:26:16 | INFO | fairseq.trainer | begin training epoch 254
2022-03-15 04:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:28:38 | INFO | train_inner | epoch 254:     90 / 103 loss=3.498, ppl=11.3, wps=39838.1, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26100, lr=0.00019574, gnorm=1.008, loss_scale=16, train_wall=154, gb_free=20.8, wall=42462
2022-03-15 04:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:29:02 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 9.281 | ppl 622.11 | wps 65831.1 | wpb 2040.3 | bsz 4 | num_updates 26113 | best_loss 7.309
2022-03-15 04:29:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 26113 updates
2022-03-15 04:29:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:29:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 254 @ 26113 updates, score 9.281) (writing took 0.9299110257998109 seconds)
2022-03-15 04:29:03 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-15 04:29:03 | INFO | train | epoch 254 | loss 3.5 | ppl 11.31 | wps 40257.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26113 | lr 0.000195691 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42486
KL Stats: Epoch 254 Divergences: Uniform: 7.500905515692523 Unigram: 4.585324696733391
2022-03-15 04:29:03 | INFO | fairseq.trainer | begin training epoch 255
2022-03-15 04:29:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:31:20 | INFO | train_inner | epoch 255:     87 / 103 loss=3.5, ppl=11.32, wps=40235.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26200, lr=0.000195366, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=42624
2022-03-15 04:31:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:31:49 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 9.293 | ppl 627.18 | wps 66405.3 | wpb 2040.3 | bsz 4 | num_updates 26216 | best_loss 7.309
2022-03-15 04:31:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 26216 updates
2022-03-15 04:31:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 255 @ 26216 updates, score 9.293) (writing took 1.00776254106313 seconds)
2022-03-15 04:31:50 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-15 04:31:50 | INFO | train | epoch 255 | loss 3.497 | ppl 11.29 | wps 40262.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26216 | lr 0.000195307 | gnorm 1.008 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 42653
KL Stats: Epoch 255 Divergences: Uniform: 7.5036493300690115 Unigram: 4.587591875068577
2022-03-15 04:31:50 | INFO | fairseq.trainer | begin training epoch 256
2022-03-15 04:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:34:03 | INFO | train_inner | epoch 256:     84 / 103 loss=3.492, ppl=11.25, wps=40229.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26300, lr=0.000194994, gnorm=1.007, loss_scale=16, train_wall=153, gb_free=20.8, wall=42786
2022-03-15 04:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:34:36 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 9.298 | ppl 629.45 | wps 66556.9 | wpb 2040.3 | bsz 4 | num_updates 26319 | best_loss 7.309
2022-03-15 04:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 26319 updates
2022-03-15 04:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:34:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 256 @ 26319 updates, score 9.298) (writing took 0.9395831851288676 seconds)
2022-03-15 04:34:37 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-15 04:34:37 | INFO | train | epoch 256 | loss 3.496 | ppl 11.28 | wps 40235.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26319 | lr 0.000194924 | gnorm 1.008 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42821
KL Stats: Epoch 256 Divergences: Uniform: 7.502240205731801 Unigram: 4.587770396306612
2022-03-15 04:34:37 | INFO | fairseq.trainer | begin training epoch 257
2022-03-15 04:34:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:36:45 | INFO | train_inner | epoch 257:     81 / 103 loss=3.494, ppl=11.27, wps=40178.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=26400, lr=0.000194625, gnorm=1.008, loss_scale=16, train_wall=153, gb_free=20.8, wall=42949
2022-03-15 04:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:37:23 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 9.281 | ppl 622.02 | wps 66019.7 | wpb 2040.3 | bsz 4 | num_updates 26422 | best_loss 7.309
2022-03-15 04:37:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 26422 updates
2022-03-15 04:37:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:37:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 257 @ 26422 updates, score 9.281) (writing took 0.9689805693924427 seconds)
2022-03-15 04:37:24 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-15 04:37:24 | INFO | train | epoch 257 | loss 3.494 | ppl 11.27 | wps 40250.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26422 | lr 0.000194544 | gnorm 1.007 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 42988
KL Stats: Epoch 257 Divergences: Uniform: 7.505029994155081 Unigram: 4.591384035877201
2022-03-15 04:37:24 | INFO | fairseq.trainer | begin training epoch 258
2022-03-15 04:37:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:39:28 | INFO | train_inner | epoch 258:     78 / 103 loss=3.492, ppl=11.25, wps=40248.3, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=26500, lr=0.000194257, gnorm=1.013, loss_scale=16, train_wall=153, gb_free=20.8, wall=43111
2022-03-15 04:39:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:40:10 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 9.284 | ppl 623.21 | wps 65575.5 | wpb 2040.3 | bsz 4 | num_updates 26524 | best_loss 7.309
2022-03-15 04:40:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 26524 updates
2022-03-15 04:40:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:40:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 258 @ 26524 updates, score 9.284) (writing took 0.9335148027166724 seconds)
2022-03-15 04:40:11 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-15 04:40:11 | INFO | train | epoch 258 | loss 3.493 | ppl 11.26 | wps 39895.3 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 26524 | lr 0.000194169 | gnorm 1.018 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43155
KL Stats: Epoch 258 Divergences: Uniform: 7.505083540635496 Unigram: 4.590613337183928
2022-03-15 04:40:11 | INFO | fairseq.trainer | begin training epoch 259
2022-03-15 04:40:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:42:12 | INFO | train_inner | epoch 259:     76 / 103 loss=3.491, ppl=11.24, wps=39779.4, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=26600, lr=0.000193892, gnorm=1.008, loss_scale=16, train_wall=155, gb_free=20.8, wall=43275
2022-03-15 04:42:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:42:57 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 9.272 | ppl 618.42 | wps 66060.1 | wpb 2040.3 | bsz 4 | num_updates 26627 | best_loss 7.309
2022-03-15 04:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 26627 updates
2022-03-15 04:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 259 @ 26627 updates, score 9.272) (writing took 0.9162823297083378 seconds)
2022-03-15 04:42:58 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-15 04:42:58 | INFO | train | epoch 259 | loss 3.491 | ppl 11.24 | wps 40212 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26627 | lr 0.000193793 | gnorm 1.01 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43322
KL Stats: Epoch 259 Divergences: Uniform: 7.502086099398053 Unigram: 4.590444192118222
2022-03-15 04:42:58 | INFO | fairseq.trainer | begin training epoch 260
2022-03-15 04:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:44:54 | INFO | train_inner | epoch 260:     73 / 103 loss=3.486, ppl=11.2, wps=40221.3, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=26700, lr=0.000193528, gnorm=1.003, loss_scale=16, train_wall=153, gb_free=20.8, wall=43438
2022-03-15 04:45:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:45:45 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 9.287 | ppl 624.86 | wps 65827.3 | wpb 2040.3 | bsz 4 | num_updates 26730 | best_loss 7.309
2022-03-15 04:45:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 26730 updates
2022-03-15 04:45:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:45:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 260 @ 26730 updates, score 9.287) (writing took 0.9985335217788815 seconds)
2022-03-15 04:45:46 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-15 04:45:46 | INFO | train | epoch 260 | loss 3.487 | ppl 11.21 | wps 40227.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26730 | lr 0.00019342 | gnorm 0.996 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43489
KL Stats: Epoch 260 Divergences: Uniform: 7.508845020138459 Unigram: 4.595144428913977
2022-03-15 04:45:46 | INFO | fairseq.trainer | begin training epoch 261
2022-03-15 04:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:47:36 | INFO | train_inner | epoch 261:     70 / 103 loss=3.486, ppl=11.21, wps=40227.5, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=26800, lr=0.000193167, gnorm=1.007, loss_scale=16, train_wall=153, gb_free=20.8, wall=43600
2022-03-15 04:48:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:48:32 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 9.289 | ppl 625.76 | wps 66303.6 | wpb 2040.3 | bsz 4 | num_updates 26833 | best_loss 7.309
2022-03-15 04:48:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 26833 updates
2022-03-15 04:48:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:48:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:48:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 261 @ 26833 updates, score 9.289) (writing took 0.9351682793349028 seconds)
2022-03-15 04:48:33 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-15 04:48:33 | INFO | train | epoch 261 | loss 3.486 | ppl 11.2 | wps 40279.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26833 | lr 0.000193048 | gnorm 1.009 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 43656
KL Stats: Epoch 261 Divergences: Uniform: 7.510080338506499 Unigram: 4.596362297111418
2022-03-15 04:48:33 | INFO | fairseq.trainer | begin training epoch 262
2022-03-15 04:48:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:50:19 | INFO | train_inner | epoch 262:     67 / 103 loss=3.484, ppl=11.19, wps=40249.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=26900, lr=0.000192807, gnorm=1.008, loss_scale=16, train_wall=153, gb_free=20.8, wall=43762
2022-03-15 04:51:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:51:19 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 9.299 | ppl 629.93 | wps 66098.8 | wpb 2040.3 | bsz 4 | num_updates 26936 | best_loss 7.309
2022-03-15 04:51:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 26936 updates
2022-03-15 04:51:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:51:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 262 @ 26936 updates, score 9.299) (writing took 0.9823057586327195 seconds)
2022-03-15 04:51:20 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-15 04:51:20 | INFO | train | epoch 262 | loss 3.484 | ppl 11.19 | wps 40273.2 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 26936 | lr 0.000192679 | gnorm 1.015 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 43823
KL Stats: Epoch 262 Divergences: Uniform: 7.51127869148998 Unigram: 4.5976057525415905
2022-03-15 04:51:20 | INFO | fairseq.trainer | begin training epoch 263
2022-03-15 04:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:53:01 | INFO | train_inner | epoch 263:     64 / 103 loss=3.48, ppl=11.16, wps=40245.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27000, lr=0.00019245, gnorm=1.009, loss_scale=16, train_wall=153, gb_free=20.8, wall=43924
2022-03-15 04:54:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:54:06 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 9.287 | ppl 624.7 | wps 66352.5 | wpb 2040.3 | bsz 4 | num_updates 27039 | best_loss 7.309
2022-03-15 04:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 27039 updates
2022-03-15 04:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:54:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 263 @ 27039 updates, score 9.287) (writing took 0.9844969445839524 seconds)
2022-03-15 04:54:07 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-15 04:54:07 | INFO | train | epoch 263 | loss 3.48 | ppl 11.16 | wps 40276.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27039 | lr 0.000192311 | gnorm 1.004 | loss_scale 32 | train_wall 157 | gb_free 20.8 | wall 43990
KL Stats: Epoch 263 Divergences: Uniform: 7.512305883819367 Unigram: 4.599999503065182
2022-03-15 04:54:07 | INFO | fairseq.trainer | begin training epoch 264
2022-03-15 04:54:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:54:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 04:55:45 | INFO | train_inner | epoch 264:     62 / 103 loss=3.479, ppl=11.15, wps=39855.8, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27100, lr=0.000192095, gnorm=1.005, loss_scale=16, train_wall=154, gb_free=20.8, wall=44088
2022-03-15 04:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:56:53 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 9.308 | ppl 633.94 | wps 66561.7 | wpb 2040.3 | bsz 4 | num_updates 27141 | best_loss 7.309
2022-03-15 04:56:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 27141 updates
2022-03-15 04:56:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:56:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:56:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 264 @ 27141 updates, score 9.308) (writing took 0.9645629022270441 seconds)
2022-03-15 04:56:54 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-15 04:56:54 | INFO | train | epoch 264 | loss 3.478 | ppl 11.15 | wps 39885.4 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27141 | lr 0.00019195 | gnorm 0.998 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44157
KL Stats: Epoch 264 Divergences: Uniform: 7.515772294173919 Unigram: 4.6022115130072
2022-03-15 04:56:54 | INFO | fairseq.trainer | begin training epoch 265
2022-03-15 04:56:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 04:58:27 | INFO | train_inner | epoch 265:     59 / 103 loss=3.479, ppl=11.15, wps=40248.4, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27200, lr=0.000191741, gnorm=1.002, loss_scale=16, train_wall=153, gb_free=20.8, wall=44251
2022-03-15 04:59:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 04:59:40 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 9.31 | ppl 634.68 | wps 66512.5 | wpb 2040.3 | bsz 4 | num_updates 27244 | best_loss 7.309
2022-03-15 04:59:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 27244 updates
2022-03-15 04:59:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:59:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 04:59:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 265 @ 27244 updates, score 9.31) (writing took 1.0095652118325233 seconds)
2022-03-15 04:59:41 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-15 04:59:41 | INFO | train | epoch 265 | loss 3.478 | ppl 11.14 | wps 40281.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27244 | lr 0.000191586 | gnorm 1.005 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44324
KL Stats: Epoch 265 Divergences: Uniform: 7.515485936677294 Unigram: 4.602650011195204
2022-03-15 04:59:41 | INFO | fairseq.trainer | begin training epoch 266
2022-03-15 04:59:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:01:09 | INFO | train_inner | epoch 266:     56 / 103 loss=3.473, ppl=11.1, wps=40236.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27300, lr=0.00019139, gnorm=1.007, loss_scale=16, train_wall=153, gb_free=20.8, wall=44413
2022-03-15 05:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:02:27 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 9.311 | ppl 635.36 | wps 66236.2 | wpb 2040.3 | bsz 4 | num_updates 27347 | best_loss 7.309
2022-03-15 05:02:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 27347 updates
2022-03-15 05:02:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:02:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:02:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 266 @ 27347 updates, score 9.311) (writing took 0.9451673710718751 seconds)
2022-03-15 05:02:28 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-15 05:02:28 | INFO | train | epoch 266 | loss 3.476 | ppl 11.13 | wps 40280.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27347 | lr 0.000191225 | gnorm 1.013 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44491
KL Stats: Epoch 266 Divergences: Uniform: 7.51847771900285 Unigram: 4.60457714308093
2022-03-15 05:02:28 | INFO | fairseq.trainer | begin training epoch 267
2022-03-15 05:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:03:52 | INFO | train_inner | epoch 267:     53 / 103 loss=3.48, ppl=11.16, wps=40250.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27400, lr=0.00019104, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=44575
2022-03-15 05:05:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:05:14 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 9.314 | ppl 636.31 | wps 65873.9 | wpb 2040.3 | bsz 4 | num_updates 27450 | best_loss 7.309
2022-03-15 05:05:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 27450 updates
2022-03-15 05:05:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:05:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:05:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 267 @ 27450 updates, score 9.314) (writing took 0.9109433405101299 seconds)
2022-03-15 05:05:15 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-15 05:05:15 | INFO | train | epoch 267 | loss 3.474 | ppl 11.11 | wps 40226.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27450 | lr 0.000190866 | gnorm 1.005 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44658
KL Stats: Epoch 267 Divergences: Uniform: 7.519013971579167 Unigram: 4.605798656074998
2022-03-15 05:05:15 | INFO | fairseq.trainer | begin training epoch 268
2022-03-15 05:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:06:34 | INFO | train_inner | epoch 268:     50 / 103 loss=3.47, ppl=11.08, wps=40192.9, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=27500, lr=0.000190693, gnorm=1.013, loss_scale=16, train_wall=153, gb_free=20.8, wall=44738
2022-03-15 05:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:07:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:08:01 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 9.318 | ppl 638.41 | wps 66151.6 | wpb 2040.3 | bsz 4 | num_updates 27552 | best_loss 7.309
2022-03-15 05:08:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 27552 updates
2022-03-15 05:08:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 268 @ 27552 updates, score 9.318) (writing took 0.895780136808753 seconds)
2022-03-15 05:08:02 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-15 05:08:02 | INFO | train | epoch 268 | loss 3.471 | ppl 11.08 | wps 39900 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 27552 | lr 0.000190512 | gnorm 1.017 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 44825
KL Stats: Epoch 268 Divergences: Uniform: 7.521474491580965 Unigram: 4.608623209872988
2022-03-15 05:08:02 | INFO | fairseq.trainer | begin training epoch 269
2022-03-15 05:08:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:09:18 | INFO | train_inner | epoch 269:     48 / 103 loss=3.469, ppl=11.08, wps=39828.2, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27600, lr=0.000190347, gnorm=1.005, loss_scale=16, train_wall=155, gb_free=20.8, wall=44902
2022-03-15 05:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:10:48 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 9.317 | ppl 637.67 | wps 66730.5 | wpb 2040.3 | bsz 4 | num_updates 27655 | best_loss 7.309
2022-03-15 05:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 27655 updates
2022-03-15 05:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:10:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 269 @ 27655 updates, score 9.317) (writing took 0.9775456879287958 seconds)
2022-03-15 05:10:49 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-15 05:10:49 | INFO | train | epoch 269 | loss 3.469 | ppl 11.07 | wps 40222 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27655 | lr 0.000190157 | gnorm 1.002 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 44993
KL Stats: Epoch 269 Divergences: Uniform: 7.520389619457585 Unigram: 4.6092353806771005
2022-03-15 05:10:49 | INFO | fairseq.trainer | begin training epoch 270
2022-03-15 05:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:12:01 | INFO | train_inner | epoch 270:     45 / 103 loss=3.47, ppl=11.08, wps=40202.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27700, lr=0.000190003, gnorm=1.011, loss_scale=16, train_wall=153, gb_free=20.8, wall=45064
2022-03-15 05:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:13:36 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 9.32 | ppl 639.15 | wps 66134 | wpb 2040.3 | bsz 4 | num_updates 27758 | best_loss 7.309
2022-03-15 05:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 27758 updates
2022-03-15 05:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:13:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 270 @ 27758 updates, score 9.32) (writing took 0.9306752290576696 seconds)
2022-03-15 05:13:37 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-15 05:13:37 | INFO | train | epoch 270 | loss 3.468 | ppl 11.07 | wps 40120.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 27758 | lr 0.000189804 | gnorm 1.003 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 45160
KL Stats: Epoch 270 Divergences: Uniform: 7.523812933834479 Unigram: 4.611699365262996
2022-03-15 05:13:37 | INFO | fairseq.trainer | begin training epoch 271
2022-03-15 05:13:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:14:43 | INFO | train_inner | epoch 271:     42 / 103 loss=3.466, ppl=11.05, wps=40121.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=27800, lr=0.000189661, gnorm=0.996, loss_scale=16, train_wall=153, gb_free=20.8, wall=45227
2022-03-15 05:16:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:16:23 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 9.322 | ppl 640.08 | wps 66389.8 | wpb 2040.3 | bsz 4 | num_updates 27861 | best_loss 7.309
2022-03-15 05:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 27861 updates
2022-03-15 05:16:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:16:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:16:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 271 @ 27861 updates, score 9.322) (writing took 0.9370096242055297 seconds)
2022-03-15 05:16:24 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-15 05:16:24 | INFO | train | epoch 271 | loss 3.467 | ppl 11.05 | wps 40309.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27861 | lr 0.000189453 | gnorm 1.008 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45327
KL Stats: Epoch 271 Divergences: Uniform: 7.521239364949515 Unigram: 4.612148827934756
2022-03-15 05:16:24 | INFO | fairseq.trainer | begin training epoch 272
2022-03-15 05:16:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:17:25 | INFO | train_inner | epoch 272:     39 / 103 loss=3.467, ppl=11.06, wps=40272.8, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=27900, lr=0.000189321, gnorm=1.022, loss_scale=16, train_wall=153, gb_free=20.8, wall=45389
2022-03-15 05:19:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:19:10 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 9.321 | ppl 639.39 | wps 66059.9 | wpb 2040.3 | bsz 4 | num_updates 27964 | best_loss 7.309
2022-03-15 05:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 27964 updates
2022-03-15 05:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:19:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 272 @ 27964 updates, score 9.321) (writing took 1.023853650316596 seconds)
2022-03-15 05:19:11 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-15 05:19:11 | INFO | train | epoch 272 | loss 3.464 | ppl 11.04 | wps 40277.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 27964 | lr 0.000189104 | gnorm 1.016 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45494
KL Stats: Epoch 272 Divergences: Uniform: 7.52450302281157 Unigram: 4.613740432433409
2022-03-15 05:19:11 | INFO | fairseq.trainer | begin training epoch 273
2022-03-15 05:19:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:20:08 | INFO | train_inner | epoch 273:     36 / 103 loss=3.461, ppl=11.01, wps=40236.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28000, lr=0.000188982, gnorm=1.001, loss_scale=16, train_wall=153, gb_free=20.8, wall=45551
2022-03-15 05:21:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:21:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:21:57 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 9.308 | ppl 633.92 | wps 66151 | wpb 2040.3 | bsz 4 | num_updates 28066 | best_loss 7.309
2022-03-15 05:21:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 28066 updates
2022-03-15 05:21:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:21:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:21:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 273 @ 28066 updates, score 9.308) (writing took 1.0083581758663058 seconds)
2022-03-15 05:21:58 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-15 05:21:58 | INFO | train | epoch 273 | loss 3.462 | ppl 11.02 | wps 39894.9 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28066 | lr 0.00018876 | gnorm 1.014 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45661
KL Stats: Epoch 273 Divergences: Uniform: 7.523600833018767 Unigram: 4.614110609519653
2022-03-15 05:21:58 | INFO | fairseq.trainer | begin training epoch 274
2022-03-15 05:21:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:22:52 | INFO | train_inner | epoch 274:     34 / 103 loss=3.463, ppl=11.03, wps=39855.4, ups=0.61, wpb=65300.5, bsz=127.6, num_updates=28100, lr=0.000188646, gnorm=1.018, loss_scale=16, train_wall=154, gb_free=20.8, wall=45715
2022-03-15 05:24:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:24:44 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 9.326 | ppl 641.62 | wps 66255.4 | wpb 2040.3 | bsz 4 | num_updates 28169 | best_loss 7.309
2022-03-15 05:24:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 28169 updates
2022-03-15 05:24:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:24:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:24:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 274 @ 28169 updates, score 9.326) (writing took 1.0151925990357995 seconds)
2022-03-15 05:24:45 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-15 05:24:45 | INFO | train | epoch 274 | loss 3.46 | ppl 11 | wps 40263.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28169 | lr 0.000188414 | gnorm 1.009 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45828
KL Stats: Epoch 274 Divergences: Uniform: 7.528616018881031 Unigram: 4.617427155093789
2022-03-15 05:24:45 | INFO | fairseq.trainer | begin training epoch 275
2022-03-15 05:24:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:25:34 | INFO | train_inner | epoch 275:     31 / 103 loss=3.461, ppl=11.01, wps=40248.1, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=28200, lr=0.000188311, gnorm=1.007, loss_scale=16, train_wall=153, gb_free=20.8, wall=45877
2022-03-15 05:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:27:31 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 9.316 | ppl 637.35 | wps 66119.5 | wpb 2040.3 | bsz 4 | num_updates 28272 | best_loss 7.309
2022-03-15 05:27:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 28272 updates
2022-03-15 05:27:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 275 @ 28272 updates, score 9.316) (writing took 0.9973104819655418 seconds)
2022-03-15 05:27:32 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-15 05:27:32 | INFO | train | epoch 275 | loss 3.458 | ppl 10.99 | wps 40278.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28272 | lr 0.000188071 | gnorm 0.999 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 45995
KL Stats: Epoch 275 Divergences: Uniform: 7.526532055096137 Unigram: 4.61781882924076
2022-03-15 05:27:32 | INFO | fairseq.trainer | begin training epoch 276
2022-03-15 05:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:28:16 | INFO | train_inner | epoch 276:     28 / 103 loss=3.457, ppl=10.98, wps=40232.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=28300, lr=0.000187978, gnorm=1.002, loss_scale=16, train_wall=153, gb_free=20.8, wall=46040
2022-03-15 05:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:30:18 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 9.339 | ppl 647.77 | wps 66211 | wpb 2040.3 | bsz 4 | num_updates 28375 | best_loss 7.309
2022-03-15 05:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 28375 updates
2022-03-15 05:30:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:30:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:30:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 276 @ 28375 updates, score 9.339) (writing took 0.96489692106843 seconds)
2022-03-15 05:30:19 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-15 05:30:19 | INFO | train | epoch 276 | loss 3.456 | ppl 10.98 | wps 40289.1 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28375 | lr 0.000187729 | gnorm 1.014 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46162
KL Stats: Epoch 276 Divergences: Uniform: 7.528016041358984 Unigram: 4.618693289453381
2022-03-15 05:30:19 | INFO | fairseq.trainer | begin training epoch 277
2022-03-15 05:30:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:30:58 | INFO | train_inner | epoch 277:     25 / 103 loss=3.457, ppl=10.98, wps=40261.5, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28400, lr=0.000187647, gnorm=1.022, loss_scale=16, train_wall=153, gb_free=20.8, wall=46202
2022-03-15 05:33:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:33:05 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 9.34 | ppl 647.95 | wps 66036.8 | wpb 2040.3 | bsz 4 | num_updates 28478 | best_loss 7.309
2022-03-15 05:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 28478 updates
2022-03-15 05:33:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:33:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 277 @ 28478 updates, score 9.34) (writing took 1.0096504930406809 seconds)
2022-03-15 05:33:06 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-15 05:33:06 | INFO | train | epoch 277 | loss 3.455 | ppl 10.97 | wps 40278.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28478 | lr 0.00018739 | gnorm 1.017 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46329
KL Stats: Epoch 277 Divergences: Uniform: 7.530478659093533 Unigram: 4.622088803048956
2022-03-15 05:33:06 | INFO | fairseq.trainer | begin training epoch 278
2022-03-15 05:33:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:33:41 | INFO | train_inner | epoch 278:     22 / 103 loss=3.457, ppl=10.98, wps=40236.4, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28500, lr=0.000187317, gnorm=1.005, loss_scale=16, train_wall=153, gb_free=20.8, wall=46364
2022-03-15 05:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:35:52 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 9.339 | ppl 647.58 | wps 66229.3 | wpb 2040.3 | bsz 4 | num_updates 28581 | best_loss 7.309
2022-03-15 05:35:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 28581 updates
2022-03-15 05:35:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:35:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:35:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 278 @ 28581 updates, score 9.339) (writing took 1.0100708259269595 seconds)
2022-03-15 05:35:53 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-15 05:35:53 | INFO | train | epoch 278 | loss 3.453 | ppl 10.95 | wps 40243.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28581 | lr 0.000187052 | gnorm 1.009 | loss_scale 32 | train_wall 158 | gb_free 20.8 | wall 46496
KL Stats: Epoch 278 Divergences: Uniform: 7.529708176669324 Unigram: 4.621777900802427
2022-03-15 05:35:53 | INFO | fairseq.trainer | begin training epoch 279
2022-03-15 05:35:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:36:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:36:25 | INFO | train_inner | epoch 279:     20 / 103 loss=3.452, ppl=10.95, wps=39821.6, ups=0.61, wpb=65310.7, bsz=127.6, num_updates=28600, lr=0.000186989, gnorm=1.013, loss_scale=16, train_wall=154, gb_free=20.8, wall=46528
2022-03-15 05:38:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:38:39 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 9.346 | ppl 650.76 | wps 66674.8 | wpb 2040.3 | bsz 4 | num_updates 28683 | best_loss 7.309
2022-03-15 05:38:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 28683 updates
2022-03-15 05:38:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:38:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:38:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 279 @ 28683 updates, score 9.346) (writing took 0.9801183948293328 seconds)
2022-03-15 05:38:40 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-15 05:38:40 | INFO | train | epoch 279 | loss 3.451 | ppl 10.94 | wps 39886 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 28683 | lr 0.000186719 | gnorm 1.015 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46664
KL Stats: Epoch 279 Divergences: Uniform: 7.532996352273956 Unigram: 4.624019713435115
2022-03-15 05:38:40 | INFO | fairseq.trainer | begin training epoch 280
2022-03-15 05:38:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:39:07 | INFO | train_inner | epoch 280:     17 / 103 loss=3.454, ppl=10.96, wps=40246.9, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=28700, lr=0.000186663, gnorm=1.021, loss_scale=16, train_wall=153, gb_free=20.8, wall=46690
2022-03-15 05:41:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:41:26 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 9.332 | ppl 644.28 | wps 66204.1 | wpb 2040.3 | bsz 4 | num_updates 28786 | best_loss 7.309
2022-03-15 05:41:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 28786 updates
2022-03-15 05:41:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 280 @ 28786 updates, score 9.332) (writing took 0.9452238399535418 seconds)
2022-03-15 05:41:27 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-15 05:41:27 | INFO | train | epoch 280 | loss 3.449 | ppl 10.92 | wps 40296 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28786 | lr 0.000186384 | gnorm 1.013 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46830
KL Stats: Epoch 280 Divergences: Uniform: 7.533852492539748 Unigram: 4.6259265990150285
2022-03-15 05:41:27 | INFO | fairseq.trainer | begin training epoch 281
2022-03-15 05:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:41:49 | INFO | train_inner | epoch 281:     14 / 103 loss=3.449, ppl=10.92, wps=40260.9, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=28800, lr=0.000186339, gnorm=1.009, loss_scale=16, train_wall=153, gb_free=20.8, wall=46853
2022-03-15 05:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:44:13 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 9.32 | ppl 639.31 | wps 66344.2 | wpb 2040.3 | bsz 4 | num_updates 28889 | best_loss 7.309
2022-03-15 05:44:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 28889 updates
2022-03-15 05:44:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 281 @ 28889 updates, score 9.32) (writing took 0.9582595210522413 seconds)
2022-03-15 05:44:14 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-15 05:44:14 | INFO | train | epoch 281 | loss 3.446 | ppl 10.9 | wps 40262.8 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28889 | lr 0.000186052 | gnorm 1.017 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 46998
KL Stats: Epoch 281 Divergences: Uniform: 7.533465663016215 Unigram: 4.625999211054946
2022-03-15 05:44:14 | INFO | fairseq.trainer | begin training epoch 282
2022-03-15 05:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:44:32 | INFO | train_inner | epoch 282:     11 / 103 loss=3.447, ppl=10.91, wps=40229.2, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=28900, lr=0.000186016, gnorm=1.015, loss_scale=16, train_wall=153, gb_free=20.8, wall=47015
2022-03-15 05:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:47:00 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 9.343 | ppl 649.3 | wps 66137 | wpb 2040.3 | bsz 4 | num_updates 28992 | best_loss 7.309
2022-03-15 05:47:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 28992 updates
2022-03-15 05:47:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 282 @ 28992 updates, score 9.343) (writing took 1.0016738772392273 seconds)
2022-03-15 05:47:01 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-15 05:47:01 | INFO | train | epoch 282 | loss 3.446 | ppl 10.89 | wps 40221.5 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 28992 | lr 0.000185721 | gnorm 1.011 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47165
KL Stats: Epoch 282 Divergences: Uniform: 7.5350844827633034 Unigram: 4.627771114715543
2022-03-15 05:47:01 | INFO | fairseq.trainer | begin training epoch 283
2022-03-15 05:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:47:14 | INFO | train_inner | epoch 283:      8 / 103 loss=3.447, ppl=10.91, wps=40191.5, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29000, lr=0.000185695, gnorm=1.014, loss_scale=16, train_wall=153, gb_free=20.8, wall=47178
2022-03-15 05:49:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:49:47 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 9.346 | ppl 650.74 | wps 65806.3 | wpb 2040.3 | bsz 4 | num_updates 29095 | best_loss 7.309
2022-03-15 05:49:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 29095 updates
2022-03-15 05:49:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:49:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:49:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 283 @ 29095 updates, score 9.346) (writing took 0.9984692726284266 seconds)
2022-03-15 05:49:48 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-15 05:49:48 | INFO | train | epoch 283 | loss 3.444 | ppl 10.88 | wps 40267.9 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29095 | lr 0.000185392 | gnorm 1.012 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47332
KL Stats: Epoch 283 Divergences: Uniform: 7.536269512927107 Unigram: 4.629529913579247
2022-03-15 05:49:48 | INFO | fairseq.trainer | begin training epoch 284
2022-03-15 05:49:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:49:56 | INFO | train_inner | epoch 284:      5 / 103 loss=3.446, ppl=10.9, wps=40230.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29100, lr=0.000185376, gnorm=1.011, loss_scale=16, train_wall=153, gb_free=20.8, wall=47340
2022-03-15 05:50:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 05:52:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:52:34 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 9.363 | ppl 658.32 | wps 66045.2 | wpb 2040.3 | bsz 4 | num_updates 29197 | best_loss 7.309
2022-03-15 05:52:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 29197 updates
2022-03-15 05:52:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:52:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:52:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 284 @ 29197 updates, score 9.363) (writing took 1.0250968923792243 seconds)
2022-03-15 05:52:35 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-15 05:52:35 | INFO | train | epoch 284 | loss 3.44 | ppl 10.86 | wps 39879.2 | ups 0.61 | wpb 65310.1 | bsz 127.6 | num_updates 29197 | lr 0.000185068 | gnorm 1.022 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47499
KL Stats: Epoch 284 Divergences: Uniform: 7.537662512978108 Unigram: 4.631683731710441
2022-03-15 05:52:35 | INFO | fairseq.trainer | begin training epoch 285
2022-03-15 05:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:52:40 | INFO | train_inner | epoch 285:      3 / 103 loss=3.44, ppl=10.86, wps=39848.8, ups=0.61, wpb=65305.6, bsz=127.6, num_updates=29200, lr=0.000185058, gnorm=1.024, loss_scale=16, train_wall=154, gb_free=20.8, wall=47504
2022-03-15 05:55:18 | INFO | train_inner | epoch 285:    103 / 103 loss=3.441, ppl=10.86, wps=41397.9, ups=0.63, wpb=65305.6, bsz=127.6, num_updates=29300, lr=0.000184742, gnorm=1.014, loss_scale=16, train_wall=153, gb_free=20.8, wall=47661
2022-03-15 05:55:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:55:22 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 9.348 | ppl 651.73 | wps 66142.5 | wpb 2040.3 | bsz 4 | num_updates 29300 | best_loss 7.309
2022-03-15 05:55:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 29300 updates
2022-03-15 05:55:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:55:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 285 @ 29300 updates, score 9.348) (writing took 0.9522517584264278 seconds)
2022-03-15 05:55:23 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-15 05:55:23 | INFO | train | epoch 285 | loss 3.439 | ppl 10.84 | wps 40255 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29300 | lr 0.000184742 | gnorm 1.015 | loss_scale 16 | train_wall 158 | gb_free 20.8 | wall 47666
KL Stats: Epoch 285 Divergences: Uniform: 7.539015658211296 Unigram: 4.633060908624468
2022-03-15 05:55:23 | INFO | fairseq.trainer | begin training epoch 286
2022-03-15 05:55:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 05:58:01 | INFO | train_inner | epoch 286:    100 / 103 loss=3.436, ppl=10.82, wps=40297.8, ups=0.61, wpb=65530.9, bsz=128, num_updates=29400, lr=0.000184428, gnorm=1.004, loss_scale=16, train_wall=153, gb_free=20.8, wall=47824
2022-03-15 05:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 05:58:08 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 9.359 | ppl 656.57 | wps 65978.7 | wpb 2040.3 | bsz 4 | num_updates 29403 | best_loss 7.309
2022-03-15 05:58:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 29403 updates
2022-03-15 05:58:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 05:58:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 286 @ 29403 updates, score 9.359) (writing took 0.9629320679232478 seconds)
2022-03-15 05:58:09 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-15 05:58:09 | INFO | train | epoch 286 | loss 3.438 | ppl 10.83 | wps 40317 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29403 | lr 0.000184418 | gnorm 1.006 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 47833
KL Stats: Epoch 286 Divergences: Uniform: 7.5403875249236245 Unigram: 4.633574998216535
2022-03-15 05:58:09 | INFO | fairseq.trainer | begin training epoch 287
2022-03-15 05:58:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:00:43 | INFO | train_inner | epoch 287:     97 / 103 loss=3.437, ppl=10.83, wps=40257.7, ups=0.62, wpb=65310.7, bsz=127.6, num_updates=29500, lr=0.000184115, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=47986
2022-03-15 06:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:00:55 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 9.368 | ppl 660.98 | wps 66311.7 | wpb 2040.3 | bsz 4 | num_updates 29506 | best_loss 7.309
2022-03-15 06:00:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 29506 updates
2022-03-15 06:00:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 287 @ 29506 updates, score 9.368) (writing took 1.016444232314825 seconds)
2022-03-15 06:00:56 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-15 06:00:56 | INFO | train | epoch 287 | loss 3.437 | ppl 10.83 | wps 40275.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29506 | lr 0.000184096 | gnorm 1.011 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48000
KL Stats: Epoch 287 Divergences: Uniform: 7.541954289415647 Unigram: 4.635497524826874
2022-03-15 06:00:56 | INFO | fairseq.trainer | begin training epoch 288
2022-03-15 06:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:03:25 | INFO | train_inner | epoch 288:     94 / 103 loss=3.433, ppl=10.8, wps=40262.6, ups=0.62, wpb=65300.5, bsz=127.6, num_updates=29600, lr=0.000183804, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=48149
2022-03-15 06:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:03:42 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 9.358 | ppl 656.26 | wps 66226.9 | wpb 2040.3 | bsz 4 | num_updates 29609 | best_loss 7.309
2022-03-15 06:03:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 29609 updates
2022-03-15 06:03:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:03:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:03:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 288 @ 29609 updates, score 9.358) (writing took 1.0108424229547381 seconds)
2022-03-15 06:03:43 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-15 06:03:43 | INFO | train | epoch 288 | loss 3.434 | ppl 10.81 | wps 40305.3 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29609 | lr 0.000183776 | gnorm 1.007 | loss_scale 16 | train_wall 157 | gb_free 20.8 | wall 48167
KL Stats: Epoch 288 Divergences: Uniform: 7.545156347001901 Unigram: 4.636966447945946
2022-03-15 06:03:43 | INFO | fairseq.trainer | begin training epoch 289
2022-03-15 06:03:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:03:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-15 06:04:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-15 06:06:11 | INFO | train_inner | epoch 289:     93 / 103 loss=3.431, ppl=10.78, wps=39363.6, ups=0.6, wpb=65305.6, bsz=127.6, num_updates=29700, lr=0.000183494, gnorm=1, loss_scale=8, train_wall=156, gb_free=20.8, wall=48314
2022-03-15 06:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:06:30 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 9.336 | ppl 646.49 | wps 66577.6 | wpb 2040.3 | bsz 4 | num_updates 29710 | best_loss 7.309
2022-03-15 06:06:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 29710 updates
2022-03-15 06:06:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:06:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:06:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 289 @ 29710 updates, score 9.336) (writing took 0.960965265519917 seconds)
2022-03-15 06:06:31 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-15 06:06:31 | INFO | train | epoch 289 | loss 3.432 | ppl 10.79 | wps 39402.2 | ups 0.6 | wpb 65307.9 | bsz 127.6 | num_updates 29710 | lr 0.000183463 | gnorm 1.003 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 48334
KL Stats: Epoch 289 Divergences: Uniform: 7.544679776549821 Unigram: 4.63849205137746
2022-03-15 06:06:31 | INFO | fairseq.trainer | begin training epoch 290
2022-03-15 06:06:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:08:53 | INFO | train_inner | epoch 290:     90 / 103 loss=3.431, ppl=10.78, wps=40286.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29800, lr=0.000183186, gnorm=1.013, loss_scale=8, train_wall=153, gb_free=20.8, wall=48477
2022-03-15 06:09:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:09:17 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 9.356 | ppl 655.39 | wps 66607.2 | wpb 2040.3 | bsz 4 | num_updates 29813 | best_loss 7.309
2022-03-15 06:09:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 29813 updates
2022-03-15 06:09:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:09:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 290 @ 29813 updates, score 9.356) (writing took 0.9452096475288272 seconds)
2022-03-15 06:09:18 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-15 06:09:18 | INFO | train | epoch 290 | loss 3.433 | ppl 10.8 | wps 40320.7 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29813 | lr 0.000183146 | gnorm 1.014 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 48501
KL Stats: Epoch 290 Divergences: Uniform: 7.5426720087823735 Unigram: 4.637474443562638
2022-03-15 06:09:18 | INFO | fairseq.trainer | begin training epoch 291
2022-03-15 06:09:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:11:35 | INFO | train_inner | epoch 291:     87 / 103 loss=3.43, ppl=10.78, wps=40279.6, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=29900, lr=0.000182879, gnorm=1.01, loss_scale=8, train_wall=153, gb_free=20.8, wall=48639
2022-03-15 06:12:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:12:03 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 9.362 | ppl 658.22 | wps 66563.3 | wpb 2040.3 | bsz 4 | num_updates 29916 | best_loss 7.309
2022-03-15 06:12:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 29916 updates
2022-03-15 06:12:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 291 @ 29916 updates, score 9.362) (writing took 1.040316709317267 seconds)
2022-03-15 06:12:05 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-15 06:12:05 | INFO | train | epoch 291 | loss 3.43 | ppl 10.78 | wps 40292.6 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 29916 | lr 0.00018283 | gnorm 1.009 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 48668
KL Stats: Epoch 291 Divergences: Uniform: 7.548557986771197 Unigram: 4.640902573591473
2022-03-15 06:12:05 | INFO | fairseq.trainer | begin training epoch 292
2022-03-15 06:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:14:17 | INFO | train_inner | epoch 292:     84 / 103 loss=3.428, ppl=10.76, wps=40278, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30000, lr=0.000182574, gnorm=1, loss_scale=8, train_wall=153, gb_free=20.8, wall=48801
2022-03-15 06:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:14:50 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 9.371 | ppl 662.04 | wps 66585.8 | wpb 2040.3 | bsz 4 | num_updates 30019 | best_loss 7.309
2022-03-15 06:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 30019 updates
2022-03-15 06:14:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:14:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 292 @ 30019 updates, score 9.371) (writing took 1.0010372074320912 seconds)
2022-03-15 06:14:51 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-15 06:14:51 | INFO | train | epoch 292 | loss 3.428 | ppl 10.76 | wps 40316.4 | ups 0.62 | wpb 65312.3 | bsz 127.6 | num_updates 30019 | lr 0.000182516 | gnorm 1.002 | loss_scale 8 | train_wall 157 | gb_free 20.8 | wall 48835
KL Stats: Epoch 292 Divergences: Uniform: 7.545192660282271 Unigram: 4.640675682861957
2022-03-15 06:14:51 | INFO | fairseq.trainer | begin training epoch 293
2022-03-15 06:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:17:00 | INFO | train_inner | epoch 293:     81 / 103 loss=3.427, ppl=10.75, wps=40201.8, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30100, lr=0.000182271, gnorm=1.007, loss_scale=8, train_wall=153, gb_free=20.8, wall=48963
2022-03-15 06:17:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-15 06:17:38 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 9.355 | ppl 654.87 | wps 65747.8 | wpb 2040.3 | bsz 4 | num_updates 30122 | best_loss 7.309
2022-03-15 06:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 30122 updates
2022-03-15 06:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt
2022-03-15 06:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625-jelinek_0.015_0.06_0.925_#1/checkpoint_last.pt (epoch 293 @ 30122 updates, score 9.355) (writing took 0.9460559533908963 seconds)
2022-03-15 06:17:39 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-15 06:17:39 | INFO | train | epoch 293 | loss 3.426 | ppl 10.75 | wps 40162.7 | ups 0.61 | wpb 65312.3 | bsz 127.6 | num_updates 30122 | lr 0.000182204 | gnorm 1.003 | loss_scale 8 | train_wall 158 | gb_free 20.8 | wall 49002
KL Stats: Epoch 293 Divergences: Uniform: 7.547815134035134 Unigram: 4.643809578865054
2022-03-15 06:17:39 | INFO | fairseq.trainer | begin training epoch 294
2022-03-15 06:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-15 06:19:42 | INFO | train_inner | epoch 294:     78 / 103 loss=3.422, ppl=10.72, wps=40199.3, ups=0.62, wpb=65305.6, bsz=127.6, num_updates=30200, lr=0.000181969, gnorm=1.01, loss_scale=16, train_wall=153, gb_free=20.8, wall=49126
Exception in thread Thread-1175:
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/threading.py", line 932, in _bootstrap_inner
Traceback (most recent call last):
  File "/cluster/home/andriusb/fq/env/bin/fairseq-train", line 33, in <module>
    self.run()
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/threading.py", line 870, in run
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 544, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 207, in main
    self._target(*self._args, **self._kwargs)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/utils/data/_utils/pin_memory.py", line 25, in _pin_memory_loop
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/cluster/home/andriusb/fq/fairseq/fairseq_cli/train.py", line 324, in train
    for i, samples in enumerate(progress):
  File "/cluster/home/andriusb/fq/fairseq/fairseq/logging/progress_bar.py", line 261, in __iter__
    for i, obj in enumerate(self.iterable, start=self.n):
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 116, in get
    x = next(self._itr)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 509, in _chunk_iterator
    return _ForkingPickler.loads(res)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/multiprocessing/reductions.py", line 282, in rebuild_storage_fd
    for x in itr:
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 56, in __next__
    x = next(self._itr)
  File "/cluster/home/andriusb/fq/fairseq/fairseq/data/iterators.py", line 635, in __next__
    item = self._queue.get(True)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/queue.py", line 170, in get
    fd = df.detach()
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    self.not_empty.wait()
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/threading.py", line 302, in wait
    with _resource_sharer.get_connection(self._id) as conn:
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    waiter.acquire()
KeyboardInterrupt
    c = Client(address, authkey=process.current_process().authkey)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 502, in Client
