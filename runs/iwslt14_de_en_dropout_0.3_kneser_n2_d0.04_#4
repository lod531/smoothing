Sender: LSF System <lsfadmin@eu-g3-065>
Subject: Job 210652857: <iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4> was submitted from host <eu-login-27> by user <andriusb> in cluster <euler> at Wed Mar 23 18:53:27 2022
Job was executed on host(s) <eu-g3-065>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 18:53:39 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 18:53:39 2022
Terminated at Thu Mar 24 00:03:35 2022
Results reported at Thu Mar 24 00:03:35 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.04 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575614 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   18574.47 sec.
    Max Memory :                                 5081 MB
    Average Memory :                             4391.43 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14919.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   18596 sec.
    Turnaround time :                            18608 sec.

The output (if any) follows:

2022-03-23 18:53:45 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575614, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.04, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575614, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.04, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 18:53:45 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 18:53:45 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 18:53:46 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:53:46 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:53:46 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1201/160239 [00:00<00:13, 12002.51it/s]  2%|▏         | 2577/160239 [00:00<00:12, 13030.02it/s]  3%|▎         | 4037/160239 [00:00<00:11, 13745.69it/s]  3%|▎         | 5412/160239 [00:00<00:11, 13483.25it/s]  4%|▍         | 6868/160239 [00:00<00:11, 13865.63it/s]  5%|▌         | 8256/160239 [00:00<00:11, 13158.71it/s]  6%|▌         | 9686/160239 [00:00<00:11, 13514.54it/s]  7%|▋         | 11093/160239 [00:00<00:10, 13681.65it/s]  8%|▊         | 12466/160239 [00:00<00:10, 13530.55it/s]  9%|▊         | 13823/160239 [00:01<00:10, 13416.44it/s]  9%|▉         | 15167/160239 [00:01<00:10, 13312.01it/s] 10%|█         | 16500/160239 [00:01<00:10, 13093.94it/s] 11%|█         | 17811/160239 [00:01<00:10, 13039.14it/s] 12%|█▏        | 19151/160239 [00:01<00:10, 13145.07it/s] 13%|█▎        | 20631/160239 [00:01<00:10, 13634.65it/s] 14%|█▎        | 21996/160239 [00:01<00:10, 13154.28it/s] 15%|█▍        | 23317/160239 [00:01<00:10, 13170.36it/s] 15%|█▌        | 24675/160239 [00:01<00:10, 13288.04it/s] 16%|█▌        | 26007/160239 [00:01<00:10, 13242.76it/s] 17%|█▋        | 27333/160239 [00:02<00:10, 13196.41it/s] 18%|█▊        | 28696/160239 [00:02<00:09, 13323.30it/s] 19%|█▊        | 30030/160239 [00:02<00:09, 13174.67it/s] 20%|█▉        | 31394/160239 [00:02<00:09, 13310.39it/s] 20%|██        | 32756/160239 [00:02<00:09, 13401.12it/s] 21%|██▏       | 34097/160239 [00:02<00:09, 12964.58it/s] 22%|██▏       | 35397/160239 [00:02<00:09, 12829.03it/s] 23%|██▎       | 36791/160239 [00:02<00:09, 13152.77it/s] 24%|██▍       | 38109/160239 [00:02<00:09, 13155.15it/s] 25%|██▍       | 39429/160239 [00:02<00:09, 13166.98it/s] 25%|██▌       | 40814/160239 [00:03<00:08, 13364.80it/s] 26%|██▋       | 42152/160239 [00:03<00:09, 13051.24it/s] 27%|██▋       | 43460/160239 [00:03<00:09, 12839.05it/s] 28%|██▊       | 44746/160239 [00:03<00:09, 12727.30it/s] 29%|██▉       | 46165/160239 [00:03<00:08, 13153.95it/s] 30%|██▉       | 47529/160239 [00:03<00:08, 13295.06it/s] 30%|███       | 48861/160239 [00:03<00:08, 13107.64it/s] 31%|███▏      | 50187/160239 [00:03<00:08, 13150.44it/s] 32%|███▏      | 51573/160239 [00:03<00:08, 13359.81it/s] 33%|███▎      | 52914/160239 [00:03<00:08, 13373.96it/s] 34%|███▍      | 54253/160239 [00:04<00:07, 13301.72it/s] 35%|███▍      | 55584/160239 [00:04<00:07, 13217.35it/s] 36%|███▌      | 57008/160239 [00:04<00:07, 13519.08it/s] 36%|███▋      | 58361/160239 [00:04<00:07, 13501.77it/s] 37%|███▋      | 59730/160239 [00:04<00:07, 13557.30it/s] 38%|███▊      | 61087/160239 [00:04<00:07, 13320.14it/s] 39%|███▉      | 62465/160239 [00:04<00:07, 13447.88it/s] 40%|███▉      | 63817/160239 [00:04<00:07, 13465.46it/s] 41%|████      | 65397/160239 [00:04<00:06, 14157.58it/s] 42%|████▏     | 66814/160239 [00:05<00:06, 13981.39it/s] 43%|████▎     | 68214/160239 [00:05<00:06, 13751.32it/s] 43%|████▎     | 69591/160239 [00:05<00:06, 13249.69it/s] 44%|████▍     | 71005/160239 [00:05<00:06, 13502.65it/s] 45%|████▌     | 72360/160239 [00:05<00:06, 13373.78it/s] 46%|████▌     | 73701/160239 [00:05<00:06, 13201.56it/s] 47%|████▋     | 75024/160239 [00:05<00:06, 13166.07it/s] 48%|████▊     | 76342/160239 [00:05<00:06, 13091.73it/s] 49%|████▊     | 77792/160239 [00:05<00:06, 13504.36it/s] 49%|████▉     | 79164/160239 [00:05<00:05, 13567.93it/s] 50%|█████     | 80604/160239 [00:06<00:05, 13813.11it/s] 51%|█████     | 81987/160239 [00:06<00:05, 13788.60it/s] 52%|█████▏    | 83367/160239 [00:06<00:05, 13746.82it/s] 53%|█████▎    | 84743/160239 [00:06<00:05, 13692.93it/s] 54%|█████▍    | 86215/160239 [00:06<00:05, 13994.89it/s] 55%|█████▍    | 87663/160239 [00:06<00:05, 14135.99it/s] 56%|█████▌    | 89077/160239 [00:06<00:05, 13846.20it/s] 56%|█████▋    | 90469/160239 [00:06<00:05, 13866.89it/s] 57%|█████▋    | 91857/160239 [00:06<00:05, 13565.98it/s] 58%|█████▊    | 93231/160239 [00:06<00:04, 13613.05it/s] 59%|█████▉    | 94594/160239 [00:07<00:04, 13336.29it/s] 60%|█████▉    | 95984/160239 [00:07<00:04, 13500.30it/s] 61%|██████    | 97336/160239 [00:07<00:04, 13477.19it/s] 62%|██████▏   | 98707/160239 [00:07<00:04, 13543.94it/s] 62%|██████▏   | 100063/160239 [00:07<00:04, 13537.21it/s] 63%|██████▎   | 101423/160239 [00:07<00:04, 13554.04it/s] 64%|██████▍   | 102779/160239 [00:07<00:04, 13434.44it/s] 65%|██████▍   | 104123/160239 [00:07<00:04, 13406.42it/s] 66%|██████▌   | 105530/160239 [00:07<00:04, 13603.08it/s] 67%|██████▋   | 106891/160239 [00:07<00:03, 13561.57it/s] 68%|██████▊   | 108248/160239 [00:08<00:03, 13138.98it/s] 68%|██████▊   | 109565/160239 [00:08<00:03, 13119.59it/s] 69%|██████▉   | 110888/160239 [00:08<00:03, 13148.02it/s] 70%|███████   | 112311/160239 [00:08<00:03, 13466.28it/s] 71%|███████   | 113660/160239 [00:08<00:03, 13444.44it/s] 72%|███████▏  | 115006/160239 [00:08<00:03, 13416.29it/s] 73%|███████▎  | 116364/160239 [00:08<00:03, 13463.91it/s] 73%|███████▎  | 117711/160239 [00:08<00:03, 13342.31it/s] 74%|███████▍  | 119128/160239 [00:08<00:03, 13586.91it/s] 75%|███████▌  | 120488/160239 [00:08<00:02, 13401.78it/s] 76%|███████▌  | 121934/160239 [00:09<00:02, 13712.40it/s] 77%|███████▋  | 123325/160239 [00:09<00:02, 13769.69it/s] 78%|███████▊  | 124703/160239 [00:09<00:02, 13504.24it/s] 79%|███████▊  | 126055/160239 [00:09<00:02, 13342.69it/s] 80%|███████▉  | 127424/160239 [00:09<00:02, 13444.06it/s] 80%|████████  | 128819/160239 [00:09<00:02, 13592.77it/s] 81%|████████  | 130180/160239 [00:09<00:02, 13165.15it/s] 82%|████████▏ | 131531/160239 [00:09<00:02, 13263.67it/s] 83%|████████▎ | 132860/160239 [00:09<00:02, 13255.05it/s] 84%|████████▎ | 134188/160239 [00:10<00:02, 12913.03it/s] 85%|████████▍ | 135565/160239 [00:10<00:01, 13161.93it/s] 85%|████████▌ | 136926/160239 [00:10<00:01, 13291.09it/s] 86%|████████▋ | 138291/160239 [00:10<00:01, 13394.59it/s] 87%|████████▋ | 139724/160239 [00:10<00:01, 13670.28it/s] 88%|████████▊ | 141133/160239 [00:10<00:01, 13792.16it/s] 89%|████████▉ | 142514/160239 [00:10<00:01, 13554.57it/s] 90%|████████▉ | 143872/160239 [00:10<00:01, 13477.95it/s] 91%|█████████ | 145221/160239 [00:10<00:01, 13414.89it/s] 91%|█████████▏| 146564/160239 [00:10<00:01, 13182.34it/s] 92%|█████████▏| 147884/160239 [00:11<00:00, 13139.96it/s] 93%|█████████▎| 149199/160239 [00:11<00:00, 12903.46it/s] 94%|█████████▍| 150559/160239 [00:11<00:00, 13104.82it/s] 95%|█████████▍| 151910/160239 [00:11<00:00, 13223.57it/s] 96%|█████████▌| 153234/160239 [00:11<00:00, 13187.75it/s] 96%|█████████▋| 154598/160239 [00:11<00:00, 13321.36it/s] 97%|█████████▋| 155995/160239 [00:11<00:00, 13512.66it/s] 98%|█████████▊| 157401/160239 [00:11<00:00, 13675.32it/s] 99%|█████████▉| 158770/160239 [00:11<00:00, 13365.34it/s]100%|█████████▉| 160199/160239 [00:11<00:00, 13636.05it/s]100%|██████████| 160239/160239 [00:11<00:00, 13395.09it/s]
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 31/6629 [00:00<00:21, 300.64it/s]  1%|          | 62/6629 [00:00<00:21, 301.15it/s]  1%|▏         | 93/6629 [00:00<00:21, 302.22it/s]  2%|▏         | 124/6629 [00:00<00:21, 304.21it/s]  2%|▏         | 155/6629 [00:00<00:21, 303.91it/s]  3%|▎         | 186/6629 [00:00<00:21, 303.05it/s]  3%|▎         | 217/6629 [00:00<00:21, 301.94it/s]  4%|▎         | 248/6629 [00:00<00:21, 301.63it/s]  4%|▍         | 279/6629 [00:00<00:21, 301.80it/s]  5%|▍         | 310/6629 [00:01<00:20, 301.62it/s]  5%|▌         | 341/6629 [00:01<00:20, 300.87it/s]  6%|▌         | 372/6629 [00:01<00:20, 299.82it/s]  6%|▌         | 403/6629 [00:01<00:20, 300.12it/s]  7%|▋         | 434/6629 [00:01<00:20, 299.22it/s]  7%|▋         | 465/6629 [00:01<00:20, 301.28it/s]  7%|▋         | 496/6629 [00:01<00:20, 301.92it/s]  8%|▊         | 527/6629 [00:01<00:20, 301.45it/s]  8%|▊         | 558/6629 [00:01<00:20, 301.05it/s]  9%|▉         | 589/6629 [00:01<00:20, 301.63it/s]  9%|▉         | 620/6629 [00:02<00:19, 302.80it/s] 10%|▉         | 651/6629 [00:02<00:19, 302.34it/s] 10%|█         | 682/6629 [00:02<00:19, 302.71it/s] 11%|█         | 713/6629 [00:02<00:19, 303.69it/s] 11%|█         | 744/6629 [00:02<00:19, 304.23it/s] 12%|█▏        | 775/6629 [00:02<00:19, 305.21it/s] 12%|█▏        | 806/6629 [00:02<00:19, 305.79it/s] 13%|█▎        | 837/6629 [00:02<00:18, 305.45it/s] 13%|█▎        | 868/6629 [00:02<00:18, 305.62it/s] 14%|█▎        | 899/6629 [00:02<00:18, 305.37it/s] 14%|█▍        | 930/6629 [00:03<00:18, 304.62it/s] 14%|█▍        | 961/6629 [00:03<00:18, 305.54it/s] 15%|█▍        | 992/6629 [00:03<00:18, 305.49it/s] 15%|█▌        | 1023/6629 [00:03<00:18, 305.53it/s] 16%|█▌        | 1057/6629 [00:03<00:17, 313.12it/s] 16%|█▋        | 1090/6629 [00:03<00:17, 317.87it/s] 17%|█▋        | 1124/6629 [00:03<00:17, 322.93it/s] 17%|█▋        | 1157/6629 [00:03<00:16, 324.40it/s] 18%|█▊        | 1190/6629 [00:03<00:16, 324.43it/s] 18%|█▊        | 1224/6629 [00:03<00:16, 326.18it/s] 19%|█▉        | 1257/6629 [00:04<00:16, 326.19it/s] 19%|█▉        | 1290/6629 [00:04<00:16, 326.10it/s] 20%|█▉        | 1323/6629 [00:04<00:16, 326.30it/s] 20%|██        | 1356/6629 [00:04<00:16, 327.16it/s] 21%|██        | 1389/6629 [00:04<00:16, 326.84it/s] 21%|██▏       | 1422/6629 [00:04<00:15, 326.37it/s] 22%|██▏       | 1456/6629 [00:04<00:15, 328.05it/s] 22%|██▏       | 1489/6629 [00:04<00:15, 327.62it/s] 23%|██▎       | 1523/6629 [00:04<00:15, 328.87it/s] 23%|██▎       | 1556/6629 [00:04<00:15, 327.93it/s] 24%|██▍       | 1589/6629 [00:05<00:15, 328.23it/s] 24%|██▍       | 1622/6629 [00:05<00:15, 327.50it/s] 25%|██▍       | 1656/6629 [00:05<00:15, 328.76it/s] 25%|██▌       | 1689/6629 [00:05<00:15, 328.57it/s] 26%|██▌       | 1722/6629 [00:05<00:14, 328.22it/s] 26%|██▋       | 1755/6629 [00:05<00:14, 327.61it/s] 27%|██▋       | 1788/6629 [00:05<00:14, 326.87it/s] 27%|██▋       | 1821/6629 [00:05<00:14, 327.13it/s] 28%|██▊       | 1854/6629 [00:05<00:14, 327.48it/s] 28%|██▊       | 1887/6629 [00:06<00:14, 327.47it/s] 29%|██▉       | 1920/6629 [00:06<00:14, 327.37it/s] 29%|██▉       | 1953/6629 [00:06<00:14, 327.53it/s] 30%|██▉       | 1986/6629 [00:06<00:14, 328.12it/s] 30%|███       | 2019/6629 [00:06<00:14, 326.17it/s] 31%|███       | 2053/6629 [00:06<00:13, 327.29it/s] 31%|███▏      | 2086/6629 [00:06<00:13, 327.08it/s] 32%|███▏      | 2119/6629 [00:06<00:13, 326.40it/s] 32%|███▏      | 2152/6629 [00:06<00:13, 325.93it/s] 33%|███▎      | 2185/6629 [00:06<00:13, 326.63it/s] 33%|███▎      | 2218/6629 [00:07<00:13, 326.23it/s] 34%|███▍      | 2251/6629 [00:07<00:13, 326.16it/s] 34%|███▍      | 2285/6629 [00:07<00:13, 327.37it/s] 35%|███▍      | 2318/6629 [00:07<00:13, 327.34it/s] 35%|███▌      | 2351/6629 [00:07<00:13, 327.48it/s] 36%|███▌      | 2384/6629 [00:07<00:13, 326.38it/s] 36%|███▋      | 2417/6629 [00:07<00:12, 326.27it/s] 37%|███▋      | 2450/6629 [00:07<00:12, 326.55it/s] 37%|███▋      | 2483/6629 [00:07<00:12, 323.89it/s] 38%|███▊      | 2516/6629 [00:07<00:12, 324.32it/s] 38%|███▊      | 2549/6629 [00:08<00:12, 324.56it/s] 39%|███▉      | 2582/6629 [00:08<00:12, 325.08it/s] 39%|███▉      | 2615/6629 [00:08<00:12, 325.87it/s] 40%|███▉      | 2648/6629 [00:08<00:12, 325.72it/s] 40%|████      | 2681/6629 [00:08<00:12, 326.80it/s] 41%|████      | 2714/6629 [00:08<00:11, 327.36it/s] 41%|████▏     | 2747/6629 [00:08<00:11, 327.16it/s] 42%|████▏     | 2780/6629 [00:08<00:11, 327.39it/s] 42%|████▏     | 2813/6629 [00:08<00:11, 327.35it/s] 43%|████▎     | 2846/6629 [00:08<00:11, 326.36it/s] 43%|████▎     | 2879/6629 [00:09<00:11, 325.82it/s] 44%|████▍     | 2912/6629 [00:09<00:11, 325.65it/s] 44%|████▍     | 2945/6629 [00:09<00:11, 325.49it/s] 45%|████▍     | 2978/6629 [00:09<00:11, 326.15it/s] 45%|████▌     | 3011/6629 [00:09<00:11, 326.02it/s] 46%|████▌     | 3044/6629 [00:09<00:10, 326.40it/s] 46%|████▋     | 3077/6629 [00:09<00:10, 324.92it/s] 47%|████▋     | 3110/6629 [00:09<00:10, 325.20it/s] 47%|████▋     | 3144/6629 [00:09<00:10, 327.30it/s] 48%|████▊     | 3177/6629 [00:09<00:10, 326.05it/s] 48%|████▊     | 3210/6629 [00:10<00:10, 326.25it/s] 49%|████▉     | 3243/6629 [00:10<00:10, 326.95it/s] 49%|████▉     | 3276/6629 [00:10<00:10, 326.23it/s] 50%|████▉     | 3310/6629 [00:10<00:10, 327.33it/s] 50%|█████     | 3343/6629 [00:10<00:10, 326.81it/s] 51%|█████     | 3376/6629 [00:10<00:09, 326.09it/s] 51%|█████▏    | 3409/6629 [00:10<00:09, 325.70it/s] 52%|█████▏    | 3442/6629 [00:10<00:09, 326.72it/s] 52%|█████▏    | 3475/6629 [00:10<00:09, 325.93it/s] 53%|█████▎    | 3508/6629 [00:10<00:09, 325.44it/s] 53%|█████▎    | 3542/6629 [00:11<00:09, 327.21it/s] 54%|█████▍    | 3575/6629 [00:11<00:09, 327.50it/s] 54%|█████▍    | 3608/6629 [00:11<00:09, 327.27it/s] 55%|█████▍    | 3641/6629 [00:11<00:09, 327.35it/s] 55%|█████▌    | 3674/6629 [00:11<00:09, 327.64it/s] 56%|█████▌    | 3707/6629 [00:11<00:08, 326.63it/s] 56%|█████▋    | 3740/6629 [00:11<00:08, 325.82it/s] 57%|█████▋    | 3773/6629 [00:11<00:08, 327.03it/s] 57%|█████▋    | 3806/6629 [00:11<00:08, 326.81it/s] 58%|█████▊    | 3839/6629 [00:11<00:08, 326.64it/s] 58%|█████▊    | 3872/6629 [00:12<00:08, 326.82it/s] 59%|█████▉    | 3905/6629 [00:12<00:08, 326.96it/s] 59%|█████▉    | 3938/6629 [00:12<00:08, 326.27it/s] 60%|█████▉    | 3971/6629 [00:12<00:08, 326.82it/s] 60%|██████    | 4005/6629 [00:12<00:08, 327.79it/s] 61%|██████    | 4038/6629 [00:12<00:07, 324.84it/s] 61%|██████▏   | 4071/6629 [00:12<00:07, 323.90it/s] 62%|██████▏   | 4104/6629 [00:12<00:07, 325.05it/s] 62%|██████▏   | 4137/6629 [00:12<00:07, 326.18it/s] 63%|██████▎   | 4171/6629 [00:13<00:07, 327.76it/s] 63%|██████▎   | 4205/6629 [00:13<00:07, 328.48it/s] 64%|██████▍   | 4238/6629 [00:13<00:07, 327.69it/s] 64%|██████▍   | 4271/6629 [00:13<00:07, 328.01it/s] 65%|██████▍   | 4304/6629 [00:13<00:07, 328.56it/s] 65%|██████▌   | 4337/6629 [00:13<00:07, 326.29it/s] 66%|██████▌   | 4370/6629 [00:13<00:06, 326.24it/s] 66%|██████▋   | 4403/6629 [00:13<00:06, 327.32it/s] 67%|██████▋   | 4436/6629 [00:13<00:06, 326.74it/s] 67%|██████▋   | 4469/6629 [00:13<00:06, 326.82it/s] 68%|██████▊   | 4502/6629 [00:14<00:06, 326.84it/s] 68%|██████▊   | 4535/6629 [00:14<00:06, 326.08it/s] 69%|██████▉   | 4568/6629 [00:14<00:06, 325.57it/s] 69%|██████▉   | 4601/6629 [00:14<00:06, 325.65it/s] 70%|██████▉   | 4634/6629 [00:14<00:06, 325.25it/s] 70%|███████   | 4667/6629 [00:14<00:06, 325.16it/s] 71%|███████   | 4700/6629 [00:14<00:05, 326.04it/s] 71%|███████▏  | 4733/6629 [00:14<00:05, 326.80it/s] 72%|███████▏  | 4766/6629 [00:14<00:05, 327.28it/s] 72%|███████▏  | 4799/6629 [00:14<00:05, 324.64it/s] 73%|███████▎  | 4832/6629 [00:15<00:05, 324.28it/s] 73%|███████▎  | 4865/6629 [00:15<00:05, 323.83it/s] 74%|███████▍  | 4898/6629 [00:15<00:05, 324.24it/s] 74%|███████▍  | 4931/6629 [00:15<00:05, 325.50it/s] 75%|███████▍  | 4964/6629 [00:15<00:05, 325.51it/s] 75%|███████▌  | 4997/6629 [00:15<00:05, 325.45it/s] 76%|███████▌  | 5030/6629 [00:15<00:04, 325.33it/s] 76%|███████▋  | 5063/6629 [00:15<00:04, 325.78it/s] 77%|███████▋  | 5096/6629 [00:15<00:04, 325.65it/s] 77%|███████▋  | 5129/6629 [00:15<00:04, 326.23it/s] 78%|███████▊  | 5162/6629 [00:16<00:04, 326.25it/s] 78%|███████▊  | 5195/6629 [00:16<00:04, 325.57it/s] 79%|███████▉  | 5228/6629 [00:16<00:04, 325.85it/s] 79%|███████▉  | 5261/6629 [00:16<00:04, 325.34it/s] 80%|███████▉  | 5294/6629 [00:16<00:04, 324.73it/s] 80%|████████  | 5327/6629 [00:16<00:03, 325.64it/s] 81%|████████  | 5360/6629 [00:16<00:03, 326.71it/s] 81%|████████▏ | 5393/6629 [00:16<00:03, 326.73it/s] 82%|████████▏ | 5426/6629 [00:16<00:03, 325.66it/s] 82%|████████▏ | 5459/6629 [00:16<00:03, 326.85it/s] 83%|████████▎ | 5492/6629 [00:17<00:03, 326.31it/s] 83%|████████▎ | 5525/6629 [00:17<00:03, 326.77it/s] 84%|████████▍ | 5558/6629 [00:17<00:03, 327.35it/s] 84%|████████▍ | 5591/6629 [00:17<00:03, 327.90it/s] 85%|████████▍ | 5624/6629 [00:17<00:03, 326.03it/s] 85%|████████▌ | 5657/6629 [00:17<00:02, 326.94it/s] 86%|████████▌ | 5690/6629 [00:17<00:02, 327.44it/s] 86%|████████▋ | 5723/6629 [00:17<00:02, 327.02it/s] 87%|████████▋ | 5756/6629 [00:17<00:02, 327.52it/s] 87%|████████▋ | 5790/6629 [00:17<00:02, 328.39it/s] 88%|████████▊ | 5823/6629 [00:18<00:02, 328.51it/s] 88%|████████▊ | 5856/6629 [00:18<00:02, 328.45it/s] 89%|████████▉ | 5889/6629 [00:18<00:02, 328.53it/s] 89%|████████▉ | 5922/6629 [00:18<00:02, 327.87it/s] 90%|████████▉ | 5955/6629 [00:18<00:02, 328.29it/s] 90%|█████████ | 5988/6629 [00:18<00:01, 326.81it/s] 91%|█████████ | 6021/6629 [00:18<00:01, 326.12it/s] 91%|█████████▏| 6054/6629 [00:18<00:01, 327.00it/s] 92%|█████████▏| 6087/6629 [00:18<00:01, 326.72it/s] 92%|█████████▏| 6120/6629 [00:18<00:01, 326.75it/s] 93%|█████████▎| 6153/6629 [00:19<00:01, 327.20it/s] 93%|█████████▎| 6186/6629 [00:19<00:01, 327.51it/s] 94%|█████████▍| 6219/6629 [00:19<00:01, 327.24it/s] 94%|█████████▍| 6252/6629 [00:19<00:01, 326.90it/s] 95%|█████████▍| 6285/6629 [00:19<00:01, 327.25it/s] 95%|█████████▌| 6318/6629 [00:19<00:00, 327.78it/s] 96%|█████████▌| 6351/6629 [00:19<00:00, 327.93it/s] 96%|█████████▋| 6385/6629 [00:19<00:00, 328.65it/s] 97%|█████████▋| 6418/6629 [00:19<00:00, 328.26it/s] 97%|█████████▋| 6451/6629 [00:19<00:00, 327.67it/s] 98%|█████████▊| 6484/6629 [00:20<00:00, 327.58it/s] 98%|█████████▊| 6517/6629 [00:20<00:00, 327.23it/s] 99%|█████████▉| 6550/6629 [00:20<00:00, 327.32it/s] 99%|█████████▉| 6583/6629 [00:20<00:00, 327.46it/s]100%|█████████▉| 6616/6629 [00:20<00:00, 327.48it/s]100%|██████████| 6629/6629 [00:20<00:00, 322.89it/s]AVERAGE DENSITY :0.0
2022-03-23 18:54:35 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 18:54:35 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 18:54:35 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 18:54:35 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-23 18:54:35 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 18:54:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 18:54:35 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 18:54:35 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 18:54:35 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 18:54:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 18:54:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:54:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 18:54:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:54:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 18:54:36 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 18:54:36 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_last.pt
2022-03-23 18:54:36 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_last.pt
2022-03-23 18:54:36 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 18:54:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:54:36 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:54:36 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 18:54:36 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 18:54:36 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 18:54:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 18:54:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 18:54:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 18:55:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 18:59:32 | INFO | train_inner | epoch 001:    104 / 157 loss=11.349, ppl=2609.15, wps=8819.9, ups=0.35, wpb=25102.3, bsz=1072.9, num_updates=100, lr=1.25e-05, gnorm=3.645, loss_scale=8, train_wall=296, gb_free=13.2, wall=297
2022-03-23 19:02:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-23 19:02:05 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 19:02:05 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:02:09 | INFO | fairseq.tasks.translation | example hypothesis: ....
2022-03-23 19:02:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:02:14 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,
2022-03-23 19:02:14 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:02:19 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,
2022-03-23 19:02:19 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:02:26 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:02:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:02:33 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:02:33 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:02:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:02:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:02:48 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:02:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:02:57 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:02:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:03:00 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:03:00 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.686 | ppl 823.99 | bleu 0.01 | wps 2967.9 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 19:03:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 19:03:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:03:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:03:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 0.863530192989856 seconds)
2022-03-23 19:03:00 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 19:03:00 | INFO | train | epoch 001 | loss 10.961 | ppl 1992.85 | wps 7768.5 | ups 0.31 | wpb 25032.1 | bsz 994.6 | num_updates 153 | lr 1.9125e-05 | gnorm 2.823 | loss_scale 8 | train_wall 443 | gb_free 13.5 | wall 505
2022-03-23 19:03:01 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 19:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:05:13 | INFO | train_inner | epoch 002:     47 / 157 loss=9.95, ppl=989.16, wps=7329.2, ups=0.29, wpb=24932.2, bsz=929.7, num_updates=200, lr=2.5e-05, gnorm=1.307, loss_scale=8, train_wall=279, gb_free=22.4, wall=637
2022-03-23 19:09:52 | INFO | train_inner | epoch 002:    147 / 157 loss=9.085, ppl=543.01, wps=8953.6, ups=0.36, wpb=25036.7, bsz=1005.3, num_updates=300, lr=3.75e-05, gnorm=1.359, loss_scale=8, train_wall=279, gb_free=13.5, wall=917
2022-03-23 19:10:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:10:26 | INFO | fairseq.tasks.translation | example hypothesis: ,,,.
2022-03-23 19:10:26 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:10:32 | INFO | fairseq.tasks.translation | example hypothesis: a a a a a a a.
2022-03-23 19:10:32 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:10:38 | INFO | fairseq.tasks.translation | example hypothesis: i i i i i i i i i i i i i i i i i.
2022-03-23 19:10:38 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:10:43 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,.
2022-03-23 19:10:43 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:10:50 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we we we we we we we we we we we we we we we we we we we we we we
2022-03-23 19:10:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:10:57 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:10:57 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:11:05 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:11:12 | INFO | fairseq.tasks.translation | example hypothesis: the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:11:21 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:11:24 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:11:24 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.643 | ppl 399.75 | bleu 0.01 | wps 2853.7 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.01
2022-03-23 19:11:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 19:11:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:11:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.01) (writing took 0.826326169015374 seconds)
2022-03-23 19:11:25 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 19:11:25 | INFO | train | epoch 002 | loss 9.228 | ppl 599.47 | wps 7834 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 1.368 | loss_scale 8 | train_wall 440 | gb_free 13.6 | wall 1009
2022-03-23 19:11:25 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 19:11:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:15:34 | INFO | train_inner | epoch 003:     90 / 157 loss=8.743, ppl=428.53, wps=7292.8, ups=0.29, wpb=24927.4, bsz=966.7, num_updates=400, lr=5e-05, gnorm=1.417, loss_scale=8, train_wall=278, gb_free=13.4, wall=1258
2022-03-23 19:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:18:51 | INFO | fairseq.tasks.translation | example hypothesis: 's.
2022-03-23 19:18:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:18:56 | INFO | fairseq.tasks.translation | example hypothesis: 's a a.
2022-03-23 19:18:56 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:19:03 | INFO | fairseq.tasks.translation | example hypothesis: i, i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i
2022-03-23 19:19:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:19:10 | INFO | fairseq.tasks.translation | example hypothesis: was was was was, was was was was was was was was was was was was was was was was was was was was was was was was was was.
2022-03-23 19:19:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:19:17 | INFO | fairseq.tasks.translation | example hypothesis: , we we we we we we we we we we we we we we we we we we we we we we we we we we we we we, we we we we we we we we we we we we we we we we we we
2022-03-23 19:19:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:19:25 | INFO | fairseq.tasks.translation | example hypothesis: , we we we we we we we we we we we we we we we we we we we we we we we we we we we we we to to to to to to to to to to to to to to to to to to to to to to to to to to to to to
2022-03-23 19:19:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:19:33 | INFO | fairseq.tasks.translation | example hypothesis: , you you you you you you you you you you you you you you you you the the the the the the the the, it it it it it it it it it it it it it it it it it it it it it it it's's's's's's's's's's's's's's's's's's's's's's's
2022-03-23 19:19:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:19:42 | INFO | fairseq.tasks.translation | example hypothesis: , we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we we the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:19:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:19:51 | INFO | fairseq.tasks.translation | example hypothesis: 's, "" "" "," "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 19:19:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:19:54 | INFO | fairseq.tasks.translation | example hypothesis: , we we we we the, we we we we we we we we we we we we we we we we the the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to the the the the the the the the the the to to to to to to to to to to to to to to to to to to to to to to to to to that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that
2022-03-23 19:19:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:19:54 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.377 | ppl 332.47 | bleu 0.05 | wps 2593.2 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.05
2022-03-23 19:19:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 19:19:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:19:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:19:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.05) (writing took 0.8589729150116909 seconds)
2022-03-23 19:19:54 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 19:19:54 | INFO | train | epoch 003 | loss 8.614 | ppl 391.84 | wps 7746.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.415 | loss_scale 8 | train_wall 440 | gb_free 14.3 | wall 1519
2022-03-23 19:19:55 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 19:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:21:28 | INFO | train_inner | epoch 004:     33 / 157 loss=8.467, ppl=353.88, wps=7230.8, ups=0.28, wpb=25598.5, bsz=1067.8, num_updates=500, lr=6.25e-05, gnorm=1.546, loss_scale=8, train_wall=284, gb_free=13.4, wall=1612
2022-03-23 19:26:09 | INFO | train_inner | epoch 004:    133 / 157 loss=8.122, ppl=278.59, wps=8974.5, ups=0.36, wpb=25215.5, bsz=1096.9, num_updates=600, lr=7.5e-05, gnorm=1.598, loss_scale=8, train_wall=281, gb_free=13.8, wall=1893
2022-03-23 19:27:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:27:21 | INFO | fairseq.tasks.translation | example hypothesis: if you can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:27:21 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:27:28 | INFO | fairseq.tasks.translation | example hypothesis: he he he he he he he he he he he he he he he he he he he he he he he he he he he.
2022-03-23 19:27:28 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:27:35 | INFO | fairseq.tasks.translation | example hypothesis: i think, i think, i think to think, i think to think to be be be be a lot of a lot of a lot.
2022-03-23 19:27:35 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:27:42 | INFO | fairseq.tasks.translation | example hypothesis: he he was was was was was was was was he was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was was
2022-03-23 19:27:42 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:27:50 | INFO | fairseq.tasks.translation | example hypothesis: we know, we know, we know, we know, we know, and we know, we know, and we know, and we know, we know, we know, we know to do we know, and we know, and we
2022-03-23 19:27:50 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:27:58 | INFO | fairseq.tasks.translation | example hypothesis: we know, and we can can can can can can can can can can can can can can can can't't't't't't't't't't't't't can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:27:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:28:06 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not not not, but you have the world, and you're the world, and they're're're're're're're're're not not not not not not not not have the world, but but they're're're're're're're're the world, and it's the world.
2022-03-23 19:28:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:28:14 | INFO | fairseq.tasks.translation | example hypothesis: we have the world, and we can can can can can can see the world, and we have the world, and we can can see the world, and we can see the world of the world, and we can can can can can can can can see the world of the world of the world of the world of the world of the world, and we can can can can can can can can can see the world of the world, and we can see the world
2022-03-23 19:28:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:28:23 | INFO | fairseq.tasks.translation | example hypothesis: we said, "it's a lot," we've've've said, "we've've've said," it's going to said, "we've've've've've said," "we've've've've've've said," "it's going to said," it's going to said, and it's going to said, "" "" "" "" "it's going to be be be be be be be be be be be be be to do," "it's the world," "" "" "it's the world, and it's, and it's the world, and it's a lot," "" "" "" "" "" "" "" "" "" "" "" we've've've've said, and it's going to be be be be be be be be be be be be be a
2022-03-23 19:28:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:28:26 | INFO | fairseq.tasks.translation | example hypothesis: , we've've've that we've've've've've've've've've've've've've've've've have the world, and it's a lot of the world, and it's the world, and it's the world, and we have the world, and it's the world of the world of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's the world, and we have the world, and we have the world, and it's the world, and we're the world, and it's a lot of the world, and we have the world, and it's a lot of the world, and we're're're're're be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be,
2022-03-23 19:28:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:28:26 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.807 | ppl 223.89 | bleu 0.83 | wps 2515.1 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 0.83
2022-03-23 19:28:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 19:28:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 4 @ 624 updates, score 0.83) (writing took 0.8325339950388297 seconds)
2022-03-23 19:28:26 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 19:28:26 | INFO | train | epoch 004 | loss 8.213 | ppl 296.76 | wps 7711.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.626 | loss_scale 8 | train_wall 440 | gb_free 14 | wall 2031
2022-03-23 19:28:27 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 19:28:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:31:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 19:32:04 | INFO | train_inner | epoch 005:     77 / 157 loss=7.796, ppl=222.19, wps=7066.6, ups=0.28, wpb=25082.2, bsz=1060.2, num_updates=700, lr=8.75e-05, gnorm=1.838, loss_scale=4, train_wall=283, gb_free=13.5, wall=2248
2022-03-23 19:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:35:54 | INFO | fairseq.tasks.translation | example hypothesis: you can can can can can't be.
2022-03-23 19:35:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:36:01 | INFO | fairseq.tasks.translation | example hypothesis: he can can he can be a few years.
2022-03-23 19:36:01 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:36:08 | INFO | fairseq.tasks.translation | example hypothesis: i think, i can can be a lot of a lot of a lot of a lot of a lot of a lot of a lot of the world.
2022-03-23 19:36:08 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:36:15 | INFO | fairseq.tasks.translation | example hypothesis: he was he was me, he was a lot, he was a lot, he was been been been been been me, he was a lot.
2022-03-23 19:36:15 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:36:23 | INFO | fairseq.tasks.translation | example hypothesis: we know, what we're going to do, and we're going to do, and we know, and we're going to do, and we know, and we're going to do, and we know, and we're going to do
2022-03-23 19:36:23 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:36:31 | INFO | fairseq.tasks.translation | example hypothesis: we don't know, and we have to have to do, and we have to do, or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 19:36:31 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:36:39 | INFO | fairseq.tasks.translation | example hypothesis: if if you're not not not not, but it, but it, but it, but it, but they are not not not not not not not not not not not not not not not not not not not not not not not not not not not not not, but it, but it, but it, but it, but it, but it,
2022-03-23 19:36:39 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:36:47 | INFO | fairseq.tasks.translation | example hypothesis: we have a lot of the world, and we can see the world, and we can see, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and the world, and we can see the world,
2022-03-23 19:36:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:36:57 | INFO | fairseq.tasks.translation | example hypothesis: i said, "" i said, "i said," i said, "i said," i said, "i said," i said, "" "i said," "" i said, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "you said," i said, "i said," i said, "i said," i said, "i said," "" "" "i said," "i said," "" "" "" "" "" "" "i said," i said, "" i said, "" "" "" "" "" "" "" "we said," i said, "i said," i said, "" "" "i said," "" "
2022-03-23 19:36:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:36:59 | INFO | fairseq.tasks.translation | example hypothesis: i think, if we think, that we have to see the world, that we have to see the world, and the world, and the world, and the world, the first first first first first first first first first first first first first first first first first first first first first first first first first first first of the world, and the first first first of the world, and it, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and the world, and it's a lot of the world, and the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first of the first first first of the first first first first first first first first first first first first first first first first first first of the first of the first of the
2022-03-23 19:36:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:36:59 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.312 | ppl 158.89 | bleu 1.14 | wps 2511 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.14
2022-03-23 19:36:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 19:36:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:37:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:37:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.14) (writing took 0.8452863289858215 seconds)
2022-03-23 19:37:00 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 19:37:00 | INFO | train | epoch 005 | loss 7.69 | ppl 206.52 | wps 7644.6 | ups 0.3 | wpb 25157.3 | bsz 1025.1 | num_updates 780 | lr 9.75e-05 | gnorm 1.772 | loss_scale 4 | train_wall 441 | gb_free 13.2 | wall 2544
2022-03-23 19:37:00 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 19:37:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:37:57 | INFO | train_inner | epoch 006:     20 / 157 loss=7.625, ppl=197.44, wps=7115.2, ups=0.28, wpb=25109.9, bsz=964.5, num_updates=800, lr=0.0001, gnorm=1.717, loss_scale=4, train_wall=280, gb_free=13.6, wall=2601
2022-03-23 19:42:37 | INFO | train_inner | epoch 006:    120 / 157 loss=7.392, ppl=167.97, wps=8936.7, ups=0.36, wpb=25050.4, bsz=929.7, num_updates=900, lr=0.0001125, gnorm=1.553, loss_scale=4, train_wall=280, gb_free=13.5, wall=2882
2022-03-23 19:44:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:44:27 | INFO | fairseq.tasks.translation | example hypothesis: you can can can't be.
2022-03-23 19:44:27 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:44:32 | INFO | fairseq.tasks.translation | example hypothesis: he can can be a year.
2022-03-23 19:44:32 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:44:38 | INFO | fairseq.tasks.translation | example hypothesis: i can can't be a lot of the way that can be a lot of the way.
2022-03-23 19:44:38 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:44:45 | INFO | fairseq.tasks.translation | example hypothesis: he was his father, because he was been been been been been been been been been been been been been been been been been been been been been been been him.
2022-03-23 19:44:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:44:51 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do, and we're going to do this is what we're going to do, and we're going to do?
2022-03-23 19:44:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:44:59 | INFO | fairseq.tasks.translation | example hypothesis: we're going to talk about the world, and we're going to have to do the world, and we're going to have to do the world.
2022-03-23 19:44:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:45:06 | INFO | fairseq.tasks.translation | example hypothesis: if if if if if you're going to see the way, but they're not just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just just the way.
2022-03-23 19:45:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:45:14 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see the world, and we're going to see the world, and we're going to see the world, and we can see the world, and we can see the world, and we can see that we can see that we can see the world, we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the world, and we can see the
2022-03-23 19:45:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:45:24 | INFO | fairseq.tasks.translation | example hypothesis: he said, "i said," we said, "i said," we said, "we said," i said, "we said," we said, "he said," we said, "we said," he said, "we said," he said, "we said," i said, "we said," we said, "we said," i said, "we said," he said, "we said," he said, "we said," we said, "we said," we said, "we said," i said, "we said," we said, "we said," we said, "we said," we said, "we said," he said, "we said," he said, "i said," he said, "we said," he said, "we're going to
2022-03-23 19:45:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:45:26 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to see that we're going to see the world, and we're going to see the world, and we're going to see that we're going to see the world, and we're going to see the world, and we're going to be a lot of the world, and we're going to see the world, and we're going to be a lot of the world, and we're going to be a lot of the world, which we're going to be a lot of the world, and we're going to see that we're going to see the world, and we're going to be a lot of the world, and we're going to see that we're going to be a lot of the world, and we're going to be a lot of the world, which we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world of the world, and
2022-03-23 19:45:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:45:26 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.931 | ppl 122 | bleu 1.7 | wps 2740.3 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.7
2022-03-23 19:45:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 19:45:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.7) (writing took 0.805334310978651 seconds)
2022-03-23 19:45:27 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 19:45:27 | INFO | train | epoch 006 | loss 7.286 | ppl 156.09 | wps 7783.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.577 | loss_scale 4 | train_wall 440 | gb_free 14.2 | wall 3052
2022-03-23 19:45:28 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 19:45:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:48:22 | INFO | train_inner | epoch 007:     63 / 157 loss=7.038, ppl=131.42, wps=7252.1, ups=0.29, wpb=24987.9, bsz=1060.7, num_updates=1000, lr=0.000125, gnorm=1.355, loss_scale=4, train_wall=278, gb_free=13.4, wall=3226
2022-03-23 19:52:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:52:52 | INFO | fairseq.tasks.translation | example hypothesis: you can't use this.
2022-03-23 19:52:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 19:52:58 | INFO | fairseq.tasks.translation | example hypothesis: he's a year in the year.
2022-03-23 19:52:58 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 19:53:04 | INFO | fairseq.tasks.translation | example hypothesis: i can't have a lot of course.
2022-03-23 19:53:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 19:53:10 | INFO | fairseq.tasks.translation | example hypothesis: he said, he was never never never never never never been been been been been been been been been been been been been been been been been been been been.
2022-03-23 19:53:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 19:53:17 | INFO | fairseq.tasks.translation | example hypothesis: what we have a lot of what we have to do, and we have a lot of what we have to do?
2022-03-23 19:53:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 19:53:24 | INFO | fairseq.tasks.translation | example hypothesis: we don't know about our time, or we're going to do our time, or we're going to do our time.
2022-03-23 19:53:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 19:53:31 | INFO | fairseq.tasks.translation | example hypothesis: if you have a lot of the way, but you can see, but you have a lot of the way, but you can see, but you're not have a lot of the way, but you can see, but you're not have a lot of the way, but you can see, but you can see, but you're not have a lot
2022-03-23 19:53:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:53:40 | INFO | fairseq.tasks.translation | example hypothesis: we can see that, and we can see that, and we can see that, and we can see that, and we can see that we can see that, and we can see that, and we can see, and we can see, and we can see that, and we can see that, and we can see that, and we can see, and we can see that, we can see the way, and we can see that we can see that the
2022-03-23 19:53:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:53:49 | INFO | fairseq.tasks.translation | example hypothesis: the "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-23 19:53:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:53:51 | INFO | fairseq.tasks.translation | example hypothesis: if you have a lot of the way that we're going to see that, and we're going to be a lot of the way that we're going to see that we're going to be a lot of the way, and we're going to be, and we're going to see that we're going to be a lot of the way that we're going to do that we're going to be a lot of the middle of the way, and that we're going to be able to be a lot of the middle of the way, and that we're going to be, which is that we're going to be a lot of the way, and we're going to do that we're going to do that we're going to do that we're going to be a lot of the middle of the way, and we're going to be a lot of the way that we're going to do that we're going to be a lot of the way, and that we're going to do that we're going to be a lot of the way, and the
2022-03-23 19:53:51 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:53:51 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.659 | ppl 101.07 | bleu 2.13 | wps 2751.3 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 2.13
2022-03-23 19:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 19:53:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 19:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 7 @ 1094 updates, score 2.13) (writing took 0.8127724300138652 seconds)
2022-03-23 19:53:52 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 19:53:52 | INFO | train | epoch 007 | loss 6.96 | ppl 124.52 | wps 7820.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.401 | loss_scale 4 | train_wall 438 | gb_free 13.4 | wall 3557
2022-03-23 19:53:53 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 19:53:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:54:09 | INFO | train_inner | epoch 008:      6 / 157 loss=6.88, ppl=117.8, wps=7297.8, ups=0.29, wpb=25346.2, bsz=1050.7, num_updates=1100, lr=0.0001375, gnorm=1.439, loss_scale=4, train_wall=281, gb_free=14.9, wall=3573
2022-03-23 19:58:48 | INFO | train_inner | epoch 008:    106 / 157 loss=6.726, ppl=105.88, wps=8976.9, ups=0.36, wpb=25024.9, bsz=1025.3, num_updates=1200, lr=0.00015, gnorm=1.424, loss_scale=4, train_wall=278, gb_free=22.4, wall=3852
2022-03-23 20:01:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:01:18 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able to use a new way.
2022-03-23 20:01:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:01:24 | INFO | fairseq.tasks.translation | example hypothesis: he can be a year.
2022-03-23 20:01:24 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:01:30 | INFO | fairseq.tasks.translation | example hypothesis: so, i can't have to make a lot of course, because i can make it.
2022-03-23 20:01:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:01:36 | INFO | fairseq.tasks.translation | example hypothesis: he didn't had his father, because he had his father was his father.
2022-03-23 20:01:36 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:01:44 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a friend, what we're going to do with what we're going to do with what we're going to do?
2022-03-23 20:01:44 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:01:50 | INFO | fairseq.tasks.translation | example hypothesis: we're going to talk about how to talk about the world or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or
2022-03-23 20:01:50 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:01:57 | INFO | fairseq.tasks.translation | example hypothesis: some of these are some of them, but if you're not not going to get a lot of the way, but they're not not not not going to look at the way, but they're going to make it, but it, but they're not not not not not not not not not not not not not like it.
2022-03-23 20:01:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:02:05 | INFO | fairseq.tasks.translation | example hypothesis: if we look at the world, we can see that, if we can make a kind of the way, we can see that we can make a kind of a kind of the brain, we can see that we can see that we can make a kind of the kind of a kind of the brain, and we can see that we can see that we can see that we can make a kind of a kind of a kind of a kind of a kind of the way
2022-03-23 20:02:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:02:13 | INFO | fairseq.tasks.translation | example hypothesis: one: "one of you say," if you're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, because we're going to say, "well," we're going to say, "well," well, "well, we're going to say, we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," well, "
2022-03-23 20:02:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:02:16 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the way that we're going to get to get a lot of people, because we're going to get a lot of the way that we're going to get to get a lot of the way that we're going to make it, or that we're going to get a lot of the way that we're going to get to get to get to get to get to get to get to get to make it, or a lot of the way to get to get to get to get to get to get to get to get to get a lot of the way, or a kind of the same way that we're going to get a kind of the way to get a little bit of the way that we're going to get to get to get a kind of the way that we're going to get to get to get a lot of the way that we're going to get a kind of the way that we're going to get to get to get to get to get a kind of that we're going to get a kind of the way that
2022-03-23 20:02:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:02:16 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.402 | ppl 84.56 | bleu 3.03 | wps 2818.7 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 3.03
2022-03-23 20:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 20:02:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:02:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:02:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 8 @ 1251 updates, score 3.03) (writing took 0.7472612169804052 seconds)
2022-03-23 20:02:17 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 20:02:17 | INFO | train | epoch 008 | loss 6.724 | ppl 105.74 | wps 7830.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.504 | loss_scale 4 | train_wall 439 | gb_free 13.6 | wall 4061
2022-03-23 20:02:17 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 20:02:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:04:33 | INFO | train_inner | epoch 009:     49 / 157 loss=6.633, ppl=99.23, wps=7305.2, ups=0.29, wpb=25186.9, bsz=1004.9, num_updates=1300, lr=0.0001625, gnorm=1.589, loss_scale=4, train_wall=279, gb_free=13.2, wall=4197
2022-03-23 20:09:15 | INFO | train_inner | epoch 009:    149 / 157 loss=6.446, ppl=87.2, wps=8961.8, ups=0.35, wpb=25327, bsz=1022.6, num_updates=1400, lr=0.000175, gnorm=1.35, loss_scale=4, train_wall=282, gb_free=13.5, wall=4480
2022-03-23 20:09:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:09:42 | INFO | fairseq.tasks.translation | example hypothesis: these can't be able.
2022-03-23 20:09:42 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:09:48 | INFO | fairseq.tasks.translation | example hypothesis: he's going to do it in the last year.
2022-03-23 20:09:48 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:09:54 | INFO | fairseq.tasks.translation | example hypothesis: this is that i can be able to be a lot of course.
2022-03-23 20:09:54 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:10:00 | INFO | fairseq.tasks.translation | example hypothesis: he didn't know he had his father, because he was his father, because she had his father had his father, she was his father.
2022-03-23 20:10:00 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:10:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my mother is a mother, and my mother's a little bit of my mother and said, and what we said, "well, what we do?
2022-03-23 20:10:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:10:14 | INFO | fairseq.tasks.translation | example hypothesis: we're going to do our time, our time, our time, or our time, or our time, or we don't think about the same time, or the same time, or or or or the other other things about the other or or or or or or or or or or the
2022-03-23 20:10:14 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:10:22 | INFO | fairseq.tasks.translation | example hypothesis: some of them are some of them, but they don't look at the way, but they don't look at the way, but they don't look like it, but if they don't get it, but they don't look like it, but they don't look like it, but they don't look like it, but they don't look like
2022-03-23 20:10:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:10:30 | INFO | fairseq.tasks.translation | example hypothesis: if we look at this information, we can see the information of these kinds of these kinds of these kinds of the information, and we can see that we can see that, and then we can make a kind of the way that we can make a kind of the way, and then we can see that we can see that we can make a kind of the structure of the way of the way to make it, and create a kind of the structure of these kinds of
2022-03-23 20:10:30 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:10:39 | INFO | fairseq.tasks.translation | example hypothesis: one: "one of the one of the one of the one of the one of the one of the example," and it's going to say, "and it's going to say," we said, "well," we said, "well," we said, "well," we said, "well," well, "well," well, "well," well, "well," well, "well," we said, "we said," well, "well," well, "well," well, "well," well, "well," well, "it's going to say," we're going to say, "it's going to say," we're going to say, "we're going to say," we're going to say, "we're going to say," we're going to say, ""
2022-03-23 20:10:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:10:41 | INFO | fairseq.tasks.translation | example hypothesis: that's the way of course, the mother is the mother, and the way that we've got to get a little bit of the way, and if we've got to have a few years, if we're going to have a little bit of the way that we're going to do that we're going to get to get to get to get a lot of a little bit of the way to get to be a lot of the way to get to be a lot of the way to be a lot of the way, and then we've got to get a lot of the way, and then we've got to get a lot of the way to get a few years, and then we're going to get a little bit of the way to get a lot of the way to get a lot of the way to do that we've got to get a lot of the way that we've got to get a few years, and then we're going to do that we've got to have a lot of the way to get a lot of the way to get a
2022-03-23 20:10:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:10:41 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.129 | ppl 70 | bleu 3.6 | wps 2769.3 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.6
2022-03-23 20:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 20:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.6) (writing took 0.7584456030162983 seconds)
2022-03-23 20:10:42 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 20:10:42 | INFO | train | epoch 009 | loss 6.463 | ppl 88.2 | wps 7809.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.411 | loss_scale 4 | train_wall 440 | gb_free 13.7 | wall 4567
2022-03-23 20:10:43 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 20:10:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:15:05 | INFO | train_inner | epoch 010:     92 / 157 loss=6.168, ppl=71.9, wps=7279.5, ups=0.29, wpb=25477.1, bsz=1096.5, num_updates=1500, lr=0.0001875, gnorm=1.53, loss_scale=4, train_wall=284, gb_free=12.2, wall=4830
2022-03-23 20:18:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:18:09 | INFO | fairseq.tasks.translation | example hypothesis: these can't use these cells.
2022-03-23 20:18:09 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:18:15 | INFO | fairseq.tasks.translation | example hypothesis: the year, he can be about 30,000 miles.
2022-03-23 20:18:15 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:18:21 | INFO | fairseq.tasks.translation | example hypothesis: so, these kinds of course, i can see a lot of course.
2022-03-23 20:18:21 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:18:27 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, because he had his father, his father was his father with his father.
2022-03-23 20:18:27 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:18:33 | INFO | fairseq.tasks.translation | example hypothesis: one of my father is a mother and a lot of mother and a child, and we said, "well, what we're doing?
2022-03-23 20:18:33 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:18:39 | INFO | fairseq.tasks.translation | example hypothesis: our time, our time we're talking about our time, and the same time, or not about the time.
2022-03-23 20:18:39 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:18:46 | INFO | fairseq.tasks.translation | example hypothesis: some of them are looking at the gly, but if you don't know, but it doesn't need to use the energy, but if you don't need to use the energy, but it doesn't need it.
2022-03-23 20:18:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:18:53 | INFO | fairseq.tasks.translation | example hypothesis: if we look at the information of information, we can use this information, and we can see a little bit of information, and then we can use the structure of the structure, and all of the structure.
2022-03-23 20:18:53 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:19:00 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons, and it's interesting to say, "well," well, "well," if we're going to say, "well," well, "well," well, "well," well, "if we're going to say," well, "well," well, "well," well, "well," well, "well," if we're going to tell you want to tell you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "well," well, "well,"], "well," you know, "you're going to tell you know," you know, "you know," for you know, "you know,"
2022-03-23 20:19:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:19:02 | INFO | fairseq.tasks.translation | example hypothesis: for course, it's always always always a lot of science, and the internet, and if we were able to make a new idea that we were able to create a new idea that we're going to have a new idea that we're going to have to have a new idea that we're going to have to have a new idea that we're going to have to have a lot of the system, or a new idea that we're going to have a new idea that we're going to have a new idea that we're going to have to do, or a new idea that we're going to create a new idea that we're going to have a new idea that we're going to have a new idea that we're going to have a new idea that we're going to have a new idea that we're going to have a lot of the way that we're going to have a new idea that we're going to have a new idea that we're going to have to have to do, or a lot of the way, or or or or or a
2022-03-23 20:19:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:19:02 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.69 | ppl 51.61 | bleu 6.93 | wps 3078.6 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.93
2022-03-23 20:19:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 20:19:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:19:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.93) (writing took 0.7942409749957733 seconds)
2022-03-23 20:19:03 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 20:19:03 | INFO | train | epoch 010 | loss 6.183 | ppl 72.64 | wps 7887.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.43 | loss_scale 4 | train_wall 440 | gb_free 13 | wall 5067
2022-03-23 20:19:03 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 20:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:20:43 | INFO | train_inner | epoch 011:     35 / 157 loss=6.141, ppl=70.55, wps=7364.2, ups=0.3, wpb=24864.8, bsz=936, num_updates=1600, lr=0.0002, gnorm=1.366, loss_scale=4, train_wall=277, gb_free=22.4, wall=5167
2022-03-23 20:25:24 | INFO | train_inner | epoch 011:    135 / 157 loss=5.856, ppl=57.94, wps=8979.5, ups=0.36, wpb=25264, bsz=1018.2, num_updates=1700, lr=0.0002125, gnorm=1.372, loss_scale=4, train_wall=281, gb_free=13.9, wall=5449
2022-03-23 20:26:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:26:30 | INFO | fairseq.tasks.translation | example hypothesis: this can't be able to use these materials.
2022-03-23 20:26:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:26:36 | INFO | fairseq.tasks.translation | example hypothesis: last year, he can be about about 70,000 miles in the house.
2022-03-23 20:26:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:26:42 | INFO | fairseq.tasks.translation | example hypothesis: so, these kinds of course, i can also also also also be able to be a lot of course of course.
2022-03-23 20:26:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:26:48 | INFO | fairseq.tasks.translation | example hypothesis: he had never seen his father, because he had his father, because his father had his father was his father when she had his father.
2022-03-23 20:26:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:26:55 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is, and i've got a lot of aids, and a child has got a child, and we said, what we do?
2022-03-23 20:26:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:27:01 | INFO | fairseq.tasks.translation | example hypothesis: so our time we have our time about time about things like things like the same time, and we don't talk about how to talk about the past or three years.
2022-03-23 20:27:01 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:27:08 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of them are looking at the same way, but it's not going to take the same way, but if you don't need to make it.
2022-03-23 20:27:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:27:14 | INFO | fairseq.tasks.translation | example hypothesis: if we can use the information of information, the information that we can use the information of this information, we can make a little bit of the information, and then the information of the information and all of the information.
2022-03-23 20:27:14 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:27:20 | INFO | fairseq.tasks.translation | example hypothesis: of course, one of the reasons, the reasons that's interesting interesting interesting interesting thing for me, and it's really interesting for me to say, "let's say," well, "if we're going to say," well, "well," if we're going to tell you know, "well," well, "well," well, "well," well, "well," well, we're going to tell you know, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, we've got the next next next next next next next next next next next next next next next year, "and we're going to tell you know," well, "well, and we've got a young young young young young young
2022-03-23 20:27:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:27:22 | INFO | fairseq.tasks.translation | example hypothesis: for course, it's still still the mother, the mother, and the mother, and the great work of the work that we're going to make a lot of the problem that we're going to make a lot of the problem, and if we had to make it.
2022-03-23 20:27:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:27:22 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.513 | ppl 45.67 | bleu 8.3 | wps 3104.2 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.3
2022-03-23 20:27:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 20:27:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.3) (writing took 0.7742162539507262 seconds)
2022-03-23 20:27:23 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 20:27:23 | INFO | train | epoch 011 | loss 5.842 | ppl 57.37 | wps 7893.6 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.374 | loss_scale 4 | train_wall 440 | gb_free 13.3 | wall 5568
2022-03-23 20:27:24 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 20:27:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:31:10 | INFO | train_inner | epoch 012:     78 / 157 loss=5.46, ppl=44.03, wps=7421.1, ups=0.29, wpb=25628.6, bsz=1117, num_updates=1800, lr=0.000225, gnorm=1.321, loss_scale=4, train_wall=285, gb_free=14.3, wall=5794
2022-03-23 20:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:34:51 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use these chemical materials.
2022-03-23 20:34:51 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:34:57 | INFO | fairseq.tasks.translation | example hypothesis: the year can be about 888,000 miles in the restaurant.
2022-03-23 20:34:57 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:35:03 | INFO | fairseq.tasks.translation | example hypothesis: this pattern can be able to course, i can make a sense of course.
2022-03-23 20:35:03 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:35:10 | INFO | fairseq.tasks.translation | example hypothesis: he had his father, his father, because his father had his father, his father had his father with him.
2022-03-23 20:35:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:35:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my friends is a child, and a child has got a child, so we asked us, so what do?
2022-03-23 20:35:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:35:23 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about how things are not going to talk about the time, and not talk about poverty or poverty, or each other.
2022-03-23 20:35:23 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:35:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some of those are some of the mac, but it doesn't have to get out, but if you don't need to be able to be able to take your own energy, but if you don't need your power, you don't need to get your own energy, you need to be so that if you don't need to have to
2022-03-23 20:35:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:35:36 | INFO | fairseq.tasks.translation | example hypothesis: if we use information information, we can use the information, we can start with one of these kinds of interactions, and then we can start with a structure of information, which is the structure of information, and all the structure of information, which is all the information, and all the structure of information, which is a structure of information, which is a structure, and all the information, and all the structure of information.
2022-03-23 20:35:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:35:44 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons: the reasons, it's interesting to be interesting for me, and say, "oh, for me," oh, "yes," yes, "yes," yes, "oh, the best thing is that we've got to say," oh, "oh," the best time, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," oh, "oh," the best time, "oh," oh, "oh," oh, "the best," oh, "the best time," oh, "oh," oh, "oh," the best, "oh,"
2022-03-23 20:35:44 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:35:47 | INFO | fairseq.tasks.translation | example hypothesis: it's still still the mother of mother, and the part of the work that we were working on our work on our work, and we had to see that if you had to see that it was a big system that we had to see that if you had to take a whole system, we had to see that there was a huge system, to see that it was a huge system, the bottom of the bottom of the top of the bottom of the bottom of the bottom of the bottom of the system, the bottom of the bottom, the system, the bottom of a whole system, we had to see, we had to see, to see, we had to see that it was a whole system, to see that it was able to see that it was a whole system, the bottom of the bottom of a whole system, the bottom of the bottom of the bottom of a whole system, the bottom of the bottom of a whole system, the bottom of a whole system, the bottom of a whole system, we had to see that we had to see,
2022-03-23 20:35:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:35:47 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.046 | ppl 33.05 | bleu 9.81 | wps 2962.5 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.81
2022-03-23 20:35:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 20:35:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:35:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:35:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.81) (writing took 0.7631366029963829 seconds)
2022-03-23 20:35:47 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 20:35:47 | INFO | train | epoch 012 | loss 5.544 | ppl 46.64 | wps 7834.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.4 | loss_scale 4 | train_wall 441 | gb_free 13.3 | wall 6072
2022-03-23 20:35:48 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 20:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:36:48 | INFO | train_inner | epoch 013:     21 / 157 loss=5.565, ppl=47.33, wps=7283.4, ups=0.3, wpb=24629.9, bsz=935.6, num_updates=1900, lr=0.0002375, gnorm=1.436, loss_scale=4, train_wall=276, gb_free=13.6, wall=6132
2022-03-23 20:41:29 | INFO | train_inner | epoch 013:    121 / 157 loss=5.212, ppl=37.08, wps=8937.4, ups=0.36, wpb=25130.8, bsz=1047.4, num_updates=2000, lr=0.00025, gnorm=1.376, loss_scale=4, train_wall=281, gb_free=13.4, wall=6413
2022-03-23 20:43:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:43:14 | INFO | fairseq.tasks.translation | example hypothesis: these are not able to use chemical materials.
2022-03-23 20:43:14 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:43:20 | INFO | fairseq.tasks.translation | example hypothesis: then he can be about 8,000 days.
2022-03-23 20:43:20 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:43:25 | INFO | fairseq.tasks.translation | example hypothesis: these particles can be able to be able to be able to be able to make forms of forms.
2022-03-23 20:43:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:43:31 | INFO | fairseq.tasks.translation | example hypothesis: he had never seen his father because his father had been told him with him with him.
2022-03-23 20:43:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:43:36 | INFO | fairseq.tasks.translation | example hypothesis: one of my grandgrandaids has died and a child, so we asked us what do we do?
2022-03-23 20:43:36 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:43:42 | INFO | fairseq.tasks.translation | example hypothesis: so so we spend our time to talk about how things are not going to talk about the quality of poverty or other poverty.
2022-03-23 20:43:42 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:43:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to get out of the field, but if you don't like the energy, if you don't need the energy, so the energy is so the energy.
2022-03-23 20:43:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:43:54 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, we can use the reflection, we can start with one of the traditional patterns, and then we start able to start with the structure of the structure of information.
2022-03-23 20:43:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:44:00 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, it's interesting, and it's interesting for me to be here for me here, "yes, yes, it's the best time when we said," well, "well, we're going to tell you the best revolution."
2022-03-23 20:44:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:44:02 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still the mother, and the invention that we're working on our work on our airplane, we had to see that if we had to use the surface of a system that we had to use it.
2022-03-23 20:44:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:44:02 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.942 | ppl 30.73 | bleu 10.84 | wps 3404.9 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 10.84
2022-03-23 20:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 20:44:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:44:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:44:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 13 @ 2036 updates, score 10.84) (writing took 0.7576261319918558 seconds)
2022-03-23 20:44:03 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 20:44:03 | INFO | train | epoch 013 | loss 5.211 | ppl 37.05 | wps 7971.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.36 | loss_scale 4 | train_wall 440 | gb_free 13.6 | wall 6567
2022-03-23 20:44:03 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 20:44:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:47:08 | INFO | train_inner | epoch 014:     64 / 157 loss=5.009, ppl=32.2, wps=7520.9, ups=0.29, wpb=25533.6, bsz=1070, num_updates=2100, lr=0.0002625, gnorm=1.369, loss_scale=4, train_wall=284, gb_free=13.5, wall=6753
2022-03-23 20:51:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:51:30 | INFO | fairseq.tasks.translation | example hypothesis: this case can't use chemical chemical chemical chemical chemical chemical materials.
2022-03-23 20:51:30 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 20:51:36 | INFO | fairseq.tasks.translation | example hypothesis: he can be about 8,000 dollars in the restaurant.
2022-03-23 20:51:36 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 20:51:42 | INFO | fairseq.tasks.translation | example hypothesis: these magnetic magnetic magnetic particles can also be able to be a sense of course of course.
2022-03-23 20:51:42 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 20:51:48 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had never learned his mother, because she had his mother.
2022-03-23 20:51:48 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 20:51:55 | INFO | fairseq.tasks.translation | example hypothesis: one day, i've died at aids, and a child has died a child, so we asked us what do we do?
2022-03-23 20:51:55 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 20:52:02 | INFO | fairseq.tasks.translation | example hypothesis: so so so we spend our time to talk about how things are not going to talk about gender, or not about the end of poverty or poverty.
2022-03-23 20:52:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 20:52:09 | INFO | fairseq.tasks.translation | example hypothesis: first, first of course, some of the magnetic magnetic field in the field, but if you don't want to move the power of energy, if you don't need the power of energy and so that you need so much.
2022-03-23 20:52:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:52:16 | INFO | fairseq.tasks.translation | example hypothesis: if we use information from this information, we can use the reflection of these traditional patterns that we can start with the traditional information, and you can begin to get the structure of information, and all the information of the information, and the information that all of the information, and the information is the information that all the information of the information that the information that the information is the information that the information that we're all the information, and the information that the information can
2022-03-23 20:52:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:52:24 | INFO | fairseq.tasks.translation | example hypothesis: th th th: the reasons it's interesting, and it's interesting for tedtedtedtedtedtedtalks for tedtedson, "yes, it's the best time to tell you," if we're going to tell you, "if you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to have a long time, you know, you're going to get the most important revolution, you know, you know, you know, you know, you know, you know, you know, you're going to get the most important for the best time, the most important revolution, the most important revolution, you're going to get the best time, you know, you know, you're going to get the most important revolution, you know, you know, you know, you know, you know,"
2022-03-23 20:52:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:52:26 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need is still still the invention of the invention, and a big design part of our work that we were able to use that if we were able to use it in the bottom of the air, we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use with the
2022-03-23 20:52:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:52:26 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.604 | ppl 24.32 | bleu 11.92 | wps 2917.1 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 11.92
2022-03-23 20:52:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 20:52:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:52:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 20:52:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 14 @ 2193 updates, score 11.92) (writing took 0.7649200250161812 seconds)
2022-03-23 20:52:27 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 20:52:27 | INFO | train | epoch 014 | loss 4.99 | ppl 31.78 | wps 7835.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.443 | loss_scale 4 | train_wall 441 | gb_free 13.2 | wall 7071
2022-03-23 20:52:27 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 20:52:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:52:48 | INFO | train_inner | epoch 015:      7 / 157 loss=4.995, ppl=31.88, wps=7299.1, ups=0.29, wpb=24799.2, bsz=974.9, num_updates=2200, lr=0.000275, gnorm=1.44, loss_scale=4, train_wall=276, gb_free=13.5, wall=7093
2022-03-23 20:57:27 | INFO | train_inner | epoch 015:    107 / 157 loss=4.741, ppl=26.75, wps=8954, ups=0.36, wpb=24973.8, bsz=1003.1, num_updates=2300, lr=0.0002875, gnorm=1.267, loss_scale=4, train_wall=279, gb_free=13.3, wall=7371
2022-03-23 20:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:59:54 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical chemical rays.
2022-03-23 20:59:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:00:00 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 miles in the restaurant.
2022-03-23 21:00:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:00:06 | INFO | fairseq.tasks.translation | example hypothesis: these magnets can also be able to be able to be a popular bible bible of forms.
2022-03-23 21:00:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:00:13 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had learned his mother, his mother had been pregnant when she was pregnant.
2022-03-23 21:00:13 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:00:19 | INFO | fairseq.tasks.translation | example hypothesis: one of my coup is died in aids and aids has died a child, so we said, "well, what do we do we do?
2022-03-23 21:00:19 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:00:25 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about how things like the equation of gender and not talking about nuclear weapons or nuclear weapons or poverty or the end of poverty.
2022-03-23 21:00:25 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:00:32 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the bloop of magnetic magnetic magnetic lines, but if you don't want to move it, but if you don't need your movements, you don't need your movements, you need to move your movements, and you need to move your energy.
2022-03-23 21:00:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:00:39 | INFO | fairseq.tasks.translation | example hypothesis: if we use the information that can use the reflection of this reflection, we can start with a traditional face, and you can begin to start with the traditional form of the shape of the shape of the shape of the shape, and you can start with it, and then the information, and the information that all the information is the structure of the structure of the structure of the structure of the structure of the structure, and the information that you can start start to
2022-03-23 21:00:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:00:47 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons of the reasons that it's interesting, and it's interesting for me to be here for ted4 women, "yes, it's the best thing to say," yes, "if you're going to say," if you've got a long time, "if you're going to have a long time," if you're going to put it up with this guy, "and then you're going to take a long time, you're going to take it up with me," oh, "and then," if you're going to take me, "oh," oh, you're going to take it up with me, you're going to take me, "oh," if you're going to take it up with me, you're going to take me, you're going to take me, you're looking at this guy, you're going to take me
2022-03-23 21:00:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:00:50 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need to use is still the invention of the invention, and a big design part of our work that we had to solve on our airplane, that if we had to solve it, we had to solve the unique problems that if you had to solve it, it was able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use with the surface, that if you're able to use the surface, the surface of the heat the surface of the surface of a solar solar solar solar solar solar system, it, it, and the surface, it was the surface, the surface of the surface of the surface, the surface of the surface of a solar system, we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use,
2022-03-23 21:00:50 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:00:50 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.282 | ppl 19.45 | bleu 14.14 | wps 2941.4 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 14.14
2022-03-23 21:00:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 21:00:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 15 @ 2350 updates, score 14.14) (writing took 0.7620317150140181 seconds)
2022-03-23 21:00:50 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 21:00:50 | INFO | train | epoch 015 | loss 4.693 | ppl 25.87 | wps 7840.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.202 | loss_scale 4 | train_wall 441 | gb_free 13.2 | wall 7575
2022-03-23 21:00:51 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 21:00:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:03:13 | INFO | train_inner | epoch 016:     50 / 157 loss=4.607, ppl=24.37, wps=7313.8, ups=0.29, wpb=25310.7, bsz=965.4, num_updates=2400, lr=0.0003, gnorm=1.116, loss_scale=4, train_wall=283, gb_free=13.9, wall=7718
2022-03-23 21:07:53 | INFO | train_inner | epoch 016:    150 / 157 loss=4.34, ppl=20.26, wps=8967.3, ups=0.36, wpb=25079.7, bsz=1070.1, num_updates=2500, lr=0.0003125, gnorm=1.221, loss_scale=4, train_wall=279, gb_free=13.3, wall=7997
2022-03-23 21:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:08:18 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rays.
2022-03-23 21:08:18 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:08:24 | INFO | fairseq.tasks.translation | example hypothesis: then he can do about 8,000 places in the restaurant.
2022-03-23 21:08:24 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:08:30 | INFO | fairseq.tasks.translation | example hypothesis: these magnets, i also can also be a popular bible.
2022-03-23 21:08:30 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:08:35 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had been pregnant when she was pregnant.
2022-03-23 21:08:35 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:08:41 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and a wash kid said, "well, what do we do?"
2022-03-23 21:08:41 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:08:47 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time to talk about things like gender times and not talking about nuclear weapons or nuclear weapons.
2022-03-23 21:08:47 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:08:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field of magnetic lines in the field, but the susususues don't move their movements, because they need their movements and so forth.
2022-03-23 21:08:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:08:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection comes from this reflection reflection, we can start with a traditional face of traditional face, and then there's all the interfaces of the face, and then there's all the information, and then we can use all the information.
2022-03-23 21:08:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:09:06 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting, and it's interesting for me to be here with tedra women, "yes, it's the best time when we said,"] ["] [[men, and then we're going to take a lot of you, and then we're going to take a lot of time, and then we're going to take it's going to be in this long time, and then we're going to take it's going to take it's going to be interesting for you, and then we're going to say,"] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 21:09:06 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:09:08 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of invention, and a big part of the work that we had to see on our airplane, and we had to solve a unique result, and so we had to solve it in the bottom of the air, and we had to see it, and we had to be in a lot of air.
2022-03-23 21:09:08 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:09:08 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.115 | ppl 17.32 | bleu 16.31 | wps 3252.3 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.31
2022-03-23 21:09:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 21:09:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 16 @ 2507 updates, score 16.31) (writing took 0.7645844939979725 seconds)
2022-03-23 21:09:09 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 21:09:09 | INFO | train | epoch 016 | loss 4.417 | ppl 21.36 | wps 7922.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.196 | loss_scale 4 | train_wall 441 | gb_free 13.4 | wall 8073
2022-03-23 21:09:09 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 21:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:13:42 | INFO | train_inner | epoch 017:     93 / 157 loss=4.194, ppl=18.31, wps=7420.9, ups=0.29, wpb=25878.1, bsz=1012.9, num_updates=2600, lr=0.000325, gnorm=1.054, loss_scale=4, train_wall=291, gb_free=13.4, wall=8346
2022-03-23 21:16:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:16:38 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical chemical rockets.
2022-03-23 21:16:38 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:16:44 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 21:16:44 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:16:50 | INFO | fairseq.tasks.translation | example hypothesis: these magnetic magnets, i can also increase, of course, too much of course, to form a popular bicycle.
2022-03-23 21:16:50 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:16:56 | INFO | fairseq.tasks.translation | example hypothesis: he never learned his father, because his father had never learned to leave his mother when she was pregnant with him pregnant.
2022-03-23 21:16:56 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:17:03 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids and a wash child, so we asked us good, so what do we do with her?
2022-03-23 21:17:03 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:17:10 | INFO | fairseq.tasks.translation | example hypothesis: so so we spend our time over things like things like gender times and not talking about nuclear weapons or nuclear weapons.
2022-03-23 21:17:10 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:17:16 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic magnetic magnetic magnetic magnetic lines, but the sususususususuer doesn't like that, if you need your movements, you need your movements, and so your power needs.
2022-03-23 21:17:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:17:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection of reflection, we can start with a traditional face of the contextures, and there's the actual shape of the factors, and there's all the information that are all the information.
2022-03-23 21:17:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:17:29 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons that are interesting and measure it's interesting for me to be here in tedsters to be here in tedsters, is that... it was the best one of them, when someone said, "somebody said," the men, "and then," if we've got a long time, "and then we've started to support them," and then, "and then the truth is that the truth is that the truth."
2022-03-23 21:17:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:17:31 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention of invention, and a big part of design that we have to solve on our airplane, and if we had to solve a result of it, it's a unique problems that we had to solve everything in the ground, and it's all the way that we need to use it, to use it, to use it, to be a recover the air air, or to see it, to be in the air.
2022-03-23 21:17:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:17:31 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.891 | ppl 14.83 | bleu 18.79 | wps 3055 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 18.79
2022-03-23 21:17:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 21:17:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:17:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:17:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 17 @ 2664 updates, score 18.79) (writing took 0.7643301920033991 seconds)
2022-03-23 21:17:32 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 21:17:32 | INFO | train | epoch 017 | loss 4.144 | ppl 17.68 | wps 7848.4 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.074 | loss_scale 4 | train_wall 442 | gb_free 13.7 | wall 8576
2022-03-23 21:17:32 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 21:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:19:15 | INFO | train_inner | epoch 018:     36 / 157 loss=4.038, ppl=16.43, wps=7328.8, ups=0.3, wpb=24419.9, bsz=1055, num_updates=2700, lr=0.0003375, gnorm=1.14, loss_scale=4, train_wall=273, gb_free=13.6, wall=8679
2022-03-23 21:23:59 | INFO | train_inner | epoch 018:    136 / 157 loss=3.972, ppl=15.7, wps=8985.4, ups=0.35, wpb=25529, bsz=1000.5, num_updates=2800, lr=0.00035, gnorm=1.067, loss_scale=4, train_wall=284, gb_free=13.2, wall=8963
2022-03-23 21:24:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:24:59 | INFO | fairseq.tasks.translation | example hypothesis: this light can't use chemical rockets.
2022-03-23 21:24:59 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:25:05 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 21:25:05 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:25:11 | INFO | fairseq.tasks.translation | example hypothesis: i can also add these magnets, of course, to make a popular bike.
2022-03-23 21:25:11 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:25:17 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his father had left his mother, when she was pregnant.
2022-03-23 21:25:17 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:25:23 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousin is died in aids, and a wash child, so we said, "well, what do we do with?
2022-03-23 21:25:23 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:25:29 | INFO | fairseq.tasks.translation | example hypothesis: so, so we spend our time to talk about things like gender times and not talking about the lack of nuclear weapons or any other topic.
2022-03-23 21:25:29 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:25:35 | INFO | fairseq.tasks.translation | example hypothesis: first, some bull of magnetic magnetic magnetic magnetic lines are starting in the inside of the inside, but the suck doesn't like, if you need your movements, your movements and so the sucy.
2022-03-23 21:25:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:25:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the big face of the face of the face and repeat the information.
2022-03-23 21:25:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:25:47 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting and measure it for me to be here at tedth women, is that... "
2022-03-23 21:25:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:25:49 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of invention, and one big part of the design work that we have to see on our plane, and if you have to solve the very unique problems that we had to solve everything from the ground, and you need to use the air.
2022-03-23 21:25:49 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:25:49 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.654 | ppl 12.59 | bleu 20.48 | wps 3284.7 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.48
2022-03-23 21:25:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 21:25:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:25:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:25:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.48) (writing took 0.7667639409773983 seconds)
2022-03-23 21:25:50 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 21:25:50 | INFO | train | epoch 018 | loss 3.962 | ppl 15.58 | wps 7934.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.107 | loss_scale 4 | train_wall 440 | gb_free 14.3 | wall 9074
2022-03-23 21:25:50 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 21:25:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:29:30 | INFO | train_inner | epoch 019:     79 / 157 loss=3.805, ppl=13.98, wps=7382.4, ups=0.3, wpb=24471.5, bsz=993, num_updates=2900, lr=0.0003625, gnorm=1.038, loss_scale=4, train_wall=274, gb_free=13.2, wall=9295
2022-03-23 21:33:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:33:17 | INFO | fairseq.tasks.translation | example hypothesis: these sunlight can't use chemical rockets.
2022-03-23 21:33:17 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:33:23 | INFO | fairseq.tasks.translation | example hypothesis: it can be about 8,000 places in the restaurant.
2022-03-23 21:33:23 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:33:28 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand these rors too, to form a bibible.
2022-03-23 21:33:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:33:34 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had left with pregnant.
2022-03-23 21:33:34 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:33:40 | INFO | fairseq.tasks.translation | example hypothesis: one of my couples died on aids and has a wash child, so we said, well, well, what do we do with?
2022-03-23 21:33:40 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:33:46 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about nuclear weapons or any other topic.
2022-03-23 21:33:46 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:33:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some bellull of magnetic field are starting in the inside, but the superconductor doesn't like when they're moving, because they need to move their movements, and they need so the susususususues.
2022-03-23 21:33:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:33:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial face of the face of the face of the face and the basic shape of the face of the face and the interior form of factors.
2022-03-23 21:33:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:34:04 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting to be here for me in tedwomen, is that...
2022-03-23 21:34:04 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:34:05 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother's invention of invention, and a big part of design work that we've had to solve in our airplane, or if we were on the plane.
2022-03-23 21:34:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:34:05 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.59 | ppl 12.04 | bleu 19.26 | wps 3381.3 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 20.48
2022-03-23 21:34:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 21:34:05 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 21:34:05 | INFO | train | epoch 019 | loss 3.757 | ppl 13.52 | wps 7968.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.013 | loss_scale 4 | train_wall 441 | gb_free 13.9 | wall 9570
2022-03-23 21:34:06 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 21:34:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:35:06 | INFO | train_inner | epoch 020:     22 / 157 loss=3.75, ppl=13.46, wps=7502.7, ups=0.3, wpb=25161.3, bsz=989, num_updates=3000, lr=0.000375, gnorm=0.98, loss_scale=4, train_wall=281, gb_free=14.1, wall=9630
2022-03-23 21:39:54 | INFO | train_inner | epoch 020:    122 / 157 loss=3.458, ppl=10.99, wps=8997.6, ups=0.35, wpb=25907.7, bsz=1082.2, num_updates=3100, lr=0.0003875, gnorm=0.9, loss_scale=4, train_wall=288, gb_free=22.4, wall=9918
2022-03-23 21:41:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:41:33 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 21:41:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:41:39 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in the restaurant.
2022-03-23 21:41:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:41:45 | INFO | fairseq.tasks.translation | example hypothesis: of course, i can also expanded to form a bible.
2022-03-23 21:41:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:41:51 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had left his mother when she was pregnant.
2022-03-23 21:41:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:41:57 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died in aids and has a wash child, so we asked us, well, what do we do with your coup?
2022-03-23 21:41:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:42:02 | INFO | fairseq.tasks.translation | example hypothesis: so we spend time talking about things like gender times and not talking about angry or the spread of nuclear weapons or poverty.
2022-03-23 21:42:02 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:42:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic field are starting in the inner lines, but the superconductor doesn't like the superconductor doesn't like if you move your movement, and so the susuits the suits movement.
2022-03-23 21:42:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:42:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with traditional factors that are starting to begin with a traditional face of the face and the basic shape, and the basic form of information, and through that information that information, and the whole structure.
2022-03-23 21:42:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:42:21 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting and measure it for me to be here at tedwomen is that... yes, when it turned out to the best time, when someone said, "when someone said," listen to you, the men who started to you, and then when you're going to be very interesting. "
2022-03-23 21:42:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:42:25 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of invention, and a great part of design work that we're working on our plane was a result that we had to solve the unique problems so that we had to solve the unique problems that we had to solve it at the ground -- all the time, and a lot of the time, and a lot of the time, and a lot of design works, and a lot of the fought to use it is that it's been able to use it is, when it's a refrigergergergergergergergergergeration, it's a refrigeration, it's been able to use it's been able to use it's been able to use it's been able to use the ffloop us to be able to use the ffloop the fused to use it, when it's a refriction, when it's a refriction, it's a refriction, it's got to use it's a refriction, it, it's a
2022-03-23 21:42:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:42:25 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.44 | ppl 10.85 | bleu 21.61 | wps 3197.7 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 21.61
2022-03-23 21:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 21:42:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 20 @ 3135 updates, score 21.61) (writing took 0.8216154929832555 seconds)
2022-03-23 21:42:25 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 21:42:25 | INFO | train | epoch 020 | loss 3.55 | ppl 11.71 | wps 7898.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.954 | loss_scale 4 | train_wall 442 | gb_free 14.2 | wall 10070
2022-03-23 21:42:26 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 21:42:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:45:29 | INFO | train_inner | epoch 021:     65 / 157 loss=3.55, ppl=11.71, wps=7347.2, ups=0.3, wpb=24640.5, bsz=979.8, num_updates=3200, lr=0.0004, gnorm=0.979, loss_scale=4, train_wall=277, gb_free=14.2, wall=10253
2022-03-23 21:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:49:52 | INFO | fairseq.tasks.translation | example hypothesis: this sunlight can't use chemical rockets.
2022-03-23 21:49:52 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:49:58 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in the restaurant.
2022-03-23 21:49:58 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:50:04 | INFO | fairseq.tasks.translation | example hypothesis: these rough magnets, i can also expand to form a popular bias.
2022-03-23 21:50:04 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:50:10 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father, because his father had left his mother when she was pregnant.
2022-03-23 21:50:10 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:50:16 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died in aids, and a waan child, so we asked us, well, what do we do?
2022-03-23 21:50:16 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:50:22 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not talking about nuclear weapons or poverty.
2022-03-23 21:50:22 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:50:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught in the inner lines, but the superconductor doesn't like if you move your movements, and so the superconductor disorder.
2022-03-23 21:50:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:50:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start to start with a traditional face, the big configurations of the face and the basic form of information, which is the whole information that the whole portraits and folds.
2022-03-23 21:50:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:50:40 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's really interesting to be here in tedwomen, is that... yes, when someone said, "stop, you know, man said," stop in a table and you're going to help you say, "if you're going to go to the men and talk," if we started to you. "
2022-03-23 21:50:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:50:41 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need is still the mother of invention, and a big part of design that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous refrigeration to a continuing system.
2022-03-23 21:50:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:50:41 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.246 | ppl 9.49 | bleu 23.34 | wps 3386.1 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.34
2022-03-23 21:50:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 21:50:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:50:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 21:50:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 21 @ 3292 updates, score 23.34) (writing took 0.7922677000169642 seconds)
2022-03-23 21:50:41 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 21:50:41 | INFO | train | epoch 021 | loss 3.383 | ppl 10.43 | wps 7961.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.864 | loss_scale 4 | train_wall 440 | gb_free 13.9 | wall 10566
2022-03-23 21:50:42 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 21:50:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:51:06 | INFO | train_inner | epoch 022:      8 / 157 loss=3.305, ppl=9.88, wps=7514.8, ups=0.3, wpb=25353.9, bsz=1045.3, num_updates=3300, lr=0.0004125, gnorm=0.839, loss_scale=4, train_wall=282, gb_free=13.9, wall=10591
2022-03-23 21:55:50 | INFO | train_inner | epoch 022:    108 / 157 loss=3.291, ppl=9.79, wps=8892.2, ups=0.35, wpb=25256.1, bsz=1025.2, num_updates=3400, lr=0.000425, gnorm=0.891, loss_scale=4, train_wall=284, gb_free=13.4, wall=10875
2022-03-23 21:58:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:58:11 | INFO | fairseq.tasks.translation | example hypothesis: that sonsonic can't use chemical rockets.
2022-03-23 21:58:11 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 21:58:17 | INFO | fairseq.tasks.translation | example hypothesis: he can protect about 8,000 places in restaurant.
2022-03-23 21:58:17 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 21:58:23 | INFO | fairseq.tasks.translation | example hypothesis: these rough magnetic magnets, i can also expand to form a popular equivalent.
2022-03-23 21:58:23 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 21:58:28 | INFO | fairseq.tasks.translation | example hypothesis: he had never learned his father because his mother had left his pregnant when she was pregnant.
2022-03-23 21:58:28 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 21:58:34 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died to aids, so we asked, well, what do we do with her?
2022-03-23 21:58:34 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 21:58:40 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about the spread of nuclear weapons or poverty.
2022-03-23 21:58:40 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 21:58:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some bough lines are caught inside the inner lines, but the superconductor doesn't like if they're moving, because their movements need their energy, and so the superconductor disorder.
2022-03-23 21:58:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:58:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with traditional factors of face and the basic form of the face and repair it through that information that creates all the ports and folding a structure.
2022-03-23 21:58:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:58:57 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons to be highly interesting for tedwomen at tedwomen, is that... yes, when he said, it was the best summaried when someone said, "take you to the men and say," if we love the truth for me, "we've already started with a silent," and then we've already started a long time. "
2022-03-23 21:58:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:59:00 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, mother's invention is still a big part of design work that we're on the plane, was a result that we had to solve the unique problems that we had to operate with it -- everything from a continuous refrigeration system, and we use a refrigeration system to get a refrigeration, or a refrigeration, if we're going to go to the cocktail, then we're going to the cocktail, then we're going to the cocktail, then we're going to the water to a very much more, or a refrifrightened to the water, then we're going to the cocktail, then we're going to the water, then we're going to the water, then we're going to the water, either to the water, and then we had to the water, then we're going to the water, and we're going to a recook.
2022-03-23 21:59:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:59:00 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.26 | ppl 9.58 | bleu 22.48 | wps 3383.4 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.34
2022-03-23 21:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 21:59:00 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 21:59:00 | INFO | train | epoch 022 | loss 3.255 | ppl 9.55 | wps 7925.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.861 | loss_scale 4 | train_wall 443 | gb_free 14.2 | wall 11064
2022-03-23 21:59:00 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 21:59:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:01:26 | INFO | train_inner | epoch 023:     51 / 157 loss=3.104, ppl=8.6, wps=7488, ups=0.3, wpb=25150.8, bsz=1066.9, num_updates=3500, lr=0.0004375, gnorm=0.822, loss_scale=4, train_wall=280, gb_free=14.2, wall=11211
2022-03-23 22:06:03 | INFO | train_inner | epoch 023:    151 / 157 loss=3.144, ppl=8.84, wps=8946.4, ups=0.36, wpb=24796.2, bsz=973.8, num_updates=3600, lr=0.00045, gnorm=0.809, loss_scale=4, train_wall=277, gb_free=13.4, wall=11488
2022-03-23 22:06:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:06:28 | INFO | fairseq.tasks.translation | example hypothesis: this sonsonic can't use chemical rockets.
2022-03-23 22:06:28 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:06:34 | INFO | fairseq.tasks.translation | example hypothesis: he can do about 8,000 places in the restaurant.
2022-03-23 22:06:34 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:06:39 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, i can also expand, of course, to form a popular equation.
2022-03-23 22:06:39 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:06:45 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 22:06:45 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:06:51 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins is died on aids and left a wash child, so we asked ourselves, well, what do we do with them?
2022-03-23 22:06:51 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:06:58 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not talking about genocide or poverty or any other promising topic.
2022-03-23 22:06:58 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:07:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bble of magnetic field lines are caught inside, but the superconductor doesn't like it if you move, because your movements are required, and so the superconductor disorder disorders.
2022-03-23 22:07:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:07:10 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection reflection reflection, we can start with a traditional facial, which is the big configuration of the face and the basic shape, and restoring it through that information that whole ports and fabric.
2022-03-23 22:07:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:07:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are doing it very interesting and measured to you, for me here at tedwomen, is that... t.m., when someone said, "turn you to the men of delection and say," if you're going to support women's revolution, "and then we've already been supported for you."
2022-03-23 22:07:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:07:18 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane was a result that we had to solve the unique problems that were connected to the ground -- all of the continuous to be refrigerated by continuous and refrigered with a continuous system that allows us to be used to be used to be used to be able to be used to be able to get rid of a mechanism.
2022-03-23 22:07:18 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:07:18 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.01 | ppl 8.06 | bleu 26.33 | wps 3253.6 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 26.33
2022-03-23 22:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 22:07:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:07:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 23 @ 3606 updates, score 26.33) (writing took 0.7670103670097888 seconds)
2022-03-23 22:07:19 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 22:07:19 | INFO | train | epoch 023 | loss 3.1 | ppl 8.57 | wps 7911.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.808 | loss_scale 4 | train_wall 442 | gb_free 13.8 | wall 11563
2022-03-23 22:07:19 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 22:07:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:11:43 | INFO | train_inner | epoch 024:     94 / 157 loss=2.973, ppl=7.85, wps=7408.4, ups=0.29, wpb=25153.4, bsz=1052.8, num_updates=3700, lr=0.0004625, gnorm=0.822, loss_scale=4, train_wall=282, gb_free=13.5, wall=11827
2022-03-23 22:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:14:47 | INFO | fairseq.tasks.translation | example hypothesis: this sonic rockets can't use chemical rockets.
2022-03-23 22:14:47 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:14:52 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant.
2022-03-23 22:14:52 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:14:58 | INFO | fairseq.tasks.translation | example hypothesis: this round magnets, of course, i can expand to form a popular equation.
2022-03-23 22:14:58 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:15:04 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 22:15:04 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:15:10 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died to aids and left an orphanage child, so we asked ourselves, well, what do we do with her?
2022-03-23 22:15:10 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:15:16 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about genocide or poverty or any other promising topic.
2022-03-23 22:15:16 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:15:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some buminum of magnetic field are caught inside the inner lines, but the susuperconductor doesn't like it if you're moving your movements, and so the superconductor disorder.
2022-03-23 22:15:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:15:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face, which is the great configuration of the face and the basic shape, and reducing all the ports and folding it.
2022-03-23 22:15:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:15:33 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it starts to be highly interesting and say, "for me here at tedwomen, is that... tyes, when dinner was the best summared when somebody said," turn you to the men of your table and say, "when we're already supporting you."
2022-03-23 22:15:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:15:34 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we had to deal with our airplane was a result that we had to solve the unique problems that were connected to the air -- everything from a continuing system that allows us to use the air conditioning and refrigeration with a refrigeration system that allows us to see when we were on the aircraft at the first stest.
2022-03-23 22:15:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:15:34 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.974 | ppl 7.86 | bleu 26.11 | wps 3421.4 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.33
2022-03-23 22:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 22:15:34 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 22:15:34 | INFO | train | epoch 024 | loss 2.998 | ppl 7.99 | wps 7970.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.806 | loss_scale 4 | train_wall 441 | gb_free 13.5 | wall 12059
2022-03-23 22:15:35 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 22:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:17:15 | INFO | train_inner | epoch 025:     37 / 157 loss=2.988, ppl=7.93, wps=7471, ups=0.3, wpb=24829.4, bsz=965.9, num_updates=3800, lr=0.000475, gnorm=0.783, loss_scale=4, train_wall=278, gb_free=14.3, wall=12160
2022-03-23 22:21:58 | INFO | train_inner | epoch 025:    137 / 157 loss=2.919, ppl=7.56, wps=8976.3, ups=0.35, wpb=25373.1, bsz=1046.8, num_updates=3900, lr=0.0004875, gnorm=0.807, loss_scale=4, train_wall=282, gb_free=13.3, wall=12442
2022-03-23 22:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:23:03 | INFO | fairseq.tasks.translation | example hypothesis: these sonic rockets can't use chemical rockets.
2022-03-23 22:23:03 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:23:09 | INFO | fairseq.tasks.translation | example hypothesis: he can do about 8,000 places in the restaurant.
2022-03-23 22:23:09 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:23:14 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can expand to form a popular comparison.
2022-03-23 22:23:14 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:23:20 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 22:23:20 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:23:26 | INFO | fairseq.tasks.translation | example hypothesis: one of my couples is died on aids, and left an orphanage, so we asked us, well, what do we do with her?
2022-03-23 22:23:26 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:23:32 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times, and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 22:23:32 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:23:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some bold lines of magnetic field are caught inside, but the superconductor doesn't like the superconductor, if you move, because your movements are using energy, and so the superconductor.
2022-03-23 22:23:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:23:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big contexts of the face and the basic shape, and through the contrast of the whole porter structure, which is folding all the porter structure and fold a fold.
2022-03-23 22:23:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:23:50 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and measured, for me here at tedwomen, is that... yes, when i said, "listen to the men in a table and say," stop, "let's support you to the men on your table and say," if the revolution starts to support you. "
2022-03-23 22:23:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:23:53 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention, and a large part of the design work that we are on our plane on the stest, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and refrigeration system that allows us to use a refrigeration, and that allows us to see that it's a refrigeration in the atmosphere, either we need to see the frigeration of a mechanism, or the mechanism, the mechanism of a mechanism, the mechanism, the fuse of a mechanism, and we need to go to the verization, and we have to be delivered by a mechanism, and we have to the farther, to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 22:23:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:23:53 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.846 | ppl 7.19 | bleu 28.07 | wps 3285.4 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.07
2022-03-23 22:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 22:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:23:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 25 @ 3920 updates, score 28.07) (writing took 0.7600382239907049 seconds)
2022-03-23 22:23:53 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 22:23:53 | INFO | train | epoch 025 | loss 2.906 | ppl 7.49 | wps 7913.5 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.786 | loss_scale 4 | train_wall 442 | gb_free 13.3 | wall 12558
2022-03-23 22:23:54 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 22:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:27:40 | INFO | train_inner | epoch 026:     80 / 157 loss=2.828, ppl=7.1, wps=7418.5, ups=0.29, wpb=25340.3, bsz=1008.7, num_updates=4000, lr=0.0005, gnorm=0.792, loss_scale=4, train_wall=285, gb_free=13.5, wall=12784
2022-03-23 22:31:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:31:23 | INFO | fairseq.tasks.translation | example hypothesis: these sonry can't use chemical rockets.
2022-03-23 22:31:23 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:31:29 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can talk about 8,000 places in the restaurant.
2022-03-23 22:31:29 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:31:34 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can expand to form any random glimpse.
2022-03-23 22:31:34 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:31:40 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant.
2022-03-23 22:31:40 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:31:46 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a wais-child, so we asked us, well, what do we do with her?
2022-03-23 22:31:46 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:31:52 | INFO | fairseq.tasks.translation | example hypothesis: so we spend time talking about things like gender times, and not about genocide or the spread of nuclear weapons or poverty or any other promised topic.
2022-03-23 22:31:52 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:31:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are caught inside, but the superconductor doesn't like it if you move, because your movements use, and so the superconductor disorder.
2022-03-23 22:31:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:32:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big configurations of facial facial and the basic shape, which draws all the portural structure and all folds.
2022-03-23 22:32:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:32:10 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that it's highly interesting and measuring me here at tedwomen is that... tyes, at dinner dinner, it was best summarized when someone said, "turn you to men at dtable and tell you," if the revolution begins, we support you. "
2022-03-23 22:32:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:32:11 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is invention, and a large part of design work that we are on our airplane's stump was a result that we had to solve the unique problems that were connected to operate on the ground -- all a continuous variation and a cooler system that allows us to use a refrigerator, and you can use a mechanism, and you can use a mechanism.
2022-03-23 22:32:11 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:32:11 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.837 | ppl 7.15 | bleu 27.61 | wps 3375.2 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.07
2022-03-23 22:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 22:32:11 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 22:32:11 | INFO | train | epoch 026 | loss 2.825 | ppl 7.08 | wps 7930.2 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.778 | loss_scale 4 | train_wall 443 | gb_free 12.9 | wall 13056
2022-03-23 22:32:12 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 22:32:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:33:18 | INFO | train_inner | epoch 027:     23 / 157 loss=2.829, ppl=7.1, wps=7453.6, ups=0.3, wpb=25215.6, bsz=999.6, num_updates=4100, lr=0.000493865, gnorm=0.774, loss_scale=4, train_wall=283, gb_free=13.2, wall=13122
2022-03-23 22:37:58 | INFO | train_inner | epoch 027:    123 / 157 loss=2.712, ppl=6.55, wps=8907.6, ups=0.36, wpb=24978.6, bsz=1019.3, num_updates=4200, lr=0.00048795, gnorm=0.67, loss_scale=4, train_wall=280, gb_free=13.7, wall=13403
2022-03-23 22:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:39:41 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 22:39:41 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:39:46 | INFO | fairseq.tasks.translation | example hypothesis: he can talk about 8,000 places in the restaurant over year.
2022-03-23 22:39:46 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:39:52 | INFO | fairseq.tasks.translation | example hypothesis: i can also expand this round magnet, of course, to make a popular comparison.
2022-03-23 22:39:52 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:39:58 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 22:39:58 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:40:04 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with them?
2022-03-23 22:40:04 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:40:11 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding and not about genocide or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 22:40:11 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:40:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught in the inside, but the superconductor doesn't like it if you move, because your movements need energy, and so the superconductor disorders.
2022-03-23 22:40:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:40:23 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which is the big configurations of the facial facial and the elementary form, and the actual form repeats it through this single information that puts all the porter structure and all a folding fold.
2022-03-23 22:40:23 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:40:28 | INFO | fairseq.tasks.translation | example hypothesis: i think one of the reasons that makes it interesting and measured for me here at tedwomen, is that... tye, it was the best summarized when someone said, "take you to the men on your table and we say," the truth is that we've already been supporting you for this long time. "
2022-03-23 22:40:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:40:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of design work that we're on our plane stststest was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous operating system to a refrigerator, and allows us to use a little bit of heat, to a computer in a particular place that allows us to use a remote remote remote vehicle to the ground, to a vehicle.
2022-03-23 22:40:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:40:31 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.78 | ppl 6.87 | bleu 28.58 | wps 3265.8 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.58
2022-03-23 22:40:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 22:40:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:40:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 27 @ 4234 updates, score 28.58) (writing took 0.797871329006739 seconds)
2022-03-23 22:40:31 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 22:40:31 | INFO | train | epoch 027 | loss 2.709 | ppl 6.54 | wps 7897 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.708 | loss_scale 4 | train_wall 442 | gb_free 13 | wall 13556
2022-03-23 22:40:33 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 22:40:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:43:40 | INFO | train_inner | epoch 028:     66 / 157 loss=2.68, ppl=6.41, wps=7442.1, ups=0.29, wpb=25419.3, bsz=1023.5, num_updates=4300, lr=0.000482243, gnorm=0.748, loss_scale=4, train_wall=283, gb_free=13.4, wall=13744
2022-03-23 22:47:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:47:59 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 22:47:59 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:48:04 | INFO | fairseq.tasks.translation | example hypothesis: over year, it can occur about 8,000 places in the restaurant.
2022-03-23 22:48:04 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:48:10 | INFO | fairseq.tasks.translation | example hypothesis: these round magnets, of course, i can expand to make a random glide.
2022-03-23 22:48:10 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:48:16 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 22:48:16 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:48:22 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left a wais-child, so we said, well, what do we do with them?
2022-03-23 22:48:22 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:48:28 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender times, and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 22:48:28 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:48:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 22:48:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:48:41 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial that repeats the big configurations of the face and the basic form, and by the fact that the whole portion structure and all the fits.
2022-03-23 22:48:41 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:48:47 | INFO | fairseq.tasks.translation | example hypothesis: i mean, one of the reasons that makes it interesting and measured to me here at tedwomen, is that... tyes, it was the best summarized when someone said, "stop to the men in your table and tell them," 'if the revolution begins, and the truth is that we've already been supporting you in this long term for sandra, and then we've already started with sandra, you. "
2022-03-23 22:48:47 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:48:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still a big part of design work that we're on our airplane on the top of our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigeration system that allows us to get rid of the aircraft, either to get rid of the frightened, or to get rid of the frightened, or to get rid of the friction, or to get rid of anxiety of the air conditioning equipment, or to get rid of anxiety and regulations.
2022-03-23 22:48:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:48:48 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.698 | ppl 6.49 | bleu 28.78 | wps 3289.3 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 28.78
2022-03-23 22:48:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 22:48:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:48:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 22:48:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 28 @ 4391 updates, score 28.78) (writing took 0.7871101920027286 seconds)
2022-03-23 22:48:49 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 22:48:49 | INFO | train | epoch 028 | loss 2.653 | ppl 6.29 | wps 7934.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.709 | loss_scale 4 | train_wall 440 | gb_free 12.9 | wall 14054
2022-03-23 22:48:50 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 22:48:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:49:17 | INFO | train_inner | epoch 029:      9 / 157 loss=2.601, ppl=6.07, wps=7470.1, ups=0.3, wpb=25155.3, bsz=1054.1, num_updates=4400, lr=0.000476731, gnorm=0.655, loss_scale=4, train_wall=280, gb_free=13.7, wall=14081
2022-03-23 22:53:59 | INFO | train_inner | epoch 029:    109 / 157 loss=2.573, ppl=5.95, wps=8953, ups=0.35, wpb=25262.1, bsz=1004.5, num_updates=4500, lr=0.000471405, gnorm=0.707, loss_scale=4, train_wall=282, gb_free=14.1, wall=14363
2022-03-23 22:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:56:16 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 22:56:16 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 22:56:22 | INFO | fairseq.tasks.translation | example hypothesis: he can deal with about 8,000 places in the restaurant.
2022-03-23 22:56:22 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 22:56:28 | INFO | fairseq.tasks.translation | example hypothesis: , of course, i can expand this round magnets.
2022-03-23 22:56:28 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 22:56:33 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant.
2022-03-23 22:56:33 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 22:56:39 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with them?
2022-03-23 22:56:39 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 22:56:45 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender times and not about genocide or distribution of nuclear weapons or poverty or any other promising topic.
2022-03-23 22:56:45 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 22:56:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use, and so the superconductor disorder.
2022-03-23 22:56:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:56:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that refers the big configurations of the face and the baseline, and by thief, the whole porter structure and all the fits.
2022-03-23 22:56:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:57:05 | INFO | fairseq.tasks.translation | example hypothesis: i mean, one of the reasons that makes it interesting and measured for me here at tedwomen, is that... well, when constrained dinner, it was best summarized when somebody said, "turn on the men at your table and tell them," if the revolution begins, then we support you. "the truth is that we've already supported with you, you know, you know, women, you've been supporting this topic for a long time, and you've already, you know, you know, you know, you know, you know, you know, you know, you know, you've got a cake, and you've got a couple of sand, and you've got a long time, and you know, and you've got a couple of sand, and you've got a couple of sand, and you've got a long time,"
2022-03-23 22:57:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:57:07 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, it's still the mother of invention, and it's a big part of design work that we're on our plane at the stunt toys, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a coolness system that allows us to use a hydrogen machine in the flight, or a fluid, or a fluid that allows us to use a motor motor motor, or a motor motor motor, and you can use it, and you can use it, and you know, and you know, you know, and you can use it, you know, you know, and you know, and you know, you know, and you know, you know, you know, and you know, and you know, you know, and you can use a little bit, you know, and you know, you know, and you know, and you know, and you know, you know, and you know, and you know, you know,
2022-03-23 22:57:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:57:07 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.65 | ppl 6.28 | bleu 28.59 | wps 3225 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 28.78
2022-03-23 22:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 22:57:07 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 22:57:07 | INFO | train | epoch 029 | loss 2.554 | ppl 5.87 | wps 7930.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.69 | loss_scale 4 | train_wall 441 | gb_free 14 | wall 14552
2022-03-23 22:57:07 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 22:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:59:35 | INFO | train_inner | epoch 030:     52 / 157 loss=2.473, ppl=5.55, wps=7421.9, ups=0.3, wpb=24939.1, bsz=1079.5, num_updates=4600, lr=0.000466252, gnorm=0.667, loss_scale=4, train_wall=279, gb_free=13.9, wall=14699
2022-03-23 23:04:15 | INFO | train_inner | epoch 030:    152 / 157 loss=2.518, ppl=5.73, wps=8979.5, ups=0.36, wpb=25128.5, bsz=975.4, num_updates=4700, lr=0.000461266, gnorm=0.675, loss_scale=4, train_wall=280, gb_free=13.5, wall=14979
2022-03-23 23:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:04:34 | INFO | fairseq.tasks.translation | example hypothesis: that probe can't use chemical rockets.
2022-03-23 23:04:34 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:04:40 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can do about 8,000 places in the restaurant.
2022-03-23 23:04:40 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:04:46 | INFO | fairseq.tasks.translation | example hypothesis: of course, these round magnets can expand, of course, to make any same glide.
2022-03-23 23:04:46 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:04:52 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his dad had left his mother when she was pregnant with him.
2022-03-23 23:04:52 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:04:58 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 23:04:58 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:05:04 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs and not about genocide or poverty or any other promising topic.
2022-03-23 23:05:04 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:05:11 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of the magnetic field lines are caught inside, but the superconductor doesn't like if you move, because your movements use energy, and the superconductor disorder.
2022-03-23 23:05:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:05:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face that gives the big configurations of the face and the baseline, and defend it through this single information that refers the whole porter structure and all the fits.
2022-03-23 23:05:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:05:23 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and measured it for me to be here at tedwomen, is that... well, the truth is that, you know, in a long time, when somebody said, "turn you to the men on your table and say," if the revolution begins to be able to support you. "
2022-03-23 23:05:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:05:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a great part of the design work that we're doing on our airplane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable and cooling system, or a cooling system, that allows us to use the air conditioning, or whatever we're going to be able to be able to do is to use on the air conditioning system, either, and we need to get rid of the air conditioning system, or to the air conditioning.
2022-03-23 23:05:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:05:26 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.591 | ppl 6.03 | bleu 30.66 | wps 3187 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.66
2022-03-23 23:05:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 23:05:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:05:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:05:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 30 @ 4705 updates, score 30.66) (writing took 0.8127973870141432 seconds)
2022-03-23 23:05:27 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 23:05:27 | INFO | train | epoch 030 | loss 2.488 | ppl 5.61 | wps 7905.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.672 | loss_scale 4 | train_wall 441 | gb_free 13.5 | wall 15051
2022-03-23 23:05:27 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 23:05:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:09:54 | INFO | train_inner | epoch 031:     95 / 157 loss=2.395, ppl=5.26, wps=7399.1, ups=0.29, wpb=25096.2, bsz=1014, num_updates=4800, lr=0.000456435, gnorm=0.636, loss_scale=4, train_wall=280, gb_free=14, wall=15318
2022-03-23 23:12:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:12:53 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 23:12:53 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:12:59 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can discuss about 8,000 places in the restaurant.
2022-03-23 23:12:59 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:13:05 | INFO | fairseq.tasks.translation | example hypothesis: of course, these round magnets, i can expand, of course, to form any same glide.
2022-03-23 23:13:05 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:13:11 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 23:13:11 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:13:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins has died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 23:13:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:13:23 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender marriage and not about genocide or poverty or any other prevalence.
2022-03-23 23:13:23 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:13:29 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 23:13:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:13:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial bar, which gives the big contextures of the face and the basic form, and then refuse it through this particular information that comes from the entire porter structure and all the fits together.
2022-03-23 23:13:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:13:42 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that it's interesting and done it for me here at tedwomen is that... tja, when dinner was stripped, it was best summed when someone said, "turn you to the men at your table and say," if the revolution begins to support you, then we support you. '' '' the truth is that we've been supporting you for this long time, "and then we've been supporting you for a long time at the moon, and then we've started with the sandra borra, and then."
2022-03-23 23:13:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:13:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane stumbris was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuously variable and a cooling system that allows us to use in the aircraft until we get a conditioning system, or if you have to operate in the air conditioning system, or either, or if you're going to be able to be able to be able to be able to operate, or if you're going to operate, or if you're going to operate in the vehicle, or if you're going to be able to operate, or if you're going to be able to operate, or if you're going to be able to have a mechanism, or not going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to operate,
2022-03-23 23:13:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:13:44 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.59 | ppl 6.02 | bleu 30.46 | wps 3219.7 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.66
2022-03-23 23:13:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 23:13:44 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 23:13:44 | INFO | train | epoch 031 | loss 2.413 | ppl 5.32 | wps 7939.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.652 | loss_scale 4 | train_wall 440 | gb_free 13.3 | wall 15548
2022-03-23 23:13:44 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 23:13:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:15:34 | INFO | train_inner | epoch 032:     38 / 157 loss=2.431, ppl=5.39, wps=7426.2, ups=0.29, wpb=25261.7, bsz=997.7, num_updates=4900, lr=0.000451754, gnorm=0.671, loss_scale=4, train_wall=283, gb_free=14.5, wall=15658
2022-03-23 23:20:17 | INFO | train_inner | epoch 032:    138 / 157 loss=2.326, ppl=5.01, wps=8949.9, ups=0.35, wpb=25289.7, bsz=1052.7, num_updates=5000, lr=0.000447214, gnorm=0.593, loss_scale=4, train_wall=282, gb_free=13.7, wall=15941
2022-03-23 23:21:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:21:13 | INFO | fairseq.tasks.translation | example hypothesis: that probe can't use chemical rockets.
2022-03-23 23:21:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:21:19 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can discuss about 8,000 places in the restaurant.
2022-03-23 23:21:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:21:25 | INFO | fairseq.tasks.translation | example hypothesis: i can expand these round magnets, of course, to shape a popular equation.
2022-03-23 23:21:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:21:31 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his dad more, because his father had left his mother when she was pregnant with him.
2022-03-23 23:21:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:21:37 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with them?
2022-03-23 23:21:37 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:21:43 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender marriage and not about genocide or poverty or any other promising topic.
2022-03-23 23:21:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:21:49 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and so the superconducting.
2022-03-23 23:21:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:21:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflective reflection, we can start with a traditional facial contexts of the face and the basic form, and release it through that particular information that includes the entire porter structure and all the fits.
2022-03-23 23:21:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:22:01 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and appropriate for me to be here at tedwomen, is that... tyes, when they stripped dinner, it was best summarized when someone said, "turn on the men at your table and tell them," if the revolution begins, then we support you. "'the truth is that we've already started you on this long time with silent carchra borra borra and then" meal. "
2022-03-23 23:22:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:22:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're stumbling at our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variable operating and coolness system that allows us to use an aircraft in the world to either be used to the vehicle, or to operate in the air conditioning system, to the air conditioning system.
2022-03-23 23:22:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:22:03 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.524 | ppl 5.75 | bleu 30.85 | wps 3302 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.85
2022-03-23 23:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 23:22:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:22:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 32 @ 5019 updates, score 30.85) (writing took 0.8541244470397942 seconds)
2022-03-23 23:22:04 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 23:22:04 | INFO | train | epoch 032 | loss 2.347 | ppl 5.09 | wps 7904.2 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.611 | loss_scale 4 | train_wall 443 | gb_free 12.9 | wall 16048
2022-03-23 23:22:04 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 23:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:25:56 | INFO | train_inner | epoch 033:     81 / 157 loss=2.314, ppl=4.97, wps=7399.7, ups=0.29, wpb=25094.4, bsz=975.9, num_updates=5100, lr=0.000442807, gnorm=0.622, loss_scale=4, train_wall=282, gb_free=13.1, wall=16280
2022-03-23 23:29:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:29:33 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 23:29:33 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:29:39 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can discuss about 8,000 places in the restaurant.
2022-03-23 23:29:39 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:29:45 | INFO | fairseq.tasks.translation | example hypothesis: , of course, these roundings magnets, i can expand, of course, to shape any same glide.
2022-03-23 23:29:45 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:29:51 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father more closely because his father had left his mother when she was pregnant.
2022-03-23 23:29:51 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:29:57 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 23:29:57 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:30:03 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender webs and not about genocide or the prevalence of nuclear weapons or poverty or any other promising topic.
2022-03-23 23:30:03 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:30:09 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements use energy, and the superconductor collision.
2022-03-23 23:30:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:30:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial sky that gives the big constructions of the face and the basic form, and through the thief of information, which is the entire porter structure, and all the fa folding folds.
2022-03-23 23:30:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:30:22 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that i think it's interesting and appropriate for me to be here with tedwomen is that... well, when contestion dinner, it's been summoned best when someone said, "turn to the men at your table and tell them, 'if the revolution begins, then we support you.' 'the truth is that we've been supporting you for this long time, women, we've already been supporting you, and we've been supported by silence," and then it's been a silly, and then it's been a sand-borra borra runner, and then we've been going to downstream. "
2022-03-23 23:30:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:30:24 | INFO | fairseq.tasks.translation | example hypothesis: , luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane are the most stumbling, was a result of that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable version of design work, and a coolness system that allows us to use aircraft in the gossip, or a structural transport, and if you're going to be able, or if you're going to be able, you're going to operate, you're going to operate, you're going to operate at the same time, you're going to operate it, you're going to operate it, you're going to operate it, you know, you're going to operate it, you're going to operate it, you're going to operate it, you know, you're going to operate it, you know, you're going to operate it, you're going to operate it, you're going to operate it,
2022-03-23 23:30:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:30:24 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.527 | ppl 5.77 | bleu 30.87 | wps 3212.6 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 30.87
2022-03-23 23:30:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 23:30:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:30:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:30:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 33 @ 5176 updates, score 30.87) (writing took 0.8265832390170544 seconds)
2022-03-23 23:30:25 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 23:30:25 | INFO | train | epoch 033 | loss 2.294 | ppl 4.9 | wps 7874.3 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.631 | loss_scale 4 | train_wall 443 | gb_free 13.4 | wall 16550
2022-03-23 23:30:26 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 23:30:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:31:35 | INFO | train_inner | epoch 034:     24 / 157 loss=2.245, ppl=4.74, wps=7405.7, ups=0.29, wpb=25158.1, bsz=1109.5, num_updates=5200, lr=0.000438529, gnorm=0.626, loss_scale=4, train_wall=282, gb_free=13.6, wall=16620
2022-03-23 23:36:17 | INFO | train_inner | epoch 034:    124 / 157 loss=2.249, ppl=4.75, wps=8944, ups=0.36, wpb=25147.3, bsz=995.5, num_updates=5300, lr=0.000434372, gnorm=0.612, loss_scale=4, train_wall=281, gb_free=13.5, wall=16901
2022-03-23 23:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:37:54 | INFO | fairseq.tasks.translation | example hypothesis: they can't use chemical rockets.
2022-03-23 23:37:54 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:38:00 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can discuss about 8,000 places in the restaurant.
2022-03-23 23:38:00 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:38:06 | INFO | fairseq.tasks.translation | example hypothesis: of course, this round magnet, i can also expand to shape any same glide.
2022-03-23 23:38:06 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:38:11 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father, because his father had left his mother when she was pregnant with him.
2022-03-23 23:38:11 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:38:17 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with her?
2022-03-23 23:38:17 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:38:24 | INFO | fairseq.tasks.translation | example hypothesis: that's why we spend our time talking about things like gender wedding and not about genocide or the spread of nuclear weapons or poverty or any other topic.
2022-03-23 23:38:24 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:38:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, because your movements use energy, and the superconductor field.
2022-03-23 23:38:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:38:36 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial face that gives the big configurations of the face and the basic form of the site, and adding it through that information that attract the entire porter structure and all the ffloods.
2022-03-23 23:38:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:38:42 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it interesting and done it for me, is that, at tedwomen, one of the reasons that i think it was best summarized when someone said, "take you to the men at your table and tell you," if the revolution begins, then we support you. "'"' "the truth, women is that we've already supported you with this issue for a long time."
2022-03-23 23:38:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:38:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're most proud of in our airplane was a result of that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and cooling system with a coolness system that allows us to use a robotic aircraft in the world on the world to use a garbage machine in the go-to-the world, either to use the wrong vehicle vehicle vehicle, or if you can use the wrong vehicle, if you can use a vehicle, you can use it to operate it, you can use it to operate it in the ground, or if you can use it in the air conditioning system, if you can use a vehicle, you can use a vehicle, you can use it, you can use it in the wrong system, you can use a vehicle, you can use it, you can use it to the wrong device, you can use it to see it,
2022-03-23 23:38:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:38:45 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.487 | ppl 5.6 | bleu 31.63 | wps 3228.9 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.63
2022-03-23 23:38:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 23:38:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt
2022-03-23 23:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.04_#4/checkpoint_best.pt (epoch 34 @ 5333 updates, score 31.63) (writing took 1.067820206983015 seconds)
2022-03-23 23:38:46 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 23:38:46 | INFO | train | epoch 034 | loss 2.248 | ppl 4.75 | wps 7890.9 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.606 | loss_scale 4 | train_wall 442 | gb_free 13.7 | wall 17050
2022-03-23 23:38:46 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 23:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:41:53 | INFO | train_inner | epoch 035:     67 / 157 loss=2.282, ppl=4.86, wps=7359.4, ups=0.3, wpb=24737.3, bsz=977.8, num_updates=5400, lr=0.000430331, gnorm=0.661, loss_scale=4, train_wall=278, gb_free=14.3, wall=17237
2022-03-23 23:46:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:46:13 | INFO | fairseq.tasks.translation | example hypothesis: they can't use chemical rockets.
2022-03-23 23:46:13 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:46:19 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can talk about 8,000 places in the restaurant.
2022-03-23 23:46:19 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:46:25 | INFO | fairseq.tasks.translation | example hypothesis: of course, these round magnets, i can also expand to shape any same glide.
2022-03-23 23:46:25 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:46:31 | INFO | fairseq.tasks.translation | example hypothesis: he'd never met his father because his father had left his mother when she was pregnant with him.
2022-03-23 23:46:31 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:46:37 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what do we do with it?
2022-03-23 23:46:37 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:46:43 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender marriage and not about genocide or the spread of nuclear weapons or poverty or any other promising topic.
2022-03-23 23:46:43 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:46:49 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when you move, because your movements use energy, and so the superconducting system disrupted.
2022-03-23 23:46:49 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:46:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional face that restores the big configurations of the face and the basic form, and refuse it through that information that refers the entire porter structure and all the fits.
2022-03-23 23:46:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:47:01 | INFO | fairseq.tasks.translation | example hypothesis: , th: one of the reasons why it makes it interesting and appropriate for me here at tedwomen, is that... tyes, when constrict dinner, it was best summoned when someone said, "turn to the men at your table and tell them," if the revolution begins, then we support you. "'the truth is that we've already been supporting you with this issue for a long time."
2022-03-23 23:47:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:47:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're proud of on our airplane is a result of that we had to solve the unique problems associated with operating on the ground -- everything from a continuously variable and cooling system that allows us to use an aircraft in the world to stop and to a refrigerator that it allows us to use a robotic transport, either if you're not to a robotic device in the air force in the air force in the air force, or whatever you see the ground, if you're going on the ground, either the air force that you're going on the ground, to be used to be used to be used by the land, to be able to a robotic transport, to a robotic space that you see the ground, to a mechanism, to a robotic space that you can see the ground, if you have been able to a robotic cycle, to a mechanism, to a mechanism, to
2022-03-23 23:47:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:47:03 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.473 | ppl 5.55 | bleu 30.76 | wps 3276.3 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.63
2022-03-23 23:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 23:47:03 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 23:47:03 | INFO | train | epoch 035 | loss 2.231 | ppl 4.69 | wps 7935.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.652 | loss_scale 4 | train_wall 441 | gb_free 14.5 | wall 17548
2022-03-23 23:47:04 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 23:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:47:34 | INFO | train_inner | epoch 036:     10 / 157 loss=2.193, ppl=4.57, wps=7496.8, ups=0.29, wpb=25566.1, bsz=1051.8, num_updates=5500, lr=0.000426401, gnorm=0.604, loss_scale=4, train_wall=285, gb_free=13.7, wall=17578
2022-03-23 23:52:18 | INFO | train_inner | epoch 036:    110 / 157 loss=2.13, ppl=4.38, wps=9029.7, ups=0.35, wpb=25691.2, bsz=1093.6, num_updates=5600, lr=0.000422577, gnorm=0.592, loss_scale=4, train_wall=284, gb_free=13, wall=17863
2022-03-23 23:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:54:29 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-23 23:54:29 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-23 23:54:35 | INFO | fairseq.tasks.translation | example hypothesis: over the year, he can discuss about 8,000 places in the restaurant.
2022-03-23 23:54:35 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-23 23:54:41 | INFO | fairseq.tasks.translation | example hypothesis: , of course, i can expand this round magnet to shape any similarity.
2022-03-23 23:54:41 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-23 23:54:47 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father because his father had left his mother when she was pregnant.
2022-03-23 23:54:47 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-23 23:54:53 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we asked ourselves, well, what do we do with them?
2022-03-23 23:54:53 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-23 23:54:59 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender wedding, and not about genocide, or the spread of nuclear weapons or poverty, or any other speaker.
2022-03-23 23:54:59 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-23 23:55:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it if you move around, because your movements use energy, and that's how superconducting.
2022-03-23 23:55:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:55:11 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional face, which is where the big contexts of the face and the basic form, and then advance it through the fact that the whole porter structure and all the fine folds.
2022-03-23 23:55:11 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:55:17 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it interesting and measured it, for me here at tedwomen, is that... well, when it was stripped dinner, it was best summoned when someone said, "turn you to the men at your table and say, '"], if the revolution begins, then we support you. "'" '"' the truth, women, women, we've been supporting you in this queue for a long time."
2022-03-23 23:55:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:55:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're proud of at our airplane was a result of how we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuously variable operating and cooling system with refrigeration system that allows us to use an aircraft in the go-of-the-ground, or whatever the way that's going on the ground, except for a steady.
2022-03-23 23:55:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:55:19 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.45 | ppl 5.46 | bleu 31.49 | wps 3258.6 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.63
2022-03-23 23:55:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 23:55:19 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 23:55:19 | INFO | train | epoch 036 | loss 2.156 | ppl 4.46 | wps 7959.2 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.594 | loss_scale 4 | train_wall 439 | gb_free 14.3 | wall 18044
2022-03-23 23:55:20 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 23:55:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:57:49 | INFO | train_inner | epoch 037:     53 / 157 loss=2.154, ppl=4.45, wps=7429.6, ups=0.3, wpb=24594.8, bsz=930.9, num_updates=5700, lr=0.000418854, gnorm=0.568, loss_scale=4, train_wall=274, gb_free=13.2, wall=18194
2022-03-24 00:02:27 | INFO | train_inner | epoch 037:    153 / 157 loss=2.127, ppl=4.37, wps=9051.4, ups=0.36, wpb=25108.7, bsz=1017.4, num_updates=5800, lr=0.000415227, gnorm=0.602, loss_scale=4, train_wall=277, gb_free=14.2, wall=18471
2022-03-24 00:02:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-24 00:02:43 | INFO | fairseq.tasks.translation | example hypothesis: this probe can't use chemical rockets.
2022-03-24 00:02:43 | INFO | fairseq.tasks.translation | example reference: this probe actually can't use chemical rockets.
2022-03-24 00:02:49 | INFO | fairseq.tasks.translation | example hypothesis: over year, he can discuss about 8,000 places in the restaurant.
2022-03-24 00:02:49 | INFO | fairseq.tasks.translation | example reference: he can seat, throughout the year, he can seat 8,000 people.
2022-03-24 00:02:55 | INFO | fairseq.tasks.translation | example hypothesis: , of course, i can expand this round magnet to shape any similarity.
2022-03-24 00:02:55 | INFO | fairseq.tasks.translation | example reference: now, i can extend this circular magnet, and make whatever track i want.
2022-03-24 00:03:01 | INFO | fairseq.tasks.translation | example hypothesis: he had never met his father, because his father had left his mother when she was pregnant with him.
2022-03-24 00:03:01 | INFO | fairseq.tasks.translation | example reference: he never knew his father very well, because his father left his mom while she was pregnant with him.
2022-03-24 00:03:07 | INFO | fairseq.tasks.translation | example hypothesis: one of my cousins died of aids and left an orphanage, so we wondered, well, what are we doing with her?
2022-03-24 00:03:07 | INFO | fairseq.tasks.translation | example reference: a cousin of mine died of aids, left an orphan, so we said, well, what are we going to do with her?
2022-03-24 00:03:13 | INFO | fairseq.tasks.translation | example hypothesis: so we spend our time talking about things like gender marriage and not about genocide or the spread of nuclear weapons or poverty or any other promising issue.
2022-03-24 00:03:13 | INFO | fairseq.tasks.translation | example reference: this is why we spend our time talking about things like gay marriage and not about genocide or nuclear proliferation or poverty or any other hugely consequential issue.
2022-03-24 00:03:19 | INFO | fairseq.tasks.translation | example hypothesis: first, some strust of magnetic field are trapped inside, but the superconductor doesn't like it if you move, because your movements are using power, and so the superconductor disorders.
2022-03-24 00:03:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-24 00:03:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflective reflection, we can start with a traditional face that restores the big contexts of the face and the basic form, and breaks it through the thief of information that attract all the porter structure and all the ffin.
2022-03-24 00:03:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-24 00:03:31 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when constrict dinner, it was best summoned when someone said, "turn you to the men at your table and tell them," 'when the revolution starts, then we support you. "' the truth, women, we've been supporting you for this long time with stone borne."
2022-03-24 00:03:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-24 00:03:32 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work we stumbled on on our airplane was a result that we had to solve the unique problems that were connected to operating it on the floor -- everything from a continuously varying varieties and cooling system that allows us to use an aircraft in the go-to-hand vehicle vehicle vehicle, either to the ground.
2022-03-24 00:03:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-24 00:03:32 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 2.462 | ppl 5.51 | bleu 31.46 | wps 3325.3 | wpb 17862.2 | bsz 728.3 | num_updates 5804 | best_bleu 31.63
2022-03-24 00:03:32 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-24 00:03:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5804 updates
2022-03-24 00:03:32 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-24 00:03:32 | INFO | train | epoch 037 | loss 2.105 | ppl 4.3 | wps 8015.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5804 | lr 0.000415084 | gnorm 0.573 | loss_scale 4 | train_wall 437 | gb_free 13.6 | wall 18537
2022-03-24 00:03:32 | INFO | fairseq_cli.train | done training in 18536.2 seconds
