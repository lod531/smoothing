Sender: LSF System <lsfadmin@eu-g2-20>
Subject: Job 202625134: <w2_jelinek_0.09_0.01_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.09_0.01_0.9_#1> was submitted from host <eu-login-14> by user <andriusb> in cluster <euler> at Mon Jan 31 08:51:47 2022
Job was executed on host(s) <eu-g2-20>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Mon Jan 31 08:52:12 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Jan 31 08:52:12 2022
Terminated at Tue Feb  1 04:52:19 2022
Results reported at Tue Feb  1 04:52:19 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.09, 0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   72903.00 sec.
    Max Memory :                                 5182 MB
    Average Memory :                             2564.47 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14818.00 MB
    Max Swap :                                   551 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72007 sec.
    Turnaround time :                            72032 sec.

The output (if any) follows:

2022-01-31 08:52:21 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.09, 0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-01-31 08:52:21 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-01-31 08:52:23 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  4%|▎         | 1350/36718 [00:00<00:02, 13489.69it/s]  7%|▋         | 2699/36718 [00:00<00:02, 13031.77it/s] 11%|█▏        | 4177/36718 [00:00<00:02, 13802.99it/s] 16%|█▌        | 5740/36718 [00:00<00:02, 14510.76it/s] 20%|█▉        | 7194/36718 [00:00<00:02, 14066.33it/s] 23%|██▎       | 8604/36718 [00:00<00:02, 13640.94it/s] 27%|██▋       | 10015/36718 [00:00<00:01, 13784.84it/s] 31%|███       | 11397/36718 [00:00<00:01, 13454.82it/s] 35%|███▍      | 12749/36718 [00:00<00:01, 13467.73it/s] 39%|███▊      | 14169/36718 [00:01<00:01, 13687.18it/s] 42%|████▏     | 15593/36718 [00:01<00:01, 13851.47it/s] 46%|████▌     | 16980/36718 [00:01<00:01, 13684.00it/s] 50%|█████     | 18378/36718 [00:01<00:01, 13767.64it/s] 54%|█████▍    | 19932/36718 [00:01<00:01, 14292.33it/s] 58%|█████▊    | 21363/36718 [00:01<00:01, 13806.09it/s] 62%|██████▏   | 22833/36718 [00:01<00:00, 14065.04it/s] 67%|██████▋   | 24444/36718 [00:01<00:00, 14665.89it/s] 71%|███████   | 25924/36718 [00:01<00:00, 14703.54it/s] 75%|███████▍  | 27398/36718 [00:01<00:00, 13992.72it/s] 79%|███████▊  | 28834/36718 [00:02<00:00, 14097.99it/s] 82%|████████▏ | 30251/36718 [00:02<00:00, 13841.87it/s] 86%|████████▌ | 31641/36718 [00:02<00:00, 13474.28it/s] 90%|████████▉ | 32994/36718 [00:02<00:00, 13215.97it/s] 93%|█████████▎| 34319/36718 [00:02<00:00, 13149.49it/s] 97%|█████████▋| 35780/36718 [00:02<00:00, 13567.77it/s]100%|██████████| 36718/36718 [00:02<00:00, 13766.98it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  7%|▋         | 2731/36718 [00:00<00:01, 27308.07it/s] 16%|█▌        | 5883/36718 [00:00<00:01, 29783.07it/s] 24%|██▍       | 8862/36718 [00:00<00:00, 27962.84it/s] 32%|███▏      | 11671/36718 [00:00<00:00, 27900.82it/s] 39%|███▉      | 14492/36718 [00:00<00:00, 28005.03it/s] 47%|████▋     | 17298/36718 [00:00<00:00, 27865.20it/s] 55%|█████▍    | 20114/36718 [00:00<00:00, 27957.67it/s] 62%|██████▏   | 22913/36718 [00:00<00:00, 27820.20it/s] 71%|███████   | 25938/36718 [00:00<00:00, 28568.05it/s] 78%|███████▊  | 28797/36718 [00:01<00:00, 28047.43it/s] 86%|████████▌ | 31605/36718 [00:01<00:00, 27315.95it/s] 94%|█████████▎| 34342/36718 [00:01<00:00, 26844.56it/s]100%|██████████| 36718/36718 [00:01<00:00, 27730.89it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 199.11it/s]2022-01-31 08:52:36 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-01-31 08:52:36 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-01-31 08:52:36 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-01-31 08:52:36 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-01-31 08:52:36 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-01-31 08:52:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-01-31 08:52:36 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-01-31 08:52:36 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-01-31 08:52:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:52:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2022-01-31 08:52:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-01-31 08:52:36 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-01-31 08:52:36 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-01-31 08:52:36 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint_last.pt
2022-01-31 08:52:36 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint_last.pt
2022-01-31 08:52:36 | INFO | fairseq.trainer | loading train data for epoch 1
2022-01-31 08:52:36 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-01-31 08:52:36 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-01-31 08:52:36 | INFO | fairseq.trainer | begin training epoch 1
2022-01-31 08:52:36 | INFO | fairseq_cli.train | Start iterating over samples

2022-01-31 08:58:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-01-31 08:58:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.679 | ppl 26227.6 | wps 7967.4 | wpb 2034.1 | bsz 4 | num_updates 64
2022-01-31 08:58:28 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-01-31 08:58:28 | INFO | train | epoch 001 | loss 16.131 | ppl 71746.6 | wps 5944.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.273 | train_wall 323 | gb_free 6.1 | wall 353
KL Stats: Epoch 1 Divergences: Uniform: 0.5172925508133422 Unigram: 3.685318486297919
2022-01-31 08:58:28 | INFO | fairseq.trainer | begin training epoch 2
2022-01-31 08:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:01:31 | INFO | train_inner | epoch 002:     36 / 64 loss=15.584, ppl=49132, wps=6121.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.682, train_wall=505, gb_free=6.1, wall=535
2022-01-31 09:03:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:04:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.667 | ppl 13005.3 | wps 7931.9 | wpb 2034.1 | bsz 4 | num_updates 128
2022-01-31 09:04:20 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-01-31 09:04:20 | INFO | train | epoch 002 | loss 14.402 | ppl 21650.6 | wps 5948.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.512 | train_wall 323 | gb_free 6.1 | wall 704
KL Stats: Epoch 2 Divergences: Uniform: 0.5355066972682596 Unigram: 2.4150737509746527
2022-01-31 09:04:20 | INFO | fairseq.trainer | begin training epoch 3
2022-01-31 09:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:10:11 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.836 | ppl 7313.14 | wps 7917.4 | wpb 2034.1 | bsz 4 | num_updates 192
2022-01-31 09:10:11 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-01-31 09:10:11 | INFO | train | epoch 003 | loss 13.489 | ppl 11496.4 | wps 5941.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.219 | train_wall 323 | gb_free 6.1 | wall 1055
KL Stats: Epoch 3 Divergences: Uniform: 0.5218326599133369 Unigram: 1.7313023709848727
2022-01-31 09:10:11 | INFO | fairseq.trainer | begin training epoch 4
2022-01-31 09:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:10:52 | INFO | train_inner | epoch 004:      8 / 64 loss=13.623, ppl=12620.1, wps=5812.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.248, train_wall=504, gb_free=6.1, wall=1096
2022-01-31 09:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:16:01 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.98 | ppl 4038.3 | wps 8022.5 | wpb 2034.1 | bsz 4 | num_updates 256
2022-01-31 09:16:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-01-31 09:16:01 | INFO | train | epoch 004 | loss 12.532 | ppl 5920.87 | wps 5973.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 0.972 | train_wall 322 | gb_free 6.1 | wall 1405
KL Stats: Epoch 4 Divergences: Uniform: 0.6079998372450861 Unigram: 1.1139984562616057
2022-01-31 09:16:01 | INFO | fairseq.trainer | begin training epoch 5
2022-01-31 09:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:19:42 | INFO | train_inner | epoch 005:     44 / 64 loss=12.178, ppl=4634.5, wps=6165.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.853, train_wall=501, gb_free=6.1, wall=1626
2022-01-31 09:21:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:21:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.455 | ppl 2807.14 | wps 7933.1 | wpb 2034.1 | bsz 4 | num_updates 320
2022-01-31 09:21:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-01-31 09:21:49 | INFO | train | epoch 005 | loss 11.725 | ppl 3385.99 | wps 5997.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.694 | train_wall 320 | gb_free 6.1 | wall 1753
KL Stats: Epoch 5 Divergences: Uniform: 0.8527021028177504 Unigram: 0.6570025670544285
2022-01-31 09:21:49 | INFO | fairseq.trainer | begin training epoch 6
2022-01-31 09:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:27:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:27:40 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.208 | ppl 2365.91 | wps 7935.9 | wpb 2034.1 | bsz 4 | num_updates 384
2022-01-31 09:27:40 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-01-31 09:27:40 | INFO | train | epoch 006 | loss 11.288 | ppl 2500.35 | wps 5944.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.587 | train_wall 323 | gb_free 6.1 | wall 2104
KL Stats: Epoch 6 Divergences: Uniform: 1.158623902415679 Unigram: 0.4516596964502991
2022-01-31 09:27:40 | INFO | fairseq.trainer | begin training epoch 7
2022-01-31 09:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:29:02 | INFO | train_inner | epoch 007:     16 / 64 loss=11.311, ppl=2540.2, wps=5824.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.586, train_wall=503, gb_free=6.1, wall=2186
2022-01-31 09:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:33:32 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.065 | ppl 2142.7 | wps 7912.5 | wpb 2034.1 | bsz 4 | num_updates 448
2022-01-31 09:33:32 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-01-31 09:33:32 | INFO | train | epoch 007 | loss 11.085 | ppl 2172.54 | wps 5937.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.524 | train_wall 323 | gb_free 6.1 | wall 2456
KL Stats: Epoch 7 Divergences: Uniform: 1.392642527964186 Unigram: 0.45654338669681677
2022-01-31 09:33:32 | INFO | fairseq.trainer | begin training epoch 8
2022-01-31 09:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:37:57 | INFO | train_inner | epoch 008:     52 / 64 loss=11.024, ppl=2082.14, wps=6108.9, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.517, train_wall=506, gb_free=6.1, wall=2721
2022-01-31 09:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:39:24 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.962 | ppl 1994.18 | wps 7893.8 | wpb 2034.1 | bsz 4 | num_updates 512
2022-01-31 09:39:24 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-01-31 09:39:24 | INFO | train | epoch 008 | loss 10.972 | ppl 2009.09 | wps 5930.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.512 | train_wall 324 | gb_free 6.1 | wall 2808
KL Stats: Epoch 8 Divergences: Uniform: 1.5156018024966074 Unigram: 0.5258306782085844
2022-01-31 09:39:24 | INFO | fairseq.trainer | begin training epoch 9
2022-01-31 09:39:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:44:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:45:15 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.846 | ppl 1841.01 | wps 7933 | wpb 2034.1 | bsz 4 | num_updates 576
2022-01-31 09:45:15 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-01-31 09:45:15 | INFO | train | epoch 009 | loss 10.868 | ppl 1868.46 | wps 5952.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.486 | train_wall 322 | gb_free 6.1 | wall 3159
KL Stats: Epoch 9 Divergences: Uniform: 1.5656219075321887 Unigram: 0.6215845768683442
2022-01-31 09:45:15 | INFO | fairseq.trainer | begin training epoch 10
2022-01-31 09:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:47:17 | INFO | train_inner | epoch 010:     24 / 64 loss=10.859, ppl=1856.76, wps=5814.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.488, train_wall=504, gb_free=6.1, wall=3281
2022-01-31 09:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:51:07 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.743 | ppl 1713.51 | wps 7913.9 | wpb 2034.1 | bsz 4 | num_updates 640
2022-01-31 09:51:07 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-01-31 09:51:07 | INFO | train | epoch 010 | loss 10.759 | ppl 1733.43 | wps 5940.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.484 | train_wall 323 | gb_free 6.1 | wall 3511
KL Stats: Epoch 10 Divergences: Uniform: 1.5928129414902545 Unigram: 0.726575061791323
2022-01-31 09:51:07 | INFO | fairseq.trainer | begin training epoch 11
2022-01-31 09:51:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 09:56:11 | INFO | train_inner | epoch 011:     60 / 64 loss=10.684, ppl=1645.03, wps=6118.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.494, train_wall=505, gb_free=6.1, wall=3815
2022-01-31 09:56:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 09:56:58 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.636 | ppl 1591.08 | wps 7939.1 | wpb 2034.1 | bsz 4 | num_updates 704
2022-01-31 09:56:58 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-01-31 09:56:58 | INFO | train | epoch 011 | loss 10.644 | ppl 1600.58 | wps 5947.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.499 | train_wall 323 | gb_free 6.1 | wall 3862
KL Stats: Epoch 11 Divergences: Uniform: 1.6123376178889608 Unigram: 0.8304129090247766
2022-01-31 09:56:58 | INFO | fairseq.trainer | begin training epoch 12
2022-01-31 09:56:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:02:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:02:50 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.529 | ppl 1477.1 | wps 7935.4 | wpb 2034.1 | bsz 4 | num_updates 768
2022-01-31 10:02:50 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-01-31 10:02:50 | INFO | train | epoch 012 | loss 10.528 | ppl 1476.5 | wps 5935.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.478 | train_wall 323 | gb_free 6.1 | wall 4214
KL Stats: Epoch 12 Divergences: Uniform: 1.6237976215068786 Unigram: 0.931897225138668
2022-01-31 10:02:50 | INFO | fairseq.trainer | begin training epoch 13
2022-01-31 10:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:05:33 | INFO | train_inner | epoch 013:     32 / 64 loss=10.504, ppl=1452.23, wps=5807.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.492, train_wall=505, gb_free=6.1, wall=4377
2022-01-31 10:08:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:08:42 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.437 | ppl 1386.69 | wps 7978 | wpb 2034.1 | bsz 4 | num_updates 832
2022-01-31 10:08:42 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-01-31 10:08:42 | INFO | train | epoch 013 | loss 10.414 | ppl 1364.48 | wps 5934.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.518 | train_wall 324 | gb_free 6.1 | wall 4566
KL Stats: Epoch 13 Divergences: Uniform: 1.6509153539214831 Unigram: 1.0206337089915303
2022-01-31 10:08:42 | INFO | fairseq.trainer | begin training epoch 14
2022-01-31 10:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:14:33 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.344 | ppl 1300.03 | wps 7946.1 | wpb 2034.1 | bsz 4 | num_updates 896
2022-01-31 10:14:33 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-01-31 10:14:33 | INFO | train | epoch 014 | loss 10.304 | ppl 1263.76 | wps 5943.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.554 | train_wall 323 | gb_free 6.1 | wall 4917
KL Stats: Epoch 14 Divergences: Uniform: 1.677293718416745 Unigram: 1.103458534226754
2022-01-31 10:14:33 | INFO | fairseq.trainer | begin training epoch 15
2022-01-31 10:14:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:14:54 | INFO | train_inner | epoch 015:      4 / 64 loss=10.326, ppl=1283.69, wps=5812.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.536, train_wall=505, gb_free=6.1, wall=4938
2022-01-31 10:19:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:20:25 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.275 | ppl 1239.39 | wps 7928.9 | wpb 2034.1 | bsz 4 | num_updates 960
2022-01-31 10:20:25 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-01-31 10:20:25 | INFO | train | epoch 015 | loss 10.192 | ppl 1169.65 | wps 5939.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.532 | train_wall 323 | gb_free 6.1 | wall 5269
KL Stats: Epoch 15 Divergences: Uniform: 1.7021763677656307 Unigram: 1.1782900924106943
2022-01-31 10:20:25 | INFO | fairseq.trainer | begin training epoch 16
2022-01-31 10:20:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:23:48 | INFO | train_inner | epoch 016:     40 / 64 loss=10.151, ppl=1136.82, wps=6114, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.553, train_wall=506, gb_free=6.1, wall=5472
2022-01-31 10:25:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:26:16 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.196 | ppl 1172.82 | wps 7990.7 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-01-31 10:26:16 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-01-31 10:26:16 | INFO | train | epoch 016 | loss 10.086 | ppl 1086.63 | wps 5945.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.553 | train_wall 323 | gb_free 6.1 | wall 5620
KL Stats: Epoch 16 Divergences: Uniform: 1.7317401962284507 Unigram: 1.2510396704586992
2022-01-31 10:26:16 | INFO | fairseq.trainer | begin training epoch 17
2022-01-31 10:26:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:31:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:32:08 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.102 | ppl 1099.16 | wps 7898.9 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-01-31 10:32:08 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-01-31 10:32:08 | INFO | train | epoch 017 | loss 9.979 | ppl 1009.13 | wps 5943.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.544 | train_wall 323 | gb_free 6.1 | wall 5972
KL Stats: Epoch 17 Divergences: Uniform: 1.7665163546840297 Unigram: 1.3139824541843683
2022-01-31 10:32:08 | INFO | fairseq.trainer | begin training epoch 18
2022-01-31 10:32:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:33:09 | INFO | train_inner | epoch 018:     12 / 64 loss=9.993, ppl=1019.04, wps=5816.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.548, train_wall=504, gb_free=6.1, wall=6033
2022-01-31 10:37:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:37:58 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.036 | ppl 1050.04 | wps 8002.5 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-01-31 10:37:58 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-01-31 10:37:58 | INFO | train | epoch 018 | loss 9.878 | ppl 941.25 | wps 5955 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.569 | train_wall 323 | gb_free 6.1 | wall 6322
KL Stats: Epoch 18 Divergences: Uniform: 1.8017846695645565 Unigram: 1.375909205706343
2022-01-31 10:37:58 | INFO | fairseq.trainer | begin training epoch 19
2022-01-31 10:37:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:42:00 | INFO | train_inner | epoch 019:     48 / 64 loss=9.829, ppl=909.47, wps=6144.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.541, train_wall=503, gb_free=6.1, wall=6565
2022-01-31 10:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:43:47 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.965 | ppl 999.23 | wps 7987.9 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-01-31 10:43:47 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-01-31 10:43:47 | INFO | train | epoch 019 | loss 9.775 | ppl 876.26 | wps 5983.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.528 | train_wall 321 | gb_free 6.1 | wall 6671
KL Stats: Epoch 19 Divergences: Uniform: 1.8337019048581586 Unigram: 1.4378193049657308
2022-01-31 10:43:47 | INFO | fairseq.trainer | begin training epoch 20
2022-01-31 10:43:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:49:38 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.879 | ppl 941.94 | wps 7919.5 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-01-31 10:49:38 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-01-31 10:49:38 | INFO | train | epoch 020 | loss 9.679 | ppl 819.72 | wps 5963.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.554 | train_wall 322 | gb_free 6.1 | wall 7022
KL Stats: Epoch 20 Divergences: Uniform: 1.8650812480484598 Unigram: 1.4935647577801334
2022-01-31 10:49:38 | INFO | fairseq.trainer | begin training epoch 21
2022-01-31 10:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 10:51:19 | INFO | train_inner | epoch 021:     20 / 64 loss=9.674, ppl=816.96, wps=5835.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.549, train_wall=502, gb_free=6.1, wall=7123
2022-01-31 10:55:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 10:55:29 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.836 | ppl 914.09 | wps 7955.9 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-01-31 10:55:29 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-01-31 10:55:29 | INFO | train | epoch 021 | loss 9.585 | ppl 767.88 | wps 5951.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.522 | train_wall 323 | gb_free 6.1 | wall 7373
KL Stats: Epoch 21 Divergences: Uniform: 1.8959466477684905 Unigram: 1.5474696312805731
2022-01-31 10:55:29 | INFO | fairseq.trainer | begin training epoch 22
2022-01-31 10:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:00:13 | INFO | train_inner | epoch 022:     56 / 64 loss=9.532, ppl=740.38, wps=6118.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.529, train_wall=505, gb_free=6.1, wall=7657
2022-01-31 11:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:01:20 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.772 | ppl 874.3 | wps 7896.4 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-01-31 11:01:20 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-01-31 11:01:20 | INFO | train | epoch 022 | loss 9.496 | ppl 721.95 | wps 5937.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.542 | train_wall 323 | gb_free 6.1 | wall 7724
KL Stats: Epoch 22 Divergences: Uniform: 1.9216239144417957 Unigram: 1.599239671066291
2022-01-31 11:01:20 | INFO | fairseq.trainer | begin training epoch 23
2022-01-31 11:01:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:07:12 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.713 | ppl 839.35 | wps 7931.8 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-01-31 11:07:12 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-01-31 11:07:12 | INFO | train | epoch 023 | loss 9.409 | ppl 679.96 | wps 5938.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.515 | train_wall 323 | gb_free 6.1 | wall 8076
KL Stats: Epoch 23 Divergences: Uniform: 1.949994775913474 Unigram: 1.646232332910266
2022-01-31 11:07:12 | INFO | fairseq.trainer | begin training epoch 24
2022-01-31 11:07:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:09:34 | INFO | train_inner | epoch 024:     28 / 64 loss=9.394, ppl=672.87, wps=5814.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.526, train_wall=504, gb_free=6.1, wall=8218
2022-01-31 11:12:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:13:03 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.654 | ppl 805.76 | wps 7931.3 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-01-31 11:13:03 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-01-31 11:13:03 | INFO | train | epoch 024 | loss 9.326 | ppl 641.69 | wps 5953.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.546 | train_wall 322 | gb_free 6.1 | wall 8427
KL Stats: Epoch 24 Divergences: Uniform: 1.9727753792875775 Unigram: 1.6889862349654534
2022-01-31 11:13:03 | INFO | fairseq.trainer | begin training epoch 25
2022-01-31 11:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:18:26 | INFO | train_inner | epoch 025:     64 / 64 loss=9.272, ppl=618.13, wps=6123.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.53, train_wall=503, gb_free=6.1, wall=8750
2022-01-31 11:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:18:54 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.624 | ppl 789.3 | wps 7885.9 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-01-31 11:18:54 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-01-31 11:18:54 | INFO | train | epoch 025 | loss 9.244 | ppl 606.39 | wps 5947.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.521 | train_wall 323 | gb_free 6.1 | wall 8778
KL Stats: Epoch 25 Divergences: Uniform: 2.0026716159493776 Unigram: 1.7330858693671025
2022-01-31 11:18:54 | INFO | fairseq.trainer | begin training epoch 26
2022-01-31 11:18:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:24:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:24:45 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.576 | ppl 763.5 | wps 7936 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-01-31 11:24:45 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-01-31 11:24:45 | INFO | train | epoch 026 | loss 9.163 | ppl 573.26 | wps 5946.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.534 | train_wall 323 | gb_free 6.1 | wall 9129
KL Stats: Epoch 26 Divergences: Uniform: 2.0169362838777287 Unigram: 1.7723366416299602
2022-01-31 11:24:45 | INFO | fairseq.trainer | begin training epoch 27
2022-01-31 11:24:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:27:48 | INFO | train_inner | epoch 027:     36 / 64 loss=9.135, ppl=562.15, wps=5819.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.523, train_wall=505, gb_free=6.1, wall=9312
2022-01-31 11:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:30:36 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.543 | ppl 745.9 | wps 7918.3 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-01-31 11:30:36 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-01-31 11:30:36 | INFO | train | epoch 027 | loss 9.082 | ppl 542.07 | wps 5952.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.514 | train_wall 322 | gb_free 6.1 | wall 9480
KL Stats: Epoch 27 Divergences: Uniform: 2.0451686198162173 Unigram: 1.8091918034813852
2022-01-31 11:30:36 | INFO | fairseq.trainer | begin training epoch 28
2022-01-31 11:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:36:28 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.514 | ppl 731.27 | wps 7943.5 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-01-31 11:36:28 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-01-31 11:36:28 | INFO | train | epoch 028 | loss 9.005 | ppl 513.67 | wps 5943 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.522 | train_wall 323 | gb_free 6.1 | wall 9832
KL Stats: Epoch 28 Divergences: Uniform: 2.0734511726547016 Unigram: 1.846561328919263
2022-01-31 11:36:28 | INFO | fairseq.trainer | begin training epoch 29
2022-01-31 11:36:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:37:08 | INFO | train_inner | epoch 029:      8 / 64 loss=9.02, ppl=519.29, wps=5815.5, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.527, train_wall=504, gb_free=6.1, wall=9872
2022-01-31 11:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:42:18 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.483 | ppl 715.84 | wps 7940.3 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-01-31 11:42:18 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-01-31 11:42:18 | INFO | train | epoch 029 | loss 8.926 | ppl 486.44 | wps 5951.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.529 | train_wall 323 | gb_free 6.1 | wall 10183
KL Stats: Epoch 29 Divergences: Uniform: 2.0946086788516123 Unigram: 1.882260890309672
2022-01-31 11:42:18 | INFO | fairseq.trainer | begin training epoch 30
2022-01-31 11:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:46:02 | INFO | train_inner | epoch 030:     44 / 64 loss=8.893, ppl=475.35, wps=6127.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.517, train_wall=505, gb_free=6.1, wall=10406
2022-01-31 11:47:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:48:09 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.462 | ppl 705.19 | wps 7927.2 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-01-31 11:48:09 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-01-31 11:48:09 | INFO | train | epoch 030 | loss 8.848 | ppl 460.8 | wps 5954.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.516 | train_wall 322 | gb_free 6.1 | wall 10533
KL Stats: Epoch 30 Divergences: Uniform: 2.1129783086653977 Unigram: 1.9192933076442849
2022-01-31 11:48:09 | INFO | fairseq.trainer | begin training epoch 31
2022-01-31 11:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:53:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:54:01 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.411 | ppl 680.78 | wps 7906.8 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-01-31 11:54:01 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-01-31 11:54:01 | INFO | train | epoch 031 | loss 8.769 | ppl 436.27 | wps 5940.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.494 | train_wall 323 | gb_free 6.1 | wall 10885
KL Stats: Epoch 31 Divergences: Uniform: 2.1328234181528987 Unigram: 1.951347608752532
2022-01-31 11:54:01 | INFO | fairseq.trainer | begin training epoch 32
2022-01-31 11:54:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 11:55:22 | INFO | train_inner | epoch 032:     16 / 64 loss=8.77, ppl=436.67, wps=5816.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.502, train_wall=504, gb_free=6.1, wall=10966
2022-01-31 11:59:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 11:59:52 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.375 | ppl 663.8 | wps 7952.9 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-01-31 11:59:52 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-01-31 11:59:52 | INFO | train | epoch 032 | loss 8.695 | ppl 414.53 | wps 5946.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.507 | train_wall 323 | gb_free 6.1 | wall 11236
KL Stats: Epoch 32 Divergences: Uniform: 2.1587278027032886 Unigram: 1.985949289624129
2022-01-31 11:59:52 | INFO | fairseq.trainer | begin training epoch 33
2022-01-31 11:59:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:04:16 | INFO | train_inner | epoch 033:     52 / 64 loss=8.658, ppl=404.03, wps=6125.6, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.507, train_wall=505, gb_free=6.1, wall=11500
2022-01-31 12:05:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:05:43 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.362 | ppl 658.15 | wps 7903.6 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-01-31 12:05:43 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-01-31 12:05:43 | INFO | train | epoch 033 | loss 8.621 | ppl 393.67 | wps 5952.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.505 | train_wall 322 | gb_free 6.1 | wall 11587
KL Stats: Epoch 33 Divergences: Uniform: 2.185260094275646 Unigram: 2.0201879666214566
2022-01-31 12:05:43 | INFO | fairseq.trainer | begin training epoch 34
2022-01-31 12:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:11:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:11:33 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.346 | ppl 650.72 | wps 8011.1 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-01-31 12:11:33 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-01-31 12:11:33 | INFO | train | epoch 034 | loss 8.545 | ppl 373.54 | wps 5966.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.507 | train_wall 322 | gb_free 6.1 | wall 11937
KL Stats: Epoch 34 Divergences: Uniform: 2.2078339469416957 Unigram: 2.0538029326791505
2022-01-31 12:11:33 | INFO | fairseq.trainer | begin training epoch 35
2022-01-31 12:11:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:13:34 | INFO | train_inner | epoch 035:     24 / 64 loss=8.533, ppl=370.29, wps=5839, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.507, train_wall=502, gb_free=6.1, wall=12058
2022-01-31 12:16:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:17:22 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.316 | ppl 637.46 | wps 8018.6 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-01-31 12:17:22 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-01-31 12:17:22 | INFO | train | epoch 035 | loss 8.474 | ppl 355.45 | wps 5990.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.504 | train_wall 320 | gb_free 6.1 | wall 12286
KL Stats: Epoch 35 Divergences: Uniform: 2.229343265943193 Unigram: 2.0819022033249492
2022-01-31 12:17:22 | INFO | fairseq.trainer | begin training epoch 36
2022-01-31 12:17:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:22:26 | INFO | train_inner | epoch 036:     60 / 64 loss=8.429, ppl=344.68, wps=6140.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.497, train_wall=504, gb_free=6.1, wall=12590
2022-01-31 12:22:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:23:13 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.286 | ppl 624.13 | wps 7950.4 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-01-31 12:23:13 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-01-31 12:23:13 | INFO | train | epoch 036 | loss 8.399 | ppl 337.59 | wps 5947.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.494 | train_wall 323 | gb_free 6.1 | wall 12637
KL Stats: Epoch 36 Divergences: Uniform: 2.250290759235184 Unigram: 2.1151387002591924
2022-01-31 12:23:13 | INFO | fairseq.trainer | begin training epoch 37
2022-01-31 12:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:28:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:29:04 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.3 | ppl 630.17 | wps 7935.5 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-01-31 12:29:04 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-01-31 12:29:04 | INFO | train | epoch 037 | loss 8.33 | ppl 321.79 | wps 5943.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.506 | train_wall 323 | gb_free 6.1 | wall 12988
KL Stats: Epoch 37 Divergences: Uniform: 2.271226338370874 Unigram: 2.1479327047977033
2022-01-31 12:29:04 | INFO | fairseq.trainer | begin training epoch 38
2022-01-31 12:29:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:31:47 | INFO | train_inner | epoch 038:     32 / 64 loss=8.309, ppl=317.05, wps=5814.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.503, train_wall=504, gb_free=6.1, wall=13151
2022-01-31 12:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:34:56 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.282 | ppl 622.59 | wps 7907 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-01-31 12:34:56 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-01-31 12:34:56 | INFO | train | epoch 038 | loss 8.262 | ppl 306.95 | wps 5941.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.507 | train_wall 323 | gb_free 6.1 | wall 13340
KL Stats: Epoch 38 Divergences: Uniform: 2.3018023846046796 Unigram: 2.1705607920289833
2022-01-31 12:34:56 | INFO | fairseq.trainer | begin training epoch 39
2022-01-31 12:34:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:40:47 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.266 | ppl 615.56 | wps 7957.2 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-01-31 12:40:47 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-01-31 12:40:47 | INFO | train | epoch 039 | loss 8.193 | ppl 292.56 | wps 5944.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.494 | train_wall 323 | gb_free 6.1 | wall 13691
KL Stats: Epoch 39 Divergences: Uniform: 2.311048492981072 Unigram: 2.206612928570825
2022-01-31 12:40:47 | INFO | fairseq.trainer | begin training epoch 40
2022-01-31 12:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:41:08 | INFO | train_inner | epoch 040:      4 / 64 loss=8.215, ppl=297.05, wps=5813.7, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.5, train_wall=504, gb_free=6.1, wall=13712
2022-01-31 12:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:46:39 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.246 | ppl 607.32 | wps 7888.2 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-01-31 12:46:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-01-31 12:46:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt
2022-01-31 12:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt
2022-01-31 12:46:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.246) (writing took 5.169515993446112 seconds)
2022-01-31 12:46:44 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-01-31 12:46:44 | INFO | train | epoch 040 | loss 8.125 | ppl 279.09 | wps 5856.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.498 | train_wall 323 | gb_free 6.1 | wall 14048
KL Stats: Epoch 40 Divergences: Uniform: 2.3392316898239276 Unigram: 2.233293056382214
2022-01-31 12:46:44 | INFO | fairseq.trainer | begin training epoch 41
2022-01-31 12:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:50:06 | INFO | train_inner | epoch 041:     40 / 64 loss=8.101, ppl=274.59, wps=6065, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.497, train_wall=505, gb_free=6.1, wall=14251
2022-01-31 12:52:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:52:35 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.24 | ppl 604.83 | wps 7914.7 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.24
2022-01-31 12:52:35 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-01-31 12:52:35 | INFO | train | epoch 041 | loss 8.061 | ppl 267.01 | wps 5951.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.5 | train_wall 322 | gb_free 6.1 | wall 14399
KL Stats: Epoch 41 Divergences: Uniform: 2.3539291284267394 Unigram: 2.2586266373296975
2022-01-31 12:52:35 | INFO | fairseq.trainer | begin training epoch 42
2022-01-31 12:52:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:57:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 12:58:26 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.213 | ppl 593.27 | wps 7939.3 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.213
2022-01-31 12:58:26 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-01-31 12:58:26 | INFO | train | epoch 042 | loss 7.997 | ppl 255.42 | wps 5945.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.507 | train_wall 323 | gb_free 6.1 | wall 14750
KL Stats: Epoch 42 Divergences: Uniform: 2.373181215456418 Unigram: 2.2907259681200483
2022-01-31 12:58:26 | INFO | fairseq.trainer | begin training epoch 43
2022-01-31 12:58:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 12:59:27 | INFO | train_inner | epoch 043:     12 / 64 loss=8.003, ppl=256.56, wps=5815.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.506, train_wall=504, gb_free=6.1, wall=14811
2022-01-31 13:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:04:17 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.242 | ppl 605.34 | wps 7911.4 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.242
2022-01-31 13:04:17 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-01-31 13:04:17 | INFO | train | epoch 043 | loss 7.932 | ppl 244.17 | wps 5946.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.497 | train_wall 323 | gb_free 6.1 | wall 15101
KL Stats: Epoch 43 Divergences: Uniform: 2.39493089001601 Unigram: 2.3174577780527588
2022-01-31 13:04:17 | INFO | fairseq.trainer | begin training epoch 44
2022-01-31 13:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:08:21 | INFO | train_inner | epoch 044:     48 / 64 loss=7.897, ppl=238.43, wps=6118.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.499, train_wall=505, gb_free=6.1, wall=15345
2022-01-31 13:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:10:09 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.242 | ppl 605.69 | wps 7905 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.242
2022-01-31 13:10:09 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-01-31 13:10:09 | INFO | train | epoch 044 | loss 7.872 | ppl 234.26 | wps 5942.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.502 | train_wall 323 | gb_free 6.1 | wall 15453
KL Stats: Epoch 44 Divergences: Uniform: 2.412821130862619 Unigram: 2.340842516116444
2022-01-31 13:10:09 | INFO | fairseq.trainer | begin training epoch 45
2022-01-31 13:10:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:16:00 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.221 | ppl 596.66 | wps 7922.3 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.221
2022-01-31 13:16:00 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-01-31 13:16:00 | INFO | train | epoch 045 | loss 7.81 | ppl 224.36 | wps 5943.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.504 | train_wall 323 | gb_free 6.1 | wall 15804
KL Stats: Epoch 45 Divergences: Uniform: 2.4316907512099277 Unigram: 2.371139778331074
2022-01-31 13:16:00 | INFO | fairseq.trainer | begin training epoch 46
2022-01-31 13:16:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:17:42 | INFO | train_inner | epoch 046:     20 / 64 loss=7.809, ppl=224.28, wps=5815.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.504, train_wall=504, gb_free=6.1, wall=15906
2022-01-31 13:21:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:21:52 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.227 | ppl 599.36 | wps 7920.2 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.227
2022-01-31 13:21:52 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-01-31 13:21:52 | INFO | train | epoch 046 | loss 7.751 | ppl 215.37 | wps 5941.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.507 | train_wall 323 | gb_free 6.1 | wall 16156
KL Stats: Epoch 46 Divergences: Uniform: 2.44571838345043 Unigram: 2.389719107073781
2022-01-31 13:21:52 | INFO | fairseq.trainer | begin training epoch 47
2022-01-31 13:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:26:36 | INFO | train_inner | epoch 047:     56 / 64 loss=7.72, ppl=210.81, wps=6112, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.499, train_wall=506, gb_free=6.1, wall=16441
2022-01-31 13:27:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:27:43 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.208 | ppl 591.33 | wps 7910.6 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.208
2022-01-31 13:27:43 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-01-31 13:27:43 | INFO | train | epoch 047 | loss 7.692 | ppl 206.72 | wps 5938.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.492 | train_wall 323 | gb_free 6.1 | wall 16508
KL Stats: Epoch 47 Divergences: Uniform: 2.4685463246058954 Unigram: 2.412590927406782
2022-01-31 13:27:43 | INFO | fairseq.trainer | begin training epoch 48
2022-01-31 13:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:33:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:33:35 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.206 | ppl 590.43 | wps 7914 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.206
2022-01-31 13:33:35 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-01-31 13:33:35 | INFO | train | epoch 048 | loss 7.635 | ppl 198.75 | wps 5948.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.508 | train_wall 323 | gb_free 6.1 | wall 16859
KL Stats: Epoch 48 Divergences: Uniform: 2.4871440295690546 Unigram: 2.442350126085311
2022-01-31 13:33:35 | INFO | fairseq.trainer | begin training epoch 49
2022-01-31 13:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:35:57 | INFO | train_inner | epoch 049:     28 / 64 loss=7.617, ppl=196.34, wps=5816.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.504, train_wall=504, gb_free=6.1, wall=17001
2022-01-31 13:38:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:39:25 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.233 | ppl 601.7 | wps 7966.1 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.233
2022-01-31 13:39:25 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-01-31 13:39:25 | INFO | train | epoch 049 | loss 7.578 | ppl 191.08 | wps 5954.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.507 | train_wall 322 | gb_free 6.1 | wall 17209
KL Stats: Epoch 49 Divergences: Uniform: 2.492513298935431 Unigram: 2.4626103808389894
2022-01-31 13:39:25 | INFO | fairseq.trainer | begin training epoch 50
2022-01-31 13:39:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:44:46 | INFO | train_inner | epoch 050:     64 / 64 loss=7.553, ppl=187.82, wps=6158.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.52, train_wall=501, gb_free=6.1, wall=17530
2022-01-31 13:44:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:45:14 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.242 | ppl 605.51 | wps 7987.9 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.242
2022-01-31 13:45:14 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-01-31 13:45:14 | INFO | train | epoch 050 | loss 7.526 | ppl 184.35 | wps 5997.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.524 | train_wall 320 | gb_free 6.1 | wall 17558
KL Stats: Epoch 50 Divergences: Uniform: 2.5132236073295435 Unigram: 2.4790649263794244
2022-01-31 13:45:14 | INFO | fairseq.trainer | begin training epoch 51
2022-01-31 13:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:50:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:51:04 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.26 | ppl 613.29 | wps 7893.8 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.246
2022-01-31 13:51:04 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-01-31 13:51:04 | INFO | train | epoch 051 | loss 7.47 | ppl 177.31 | wps 5962.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.505 | train_wall 322 | gb_free 6.1 | wall 17908
KL Stats: Epoch 51 Divergences: Uniform: 2.5384572158640775 Unigram: 2.5002152715531447
2022-01-31 13:51:04 | INFO | fairseq.trainer | begin training epoch 52
2022-01-31 13:51:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 13:54:06 | INFO | train_inner | epoch 052:     36 / 64 loss=7.446, ppl=174.39, wps=5832.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.504, train_wall=504, gb_free=6.1, wall=18091
2022-01-31 13:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 13:56:55 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.248 | ppl 607.87 | wps 7944.4 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.246
2022-01-31 13:56:55 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-01-31 13:56:55 | INFO | train | epoch 052 | loss 7.418 | ppl 171.02 | wps 5955.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.512 | train_wall 322 | gb_free 6.1 | wall 18259
KL Stats: Epoch 52 Divergences: Uniform: 2.5459241317845533 Unigram: 2.5297980139216367
2022-01-31 13:56:55 | INFO | fairseq.trainer | begin training epoch 53
2022-01-31 13:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:02:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:02:46 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.215 | ppl 594.48 | wps 7911.1 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.215
2022-01-31 14:02:46 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-01-31 14:02:46 | INFO | train | epoch 053 | loss 7.367 | ppl 165.04 | wps 5948.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.499 | train_wall 323 | gb_free 6.1 | wall 18610
KL Stats: Epoch 53 Divergences: Uniform: 2.571177017408321 Unigram: 2.546479536065831
2022-01-31 14:02:46 | INFO | fairseq.trainer | begin training epoch 54
2022-01-31 14:02:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:03:27 | INFO | train_inner | epoch 054:      8 / 64 loss=7.38, ppl=166.53, wps=5820.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.51, train_wall=503, gb_free=6.1, wall=18651
2022-01-31 14:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:08:38 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.28 | ppl 621.83 | wps 7901.5 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.246
2022-01-31 14:08:38 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-01-31 14:08:38 | INFO | train | epoch 054 | loss 7.316 | ppl 159.36 | wps 5929.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.515 | train_wall 324 | gb_free 6.1 | wall 18962
KL Stats: Epoch 54 Divergences: Uniform: 2.575243285746771 Unigram: 2.5651617547537664
2022-01-31 14:08:38 | INFO | fairseq.trainer | begin training epoch 55
2022-01-31 14:08:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:12:22 | INFO | train_inner | epoch 055:     44 / 64 loss=7.289, ppl=156.37, wps=6103.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.516, train_wall=506, gb_free=6.1, wall=19186
2022-01-31 14:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:14:30 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.271 | ppl 617.99 | wps 7944.7 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.246
2022-01-31 14:14:30 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-01-31 14:14:30 | INFO | train | epoch 055 | loss 7.27 | ppl 154.31 | wps 5938.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.533 | train_wall 323 | gb_free 6.1 | wall 19314
KL Stats: Epoch 55 Divergences: Uniform: 2.592504079321782 Unigram: 2.5896378388893746
2022-01-31 14:14:30 | INFO | fairseq.trainer | begin training epoch 56
2022-01-31 14:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:19:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:20:21 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.38 | ppl 666.5 | wps 7943.9 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.246
2022-01-31 14:20:21 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-01-31 14:20:21 | INFO | train | epoch 056 | loss 7.22 | ppl 149.05 | wps 5943.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.515 | train_wall 323 | gb_free 6.1 | wall 19665
KL Stats: Epoch 56 Divergences: Uniform: 2.588788986840991 Unigram: 2.6029715724272884
2022-01-31 14:20:21 | INFO | fairseq.trainer | begin training epoch 57
2022-01-31 14:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:21:42 | INFO | train_inner | epoch 057:     16 / 64 loss=7.224, ppl=149.48, wps=5816.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.525, train_wall=504, gb_free=6.1, wall=19747
2022-01-31 14:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:26:13 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.356 | ppl 655.47 | wps 7932.1 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.246
2022-01-31 14:26:13 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-01-31 14:26:13 | INFO | train | epoch 057 | loss 7.173 | ppl 144.27 | wps 5941.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.526 | train_wall 323 | gb_free 6.1 | wall 20017
KL Stats: Epoch 57 Divergences: Uniform: 2.6248513855407145 Unigram: 2.6314225590498883
2022-01-31 14:26:13 | INFO | fairseq.trainer | begin training epoch 58
2022-01-31 14:26:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:30:37 | INFO | train_inner | epoch 058:     52 / 64 loss=7.149, ppl=141.94, wps=6111.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.528, train_wall=506, gb_free=6.1, wall=20281
2022-01-31 14:31:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:32:04 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.348 | ppl 651.56 | wps 7946.3 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.246
2022-01-31 14:32:04 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-01-31 14:32:04 | INFO | train | epoch 058 | loss 7.129 | ppl 140 | wps 5937.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.529 | train_wall 323 | gb_free 6.1 | wall 20368
KL Stats: Epoch 58 Divergences: Uniform: 2.6320366394874313 Unigram: 2.6464217880594427
2022-01-31 14:32:04 | INFO | fairseq.trainer | begin training epoch 59
2022-01-31 14:32:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:37:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:37:56 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.444 | ppl 696.67 | wps 7982.5 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.246
2022-01-31 14:37:56 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-01-31 14:37:56 | INFO | train | epoch 059 | loss 7.084 | ppl 135.7 | wps 5940 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.527 | train_wall 323 | gb_free 6.1 | wall 20720
KL Stats: Epoch 59 Divergences: Uniform: 2.6483546816609564 Unigram: 2.661073766599165
2022-01-31 14:37:56 | INFO | fairseq.trainer | begin training epoch 60
2022-01-31 14:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:39:58 | INFO | train_inner | epoch 060:     24 / 64 loss=7.078, ppl=135.14, wps=5814.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.533, train_wall=504, gb_free=6.1, wall=20842
2022-01-31 14:43:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:43:48 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.374 | ppl 663.38 | wps 7925.9 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.246
2022-01-31 14:43:48 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-01-31 14:43:48 | INFO | train | epoch 060 | loss 7.039 | ppl 131.52 | wps 5941.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.536 | train_wall 323 | gb_free 6.1 | wall 21072
KL Stats: Epoch 60 Divergences: Uniform: 2.663031051172662 Unigram: 2.686090431264174
2022-01-31 14:43:48 | INFO | fairseq.trainer | begin training epoch 61
2022-01-31 14:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:48:52 | INFO | train_inner | epoch 061:     60 / 64 loss=7.019, ppl=129.71, wps=6113.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.535, train_wall=506, gb_free=6.1, wall=21377
2022-01-31 14:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:49:39 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.434 | ppl 691.88 | wps 7911.1 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.246
2022-01-31 14:49:39 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-01-31 14:49:39 | INFO | train | epoch 061 | loss 6.996 | ppl 127.67 | wps 5940 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.542 | train_wall 323 | gb_free 6.1 | wall 21423
KL Stats: Epoch 61 Divergences: Uniform: 2.6812445053882827 Unigram: 2.6953474898577476
2022-01-31 14:49:39 | INFO | fairseq.trainer | begin training epoch 62
2022-01-31 14:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 14:55:31 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.409 | ppl 679.96 | wps 7901.5 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.246
2022-01-31 14:55:31 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-01-31 14:55:31 | INFO | train | epoch 062 | loss 6.955 | ppl 124.04 | wps 5939.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.538 | train_wall 323 | gb_free 6.1 | wall 21775
KL Stats: Epoch 62 Divergences: Uniform: 2.687262237415915 Unigram: 2.7204856309581746
2022-01-31 14:55:31 | INFO | fairseq.trainer | begin training epoch 63
2022-01-31 14:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 14:58:14 | INFO | train_inner | epoch 063:     32 / 64 loss=6.929, ppl=121.85, wps=5807.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.538, train_wall=505, gb_free=6.1, wall=21938
2022-01-31 15:00:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:01:23 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.431 | ppl 690.24 | wps 7926.9 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.246
2022-01-31 15:01:23 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-01-31 15:01:23 | INFO | train | epoch 063 | loss 6.912 | ppl 120.4 | wps 5930.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.536 | train_wall 324 | gb_free 6.1 | wall 22127
KL Stats: Epoch 63 Divergences: Uniform: 2.7028314626010532 Unigram: 2.7365208688017213
2022-01-31 15:01:23 | INFO | fairseq.trainer | begin training epoch 64
2022-01-31 15:01:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:07:15 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.458 | ppl 703.14 | wps 7914.3 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.246
2022-01-31 15:07:15 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-01-31 15:07:15 | INFO | train | epoch 064 | loss 6.869 | ppl 116.89 | wps 5933.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.546 | train_wall 323 | gb_free 6.1 | wall 22479
KL Stats: Epoch 64 Divergences: Uniform: 2.71180065716313 Unigram: 2.753621684356737
2022-01-31 15:07:15 | INFO | fairseq.trainer | begin training epoch 65
2022-01-31 15:07:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:07:35 | INFO | train_inner | epoch 065:      4 / 64 loss=6.896, ppl=119.1, wps=5803.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.544, train_wall=505, gb_free=6.1, wall=22500
2022-01-31 15:12:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:13:05 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.504 | ppl 726.05 | wps 8021.4 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.246
2022-01-31 15:13:05 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-01-31 15:13:05 | INFO | train | epoch 065 | loss 6.826 | ppl 113.49 | wps 5973.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.552 | train_wall 322 | gb_free 6.1 | wall 22829
KL Stats: Epoch 65 Divergences: Uniform: 2.7159273904850365 Unigram: 2.771189072160683
2022-01-31 15:13:05 | INFO | fairseq.trainer | begin training epoch 66
2022-01-31 15:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:16:26 | INFO | train_inner | epoch 066:     40 / 64 loss=6.802, ppl=111.57, wps=6157.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.555, train_wall=502, gb_free=6.1, wall=23030
2022-01-31 15:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:18:53 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.478 | ppl 713.33 | wps 7958.2 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.246
2022-01-31 15:18:53 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-01-31 15:18:53 | INFO | train | epoch 066 | loss 6.786 | ppl 110.38 | wps 5989.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.558 | train_wall 320 | gb_free 6.1 | wall 23177
KL Stats: Epoch 66 Divergences: Uniform: 2.7363678512708693 Unigram: 2.7854401653626732
2022-01-31 15:18:53 | INFO | fairseq.trainer | begin training epoch 67
2022-01-31 15:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:24:44 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.455 | ppl 701.94 | wps 7905.7 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.246
2022-01-31 15:24:44 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-01-31 15:24:44 | INFO | train | epoch 067 | loss 6.745 | ppl 107.3 | wps 5947.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.554 | train_wall 323 | gb_free 6.1 | wall 23529
KL Stats: Epoch 67 Divergences: Uniform: 2.7525707326144895 Unigram: 2.8078312264301486
2022-01-31 15:24:44 | INFO | fairseq.trainer | begin training epoch 68
2022-01-31 15:24:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:25:46 | INFO | train_inner | epoch 068:     12 / 64 loss=6.755, ppl=107.98, wps=5827.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.556, train_wall=503, gb_free=6.1, wall=23590
2022-01-31 15:30:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:30:36 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.527 | ppl 737.87 | wps 7908 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.246
2022-01-31 15:30:36 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-01-31 15:30:36 | INFO | train | epoch 068 | loss 6.707 | ppl 104.48 | wps 5944.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.562 | train_wall 323 | gb_free 6.1 | wall 23880
KL Stats: Epoch 68 Divergences: Uniform: 2.769761139056548 Unigram: 2.826800064674442
2022-01-31 15:30:36 | INFO | fairseq.trainer | begin training epoch 69
2022-01-31 15:30:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:34:40 | INFO | train_inner | epoch 069:     48 / 64 loss=6.689, ppl=103.2, wps=6118.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.555, train_wall=505, gb_free=6.1, wall=24124
2022-01-31 15:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:36:27 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.544 | ppl 746.61 | wps 7947.7 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.246
2022-01-31 15:36:27 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-01-31 15:36:27 | INFO | train | epoch 069 | loss 6.67 | ppl 101.83 | wps 5945.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.556 | train_wall 323 | gb_free 6.1 | wall 24231
KL Stats: Epoch 69 Divergences: Uniform: 2.778441064473104 Unigram: 2.8393852453574677
2022-01-31 15:36:27 | INFO | fairseq.trainer | begin training epoch 70
2022-01-31 15:36:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:42:18 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.603 | ppl 777.69 | wps 7926.5 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.246
2022-01-31 15:42:18 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-01-31 15:42:18 | INFO | train | epoch 070 | loss 6.635 | ppl 99.37 | wps 5949.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.554 | train_wall 323 | gb_free 6.1 | wall 24582
KL Stats: Epoch 70 Divergences: Uniform: 2.7869951213882387 Unigram: 2.847321428408159
2022-01-31 15:42:18 | INFO | fairseq.trainer | begin training epoch 71
2022-01-31 15:42:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:44:00 | INFO | train_inner | epoch 071:     20 / 64 loss=6.63, ppl=99.02, wps=5816.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.562, train_wall=504, gb_free=6.1, wall=24684
2022-01-31 15:47:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:48:10 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.576 | ppl 763.45 | wps 7905.1 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.246
2022-01-31 15:48:10 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-01-31 15:48:10 | INFO | train | epoch 071 | loss 6.602 | ppl 97.14 | wps 5929.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.576 | train_wall 324 | gb_free 6.1 | wall 24935
KL Stats: Epoch 71 Divergences: Uniform: 2.7953830080671516 Unigram: 2.872068287899798
2022-01-31 15:48:10 | INFO | fairseq.trainer | begin training epoch 72
2022-01-31 15:48:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:52:55 | INFO | train_inner | epoch 072:     56 / 64 loss=6.586, ppl=96.07, wps=6112.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.568, train_wall=506, gb_free=6.1, wall=25219
2022-01-31 15:53:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:54:02 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.558 | ppl 753.89 | wps 7910.8 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.246
2022-01-31 15:54:02 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-01-31 15:54:02 | INFO | train | epoch 072 | loss 6.566 | ppl 94.72 | wps 5942.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.562 | train_wall 323 | gb_free 6.1 | wall 25286
KL Stats: Epoch 72 Divergences: Uniform: 2.8144443693343026 Unigram: 2.887326286995723
2022-01-31 15:54:02 | INFO | fairseq.trainer | begin training epoch 73
2022-01-31 15:54:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 15:59:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 15:59:53 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.631 | ppl 792.77 | wps 7922.7 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.246
2022-01-31 15:59:53 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-01-31 15:59:53 | INFO | train | epoch 073 | loss 6.534 | ppl 92.67 | wps 5942.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.565 | train_wall 323 | gb_free 6.1 | wall 25637
KL Stats: Epoch 73 Divergences: Uniform: 2.8112855059170374 Unigram: 2.9000206296305313
2022-01-31 15:59:53 | INFO | fairseq.trainer | begin training epoch 74
2022-01-31 15:59:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:02:15 | INFO | train_inner | epoch 074:     28 / 64 loss=6.523, ppl=91.95, wps=5814.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.565, train_wall=504, gb_free=6.1, wall=25780
2022-01-31 16:05:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:05:45 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.583 | ppl 766.81 | wps 7930.8 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.246
2022-01-31 16:05:45 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-01-31 16:05:45 | INFO | train | epoch 074 | loss 6.501 | ppl 90.57 | wps 5941.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.568 | train_wall 323 | gb_free 6.1 | wall 25989
KL Stats: Epoch 74 Divergences: Uniform: 2.8285110012669064 Unigram: 2.9194100935936396
2022-01-31 16:05:45 | INFO | fairseq.trainer | begin training epoch 75
2022-01-31 16:05:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:11:09 | INFO | train_inner | epoch 075:     64 / 64 loss=6.492, ppl=90.01, wps=6109.2, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.575, train_wall=505, gb_free=6.1, wall=26313
2022-01-31 16:11:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:11:37 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.724 | ppl 845.67 | wps 7932 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.246
2022-01-31 16:11:37 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-01-31 16:11:37 | INFO | train | epoch 075 | loss 6.472 | ppl 88.76 | wps 5936.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.576 | train_wall 323 | gb_free 6.1 | wall 26341
KL Stats: Epoch 75 Divergences: Uniform: 2.8262790088594305 Unigram: 2.9311146187983352
2022-01-31 16:11:37 | INFO | fairseq.trainer | begin training epoch 76
2022-01-31 16:11:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:17:28 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.696 | ppl 829.72 | wps 7916.2 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.246
2022-01-31 16:17:28 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-01-31 16:17:28 | INFO | train | epoch 076 | loss 6.442 | ppl 86.97 | wps 5942.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.584 | train_wall 323 | gb_free 6.1 | wall 26692
KL Stats: Epoch 76 Divergences: Uniform: 2.839954368072354 Unigram: 2.951171327049977
2022-01-31 16:17:28 | INFO | fairseq.trainer | begin training epoch 77
2022-01-31 16:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:20:31 | INFO | train_inner | epoch 077:     36 / 64 loss=6.417, ppl=85.47, wps=5813.9, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.585, train_wall=506, gb_free=6.1, wall=26875
2022-01-31 16:22:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:23:20 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.683 | ppl 822.03 | wps 7908.4 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.246
2022-01-31 16:23:20 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-01-31 16:23:20 | INFO | train | epoch 077 | loss 6.413 | ppl 85.24 | wps 5940.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.593 | train_wall 323 | gb_free 6.1 | wall 27044
KL Stats: Epoch 77 Divergences: Uniform: 2.8446341214897473 Unigram: 2.97305975360337
2022-01-31 16:23:20 | INFO | fairseq.trainer | begin training epoch 78
2022-01-31 16:23:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:29:11 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.665 | ppl 811.8 | wps 7943 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.246
2022-01-31 16:29:11 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-01-31 16:29:11 | INFO | train | epoch 078 | loss 6.385 | ppl 83.55 | wps 5948.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.595 | train_wall 323 | gb_free 6.1 | wall 27395
KL Stats: Epoch 78 Divergences: Uniform: 2.8578261340717397 Unigram: 2.981098338227456
2022-01-31 16:29:11 | INFO | fairseq.trainer | begin training epoch 79
2022-01-31 16:29:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:29:52 | INFO | train_inner | epoch 079:      8 / 64 loss=6.4, ppl=84.44, wps=5816.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.597, train_wall=504, gb_free=6.1, wall=27436
2022-01-31 16:34:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:35:03 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.737 | ppl 853.54 | wps 7909.4 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.246
2022-01-31 16:35:03 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-01-31 16:35:03 | INFO | train | epoch 079 | loss 6.354 | ppl 81.82 | wps 5930.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.584 | train_wall 324 | gb_free 6.1 | wall 27747
KL Stats: Epoch 79 Divergences: Uniform: 2.8578794912608316 Unigram: 2.988907619100436
2022-01-31 16:35:03 | INFO | fairseq.trainer | begin training epoch 80
2022-01-31 16:35:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:38:46 | INFO | train_inner | epoch 080:     44 / 64 loss=6.338, ppl=80.89, wps=6111, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.583, train_wall=506, gb_free=6.1, wall=27971
2022-01-31 16:40:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:40:53 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.67 | ppl 814.8 | wps 8017.7 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.246
2022-01-31 16:40:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-01-31 16:40:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt
2022-01-31 16:40:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt
2022-01-31 16:40:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.67) (writing took 3.4543910957872868 seconds)
2022-01-31 16:40:57 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-01-31 16:40:57 | INFO | train | epoch 080 | loss 6.329 | ppl 80.4 | wps 5905.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.595 | train_wall 322 | gb_free 6.1 | wall 28101
KL Stats: Epoch 80 Divergences: Uniform: 2.8694258485430884 Unigram: 3.003587363404377
2022-01-31 16:40:57 | INFO | fairseq.trainer | begin training epoch 81
2022-01-31 16:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:46:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:46:46 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.679 | ppl 819.77 | wps 7962 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.246
2022-01-31 16:46:46 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-01-31 16:46:46 | INFO | train | epoch 081 | loss 6.303 | ppl 78.95 | wps 5988.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.606 | train_wall 320 | gb_free 6.1 | wall 28450
KL Stats: Epoch 81 Divergences: Uniform: 2.890615850356331 Unigram: 3.0291461778438413
2022-01-31 16:46:46 | INFO | fairseq.trainer | begin training epoch 82
2022-01-31 16:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:48:07 | INFO | train_inner | epoch 082:     16 / 64 loss=6.31, ppl=79.32, wps=5816.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.61, train_wall=501, gb_free=6.1, wall=28531
2022-01-31 16:52:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:52:37 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.682 | ppl 821.24 | wps 7909.7 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.246
2022-01-31 16:52:37 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-01-31 16:52:37 | INFO | train | epoch 082 | loss 6.278 | ppl 77.61 | wps 5939.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.608 | train_wall 323 | gb_free 6.1 | wall 28801
KL Stats: Epoch 82 Divergences: Uniform: 2.8985036248055978 Unigram: 3.0428841215633997
2022-01-31 16:52:37 | INFO | fairseq.trainer | begin training epoch 83
2022-01-31 16:52:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 16:57:01 | INFO | train_inner | epoch 083:     52 / 64 loss=6.264, ppl=76.86, wps=6124.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.612, train_wall=505, gb_free=6.1, wall=29065
2022-01-31 16:58:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 16:58:28 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.62 | ppl 787.11 | wps 7940.8 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.246
2022-01-31 16:58:28 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-01-31 16:58:28 | INFO | train | epoch 083 | loss 6.254 | ppl 76.32 | wps 5959.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.618 | train_wall 322 | gb_free 6.1 | wall 29152
KL Stats: Epoch 83 Divergences: Uniform: 2.90211026498174 Unigram: 3.0555249795985655
2022-01-31 16:58:28 | INFO | fairseq.trainer | begin training epoch 84
2022-01-31 16:58:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:04:19 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.696 | ppl 829.53 | wps 7915.5 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.246
2022-01-31 17:04:19 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-01-31 17:04:19 | INFO | train | epoch 084 | loss 6.228 | ppl 74.94 | wps 5947.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.602 | train_wall 323 | gb_free 6.1 | wall 29503
KL Stats: Epoch 84 Divergences: Uniform: 2.90920185862887 Unigram: 3.0673680220822783
2022-01-31 17:04:19 | INFO | fairseq.trainer | begin training epoch 85
2022-01-31 17:04:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:06:21 | INFO | train_inner | epoch 085:     24 / 64 loss=6.217, ppl=74.41, wps=5818.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.606, train_wall=504, gb_free=6.1, wall=29625
2022-01-31 17:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:10:10 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.713 | ppl 839.5 | wps 7906.9 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.246
2022-01-31 17:10:10 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-01-31 17:10:10 | INFO | train | epoch 085 | loss 6.204 | ppl 73.74 | wps 5945.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.614 | train_wall 323 | gb_free 6.1 | wall 29854
KL Stats: Epoch 85 Divergences: Uniform: 2.922017007841304 Unigram: 3.0761343846572964
2022-01-31 17:10:10 | INFO | fairseq.trainer | begin training epoch 86
2022-01-31 17:10:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:15:15 | INFO | train_inner | epoch 086:     60 / 64 loss=6.201, ppl=73.59, wps=6121.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.615, train_wall=505, gb_free=6.1, wall=30159
2022-01-31 17:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:16:01 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.732 | ppl 850.35 | wps 7906.5 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.246
2022-01-31 17:16:01 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-01-31 17:16:01 | INFO | train | epoch 086 | loss 6.18 | ppl 72.51 | wps 5945.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.617 | train_wall 323 | gb_free 6.1 | wall 30206
KL Stats: Epoch 86 Divergences: Uniform: 2.919603231373333 Unigram: 3.0963559125298348
2022-01-31 17:16:01 | INFO | fairseq.trainer | begin training epoch 87
2022-01-31 17:16:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:21:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:21:53 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.739 | ppl 854.44 | wps 7931.4 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.246
2022-01-31 17:21:53 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-01-31 17:21:53 | INFO | train | epoch 087 | loss 6.159 | ppl 71.45 | wps 5941.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.638 | train_wall 323 | gb_free 6.1 | wall 30557
KL Stats: Epoch 87 Divergences: Uniform: 2.9265122665493317 Unigram: 3.109895170713815
2022-01-31 17:21:53 | INFO | fairseq.trainer | begin training epoch 88
2022-01-31 17:21:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:24:36 | INFO | train_inner | epoch 088:     32 / 64 loss=6.146, ppl=70.81, wps=5811.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.635, train_wall=504, gb_free=6.1, wall=30720
2022-01-31 17:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:27:45 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.717 | ppl 841.33 | wps 7948.2 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.246
2022-01-31 17:27:45 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-01-31 17:27:45 | INFO | train | epoch 088 | loss 6.137 | ppl 70.36 | wps 5941 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.635 | train_wall 323 | gb_free 6.1 | wall 30909
KL Stats: Epoch 88 Divergences: Uniform: 2.9324901219320147 Unigram: 3.1185036241029347
2022-01-31 17:27:45 | INFO | fairseq.trainer | begin training epoch 89
2022-01-31 17:27:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:33:36 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.737 | ppl 853.06 | wps 7956.8 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.246
2022-01-31 17:33:36 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-01-31 17:33:36 | INFO | train | epoch 089 | loss 6.118 | ppl 69.44 | wps 5939.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.644 | train_wall 323 | gb_free 6.1 | wall 31260
KL Stats: Epoch 89 Divergences: Uniform: 2.9409127239645505 Unigram: 3.131990047438749
2022-01-31 17:33:36 | INFO | fairseq.trainer | begin training epoch 90
2022-01-31 17:33:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:33:57 | INFO | train_inner | epoch 090:      4 / 64 loss=6.128, ppl=69.96, wps=5811.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.644, train_wall=505, gb_free=6.1, wall=31281
2022-01-31 17:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:39:29 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.781 | ppl 879.89 | wps 7926.2 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.246
2022-01-31 17:39:29 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-01-31 17:39:29 | INFO | train | epoch 090 | loss 6.095 | ppl 68.38 | wps 5927.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.631 | train_wall 324 | gb_free 6.1 | wall 31613
KL Stats: Epoch 90 Divergences: Uniform: 2.9464852430002457 Unigram: 3.1402575321002795
2022-01-31 17:39:29 | INFO | fairseq.trainer | begin training epoch 91
2022-01-31 17:39:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:42:52 | INFO | train_inner | epoch 091:     40 / 64 loss=6.077, ppl=67.51, wps=6103.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.626, train_wall=507, gb_free=6.1, wall=31816
2022-01-31 17:44:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:45:20 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.804 | ppl 894 | wps 7893.6 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.246
2022-01-31 17:45:20 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-01-31 17:45:20 | INFO | train | epoch 091 | loss 6.073 | ppl 67.33 | wps 5938.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.633 | train_wall 323 | gb_free 6.1 | wall 31964
KL Stats: Epoch 91 Divergences: Uniform: 2.9541651263958713 Unigram: 3.162081193140862
2022-01-31 17:45:20 | INFO | fairseq.trainer | begin training epoch 92
2022-01-31 17:45:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:50:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:51:12 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.805 | ppl 894.32 | wps 7929.9 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.246
2022-01-31 17:51:12 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-01-31 17:51:12 | INFO | train | epoch 092 | loss 6.054 | ppl 66.45 | wps 5940.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.665 | train_wall 323 | gb_free 6.1 | wall 32316
KL Stats: Epoch 92 Divergences: Uniform: 2.9608603573565055 Unigram: 3.1701059523445734
2022-01-31 17:51:12 | INFO | fairseq.trainer | begin training epoch 93
2022-01-31 17:51:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 17:52:13 | INFO | train_inner | epoch 093:     12 / 64 loss=6.063, ppl=66.88, wps=5811.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.656, train_wall=504, gb_free=6.1, wall=32377
2022-01-31 17:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 17:57:03 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.788 | ppl 884.31 | wps 7944.9 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.246
2022-01-31 17:57:03 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-01-31 17:57:03 | INFO | train | epoch 093 | loss 6.036 | ppl 65.63 | wps 5945 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.649 | train_wall 323 | gb_free 6.1 | wall 32667
KL Stats: Epoch 93 Divergences: Uniform: 2.9630128706607404 Unigram: 3.1805304436486823
2022-01-31 17:57:03 | INFO | fairseq.trainer | begin training epoch 94
2022-01-31 17:57:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:01:05 | INFO | train_inner | epoch 094:     48 / 64 loss=6.022, ppl=64.99, wps=6142, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.656, train_wall=503, gb_free=6.1, wall=32909
2022-01-31 18:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:02:52 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.828 | ppl 908.81 | wps 8024.8 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.246
2022-01-31 18:02:52 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-01-31 18:02:52 | INFO | train | epoch 094 | loss 6.015 | ppl 64.66 | wps 5989 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.658 | train_wall 321 | gb_free 6.1 | wall 33016
KL Stats: Epoch 94 Divergences: Uniform: 2.966390253118658 Unigram: 3.198641726878607
2022-01-31 18:02:52 | INFO | fairseq.trainer | begin training epoch 95
2022-01-31 18:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:08:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:08:40 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.896 | ppl 952.69 | wps 8059.2 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.246
2022-01-31 18:08:40 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-01-31 18:08:40 | INFO | train | epoch 095 | loss 5.996 | ppl 63.84 | wps 6006.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.648 | train_wall 320 | gb_free 6.1 | wall 33364
KL Stats: Epoch 95 Divergences: Uniform: 2.9713336326152127 Unigram: 3.2089014736959474
2022-01-31 18:08:40 | INFO | fairseq.trainer | begin training epoch 96
2022-01-31 18:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:10:20 | INFO | train_inner | epoch 096:     20 / 64 loss=5.995, ppl=63.79, wps=5874.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.654, train_wall=499, gb_free=6.1, wall=33464
2022-01-31 18:14:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:14:27 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.799 | ppl 890.73 | wps 7911.7 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.246
2022-01-31 18:14:27 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-01-31 18:14:27 | INFO | train | epoch 096 | loss 5.98 | ppl 63.13 | wps 6005.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.673 | train_wall 319 | gb_free 6.1 | wall 33712
KL Stats: Epoch 96 Divergences: Uniform: 2.981195968783701 Unigram: 3.2182568683658133
2022-01-31 18:14:27 | INFO | fairseq.trainer | begin training epoch 97
2022-01-31 18:14:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:19:10 | INFO | train_inner | epoch 097:     56 / 64 loss=5.975, ppl=62.88, wps=6162.7, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.683, train_wall=501, gb_free=6.1, wall=33994
2022-01-31 18:19:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:20:17 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.845 | ppl 919.52 | wps 7950.9 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.246
2022-01-31 18:20:17 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-01-31 18:20:17 | INFO | train | epoch 097 | loss 5.963 | ppl 62.37 | wps 5974 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.684 | train_wall 321 | gb_free 6.1 | wall 34061
KL Stats: Epoch 97 Divergences: Uniform: 2.9905779922585247 Unigram: 3.23319567323948
2022-01-31 18:20:17 | INFO | fairseq.trainer | begin training epoch 98
2022-01-31 18:20:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:25:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:26:06 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.856 | ppl 926.53 | wps 7977.4 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.246
2022-01-31 18:26:06 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-01-31 18:26:06 | INFO | train | epoch 098 | loss 5.942 | ppl 61.49 | wps 5980.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.674 | train_wall 321 | gb_free 6.1 | wall 34410
KL Stats: Epoch 98 Divergences: Uniform: 2.986913658490035 Unigram: 3.2348868696625055
2022-01-31 18:26:06 | INFO | fairseq.trainer | begin training epoch 99
2022-01-31 18:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:28:28 | INFO | train_inner | epoch 099:     28 / 64 loss=5.933, ppl=61.1, wps=5845.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.674, train_wall=501, gb_free=6.1, wall=34552
2022-01-31 18:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:31:56 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.821 | ppl 904.67 | wps 7949.8 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.246
2022-01-31 18:31:56 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-01-31 18:31:56 | INFO | train | epoch 099 | loss 5.925 | ppl 60.74 | wps 5963.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.687 | train_wall 322 | gb_free 6.1 | wall 34761
KL Stats: Epoch 99 Divergences: Uniform: 2.9997902692184413 Unigram: 3.2533463750264406
2022-01-31 18:31:56 | INFO | fairseq.trainer | begin training epoch 100
2022-01-31 18:31:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:37:20 | INFO | train_inner | epoch 100:     64 / 64 loss=5.928, ppl=60.89, wps=6123, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.694, train_wall=504, gb_free=6.1, wall=35085
2022-01-31 18:37:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:37:48 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.791 | ppl 886.05 | wps 7878.8 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.246
2022-01-31 18:37:48 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-01-31 18:37:48 | INFO | train | epoch 100 | loss 5.911 | ppl 60.17 | wps 5937.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.691 | train_wall 323 | gb_free 6.1 | wall 35112
KL Stats: Epoch 100 Divergences: Uniform: 2.9996437611603177 Unigram: 3.258376529573389
2022-01-31 18:37:48 | INFO | fairseq.trainer | begin training epoch 101
2022-01-31 18:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:43:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:43:39 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.87 | ppl 935.89 | wps 7911.7 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.246
2022-01-31 18:43:39 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-01-31 18:43:39 | INFO | train | epoch 101 | loss 5.891 | ppl 59.33 | wps 5945.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.691 | train_wall 323 | gb_free 6.1 | wall 35464
KL Stats: Epoch 101 Divergences: Uniform: 3.0136383977721546 Unigram: 3.2770153218991904
2022-01-31 18:43:40 | INFO | fairseq.trainer | begin training epoch 102
2022-01-31 18:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:46:43 | INFO | train_inner | epoch 102:     36 / 64 loss=5.877, ppl=58.77, wps=5806.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.704, train_wall=506, gb_free=6.1, wall=35647
2022-01-31 18:49:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:49:33 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.869 | ppl 935.37 | wps 7878.4 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.246
2022-01-31 18:49:33 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-01-31 18:49:33 | INFO | train | epoch 102 | loss 5.877 | ppl 58.79 | wps 5912.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.713 | train_wall 325 | gb_free 6.1 | wall 35817
KL Stats: Epoch 102 Divergences: Uniform: 3.0074707747458143 Unigram: 3.285721747969396
2022-01-31 18:49:33 | INFO | fairseq.trainer | begin training epoch 103
2022-01-31 18:49:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 18:55:24 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.877 | ppl 940.37 | wps 8024.3 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.246
2022-01-31 18:55:24 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-01-31 18:55:24 | INFO | train | epoch 103 | loss 5.86 | ppl 58.1 | wps 5955 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.699 | train_wall 323 | gb_free 6.1 | wall 36168
KL Stats: Epoch 103 Divergences: Uniform: 3.019424094658558 Unigram: 3.2963978197645516
2022-01-31 18:55:24 | INFO | fairseq.trainer | begin training epoch 104
2022-01-31 18:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 18:56:04 | INFO | train_inner | epoch 104:      8 / 64 loss=5.868, ppl=58.39, wps=5816.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.699, train_wall=504, gb_free=6.1, wall=36208
2022-01-31 19:00:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:01:12 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.893 | ppl 950.83 | wps 7994.7 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.246
2022-01-31 19:01:12 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-01-31 19:01:12 | INFO | train | epoch 104 | loss 5.847 | ppl 57.56 | wps 6001.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.72 | train_wall 320 | gb_free 6.1 | wall 36516
KL Stats: Epoch 104 Divergences: Uniform: 3.0147308982640864 Unigram: 3.309288526290372
2022-01-31 19:01:12 | INFO | fairseq.trainer | begin training epoch 105
2022-01-31 19:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:04:53 | INFO | train_inner | epoch 105:     44 / 64 loss=5.835, ppl=57.07, wps=6179.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.72, train_wall=500, gb_free=6.1, wall=36737
2022-01-31 19:06:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:06:59 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.835 | ppl 913.61 | wps 8008 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.246
2022-01-31 19:06:59 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-01-31 19:06:59 | INFO | train | epoch 105 | loss 5.831 | ppl 56.91 | wps 6008.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.717 | train_wall 319 | gb_free 6.1 | wall 36863
KL Stats: Epoch 105 Divergences: Uniform: 3.02241235725413 Unigram: 3.313443933547046
2022-01-31 19:06:59 | INFO | fairseq.trainer | begin training epoch 106
2022-01-31 19:06:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:12:47 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.876 | ppl 939.47 | wps 8045.8 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.246
2022-01-31 19:12:47 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-01-31 19:12:47 | INFO | train | epoch 106 | loss 5.815 | ppl 56.29 | wps 6010 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.72 | train_wall 319 | gb_free 6.1 | wall 37211
KL Stats: Epoch 106 Divergences: Uniform: 3.02000442061274 Unigram: 3.3225626371936485
2022-01-31 19:12:47 | INFO | fairseq.trainer | begin training epoch 107
2022-01-31 19:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:14:07 | INFO | train_inner | epoch 107:     16 / 64 loss=5.818, ppl=56.42, wps=5877.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.717, train_wall=499, gb_free=6.1, wall=37291
2022-01-31 19:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:18:36 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.881 | ppl 943.24 | wps 7953.7 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.246
2022-01-31 19:18:36 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-01-31 19:18:36 | INFO | train | epoch 107 | loss 5.799 | ppl 55.67 | wps 5987.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.709 | train_wall 320 | gb_free 6.1 | wall 37560
KL Stats: Epoch 107 Divergences: Uniform: 3.0309695071556066 Unigram: 3.338660753625158
2022-01-31 19:18:36 | INFO | fairseq.trainer | begin training epoch 108
2022-01-31 19:18:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:22:58 | INFO | train_inner | epoch 108:     52 / 64 loss=5.795, ppl=55.5, wps=6159.9, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.721, train_wall=502, gb_free=6.1, wall=37822
2022-01-31 19:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:24:24 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.919 | ppl 968.25 | wps 8063.2 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.246
2022-01-31 19:24:24 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-01-31 19:24:24 | INFO | train | epoch 108 | loss 5.788 | ppl 55.26 | wps 5992.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.737 | train_wall 321 | gb_free 6.1 | wall 37908
KL Stats: Epoch 108 Divergences: Uniform: 3.03347689154092 Unigram: 3.3434450013659767
2022-01-31 19:24:24 | INFO | fairseq.trainer | begin training epoch 109
2022-01-31 19:24:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:29:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:30:13 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.946 | ppl 986.28 | wps 7996.6 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.246
2022-01-31 19:30:13 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-01-31 19:30:13 | INFO | train | epoch 109 | loss 5.773 | ppl 54.68 | wps 5983.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.73 | train_wall 321 | gb_free 6.1 | wall 38257
KL Stats: Epoch 109 Divergences: Uniform: 3.0385399153642108 Unigram: 3.3572704321111617
2022-01-31 19:30:13 | INFO | fairseq.trainer | begin training epoch 110
2022-01-31 19:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:32:13 | INFO | train_inner | epoch 110:     24 / 64 loss=5.767, ppl=54.47, wps=5866.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.738, train_wall=500, gb_free=6.1, wall=38378
2022-01-31 19:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:35:59 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.966 | ppl 1000.12 | wps 8088.4 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.246
2022-01-31 19:35:59 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-01-31 19:35:59 | INFO | train | epoch 110 | loss 5.759 | ppl 54.17 | wps 6030.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.734 | train_wall 318 | gb_free 6.1 | wall 38604
KL Stats: Epoch 110 Divergences: Uniform: 3.0451966794501186 Unigram: 3.3682384829599488
2022-01-31 19:35:59 | INFO | fairseq.trainer | begin training epoch 111
2022-01-31 19:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:41:02 | INFO | train_inner | epoch 111:     60 / 64 loss=5.759, ppl=54.15, wps=6183.1, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.744, train_wall=500, gb_free=6.1, wall=38906
2022-01-31 19:41:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:41:49 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.937 | ppl 980.21 | wps 7842.8 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.246
2022-01-31 19:41:49 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-01-31 19:41:49 | INFO | train | epoch 111 | loss 5.747 | ppl 53.69 | wps 5975.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.758 | train_wall 321 | gb_free 6.1 | wall 38953
KL Stats: Epoch 111 Divergences: Uniform: 3.0494284835117846 Unigram: 3.3816936833034132
2022-01-31 19:41:49 | INFO | fairseq.trainer | begin training epoch 112
2022-01-31 19:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:47:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:47:42 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.938 | ppl 980.67 | wps 7887.2 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.246
2022-01-31 19:47:42 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-01-31 19:47:42 | INFO | train | epoch 112 | loss 5.733 | ppl 53.17 | wps 5923 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.747 | train_wall 324 | gb_free 6.1 | wall 39306
KL Stats: Epoch 112 Divergences: Uniform: 3.0453683405096035 Unigram: 3.39058479212995
2022-01-31 19:47:42 | INFO | fairseq.trainer | begin training epoch 113
2022-01-31 19:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:50:25 | INFO | train_inner | epoch 113:     32 / 64 loss=5.721, ppl=52.74, wps=5794.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.748, train_wall=506, gb_free=6.1, wall=39469
2022-01-31 19:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:53:33 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.962 | ppl 997.22 | wps 7939.9 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.246
2022-01-31 19:53:33 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-01-31 19:53:33 | INFO | train | epoch 113 | loss 5.717 | ppl 52.6 | wps 5940.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.748 | train_wall 323 | gb_free 6.1 | wall 39657
KL Stats: Epoch 113 Divergences: Uniform: 3.0625494583627675 Unigram: 3.399464567237783
2022-01-31 19:53:33 | INFO | fairseq.trainer | begin training epoch 114
2022-01-31 19:53:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:58:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 19:59:26 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.954 | ppl 991.75 | wps 7746.1 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.246
2022-01-31 19:59:26 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-01-31 19:59:26 | INFO | train | epoch 114 | loss 5.705 | ppl 52.16 | wps 5918.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.752 | train_wall 324 | gb_free 6.1 | wall 40010
KL Stats: Epoch 114 Divergences: Uniform: 3.056717262340026 Unigram: 3.4063503651210483
2022-01-31 19:59:26 | INFO | fairseq.trainer | begin training epoch 115
2022-01-31 19:59:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 19:59:47 | INFO | train_inner | epoch 115:      4 / 64 loss=5.717, ppl=52.59, wps=5798.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.753, train_wall=505, gb_free=6.1, wall=40031
2022-01-31 20:04:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:05:22 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.966 | ppl 999.98 | wps 7737.6 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.246
2022-01-31 20:05:22 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-01-31 20:05:22 | INFO | train | epoch 115 | loss 5.692 | ppl 51.71 | wps 5861.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.763 | train_wall 327 | gb_free 6.1 | wall 40367
KL Stats: Epoch 115 Divergences: Uniform: 3.062692138495786 Unigram: 3.413147659657322
2022-01-31 20:05:22 | INFO | fairseq.trainer | begin training epoch 116
2022-01-31 20:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:08:50 | INFO | train_inner | epoch 116:     40 / 64 loss=5.679, ppl=51.23, wps=6020.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.759, train_wall=513, gb_free=6.1, wall=40574
2022-01-31 20:10:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:11:20 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.935 | ppl 979.11 | wps 7801.9 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.246
2022-01-31 20:11:20 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-01-31 20:11:20 | INFO | train | epoch 116 | loss 5.68 | ppl 51.27 | wps 5833.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.766 | train_wall 329 | gb_free 6.1 | wall 40725
KL Stats: Epoch 116 Divergences: Uniform: 3.064045496744629 Unigram: 3.4177973114856868
2022-01-31 20:11:20 | INFO | fairseq.trainer | begin training epoch 117
2022-01-31 20:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:17:18 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 10 | ppl 1024.18 | wps 7771.9 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.246
2022-01-31 20:17:18 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-01-31 20:17:18 | INFO | train | epoch 117 | loss 5.669 | ppl 50.88 | wps 5837.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.773 | train_wall 329 | gb_free 6.1 | wall 41082
KL Stats: Epoch 117 Divergences: Uniform: 3.0629582802983744 Unigram: 3.4318073903831756
2022-01-31 20:17:18 | INFO | fairseq.trainer | begin training epoch 118
2022-01-31 20:17:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:18:21 | INFO | train_inner | epoch 118:     12 / 64 loss=5.674, ppl=51.05, wps=5709.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.78, train_wall=513, gb_free=6.1, wall=41145
2022-01-31 20:22:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:23:17 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.986 | ppl 1014.15 | wps 7757.9 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.246
2022-01-31 20:23:17 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-01-31 20:23:17 | INFO | train | epoch 118 | loss 5.656 | ppl 50.42 | wps 5827.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.781 | train_wall 329 | gb_free 6.1 | wall 41441
KL Stats: Epoch 118 Divergences: Uniform: 3.0735088211665724 Unigram: 3.4409717074299833
2022-01-31 20:23:17 | INFO | fairseq.trainer | begin training epoch 119
2022-01-31 20:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:27:24 | INFO | train_inner | epoch 119:     48 / 64 loss=5.646, ppl=50.08, wps=6010.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.775, train_wall=514, gb_free=6.1, wall=41688
2022-01-31 20:28:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:29:14 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.971 | ppl 1003.45 | wps 7750.4 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.246
2022-01-31 20:29:14 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-01-31 20:29:14 | INFO | train | epoch 119 | loss 5.644 | ppl 50.01 | wps 5850.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.783 | train_wall 328 | gb_free 6.1 | wall 41798
KL Stats: Epoch 119 Divergences: Uniform: 3.078349062351984 Unigram: 3.453722884694153
2022-01-31 20:29:14 | INFO | fairseq.trainer | begin training epoch 120
2022-01-31 20:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:34:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:35:12 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.984 | ppl 1012.61 | wps 7671.6 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.246
2022-01-31 20:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-01-31 20:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt
2022-01-31 20:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt
2022-01-31 20:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.984) (writing took 3.675444232299924 seconds)
2022-01-31 20:35:16 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-01-31 20:35:16 | INFO | train | epoch 120 | loss 5.634 | ppl 49.67 | wps 5766.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.786 | train_wall 329 | gb_free 6.1 | wall 42160
KL Stats: Epoch 120 Divergences: Uniform: 3.0841357559825493 Unigram: 3.457134184284947
2022-01-31 20:35:16 | INFO | fairseq.trainer | begin training epoch 121
2022-01-31 20:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:37:00 | INFO | train_inner | epoch 121:     20 / 64 loss=5.635, ppl=49.71, wps=5663.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.785, train_wall=514, gb_free=6.1, wall=42264
2022-01-31 20:40:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:41:15 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.998 | ppl 1022.53 | wps 7772.7 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.246
2022-01-31 20:41:15 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-01-31 20:41:15 | INFO | train | epoch 121 | loss 5.621 | ppl 49.23 | wps 5820.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.772 | train_wall 330 | gb_free 6.1 | wall 42519
KL Stats: Epoch 121 Divergences: Uniform: 3.0837452827534886 Unigram: 3.4635553600202917
2022-01-31 20:41:15 | INFO | fairseq.trainer | begin training epoch 122
2022-01-31 20:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:46:03 | INFO | train_inner | epoch 122:     56 / 64 loss=5.619, ppl=49.16, wps=6014, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.794, train_wall=514, gb_free=6.1, wall=42807
2022-01-31 20:46:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:47:11 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.95 | ppl 989.2 | wps 7802.3 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.246
2022-01-31 20:47:11 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-01-31 20:47:11 | INFO | train | epoch 122 | loss 5.612 | ppl 48.89 | wps 5856.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.81 | train_wall 328 | gb_free 6.1 | wall 42875
KL Stats: Epoch 122 Divergences: Uniform: 3.089669705495483 Unigram: 3.4775312468574886
2022-01-31 20:47:11 | INFO | fairseq.trainer | begin training epoch 123
2022-01-31 20:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:53:08 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 10.023 | ppl 1040.73 | wps 7762.3 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.246
2022-01-31 20:53:08 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-01-31 20:53:08 | INFO | train | epoch 123 | loss 5.6 | ppl 48.51 | wps 5856.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.811 | train_wall 328 | gb_free 6.1 | wall 43232
KL Stats: Epoch 123 Divergences: Uniform: 3.086775258018131 Unigram: 3.4861835337087306
2022-01-31 20:53:08 | INFO | fairseq.trainer | begin training epoch 124
2022-01-31 20:53:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 20:55:31 | INFO | train_inner | epoch 124:     28 / 64 loss=5.593, ppl=48.26, wps=5738.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.806, train_wall=510, gb_free=6.1, wall=43376
2022-01-31 20:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 20:59:02 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 10.005 | ppl 1027.41 | wps 7835.3 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.246
2022-01-31 20:59:02 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-01-31 20:59:02 | INFO | train | epoch 124 | loss 5.588 | ppl 48.1 | wps 5898.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.801 | train_wall 325 | gb_free 6.1 | wall 43586
KL Stats: Epoch 124 Divergences: Uniform: 3.076812669218142 Unigram: 3.4853046724545496
2022-01-31 20:59:02 | INFO | fairseq.trainer | begin training epoch 125
2022-01-31 20:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:04:29 | INFO | train_inner | epoch 125:     64 / 64 loss=5.591, ppl=48.21, wps=6066.2, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.813, train_wall=508, gb_free=6.1, wall=43913
2022-01-31 21:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:04:57 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 10.049 | ppl 1059.55 | wps 7768.8 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.246
2022-01-31 21:04:57 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-01-31 21:04:57 | INFO | train | epoch 125 | loss 5.577 | ppl 47.75 | wps 5885.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.816 | train_wall 326 | gb_free 6.1 | wall 43941
KL Stats: Epoch 125 Divergences: Uniform: 3.090824957905586 Unigram: 3.4981979701553936
2022-01-31 21:04:57 | INFO | fairseq.trainer | begin training epoch 126
2022-01-31 21:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:10:54 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.973 | ppl 1005.3 | wps 7780.5 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.246
2022-01-31 21:10:54 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-01-31 21:10:54 | INFO | train | epoch 126 | loss 5.567 | ppl 47.4 | wps 5841.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.801 | train_wall 329 | gb_free 6.1 | wall 44299
KL Stats: Epoch 126 Divergences: Uniform: 3.097918617952891 Unigram: 3.5052430565178367
2022-01-31 21:10:54 | INFO | fairseq.trainer | begin training epoch 127
2022-01-31 21:10:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:14:00 | INFO | train_inner | epoch 127:     36 / 64 loss=5.555, ppl=47.02, wps=5717.2, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.824, train_wall=514, gb_free=6.1, wall=44484
2022-01-31 21:16:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:16:52 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 10.003 | ppl 1026.13 | wps 7744.8 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.246
2022-01-31 21:16:52 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-01-31 21:16:52 | INFO | train | epoch 127 | loss 5.558 | ppl 47.11 | wps 5843.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.844 | train_wall 328 | gb_free 6.1 | wall 44656
KL Stats: Epoch 127 Divergences: Uniform: 3.0916964797194777 Unigram: 3.510811431430151
2022-01-31 21:16:52 | INFO | fairseq.trainer | begin training epoch 128
2022-01-31 21:16:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:22:48 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 10.019 | ppl 1037.89 | wps 7791.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.246
2022-01-31 21:22:48 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-01-31 21:22:48 | INFO | train | epoch 128 | loss 5.546 | ppl 46.72 | wps 5862.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.838 | train_wall 327 | gb_free 6.1 | wall 45012
KL Stats: Epoch 128 Divergences: Uniform: 3.0960420328301956 Unigram: 3.5200384903419724
2022-01-31 21:22:48 | INFO | fairseq.trainer | begin training epoch 129
2022-01-31 21:22:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:23:29 | INFO | train_inner | epoch 129:      8 / 64 loss=5.554, ppl=46.97, wps=5728, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.835, train_wall=511, gb_free=6.1, wall=45054
2022-01-31 21:28:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:28:46 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 10.013 | ppl 1033.11 | wps 7772.3 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.246
2022-01-31 21:28:46 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-01-31 21:28:46 | INFO | train | epoch 129 | loss 5.54 | ppl 46.52 | wps 5842.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.841 | train_wall 328 | gb_free 6.1 | wall 45370
KL Stats: Epoch 129 Divergences: Uniform: 3.0944421038435026 Unigram: 3.525352858777476
2022-01-31 21:28:46 | INFO | fairseq.trainer | begin training epoch 130
2022-01-31 21:28:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:32:33 | INFO | train_inner | epoch 130:     44 / 64 loss=5.527, ppl=46.11, wps=6009.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.831, train_wall=514, gb_free=6.1, wall=45597
2022-01-31 21:34:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:34:43 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 10.087 | ppl 1087.68 | wps 7810.2 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.246
2022-01-31 21:34:43 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-01-31 21:34:43 | INFO | train | epoch 130 | loss 5.526 | ppl 46.08 | wps 5840.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.824 | train_wall 329 | gb_free 6.1 | wall 45727
KL Stats: Epoch 130 Divergences: Uniform: 3.096336222943654 Unigram: 3.5374585601207262
2022-01-31 21:34:43 | INFO | fairseq.trainer | begin training epoch 131
2022-01-31 21:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:40:41 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 10.055 | ppl 1063.81 | wps 7763.2 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.246
2022-01-31 21:40:41 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-01-31 21:40:41 | INFO | train | epoch 131 | loss 5.518 | ppl 45.83 | wps 5840.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.845 | train_wall 329 | gb_free 6.1 | wall 46085
KL Stats: Epoch 131 Divergences: Uniform: 3.096469563798697 Unigram: 3.539068610838557
2022-01-31 21:40:41 | INFO | fairseq.trainer | begin training epoch 132
2022-01-31 21:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:42:03 | INFO | train_inner | epoch 132:     16 / 64 loss=5.521, ppl=45.93, wps=5718.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.847, train_wall=512, gb_free=6.1, wall=46168
2022-01-31 21:46:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:46:38 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 10.078 | ppl 1080.82 | wps 7770.3 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.246
2022-01-31 21:46:38 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-01-31 21:46:38 | INFO | train | epoch 132 | loss 5.509 | ppl 45.55 | wps 5848 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.876 | train_wall 328 | gb_free 6.1 | wall 46442
KL Stats: Epoch 132 Divergences: Uniform: 3.1037304387640754 Unigram: 3.5483974909919977
2022-01-31 21:46:38 | INFO | fairseq.trainer | begin training epoch 133
2022-01-31 21:46:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:51:06 | INFO | train_inner | epoch 133:     52 / 64 loss=5.503, ppl=45.35, wps=6027.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.865, train_wall=513, gb_free=6.1, wall=46710
2022-01-31 21:52:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:52:34 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 10.048 | ppl 1058.94 | wps 7767.8 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.246
2022-01-31 21:52:34 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-01-31 21:52:34 | INFO | train | epoch 133 | loss 5.498 | ppl 45.19 | wps 5860 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.856 | train_wall 327 | gb_free 6.1 | wall 46798
KL Stats: Epoch 133 Divergences: Uniform: 3.114140632784319 Unigram: 3.5550237927392385
2022-01-31 21:52:34 | INFO | fairseq.trainer | begin training epoch 134
2022-01-31 21:52:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 21:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 21:58:32 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 10.132 | ppl 1122.15 | wps 7774.9 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.246
2022-01-31 21:58:32 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-01-31 21:58:32 | INFO | train | epoch 134 | loss 5.49 | ppl 44.95 | wps 5832.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.879 | train_wall 329 | gb_free 6.1 | wall 47157
KL Stats: Epoch 134 Divergences: Uniform: 3.1078433724863497 Unigram: 3.558811212929947
2022-01-31 21:58:32 | INFO | fairseq.trainer | begin training epoch 135
2022-01-31 21:58:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:00:37 | INFO | train_inner | epoch 135:     24 / 64 loss=5.489, ppl=44.92, wps=5707.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.872, train_wall=513, gb_free=6.1, wall=47281
2022-01-31 22:04:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:04:30 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 10.029 | ppl 1044.72 | wps 7744 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.246
2022-01-31 22:04:30 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-01-31 22:04:30 | INFO | train | epoch 135 | loss 5.481 | ppl 44.65 | wps 5836.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.859 | train_wall 329 | gb_free 6.1 | wall 47514
KL Stats: Epoch 135 Divergences: Uniform: 3.111670229840268 Unigram: 3.5685190033817418
2022-01-31 22:04:30 | INFO | fairseq.trainer | begin training epoch 136
2022-01-31 22:04:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:09:40 | INFO | train_inner | epoch 136:     60 / 64 loss=5.481, ppl=44.67, wps=6013.6, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.867, train_wall=514, gb_free=6.1, wall=47824
2022-01-31 22:10:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:10:28 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 10.076 | ppl 1079.26 | wps 7765.1 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.246
2022-01-31 22:10:28 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-01-31 22:10:28 | INFO | train | epoch 136 | loss 5.472 | ppl 44.39 | wps 5844.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.872 | train_wall 328 | gb_free 6.1 | wall 47872
KL Stats: Epoch 136 Divergences: Uniform: 3.1115972082508017 Unigram: 3.5743016246367283
2022-01-31 22:10:28 | INFO | fairseq.trainer | begin training epoch 137
2022-01-31 22:10:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:15:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:16:25 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 10.121 | ppl 1113.42 | wps 7757.5 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.246
2022-01-31 22:16:25 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-01-31 22:16:25 | INFO | train | epoch 137 | loss 5.465 | ppl 44.16 | wps 5842.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.887 | train_wall 328 | gb_free 6.1 | wall 48229
KL Stats: Epoch 137 Divergences: Uniform: 3.114532469221607 Unigram: 3.5864768893889094
2022-01-31 22:16:25 | INFO | fairseq.trainer | begin training epoch 138
2022-01-31 22:16:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:19:08 | INFO | train_inner | epoch 138:     32 / 64 loss=5.455, ppl=43.87, wps=5739.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.875, train_wall=510, gb_free=6.1, wall=48392
2022-01-31 22:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:22:17 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 10.124 | ppl 1115.96 | wps 7922.2 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.246
2022-01-31 22:22:17 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-01-31 22:22:17 | INFO | train | epoch 138 | loss 5.454 | ppl 43.83 | wps 5939.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.889 | train_wall 323 | gb_free 6.1 | wall 48581
KL Stats: Epoch 138 Divergences: Uniform: 3.117839864238971 Unigram: 3.5910906533479583
2022-01-31 22:22:17 | INFO | fairseq.trainer | begin training epoch 139
2022-01-31 22:22:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:27:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:28:12 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 10.07 | ppl 1074.55 | wps 7772.2 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.246
2022-01-31 22:28:12 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-01-31 22:28:12 | INFO | train | epoch 139 | loss 5.445 | ppl 43.55 | wps 5882.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.895 | train_wall 326 | gb_free 6.1 | wall 48936
KL Stats: Epoch 139 Divergences: Uniform: 3.1199963792292107 Unigram: 3.6010009246670402
2022-01-31 22:28:12 | INFO | fairseq.trainer | begin training epoch 140
2022-01-31 22:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:28:33 | INFO | train_inner | epoch 140:      4 / 64 loss=5.453, ppl=43.79, wps=5776.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.903, train_wall=507, gb_free=6.1, wall=48957
2022-01-31 22:33:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:34:08 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 10.085 | ppl 1086.12 | wps 7818 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.246
2022-01-31 22:34:08 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-01-31 22:34:08 | INFO | train | epoch 140 | loss 5.437 | ppl 43.31 | wps 5863.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.907 | train_wall 327 | gb_free 6.1 | wall 49292
KL Stats: Epoch 140 Divergences: Uniform: 3.114179465805643 Unigram: 3.6032917672033262
2022-01-31 22:34:08 | INFO | fairseq.trainer | begin training epoch 141
2022-01-31 22:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:37:34 | INFO | train_inner | epoch 141:     40 / 64 loss=5.429, ppl=43.09, wps=6040.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.913, train_wall=512, gb_free=6.1, wall=49498
2022-01-31 22:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:40:04 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 10.13 | ppl 1120.89 | wps 7751.9 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.246
2022-01-31 22:40:04 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-01-31 22:40:04 | INFO | train | epoch 141 | loss 5.429 | ppl 43.08 | wps 5867.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.9 | train_wall 327 | gb_free 6.1 | wall 49648
KL Stats: Epoch 141 Divergences: Uniform: 3.1216654506620705 Unigram: 3.6082183314703116
2022-01-31 22:40:04 | INFO | fairseq.trainer | begin training epoch 142
2022-01-31 22:40:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:45:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:46:01 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 10.069 | ppl 1073.79 | wps 7794.7 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.246
2022-01-31 22:46:01 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-01-31 22:46:01 | INFO | train | epoch 142 | loss 5.419 | ppl 42.79 | wps 5849.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.915 | train_wall 328 | gb_free 6.1 | wall 50005
KL Stats: Epoch 142 Divergences: Uniform: 3.1228926772283967 Unigram: 3.6120658966365835
2022-01-31 22:46:01 | INFO | fairseq.trainer | begin training epoch 143
2022-01-31 22:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:47:03 | INFO | train_inner | epoch 143:     12 / 64 loss=5.421, ppl=42.84, wps=5723.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.907, train_wall=512, gb_free=6.1, wall=50067
2022-01-31 22:51:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:51:59 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 10.074 | ppl 1077.97 | wps 7765.7 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.246
2022-01-31 22:51:59 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-01-31 22:51:59 | INFO | train | epoch 143 | loss 5.414 | ppl 42.62 | wps 5840.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.917 | train_wall 328 | gb_free 6.1 | wall 50363
KL Stats: Epoch 143 Divergences: Uniform: 3.13257279959034 Unigram: 3.6190608785885785
2022-01-31 22:51:59 | INFO | fairseq.trainer | begin training epoch 144
2022-01-31 22:51:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 22:56:06 | INFO | train_inner | epoch 144:     48 / 64 loss=5.41, ppl=42.51, wps=6015.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.91, train_wall=514, gb_free=6.1, wall=50610
2022-01-31 22:57:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 22:57:56 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 10.129 | ppl 1119.96 | wps 7756.5 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.246
2022-01-31 22:57:56 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-01-31 22:57:56 | INFO | train | epoch 144 | loss 5.406 | ppl 42.39 | wps 5847.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.907 | train_wall 328 | gb_free 6.1 | wall 50720
KL Stats: Epoch 144 Divergences: Uniform: 3.122829273442295 Unigram: 3.620045999924024
2022-01-31 22:57:56 | INFO | fairseq.trainer | begin training epoch 145
2022-01-31 22:57:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:03:54 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 10.148 | ppl 1134.8 | wps 7760.6 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.246
2022-01-31 23:03:54 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-01-31 23:03:54 | INFO | train | epoch 145 | loss 5.398 | ppl 42.17 | wps 5838.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.937 | train_wall 329 | gb_free 6.1 | wall 51078
KL Stats: Epoch 145 Divergences: Uniform: 3.133467826428437 Unigram: 3.6309601271147205
2022-01-31 23:03:54 | INFO | fairseq.trainer | begin training epoch 146
2022-01-31 23:03:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:05:37 | INFO | train_inner | epoch 146:     20 / 64 loss=5.394, ppl=42.06, wps=5711, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.933, train_wall=513, gb_free=6.1, wall=51181
2022-01-31 23:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:09:51 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 10.106 | ppl 1102.12 | wps 7803.9 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.246
2022-01-31 23:09:51 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-01-31 23:09:51 | INFO | train | epoch 146 | loss 5.388 | ppl 41.88 | wps 5844.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.945 | train_wall 328 | gb_free 6.1 | wall 51435
KL Stats: Epoch 146 Divergences: Uniform: 3.1301713620510516 Unigram: 3.635953028467672
2022-01-31 23:09:51 | INFO | fairseq.trainer | begin training epoch 147
2022-01-31 23:09:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:14:39 | INFO | train_inner | epoch 147:     56 / 64 loss=5.39, ppl=41.93, wps=6026.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.942, train_wall=513, gb_free=6.1, wall=51724
2022-01-31 23:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:15:48 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 10.126 | ppl 1117.28 | wps 7765.2 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.246
2022-01-31 23:15:48 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-01-31 23:15:48 | INFO | train | epoch 147 | loss 5.381 | ppl 41.67 | wps 5859.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.943 | train_wall 327 | gb_free 6.1 | wall 51792
KL Stats: Epoch 147 Divergences: Uniform: 3.1374342874373746 Unigram: 3.64663195049186
2022-01-31 23:15:48 | INFO | fairseq.trainer | begin training epoch 148
2022-01-31 23:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:21:44 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 10.11 | ppl 1105.44 | wps 7754.3 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.246
2022-01-31 23:21:44 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-01-31 23:21:44 | INFO | train | epoch 148 | loss 5.373 | ppl 41.45 | wps 5861.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.941 | train_wall 327 | gb_free 6.1 | wall 52148
KL Stats: Epoch 148 Divergences: Uniform: 3.1352670913371203 Unigram: 3.650489253887747
2022-01-31 23:21:44 | INFO | fairseq.trainer | begin training epoch 149
2022-01-31 23:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:24:08 | INFO | train_inner | epoch 149:     28 / 64 loss=5.368, ppl=41.31, wps=5729.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.943, train_wall=511, gb_free=6.1, wall=52293
2022-01-31 23:27:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:27:41 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 10.123 | ppl 1114.99 | wps 7760.2 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.246
2022-01-31 23:27:41 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-01-31 23:27:41 | INFO | train | epoch 149 | loss 5.368 | ppl 41.29 | wps 5848 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.975 | train_wall 328 | gb_free 6.1 | wall 52505
KL Stats: Epoch 149 Divergences: Uniform: 3.1419838030392255 Unigram: 3.6569394030361453
2022-01-31 23:27:41 | INFO | fairseq.trainer | begin training epoch 150
2022-01-31 23:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:33:09 | INFO | train_inner | epoch 150:     64 / 64 loss=5.37, ppl=41.34, wps=6025.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.981, train_wall=512, gb_free=6.1, wall=52834
2022-01-31 23:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:33:37 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 10.162 | ppl 1145.35 | wps 7804.5 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.246
2022-01-31 23:33:37 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-01-31 23:33:37 | INFO | train | epoch 150 | loss 5.359 | ppl 41.03 | wps 5859.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.967 | train_wall 328 | gb_free 6.1 | wall 52862
KL Stats: Epoch 150 Divergences: Uniform: 3.139678197175833 Unigram: 3.6605557191123235
2022-01-31 23:33:37 | INFO | fairseq.trainer | begin training epoch 151
2022-01-31 23:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:39:34 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 10.176 | ppl 1156.71 | wps 7784.5 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.246
2022-01-31 23:39:34 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-01-31 23:39:34 | INFO | train | epoch 151 | loss 5.351 | ppl 40.82 | wps 5851.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.969 | train_wall 328 | gb_free 6.1 | wall 53219
KL Stats: Epoch 151 Divergences: Uniform: 3.138224029879648 Unigram: 3.665370863699881
2022-01-31 23:39:34 | INFO | fairseq.trainer | begin training epoch 152
2022-01-31 23:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:42:39 | INFO | train_inner | epoch 152:     36 / 64 loss=5.339, ppl=40.47, wps=5735.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.97, train_wall=512, gb_free=6.1, wall=53403
2022-01-31 23:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:45:29 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 10.146 | ppl 1132.94 | wps 7874.2 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.246
2022-01-31 23:45:29 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-01-31 23:45:29 | INFO | train | epoch 152 | loss 5.344 | ppl 40.62 | wps 5897.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.975 | train_wall 325 | gb_free 6.1 | wall 53573
KL Stats: Epoch 152 Divergences: Uniform: 3.1477865279646804 Unigram: 3.6749283161578155
2022-01-31 23:45:29 | INFO | fairseq.trainer | begin training epoch 153
2022-01-31 23:45:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:51:23 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 10.137 | ppl 1125.81 | wps 7776.7 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.246
2022-01-31 23:51:23 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-01-31 23:51:23 | INFO | train | epoch 153 | loss 5.336 | ppl 40.39 | wps 5892.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.954 | train_wall 325 | gb_free 6.1 | wall 53927
KL Stats: Epoch 153 Divergences: Uniform: 3.1489724360515527 Unigram: 3.6805198993674395
2022-01-31 23:51:23 | INFO | fairseq.trainer | begin training epoch 154
2022-01-31 23:51:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-01-31 23:52:04 | INFO | train_inner | epoch 154:      8 / 64 loss=5.344, ppl=40.61, wps=5767.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.961, train_wall=508, gb_free=6.1, wall=53969
2022-01-31 23:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-01-31 23:57:20 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 10.194 | ppl 1171.08 | wps 7731.4 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.246
2022-01-31 23:57:20 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-01-31 23:57:20 | INFO | train | epoch 154 | loss 5.332 | ppl 40.27 | wps 5855.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 0.997 | train_wall 327 | gb_free 6.1 | wall 54284
KL Stats: Epoch 154 Divergences: Uniform: 3.1526098467221115 Unigram: 3.6799221807091276
2022-01-31 23:57:20 | INFO | fairseq.trainer | begin training epoch 155
2022-01-31 23:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:01:07 | INFO | train_inner | epoch 155:     44 / 64 loss=5.323, ppl=40.02, wps=6024, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=0.996, train_wall=513, gb_free=6.1, wall=54511
2022-02-01 00:02:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:03:17 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 10.185 | ppl 1164.28 | wps 7739.5 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.246
2022-02-01 00:03:17 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-01 00:03:17 | INFO | train | epoch 155 | loss 5.324 | ppl 40.06 | wps 5845.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 0.998 | train_wall 328 | gb_free 6.1 | wall 54641
KL Stats: Epoch 155 Divergences: Uniform: 3.144106154752952 Unigram: 3.6947574393250813
2022-02-01 00:03:17 | INFO | fairseq.trainer | begin training epoch 156
2022-02-01 00:03:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:08:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:09:12 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 10.157 | ppl 1142.04 | wps 7849.7 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.246
2022-02-01 00:09:12 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-01 00:09:12 | INFO | train | epoch 156 | loss 5.318 | ppl 39.9 | wps 5877.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.012 | train_wall 327 | gb_free 6.1 | wall 54997
KL Stats: Epoch 156 Divergences: Uniform: 3.1490253064561515 Unigram: 3.6845379121241124
2022-02-01 00:09:12 | INFO | fairseq.trainer | begin training epoch 157
2022-02-01 00:09:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:10:34 | INFO | train_inner | epoch 157:     16 / 64 loss=5.324, ppl=40.05, wps=5746.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.011, train_wall=510, gb_free=6.1, wall=55078
2022-02-01 00:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:15:06 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 10.128 | ppl 1119.04 | wps 7871 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.246
2022-02-01 00:15:06 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-01 00:15:06 | INFO | train | epoch 157 | loss 5.31 | ppl 39.68 | wps 5906 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.017 | train_wall 325 | gb_free 6.1 | wall 55350
KL Stats: Epoch 157 Divergences: Uniform: 3.1475109914330126 Unigram: 3.6988670225943454
2022-02-01 00:15:06 | INFO | fairseq.trainer | begin training epoch 158
2022-02-01 00:15:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:19:33 | INFO | train_inner | epoch 158:     52 / 64 loss=5.302, ppl=39.46, wps=6064.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=0.99, train_wall=510, gb_free=6.1, wall=55617
2022-02-01 00:20:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:21:02 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 10.212 | ppl 1186.47 | wps 7809.4 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.246
2022-02-01 00:21:02 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-01 00:21:02 | INFO | train | epoch 158 | loss 5.302 | ppl 39.46 | wps 5871.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 0.967 | train_wall 327 | gb_free 6.1 | wall 55706
KL Stats: Epoch 158 Divergences: Uniform: 3.1480411072598526 Unigram: 3.7040085168187478
2022-02-01 00:21:02 | INFO | fairseq.trainer | begin training epoch 159
2022-02-01 00:21:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:26:59 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10.23 | ppl 1201.39 | wps 7772.4 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.246
2022-02-01 00:26:59 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-01 00:26:59 | INFO | train | epoch 159 | loss 5.296 | ppl 39.29 | wps 5853.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.015 | train_wall 328 | gb_free 6.1 | wall 56063
KL Stats: Epoch 159 Divergences: Uniform: 3.1430791221191976 Unigram: 3.7161618646282224
2022-02-01 00:26:59 | INFO | fairseq.trainer | begin training epoch 160
2022-02-01 00:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:29:03 | INFO | train_inner | epoch 160:     24 / 64 loss=5.296, ppl=39.29, wps=5723.4, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.013, train_wall=512, gb_free=6.1, wall=56187
2022-02-01 00:32:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:32:56 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.195 | ppl 1172.52 | wps 7753.5 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.246
2022-02-01 00:32:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-01 00:32:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt
2022-02-01 00:32:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt
2022-02-01 00:33:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.195) (writing took 3.5126639399677515 seconds)
2022-02-01 00:33:00 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-01 00:33:00 | INFO | train | epoch 160 | loss 5.292 | ppl 39.18 | wps 5783 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.032 | train_wall 329 | gb_free 6.1 | wall 56424
KL Stats: Epoch 160 Divergences: Uniform: 3.1510534993394765 Unigram: 3.71617796872914
2022-02-01 00:33:00 | INFO | fairseq.trainer | begin training epoch 161
2022-02-01 00:33:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:38:10 | INFO | train_inner | epoch 161:     60 / 64 loss=5.293, ppl=39.2, wps=5975.7, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.031, train_wall=514, gb_free=6.1, wall=56734
2022-02-01 00:38:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:38:57 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 10.156 | ppl 1141.02 | wps 7735.3 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.246
2022-02-01 00:38:57 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-01 00:38:57 | INFO | train | epoch 161 | loss 5.285 | ppl 38.99 | wps 5841.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.021 | train_wall 328 | gb_free 6.1 | wall 56781
KL Stats: Epoch 161 Divergences: Uniform: 3.158335517577685 Unigram: 3.72012645617306
2022-02-01 00:38:57 | INFO | fairseq.trainer | begin training epoch 162
2022-02-01 00:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:44:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:44:54 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.195 | ppl 1172.35 | wps 7797.9 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.246
2022-02-01 00:44:54 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-01 00:44:54 | INFO | train | epoch 162 | loss 5.277 | ppl 38.78 | wps 5858.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.03 | train_wall 328 | gb_free 6.1 | wall 57138
KL Stats: Epoch 162 Divergences: Uniform: 3.161009652107703 Unigram: 3.726535426527989
2022-02-01 00:44:54 | INFO | fairseq.trainer | begin training epoch 163
2022-02-01 00:44:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:47:38 | INFO | train_inner | epoch 163:     32 / 64 loss=5.264, ppl=38.44, wps=5732.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.026, train_wall=511, gb_free=6.1, wall=57302
2022-02-01 00:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:50:51 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 10.261 | ppl 1226.92 | wps 7770.7 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.246
2022-02-01 00:50:51 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-01 00:50:51 | INFO | train | epoch 163 | loss 5.273 | ppl 38.68 | wps 5848.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.032 | train_wall 328 | gb_free 6.1 | wall 57495
KL Stats: Epoch 163 Divergences: Uniform: 3.15149764108806 Unigram: 3.7293601410684194
2022-02-01 00:50:51 | INFO | fairseq.trainer | begin training epoch 164
2022-02-01 00:50:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:56:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 00:56:48 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.168 | ppl 1150.78 | wps 7804 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.246
2022-02-01 00:56:48 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-01 00:56:48 | INFO | train | epoch 164 | loss 5.266 | ppl 38.49 | wps 5852.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.053 | train_wall 328 | gb_free 6.1 | wall 57852
KL Stats: Epoch 164 Divergences: Uniform: 3.1513544582971402 Unigram: 3.733933988910646
2022-02-01 00:56:48 | INFO | fairseq.trainer | begin training epoch 165
2022-02-01 00:56:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 00:57:09 | INFO | train_inner | epoch 165:      4 / 64 loss=5.281, ppl=38.88, wps=5715.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.05, train_wall=513, gb_free=6.1, wall=57873
2022-02-01 01:02:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:02:44 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 10.201 | ppl 1176.75 | wps 7790.9 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.246
2022-02-01 01:02:44 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-01 01:02:44 | INFO | train | epoch 165 | loss 5.258 | ppl 38.27 | wps 5856.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.054 | train_wall 328 | gb_free 6.1 | wall 58209
KL Stats: Epoch 165 Divergences: Uniform: 3.156471710547944 Unigram: 3.741887934304215
2022-02-01 01:02:44 | INFO | fairseq.trainer | begin training epoch 166
2022-02-01 01:02:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:06:11 | INFO | train_inner | epoch 166:     40 / 64 loss=5.251, ppl=38.09, wps=6028.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.073, train_wall=513, gb_free=6.1, wall=58415
2022-02-01 01:08:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:08:41 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.114 | ppl 1107.97 | wps 7842.3 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.246
2022-02-01 01:08:41 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-01 01:08:41 | INFO | train | epoch 166 | loss 5.254 | ppl 38.16 | wps 5858.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.079 | train_wall 328 | gb_free 6.1 | wall 58565
KL Stats: Epoch 166 Divergences: Uniform: 3.159389989195111 Unigram: 3.7476906918230664
2022-02-01 01:08:41 | INFO | fairseq.trainer | begin training epoch 167
2022-02-01 01:08:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:14:38 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.139 | ppl 1127.82 | wps 7786.7 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.246
2022-02-01 01:14:38 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-01 01:14:38 | INFO | train | epoch 167 | loss 5.247 | ppl 37.98 | wps 5858.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.065 | train_wall 327 | gb_free 6.1 | wall 58922
KL Stats: Epoch 167 Divergences: Uniform: 3.1548258114326706 Unigram: 3.7444339634522406
2022-02-01 01:14:38 | INFO | fairseq.trainer | begin training epoch 168
2022-02-01 01:14:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:15:40 | INFO | train_inner | epoch 168:     12 / 64 loss=5.249, ppl=38.03, wps=5730.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.055, train_wall=512, gb_free=6.1, wall=58984
2022-02-01 01:20:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:20:35 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.22 | ppl 1192.55 | wps 7753.3 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.246
2022-02-01 01:20:35 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-01 01:20:35 | INFO | train | epoch 168 | loss 5.241 | ppl 37.82 | wps 5846.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.056 | train_wall 328 | gb_free 6.1 | wall 59279
KL Stats: Epoch 168 Divergences: Uniform: 3.16180785549941 Unigram: 3.7506524654054876
2022-02-01 01:20:35 | INFO | fairseq.trainer | begin training epoch 169
2022-02-01 01:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:24:42 | INFO | train_inner | epoch 169:     48 / 64 loss=5.241, ppl=37.81, wps=6025.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.076, train_wall=513, gb_free=6.1, wall=59526
2022-02-01 01:26:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:26:31 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.181 | ppl 1160.99 | wps 7731.8 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.246
2022-02-01 01:26:31 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-01 01:26:31 | INFO | train | epoch 169 | loss 5.236 | ppl 37.68 | wps 5854.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.082 | train_wall 328 | gb_free 6.1 | wall 59636
KL Stats: Epoch 169 Divergences: Uniform: 3.16005977058326 Unigram: 3.7566339754814897
2022-02-01 01:26:31 | INFO | fairseq.trainer | begin training epoch 170
2022-02-01 01:26:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:32:28 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.22 | ppl 1192.61 | wps 7864.7 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.246
2022-02-01 01:32:28 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-01 01:32:28 | INFO | train | epoch 170 | loss 5.232 | ppl 37.57 | wps 5862.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.119 | train_wall 328 | gb_free 6.1 | wall 59992
KL Stats: Epoch 170 Divergences: Uniform: 3.167935037422434 Unigram: 3.7641906196468944
2022-02-01 01:32:28 | INFO | fairseq.trainer | begin training epoch 171
2022-02-01 01:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:34:10 | INFO | train_inner | epoch 171:     20 / 64 loss=5.225, ppl=37.41, wps=5738.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.113, train_wall=511, gb_free=6.1, wall=60094
2022-02-01 01:37:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:38:21 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.207 | ppl 1182.25 | wps 7866.1 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.246
2022-02-01 01:38:21 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-01 01:38:21 | INFO | train | epoch 171 | loss 5.225 | ppl 37.41 | wps 5908.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.125 | train_wall 325 | gb_free 6.1 | wall 60345
KL Stats: Epoch 171 Divergences: Uniform: 3.162335560261489 Unigram: 3.7644736666283607
2022-02-01 01:38:21 | INFO | fairseq.trainer | begin training epoch 172
2022-02-01 01:38:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:43:09 | INFO | train_inner | epoch 172:     56 / 64 loss=5.227, ppl=37.46, wps=6067.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.099, train_wall=509, gb_free=6.1, wall=60633
2022-02-01 01:43:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:44:17 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.204 | ppl 1179.87 | wps 7785 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.246
2022-02-01 01:44:17 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-01 01:44:17 | INFO | train | epoch 172 | loss 5.218 | ppl 37.21 | wps 5876.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.094 | train_wall 326 | gb_free 6.1 | wall 60701
KL Stats: Epoch 172 Divergences: Uniform: 3.1693925541134025 Unigram: 3.7705039571668113
2022-02-01 01:44:17 | INFO | fairseq.trainer | begin training epoch 173
2022-02-01 01:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:50:13 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.167 | ppl 1149.27 | wps 7794.5 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.246
2022-02-01 01:50:13 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-01 01:50:13 | INFO | train | epoch 173 | loss 5.214 | ppl 37.13 | wps 5855.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.147 | train_wall 328 | gb_free 6.1 | wall 61058
KL Stats: Epoch 173 Divergences: Uniform: 3.167246454089047 Unigram: 3.7749430577701006
2022-02-01 01:50:13 | INFO | fairseq.trainer | begin training epoch 174
2022-02-01 01:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 01:52:38 | INFO | train_inner | epoch 174:     28 / 64 loss=5.208, ppl=36.97, wps=5727.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.139, train_wall=512, gb_free=6.1, wall=61202
2022-02-01 01:55:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 01:56:10 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.221 | ppl 1193.88 | wps 7793.5 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.246
2022-02-01 01:56:10 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-01 01:56:10 | INFO | train | epoch 174 | loss 5.209 | ppl 37 | wps 5857 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.133 | train_wall 328 | gb_free 6.1 | wall 61414
KL Stats: Epoch 174 Divergences: Uniform: 3.1646548739762186 Unigram: 3.783897610701194
2022-02-01 01:56:10 | INFO | fairseq.trainer | begin training epoch 175
2022-02-01 01:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:01:39 | INFO | train_inner | epoch 175:     64 / 64 loss=5.213, ppl=37.09, wps=6024.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.136, train_wall=512, gb_free=6.1, wall=61743
2022-02-01 02:01:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:02:07 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.246 | ppl 1214.58 | wps 7794 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.246
2022-02-01 02:02:07 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-01 02:02:07 | INFO | train | epoch 175 | loss 5.203 | ppl 36.82 | wps 5851.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.128 | train_wall 328 | gb_free 6.1 | wall 61771
KL Stats: Epoch 175 Divergences: Uniform: 3.1747484809284576 Unigram: 3.7846221077246396
2022-02-01 02:02:07 | INFO | fairseq.trainer | begin training epoch 176
2022-02-01 02:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:08:03 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.231 | ppl 1201.99 | wps 7786.9 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.246
2022-02-01 02:08:03 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-01 02:08:03 | INFO | train | epoch 176 | loss 5.198 | ppl 36.71 | wps 5864.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.136 | train_wall 327 | gb_free 6.1 | wall 62127
KL Stats: Epoch 176 Divergences: Uniform: 3.1697322154013357 Unigram: 3.7887824058956006
2022-02-01 02:08:03 | INFO | fairseq.trainer | begin training epoch 177
2022-02-01 02:08:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:11:08 | INFO | train_inner | epoch 177:     36 / 64 loss=5.185, ppl=36.38, wps=5738.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.127, train_wall=512, gb_free=6.1, wall=62313
2022-02-01 02:13:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:14:00 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.224 | ppl 1196.03 | wps 7819.2 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.246
2022-02-01 02:14:00 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-01 02:14:00 | INFO | train | epoch 177 | loss 5.192 | ppl 36.56 | wps 5859.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.13 | train_wall 328 | gb_free 6.1 | wall 62484
KL Stats: Epoch 177 Divergences: Uniform: 3.170895565471488 Unigram: 3.7928213436128404
2022-02-01 02:14:00 | INFO | fairseq.trainer | begin training epoch 178
2022-02-01 02:14:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:19:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:19:56 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.23 | ppl 1201.39 | wps 7798.4 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.246
2022-02-01 02:19:56 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-01 02:19:56 | INFO | train | epoch 178 | loss 5.192 | ppl 36.54 | wps 5859.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.203 | train_wall 328 | gb_free 6.1 | wall 62840
KL Stats: Epoch 178 Divergences: Uniform: 3.1791057690376183 Unigram: 3.7987952126538125
2022-02-01 02:19:56 | INFO | fairseq.trainer | begin training epoch 179
2022-02-01 02:19:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:20:37 | INFO | train_inner | epoch 179:      8 / 64 loss=5.198, ppl=36.71, wps=5730.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.185, train_wall=511, gb_free=6.1, wall=62881
2022-02-01 02:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:25:52 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.187 | ppl 1165.68 | wps 7789.1 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.246
2022-02-01 02:25:52 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-01 02:25:52 | INFO | train | epoch 179 | loss 5.182 | ppl 36.29 | wps 5864.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.16 | train_wall 327 | gb_free 6.1 | wall 63196
KL Stats: Epoch 179 Divergences: Uniform: 3.179375766808332 Unigram: 3.8035008846999165
2022-02-01 02:25:52 | INFO | fairseq.trainer | begin training epoch 180
2022-02-01 02:25:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:29:39 | INFO | train_inner | epoch 180:     44 / 64 loss=5.177, ppl=36.18, wps=6029.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.155, train_wall=513, gb_free=6.1, wall=63423
2022-02-01 02:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:31:49 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.172 | ppl 1153.89 | wps 7790.5 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.246
2022-02-01 02:31:49 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-01 02:31:49 | INFO | train | epoch 180 | loss 5.178 | ppl 36.19 | wps 5851.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.17 | train_wall 328 | gb_free 6.1 | wall 63553
KL Stats: Epoch 180 Divergences: Uniform: 3.1717641813935993 Unigram: 3.8072895474609565
2022-02-01 02:31:49 | INFO | fairseq.trainer | begin training epoch 181
2022-02-01 02:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:37:45 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.19 | ppl 1168.22 | wps 7765.5 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.246
2022-02-01 02:37:45 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-01 02:37:45 | INFO | train | epoch 181 | loss 5.17 | ppl 36.01 | wps 5862.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.16 | train_wall 327 | gb_free 6.1 | wall 63909
KL Stats: Epoch 181 Divergences: Uniform: 3.177378616595448 Unigram: 3.8118337992292695
2022-02-01 02:37:45 | INFO | fairseq.trainer | begin training epoch 182
2022-02-01 02:37:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:39:08 | INFO | train_inner | epoch 182:     16 / 64 loss=5.171, ppl=36.03, wps=5733.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.167, train_wall=511, gb_free=6.1, wall=63992
2022-02-01 02:43:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:43:42 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.198 | ppl 1174.72 | wps 7762.9 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.246
2022-02-01 02:43:42 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-01 02:43:42 | INFO | train | epoch 182 | loss 5.169 | ppl 35.97 | wps 5853.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.193 | train_wall 328 | gb_free 6.1 | wall 64266
KL Stats: Epoch 182 Divergences: Uniform: 3.182958410519576 Unigram: 3.811672530912898
2022-02-01 02:43:42 | INFO | fairseq.trainer | begin training epoch 183
2022-02-01 02:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:48:10 | INFO | train_inner | epoch 183:     52 / 64 loss=5.166, ppl=35.89, wps=6028.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.197, train_wall=513, gb_free=6.1, wall=64534
2022-02-01 02:49:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:49:39 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.206 | ppl 1181.2 | wps 7786.3 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.246
2022-02-01 02:49:39 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-01 02:49:39 | INFO | train | epoch 183 | loss 5.161 | ppl 35.77 | wps 5859.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.186 | train_wall 327 | gb_free 6.1 | wall 64623
KL Stats: Epoch 183 Divergences: Uniform: 3.180219092794487 Unigram: 3.8182755778008337
2022-02-01 02:49:39 | INFO | fairseq.trainer | begin training epoch 184
2022-02-01 02:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 02:55:35 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.158 | ppl 1142.63 | wps 7811.3 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.246
2022-02-01 02:55:35 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-01 02:55:35 | INFO | train | epoch 184 | loss 5.159 | ppl 35.72 | wps 5858.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.237 | train_wall 328 | gb_free 6.1 | wall 64979
KL Stats: Epoch 184 Divergences: Uniform: 3.179069445919472 Unigram: 3.8201804522985467
2022-02-01 02:55:35 | INFO | fairseq.trainer | begin training epoch 185
2022-02-01 02:55:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 02:57:38 | INFO | train_inner | epoch 185:     24 / 64 loss=5.159, ppl=35.72, wps=5740.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.225, train_wall=510, gb_free=6.1, wall=65102
2022-02-01 03:01:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:01:28 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.211 | ppl 1184.92 | wps 7908.1 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.246
2022-02-01 03:01:28 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-01 03:01:28 | INFO | train | epoch 185 | loss 5.154 | ppl 35.6 | wps 5913.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.195 | train_wall 325 | gb_free 6.1 | wall 65332
KL Stats: Epoch 185 Divergences: Uniform: 3.178993884690645 Unigram: 3.825198452683274
2022-02-01 03:01:28 | INFO | fairseq.trainer | begin training epoch 186
2022-02-01 03:01:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:06:35 | INFO | train_inner | epoch 186:     60 / 64 loss=5.154, ppl=35.61, wps=6084.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.214, train_wall=508, gb_free=6.1, wall=65639
2022-02-01 03:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:07:22 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.152 | ppl 1137.74 | wps 7783.7 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.246
2022-02-01 03:07:22 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-01 03:07:22 | INFO | train | epoch 186 | loss 5.151 | ppl 35.52 | wps 5901.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.235 | train_wall 325 | gb_free 6.1 | wall 65686
KL Stats: Epoch 186 Divergences: Uniform: 3.1775096567588226 Unigram: 3.8243792362865
2022-02-01 03:07:22 | INFO | fairseq.trainer | begin training epoch 187
2022-02-01 03:07:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:12:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:13:18 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.269 | ppl 1233.48 | wps 7787.4 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.246
2022-02-01 03:13:18 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-01 03:13:18 | INFO | train | epoch 187 | loss 5.144 | ppl 35.36 | wps 5868.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.215 | train_wall 327 | gb_free 6.1 | wall 66042
KL Stats: Epoch 187 Divergences: Uniform: 3.1799654653746448 Unigram: 3.834803896166196
2022-02-01 03:13:18 | INFO | fairseq.trainer | begin training epoch 188
2022-02-01 03:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:16:03 | INFO | train_inner | epoch 188:     32 / 64 loss=5.137, ppl=35.18, wps=5740.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.203, train_wall=510, gb_free=6.1, wall=66207
2022-02-01 03:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:19:14 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.219 | ppl 1191.62 | wps 7773.2 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.246
2022-02-01 03:19:14 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-01 03:19:14 | INFO | train | epoch 188 | loss 5.138 | ppl 35.2 | wps 5861.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.222 | train_wall 327 | gb_free 6.1 | wall 66399
KL Stats: Epoch 188 Divergences: Uniform: 3.1785500497221153 Unigram: 3.8384672724507514
2022-02-01 03:19:14 | INFO | fairseq.trainer | begin training epoch 189
2022-02-01 03:19:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:24:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:25:10 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.201 | ppl 1177.41 | wps 7837.5 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.246
2022-02-01 03:25:10 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-01 03:25:10 | INFO | train | epoch 189 | loss 5.134 | ppl 35.12 | wps 5877.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.268 | train_wall 327 | gb_free 6.1 | wall 66754
KL Stats: Epoch 189 Divergences: Uniform: 3.183505595973794 Unigram: 3.8421271093887484
2022-02-01 03:25:10 | INFO | fairseq.trainer | begin training epoch 190
2022-02-01 03:25:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:25:30 | INFO | train_inner | epoch 190:      4 / 64 loss=5.14, ppl=35.27, wps=5742.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.268, train_wall=510, gb_free=6.1, wall=66775
2022-02-01 03:30:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:31:05 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.245 | ppl 1213.46 | wps 7811.9 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.246
2022-02-01 03:31:05 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-01 03:31:05 | INFO | train | epoch 190 | loss 5.129 | ppl 34.99 | wps 5881.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.235 | train_wall 326 | gb_free 6.1 | wall 67109
KL Stats: Epoch 190 Divergences: Uniform: 3.1838642796356837 Unigram: 3.8461705168458655
2022-02-01 03:31:05 | INFO | fairseq.trainer | begin training epoch 191
2022-02-01 03:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:34:30 | INFO | train_inner | epoch 191:     40 / 64 loss=5.119, ppl=34.74, wps=6051.9, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.251, train_wall=511, gb_free=6.1, wall=67315
2022-02-01 03:36:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:37:01 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.203 | ppl 1178.97 | wps 7783.2 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.246
2022-02-01 03:37:01 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-01 03:37:01 | INFO | train | epoch 191 | loss 5.126 | ppl 34.91 | wps 5863.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.261 | train_wall 327 | gb_free 6.1 | wall 67465
KL Stats: Epoch 191 Divergences: Uniform: 3.184101226009161 Unigram: 3.846745972732835
2022-02-01 03:37:01 | INFO | fairseq.trainer | begin training epoch 192
2022-02-01 03:37:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:42:57 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.195 | ppl 1172.39 | wps 7792.4 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.246
2022-02-01 03:42:57 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-01 03:42:57 | INFO | train | epoch 192 | loss 5.122 | ppl 34.83 | wps 5866.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.272 | train_wall 327 | gb_free 6.1 | wall 67821
KL Stats: Epoch 192 Divergences: Uniform: 3.1823351248814378 Unigram: 3.8438328492392766
2022-02-01 03:42:57 | INFO | fairseq.trainer | begin training epoch 193
2022-02-01 03:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:43:59 | INFO | train_inner | epoch 193:     12 / 64 loss=5.128, ppl=34.97, wps=5733.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.268, train_wall=511, gb_free=6.1, wall=67883
2022-02-01 03:48:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:48:53 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.15 | ppl 1136.23 | wps 7809.2 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.246
2022-02-01 03:48:53 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-01 03:48:53 | INFO | train | epoch 193 | loss 5.118 | ppl 34.72 | wps 5862.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.294 | train_wall 327 | gb_free 6.1 | wall 68178
KL Stats: Epoch 193 Divergences: Uniform: 3.1914390736667517 Unigram: 3.852600357345195
2022-02-01 03:48:53 | INFO | fairseq.trainer | begin training epoch 194
2022-02-01 03:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 03:53:00 | INFO | train_inner | epoch 194:     48 / 64 loss=5.114, ppl=34.63, wps=6043.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.293, train_wall=511, gb_free=6.1, wall=68424
2022-02-01 03:54:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 03:54:49 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.182 | ppl 1161.79 | wps 7781.5 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.246
2022-02-01 03:54:49 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-01 03:54:49 | INFO | train | epoch 194 | loss 5.113 | ppl 34.6 | wps 5873.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.318 | train_wall 327 | gb_free 6.1 | wall 68533
KL Stats: Epoch 194 Divergences: Uniform: 3.1890637539145263 Unigram: 3.8575371569969152
2022-02-01 03:54:49 | INFO | fairseq.trainer | begin training epoch 195
2022-02-01 03:54:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:00:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:00:45 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.218 | ppl 1191.36 | wps 7792.9 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.246
2022-02-01 04:00:45 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-01 04:00:45 | INFO | train | epoch 195 | loss 5.108 | ppl 34.49 | wps 5862.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.298 | train_wall 327 | gb_free 6.1 | wall 68889
KL Stats: Epoch 195 Divergences: Uniform: 3.1885844526743816 Unigram: 3.858804741066612
2022-02-01 04:00:45 | INFO | fairseq.trainer | begin training epoch 196
2022-02-01 04:00:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:02:28 | INFO | train_inner | epoch 196:     20 / 64 loss=5.106, ppl=34.45, wps=5733, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.311, train_wall=511, gb_free=6.1, wall=68993
2022-02-01 04:06:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:06:42 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.21 | ppl 1184.84 | wps 7793.5 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.246
2022-02-01 04:06:42 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-01 04:06:42 | INFO | train | epoch 196 | loss 5.106 | ppl 34.43 | wps 5855.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.336 | train_wall 328 | gb_free 6.1 | wall 69246
KL Stats: Epoch 196 Divergences: Uniform: 3.1877433700239823 Unigram: 3.8604513818933017
2022-02-01 04:06:42 | INFO | fairseq.trainer | begin training epoch 197
2022-02-01 04:06:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:11:30 | INFO | train_inner | epoch 197:     56 / 64 loss=5.105, ppl=34.41, wps=6035.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.34, train_wall=512, gb_free=6.1, wall=69534
2022-02-01 04:12:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:12:38 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.211 | ppl 1185.54 | wps 7766.4 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.246
2022-02-01 04:12:38 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-01 04:12:38 | INFO | train | epoch 197 | loss 5.099 | ppl 34.28 | wps 5868.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.328 | train_wall 327 | gb_free 6.1 | wall 69602
KL Stats: Epoch 197 Divergences: Uniform: 3.1865663248012184 Unigram: 3.8635427002582983
2022-02-01 04:12:38 | INFO | fairseq.trainer | begin training epoch 198
2022-02-01 04:12:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:18:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:18:33 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.205 | ppl 1180.13 | wps 7818.7 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.246
2022-02-01 04:18:33 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-01 04:18:33 | INFO | train | epoch 198 | loss 5.095 | ppl 34.18 | wps 5882.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.337 | train_wall 326 | gb_free 6.1 | wall 69957
KL Stats: Epoch 198 Divergences: Uniform: 3.1929393927891203 Unigram: 3.8711975379567964
2022-02-01 04:18:33 | INFO | fairseq.trainer | begin training epoch 199
2022-02-01 04:18:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:20:57 | INFO | train_inner | epoch 199:     28 / 64 loss=5.091, ppl=34.07, wps=5749.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.332, train_wall=509, gb_free=6.1, wall=70101
2022-02-01 04:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:24:28 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.221 | ppl 1193.68 | wps 7867.5 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.246
2022-02-01 04:24:28 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-01 04:24:28 | INFO | train | epoch 199 | loss 5.091 | ppl 34.09 | wps 5886.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.314 | train_wall 326 | gb_free 6.1 | wall 70312
KL Stats: Epoch 199 Divergences: Uniform: 3.191141017214542 Unigram: 3.8772058656254824
2022-02-01 04:24:28 | INFO | fairseq.trainer | begin training epoch 200
2022-02-01 04:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:29:53 | INFO | train_inner | epoch 200:     64 / 64 loss=5.099, ppl=34.27, wps=6079.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.341, train_wall=507, gb_free=6.1, wall=70637
2022-02-01 04:29:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:30:21 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.241 | ppl 1209.92 | wps 7865.2 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.246
2022-02-01 04:30:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-01 04:30:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint200.pt
2022-02-01 04:30:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint200.pt
2022-02-01 04:30:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.241) (writing took 3.9518785681575537 seconds)
2022-02-01 04:30:25 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-01 04:30:25 | INFO | train | epoch 200 | loss 5.087 | ppl 33.99 | wps 5848.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.357 | train_wall 324 | gb_free 6.1 | wall 70669
KL Stats: Epoch 200 Divergences: Uniform: 3.190097251998759 Unigram: 3.876024122403243
2022-02-01 04:30:25 | INFO | fairseq.trainer | begin training epoch 201
2022-02-01 04:30:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:36:20 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.238 | ppl 1207.87 | wps 7778.4 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.246
2022-02-01 04:36:20 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-01 04:36:20 | INFO | train | epoch 201 | loss 5.084 | ppl 33.93 | wps 5877.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.335 | train_wall 326 | gb_free 6.1 | wall 71024
KL Stats: Epoch 201 Divergences: Uniform: 3.188080827236387 Unigram: 3.8778765306333094
2022-02-01 04:36:20 | INFO | fairseq.trainer | begin training epoch 202
2022-02-01 04:36:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:39:26 | INFO | train_inner | epoch 202:     36 / 64 loss=5.071, ppl=33.62, wps=5707.8, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.352, train_wall=511, gb_free=6.1, wall=71210
2022-02-01 04:41:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:42:17 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.206 | ppl 1181.42 | wps 7759.7 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.246
2022-02-01 04:42:17 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-01 04:42:17 | INFO | train | epoch 202 | loss 5.08 | ppl 33.82 | wps 5862.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.358 | train_wall 327 | gb_free 6.1 | wall 71381
KL Stats: Epoch 202 Divergences: Uniform: 3.1914965566718942 Unigram: 3.887394019142554
2022-02-01 04:42:17 | INFO | fairseq.trainer | begin training epoch 203
2022-02-01 04:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:47:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-01 04:48:14 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.225 | ppl 1196.91 | wps 7782.6 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.246
2022-02-01 04:48:14 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-01 04:48:14 | INFO | train | epoch 203 | loss 5.074 | ppl 33.68 | wps 5849.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.364 | train_wall 328 | gb_free 6.1 | wall 71738
KL Stats: Epoch 203 Divergences: Uniform: 3.19078468916631 Unigram: 3.887174998290582
2022-02-01 04:48:14 | INFO | fairseq.trainer | begin training epoch 204
2022-02-01 04:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-01 04:48:55 | INFO | train_inner | epoch 204:      8 / 64 loss=5.083, ppl=33.89, wps=5725.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.354, train_wall=512, gb_free=6.1, wall=71779
User defined signal 2
Sender: LSF System <lsfadmin@eu-g3-022>
Subject: Job 202993777: <w2_jelinek_0.09_0.01_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.09_0.01_0.9_#1> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:10:42 2022
Job was executed on host(s) <eu-g3-022>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:11:20 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:11:20 2022
Terminated at Thu Feb  3 02:11:22 2022
Results reported at Thu Feb  3 02:11:22 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.09, 0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 10002 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71977.00 sec.
    Max Memory :                                 5223 MB
    Average Memory :                             2762.38 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14777.00 MB
    Max Swap :                                   2 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72001 sec.
    Turnaround time :                            72040 sec.

The output (if any) follows:

2022-02-02 06:11:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 10002, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 10002, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.09, 0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:11:26 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:11:27 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1122/36718 [00:00<00:03, 11219.32it/s]  6%|▌         | 2244/36718 [00:00<00:03, 10227.20it/s]  9%|▉         | 3470/36718 [00:00<00:02, 11108.22it/s] 13%|█▎        | 4694/36718 [00:00<00:02, 11538.40it/s] 16%|█▋        | 6021/36718 [00:00<00:02, 12146.23it/s] 20%|█▉        | 7241/36718 [00:00<00:02, 11371.55it/s] 23%|██▎       | 8390/36718 [00:00<00:02, 11239.99it/s] 26%|██▌       | 9522/36718 [00:00<00:02, 11082.41it/s] 29%|██▉       | 10646/36718 [00:00<00:02, 11124.97it/s] 32%|███▏      | 11762/36718 [00:01<00:02, 11006.17it/s] 35%|███▌      | 12915/36718 [00:01<00:02, 11152.34it/s] 38%|███▊      | 14090/36718 [00:01<00:01, 11323.18it/s] 42%|████▏     | 15296/36718 [00:01<00:01, 11539.63it/s] 45%|████▍     | 16452/36718 [00:01<00:01, 11122.17it/s] 48%|████▊     | 17569/36718 [00:01<00:01, 11068.54it/s] 51%|█████     | 18679/36718 [00:01<00:01, 11065.58it/s] 54%|█████▍    | 19956/36718 [00:01<00:01, 11566.91it/s] 58%|█████▊    | 21116/36718 [00:01<00:01, 11303.25it/s] 61%|██████    | 22249/36718 [00:01<00:01, 11177.01it/s] 64%|██████▍   | 23417/36718 [00:02<00:01, 11322.94it/s] 68%|██████▊   | 24809/36718 [00:02<00:00, 12087.42it/s] 71%|███████   | 26021/36718 [00:02<00:00, 11871.05it/s] 74%|███████▍  | 27211/36718 [00:02<00:00, 11187.79it/s] 77%|███████▋  | 28376/36718 [00:02<00:00, 11313.40it/s] 80%|████████  | 29515/36718 [00:02<00:00, 11250.07it/s] 83%|████████▎ | 30645/36718 [00:02<00:00, 11118.07it/s] 87%|████████▋ | 31764/36718 [00:02<00:00, 11136.20it/s] 90%|████████▉ | 32880/36718 [00:02<00:00, 10803.50it/s] 92%|█████████▏| 33964/36718 [00:03<00:00, 10790.65it/s] 96%|█████████▌| 35102/36718 [00:03<00:00, 10959.83it/s] 99%|█████████▊| 36227/36718 [00:03<00:00, 11036.18it/s]100%|██████████| 36718/36718 [00:03<00:00, 11224.52it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  5%|▌         | 1991/36718 [00:00<00:01, 19901.00it/s] 11%|█▏        | 4176/36718 [00:00<00:01, 21043.61it/s] 18%|█▊        | 6437/36718 [00:00<00:01, 21745.61it/s] 23%|██▎       | 8612/36718 [00:00<00:01, 20811.50it/s] 29%|██▉       | 10740/36718 [00:00<00:01, 20971.44it/s] 35%|███▍      | 12842/36718 [00:00<00:01, 20898.20it/s] 41%|████      | 15025/36718 [00:00<00:01, 21189.79it/s] 47%|████▋     | 17147/36718 [00:00<00:00, 20810.58it/s] 53%|█████▎    | 19415/36718 [00:00<00:00, 21378.04it/s] 59%|█████▊    | 21556/36718 [00:01<00:00, 20737.04it/s] 65%|██████▍   | 23843/36718 [00:01<00:00, 21366.47it/s] 71%|███████   | 26134/36718 [00:01<00:00, 21824.81it/s] 77%|███████▋  | 28322/36718 [00:01<00:00, 21252.09it/s] 83%|████████▎ | 30454/36718 [00:01<00:00, 21268.18it/s] 89%|████████▊ | 32586/36718 [00:01<00:00, 20695.15it/s] 94%|█████████▍| 34661/36718 [00:01<00:00, 20700.64it/s]100%|██████████| 36718/36718 [00:01<00:00, 20974.91it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 286.77it/s]2022-02-02 06:11:35 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:11:35 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:11:35 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:11:35 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:11:35 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:11:35 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:11:35 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:11:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:11:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:11:35 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:11:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:11:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:11:35 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:11:35 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:11:35 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:11:35 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:11:35 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:11:35 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:11:35 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:11:35 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:17:23 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.783 | ppl 28195.8 | wps 8218.8 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:17:23 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:17:23 | INFO | train | epoch 001 | loss 16.125 | ppl 71491.5 | wps 6057.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.151 | train_wall 317 | gb_free 6.1 | wall 348
KL Stats: Epoch 1 Divergences: Uniform: 0.5118491660209957 Unigram: 3.6911737086028986
2022-02-02 06:17:23 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:17:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:20:23 | INFO | train_inner | epoch 002:     36 / 64 loss=15.602, ppl=49723.2, wps=6235.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.621, train_wall=495, gb_free=6.1, wall=527
2022-02-02 06:22:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:23:07 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.732 | ppl 13604.9 | wps 8227.4 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:23:07 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:23:07 | INFO | train | epoch 002 | loss 14.441 | ppl 22247.2 | wps 6067.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.575 | train_wall 316 | gb_free 6.1 | wall 692
KL Stats: Epoch 2 Divergences: Uniform: 0.5155452949917163 Unigram: 2.448847361580298
2022-02-02 06:23:07 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:28:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:28:52 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.864 | ppl 7454.01 | wps 8236.1 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:28:52 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:28:52 | INFO | train | epoch 003 | loss 13.507 | ppl 11641.5 | wps 6068 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.296 | train_wall 316 | gb_free 6.1 | wall 1036
KL Stats: Epoch 3 Divergences: Uniform: 0.49998427577617693 Unigram: 1.7510088537726676
2022-02-02 06:28:52 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:29:31 | INFO | train_inner | epoch 004:      8 / 64 loss=13.641, ppl=12771.9, wps=5939.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.326, train_wall=493, gb_free=6.1, wall=1076
2022-02-02 06:34:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:34:36 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.994 | ppl 4077.85 | wps 8212.8 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:34:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:34:36 | INFO | train | epoch 004 | loss 12.52 | ppl 5873.46 | wps 6067.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 1.029 | train_wall 316 | gb_free 6.1 | wall 1380
KL Stats: Epoch 4 Divergences: Uniform: 0.5896695263376248 Unigram: 1.1181568717141708
2022-02-02 06:34:36 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:38:15 | INFO | train_inner | epoch 005:     44 / 64 loss=12.165, ppl=4592.55, wps=6237.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.928, train_wall=495, gb_free=6.1, wall=1600
2022-02-02 06:39:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:40:21 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.476 | ppl 2847.84 | wps 8197.9 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:40:21 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:40:21 | INFO | train | epoch 005 | loss 11.714 | ppl 3358.93 | wps 6056.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.768 | train_wall 317 | gb_free 6.1 | wall 1725
KL Stats: Epoch 5 Divergences: Uniform: 0.8370968797076717 Unigram: 0.6376283045906096
2022-02-02 06:40:21 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:40:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:46:05 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.219 | ppl 2384.23 | wps 8233.2 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:46:05 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:46:05 | INFO | train | epoch 006 | loss 11.284 | ppl 2493.42 | wps 6066.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.598 | train_wall 316 | gb_free 6.1 | wall 2070
KL Stats: Epoch 6 Divergences: Uniform: 1.1620054775696038 Unigram: 0.4216801646916643
2022-02-02 06:46:05 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:47:25 | INFO | train_inner | epoch 007:     16 / 64 loss=11.308, ppl=2534.73, wps=5935.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.594, train_wall=493, gb_free=6.1, wall=2149
2022-02-02 06:51:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:51:49 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.072 | ppl 2153.36 | wps 8241.9 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:51:49 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:51:49 | INFO | train | epoch 007 | loss 11.087 | ppl 2175.08 | wps 6070 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.502 | train_wall 316 | gb_free 6.1 | wall 2414
KL Stats: Epoch 7 Divergences: Uniform: 1.3967063726449722 Unigram: 0.4438190927941483
2022-02-02 06:51:49 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:51:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:56:09 | INFO | train_inner | epoch 008:     52 / 64 loss=11.022, ppl=2079.78, wps=6236.9, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.493, train_wall=495, gb_free=6.1, wall=2673
2022-02-02 06:57:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:57:34 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.968 | ppl 2002.8 | wps 8218.7 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:57:34 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:57:34 | INFO | train | epoch 008 | loss 10.971 | ppl 2006.69 | wps 6056.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.486 | train_wall 317 | gb_free 6.1 | wall 2759
KL Stats: Epoch 8 Divergences: Uniform: 1.5183995969550534 Unigram: 0.5263649910701628
2022-02-02 06:57:34 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:57:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:03:18 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.865 | ppl 1864.61 | wps 8230.5 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 07:03:18 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 07:03:18 | INFO | train | epoch 009 | loss 10.867 | ppl 1867.16 | wps 6073.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.497 | train_wall 316 | gb_free 6.1 | wall 3102
KL Stats: Epoch 9 Divergences: Uniform: 1.5709635985463766 Unigram: 0.6196227517595727
2022-02-02 07:03:18 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 07:03:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:05:17 | INFO | train_inner | epoch 010:     24 / 64 loss=10.855, ppl=1852.73, wps=5940.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.49, train_wall=493, gb_free=6.1, wall=3222
2022-02-02 07:08:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:09:02 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.742 | ppl 1712.86 | wps 8218.2 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:09:02 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:09:02 | INFO | train | epoch 010 | loss 10.755 | ppl 1728.65 | wps 6063 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.506 | train_wall 316 | gb_free 6.1 | wall 3447
KL Stats: Epoch 10 Divergences: Uniform: 1.5947959660108069 Unigram: 0.7303115537681952
2022-02-02 07:09:02 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:09:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:14:02 | INFO | train_inner | epoch 011:     60 / 64 loss=10.682, ppl=1642.39, wps=6233.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.501, train_wall=495, gb_free=6.1, wall=3746
2022-02-02 07:14:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:14:47 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.636 | ppl 1590.83 | wps 8243 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:14:47 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:14:47 | INFO | train | epoch 011 | loss 10.639 | ppl 1594.26 | wps 6059.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.484 | train_wall 317 | gb_free 6.1 | wall 3792
KL Stats: Epoch 11 Divergences: Uniform: 1.6153457766895658 Unigram: 0.8332293433080606
2022-02-02 07:14:47 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:14:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:20:31 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.552 | ppl 1501.12 | wps 8217.2 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:20:31 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:20:31 | INFO | train | epoch 012 | loss 10.523 | ppl 1471.77 | wps 6077.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.503 | train_wall 315 | gb_free 6.1 | wall 4135
KL Stats: Epoch 12 Divergences: Uniform: 1.635430809661012 Unigram: 0.9318453074559814
2022-02-02 07:20:31 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:20:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:23:10 | INFO | train_inner | epoch 013:     32 / 64 loss=10.495, ppl=1443.51, wps=5945.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.492, train_wall=493, gb_free=6.1, wall=4295
2022-02-02 07:25:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:26:14 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.445 | ppl 1394.31 | wps 8238.5 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:26:14 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:26:14 | INFO | train | epoch 013 | loss 10.409 | ppl 1359.18 | wps 6073.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.483 | train_wall 316 | gb_free 6.1 | wall 4479
KL Stats: Epoch 13 Divergences: Uniform: 1.651291588439552 Unigram: 1.0229696038559812
2022-02-02 07:26:14 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:26:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:31:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:31:58 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.359 | ppl 1313.28 | wps 8239.2 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:31:58 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:31:58 | INFO | train | epoch 014 | loss 10.296 | ppl 1257.56 | wps 6071.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.537 | train_wall 316 | gb_free 6.1 | wall 4823
KL Stats: Epoch 14 Divergences: Uniform: 1.6793214393307567 Unigram: 1.0988846404574681
2022-02-02 07:31:58 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:31:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:32:18 | INFO | train_inner | epoch 015:      4 / 64 loss=10.321, ppl=1279.3, wps=5943.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.523, train_wall=493, gb_free=6.1, wall=4843
2022-02-02 07:37:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:37:43 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.268 | ppl 1232.94 | wps 8251.2 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:37:43 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:37:43 | INFO | train | epoch 015 | loss 10.184 | ppl 1163.39 | wps 6067.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.496 | train_wall 316 | gb_free 6.1 | wall 5167
KL Stats: Epoch 15 Divergences: Uniform: 1.7063984040202325 Unigram: 1.1743598031405074
2022-02-02 07:37:43 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:37:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:41:02 | INFO | train_inner | epoch 016:     40 / 64 loss=10.145, ppl=1131.89, wps=6243, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.513, train_wall=495, gb_free=6.1, wall=5367
2022-02-02 07:43:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:43:27 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.177 | ppl 1157.5 | wps 8254.4 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:43:27 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:43:27 | INFO | train | epoch 016 | loss 10.079 | ppl 1081.4 | wps 6072.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.521 | train_wall 316 | gb_free 6.1 | wall 5511
KL Stats: Epoch 16 Divergences: Uniform: 1.7394564964482375 Unigram: 1.243256312711896
2022-02-02 07:43:27 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:43:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:48:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:49:10 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.1 | ppl 1097.7 | wps 8262.4 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:49:10 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:49:10 | INFO | train | epoch 017 | loss 9.973 | ppl 1005.01 | wps 6080.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.54 | train_wall 315 | gb_free 6.1 | wall 5855
KL Stats: Epoch 17 Divergences: Uniform: 1.768504551501471 Unigram: 1.3059780513028594
2022-02-02 07:49:10 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:50:10 | INFO | train_inner | epoch 018:     12 / 64 loss=9.983, ppl=1012.02, wps=5949.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.528, train_wall=492, gb_free=6.1, wall=5915
2022-02-02 07:54:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:54:54 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.045 | ppl 1056.34 | wps 8202.4 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:54:54 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:54:54 | INFO | train | epoch 018 | loss 9.87 | ppl 935.74 | wps 6072.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.51 | train_wall 316 | gb_free 6.1 | wall 6199
KL Stats: Epoch 18 Divergences: Uniform: 1.8055993774124532 Unigram: 1.3729866248895686
2022-02-02 07:54:54 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:58:53 | INFO | train_inner | epoch 019:     48 / 64 loss=9.827, ppl=908.15, wps=6245, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.534, train_wall=494, gb_free=6.1, wall=6438
2022-02-02 08:00:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:00:38 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.99 | ppl 1017.17 | wps 8248.6 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 08:00:38 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 08:00:38 | INFO | train | epoch 019 | loss 9.772 | ppl 874.52 | wps 6072.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.551 | train_wall 316 | gb_free 6.1 | wall 6543
KL Stats: Epoch 19 Divergences: Uniform: 1.8382102533070395 Unigram: 1.4323132512202223
2022-02-02 08:00:38 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 08:00:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:05:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:06:21 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.914 | ppl 964.52 | wps 8233.6 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:06:21 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:06:21 | INFO | train | epoch 020 | loss 9.678 | ppl 818.93 | wps 6081.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.524 | train_wall 315 | gb_free 6.1 | wall 6886
KL Stats: Epoch 20 Divergences: Uniform: 1.8697537885895317 Unigram: 1.4904226587446223
2022-02-02 08:06:21 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:08:01 | INFO | train_inner | epoch 021:     20 / 64 loss=9.67, ppl=814.88, wps=5949.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.523, train_wall=492, gb_free=6.1, wall=6986
2022-02-02 08:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:12:05 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.845 | ppl 919.43 | wps 8241 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:12:05 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:12:05 | INFO | train | epoch 021 | loss 9.587 | ppl 768.96 | wps 6074.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.524 | train_wall 316 | gb_free 6.1 | wall 7230
KL Stats: Epoch 21 Divergences: Uniform: 1.895841569515318 Unigram: 1.5442153809602874
2022-02-02 08:12:05 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:16:44 | INFO | train_inner | epoch 022:     56 / 64 loss=9.539, ppl=743.82, wps=6248.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.527, train_wall=494, gb_free=6.1, wall=7509
2022-02-02 08:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:17:49 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.776 | ppl 876.64 | wps 8241.7 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:17:49 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:17:49 | INFO | train | epoch 022 | loss 9.499 | ppl 723.47 | wps 6072.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.537 | train_wall 316 | gb_free 6.1 | wall 7574
KL Stats: Epoch 22 Divergences: Uniform: 1.9237560890433103 Unigram: 1.5888901530929105
2022-02-02 08:17:49 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:23:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:23:33 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.73 | ppl 849.11 | wps 8226 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:23:33 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:23:33 | INFO | train | epoch 023 | loss 9.412 | ppl 681.24 | wps 6073.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.523 | train_wall 316 | gb_free 6.1 | wall 7918
KL Stats: Epoch 23 Divergences: Uniform: 1.9461257169895367 Unigram: 1.6393831878358187
2022-02-02 08:23:33 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:23:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:25:53 | INFO | train_inner | epoch 024:     28 / 64 loss=9.394, ppl=672.69, wps=5941.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.52, train_wall=493, gb_free=6.1, wall=8057
2022-02-02 08:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:29:18 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.687 | ppl 824.1 | wps 8252.1 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:29:18 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:29:18 | INFO | train | epoch 024 | loss 9.33 | ppl 643.61 | wps 6065.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.526 | train_wall 316 | gb_free 6.1 | wall 8262
KL Stats: Epoch 24 Divergences: Uniform: 1.977702619020959 Unigram: 1.6790609400482956
2022-02-02 08:29:18 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:29:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:34:35 | INFO | train_inner | epoch 025:     64 / 64 loss=9.277, ppl=620.29, wps=6238.6, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.543, train_wall=494, gb_free=6.1, wall=8580
2022-02-02 08:34:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:35:02 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.647 | ppl 801.56 | wps 8224.1 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:35:02 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:35:02 | INFO | train | epoch 025 | loss 9.248 | ppl 607.9 | wps 6064.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.542 | train_wall 316 | gb_free 6.1 | wall 8607
KL Stats: Epoch 25 Divergences: Uniform: 2.0018680527429287 Unigram: 1.7228074583856996
2022-02-02 08:35:02 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:35:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:40:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:40:47 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.606 | ppl 779.26 | wps 8215.5 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:40:47 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:40:47 | INFO | train | epoch 026 | loss 9.167 | ppl 574.81 | wps 6054.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.53 | train_wall 317 | gb_free 6.1 | wall 8952
KL Stats: Epoch 26 Divergences: Uniform: 2.0226353067744323 Unigram: 1.76660750825512
2022-02-02 08:40:47 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:43:46 | INFO | train_inner | epoch 027:     36 / 64 loss=9.14, ppl=564.12, wps=5930.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.529, train_wall=495, gb_free=6.1, wall=9131
2022-02-02 08:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:46:31 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.561 | ppl 755.39 | wps 8232.6 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:46:31 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:46:31 | INFO | train | epoch 027 | loss 9.089 | ppl 544.59 | wps 6064.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.54 | train_wall 316 | gb_free 6.1 | wall 9296
KL Stats: Epoch 27 Divergences: Uniform: 2.044961802016562 Unigram: 1.800725932233449
2022-02-02 08:46:31 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:46:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:52:17 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.524 | ppl 736.28 | wps 8243.2 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:52:17 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:52:17 | INFO | train | epoch 028 | loss 9.01 | ppl 515.65 | wps 6049.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.532 | train_wall 317 | gb_free 6.1 | wall 9641
KL Stats: Epoch 28 Divergences: Uniform: 2.073284570026863 Unigram: 1.8371652717649594
2022-02-02 08:52:17 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:52:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:52:57 | INFO | train_inner | epoch 029:      8 / 64 loss=9.023, ppl=520.22, wps=5925.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.537, train_wall=495, gb_free=6.1, wall=9681
2022-02-02 08:57:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:58:01 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.493 | ppl 720.44 | wps 8212.3 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 08:58:01 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 08:58:01 | INFO | train | epoch 029 | loss 8.932 | ppl 488.5 | wps 6064.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.52 | train_wall 316 | gb_free 6.1 | wall 9986
KL Stats: Epoch 29 Divergences: Uniform: 2.0950653634492524 Unigram: 1.87332143521129
2022-02-02 08:58:01 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 08:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:01:40 | INFO | train_inner | epoch 030:     44 / 64 loss=8.899, ppl=477.35, wps=6237.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.516, train_wall=495, gb_free=6.1, wall=10205
2022-02-02 09:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:03:45 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.459 | ppl 703.9 | wps 8211 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 09:03:45 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 09:03:45 | INFO | train | epoch 030 | loss 8.853 | ppl 462.45 | wps 6064.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.513 | train_wall 316 | gb_free 6.1 | wall 10330
KL Stats: Epoch 30 Divergences: Uniform: 2.119707931373789 Unigram: 1.9083637433532499
2022-02-02 09:03:45 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 09:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:09:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:09:29 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.425 | ppl 687.45 | wps 8250.4 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:09:29 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:09:29 | INFO | train | epoch 031 | loss 8.778 | ppl 439.1 | wps 6069.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.521 | train_wall 316 | gb_free 6.1 | wall 10674
KL Stats: Epoch 31 Divergences: Uniform: 2.136221503872793 Unigram: 1.9411581747805973
2022-02-02 09:09:29 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:10:49 | INFO | train_inner | epoch 032:     16 / 64 loss=8.784, ppl=440.73, wps=5939.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.527, train_wall=493, gb_free=6.1, wall=10754
2022-02-02 09:14:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:15:14 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.411 | ppl 680.56 | wps 8221.3 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:15:14 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:15:14 | INFO | train | epoch 032 | loss 8.705 | ppl 417.22 | wps 6062.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.511 | train_wall 316 | gb_free 6.1 | wall 11019
KL Stats: Epoch 32 Divergences: Uniform: 2.1516273067201768 Unigram: 1.9793395840534358
2022-02-02 09:15:14 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:19:33 | INFO | train_inner | epoch 033:     52 / 64 loss=8.664, ppl=405.51, wps=6237.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.508, train_wall=495, gb_free=6.1, wall=11278
2022-02-02 09:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:20:58 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.371 | ppl 661.96 | wps 8227.3 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:20:58 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:20:58 | INFO | train | epoch 033 | loss 8.63 | ppl 396.19 | wps 6066.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.514 | train_wall 316 | gb_free 6.1 | wall 11363
KL Stats: Epoch 33 Divergences: Uniform: 2.1739991588482472 Unigram: 2.008960980602862
2022-02-02 09:20:58 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:26:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:26:43 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.339 | ppl 647.58 | wps 8231.2 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:26:43 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:26:43 | INFO | train | epoch 034 | loss 8.556 | ppl 376.49 | wps 6060.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.5 | train_wall 316 | gb_free 6.1 | wall 11708
KL Stats: Epoch 34 Divergences: Uniform: 2.2047916847073235 Unigram: 2.0402233537122827
2022-02-02 09:26:43 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:28:42 | INFO | train_inner | epoch 035:     24 / 64 loss=8.546, ppl=373.83, wps=5935.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.497, train_wall=494, gb_free=6.1, wall=11827
2022-02-02 09:32:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:32:27 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.336 | ppl 646.45 | wps 8240.7 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:32:27 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:32:27 | INFO | train | epoch 035 | loss 8.485 | ppl 358.21 | wps 6071.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.504 | train_wall 316 | gb_free 6.1 | wall 12052
KL Stats: Epoch 35 Divergences: Uniform: 2.2303383084757296 Unigram: 2.0735293893987636
2022-02-02 09:32:27 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:37:26 | INFO | train_inner | epoch 036:     60 / 64 loss=8.443, ppl=348, wps=6247, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.508, train_wall=494, gb_free=6.1, wall=12350
2022-02-02 09:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:38:11 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.317 | ppl 637.87 | wps 8225.9 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:38:11 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:38:11 | INFO | train | epoch 036 | loss 8.414 | ppl 341.12 | wps 6073.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.508 | train_wall 316 | gb_free 6.1 | wall 12395
KL Stats: Epoch 36 Divergences: Uniform: 2.246322598184314 Unigram: 2.107521652910797
2022-02-02 09:38:11 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:43:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:43:55 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.282 | ppl 622.34 | wps 8211.6 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:43:55 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:43:55 | INFO | train | epoch 037 | loss 8.343 | ppl 324.74 | wps 6075.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.507 | train_wall 316 | gb_free 6.1 | wall 12739
KL Stats: Epoch 37 Divergences: Uniform: 2.267135696944479 Unigram: 2.137144958078729
2022-02-02 09:43:55 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:43:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:46:34 | INFO | train_inner | epoch 038:     32 / 64 loss=8.322, ppl=320.07, wps=5941.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.512, train_wall=493, gb_free=6.1, wall=12899
2022-02-02 09:49:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:49:39 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.268 | ppl 616.72 | wps 8209.3 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:49:39 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:49:39 | INFO | train | epoch 038 | loss 8.275 | ppl 309.7 | wps 6060.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.508 | train_wall 316 | gb_free 6.1 | wall 13084
KL Stats: Epoch 38 Divergences: Uniform: 2.293787634642559 Unigram: 2.164907222316893
2022-02-02 09:49:39 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:55:24 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.278 | ppl 620.72 | wps 8224 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 09:55:24 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 09:55:24 | INFO | train | epoch 039 | loss 8.208 | ppl 295.75 | wps 6057.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.496 | train_wall 317 | gb_free 6.1 | wall 13429
KL Stats: Epoch 39 Divergences: Uniform: 2.31484335272036 Unigram: 2.200027367511009
2022-02-02 09:55:24 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 09:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:55:44 | INFO | train_inner | epoch 040:      4 / 64 loss=8.23, ppl=300.2, wps=5929.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.497, train_wall=494, gb_free=6.1, wall=13449
2022-02-02 10:00:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:01:08 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.232 | ppl 601.27 | wps 8217.3 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 10:01:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 10:01:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt
2022-02-02 10:01:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt
2022-02-02 10:01:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.232) (writing took 4.915129384957254 seconds)
2022-02-02 10:01:13 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 10:01:13 | INFO | train | epoch 040 | loss 8.14 | ppl 282 | wps 5981.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.491 | train_wall 316 | gb_free 6.1 | wall 13778
KL Stats: Epoch 40 Divergences: Uniform: 2.339286724726359 Unigram: 2.224733274352323
2022-02-02 10:01:13 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 10:01:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:04:33 | INFO | train_inner | epoch 041:     40 / 64 loss=8.111, ppl=276.43, wps=6181.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.491, train_wall=495, gb_free=6.1, wall=13977
2022-02-02 10:06:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:06:58 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.23 | ppl 600.47 | wps 8194.7 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.23
2022-02-02 10:06:58 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:06:58 | INFO | train | epoch 041 | loss 8.075 | ppl 269.74 | wps 6059 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.497 | train_wall 316 | gb_free 6.1 | wall 14123
KL Stats: Epoch 41 Divergences: Uniform: 2.354496961797654 Unigram: 2.2502375653305426
2022-02-02 10:06:58 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:06:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:12:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:12:43 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.2 | ppl 588.29 | wps 8187.2 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.2
2022-02-02 10:12:43 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:12:43 | INFO | train | epoch 042 | loss 8.01 | ppl 257.77 | wps 6044.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.495 | train_wall 317 | gb_free 6.1 | wall 14468
KL Stats: Epoch 42 Divergences: Uniform: 2.374429449419207 Unigram: 2.2769936525816394
2022-02-02 10:12:43 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:12:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:13:44 | INFO | train_inner | epoch 043:     12 / 64 loss=8.016, ppl=258.78, wps=5916.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.495, train_wall=495, gb_free=6.1, wall=14528
2022-02-02 10:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:18:29 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.189 | ppl 583.78 | wps 8168.1 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.189
2022-02-02 10:18:29 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:18:29 | INFO | train | epoch 043 | loss 7.95 | ppl 247.31 | wps 6048 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.503 | train_wall 317 | gb_free 6.1 | wall 14813
KL Stats: Epoch 43 Divergences: Uniform: 2.3998650162684565 Unigram: 2.3033385255629892
2022-02-02 10:18:29 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:18:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:22:29 | INFO | train_inner | epoch 044:     48 / 64 loss=7.922, ppl=242.47, wps=6217.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.504, train_wall=496, gb_free=6.1, wall=15054
2022-02-02 10:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:24:15 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.199 | ppl 587.72 | wps 8161.4 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.199
2022-02-02 10:24:15 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:24:15 | INFO | train | epoch 044 | loss 7.887 | ppl 236.77 | wps 6037.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.498 | train_wall 318 | gb_free 6.1 | wall 15159
KL Stats: Epoch 44 Divergences: Uniform: 2.411983199824347 Unigram: 2.3387801496918024
2022-02-02 10:24:15 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:30:01 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.196 | ppl 586.4 | wps 8156.7 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.196
2022-02-02 10:30:01 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:30:01 | INFO | train | epoch 045 | loss 7.826 | ppl 226.98 | wps 6039.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.508 | train_wall 317 | gb_free 6.1 | wall 15505
KL Stats: Epoch 45 Divergences: Uniform: 2.4264099281520988 Unigram: 2.3603639683086395
2022-02-02 10:30:01 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:31:41 | INFO | train_inner | epoch 046:     20 / 64 loss=7.824, ppl=226.63, wps=5911.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.508, train_wall=495, gb_free=6.1, wall=15605
2022-02-02 10:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:35:46 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.194 | ppl 585.71 | wps 8185.6 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.194
2022-02-02 10:35:46 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:35:46 | INFO | train | epoch 046 | loss 7.765 | ppl 217.52 | wps 6043.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.499 | train_wall 317 | gb_free 6.1 | wall 15851
KL Stats: Epoch 46 Divergences: Uniform: 2.4470665483436633 Unigram: 2.3869179365003155
2022-02-02 10:35:46 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:35:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:40:26 | INFO | train_inner | epoch 047:     56 / 64 loss=7.733, ppl=212.72, wps=6216.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.496, train_wall=497, gb_free=6.1, wall=16131
2022-02-02 10:41:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:41:32 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.182 | ppl 580.77 | wps 8170.2 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.182
2022-02-02 10:41:32 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:41:32 | INFO | train | epoch 047 | loss 7.708 | ppl 209.06 | wps 6039.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.499 | train_wall 317 | gb_free 6.1 | wall 16197
KL Stats: Epoch 47 Divergences: Uniform: 2.4691139946923593 Unigram: 2.409645094323359
2022-02-02 10:41:32 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:41:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:47:18 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.178 | ppl 579.36 | wps 8192.4 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.178
2022-02-02 10:47:18 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:47:18 | INFO | train | epoch 048 | loss 7.65 | ppl 200.89 | wps 6039.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.504 | train_wall 318 | gb_free 6.1 | wall 16542
KL Stats: Epoch 48 Divergences: Uniform: 2.488895587057629 Unigram: 2.431140269272284
2022-02-02 10:47:18 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:47:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:49:38 | INFO | train_inner | epoch 049:     28 / 64 loss=7.635, ppl=198.75, wps=5912.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.51, train_wall=495, gb_free=6.1, wall=16682
2022-02-02 10:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:53:03 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.155 | ppl 569.99 | wps 8155.2 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.155
2022-02-02 10:53:03 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 10:53:03 | INFO | train | epoch 049 | loss 7.593 | ppl 193.11 | wps 6047.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.514 | train_wall 317 | gb_free 6.1 | wall 16888
KL Stats: Epoch 49 Divergences: Uniform: 2.510520157049986 Unigram: 2.4557097932787615
2022-02-02 10:53:03 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 10:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:58:24 | INFO | train_inner | epoch 050:     64 / 64 loss=7.567, ppl=189.56, wps=6195.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.508, train_wall=497, gb_free=6.1, wall=17209
2022-02-02 10:58:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:58:51 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.179 | ppl 579.55 | wps 8153.4 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.179
2022-02-02 10:58:51 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 10:58:51 | INFO | train | epoch 050 | loss 7.54 | ppl 186.15 | wps 6009.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.511 | train_wall 319 | gb_free 6.1 | wall 17235
KL Stats: Epoch 50 Divergences: Uniform: 2.519366051216312 Unigram: 2.471622544397421
2022-02-02 10:58:51 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 10:58:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:04:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:04:38 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.17 | ppl 576.18 | wps 8128.7 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.17
2022-02-02 11:04:38 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 11:04:38 | INFO | train | epoch 051 | loss 7.485 | ppl 179.17 | wps 6013.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.511 | train_wall 319 | gb_free 6.1 | wall 17583
KL Stats: Epoch 51 Divergences: Uniform: 2.540298939386157 Unigram: 2.5024366823239586
2022-02-02 11:04:38 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 11:04:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:07:39 | INFO | train_inner | epoch 052:     36 / 64 loss=7.461, ppl=176.25, wps=5888.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.513, train_wall=499, gb_free=6.1, wall=17764
2022-02-02 11:09:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:10:25 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.187 | ppl 582.67 | wps 8169.5 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.187
2022-02-02 11:10:25 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:10:25 | INFO | train | epoch 052 | loss 7.433 | ppl 172.81 | wps 6018.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.513 | train_wall 319 | gb_free 6.1 | wall 17930
KL Stats: Epoch 52 Divergences: Uniform: 2.558188459050957 Unigram: 2.517902986875281
2022-02-02 11:10:25 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:10:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:15:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:16:12 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.177 | ppl 579.03 | wps 8118.6 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.177
2022-02-02 11:16:12 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:16:12 | INFO | train | epoch 053 | loss 7.381 | ppl 166.74 | wps 6012.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.515 | train_wall 319 | gb_free 6.1 | wall 18277
KL Stats: Epoch 53 Divergences: Uniform: 2.569048540569971 Unigram: 2.541568232492717
2022-02-02 11:16:12 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:16:53 | INFO | train_inner | epoch 054:      8 / 64 loss=7.393, ppl=168.11, wps=5886.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.514, train_wall=497, gb_free=6.1, wall=18317
2022-02-02 11:21:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:22:00 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.163 | ppl 573.13 | wps 8130 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.163
2022-02-02 11:22:00 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:22:00 | INFO | train | epoch 054 | loss 7.331 | ppl 160.98 | wps 6007.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.518 | train_wall 319 | gb_free 6.1 | wall 18625
KL Stats: Epoch 54 Divergences: Uniform: 2.581857868792267 Unigram: 2.565133560619193
2022-02-02 11:22:00 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:25:41 | INFO | train_inner | epoch 055:     44 / 64 loss=7.3, ppl=157.59, wps=6181.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.514, train_wall=499, gb_free=6.1, wall=18846
2022-02-02 11:27:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:27:48 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.199 | ppl 587.89 | wps 8142.3 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.199
2022-02-02 11:27:48 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:27:48 | INFO | train | epoch 055 | loss 7.28 | ppl 155.37 | wps 6009.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.508 | train_wall 319 | gb_free 6.1 | wall 18972
KL Stats: Epoch 55 Divergences: Uniform: 2.6010973532888766 Unigram: 2.585105742764801
2022-02-02 11:27:48 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:33:35 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.194 | ppl 585.59 | wps 8173 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.194
2022-02-02 11:33:35 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:33:35 | INFO | train | epoch 056 | loss 7.233 | ppl 150.44 | wps 6021.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.53 | train_wall 318 | gb_free 6.1 | wall 19319
KL Stats: Epoch 56 Divergences: Uniform: 2.613506553334974 Unigram: 2.603840175862319
2022-02-02 11:33:35 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:34:55 | INFO | train_inner | epoch 057:     16 / 64 loss=7.24, ppl=151.15, wps=5893.8, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.524, train_wall=497, gb_free=6.1, wall=19399
2022-02-02 11:38:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:39:20 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.181 | ppl 580.42 | wps 8194.2 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.181
2022-02-02 11:39:20 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:39:20 | INFO | train | epoch 057 | loss 7.186 | ppl 145.66 | wps 6049.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.527 | train_wall 317 | gb_free 6.1 | wall 19664
KL Stats: Epoch 57 Divergences: Uniform: 2.6298363300836516 Unigram: 2.623621466950316
2022-02-02 11:39:20 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:39:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:43:40 | INFO | train_inner | epoch 058:     52 / 64 loss=7.163, ppl=143.28, wps=6225.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.531, train_wall=496, gb_free=6.1, wall=19924
2022-02-02 11:44:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:45:05 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.23 | ppl 600.63 | wps 8203.1 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.23
2022-02-02 11:45:05 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:45:05 | INFO | train | epoch 058 | loss 7.139 | ppl 140.91 | wps 6051.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.536 | train_wall 317 | gb_free 6.1 | wall 20010
KL Stats: Epoch 58 Divergences: Uniform: 2.6424655488899322 Unigram: 2.6400424205510817
2022-02-02 11:45:05 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:45:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:50:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:50:50 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.228 | ppl 599.82 | wps 8206.6 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.228
2022-02-02 11:50:50 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 11:50:50 | INFO | train | epoch 059 | loss 7.094 | ppl 136.61 | wps 6047.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.546 | train_wall 317 | gb_free 6.1 | wall 20355
KL Stats: Epoch 59 Divergences: Uniform: 2.664349787826809 Unigram: 2.657658149653205
2022-02-02 11:50:50 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 11:50:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:52:50 | INFO | train_inner | epoch 060:     24 / 64 loss=7.084, ppl=135.67, wps=5919.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.535, train_wall=495, gb_free=6.1, wall=20475
2022-02-02 11:56:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:56:36 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.253 | ppl 610.33 | wps 8163.5 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.232
2022-02-02 11:56:36 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 11:56:36 | INFO | train | epoch 060 | loss 7.048 | ppl 132.32 | wps 6044.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.529 | train_wall 317 | gb_free 6.1 | wall 20700
KL Stats: Epoch 60 Divergences: Uniform: 2.664865477054425 Unigram: 2.679306304248449
2022-02-02 11:56:36 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 11:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:01:36 | INFO | train_inner | epoch 061:     60 / 64 loss=7.03, ppl=130.73, wps=6214.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.545, train_wall=497, gb_free=6.1, wall=21001
2022-02-02 12:01:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:02:22 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.186 | ppl 582.44 | wps 8173.5 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.186
2022-02-02 12:02:22 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 12:02:22 | INFO | train | epoch 061 | loss 7.004 | ppl 128.39 | wps 6039.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.551 | train_wall 317 | gb_free 6.1 | wall 21046
KL Stats: Epoch 61 Divergences: Uniform: 2.678901767180435 Unigram: 2.6981892231248295
2022-02-02 12:02:22 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 12:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:07:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 12:08:07 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.244 | ppl 606.32 | wps 8209.3 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.232
2022-02-02 12:08:07 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:08:07 | INFO | train | epoch 062 | loss 6.962 | ppl 124.64 | wps 6050.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.553 | train_wall 317 | gb_free 6.1 | wall 21392
KL Stats: Epoch 62 Divergences: Uniform: 2.698312411454324 Unigram: 2.7202111243990013
2022-02-02 12:08:07 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:08:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:10:47 | INFO | train_inner | epoch 063:     32 / 64 loss=6.938, ppl=122.59, wps=5917.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.551, train_wall=495, gb_free=6.1, wall=21552
2022-02-02 12:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:13:52 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.241 | ppl 604.94 | wps 8200.6 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.232
2022-02-02 12:13:52 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:13:52 | INFO | train | epoch 063 | loss 6.917 | ppl 120.84 | wps 6044.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.541 | train_wall 317 | gb_free 6.1 | wall 21737
KL Stats: Epoch 63 Divergences: Uniform: 2.716301916548267 Unigram: 2.7345301399112434
2022-02-02 12:13:52 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:13:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:19:37 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.294 | ppl 627.83 | wps 8192.3 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.232
2022-02-02 12:19:37 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:19:37 | INFO | train | epoch 064 | loss 6.875 | ppl 117.39 | wps 6052 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.566 | train_wall 317 | gb_free 6.1 | wall 22082
KL Stats: Epoch 64 Divergences: Uniform: 2.723115810753238 Unigram: 2.756221401389842
2022-02-02 12:19:37 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:19:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:19:58 | INFO | train_inner | epoch 065:      4 / 64 loss=6.896, ppl=119.12, wps=5920, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.557, train_wall=495, gb_free=6.1, wall=22102
2022-02-02 12:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:25:23 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.335 | ppl 645.83 | wps 8163.1 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.232
2022-02-02 12:25:23 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:25:23 | INFO | train | epoch 065 | loss 6.831 | ppl 113.86 | wps 6039.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.555 | train_wall 317 | gb_free 6.1 | wall 22428
KL Stats: Epoch 65 Divergences: Uniform: 2.737646705565641 Unigram: 2.774107440439691
2022-02-02 12:25:23 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:28:44 | INFO | train_inner | epoch 066:     40 / 64 loss=6.807, ppl=111.98, wps=6213, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.553, train_wall=497, gb_free=6.1, wall=22628
2022-02-02 12:30:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:31:09 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.373 | ppl 663.1 | wps 8184.5 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.232
2022-02-02 12:31:09 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:31:09 | INFO | train | epoch 066 | loss 6.791 | ppl 110.7 | wps 6035.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.557 | train_wall 318 | gb_free 6.1 | wall 22774
KL Stats: Epoch 66 Divergences: Uniform: 2.7398714401221413 Unigram: 2.7868479252708154
2022-02-02 12:31:09 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:31:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:36:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:36:55 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.301 | ppl 630.81 | wps 8158.4 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.232
2022-02-02 12:36:55 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:36:55 | INFO | train | epoch 067 | loss 6.749 | ppl 107.6 | wps 6046.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.566 | train_wall 317 | gb_free 6.1 | wall 23119
KL Stats: Epoch 67 Divergences: Uniform: 2.766313309675844 Unigram: 2.8126772072280293
2022-02-02 12:36:55 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:37:55 | INFO | train_inner | epoch 068:     12 / 64 loss=6.76, ppl=108.42, wps=5912.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.569, train_wall=495, gb_free=6.1, wall=23180
2022-02-02 12:42:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:42:41 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.345 | ppl 650.47 | wps 8160.4 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.232
2022-02-02 12:42:41 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:42:41 | INFO | train | epoch 068 | loss 6.711 | ppl 104.73 | wps 6028.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.563 | train_wall 318 | gb_free 6.1 | wall 23466
KL Stats: Epoch 68 Divergences: Uniform: 2.770221429986526 Unigram: 2.82044375350197
2022-02-02 12:42:41 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:42:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:46:42 | INFO | train_inner | epoch 069:     48 / 64 loss=6.687, ppl=103.06, wps=6204.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.566, train_wall=497, gb_free=6.1, wall=23706
2022-02-02 12:48:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:48:27 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.33 | ppl 643.57 | wps 8197.4 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.232
2022-02-02 12:48:27 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 12:48:27 | INFO | train | epoch 069 | loss 6.674 | ppl 102.12 | wps 6037.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.573 | train_wall 318 | gb_free 6.1 | wall 23812
KL Stats: Epoch 69 Divergences: Uniform: 2.7908506326764306 Unigram: 2.8514522553760107
2022-02-02 12:48:27 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 12:48:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:53:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:54:14 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.349 | ppl 652.17 | wps 8164.1 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.232
2022-02-02 12:54:14 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 12:54:14 | INFO | train | epoch 070 | loss 6.635 | ppl 99.36 | wps 6029.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.567 | train_wall 318 | gb_free 6.1 | wall 24158
KL Stats: Epoch 70 Divergences: Uniform: 2.7967332318471474 Unigram: 2.864734191022552
2022-02-02 12:54:14 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 12:54:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:55:54 | INFO | train_inner | epoch 071:     20 / 64 loss=6.633, ppl=99.25, wps=5904.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.57, train_wall=496, gb_free=6.1, wall=24259
2022-02-02 12:59:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:00:00 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.357 | ppl 655.54 | wps 8164.3 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.232
2022-02-02 13:00:00 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 13:00:00 | INFO | train | epoch 071 | loss 6.599 | ppl 96.93 | wps 6038.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.564 | train_wall 317 | gb_free 6.1 | wall 24504
KL Stats: Epoch 71 Divergences: Uniform: 2.8094766606662307 Unigram: 2.8906740513686016
2022-02-02 13:00:00 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 13:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:04:40 | INFO | train_inner | epoch 072:     56 / 64 loss=6.585, ppl=96.02, wps=6208.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.566, train_wall=497, gb_free=6.1, wall=24785
2022-02-02 13:05:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:05:46 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.33 | ppl 643.72 | wps 8174.4 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.232
2022-02-02 13:05:46 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 13:05:46 | INFO | train | epoch 072 | loss 6.565 | ppl 94.7 | wps 6032.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.573 | train_wall 318 | gb_free 6.1 | wall 24850
KL Stats: Epoch 72 Divergences: Uniform: 2.8154324067205097 Unigram: 2.8961960213267957
2022-02-02 13:05:46 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 13:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:11:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:11:31 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.376 | ppl 664.23 | wps 8195.4 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.232
2022-02-02 13:11:31 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:11:31 | INFO | train | epoch 073 | loss 6.531 | ppl 92.49 | wps 6043.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.576 | train_wall 317 | gb_free 6.1 | wall 25196
KL Stats: Epoch 73 Divergences: Uniform: 2.8189937472608 Unigram: 2.9204242712013255
2022-02-02 13:11:31 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:13:51 | INFO | train_inner | epoch 074:     28 / 64 loss=6.518, ppl=91.67, wps=5915.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.577, train_wall=495, gb_free=6.1, wall=25336
2022-02-02 13:16:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:17:16 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.387 | ppl 669.48 | wps 8187.1 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.232
2022-02-02 13:17:16 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:17:16 | INFO | train | epoch 074 | loss 6.499 | ppl 90.44 | wps 6051.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.589 | train_wall 317 | gb_free 6.1 | wall 25541
KL Stats: Epoch 74 Divergences: Uniform: 2.8349536005994556 Unigram: 2.934558519616531
2022-02-02 13:17:16 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:17:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:22:36 | INFO | train_inner | epoch 075:     64 / 64 loss=6.49, ppl=89.9, wps=6216.3, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.587, train_wall=495, gb_free=6.1, wall=25860
2022-02-02 13:22:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:23:02 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.382 | ppl 667.03 | wps 8202.2 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.232
2022-02-02 13:23:02 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:23:02 | INFO | train | epoch 075 | loss 6.467 | ppl 88.46 | wps 6038.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.582 | train_wall 318 | gb_free 6.1 | wall 25887
KL Stats: Epoch 75 Divergences: Uniform: 2.8441827408324545 Unigram: 2.9465384556355074
2022-02-02 13:23:02 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:23:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:28:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:28:48 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.414 | ppl 682.37 | wps 8231.3 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.232
2022-02-02 13:28:48 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:28:48 | INFO | train | epoch 076 | loss 6.437 | ppl 86.63 | wps 6044.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.6 | train_wall 317 | gb_free 6.1 | wall 26233
KL Stats: Epoch 76 Divergences: Uniform: 2.8584155096671235 Unigram: 2.9643411804610658
2022-02-02 13:28:48 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:31:47 | INFO | train_inner | epoch 077:     36 / 64 loss=6.416, ppl=85.41, wps=5924.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.595, train_wall=496, gb_free=6.1, wall=26412
2022-02-02 13:34:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:34:32 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.418 | ppl 684.2 | wps 8211.2 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.232
2022-02-02 13:34:32 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:34:32 | INFO | train | epoch 077 | loss 6.408 | ppl 84.92 | wps 6063.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.6 | train_wall 316 | gb_free 6.1 | wall 26577
KL Stats: Epoch 77 Divergences: Uniform: 2.862509853936173 Unigram: 2.98491346597989
2022-02-02 13:34:32 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:34:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:40:17 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.417 | ppl 683.75 | wps 8200.8 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.232
2022-02-02 13:40:17 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:40:17 | INFO | train | epoch 078 | loss 6.378 | ppl 83.17 | wps 6063.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.601 | train_wall 316 | gb_free 6.1 | wall 26921
KL Stats: Epoch 78 Divergences: Uniform: 2.8735109211548773 Unigram: 2.993588578261855
2022-02-02 13:40:17 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:40:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:40:57 | INFO | train_inner | epoch 079:      8 / 64 loss=6.388, ppl=83.75, wps=5933, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.607, train_wall=494, gb_free=6.1, wall=26961
2022-02-02 13:45:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:46:02 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.376 | ppl 664.22 | wps 8208.4 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.232
2022-02-02 13:46:02 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 13:46:02 | INFO | train | epoch 079 | loss 6.351 | ppl 81.62 | wps 6055.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.603 | train_wall 317 | gb_free 6.1 | wall 27266
KL Stats: Epoch 79 Divergences: Uniform: 2.880840815600426 Unigram: 3.0128930117678654
2022-02-02 13:46:02 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 13:46:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:49:42 | INFO | train_inner | epoch 080:     44 / 64 loss=6.334, ppl=80.65, wps=6227, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.609, train_wall=496, gb_free=6.1, wall=27486
2022-02-02 13:51:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:51:47 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.424 | ppl 686.84 | wps 8202.8 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.232
2022-02-02 13:51:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 13:51:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt
2022-02-02 13:51:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt
2022-02-02 13:51:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.424) (writing took 3.14213187713176 seconds)
2022-02-02 13:51:50 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 13:51:50 | INFO | train | epoch 080 | loss 6.323 | ppl 80.07 | wps 5994.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.619 | train_wall 317 | gb_free 6.1 | wall 27615
KL Stats: Epoch 80 Divergences: Uniform: 2.8895744576858404 Unigram: 3.034613179250447
2022-02-02 13:51:50 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 13:51:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:57:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:57:36 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.441 | ppl 695.1 | wps 8181.4 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.232
2022-02-02 13:57:36 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 13:57:36 | INFO | train | epoch 081 | loss 6.296 | ppl 78.57 | wps 6035.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.613 | train_wall 318 | gb_free 6.1 | wall 27961
KL Stats: Epoch 81 Divergences: Uniform: 2.903866805767833 Unigram: 3.0448937456289293
2022-02-02 13:57:36 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 13:57:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:58:56 | INFO | train_inner | epoch 082:     16 / 64 loss=6.301, ppl=78.87, wps=5877, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.613, train_wall=496, gb_free=6.1, wall=28041
2022-02-02 14:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:03:22 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.485 | ppl 716.37 | wps 8194.5 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.232
2022-02-02 14:03:22 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 14:03:22 | INFO | train | epoch 082 | loss 6.27 | ppl 77.19 | wps 6040.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.614 | train_wall 317 | gb_free 6.1 | wall 28307
KL Stats: Epoch 82 Divergences: Uniform: 2.9040142459124394 Unigram: 3.059938159456689
2022-02-02 14:03:22 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 14:03:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:07:42 | INFO | train_inner | epoch 083:     52 / 64 loss=6.256, ppl=76.42, wps=6220, ups=0.19, wpb=32686.1, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.619, train_wall=496, gb_free=6.1, wall=28566
2022-02-02 14:08:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:09:07 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.496 | ppl 722.15 | wps 8203.8 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.232
2022-02-02 14:09:07 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:09:07 | INFO | train | epoch 083 | loss 6.244 | ppl 75.79 | wps 6049.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.627 | train_wall 317 | gb_free 6.1 | wall 28652
KL Stats: Epoch 83 Divergences: Uniform: 2.913725297185404 Unigram: 3.0709923383557842
2022-02-02 14:09:07 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:14:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:14:53 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.474 | ppl 711.31 | wps 8171.9 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.232
2022-02-02 14:14:53 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:14:53 | INFO | train | epoch 084 | loss 6.222 | ppl 74.66 | wps 6041.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.648 | train_wall 317 | gb_free 6.1 | wall 28998
KL Stats: Epoch 84 Divergences: Uniform: 2.920557479037214 Unigram: 3.0848418019688824
2022-02-02 14:14:53 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:14:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:16:53 | INFO | train_inner | epoch 085:     24 / 64 loss=6.214, ppl=74.25, wps=5914.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.648, train_wall=495, gb_free=6.1, wall=29118
2022-02-02 14:20:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:20:38 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.508 | ppl 728.14 | wps 8181.8 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.232
2022-02-02 14:20:38 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:20:38 | INFO | train | epoch 085 | loss 6.196 | ppl 73.29 | wps 6043.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.639 | train_wall 317 | gb_free 6.1 | wall 29343
KL Stats: Epoch 85 Divergences: Uniform: 2.924701630989816 Unigram: 3.1020679498216177
2022-02-02 14:20:38 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:20:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:25:38 | INFO | train_inner | epoch 086:     60 / 64 loss=6.192, ppl=73.13, wps=6218.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.638, train_wall=496, gb_free=6.1, wall=29643
2022-02-02 14:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:26:24 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.465 | ppl 706.72 | wps 8209.3 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.232
2022-02-02 14:26:24 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:26:24 | INFO | train | epoch 086 | loss 6.173 | ppl 72.18 | wps 6047.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.64 | train_wall 317 | gb_free 6.1 | wall 29688
KL Stats: Epoch 86 Divergences: Uniform: 2.9342950266623467 Unigram: 3.1138233862291482
2022-02-02 14:26:24 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:26:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:31:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:32:10 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.532 | ppl 740.28 | wps 8192.9 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.232
2022-02-02 14:32:10 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:32:10 | INFO | train | epoch 087 | loss 6.149 | ppl 70.95 | wps 6040.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.644 | train_wall 317 | gb_free 6.1 | wall 30034
KL Stats: Epoch 87 Divergences: Uniform: 2.9387296038736412 Unigram: 3.128398265618512
2022-02-02 14:32:10 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:34:49 | INFO | train_inner | epoch 088:     32 / 64 loss=6.133, ppl=70.19, wps=5919.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.64, train_wall=495, gb_free=6.1, wall=30194
2022-02-02 14:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:37:54 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.536 | ppl 742.32 | wps 8200.1 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.232
2022-02-02 14:37:54 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:37:54 | INFO | train | epoch 088 | loss 6.128 | ppl 69.96 | wps 6060.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.642 | train_wall 316 | gb_free 6.1 | wall 30379
KL Stats: Epoch 88 Divergences: Uniform: 2.9487385291604533 Unigram: 3.136831355740428
2022-02-02 14:37:54 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:37:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 14:43:40 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.509 | ppl 728.5 | wps 8208.9 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.232
2022-02-02 14:43:40 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 14:43:40 | INFO | train | epoch 089 | loss 6.105 | ppl 68.85 | wps 6047 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.641 | train_wall 317 | gb_free 6.1 | wall 30724
KL Stats: Epoch 89 Divergences: Uniform: 2.954720506655392 Unigram: 3.1498722857599306
2022-02-02 14:43:40 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 14:43:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:44:00 | INFO | train_inner | epoch 090:      4 / 64 loss=6.122, ppl=69.65, wps=5923.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.645, train_wall=495, gb_free=6.1, wall=30744
2022-02-02 14:48:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:49:25 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.578 | ppl 764.38 | wps 8197.8 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.232
2022-02-02 14:49:25 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 14:49:25 | INFO | train | epoch 090 | loss 6.084 | ppl 67.83 | wps 6054 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.641 | train_wall 317 | gb_free 6.1 | wall 31069
KL Stats: Epoch 90 Divergences: Uniform: 2.958266311574395 Unigram: 3.1603648696430406
2022-02-02 14:49:25 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 14:49:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:52:46 | INFO | train_inner | epoch 091:     40 / 64 loss=6.063, ppl=66.87, wps=6209.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.647, train_wall=497, gb_free=6.1, wall=31271
2022-02-02 14:54:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:55:11 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.554 | ppl 751.88 | wps 8193.3 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.232
2022-02-02 14:55:11 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 14:55:11 | INFO | train | epoch 091 | loss 6.063 | ppl 66.84 | wps 6025.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.655 | train_wall 318 | gb_free 6.1 | wall 31416
KL Stats: Epoch 91 Divergences: Uniform: 2.9606722265786187 Unigram: 3.1830085137659743
2022-02-02 14:55:11 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 14:55:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:00:59 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.545 | ppl 746.89 | wps 8169 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.232
2022-02-02 15:00:59 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 15:00:59 | INFO | train | epoch 092 | loss 6.046 | ppl 66.09 | wps 6002.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.687 | train_wall 320 | gb_free 6.1 | wall 31764
KL Stats: Epoch 92 Divergences: Uniform: 2.9687531649457894 Unigram: 3.189278994144147
2022-02-02 15:00:59 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 15:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:01:59 | INFO | train_inner | epoch 093:     12 / 64 loss=6.054, ppl=66.43, wps=5891.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.676, train_wall=497, gb_free=6.1, wall=31824
2022-02-02 15:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:06:44 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.532 | ppl 740.12 | wps 8180.9 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.232
2022-02-02 15:06:44 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 15:06:44 | INFO | train | epoch 093 | loss 6.023 | ppl 65.02 | wps 6049.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.659 | train_wall 317 | gb_free 6.1 | wall 32109
KL Stats: Epoch 93 Divergences: Uniform: 2.9849490717258447 Unigram: 3.2019777118075017
2022-02-02 15:06:44 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 15:06:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:10:44 | INFO | train_inner | epoch 094:     48 / 64 loss=6.012, ppl=64.51, wps=6226.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.667, train_wall=496, gb_free=6.1, wall=32349
2022-02-02 15:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:12:29 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.63 | ppl 792.32 | wps 8164.2 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.232
2022-02-02 15:12:29 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:12:29 | INFO | train | epoch 094 | loss 6.004 | ppl 64.17 | wps 6053.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.677 | train_wall 317 | gb_free 6.1 | wall 32454
KL Stats: Epoch 94 Divergences: Uniform: 2.9789358367403507 Unigram: 3.2165215240813763
2022-02-02 15:12:29 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:17:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 15:18:14 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.563 | ppl 756.31 | wps 8219.7 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.232
2022-02-02 15:18:14 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:18:14 | INFO | train | epoch 095 | loss 5.983 | ppl 63.26 | wps 6056.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.658 | train_wall 317 | gb_free 6.1 | wall 32799
KL Stats: Epoch 95 Divergences: Uniform: 2.9912440138713974 Unigram: 3.227711906551627
2022-02-02 15:18:14 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:18:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:19:54 | INFO | train_inner | epoch 096:     20 / 64 loss=5.978, ppl=63.02, wps=5925, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.667, train_wall=494, gb_free=6.1, wall=32899
2022-02-02 15:23:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:23:59 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.635 | ppl 794.89 | wps 8206.5 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.232
2022-02-02 15:23:59 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:23:59 | INFO | train | epoch 096 | loss 5.966 | ppl 62.5 | wps 6055.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.686 | train_wall 317 | gb_free 6.1 | wall 33144
KL Stats: Epoch 96 Divergences: Uniform: 2.9886605194606517 Unigram: 3.2443216463961817
2022-02-02 15:23:59 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:23:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:28:39 | INFO | train_inner | epoch 097:     56 / 64 loss=5.969, ppl=62.62, wps=6231.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.679, train_wall=495, gb_free=6.1, wall=33423
2022-02-02 15:29:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:29:44 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.59 | ppl 770.48 | wps 8185.8 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.232
2022-02-02 15:29:44 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:29:44 | INFO | train | epoch 097 | loss 5.947 | ppl 61.69 | wps 6056.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.677 | train_wall 317 | gb_free 6.1 | wall 33489
KL Stats: Epoch 97 Divergences: Uniform: 2.99899519828495 Unigram: 3.2520551804272904
2022-02-02 15:29:44 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:29:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:35:29 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.642 | ppl 798.92 | wps 8200.2 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.232
2022-02-02 15:35:29 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:35:29 | INFO | train | epoch 098 | loss 5.929 | ppl 60.94 | wps 6059.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.691 | train_wall 316 | gb_free 6.1 | wall 33833
KL Stats: Epoch 98 Divergences: Uniform: 2.99909697550432 Unigram: 3.2663341375969805
2022-02-02 15:35:29 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:35:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:37:49 | INFO | train_inner | epoch 099:     28 / 64 loss=5.913, ppl=60.26, wps=5925.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.699, train_wall=494, gb_free=6.1, wall=33974
2022-02-02 15:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:41:14 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.636 | ppl 795.83 | wps 8209.4 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.232
2022-02-02 15:41:14 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 15:41:14 | INFO | train | epoch 099 | loss 5.912 | ppl 60.21 | wps 6046.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.698 | train_wall 317 | gb_free 6.1 | wall 34179
KL Stats: Epoch 99 Divergences: Uniform: 3.0125737270671844 Unigram: 3.279068398041774
2022-02-02 15:41:14 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 15:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:46:33 | INFO | train_inner | epoch 100:     64 / 64 loss=5.915, ppl=60.33, wps=6223.4, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.689, train_wall=495, gb_free=6.1, wall=34497
2022-02-02 15:46:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:46:59 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.585 | ppl 768.12 | wps 8173.8 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.232
2022-02-02 15:46:59 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 15:46:59 | INFO | train | epoch 100 | loss 5.895 | ppl 59.49 | wps 6051.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.692 | train_wall 317 | gb_free 6.1 | wall 34524
KL Stats: Epoch 100 Divergences: Uniform: 3.0197107431045174 Unigram: 3.2911315473301697
2022-02-02 15:46:59 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 15:46:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:52:45 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.637 | ppl 796.29 | wps 8191.3 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.232
2022-02-02 15:52:45 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 15:52:45 | INFO | train | epoch 101 | loss 5.878 | ppl 58.82 | wps 6047.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.698 | train_wall 317 | gb_free 6.1 | wall 34869
KL Stats: Epoch 101 Divergences: Uniform: 3.0144030868980654 Unigram: 3.3001726468404136
2022-02-02 15:52:45 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 15:52:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:55:45 | INFO | train_inner | epoch 102:     36 / 64 loss=5.861, ppl=58.12, wps=5914.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.705, train_wall=497, gb_free=6.1, wall=35050
2022-02-02 15:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:58:31 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.619 | ppl 786.24 | wps 8180.8 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.232
2022-02-02 15:58:31 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 15:58:31 | INFO | train | epoch 102 | loss 5.862 | ppl 58.18 | wps 6032.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.714 | train_wall 318 | gb_free 6.1 | wall 35216
KL Stats: Epoch 102 Divergences: Uniform: 3.023994308019605 Unigram: 3.3077396100963217
2022-02-02 15:58:31 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 15:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:03:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:04:17 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.647 | ppl 801.66 | wps 8173.3 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.232
2022-02-02 16:04:17 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 16:04:17 | INFO | train | epoch 103 | loss 5.847 | ppl 57.56 | wps 6042.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.728 | train_wall 317 | gb_free 6.1 | wall 35561
KL Stats: Epoch 103 Divergences: Uniform: 3.029078887083559 Unigram: 3.3186153809970294
2022-02-02 16:04:17 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 16:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:04:57 | INFO | train_inner | epoch 104:      8 / 64 loss=5.855, ppl=57.88, wps=5912, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.722, train_wall=495, gb_free=6.1, wall=35601
2022-02-02 16:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:10:02 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.669 | ppl 814.04 | wps 8205.2 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.232
2022-02-02 16:10:02 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:10:02 | INFO | train | epoch 104 | loss 5.831 | ppl 56.93 | wps 6048.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.734 | train_wall 317 | gb_free 6.1 | wall 35907
KL Stats: Epoch 104 Divergences: Uniform: 3.0270360859034064 Unigram: 3.331126118997336
2022-02-02 16:10:02 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:13:42 | INFO | train_inner | epoch 105:     44 / 64 loss=5.821, ppl=56.53, wps=6220.4, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.734, train_wall=496, gb_free=6.1, wall=36127
2022-02-02 16:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:15:47 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.659 | ppl 808.29 | wps 8195.9 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.232
2022-02-02 16:15:47 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:15:47 | INFO | train | epoch 105 | loss 5.817 | ppl 56.36 | wps 6044.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.732 | train_wall 317 | gb_free 6.1 | wall 36252
KL Stats: Epoch 105 Divergences: Uniform: 3.0356220613836027 Unigram: 3.339916417612481
2022-02-02 16:15:47 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:15:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:21:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:21:33 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.649 | ppl 802.94 | wps 8187 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.232
2022-02-02 16:21:33 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:21:33 | INFO | train | epoch 106 | loss 5.799 | ppl 55.68 | wps 6044.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.723 | train_wall 317 | gb_free 6.1 | wall 36598
KL Stats: Epoch 106 Divergences: Uniform: 3.037862236320946 Unigram: 3.3518090891510024
2022-02-02 16:21:33 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:21:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:22:53 | INFO | train_inner | epoch 107:     16 / 64 loss=5.806, ppl=55.96, wps=5916.4, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.729, train_wall=495, gb_free=6.1, wall=36678
2022-02-02 16:26:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:27:18 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.659 | ppl 808.37 | wps 8184.7 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.232
2022-02-02 16:27:18 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:27:18 | INFO | train | epoch 107 | loss 5.784 | ppl 55.11 | wps 6052.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.739 | train_wall 317 | gb_free 6.1 | wall 36943
KL Stats: Epoch 107 Divergences: Uniform: 3.044807242013802 Unigram: 3.3632085943454855
2022-02-02 16:27:18 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:27:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:31:38 | INFO | train_inner | epoch 108:     52 / 64 loss=5.776, ppl=54.8, wps=6228.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.749, train_wall=495, gb_free=6.1, wall=37202
2022-02-02 16:32:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:33:03 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.682 | ppl 821.34 | wps 8208.9 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.232
2022-02-02 16:33:03 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:33:03 | INFO | train | epoch 108 | loss 5.771 | ppl 54.6 | wps 6059.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.751 | train_wall 316 | gb_free 6.1 | wall 37287
KL Stats: Epoch 108 Divergences: Uniform: 3.0498018203393333 Unigram: 3.3702291153401096
2022-02-02 16:33:03 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:33:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:38:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:38:48 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.675 | ppl 817.32 | wps 8206.1 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.232
2022-02-02 16:38:48 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 16:38:48 | INFO | train | epoch 109 | loss 5.757 | ppl 54.07 | wps 6048.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.729 | train_wall 317 | gb_free 6.1 | wall 37633
KL Stats: Epoch 109 Divergences: Uniform: 3.0605108897737856 Unigram: 3.3821718945695833
2022-02-02 16:38:48 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 16:38:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:40:48 | INFO | train_inner | epoch 110:     24 / 64 loss=5.748, ppl=53.76, wps=5921.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.735, train_wall=495, gb_free=6.1, wall=37753
2022-02-02 16:44:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:44:33 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.696 | ppl 829.27 | wps 8206.5 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.232
2022-02-02 16:44:33 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 16:44:33 | INFO | train | epoch 110 | loss 5.741 | ppl 53.48 | wps 6050.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.754 | train_wall 317 | gb_free 6.1 | wall 37978
KL Stats: Epoch 110 Divergences: Uniform: 3.053136108718445 Unigram: 3.394504077266282
2022-02-02 16:44:33 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 16:44:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:49:33 | INFO | train_inner | epoch 111:     60 / 64 loss=5.742, ppl=53.51, wps=6226, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.758, train_wall=496, gb_free=6.1, wall=38278
2022-02-02 16:49:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:50:18 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.755 | ppl 864.02 | wps 8220.3 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.232
2022-02-02 16:50:18 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 16:50:18 | INFO | train | epoch 111 | loss 5.73 | ppl 53.06 | wps 6053.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.762 | train_wall 317 | gb_free 6.1 | wall 38323
KL Stats: Epoch 111 Divergences: Uniform: 3.0585778651637496 Unigram: 3.4039120966203997
2022-02-02 16:50:18 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 16:50:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:56:03 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.719 | ppl 842.9 | wps 8181.7 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.232
2022-02-02 16:56:03 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 16:56:03 | INFO | train | epoch 112 | loss 5.715 | ppl 52.52 | wps 6052.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.757 | train_wall 317 | gb_free 6.1 | wall 38668
KL Stats: Epoch 112 Divergences: Uniform: 3.0609990467879173 Unigram: 3.410503035273173
2022-02-02 16:56:03 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 16:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:58:44 | INFO | train_inner | epoch 113:     32 / 64 loss=5.702, ppl=52.06, wps=5922, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.759, train_wall=495, gb_free=6.1, wall=38828
2022-02-02 17:01:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:01:49 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.752 | ppl 862.36 | wps 8186.6 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.232
2022-02-02 17:01:49 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 17:01:49 | INFO | train | epoch 113 | loss 5.703 | ppl 52.08 | wps 6043.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.777 | train_wall 317 | gb_free 6.1 | wall 39014
KL Stats: Epoch 113 Divergences: Uniform: 3.0620876687714857 Unigram: 3.4233757805094105
2022-02-02 17:01:49 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 17:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:07:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:07:35 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.738 | ppl 853.75 | wps 8220.8 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.232
2022-02-02 17:07:35 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 17:07:35 | INFO | train | epoch 114 | loss 5.691 | ppl 51.66 | wps 6039.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.785 | train_wall 318 | gb_free 6.1 | wall 39360
KL Stats: Epoch 114 Divergences: Uniform: 3.0642410035774645 Unigram: 3.423949386403659
2022-02-02 17:07:35 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 17:07:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:07:55 | INFO | train_inner | epoch 115:      4 / 64 loss=5.705, ppl=52.18, wps=5913, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.784, train_wall=495, gb_free=6.1, wall=39380
2022-02-02 17:12:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:13:20 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.767 | ppl 871.51 | wps 8171.9 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.232
2022-02-02 17:13:20 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:13:20 | INFO | train | epoch 115 | loss 5.676 | ppl 51.14 | wps 6046.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.771 | train_wall 317 | gb_free 6.1 | wall 39705
KL Stats: Epoch 115 Divergences: Uniform: 3.0709569171646462 Unigram: 3.440893466558342
2022-02-02 17:13:20 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:16:41 | INFO | train_inner | epoch 116:     40 / 64 loss=5.662, ppl=50.64, wps=6214.8, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.777, train_wall=497, gb_free=6.1, wall=39905
2022-02-02 17:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:19:06 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.756 | ppl 864.64 | wps 8181.6 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.232
2022-02-02 17:19:06 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:19:06 | INFO | train | epoch 116 | loss 5.665 | ppl 50.73 | wps 6035.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.788 | train_wall 318 | gb_free 6.1 | wall 40051
KL Stats: Epoch 116 Divergences: Uniform: 3.0766382636465184 Unigram: 3.446583256211431
2022-02-02 17:19:06 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:19:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:24:53 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.724 | ppl 845.64 | wps 8196.4 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.232
2022-02-02 17:24:53 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:24:53 | INFO | train | epoch 117 | loss 5.653 | ppl 50.31 | wps 6033.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.793 | train_wall 318 | gb_free 6.1 | wall 40397
KL Stats: Epoch 117 Divergences: Uniform: 3.07776982065735 Unigram: 3.456432113317294
2022-02-02 17:24:53 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:24:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:25:53 | INFO | train_inner | epoch 118:     12 / 64 loss=5.658, ppl=50.49, wps=5907.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.791, train_wall=496, gb_free=6.1, wall=40457
2022-02-02 17:30:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:30:38 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.74 | ppl 855.23 | wps 8218.2 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.232
2022-02-02 17:30:38 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:30:38 | INFO | train | epoch 118 | loss 5.639 | ppl 49.83 | wps 6045.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.779 | train_wall 317 | gb_free 6.1 | wall 40743
KL Stats: Epoch 118 Divergences: Uniform: 3.093176144999078 Unigram: 3.46520910102211
2022-02-02 17:30:38 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:30:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:34:38 | INFO | train_inner | epoch 119:     48 / 64 loss=5.633, ppl=49.63, wps=6217.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.796, train_wall=496, gb_free=6.1, wall=40983
2022-02-02 17:35:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:36:24 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.765 | ppl 869.79 | wps 8152.9 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.232
2022-02-02 17:36:24 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 17:36:24 | INFO | train | epoch 119 | loss 5.629 | ppl 49.49 | wps 6038.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.804 | train_wall 317 | gb_free 6.1 | wall 41089
KL Stats: Epoch 119 Divergences: Uniform: 3.087969246621773 Unigram: 3.4751002817115832
2022-02-02 17:36:24 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 17:36:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:42:10 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.771 | ppl 873.92 | wps 8180.8 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.232
2022-02-02 17:42:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 17:42:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt
2022-02-02 17:42:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt
2022-02-02 17:42:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.771) (writing took 2.9871855909004807 seconds)
2022-02-02 17:42:13 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 17:42:13 | INFO | train | epoch 120 | loss 5.616 | ppl 49.03 | wps 5978.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.813 | train_wall 318 | gb_free 6.1 | wall 41438
KL Stats: Epoch 120 Divergences: Uniform: 3.086263591323595 Unigram: 3.4838967230179234
2022-02-02 17:42:13 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 17:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:43:53 | INFO | train_inner | epoch 121:     20 / 64 loss=5.617, ppl=49.09, wps=5873.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.806, train_wall=496, gb_free=6.1, wall=41538
2022-02-02 17:47:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:47:59 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.775 | ppl 876.13 | wps 8176.7 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.232
2022-02-02 17:47:59 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 17:47:59 | INFO | train | epoch 121 | loss 5.604 | ppl 48.64 | wps 6043.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.81 | train_wall 317 | gb_free 6.1 | wall 41783
KL Stats: Epoch 121 Divergences: Uniform: 3.089027172821763 Unigram: 3.4889615913311536
2022-02-02 17:47:59 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 17:47:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:52:39 | INFO | train_inner | epoch 122:     56 / 64 loss=5.6, ppl=48.51, wps=6213.7, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.813, train_wall=497, gb_free=6.1, wall=42064
2022-02-02 17:53:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:53:45 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.751 | ppl 861.59 | wps 8186.4 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.232
2022-02-02 17:53:45 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 17:53:45 | INFO | train | epoch 122 | loss 5.594 | ppl 48.29 | wps 6039.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.814 | train_wall 318 | gb_free 6.1 | wall 42129
KL Stats: Epoch 122 Divergences: Uniform: 3.08613996425312 Unigram: 3.495267424327344
2022-02-02 17:53:45 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 17:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:59:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:59:30 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 9.79 | ppl 885.34 | wps 8176.9 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.232
2022-02-02 17:59:30 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 17:59:30 | INFO | train | epoch 123 | loss 5.583 | ppl 47.94 | wps 6043.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.828 | train_wall 317 | gb_free 6.1 | wall 42475
KL Stats: Epoch 123 Divergences: Uniform: 3.0909521209362927 Unigram: 3.5081549954319127
2022-02-02 17:59:30 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 17:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:01:50 | INFO | train_inner | epoch 124:     28 / 64 loss=5.576, ppl=47.71, wps=5916.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.82, train_wall=495, gb_free=6.1, wall=42615
2022-02-02 18:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:05:15 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.791 | ppl 885.65 | wps 8194.7 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.232
2022-02-02 18:05:15 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 18:05:15 | INFO | train | epoch 124 | loss 5.574 | ppl 47.62 | wps 6050.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.814 | train_wall 317 | gb_free 6.1 | wall 42820
KL Stats: Epoch 124 Divergences: Uniform: 3.095706304972615 Unigram: 3.5146868223621217
2022-02-02 18:05:15 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 18:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:10:34 | INFO | train_inner | epoch 125:     64 / 64 loss=5.576, ppl=47.7, wps=6223.1, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.837, train_wall=495, gb_free=6.1, wall=43139
2022-02-02 18:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:11:01 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.837 | ppl 914.54 | wps 8189.6 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.232
2022-02-02 18:11:01 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:11:01 | INFO | train | epoch 125 | loss 5.562 | ppl 47.23 | wps 6050.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.844 | train_wall 317 | gb_free 6.1 | wall 43165
KL Stats: Epoch 125 Divergences: Uniform: 3.0962104534922945 Unigram: 3.525363623169968
2022-02-02 18:11:01 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:16:47 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.802 | ppl 892.9 | wps 8164.6 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.232
2022-02-02 18:16:47 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:16:47 | INFO | train | epoch 126 | loss 5.549 | ppl 46.82 | wps 6036.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.827 | train_wall 318 | gb_free 6.1 | wall 43511
KL Stats: Epoch 126 Divergences: Uniform: 3.1000654537625913 Unigram: 3.5321634618959794
2022-02-02 18:16:47 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:19:47 | INFO | train_inner | epoch 127:     36 / 64 loss=5.532, ppl=46.27, wps=5911.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.821, train_wall=497, gb_free=6.1, wall=43691
2022-02-02 18:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:22:32 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.81 | ppl 897.71 | wps 8180.4 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.232
2022-02-02 18:22:32 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:22:32 | INFO | train | epoch 127 | loss 5.537 | ppl 46.44 | wps 6042 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.817 | train_wall 317 | gb_free 6.1 | wall 43857
KL Stats: Epoch 127 Divergences: Uniform: 3.1085508344864454 Unigram: 3.54335436374412
2022-02-02 18:22:32 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:27:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 18:28:18 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.858 | ppl 928.03 | wps 8193.1 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.232
2022-02-02 18:28:18 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:28:18 | INFO | train | epoch 128 | loss 5.529 | ppl 46.17 | wps 6045.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.842 | train_wall 317 | gb_free 6.1 | wall 44202
KL Stats: Epoch 128 Divergences: Uniform: 3.1063347125233305 Unigram: 3.5432869415520245
2022-02-02 18:28:18 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:28:58 | INFO | train_inner | epoch 129:      8 / 64 loss=5.538, ppl=46.48, wps=5915.8, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.84, train_wall=495, gb_free=6.1, wall=44243
2022-02-02 18:33:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:34:04 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.821 | ppl 904.73 | wps 8173.2 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.232
2022-02-02 18:34:04 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 18:34:04 | INFO | train | epoch 129 | loss 5.522 | ppl 45.95 | wps 6038.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.875 | train_wall 318 | gb_free 6.1 | wall 44548
KL Stats: Epoch 129 Divergences: Uniform: 3.108201402798791 Unigram: 3.5534303106840484
2022-02-02 18:34:04 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 18:34:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:37:44 | INFO | train_inner | epoch 130:     44 / 64 loss=5.513, ppl=45.66, wps=6214, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.859, train_wall=497, gb_free=6.1, wall=44768
2022-02-02 18:39:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:39:49 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.817 | ppl 902.26 | wps 8166.9 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.232
2022-02-02 18:39:49 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 18:39:49 | INFO | train | epoch 130 | loss 5.508 | ppl 45.5 | wps 6043 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.853 | train_wall 317 | gb_free 6.1 | wall 44894
KL Stats: Epoch 130 Divergences: Uniform: 3.1111196047244896 Unigram: 3.5644848119191366
2022-02-02 18:39:49 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 18:39:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:45:35 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.861 | ppl 930.03 | wps 8179.9 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.232
2022-02-02 18:45:35 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 18:45:35 | INFO | train | epoch 131 | loss 5.5 | ppl 45.25 | wps 6039.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.871 | train_wall 317 | gb_free 6.1 | wall 45240
KL Stats: Epoch 131 Divergences: Uniform: 3.11510739144462 Unigram: 3.568560290537672
2022-02-02 18:45:35 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 18:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:46:55 | INFO | train_inner | epoch 132:     16 / 64 loss=5.498, ppl=45.2, wps=5912.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.873, train_wall=495, gb_free=6.1, wall=45320
2022-02-02 18:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:51:21 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.872 | ppl 937.34 | wps 8190.4 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.232
2022-02-02 18:51:21 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 18:51:21 | INFO | train | epoch 132 | loss 5.491 | ppl 44.98 | wps 6047.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.855 | train_wall 317 | gb_free 6.1 | wall 45585
KL Stats: Epoch 132 Divergences: Uniform: 3.119380474513867 Unigram: 3.578053559931024
2022-02-02 18:51:21 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 18:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:55:41 | INFO | train_inner | epoch 133:     52 / 64 loss=5.487, ppl=44.85, wps=6218.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.857, train_wall=496, gb_free=6.1, wall=45845
2022-02-02 18:56:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:57:06 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.871 | ppl 936.56 | wps 8162.3 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.232
2022-02-02 18:57:06 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 18:57:06 | INFO | train | epoch 133 | loss 5.481 | ppl 44.66 | wps 6039.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.865 | train_wall 317 | gb_free 6.1 | wall 45931
KL Stats: Epoch 133 Divergences: Uniform: 3.1136993760804414 Unigram: 3.5828875501686026
2022-02-02 18:57:06 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 18:57:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:02:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:02:52 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.868 | ppl 934.75 | wps 8216.8 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.232
2022-02-02 19:02:52 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 19:02:52 | INFO | train | epoch 134 | loss 5.472 | ppl 44.39 | wps 6050.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.88 | train_wall 317 | gb_free 6.1 | wall 46276
KL Stats: Epoch 134 Divergences: Uniform: 3.1172342598835097 Unigram: 3.5909046123570674
2022-02-02 19:02:52 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 19:02:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:04:51 | INFO | train_inner | epoch 135:     24 / 64 loss=5.469, ppl=44.28, wps=5919.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.881, train_wall=495, gb_free=6.1, wall=46396
2022-02-02 19:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:08:37 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.859 | ppl 928.77 | wps 8173.9 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.232
2022-02-02 19:08:37 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 19:08:37 | INFO | train | epoch 135 | loss 5.462 | ppl 44.09 | wps 6048.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.908 | train_wall 317 | gb_free 6.1 | wall 46622
KL Stats: Epoch 135 Divergences: Uniform: 3.1202229109542716 Unigram: 3.593254453597257
2022-02-02 19:08:37 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 19:08:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:13:37 | INFO | train_inner | epoch 136:     60 / 64 loss=5.464, ppl=44.13, wps=6216.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.901, train_wall=496, gb_free=6.1, wall=46922
2022-02-02 19:13:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:14:23 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.896 | ppl 952.64 | wps 8176.1 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.232
2022-02-02 19:14:23 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:14:23 | INFO | train | epoch 136 | loss 5.454 | ppl 43.82 | wps 6039.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.89 | train_wall 317 | gb_free 6.1 | wall 46967
KL Stats: Epoch 136 Divergences: Uniform: 3.117141742363433 Unigram: 3.5985904574870426
2022-02-02 19:14:23 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:19:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 19:20:08 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.869 | ppl 934.87 | wps 8180.8 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.232
2022-02-02 19:20:08 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:20:08 | INFO | train | epoch 137 | loss 5.446 | ppl 43.59 | wps 6039.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.909 | train_wall 317 | gb_free 6.1 | wall 47313
KL Stats: Epoch 137 Divergences: Uniform: 3.1287364930086436 Unigram: 3.6057896965406124
2022-02-02 19:20:08 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:20:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:22:49 | INFO | train_inner | epoch 138:     32 / 64 loss=5.435, ppl=43.27, wps=5911.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.91, train_wall=495, gb_free=6.1, wall=47473
2022-02-02 19:25:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:25:54 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.874 | ppl 938.17 | wps 8165.9 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.232
2022-02-02 19:25:54 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:25:54 | INFO | train | epoch 138 | loss 5.437 | ppl 43.31 | wps 6048.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.91 | train_wall 317 | gb_free 6.1 | wall 47658
KL Stats: Epoch 138 Divergences: Uniform: 3.1235128365460363 Unigram: 3.613148677841166
2022-02-02 19:25:54 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:31:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:31:39 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.891 | ppl 949.41 | wps 8166.8 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.232
2022-02-02 19:31:39 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 19:31:39 | INFO | train | epoch 139 | loss 5.426 | ppl 43 | wps 6045.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.927 | train_wall 317 | gb_free 6.1 | wall 48004
KL Stats: Epoch 139 Divergences: Uniform: 3.1271811115757604 Unigram: 3.620941453121844
2022-02-02 19:31:39 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 19:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:31:59 | INFO | train_inner | epoch 140:      4 / 64 loss=5.438, ppl=43.34, wps=5919.3, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.923, train_wall=495, gb_free=6.1, wall=48024
2022-02-02 19:36:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:37:25 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.894 | ppl 951.65 | wps 8194.6 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.232
2022-02-02 19:37:25 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 19:37:25 | INFO | train | epoch 140 | loss 5.421 | ppl 42.86 | wps 6050.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.917 | train_wall 317 | gb_free 6.1 | wall 48349
KL Stats: Epoch 140 Divergences: Uniform: 3.1323046248275546 Unigram: 3.6296903589699885
2022-02-02 19:37:25 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 19:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:40:45 | INFO | train_inner | epoch 141:     40 / 64 loss=5.413, ppl=42.59, wps=6218.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.931, train_wall=496, gb_free=6.1, wall=48550
2022-02-02 19:42:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:43:11 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.902 | ppl 956.51 | wps 8183.3 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.232
2022-02-02 19:43:11 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 19:43:11 | INFO | train | epoch 141 | loss 5.413 | ppl 42.6 | wps 6034 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.951 | train_wall 318 | gb_free 6.1 | wall 48695
KL Stats: Epoch 141 Divergences: Uniform: 3.1337285170912796 Unigram: 3.635190470822906
2022-02-02 19:43:11 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 19:43:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:48:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:48:56 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.865 | ppl 932.26 | wps 8221 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.232
2022-02-02 19:48:56 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 19:48:56 | INFO | train | epoch 142 | loss 5.403 | ppl 42.33 | wps 6054.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.914 | train_wall 317 | gb_free 6.1 | wall 49040
KL Stats: Epoch 142 Divergences: Uniform: 3.1362389296994335 Unigram: 3.6418004282516634
2022-02-02 19:48:56 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 19:48:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:49:56 | INFO | train_inner | epoch 143:     12 / 64 loss=5.406, ppl=42.39, wps=5919.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.924, train_wall=495, gb_free=6.1, wall=49100
2022-02-02 19:54:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:54:41 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.929 | ppl 974.87 | wps 8176.3 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.232
2022-02-02 19:54:41 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 19:54:41 | INFO | train | epoch 143 | loss 5.396 | ppl 42.12 | wps 6044.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.943 | train_wall 317 | gb_free 6.1 | wall 49386
KL Stats: Epoch 143 Divergences: Uniform: 3.129225774918246 Unigram: 3.6439080365329546
2022-02-02 19:54:41 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 19:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:58:41 | INFO | train_inner | epoch 144:     48 / 64 loss=5.393, ppl=42.01, wps=6214.6, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.939, train_wall=497, gb_free=6.1, wall=49626
2022-02-02 20:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:00:27 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.937 | ppl 979.94 | wps 8182 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.232
2022-02-02 20:00:27 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 20:00:27 | INFO | train | epoch 144 | loss 5.387 | ppl 41.86 | wps 6039.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.941 | train_wall 317 | gb_free 6.1 | wall 49732
KL Stats: Epoch 144 Divergences: Uniform: 3.1348659341408314 Unigram: 3.654124170634358
2022-02-02 20:00:27 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 20:00:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:06:12 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.922 | ppl 970.19 | wps 8208 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.232
2022-02-02 20:06:12 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 20:06:12 | INFO | train | epoch 145 | loss 5.376 | ppl 41.52 | wps 6051.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.918 | train_wall 317 | gb_free 6.1 | wall 50077
KL Stats: Epoch 145 Divergences: Uniform: 3.13575821181059 Unigram: 3.660983189338586
2022-02-02 20:06:12 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 20:06:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:07:52 | INFO | train_inner | epoch 146:     20 / 64 loss=5.374, ppl=41.48, wps=5920.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.931, train_wall=495, gb_free=6.1, wall=50177
2022-02-02 20:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:11:57 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.935 | ppl 978.75 | wps 8205.8 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.232
2022-02-02 20:11:57 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:11:57 | INFO | train | epoch 146 | loss 5.371 | ppl 41.38 | wps 6052.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.956 | train_wall 317 | gb_free 6.1 | wall 50422
KL Stats: Epoch 146 Divergences: Uniform: 3.13568194834222 Unigram: 3.670450375654726
2022-02-02 20:11:57 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:11:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:16:37 | INFO | train_inner | epoch 147:     56 / 64 loss=5.371, ppl=41.38, wps=6224.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.947, train_wall=496, gb_free=6.1, wall=50702
2022-02-02 20:17:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:17:43 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.924 | ppl 971.47 | wps 8193.5 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.232
2022-02-02 20:17:43 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:17:43 | INFO | train | epoch 147 | loss 5.363 | ppl 41.16 | wps 6048.5 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.938 | train_wall 317 | gb_free 6.1 | wall 50767
KL Stats: Epoch 147 Divergences: Uniform: 3.1437223892025665 Unigram: 3.6744336662851222
2022-02-02 20:17:43 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:17:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:23:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:23:28 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.93 | ppl 975.27 | wps 8208 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.232
2022-02-02 20:23:28 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 20:23:28 | INFO | train | epoch 148 | loss 5.358 | ppl 41.01 | wps 6048.4 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.981 | train_wall 317 | gb_free 6.1 | wall 51113
KL Stats: Epoch 148 Divergences: Uniform: 3.1439400570052918 Unigram: 3.673605050079779
2022-02-02 20:23:28 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 20:23:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:25:48 | INFO | train_inner | epoch 149:     28 / 64 loss=5.353, ppl=40.86, wps=5918.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.975, train_wall=495, gb_free=6.1, wall=51253
2022-02-02 20:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:29:13 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.973 | ppl 1004.96 | wps 8190.9 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.232
2022-02-02 20:29:13 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 20:29:13 | INFO | train | epoch 149 | loss 5.348 | ppl 40.73 | wps 6043.7 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.976 | train_wall 317 | gb_free 6.1 | wall 51458
KL Stats: Epoch 149 Divergences: Uniform: 3.1461826603623217 Unigram: 3.6855597062159577
2022-02-02 20:29:13 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 20:29:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:34:32 | INFO | train_inner | epoch 150:     64 / 64 loss=5.352, ppl=40.85, wps=6219.8, ups=0.19, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.978, train_wall=495, gb_free=6.1, wall=51777
2022-02-02 20:34:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:34:59 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.934 | ppl 978.36 | wps 8188 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.232
2022-02-02 20:34:59 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 20:34:59 | INFO | train | epoch 150 | loss 5.341 | ppl 40.54 | wps 6047.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.978 | train_wall 317 | gb_free 6.1 | wall 51803
KL Stats: Epoch 150 Divergences: Uniform: 3.146319664905614 Unigram: 3.689623131732966
2022-02-02 20:34:59 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 20:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:40:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:40:45 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.987 | ppl 1014.7 | wps 8189.4 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.232
2022-02-02 20:40:45 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 20:40:45 | INFO | train | epoch 151 | loss 5.334 | ppl 40.35 | wps 6038.9 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.996 | train_wall 318 | gb_free 6.1 | wall 52149
KL Stats: Epoch 151 Divergences: Uniform: 3.1474904738899023 Unigram: 3.6947693249092493
2022-02-02 20:40:45 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 20:40:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:43:45 | INFO | train_inner | epoch 152:     36 / 64 loss=5.319, ppl=39.93, wps=5913.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.984, train_wall=497, gb_free=6.1, wall=52330
2022-02-02 20:46:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:46:30 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.963 | ppl 998.34 | wps 8186.3 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.232
2022-02-02 20:46:30 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 20:46:30 | INFO | train | epoch 152 | loss 5.326 | ppl 40.11 | wps 6041.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.96 | train_wall 317 | gb_free 6.1 | wall 52495
KL Stats: Epoch 152 Divergences: Uniform: 3.151611878403123 Unigram: 3.7019710849773815
2022-02-02 20:46:30 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 20:46:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:52:16 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.97 | ppl 1002.83 | wps 8160.8 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.232
2022-02-02 20:52:16 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 20:52:16 | INFO | train | epoch 153 | loss 5.32 | ppl 39.95 | wps 6047 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.989 | train_wall 317 | gb_free 6.1 | wall 52840
KL Stats: Epoch 153 Divergences: Uniform: 3.150531737898595 Unigram: 3.7102250140664634
2022-02-02 20:52:16 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 20:52:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:52:56 | INFO | train_inner | epoch 154:      8 / 64 loss=5.328, ppl=40.16, wps=5915.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.979, train_wall=495, gb_free=6.1, wall=52881
2022-02-02 20:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:58:02 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.959 | ppl 995.27 | wps 8184.6 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.232
2022-02-02 20:58:02 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 20:58:02 | INFO | train | epoch 154 | loss 5.313 | ppl 39.75 | wps 6041.2 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.001 | train_wall 317 | gb_free 6.1 | wall 53186
KL Stats: Epoch 154 Divergences: Uniform: 3.150990308574502 Unigram: 3.7134454998502293
2022-02-02 20:58:02 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 20:58:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:01:42 | INFO | train_inner | epoch 155:     44 / 64 loss=5.307, ppl=39.59, wps=6215.2, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.003, train_wall=497, gb_free=6.1, wall=53406
2022-02-02 21:03:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:03:47 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.97 | ppl 1003 | wps 8185.2 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.232
2022-02-02 21:03:47 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 21:03:47 | INFO | train | epoch 155 | loss 5.307 | ppl 39.58 | wps 6043.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.001 | train_wall 317 | gb_free 6.1 | wall 53532
KL Stats: Epoch 155 Divergences: Uniform: 3.155077223983067 Unigram: 3.7176594581807185
2022-02-02 21:03:47 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 21:03:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:09:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:09:32 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.936 | ppl 979.77 | wps 8194.8 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.232
2022-02-02 21:09:32 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 21:09:32 | INFO | train | epoch 156 | loss 5.301 | ppl 39.42 | wps 6048.8 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.018 | train_wall 317 | gb_free 6.1 | wall 53877
KL Stats: Epoch 156 Divergences: Uniform: 3.159726051981588 Unigram: 3.719745385609782
2022-02-02 21:09:32 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 21:09:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:10:52 | INFO | train_inner | epoch 157:     16 / 64 loss=5.301, ppl=39.42, wps=5918.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.024, train_wall=495, gb_free=6.1, wall=53957
2022-02-02 21:14:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:15:18 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.953 | ppl 990.88 | wps 8198.1 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.232
2022-02-02 21:15:18 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:15:18 | INFO | train | epoch 157 | loss 5.291 | ppl 39.16 | wps 6048 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.01 | train_wall 317 | gb_free 6.1 | wall 54222
KL Stats: Epoch 157 Divergences: Uniform: 3.161212753519396 Unigram: 3.7292117358206434
2022-02-02 21:15:18 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:15:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:19:38 | INFO | train_inner | epoch 158:     52 / 64 loss=5.292, ppl=39.17, wps=6224.4, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.028, train_wall=496, gb_free=6.1, wall=54482
2022-02-02 21:20:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:21:03 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.991 | ppl 1017.59 | wps 8186.7 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.232
2022-02-02 21:21:03 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 21:21:03 | INFO | train | epoch 158 | loss 5.287 | ppl 39.04 | wps 6051.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.057 | train_wall 317 | gb_free 6.1 | wall 54568
KL Stats: Epoch 158 Divergences: Uniform: 3.15812009755527 Unigram: 3.7315269902818105
2022-02-02 21:21:03 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 21:21:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:26:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:26:48 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10 | ppl 1023.81 | wps 8202.1 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.232
2022-02-02 21:26:48 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 21:26:48 | INFO | train | epoch 159 | loss 5.28 | ppl 38.84 | wps 6044.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.043 | train_wall 317 | gb_free 6.1 | wall 54913
KL Stats: Epoch 159 Divergences: Uniform: 3.1635435049765595 Unigram: 3.73604023049156
2022-02-02 21:26:48 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 21:26:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:28:49 | INFO | train_inner | epoch 160:     24 / 64 loss=5.275, ppl=38.73, wps=5916, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.029, train_wall=495, gb_free=6.1, wall=55033
2022-02-02 21:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 21:32:34 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.005 | ppl 1027.21 | wps 8214.7 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.232
2022-02-02 21:32:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 21:32:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt
2022-02-02 21:32:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt
2022-02-02 21:32:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.005) (writing took 3.1683044089004397 seconds)
2022-02-02 21:32:37 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 21:32:37 | INFO | train | epoch 160 | loss 5.272 | ppl 38.64 | wps 5993.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.023 | train_wall 317 | gb_free 6.1 | wall 55262
KL Stats: Epoch 160 Divergences: Uniform: 3.158091027631899 Unigram: 3.7383337442048434
2022-02-02 21:32:37 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 21:32:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:37:37 | INFO | train_inner | epoch 161:     60 / 64 loss=5.276, ppl=38.74, wps=6185.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.055, train_wall=496, gb_free=6.1, wall=55562
2022-02-02 21:37:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:38:22 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.949 | ppl 988.5 | wps 8200.3 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.232
2022-02-02 21:38:22 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 21:38:22 | INFO | train | epoch 161 | loss 5.268 | ppl 38.52 | wps 6048.3 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.064 | train_wall 317 | gb_free 6.1 | wall 55607
KL Stats: Epoch 161 Divergences: Uniform: 3.1640368629655358 Unigram: 3.7508463408753334
2022-02-02 21:38:22 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 21:38:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:43:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:44:08 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.019 | ppl 1037.87 | wps 8171.9 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.232
2022-02-02 21:44:08 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 21:44:08 | INFO | train | epoch 162 | loss 5.263 | ppl 38.39 | wps 6044.6 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.06 | train_wall 317 | gb_free 6.1 | wall 55952
KL Stats: Epoch 162 Divergences: Uniform: 3.161451647454138 Unigram: 3.747309427180927
2022-02-02 21:44:08 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 21:44:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:46:48 | INFO | train_inner | epoch 163:     32 / 64 loss=5.252, ppl=38.11, wps=5912.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.057, train_wall=495, gb_free=6.1, wall=56113
2022-02-02 21:49:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:49:54 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.994 | ppl 1019.97 | wps 8165.6 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.232
2022-02-02 21:49:54 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 21:49:54 | INFO | train | epoch 163 | loss 5.255 | ppl 38.18 | wps 6032.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.063 | train_wall 318 | gb_free 6.1 | wall 56299
KL Stats: Epoch 163 Divergences: Uniform: 3.1653385272409142 Unigram: 3.755015727418611
2022-02-02 21:49:54 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 21:49:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:55:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:55:40 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.047 | ppl 1058.08 | wps 8147 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.232
2022-02-02 21:55:40 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 21:55:40 | INFO | train | epoch 164 | loss 5.25 | ppl 38.06 | wps 6043.1 | ups 0.19 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.076 | train_wall 317 | gb_free 6.1 | wall 56644
KL Stats: Epoch 164 Divergences: Uniform: 3.1597667457895495 Unigram: 3.757859644231614
2022-02-02 21:55:40 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 21:55:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:56:00 | INFO | train_inner | epoch 165:      4 / 64 loss=5.259, ppl=38.31, wps=5911, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.073, train_wall=495, gb_free=6.1, wall=56664
2022-02-02 22:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:01:27 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.99 | ppl 1017.04 | wps 8126.3 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.232
2022-02-02 22:01:27 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 22:01:27 | INFO | train | epoch 165 | loss 5.242 | ppl 37.84 | wps 6014.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.095 | train_wall 319 | gb_free 6.1 | wall 56992
KL Stats: Epoch 165 Divergences: Uniform: 3.173837380043094 Unigram: 3.7673808642614697
2022-02-02 22:01:27 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 22:01:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:04:48 | INFO | train_inner | epoch 166:     40 / 64 loss=5.233, ppl=37.6, wps=6189.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.116, train_wall=499, gb_free=6.1, wall=57192
2022-02-02 22:06:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:07:14 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.068 | ppl 1073.76 | wps 8146.6 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.232
2022-02-02 22:07:14 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 22:07:14 | INFO | train | epoch 166 | loss 5.238 | ppl 37.74 | wps 6020.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.129 | train_wall 318 | gb_free 6.1 | wall 57338
KL Stats: Epoch 166 Divergences: Uniform: 3.163059958658163 Unigram: 3.7682262214088356
2022-02-02 22:07:14 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 22:07:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:12:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:13:01 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.019 | ppl 1037.4 | wps 8115.5 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.232
2022-02-02 22:13:01 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:13:01 | INFO | train | epoch 167 | loss 5.232 | ppl 37.58 | wps 6013.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.077 | train_wall 319 | gb_free 6.1 | wall 57686
KL Stats: Epoch 167 Divergences: Uniform: 3.1616149473550106 Unigram: 3.7763605857498637
2022-02-02 22:13:01 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:13:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:14:01 | INFO | train_inner | epoch 168:     12 / 64 loss=5.237, ppl=37.72, wps=5887.1, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.083, train_wall=497, gb_free=6.1, wall=57746
2022-02-02 22:18:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:18:48 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.02 | ppl 1038.63 | wps 8126.7 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.232
2022-02-02 22:18:48 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 22:18:48 | INFO | train | epoch 168 | loss 5.225 | ppl 37.41 | wps 6014.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.102 | train_wall 319 | gb_free 6.1 | wall 58033
KL Stats: Epoch 168 Divergences: Uniform: 3.165521626360301 Unigram: 3.7770522924407133
2022-02-02 22:18:48 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 22:18:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:22:50 | INFO | train_inner | epoch 169:     48 / 64 loss=5.221, ppl=37.29, wps=6184.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.106, train_wall=499, gb_free=6.1, wall=58275
2022-02-02 22:24:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:24:36 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.045 | ppl 1056.8 | wps 8118.6 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.232
2022-02-02 22:24:36 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 22:24:36 | INFO | train | epoch 169 | loss 5.219 | ppl 37.25 | wps 6006.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.094 | train_wall 319 | gb_free 6.1 | wall 58381
KL Stats: Epoch 169 Divergences: Uniform: 3.1673886120927848 Unigram: 3.7841753629488886
2022-02-02 22:24:36 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 22:24:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 22:30:24 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.029 | ppl 1044.55 | wps 8111.2 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.232
2022-02-02 22:30:24 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 22:30:24 | INFO | train | epoch 170 | loss 5.214 | ppl 37.12 | wps 6002.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.083 | train_wall 319 | gb_free 6.1 | wall 58729
KL Stats: Epoch 170 Divergences: Uniform: 3.1677745606599785 Unigram: 3.790467086179067
2022-02-02 22:30:24 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 22:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:32:05 | INFO | train_inner | epoch 171:     20 / 64 loss=5.213, ppl=37.09, wps=5875, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.095, train_wall=498, gb_free=6.1, wall=58829
2022-02-02 22:35:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:36:12 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.06 | ppl 1067.21 | wps 8085.8 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.232
2022-02-02 22:36:12 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 22:36:12 | INFO | train | epoch 171 | loss 5.209 | ppl 37 | wps 5999.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.113 | train_wall 319 | gb_free 6.1 | wall 59077
KL Stats: Epoch 171 Divergences: Uniform: 3.168936115553577 Unigram: 3.79533084043121
2022-02-02 22:36:12 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 22:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:40:54 | INFO | train_inner | epoch 172:     56 / 64 loss=5.207, ppl=36.94, wps=6176.5, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.119, train_wall=500, gb_free=6.1, wall=59359
2022-02-02 22:41:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:42:00 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.035 | ppl 1048.89 | wps 8109.3 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.232
2022-02-02 22:42:00 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 22:42:00 | INFO | train | epoch 172 | loss 5.204 | ppl 36.86 | wps 6007.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.138 | train_wall 319 | gb_free 6.1 | wall 59424
KL Stats: Epoch 172 Divergences: Uniform: 3.1734582014841552 Unigram: 3.798861876414503
2022-02-02 22:42:00 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 22:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:47:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:47:47 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.036 | ppl 1050.16 | wps 8113.4 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.232
2022-02-02 22:47:47 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 22:47:47 | INFO | train | epoch 173 | loss 5.197 | ppl 36.68 | wps 6010.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.164 | train_wall 319 | gb_free 6.1 | wall 59772
KL Stats: Epoch 173 Divergences: Uniform: 3.176570573595964 Unigram: 3.801579080472456
2022-02-02 22:47:47 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 22:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:50:08 | INFO | train_inner | epoch 174:     28 / 64 loss=5.192, ppl=36.55, wps=5882.6, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.146, train_wall=498, gb_free=6.1, wall=59913
2022-02-02 22:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 22:53:35 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.008 | ppl 1029.64 | wps 8127.1 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.232
2022-02-02 22:53:35 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 22:53:35 | INFO | train | epoch 174 | loss 5.192 | ppl 36.55 | wps 6011.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.13 | train_wall 319 | gb_free 6.1 | wall 60119
KL Stats: Epoch 174 Divergences: Uniform: 3.1779854668017444 Unigram: 3.80670847789055
2022-02-02 22:53:35 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 22:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:58:55 | INFO | train_inner | epoch 175:     64 / 64 loss=5.2, ppl=36.75, wps=6184.9, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.165, train_wall=498, gb_free=6.1, wall=60440
2022-02-02 22:58:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:59:22 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.04 | ppl 1052.72 | wps 8129.8 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.232
2022-02-02 22:59:22 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 22:59:22 | INFO | train | epoch 175 | loss 5.186 | ppl 36.41 | wps 6013.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.171 | train_wall 319 | gb_free 6.1 | wall 60467
KL Stats: Epoch 175 Divergences: Uniform: 3.1795582847493624 Unigram: 3.819793555559818
2022-02-02 22:59:22 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 22:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:04:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:05:10 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.04 | ppl 1053.06 | wps 8126.6 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.232
2022-02-02 23:05:10 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 23:05:10 | INFO | train | epoch 176 | loss 5.184 | ppl 36.34 | wps 6009.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.169 | train_wall 319 | gb_free 6.1 | wall 60814
KL Stats: Epoch 176 Divergences: Uniform: 3.178567627404353 Unigram: 3.8177287533078994
2022-02-02 23:05:10 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 23:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:08:11 | INFO | train_inner | epoch 177:     36 / 64 loss=5.171, ppl=36.03, wps=5878.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.177, train_wall=500, gb_free=6.1, wall=60996
2022-02-02 23:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:10:58 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.035 | ppl 1048.8 | wps 8145.9 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.232
2022-02-02 23:10:58 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 23:10:58 | INFO | train | epoch 177 | loss 5.176 | ppl 36.14 | wps 6002.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.168 | train_wall 320 | gb_free 6.1 | wall 61162
KL Stats: Epoch 177 Divergences: Uniform: 3.1763280295182796 Unigram: 3.818039678014018
2022-02-02 23:10:58 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 23:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:16:45 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.032 | ppl 1047.3 | wps 8135.6 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.232
2022-02-02 23:16:45 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-02 23:16:45 | INFO | train | epoch 178 | loss 5.171 | ppl 36.02 | wps 6006.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.193 | train_wall 319 | gb_free 6.1 | wall 61510
KL Stats: Epoch 178 Divergences: Uniform: 3.182082268591727 Unigram: 3.8228206524465858
2022-02-02 23:16:45 | INFO | fairseq.trainer | begin training epoch 179
2022-02-02 23:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:17:26 | INFO | train_inner | epoch 179:      8 / 64 loss=5.176, ppl=36.16, wps=5878.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.181, train_wall=498, gb_free=6.1, wall=61550
2022-02-02 23:22:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:22:32 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.077 | ppl 1079.78 | wps 8164.4 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.232
2022-02-02 23:22:32 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-02 23:22:32 | INFO | train | epoch 179 | loss 5.166 | ppl 35.91 | wps 6015.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.183 | train_wall 319 | gb_free 6.1 | wall 61857
KL Stats: Epoch 179 Divergences: Uniform: 3.175181185569543 Unigram: 3.8273302032531658
2022-02-02 23:22:32 | INFO | fairseq.trainer | begin training epoch 180
2022-02-02 23:22:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:26:13 | INFO | train_inner | epoch 180:     44 / 64 loss=5.16, ppl=35.76, wps=6196.5, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.188, train_wall=498, gb_free=6.1, wall=62078
2022-02-02 23:27:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:28:19 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.079 | ppl 1081.61 | wps 8139.3 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.232
2022-02-02 23:28:19 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-02 23:28:19 | INFO | train | epoch 180 | loss 5.162 | ppl 35.81 | wps 6030.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.2 | train_wall 318 | gb_free 6.1 | wall 62204
KL Stats: Epoch 180 Divergences: Uniform: 3.1857638887125175 Unigram: 3.831692512544377
2022-02-02 23:28:19 | INFO | fairseq.trainer | begin training epoch 181
2022-02-02 23:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:34:05 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.118 | ppl 1111.58 | wps 8147.7 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.232
2022-02-02 23:34:05 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-02 23:34:05 | INFO | train | epoch 181 | loss 5.158 | ppl 35.69 | wps 6026.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.214 | train_wall 318 | gb_free 6.1 | wall 62550
KL Stats: Epoch 181 Divergences: Uniform: 3.179794970164022 Unigram: 3.8361578506202205
2022-02-02 23:34:05 | INFO | fairseq.trainer | begin training epoch 182
2022-02-02 23:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:35:26 | INFO | train_inner | epoch 182:     16 / 64 loss=5.159, ppl=35.73, wps=5899, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.214, train_wall=496, gb_free=6.1, wall=62630
2022-02-02 23:39:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:39:52 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.064 | ppl 1070.51 | wps 8150.7 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.232
2022-02-02 23:39:52 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-02 23:39:52 | INFO | train | epoch 182 | loss 5.154 | ppl 35.6 | wps 6030.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.219 | train_wall 318 | gb_free 6.1 | wall 62896
KL Stats: Epoch 182 Divergences: Uniform: 3.1907782046677426 Unigram: 3.8339811319570463
2022-02-02 23:39:52 | INFO | fairseq.trainer | begin training epoch 183
2022-02-02 23:39:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:44:12 | INFO | train_inner | epoch 183:     52 / 64 loss=5.15, ppl=35.51, wps=6204.8, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.196, train_wall=497, gb_free=6.1, wall=63157
2022-02-02 23:45:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:45:38 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.038 | ppl 1051.17 | wps 8174.4 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.232
2022-02-02 23:45:38 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-02 23:45:38 | INFO | train | epoch 183 | loss 5.146 | ppl 35.4 | wps 6031.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.187 | train_wall 318 | gb_free 6.1 | wall 63243
KL Stats: Epoch 183 Divergences: Uniform: 3.1830029696080615 Unigram: 3.844441690076683
2022-02-02 23:45:38 | INFO | fairseq.trainer | begin training epoch 184
2022-02-02 23:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:51:25 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.112 | ppl 1106.71 | wps 8133.9 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.232
2022-02-02 23:51:25 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-02 23:51:25 | INFO | train | epoch 184 | loss 5.143 | ppl 35.33 | wps 6024.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.258 | train_wall 318 | gb_free 6.1 | wall 63589
KL Stats: Epoch 184 Divergences: Uniform: 3.1879309892548595 Unigram: 3.849236958618435
2022-02-02 23:51:25 | INFO | fairseq.trainer | begin training epoch 185
2022-02-02 23:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:53:25 | INFO | train_inner | epoch 185:     24 / 64 loss=5.142, ppl=35.3, wps=5897.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.256, train_wall=497, gb_free=6.1, wall=63710
2022-02-02 23:56:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:57:11 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.103 | ppl 1099.4 | wps 8144.1 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.232
2022-02-02 23:57:11 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-02 23:57:11 | INFO | train | epoch 185 | loss 5.138 | ppl 35.22 | wps 6029 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.262 | train_wall 318 | gb_free 6.1 | wall 63936
KL Stats: Epoch 185 Divergences: Uniform: 3.183308549737909 Unigram: 3.8451794615016213
2022-02-02 23:57:11 | INFO | fairseq.trainer | begin training epoch 186
2022-02-02 23:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:02:13 | INFO | train_inner | epoch 186:     60 / 64 loss=5.139, ppl=35.23, wps=6195, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.237, train_wall=498, gb_free=6.1, wall=64237
2022-02-03 00:02:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:02:58 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.133 | ppl 1122.82 | wps 8158.3 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.232
2022-02-03 00:02:58 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-03 00:02:58 | INFO | train | epoch 186 | loss 5.131 | ppl 35.03 | wps 6018 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.227 | train_wall 319 | gb_free 6.1 | wall 64283
KL Stats: Epoch 186 Divergences: Uniform: 3.1859677496138437 Unigram: 3.856741773357298
2022-02-03 00:02:58 | INFO | fairseq.trainer | begin training epoch 187
2022-02-03 00:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:08:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:08:45 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.11 | ppl 1104.78 | wps 8134.3 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.232
2022-02-03 00:08:45 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-03 00:08:45 | INFO | train | epoch 187 | loss 5.129 | ppl 35 | wps 6024.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.263 | train_wall 318 | gb_free 6.1 | wall 64630
KL Stats: Epoch 187 Divergences: Uniform: 3.1894487272195695 Unigram: 3.8542247434430688
2022-02-03 00:08:45 | INFO | fairseq.trainer | begin training epoch 188
2022-02-03 00:08:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:11:26 | INFO | train_inner | epoch 188:     32 / 64 loss=5.121, ppl=34.79, wps=5896.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.245, train_wall=497, gb_free=6.1, wall=64790
2022-02-03 00:14:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:14:32 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.138 | ppl 1126.74 | wps 8124.2 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.232
2022-02-03 00:14:32 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 00:14:32 | INFO | train | epoch 188 | loss 5.124 | ppl 34.87 | wps 6021 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.235 | train_wall 318 | gb_free 6.1 | wall 64976
KL Stats: Epoch 188 Divergences: Uniform: 3.1828325682621874 Unigram: 3.8608352849073957
2022-02-03 00:14:32 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 00:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:19:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:20:19 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.119 | ppl 1112.09 | wps 8135.1 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.232
2022-02-03 00:20:19 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 00:20:19 | INFO | train | epoch 189 | loss 5.119 | ppl 34.76 | wps 6016.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.285 | train_wall 319 | gb_free 6.1 | wall 65324
KL Stats: Epoch 189 Divergences: Uniform: 3.1870643564504464 Unigram: 3.868637024007053
2022-02-03 00:20:19 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 00:20:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:20:39 | INFO | train_inner | epoch 190:      4 / 64 loss=5.128, ppl=34.98, wps=5889.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.276, train_wall=497, gb_free=6.1, wall=65344
2022-02-03 00:25:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:26:06 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.118 | ppl 1111.46 | wps 8172.6 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.232
2022-02-03 00:26:06 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 00:26:06 | INFO | train | epoch 190 | loss 5.114 | ppl 34.62 | wps 6023.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.298 | train_wall 318 | gb_free 6.1 | wall 65670
KL Stats: Epoch 190 Divergences: Uniform: 3.189726561374046 Unigram: 3.87208328678827
2022-02-03 00:26:06 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 00:26:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:29:26 | INFO | train_inner | epoch 191:     40 / 64 loss=5.105, ppl=34.41, wps=6199.1, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.282, train_wall=498, gb_free=6.1, wall=65871
2022-02-03 00:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:31:52 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.149 | ppl 1135.25 | wps 8132.2 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.232
2022-02-03 00:31:52 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 00:31:52 | INFO | train | epoch 191 | loss 5.11 | ppl 34.54 | wps 6029 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.272 | train_wall 318 | gb_free 6.1 | wall 66017
KL Stats: Epoch 191 Divergences: Uniform: 3.188124397094124 Unigram: 3.8736160583513026
2022-02-03 00:31:52 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 00:31:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:37:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:37:38 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.133 | ppl 1123.04 | wps 8170 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.232
2022-02-03 00:37:38 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 00:37:38 | INFO | train | epoch 192 | loss 5.108 | ppl 34.49 | wps 6032.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.309 | train_wall 318 | gb_free 6.1 | wall 66363
KL Stats: Epoch 192 Divergences: Uniform: 3.189622769290164 Unigram: 3.8721374051601583
2022-02-03 00:37:38 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 00:37:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:38:39 | INFO | train_inner | epoch 193:     12 / 64 loss=5.111, ppl=34.57, wps=5900.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.307, train_wall=496, gb_free=6.1, wall=66423
2022-02-03 00:42:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:43:25 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.129 | ppl 1119.4 | wps 8150.5 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.232
2022-02-03 00:43:25 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 00:43:25 | INFO | train | epoch 193 | loss 5.103 | ppl 34.36 | wps 6020 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.307 | train_wall 319 | gb_free 6.1 | wall 66710
KL Stats: Epoch 193 Divergences: Uniform: 3.1931165383225064 Unigram: 3.881724333900692
2022-02-03 00:43:25 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 00:43:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:47:26 | INFO | train_inner | epoch 194:     48 / 64 loss=5.101, ppl=34.32, wps=6194.3, ups=0.19, wpb=32679.4, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.306, train_wall=498, gb_free=6.1, wall=66951
2022-02-03 00:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:49:12 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.138 | ppl 1126.79 | wps 8162.3 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.232
2022-02-03 00:49:12 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 00:49:12 | INFO | train | epoch 194 | loss 5.099 | ppl 34.27 | wps 6023.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.304 | train_wall 318 | gb_free 6.1 | wall 67057
KL Stats: Epoch 194 Divergences: Uniform: 3.189460727621384 Unigram: 3.878375228859825
2022-02-03 00:49:12 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 00:49:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:54:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:54:59 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.1 | ppl 1097.24 | wps 8129.2 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.232
2022-02-03 00:54:59 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 00:54:59 | INFO | train | epoch 195 | loss 5.092 | ppl 34.1 | wps 6018.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.299 | train_wall 319 | gb_free 6.1 | wall 67404
KL Stats: Epoch 195 Divergences: Uniform: 3.1969444619461105 Unigram: 3.8880838632477794
2022-02-03 00:54:59 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 00:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:56:39 | INFO | train_inner | epoch 196:     20 / 64 loss=5.09, ppl=34.07, wps=5893.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.311, train_wall=497, gb_free=6.1, wall=67504
2022-02-03 01:00:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:00:46 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.11 | ppl 1105.28 | wps 8161.4 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.232
2022-02-03 01:00:46 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 01:00:46 | INFO | train | epoch 196 | loss 5.09 | ppl 34.07 | wps 6026.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.386 | train_wall 318 | gb_free 6.1 | wall 67750
KL Stats: Epoch 196 Divergences: Uniform: 3.1908670279168048 Unigram: 3.889422365892108
2022-02-03 01:00:46 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 01:00:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:05:26 | INFO | train_inner | epoch 197:     56 / 64 loss=5.092, ppl=34.11, wps=6202.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.362, train_wall=498, gb_free=6.1, wall=68031
2022-02-03 01:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:06:32 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.079 | ppl 1081.28 | wps 8149.7 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.232
2022-02-03 01:06:32 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 01:06:32 | INFO | train | epoch 197 | loss 5.084 | ppl 33.93 | wps 6030.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.334 | train_wall 318 | gb_free 6.1 | wall 68097
KL Stats: Epoch 197 Divergences: Uniform: 3.197723896832557 Unigram: 3.894040114288059
2022-02-03 01:06:32 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 01:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:12:19 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.181 | ppl 1161.17 | wps 8155.7 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.232
2022-02-03 01:12:19 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 01:12:19 | INFO | train | epoch 198 | loss 5.081 | ppl 33.84 | wps 6021.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.367 | train_wall 318 | gb_free 6.1 | wall 68444
KL Stats: Epoch 198 Divergences: Uniform: 3.196138985888248 Unigram: 3.900561351962371
2022-02-03 01:12:19 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 01:12:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:14:39 | INFO | train_inner | epoch 199:     28 / 64 loss=5.076, ppl=33.74, wps=5894.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.378, train_wall=497, gb_free=6.1, wall=68584
2022-02-03 01:17:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:18:06 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.126 | ppl 1117.42 | wps 8176.8 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.232
2022-02-03 01:18:06 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 01:18:06 | INFO | train | epoch 199 | loss 5.078 | ppl 33.79 | wps 6024.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.376 | train_wall 318 | gb_free 6.1 | wall 68790
KL Stats: Epoch 199 Divergences: Uniform: 3.200054582997105 Unigram: 3.9032291489815742
2022-02-03 01:18:06 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 01:18:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:23:26 | INFO | train_inner | epoch 200:     64 / 64 loss=5.081, ppl=33.85, wps=6193.6, ups=0.19, wpb=32597.5, bsz=63.7, num_updates=12800, lr=0.000279508, gnorm=1.343, train_wall=497, gb_free=6.1, wall=69110
2022-02-03 01:23:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:23:52 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 10.121 | ppl 1113.39 | wps 8149.6 | wpb 2034.1 | bsz 4 | num_updates 12800 | best_loss 9.232
2022-02-03 01:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 12800 updates
2022-02-03 01:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint200.pt
2022-02-03 01:23:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint200.pt
2022-02-03 01:23:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint200.pt (epoch 200 @ 12800 updates, score 10.121) (writing took 3.05924082826823 seconds)
2022-02-03 01:23:56 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-02-03 01:23:56 | INFO | train | epoch 200 | loss 5.071 | ppl 33.61 | wps 5967.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12800 | lr 0.000279508 | gnorm 1.34 | train_wall 319 | gb_free 6.1 | wall 69140
KL Stats: Epoch 200 Divergences: Uniform: 3.1938734418595573 Unigram: 3.902863157943678
2022-02-03 01:23:56 | INFO | fairseq.trainer | begin training epoch 201
2022-02-03 01:23:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:29:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:29:42 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 10.136 | ppl 1125.6 | wps 8152.1 | wpb 2034.1 | bsz 4 | num_updates 12864 | best_loss 9.232
2022-02-03 01:29:42 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-02-03 01:29:42 | INFO | train | epoch 201 | loss 5.068 | ppl 33.56 | wps 6023.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12864 | lr 0.000278812 | gnorm 1.361 | train_wall 318 | gb_free 6.1 | wall 69487
KL Stats: Epoch 201 Divergences: Uniform: 3.1989136635331223 Unigram: 3.905016558783032
2022-02-03 01:29:42 | INFO | fairseq.trainer | begin training epoch 202
2022-02-03 01:29:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:32:43 | INFO | train_inner | epoch 202:     36 / 64 loss=5.057, ppl=33.28, wps=5864.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12900, lr=0.000278423, gnorm=1.367, train_wall=498, gb_free=6.1, wall=69668
2022-02-03 01:35:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:35:29 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 10.123 | ppl 1115.07 | wps 8131.4 | wpb 2034.1 | bsz 4 | num_updates 12928 | best_loss 9.232
2022-02-03 01:35:29 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-02-03 01:35:29 | INFO | train | epoch 202 | loss 5.064 | ppl 33.46 | wps 6025 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12928 | lr 0.000278121 | gnorm 1.363 | train_wall 318 | gb_free 6.1 | wall 69834
KL Stats: Epoch 202 Divergences: Uniform: 3.1969486000375964 Unigram: 3.90839559366266
2022-02-03 01:35:29 | INFO | fairseq.trainer | begin training epoch 203
2022-02-03 01:35:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:40:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:41:16 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 10.14 | ppl 1128.11 | wps 8119.4 | wpb 2034.1 | bsz 4 | num_updates 12992 | best_loss 9.232
2022-02-03 01:41:16 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-02-03 01:41:16 | INFO | train | epoch 203 | loss 5.06 | ppl 33.37 | wps 6017.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12992 | lr 0.000277435 | gnorm 1.385 | train_wall 319 | gb_free 6.1 | wall 70181
KL Stats: Epoch 203 Divergences: Uniform: 3.195349914044525 Unigram: 3.912532132517429
2022-02-03 01:41:16 | INFO | fairseq.trainer | begin training epoch 204
2022-02-03 01:41:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:41:56 | INFO | train_inner | epoch 204:      8 / 64 loss=5.067, ppl=33.51, wps=5892.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=13000, lr=0.00027735, gnorm=1.371, train_wall=497, gb_free=6.1, wall=70221
2022-02-03 01:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:47:03 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 10.175 | ppl 1156.45 | wps 8145 | wpb 2034.1 | bsz 4 | num_updates 13056 | best_loss 9.232
2022-02-03 01:47:03 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-02-03 01:47:03 | INFO | train | epoch 204 | loss 5.058 | ppl 33.3 | wps 6023 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13056 | lr 0.000276755 | gnorm 1.419 | train_wall 318 | gb_free 6.1 | wall 70527
KL Stats: Epoch 204 Divergences: Uniform: 3.1965551952018347 Unigram: 3.912711706893792
2022-02-03 01:47:03 | INFO | fairseq.trainer | begin training epoch 205
2022-02-03 01:47:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:50:44 | INFO | train_inner | epoch 205:     44 / 64 loss=5.053, ppl=33.19, wps=6197.3, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=13100, lr=0.000276289, gnorm=1.432, train_wall=498, gb_free=6.1, wall=70748
2022-02-03 01:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:52:49 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 10.128 | ppl 1119.14 | wps 8154.7 | wpb 2034.1 | bsz 4 | num_updates 13120 | best_loss 9.232
2022-02-03 01:52:49 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-02-03 01:52:49 | INFO | train | epoch 205 | loss 5.055 | ppl 33.24 | wps 6026.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13120 | lr 0.000276079 | gnorm 1.427 | train_wall 318 | gb_free 6.1 | wall 70874
KL Stats: Epoch 205 Divergences: Uniform: 3.200504448167282 Unigram: 3.9192732367788587
2022-02-03 01:52:49 | INFO | fairseq.trainer | begin training epoch 206
2022-02-03 01:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:58:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:58:36 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 10.155 | ppl 1139.97 | wps 8148.2 | wpb 2034.1 | bsz 4 | num_updates 13184 | best_loss 9.232
2022-02-03 01:58:36 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-02-03 01:58:36 | INFO | train | epoch 206 | loss 5.049 | ppl 33.11 | wps 6020.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13184 | lr 0.000275408 | gnorm 1.408 | train_wall 318 | gb_free 6.1 | wall 71221
KL Stats: Epoch 206 Divergences: Uniform: 3.19973560243091 Unigram: 3.927244496461925
2022-02-03 01:58:36 | INFO | fairseq.trainer | begin training epoch 207
2022-02-03 01:58:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:59:57 | INFO | train_inner | epoch 207:     16 / 64 loss=5.049, ppl=33.1, wps=5894.1, ups=0.18, wpb=32594.2, bsz=63.7, num_updates=13200, lr=0.000275241, gnorm=1.406, train_wall=497, gb_free=6.1, wall=71301
2022-02-03 02:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:04:23 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 10.127 | ppl 1118.1 | wps 8149.5 | wpb 2034.1 | bsz 4 | num_updates 13248 | best_loss 9.232
2022-02-03 02:04:23 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-02-03 02:04:23 | INFO | train | epoch 207 | loss 5.046 | ppl 33.03 | wps 6019 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13248 | lr 0.000274742 | gnorm 1.416 | train_wall 319 | gb_free 6.1 | wall 71568
KL Stats: Epoch 207 Divergences: Uniform: 3.201081444832996 Unigram: 3.9267099211600107
2022-02-03 02:04:23 | INFO | fairseq.trainer | begin training epoch 208
2022-02-03 02:04:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:08:44 | INFO | train_inner | epoch 208:     52 / 64 loss=5.049, ppl=33.12, wps=6195.2, ups=0.19, wpb=32682.8, bsz=63.8, num_updates=13300, lr=0.000274204, gnorm=1.434, train_wall=498, gb_free=6.1, wall=71829
2022-02-03 02:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:10:10 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 10.138 | ppl 1126.67 | wps 8157.2 | wpb 2034.1 | bsz 4 | num_updates 13312 | best_loss 9.232
2022-02-03 02:10:10 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-02-03 02:10:10 | INFO | train | epoch 208 | loss 5.042 | ppl 32.96 | wps 6028 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 13312 | lr 0.000274081 | gnorm 1.451 | train_wall 318 | gb_free 6.1 | wall 71914
KL Stats: Epoch 208 Divergences: Uniform: 3.201387906360245 Unigram: 3.9260252151709367
2022-02-03 02:10:10 | INFO | fairseq.trainer | begin training epoch 209
2022-02-03 02:10:10 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
Sender: LSF System <lsfadmin@eu-g3-002>
Subject: Job 202993774: <w2_jelinek_0.09_0.01_0.9_#1> in cluster <euler> Exited

Job <w2_jelinek_0.09_0.01_0.9_#1> was submitted from host <eu-login-26> by user <andriusb> in cluster <euler> at Wed Feb  2 06:10:42 2022
Job was executed on host(s) <eu-g3-002>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Wed Feb  2 06:11:20 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Feb  2 06:11:20 2022
Terminated at Thu Feb  3 02:11:40 2022
Results reported at Thu Feb  3 02:11:40 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-2-raw-full --save-dir /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.5 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas "(0.09, 0.01, 0.9)" --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.5 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 16 --save-interval 40 --seed 10002 --max-update 50000
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   71956.00 sec.
    Max Memory :                                 6022 MB
    Average Memory :                             3357.92 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13978.00 MB
    Max Swap :                                   41 MB
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   72020 sec.
    Turnaround time :                            72058 sec.

The output (if any) follows:

2022-02-02 06:11:32 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 10002, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 40, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.5, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-2-raw-full', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 10002, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.09, 0.01, 0.9)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.5, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-02-02 06:11:32 | INFO | fairseq.tasks.language_modeling | dictionary: 76624 types
2022-02-02 06:11:33 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
Calculating frequency stats:
  0%|          | 0/36718 [00:00<?, ?it/s]  3%|▎         | 1057/36718 [00:00<00:03, 10566.28it/s]  6%|▌         | 2114/36718 [00:00<00:03, 9949.50it/s]   9%|▉         | 3273/36718 [00:00<00:03, 10670.30it/s] 12%|█▏        | 4469/36718 [00:00<00:02, 11161.77it/s] 16%|█▌        | 5695/36718 [00:00<00:02, 11544.27it/s] 19%|█▊        | 6852/36718 [00:00<00:02, 10962.63it/s] 22%|██▏       | 7955/36718 [00:00<00:02, 10930.13it/s] 25%|██▍       | 9054/36718 [00:00<00:02, 10947.67it/s] 28%|██▊       | 10152/36718 [00:00<00:02, 10853.23it/s] 31%|███       | 11240/36718 [00:01<00:02, 10712.91it/s] 34%|███▎      | 12325/36718 [00:01<00:02, 10753.47it/s] 37%|███▋      | 13447/36718 [00:01<00:02, 10890.74it/s] 40%|███▉      | 14542/36718 [00:01<00:02, 10906.53it/s] 43%|████▎     | 15675/36718 [00:01<00:01, 11031.87it/s] 46%|████▌     | 16779/36718 [00:01<00:01, 10675.14it/s] 49%|████▉     | 17912/36718 [00:01<00:01, 10860.83it/s] 52%|█████▏    | 19065/36718 [00:01<00:01, 11057.69it/s] 55%|█████▍    | 20176/36718 [00:01<00:01, 11062.88it/s] 58%|█████▊    | 21284/36718 [00:01<00:01, 10776.66it/s] 61%|██████    | 22372/36718 [00:02<00:01, 10804.72it/s] 64%|██████▍   | 23536/36718 [00:02<00:01, 11048.08it/s] 68%|██████▊   | 24843/36718 [00:02<00:01, 11638.82it/s] 71%|███████   | 26009/36718 [00:02<00:00, 11440.74it/s] 74%|███████▍  | 27155/36718 [00:02<00:00, 10780.34it/s] 77%|███████▋  | 28242/36718 [00:02<00:00, 10797.79it/s] 80%|███████▉  | 29328/36718 [00:02<00:00, 10802.08it/s] 83%|████████▎ | 30432/36718 [00:02<00:00, 10871.08it/s] 86%|████████▌ | 31523/36718 [00:02<00:00, 10519.89it/s] 89%|████████▊ | 32580/36718 [00:03<00:00, 10351.39it/s] 92%|█████████▏| 33619/36718 [00:03<00:00, 10246.45it/s] 95%|█████████▍| 34811/36718 [00:03<00:00, 10726.57it/s] 98%|█████████▊| 35887/36718 [00:03<00:00, 10484.13it/s]100%|██████████| 36718/36718 [00:03<00:00, 10824.97it/s]

gathering stats for n=1
  0%|          | 0/36718 [00:00<?, ?it/s]  5%|▌         | 1979/36718 [00:00<00:01, 19788.93it/s] 11%|█▏        | 4158/36718 [00:00<00:01, 20950.36it/s] 17%|█▋        | 6383/36718 [00:00<00:01, 21537.05it/s] 23%|██▎       | 8537/36718 [00:00<00:01, 20569.03it/s] 29%|██▉       | 10601/36718 [00:00<00:01, 20580.58it/s] 34%|███▍      | 12664/36718 [00:00<00:01, 20535.18it/s] 40%|████      | 14756/36718 [00:00<00:01, 20658.16it/s] 46%|████▌     | 16824/36718 [00:00<00:00, 20368.57it/s] 52%|█████▏    | 18958/36718 [00:00<00:00, 20659.39it/s] 57%|█████▋    | 21027/36718 [00:01<00:00, 20666.86it/s] 63%|██████▎   | 23099/36718 [00:01<00:00, 20677.76it/s] 69%|██████▉   | 25472/36718 [00:01<00:00, 21593.57it/s] 75%|███████▌  | 27633/36718 [00:01<00:00, 20669.26it/s] 81%|████████  | 29765/36718 [00:01<00:00, 20855.31it/s] 87%|████████▋ | 31858/36718 [00:01<00:00, 20386.69it/s] 92%|█████████▏| 33903/36718 [00:01<00:00, 20120.83it/s] 98%|█████████▊| 35930/36718 [00:01<00:00, 20156.68it/s]100%|██████████| 36718/36718 [00:01<00:00, 20583.48it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 72.70it/s]2022-02-02 06:11:49 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(76624, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=76624, bias=False)
  )
)
2022-02-02 06:11:49 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-02-02 06:11:49 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-02-02 06:11:49 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-02-02 06:11:49 | INFO | fairseq_cli.train | num. shared model params: 58,145,792 (num. trained: 58,145,792)
2022-02-02 06:11:49 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-02-02 06:11:49 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-2-raw-full/valid
2022-02-02 06:11:49 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-02-02 06:11:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:11:49 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-02-02 06:11:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-02-02 06:11:49 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-02-02 06:11:49 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-02-02 06:11:49 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:11:49 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint_last.pt
2022-02-02 06:11:49 | INFO | fairseq.trainer | loading train data for epoch 1
2022-02-02 06:11:49 | INFO | fairseq.data.data_utils | loaded 36,718 examples from: data-bin/wikitext-2-raw-full/train
2022-02-02 06:11:49 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2022-02-02 06:11:49 | INFO | fairseq.trainer | begin training epoch 1
2022-02-02 06:11:49 | INFO | fairseq_cli.train | Start iterating over samples

2022-02-02 06:17:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2022-02-02 06:17:52 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.783 | ppl 28195.8 | wps 7847.9 | wpb 2034.1 | bsz 4 | num_updates 64
2022-02-02 06:17:52 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-02-02 06:17:52 | INFO | train | epoch 001 | loss 16.125 | ppl 71491.5 | wps 5815.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 64 | lr 8.0984e-06 | gnorm 3.151 | train_wall 330 | gb_free 6.1 | wall 362
KL Stats: Epoch 1 Divergences: Uniform: 0.5118491660209957 Unigram: 3.6911737086028986
2022-02-02 06:17:52 | INFO | fairseq.trainer | begin training epoch 2
2022-02-02 06:17:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:20:58 | INFO | train_inner | epoch 002:     36 / 64 loss=15.602, ppl=49723.2, wps=5989.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=100, lr=1.25975e-05, gnorm=2.621, train_wall=516, gb_free=6.1, wall=549
2022-02-02 06:23:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:23:50 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.732 | ppl 13604.9 | wps 7841.7 | wpb 2034.1 | bsz 4 | num_updates 128
2022-02-02 06:23:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-02-02 06:23:50 | INFO | train | epoch 002 | loss 14.441 | ppl 22247.2 | wps 5830.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 128 | lr 1.60968e-05 | gnorm 1.575 | train_wall 329 | gb_free 6.1 | wall 720
KL Stats: Epoch 2 Divergences: Uniform: 0.5155452949917163 Unigram: 2.448847361580298
2022-02-02 06:23:50 | INFO | fairseq.trainer | begin training epoch 3
2022-02-02 06:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:29:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:29:48 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 12.864 | ppl 7454.01 | wps 7836.3 | wpb 2034.1 | bsz 4 | num_updates 192
2022-02-02 06:29:48 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-02-02 06:29:48 | INFO | train | epoch 003 | loss 13.507 | ppl 11641.5 | wps 5828.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 192 | lr 2.40952e-05 | gnorm 1.296 | train_wall 329 | gb_free 6.1 | wall 1079
KL Stats: Epoch 3 Divergences: Uniform: 0.49998427577617693 Unigram: 1.7510088537726676
2022-02-02 06:29:48 | INFO | fairseq.trainer | begin training epoch 4
2022-02-02 06:29:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:30:30 | INFO | train_inner | epoch 004:      8 / 64 loss=13.641, ppl=12771.9, wps=5704.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=200, lr=2.5095e-05, gnorm=1.326, train_wall=513, gb_free=6.1, wall=1120
2022-02-02 06:35:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:35:47 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 11.994 | ppl 4077.85 | wps 7842.8 | wpb 2034.1 | bsz 4 | num_updates 256
2022-02-02 06:35:47 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-02-02 06:35:47 | INFO | train | epoch 004 | loss 12.52 | ppl 5873.46 | wps 5820.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 256 | lr 3.20936e-05 | gnorm 1.029 | train_wall 329 | gb_free 6.1 | wall 1438
KL Stats: Epoch 4 Divergences: Uniform: 0.5896695263376248 Unigram: 1.1181568717141708
2022-02-02 06:35:47 | INFO | fairseq.trainer | begin training epoch 5
2022-02-02 06:35:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:39:36 | INFO | train_inner | epoch 005:     44 / 64 loss=12.165, ppl=4592.55, wps=5987.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=300, lr=3.75925e-05, gnorm=0.928, train_wall=515, gb_free=6.1, wall=1666
2022-02-02 06:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:41:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 11.476 | ppl 2847.84 | wps 7835 | wpb 2034.1 | bsz 4 | num_updates 320
2022-02-02 06:41:46 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-02-02 06:41:46 | INFO | train | epoch 005 | loss 11.714 | ppl 3358.93 | wps 5818.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 320 | lr 4.0092e-05 | gnorm 0.768 | train_wall 329 | gb_free 6.1 | wall 1797
KL Stats: Epoch 5 Divergences: Uniform: 0.8370968797076717 Unigram: 0.6376283045906096
2022-02-02 06:41:46 | INFO | fairseq.trainer | begin training epoch 6
2022-02-02 06:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:47:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:47:44 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.219 | ppl 2384.23 | wps 7867.6 | wpb 2034.1 | bsz 4 | num_updates 384
2022-02-02 06:47:44 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-02-02 06:47:44 | INFO | train | epoch 006 | loss 11.284 | ppl 2493.42 | wps 5827.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 384 | lr 4.80904e-05 | gnorm 0.598 | train_wall 329 | gb_free 6.1 | wall 2155
KL Stats: Epoch 6 Divergences: Uniform: 1.1620054775696038 Unigram: 0.4216801646916643
2022-02-02 06:47:44 | INFO | fairseq.trainer | begin training epoch 7
2022-02-02 06:47:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:49:07 | INFO | train_inner | epoch 007:     16 / 64 loss=11.308, ppl=2534.73, wps=5701.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=400, lr=5.009e-05, gnorm=0.594, train_wall=513, gb_free=6.1, wall=2238
2022-02-02 06:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:53:43 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.072 | ppl 2153.36 | wps 7834.7 | wpb 2034.1 | bsz 4 | num_updates 448
2022-02-02 06:53:43 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-02-02 06:53:43 | INFO | train | epoch 007 | loss 11.087 | ppl 2175.08 | wps 5826.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 448 | lr 5.60888e-05 | gnorm 0.502 | train_wall 329 | gb_free 6.1 | wall 2513
KL Stats: Epoch 7 Divergences: Uniform: 1.3967063726449722 Unigram: 0.4438190927941483
2022-02-02 06:53:43 | INFO | fairseq.trainer | begin training epoch 8
2022-02-02 06:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 06:58:13 | INFO | train_inner | epoch 008:     52 / 64 loss=11.022, ppl=2079.78, wps=5989.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=500, lr=6.25875e-05, gnorm=0.493, train_wall=515, gb_free=6.1, wall=2784
2022-02-02 06:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 06:59:42 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.968 | ppl 2002.8 | wps 7834.7 | wpb 2034.1 | bsz 4 | num_updates 512
2022-02-02 06:59:42 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-02-02 06:59:42 | INFO | train | epoch 008 | loss 10.971 | ppl 2006.69 | wps 5819.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 512 | lr 6.40872e-05 | gnorm 0.486 | train_wall 329 | gb_free 6.1 | wall 2872
KL Stats: Epoch 8 Divergences: Uniform: 1.5183995969550534 Unigram: 0.5263649910701628
2022-02-02 06:59:42 | INFO | fairseq.trainer | begin training epoch 9
2022-02-02 06:59:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:05:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:05:40 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.865 | ppl 1864.61 | wps 7860.5 | wpb 2034.1 | bsz 4 | num_updates 576
2022-02-02 07:05:40 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-02-02 07:05:40 | INFO | train | epoch 009 | loss 10.867 | ppl 1867.16 | wps 5824.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 576 | lr 7.20856e-05 | gnorm 0.497 | train_wall 329 | gb_free 6.1 | wall 3231
KL Stats: Epoch 9 Divergences: Uniform: 1.5709635985463766 Unigram: 0.6196227517595727
2022-02-02 07:05:40 | INFO | fairseq.trainer | begin training epoch 10
2022-02-02 07:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:07:45 | INFO | train_inner | epoch 010:     24 / 64 loss=10.855, ppl=1852.73, wps=5699.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=600, lr=7.5085e-05, gnorm=0.49, train_wall=513, gb_free=6.1, wall=3356
2022-02-02 07:11:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:11:39 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.742 | ppl 1712.86 | wps 7832 | wpb 2034.1 | bsz 4 | num_updates 640
2022-02-02 07:11:39 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-02-02 07:11:39 | INFO | train | epoch 010 | loss 10.755 | ppl 1728.65 | wps 5817.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 640 | lr 8.0084e-05 | gnorm 0.506 | train_wall 329 | gb_free 6.1 | wall 3590
KL Stats: Epoch 10 Divergences: Uniform: 1.5947959660108069 Unigram: 0.7303115537681952
2022-02-02 07:11:39 | INFO | fairseq.trainer | begin training epoch 11
2022-02-02 07:11:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:16:51 | INFO | train_inner | epoch 011:     60 / 64 loss=10.682, ppl=1642.39, wps=5987.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=700, lr=8.75825e-05, gnorm=0.501, train_wall=515, gb_free=6.1, wall=3901
2022-02-02 07:17:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:17:38 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.636 | ppl 1590.83 | wps 7832.5 | wpb 2034.1 | bsz 4 | num_updates 704
2022-02-02 07:17:38 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-02-02 07:17:38 | INFO | train | epoch 011 | loss 10.639 | ppl 1594.26 | wps 5821.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 704 | lr 8.80824e-05 | gnorm 0.484 | train_wall 329 | gb_free 6.1 | wall 3949
KL Stats: Epoch 11 Divergences: Uniform: 1.6153457766895658 Unigram: 0.8332293433080606
2022-02-02 07:17:38 | INFO | fairseq.trainer | begin training epoch 12
2022-02-02 07:17:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:23:37 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.552 | ppl 1501.12 | wps 7822.2 | wpb 2034.1 | bsz 4 | num_updates 768
2022-02-02 07:23:37 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-02-02 07:23:37 | INFO | train | epoch 012 | loss 10.523 | ppl 1471.77 | wps 5815.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 768 | lr 9.60808e-05 | gnorm 0.503 | train_wall 329 | gb_free 6.1 | wall 4308
KL Stats: Epoch 12 Divergences: Uniform: 1.635430809661012 Unigram: 0.9318453074559814
2022-02-02 07:23:37 | INFO | fairseq.trainer | begin training epoch 13
2022-02-02 07:23:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:26:23 | INFO | train_inner | epoch 013:     32 / 64 loss=10.495, ppl=1443.51, wps=5693.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=800, lr=0.00010008, gnorm=0.492, train_wall=514, gb_free=6.1, wall=4474
2022-02-02 07:29:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:29:36 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.445 | ppl 1394.31 | wps 7834 | wpb 2034.1 | bsz 4 | num_updates 832
2022-02-02 07:29:36 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-02-02 07:29:36 | INFO | train | epoch 013 | loss 10.409 | ppl 1359.18 | wps 5823 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 832 | lr 0.000104079 | gnorm 0.483 | train_wall 329 | gb_free 6.1 | wall 4667
KL Stats: Epoch 13 Divergences: Uniform: 1.651291588439552 Unigram: 1.0229696038559812
2022-02-02 07:29:36 | INFO | fairseq.trainer | begin training epoch 14
2022-02-02 07:29:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:35:35 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.359 | ppl 1313.28 | wps 7843.3 | wpb 2034.1 | bsz 4 | num_updates 896
2022-02-02 07:35:35 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-02-02 07:35:35 | INFO | train | epoch 014 | loss 10.296 | ppl 1257.56 | wps 5812.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 896 | lr 0.000112078 | gnorm 0.537 | train_wall 330 | gb_free 6.1 | wall 5026
KL Stats: Epoch 14 Divergences: Uniform: 1.6793214393307567 Unigram: 1.0988846404574681
2022-02-02 07:35:35 | INFO | fairseq.trainer | begin training epoch 15
2022-02-02 07:35:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:35:56 | INFO | train_inner | epoch 015:      4 / 64 loss=10.321, ppl=1279.3, wps=5692.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=900, lr=0.000112578, gnorm=0.523, train_wall=514, gb_free=6.1, wall=5047
2022-02-02 07:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:41:34 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.268 | ppl 1232.94 | wps 7862.7 | wpb 2034.1 | bsz 4 | num_updates 960
2022-02-02 07:41:34 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-02-02 07:41:34 | INFO | train | epoch 015 | loss 10.184 | ppl 1163.39 | wps 5829 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 960 | lr 0.000120076 | gnorm 0.496 | train_wall 329 | gb_free 6.1 | wall 5384
KL Stats: Epoch 15 Divergences: Uniform: 1.7063984040202325 Unigram: 1.1743598031405074
2022-02-02 07:41:34 | INFO | fairseq.trainer | begin training epoch 16
2022-02-02 07:41:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:45:01 | INFO | train_inner | epoch 016:     40 / 64 loss=10.145, ppl=1131.89, wps=5997.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=1000, lr=0.000125075, gnorm=0.513, train_wall=514, gb_free=6.1, wall=5592
2022-02-02 07:47:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:47:32 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.177 | ppl 1157.5 | wps 7851.5 | wpb 2034.1 | bsz 4 | num_updates 1024
2022-02-02 07:47:32 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-02-02 07:47:32 | INFO | train | epoch 016 | loss 10.079 | ppl 1081.4 | wps 5830 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1024 | lr 0.000128074 | gnorm 0.521 | train_wall 329 | gb_free 6.1 | wall 5742
KL Stats: Epoch 16 Divergences: Uniform: 1.7394564964482375 Unigram: 1.243256312711896
2022-02-02 07:47:32 | INFO | fairseq.trainer | begin training epoch 17
2022-02-02 07:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:53:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:53:30 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.1 | ppl 1097.7 | wps 7848.7 | wpb 2034.1 | bsz 4 | num_updates 1088
2022-02-02 07:53:30 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-02-02 07:53:30 | INFO | train | epoch 017 | loss 9.973 | ppl 1005.01 | wps 5826.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1088 | lr 0.000136073 | gnorm 0.54 | train_wall 329 | gb_free 6.1 | wall 6101
KL Stats: Epoch 17 Divergences: Uniform: 1.768504551501471 Unigram: 1.3059780513028594
2022-02-02 07:53:30 | INFO | fairseq.trainer | begin training epoch 18
2022-02-02 07:53:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 07:54:33 | INFO | train_inner | epoch 018:     12 / 64 loss=9.983, ppl=1012.02, wps=5702.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1100, lr=0.000137573, gnorm=0.528, train_wall=513, gb_free=6.1, wall=6163
2022-02-02 07:59:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 07:59:29 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.045 | ppl 1056.34 | wps 7832.2 | wpb 2034.1 | bsz 4 | num_updates 1152
2022-02-02 07:59:29 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-02-02 07:59:29 | INFO | train | epoch 018 | loss 9.87 | ppl 935.74 | wps 5825.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1152 | lr 0.000144071 | gnorm 0.51 | train_wall 329 | gb_free 6.1 | wall 6460
KL Stats: Epoch 18 Divergences: Uniform: 1.8055993774124532 Unigram: 1.3729866248895686
2022-02-02 07:59:29 | INFO | fairseq.trainer | begin training epoch 19
2022-02-02 07:59:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:03:38 | INFO | train_inner | epoch 019:     48 / 64 loss=9.827, ppl=908.15, wps=5995.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1200, lr=0.00015007, gnorm=0.534, train_wall=514, gb_free=6.1, wall=6708
2022-02-02 08:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:05:27 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.99 | ppl 1017.17 | wps 7862.7 | wpb 2034.1 | bsz 4 | num_updates 1216
2022-02-02 08:05:27 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-02-02 08:05:27 | INFO | train | epoch 019 | loss 9.772 | ppl 874.52 | wps 5830.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1216 | lr 0.00015207 | gnorm 0.551 | train_wall 329 | gb_free 6.1 | wall 6818
KL Stats: Epoch 19 Divergences: Uniform: 1.8382102533070395 Unigram: 1.4323132512202223
2022-02-02 08:05:27 | INFO | fairseq.trainer | begin training epoch 20
2022-02-02 08:05:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:10:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:11:26 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.914 | ppl 964.52 | wps 7836.8 | wpb 2034.1 | bsz 4 | num_updates 1280
2022-02-02 08:11:26 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-02-02 08:11:26 | INFO | train | epoch 020 | loss 9.678 | ppl 818.93 | wps 5819.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1280 | lr 0.000160068 | gnorm 0.524 | train_wall 329 | gb_free 6.1 | wall 7177
KL Stats: Epoch 20 Divergences: Uniform: 1.8697537885895317 Unigram: 1.4904226587446223
2022-02-02 08:11:26 | INFO | fairseq.trainer | begin training epoch 21
2022-02-02 08:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:13:10 | INFO | train_inner | epoch 021:     20 / 64 loss=9.67, ppl=814.88, wps=5698.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1300, lr=0.000162568, gnorm=0.523, train_wall=514, gb_free=6.1, wall=7280
2022-02-02 08:16:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:17:25 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.845 | ppl 919.43 | wps 7818.6 | wpb 2034.1 | bsz 4 | num_updates 1344
2022-02-02 08:17:25 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-02-02 08:17:25 | INFO | train | epoch 021 | loss 9.587 | ppl 768.96 | wps 5818.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1344 | lr 0.000168066 | gnorm 0.524 | train_wall 329 | gb_free 6.1 | wall 7536
KL Stats: Epoch 21 Divergences: Uniform: 1.895841569515318 Unigram: 1.5442153809602874
2022-02-02 08:17:25 | INFO | fairseq.trainer | begin training epoch 22
2022-02-02 08:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:22:16 | INFO | train_inner | epoch 022:     56 / 64 loss=9.539, ppl=743.82, wps=5987.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1400, lr=0.000175065, gnorm=0.527, train_wall=515, gb_free=6.1, wall=7826
2022-02-02 08:22:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:23:24 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.776 | ppl 876.64 | wps 7843.4 | wpb 2034.1 | bsz 4 | num_updates 1408
2022-02-02 08:23:24 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-02-02 08:23:24 | INFO | train | epoch 022 | loss 9.499 | ppl 723.47 | wps 5821.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1408 | lr 0.000176065 | gnorm 0.537 | train_wall 329 | gb_free 6.1 | wall 7894
KL Stats: Epoch 22 Divergences: Uniform: 1.9237560890433103 Unigram: 1.5888901530929105
2022-02-02 08:23:24 | INFO | fairseq.trainer | begin training epoch 23
2022-02-02 08:23:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:28:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:29:22 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.73 | ppl 849.11 | wps 7822.8 | wpb 2034.1 | bsz 4 | num_updates 1472
2022-02-02 08:29:22 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-02-02 08:29:22 | INFO | train | epoch 023 | loss 9.412 | ppl 681.24 | wps 5827.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1472 | lr 0.000184063 | gnorm 0.523 | train_wall 329 | gb_free 6.1 | wall 8253
KL Stats: Epoch 23 Divergences: Uniform: 1.9461257169895367 Unigram: 1.6393831878358187
2022-02-02 08:29:22 | INFO | fairseq.trainer | begin training epoch 24
2022-02-02 08:29:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:31:48 | INFO | train_inner | epoch 024:     28 / 64 loss=9.394, ppl=672.69, wps=5698.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=1500, lr=0.000187563, gnorm=0.52, train_wall=514, gb_free=6.1, wall=8398
2022-02-02 08:34:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:35:21 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.687 | ppl 824.1 | wps 7851.2 | wpb 2034.1 | bsz 4 | num_updates 1536
2022-02-02 08:35:21 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-02-02 08:35:21 | INFO | train | epoch 024 | loss 9.33 | ppl 643.61 | wps 5817.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1536 | lr 0.000192062 | gnorm 0.526 | train_wall 329 | gb_free 6.1 | wall 8612
KL Stats: Epoch 24 Divergences: Uniform: 1.977702619020959 Unigram: 1.6790609400482956
2022-02-02 08:35:21 | INFO | fairseq.trainer | begin training epoch 25
2022-02-02 08:35:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:40:52 | INFO | train_inner | epoch 025:     64 / 64 loss=9.277, ppl=620.29, wps=5985.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=1600, lr=0.00020006, gnorm=0.543, train_wall=514, gb_free=6.1, wall=8943
2022-02-02 08:40:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:41:20 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.647 | ppl 801.56 | wps 7867.2 | wpb 2034.1 | bsz 4 | num_updates 1600
2022-02-02 08:41:20 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-02-02 08:41:20 | INFO | train | epoch 025 | loss 9.248 | ppl 607.9 | wps 5819.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1600 | lr 0.00020006 | gnorm 0.542 | train_wall 329 | gb_free 6.1 | wall 8971
KL Stats: Epoch 25 Divergences: Uniform: 2.0018680527429287 Unigram: 1.7228074583856996
2022-02-02 08:41:20 | INFO | fairseq.trainer | begin training epoch 26
2022-02-02 08:41:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:46:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:47:19 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.606 | ppl 779.26 | wps 7847.1 | wpb 2034.1 | bsz 4 | num_updates 1664
2022-02-02 08:47:19 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-02-02 08:47:19 | INFO | train | epoch 026 | loss 9.167 | ppl 574.81 | wps 5828.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1664 | lr 0.000208058 | gnorm 0.53 | train_wall 329 | gb_free 6.1 | wall 9329
KL Stats: Epoch 26 Divergences: Uniform: 2.0226353067744323 Unigram: 1.76660750825512
2022-02-02 08:47:19 | INFO | fairseq.trainer | begin training epoch 27
2022-02-02 08:47:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:50:25 | INFO | train_inner | epoch 027:     36 / 64 loss=9.14, ppl=564.12, wps=5704.4, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=1700, lr=0.000212558, gnorm=0.529, train_wall=514, gb_free=6.1, wall=9516
2022-02-02 08:52:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:53:17 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.561 | ppl 755.39 | wps 7843.6 | wpb 2034.1 | bsz 4 | num_updates 1728
2022-02-02 08:53:17 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-02-02 08:53:17 | INFO | train | epoch 027 | loss 9.089 | ppl 544.59 | wps 5825.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1728 | lr 0.000216057 | gnorm 0.54 | train_wall 329 | gb_free 6.1 | wall 9688
KL Stats: Epoch 27 Divergences: Uniform: 2.044961802016562 Unigram: 1.800725932233449
2022-02-02 08:53:17 | INFO | fairseq.trainer | begin training epoch 28
2022-02-02 08:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:58:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 08:59:16 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.524 | ppl 736.28 | wps 7843.4 | wpb 2034.1 | bsz 4 | num_updates 1792
2022-02-02 08:59:16 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-02-02 08:59:16 | INFO | train | epoch 028 | loss 9.01 | ppl 515.65 | wps 5816.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1792 | lr 0.000224055 | gnorm 0.532 | train_wall 329 | gb_free 6.1 | wall 10047
KL Stats: Epoch 28 Divergences: Uniform: 2.073284570026863 Unigram: 1.8371652717649594
2022-02-02 08:59:16 | INFO | fairseq.trainer | begin training epoch 29
2022-02-02 08:59:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 08:59:58 | INFO | train_inner | epoch 029:      8 / 64 loss=9.023, ppl=520.22, wps=5695.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=1800, lr=0.000225055, gnorm=0.537, train_wall=514, gb_free=6.1, wall=10088
2022-02-02 09:04:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:05:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.493 | ppl 720.44 | wps 7861.6 | wpb 2034.1 | bsz 4 | num_updates 1856
2022-02-02 09:05:15 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-02-02 09:05:15 | INFO | train | epoch 029 | loss 8.932 | ppl 488.5 | wps 5825 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1856 | lr 0.000232054 | gnorm 0.52 | train_wall 329 | gb_free 6.1 | wall 10405
KL Stats: Epoch 29 Divergences: Uniform: 2.0950653634492524 Unigram: 1.87332143521129
2022-02-02 09:05:15 | INFO | fairseq.trainer | begin training epoch 30
2022-02-02 09:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:09:03 | INFO | train_inner | epoch 030:     44 / 64 loss=8.899, ppl=477.35, wps=5993.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=1900, lr=0.000237553, gnorm=0.516, train_wall=515, gb_free=6.1, wall=10633
2022-02-02 09:10:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:11:13 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.459 | ppl 703.9 | wps 7835.6 | wpb 2034.1 | bsz 4 | num_updates 1920
2022-02-02 09:11:13 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-02-02 09:11:13 | INFO | train | epoch 030 | loss 8.853 | ppl 462.45 | wps 5826.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1920 | lr 0.000240052 | gnorm 0.513 | train_wall 329 | gb_free 6.1 | wall 10764
KL Stats: Epoch 30 Divergences: Uniform: 2.119707931373789 Unigram: 1.9083637433532499
2022-02-02 09:11:13 | INFO | fairseq.trainer | begin training epoch 31
2022-02-02 09:11:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:16:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:17:12 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.425 | ppl 687.45 | wps 7814.1 | wpb 2034.1 | bsz 4 | num_updates 1984
2022-02-02 09:17:12 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-02-02 09:17:12 | INFO | train | epoch 031 | loss 8.778 | ppl 439.1 | wps 5823.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 1984 | lr 0.00024805 | gnorm 0.521 | train_wall 329 | gb_free 6.1 | wall 11122
KL Stats: Epoch 31 Divergences: Uniform: 2.136221503872793 Unigram: 1.9411581747805973
2022-02-02 09:17:12 | INFO | fairseq.trainer | begin training epoch 32
2022-02-02 09:17:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:18:35 | INFO | train_inner | epoch 032:     16 / 64 loss=8.784, ppl=440.73, wps=5700.2, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2000, lr=0.00025005, gnorm=0.527, train_wall=513, gb_free=6.1, wall=11205
2022-02-02 09:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:23:10 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.411 | ppl 680.56 | wps 7847.6 | wpb 2034.1 | bsz 4 | num_updates 2048
2022-02-02 09:23:10 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-02-02 09:23:10 | INFO | train | epoch 032 | loss 8.705 | ppl 417.22 | wps 5827.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2048 | lr 0.000256049 | gnorm 0.511 | train_wall 329 | gb_free 6.1 | wall 11481
KL Stats: Epoch 32 Divergences: Uniform: 2.1516273067201768 Unigram: 1.9793395840534358
2022-02-02 09:23:10 | INFO | fairseq.trainer | begin training epoch 33
2022-02-02 09:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:27:40 | INFO | train_inner | epoch 033:     52 / 64 loss=8.664, ppl=405.51, wps=5991.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2100, lr=0.000262548, gnorm=0.508, train_wall=515, gb_free=6.1, wall=11751
2022-02-02 09:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:29:09 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.371 | ppl 661.96 | wps 7839.7 | wpb 2034.1 | bsz 4 | num_updates 2112
2022-02-02 09:29:09 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-02-02 09:29:09 | INFO | train | epoch 033 | loss 8.63 | ppl 396.19 | wps 5819.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2112 | lr 0.000264047 | gnorm 0.514 | train_wall 329 | gb_free 6.1 | wall 11840
KL Stats: Epoch 33 Divergences: Uniform: 2.1739991588482472 Unigram: 2.008960980602862
2022-02-02 09:29:09 | INFO | fairseq.trainer | begin training epoch 34
2022-02-02 09:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:35:08 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.339 | ppl 647.58 | wps 7814 | wpb 2034.1 | bsz 4 | num_updates 2176
2022-02-02 09:35:08 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-02-02 09:35:08 | INFO | train | epoch 034 | loss 8.556 | ppl 376.49 | wps 5825.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2176 | lr 0.000272046 | gnorm 0.5 | train_wall 329 | gb_free 6.1 | wall 12198
KL Stats: Epoch 34 Divergences: Uniform: 2.2047916847073235 Unigram: 2.0402233537122827
2022-02-02 09:35:08 | INFO | fairseq.trainer | begin training epoch 35
2022-02-02 09:35:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:37:12 | INFO | train_inner | epoch 035:     24 / 64 loss=8.546, ppl=373.83, wps=5701.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2200, lr=0.000275045, gnorm=0.497, train_wall=513, gb_free=6.1, wall=12323
2022-02-02 09:40:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:41:06 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.336 | ppl 646.45 | wps 7825.4 | wpb 2034.1 | bsz 4 | num_updates 2240
2022-02-02 09:41:06 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-02-02 09:41:06 | INFO | train | epoch 035 | loss 8.485 | ppl 358.21 | wps 5826.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2240 | lr 0.000280044 | gnorm 0.504 | train_wall 329 | gb_free 6.1 | wall 12557
KL Stats: Epoch 35 Divergences: Uniform: 2.2303383084757296 Unigram: 2.0735293893987636
2022-02-02 09:41:06 | INFO | fairseq.trainer | begin training epoch 36
2022-02-02 09:41:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:46:17 | INFO | train_inner | epoch 036:     60 / 64 loss=8.443, ppl=348, wps=5993.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2300, lr=0.000287543, gnorm=0.508, train_wall=515, gb_free=6.1, wall=12868
2022-02-02 09:46:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:47:05 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.317 | ppl 637.87 | wps 7851.6 | wpb 2034.1 | bsz 4 | num_updates 2304
2022-02-02 09:47:05 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-02-02 09:47:05 | INFO | train | epoch 036 | loss 8.414 | ppl 341.12 | wps 5826.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2304 | lr 0.000288042 | gnorm 0.508 | train_wall 329 | gb_free 6.1 | wall 12915
KL Stats: Epoch 36 Divergences: Uniform: 2.246322598184314 Unigram: 2.107521652910797
2022-02-02 09:47:05 | INFO | fairseq.trainer | begin training epoch 37
2022-02-02 09:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:52:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:53:03 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.282 | ppl 622.34 | wps 7822.4 | wpb 2034.1 | bsz 4 | num_updates 2368
2022-02-02 09:53:03 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-02-02 09:53:03 | INFO | train | epoch 037 | loss 8.343 | ppl 324.74 | wps 5821.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2368 | lr 0.000296041 | gnorm 0.507 | train_wall 329 | gb_free 6.1 | wall 13274
KL Stats: Epoch 37 Divergences: Uniform: 2.267135696944479 Unigram: 2.137144958078729
2022-02-02 09:53:03 | INFO | fairseq.trainer | begin training epoch 38
2022-02-02 09:53:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 09:55:49 | INFO | train_inner | epoch 038:     32 / 64 loss=8.322, ppl=320.07, wps=5698.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2400, lr=0.00030004, gnorm=0.512, train_wall=514, gb_free=6.1, wall=13440
2022-02-02 09:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 09:59:02 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.268 | ppl 616.72 | wps 7832.3 | wpb 2034.1 | bsz 4 | num_updates 2432
2022-02-02 09:59:02 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-02-02 09:59:02 | INFO | train | epoch 038 | loss 8.275 | ppl 309.7 | wps 5825 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2432 | lr 0.000304039 | gnorm 0.508 | train_wall 329 | gb_free 6.1 | wall 13632
KL Stats: Epoch 38 Divergences: Uniform: 2.293787634642559 Unigram: 2.164907222316893
2022-02-02 09:59:02 | INFO | fairseq.trainer | begin training epoch 39
2022-02-02 09:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:04:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:05:01 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.278 | ppl 620.72 | wps 7838.6 | wpb 2034.1 | bsz 4 | num_updates 2496
2022-02-02 10:05:01 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-02-02 10:05:01 | INFO | train | epoch 039 | loss 8.208 | ppl 295.75 | wps 5823.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2496 | lr 0.000312038 | gnorm 0.496 | train_wall 329 | gb_free 6.1 | wall 13991
KL Stats: Epoch 39 Divergences: Uniform: 2.31484335272036 Unigram: 2.200027367511009
2022-02-02 10:05:01 | INFO | fairseq.trainer | begin training epoch 40
2022-02-02 10:05:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:05:21 | INFO | train_inner | epoch 040:      4 / 64 loss=8.23, ppl=300.2, wps=5700.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2500, lr=0.000312538, gnorm=0.497, train_wall=513, gb_free=6.1, wall=14012
2022-02-02 10:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:10:59 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.232 | ppl 601.27 | wps 7858.4 | wpb 2034.1 | bsz 4 | num_updates 2560
2022-02-02 10:10:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 2560 updates
2022-02-02 10:10:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt
2022-02-02 10:11:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt
2022-02-02 10:11:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint40.pt (epoch 40 @ 2560 updates, score 9.232) (writing took 5.620907701551914 seconds)
2022-02-02 10:11:05 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-02-02 10:11:05 | INFO | train | epoch 040 | loss 8.14 | ppl 282 | wps 5738 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2560 | lr 0.000320036 | gnorm 0.491 | train_wall 329 | gb_free 6.1 | wall 14355
KL Stats: Epoch 40 Divergences: Uniform: 2.339286724726359 Unigram: 2.224733274352323
2022-02-02 10:11:05 | INFO | fairseq.trainer | begin training epoch 41
2022-02-02 10:11:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:14:32 | INFO | train_inner | epoch 041:     40 / 64 loss=8.111, ppl=276.43, wps=5937, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=2600, lr=0.000325035, gnorm=0.491, train_wall=514, gb_free=6.1, wall=14562
2022-02-02 10:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:17:03 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.23 | ppl 600.47 | wps 7844.6 | wpb 2034.1 | bsz 4 | num_updates 2624 | best_loss 9.23
2022-02-02 10:17:03 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-02-02 10:17:03 | INFO | train | epoch 041 | loss 8.075 | ppl 269.74 | wps 5831.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2624 | lr 0.000328034 | gnorm 0.497 | train_wall 329 | gb_free 6.1 | wall 14713
KL Stats: Epoch 41 Divergences: Uniform: 2.354496961797654 Unigram: 2.2502375653305426
2022-02-02 10:17:03 | INFO | fairseq.trainer | begin training epoch 42
2022-02-02 10:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:22:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:23:01 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.2 | ppl 588.29 | wps 7846.4 | wpb 2034.1 | bsz 4 | num_updates 2688 | best_loss 9.2
2022-02-02 10:23:01 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-02-02 10:23:01 | INFO | train | epoch 042 | loss 8.01 | ppl 257.77 | wps 5826.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2688 | lr 0.000336033 | gnorm 0.495 | train_wall 329 | gb_free 6.1 | wall 15072
KL Stats: Epoch 42 Divergences: Uniform: 2.374429449419207 Unigram: 2.2769936525816394
2022-02-02 10:23:01 | INFO | fairseq.trainer | begin training epoch 43
2022-02-02 10:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:24:04 | INFO | train_inner | epoch 043:     12 / 64 loss=8.016, ppl=258.78, wps=5699.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=2700, lr=0.000337533, gnorm=0.495, train_wall=513, gb_free=6.1, wall=15134
2022-02-02 10:28:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:29:00 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.189 | ppl 583.78 | wps 7846 | wpb 2034.1 | bsz 4 | num_updates 2752 | best_loss 9.189
2022-02-02 10:29:00 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-02-02 10:29:00 | INFO | train | epoch 043 | loss 7.95 | ppl 247.31 | wps 5818 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2752 | lr 0.000344031 | gnorm 0.503 | train_wall 329 | gb_free 6.1 | wall 15431
KL Stats: Epoch 43 Divergences: Uniform: 2.3998650162684565 Unigram: 2.3033385255629892
2022-02-02 10:29:00 | INFO | fairseq.trainer | begin training epoch 44
2022-02-02 10:29:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:33:09 | INFO | train_inner | epoch 044:     48 / 64 loss=7.922, ppl=242.47, wps=5988.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=2800, lr=0.00035003, gnorm=0.504, train_wall=515, gb_free=6.1, wall=15680
2022-02-02 10:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:34:59 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.199 | ppl 587.72 | wps 7839.7 | wpb 2034.1 | bsz 4 | num_updates 2816 | best_loss 9.199
2022-02-02 10:34:59 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-02-02 10:34:59 | INFO | train | epoch 044 | loss 7.887 | ppl 236.77 | wps 5820.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2816 | lr 0.00035203 | gnorm 0.498 | train_wall 329 | gb_free 6.1 | wall 15790
KL Stats: Epoch 44 Divergences: Uniform: 2.411983199824347 Unigram: 2.3387801496918024
2022-02-02 10:34:59 | INFO | fairseq.trainer | begin training epoch 45
2022-02-02 10:34:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:40:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:40:57 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.196 | ppl 586.4 | wps 7851.1 | wpb 2034.1 | bsz 4 | num_updates 2880 | best_loss 9.196
2022-02-02 10:40:57 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-02-02 10:40:57 | INFO | train | epoch 045 | loss 7.826 | ppl 226.98 | wps 5830.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2880 | lr 0.000360028 | gnorm 0.508 | train_wall 329 | gb_free 6.1 | wall 16148
KL Stats: Epoch 45 Divergences: Uniform: 2.4264099281520988 Unigram: 2.3603639683086395
2022-02-02 10:40:57 | INFO | fairseq.trainer | begin training epoch 46
2022-02-02 10:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:42:41 | INFO | train_inner | epoch 046:     20 / 64 loss=7.824, ppl=226.63, wps=5704.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=2900, lr=0.000362528, gnorm=0.508, train_wall=513, gb_free=6.1, wall=16251
2022-02-02 10:46:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:46:55 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.194 | ppl 585.71 | wps 7844.2 | wpb 2034.1 | bsz 4 | num_updates 2944 | best_loss 9.194
2022-02-02 10:46:55 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-02-02 10:46:55 | INFO | train | epoch 046 | loss 7.765 | ppl 217.52 | wps 5832.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 2944 | lr 0.000368026 | gnorm 0.499 | train_wall 329 | gb_free 6.1 | wall 16506
KL Stats: Epoch 46 Divergences: Uniform: 2.4470665483436633 Unigram: 2.3869179365003155
2022-02-02 10:46:55 | INFO | fairseq.trainer | begin training epoch 47
2022-02-02 10:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:51:46 | INFO | train_inner | epoch 047:     56 / 64 loss=7.733, ppl=212.72, wps=5995.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3000, lr=0.000375025, gnorm=0.496, train_wall=515, gb_free=6.1, wall=16797
2022-02-02 10:52:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:52:54 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.182 | ppl 580.77 | wps 7847.4 | wpb 2034.1 | bsz 4 | num_updates 3008 | best_loss 9.182
2022-02-02 10:52:54 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-02-02 10:52:54 | INFO | train | epoch 047 | loss 7.708 | ppl 209.06 | wps 5821.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3008 | lr 0.000376025 | gnorm 0.499 | train_wall 329 | gb_free 6.1 | wall 16865
KL Stats: Epoch 47 Divergences: Uniform: 2.4691139946923593 Unigram: 2.409645094323359
2022-02-02 10:52:54 | INFO | fairseq.trainer | begin training epoch 48
2022-02-02 10:52:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 10:58:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 10:58:53 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.178 | ppl 579.36 | wps 7829.9 | wpb 2034.1 | bsz 4 | num_updates 3072 | best_loss 9.178
2022-02-02 10:58:53 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-02-02 10:58:53 | INFO | train | epoch 048 | loss 7.65 | ppl 200.89 | wps 5817.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3072 | lr 0.000384023 | gnorm 0.504 | train_wall 329 | gb_free 6.1 | wall 17224
KL Stats: Epoch 48 Divergences: Uniform: 2.488895587057629 Unigram: 2.431140269272284
2022-02-02 10:58:53 | INFO | fairseq.trainer | begin training epoch 49
2022-02-02 10:58:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:01:19 | INFO | train_inner | epoch 049:     28 / 64 loss=7.635, ppl=198.75, wps=5693.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=3100, lr=0.000387523, gnorm=0.51, train_wall=514, gb_free=6.1, wall=17369
2022-02-02 11:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:04:52 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.155 | ppl 569.99 | wps 7857.4 | wpb 2034.1 | bsz 4 | num_updates 3136 | best_loss 9.155
2022-02-02 11:04:52 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-02-02 11:04:52 | INFO | train | epoch 049 | loss 7.593 | ppl 193.11 | wps 5823 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3136 | lr 0.000392022 | gnorm 0.514 | train_wall 329 | gb_free 6.1 | wall 17582
KL Stats: Epoch 49 Divergences: Uniform: 2.510520157049986 Unigram: 2.4557097932787615
2022-02-02 11:04:52 | INFO | fairseq.trainer | begin training epoch 50
2022-02-02 11:04:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:10:22 | INFO | train_inner | epoch 050:     64 / 64 loss=7.567, ppl=189.56, wps=5995.5, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3200, lr=0.00040002, gnorm=0.508, train_wall=513, gb_free=6.1, wall=17913
2022-02-02 11:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:10:50 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.179 | ppl 579.55 | wps 7847 | wpb 2034.1 | bsz 4 | num_updates 3200 | best_loss 9.179
2022-02-02 11:10:50 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-02-02 11:10:50 | INFO | train | epoch 050 | loss 7.54 | ppl 186.15 | wps 5829.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3200 | lr 0.00040002 | gnorm 0.511 | train_wall 329 | gb_free 6.1 | wall 17941
KL Stats: Epoch 50 Divergences: Uniform: 2.519366051216312 Unigram: 2.471622544397421
2022-02-02 11:10:50 | INFO | fairseq.trainer | begin training epoch 51
2022-02-02 11:10:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:16:48 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.17 | ppl 576.18 | wps 7854.5 | wpb 2034.1 | bsz 4 | num_updates 3264 | best_loss 9.17
2022-02-02 11:16:48 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-02-02 11:16:48 | INFO | train | epoch 051 | loss 7.485 | ppl 179.17 | wps 5831.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3264 | lr 0.000408018 | gnorm 0.511 | train_wall 329 | gb_free 6.1 | wall 18299
KL Stats: Epoch 51 Divergences: Uniform: 2.540298939386157 Unigram: 2.5024366823239586
2022-02-02 11:16:48 | INFO | fairseq.trainer | begin training epoch 52
2022-02-02 11:16:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:19:55 | INFO | train_inner | epoch 052:     36 / 64 loss=7.461, ppl=176.25, wps=5708.4, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=3300, lr=0.000412518, gnorm=0.513, train_wall=514, gb_free=6.1, wall=18485
2022-02-02 11:22:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:22:46 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.187 | ppl 582.67 | wps 7842.5 | wpb 2034.1 | bsz 4 | num_updates 3328 | best_loss 9.187
2022-02-02 11:22:46 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-02-02 11:22:46 | INFO | train | epoch 052 | loss 7.433 | ppl 172.81 | wps 5833.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3328 | lr 0.000416017 | gnorm 0.513 | train_wall 328 | gb_free 6.1 | wall 18657
KL Stats: Epoch 52 Divergences: Uniform: 2.558188459050957 Unigram: 2.517902986875281
2022-02-02 11:22:46 | INFO | fairseq.trainer | begin training epoch 53
2022-02-02 11:22:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:28:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:28:45 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.177 | ppl 579.03 | wps 7836.6 | wpb 2034.1 | bsz 4 | num_updates 3392 | best_loss 9.177
2022-02-02 11:28:45 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-02-02 11:28:45 | INFO | train | epoch 053 | loss 7.381 | ppl 166.74 | wps 5828.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3392 | lr 0.000424015 | gnorm 0.515 | train_wall 329 | gb_free 6.1 | wall 19015
KL Stats: Epoch 53 Divergences: Uniform: 2.569048540569971 Unigram: 2.541568232492717
2022-02-02 11:28:45 | INFO | fairseq.trainer | begin training epoch 54
2022-02-02 11:28:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:29:26 | INFO | train_inner | epoch 054:      8 / 64 loss=7.393, ppl=168.11, wps=5705.3, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=3400, lr=0.000425015, gnorm=0.514, train_wall=513, gb_free=6.1, wall=19057
2022-02-02 11:34:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:34:43 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.163 | ppl 573.13 | wps 7836.6 | wpb 2034.1 | bsz 4 | num_updates 3456 | best_loss 9.163
2022-02-02 11:34:43 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-02-02 11:34:43 | INFO | train | epoch 054 | loss 7.331 | ppl 160.98 | wps 5824.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3456 | lr 0.000432014 | gnorm 0.518 | train_wall 329 | gb_free 6.1 | wall 19374
KL Stats: Epoch 54 Divergences: Uniform: 2.581857868792267 Unigram: 2.565133560619193
2022-02-02 11:34:43 | INFO | fairseq.trainer | begin training epoch 55
2022-02-02 11:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:38:31 | INFO | train_inner | epoch 055:     44 / 64 loss=7.3, ppl=157.59, wps=5994, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3500, lr=0.000437513, gnorm=0.514, train_wall=515, gb_free=6.1, wall=19602
2022-02-02 11:40:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:40:42 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.199 | ppl 587.89 | wps 7859.9 | wpb 2034.1 | bsz 4 | num_updates 3520 | best_loss 9.199
2022-02-02 11:40:42 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-02-02 11:40:42 | INFO | train | epoch 055 | loss 7.28 | ppl 155.37 | wps 5826.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3520 | lr 0.000440012 | gnorm 0.508 | train_wall 329 | gb_free 6.1 | wall 19732
KL Stats: Epoch 55 Divergences: Uniform: 2.6010973532888766 Unigram: 2.585105742764801
2022-02-02 11:40:42 | INFO | fairseq.trainer | begin training epoch 56
2022-02-02 11:40:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:46:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:46:40 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.194 | ppl 585.59 | wps 7759.3 | wpb 2034.1 | bsz 4 | num_updates 3584 | best_loss 9.194
2022-02-02 11:46:40 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-02-02 11:46:40 | INFO | train | epoch 056 | loss 7.233 | ppl 150.44 | wps 5837.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3584 | lr 0.00044801 | gnorm 0.53 | train_wall 328 | gb_free 6.1 | wall 20090
KL Stats: Epoch 56 Divergences: Uniform: 2.613506553334974 Unigram: 2.603840175862319
2022-02-02 11:46:40 | INFO | fairseq.trainer | begin training epoch 57
2022-02-02 11:46:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:48:04 | INFO | train_inner | epoch 057:     16 / 64 loss=7.24, ppl=151.15, wps=5697, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=3600, lr=0.00045001, gnorm=0.524, train_wall=513, gb_free=6.1, wall=20174
2022-02-02 11:52:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:52:38 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.181 | ppl 580.42 | wps 7937.7 | wpb 2034.1 | bsz 4 | num_updates 3648 | best_loss 9.181
2022-02-02 11:52:38 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-02-02 11:52:38 | INFO | train | epoch 057 | loss 7.186 | ppl 145.66 | wps 5821.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3648 | lr 0.000456009 | gnorm 0.527 | train_wall 329 | gb_free 6.1 | wall 20449
KL Stats: Epoch 57 Divergences: Uniform: 2.6298363300836516 Unigram: 2.623621466950316
2022-02-02 11:52:38 | INFO | fairseq.trainer | begin training epoch 58
2022-02-02 11:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 11:57:06 | INFO | train_inner | epoch 058:     52 / 64 loss=7.163, ppl=143.28, wps=6024.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=3700, lr=0.000462508, gnorm=0.531, train_wall=512, gb_free=6.1, wall=20717
2022-02-02 11:58:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 11:58:34 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.23 | ppl 600.63 | wps 7883.2 | wpb 2034.1 | bsz 4 | num_updates 3712 | best_loss 9.23
2022-02-02 11:58:34 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-02-02 11:58:34 | INFO | train | epoch 058 | loss 7.139 | ppl 140.91 | wps 5866.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3712 | lr 0.000464007 | gnorm 0.536 | train_wall 327 | gb_free 6.1 | wall 20805
KL Stats: Epoch 58 Divergences: Uniform: 2.6424655488899322 Unigram: 2.6400424205510817
2022-02-02 11:58:34 | INFO | fairseq.trainer | begin training epoch 59
2022-02-02 11:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:04:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 12:04:31 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.228 | ppl 599.82 | wps 7922.1 | wpb 2034.1 | bsz 4 | num_updates 3776 | best_loss 9.228
2022-02-02 12:04:31 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-02-02 12:04:31 | INFO | train | epoch 059 | loss 7.094 | ppl 136.61 | wps 5864.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3776 | lr 0.000472006 | gnorm 0.546 | train_wall 327 | gb_free 6.1 | wall 21161
KL Stats: Epoch 59 Divergences: Uniform: 2.664349787826809 Unigram: 2.657658149653205
2022-02-02 12:04:31 | INFO | fairseq.trainer | begin training epoch 60
2022-02-02 12:04:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:06:34 | INFO | train_inner | epoch 060:     24 / 64 loss=7.084, ppl=135.67, wps=5738.7, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=3800, lr=0.000475005, gnorm=0.535, train_wall=510, gb_free=6.1, wall=21285
2022-02-02 12:09:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:10:27 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.253 | ppl 610.33 | wps 7878.9 | wpb 2034.1 | bsz 4 | num_updates 3840 | best_loss 9.232
2022-02-02 12:10:27 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-02-02 12:10:27 | INFO | train | epoch 060 | loss 7.048 | ppl 132.32 | wps 5862.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3840 | lr 0.000480004 | gnorm 0.529 | train_wall 327 | gb_free 6.1 | wall 21517
KL Stats: Epoch 60 Divergences: Uniform: 2.664865477054425 Unigram: 2.679306304248449
2022-02-02 12:10:27 | INFO | fairseq.trainer | begin training epoch 61
2022-02-02 12:10:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:15:36 | INFO | train_inner | epoch 061:     60 / 64 loss=7.03, ppl=130.73, wps=6028.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=3900, lr=0.000487503, gnorm=0.545, train_wall=512, gb_free=6.1, wall=21827
2022-02-02 12:15:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:16:23 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.186 | ppl 582.44 | wps 7894.9 | wpb 2034.1 | bsz 4 | num_updates 3904 | best_loss 9.186
2022-02-02 12:16:23 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-02-02 12:16:23 | INFO | train | epoch 061 | loss 7.004 | ppl 128.39 | wps 5859.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3904 | lr 0.000488002 | gnorm 0.551 | train_wall 327 | gb_free 6.1 | wall 21874
KL Stats: Epoch 61 Divergences: Uniform: 2.678901767180435 Unigram: 2.6981892231248295
2022-02-02 12:16:23 | INFO | fairseq.trainer | begin training epoch 62
2022-02-02 12:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:21:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:22:20 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.244 | ppl 606.32 | wps 7889.4 | wpb 2034.1 | bsz 4 | num_updates 3968 | best_loss 9.232
2022-02-02 12:22:20 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-02-02 12:22:20 | INFO | train | epoch 062 | loss 6.962 | ppl 124.64 | wps 5861.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 3968 | lr 0.000496001 | gnorm 0.553 | train_wall 327 | gb_free 6.1 | wall 22230
KL Stats: Epoch 62 Divergences: Uniform: 2.698312411454324 Unigram: 2.7202111243990013
2022-02-02 12:22:20 | INFO | fairseq.trainer | begin training epoch 63
2022-02-02 12:22:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:25:05 | INFO | train_inner | epoch 063:     32 / 64 loss=6.938, ppl=122.59, wps=5734.6, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4000, lr=0.0005, gnorm=0.551, train_wall=510, gb_free=6.1, wall=22395
2022-02-02 12:27:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:28:16 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.241 | ppl 604.94 | wps 7874.3 | wpb 2034.1 | bsz 4 | num_updates 4032 | best_loss 9.232
2022-02-02 12:28:16 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-02-02 12:28:16 | INFO | train | epoch 063 | loss 6.917 | ppl 120.84 | wps 5855 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4032 | lr 0.000498012 | gnorm 0.541 | train_wall 327 | gb_free 6.1 | wall 22587
KL Stats: Epoch 63 Divergences: Uniform: 2.716301916548267 Unigram: 2.7345301399112434
2022-02-02 12:28:16 | INFO | fairseq.trainer | begin training epoch 64
2022-02-02 12:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:33:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:34:13 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.294 | ppl 627.83 | wps 7871.1 | wpb 2034.1 | bsz 4 | num_updates 4096 | best_loss 9.232
2022-02-02 12:34:13 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-02-02 12:34:13 | INFO | train | epoch 064 | loss 6.875 | ppl 117.39 | wps 5857.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4096 | lr 0.000494106 | gnorm 0.566 | train_wall 327 | gb_free 6.1 | wall 22943
KL Stats: Epoch 64 Divergences: Uniform: 2.723115810753238 Unigram: 2.756221401389842
2022-02-02 12:34:13 | INFO | fairseq.trainer | begin training epoch 65
2022-02-02 12:34:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:34:34 | INFO | train_inner | epoch 065:      4 / 64 loss=6.896, ppl=119.12, wps=5729.2, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4100, lr=0.000493865, gnorm=0.557, train_wall=511, gb_free=6.1, wall=22964
2022-02-02 12:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:40:10 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.335 | ppl 645.83 | wps 7905.6 | wpb 2034.1 | bsz 4 | num_updates 4160 | best_loss 9.232
2022-02-02 12:40:10 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-02-02 12:40:10 | INFO | train | epoch 065 | loss 6.831 | ppl 113.86 | wps 5851.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4160 | lr 0.00049029 | gnorm 0.555 | train_wall 328 | gb_free 6.1 | wall 23300
KL Stats: Epoch 65 Divergences: Uniform: 2.737646705565641 Unigram: 2.774107440439691
2022-02-02 12:40:10 | INFO | fairseq.trainer | begin training epoch 66
2022-02-02 12:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:43:36 | INFO | train_inner | epoch 066:     40 / 64 loss=6.807, ppl=111.98, wps=6027.9, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=4200, lr=0.00048795, gnorm=0.553, train_wall=512, gb_free=6.1, wall=23506
2022-02-02 12:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:46:06 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 9.373 | ppl 663.1 | wps 7916.4 | wpb 2034.1 | bsz 4 | num_updates 4224 | best_loss 9.232
2022-02-02 12:46:06 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-02-02 12:46:06 | INFO | train | epoch 066 | loss 6.791 | ppl 110.7 | wps 5865.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4224 | lr 0.000486562 | gnorm 0.557 | train_wall 327 | gb_free 6.1 | wall 23657
KL Stats: Epoch 66 Divergences: Uniform: 2.7398714401221413 Unigram: 2.7868479252708154
2022-02-02 12:46:06 | INFO | fairseq.trainer | begin training epoch 67
2022-02-02 12:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 12:52:03 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 9.301 | ppl 630.81 | wps 7864.7 | wpb 2034.1 | bsz 4 | num_updates 4288 | best_loss 9.232
2022-02-02 12:52:03 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-02-02 12:52:03 | INFO | train | epoch 067 | loss 6.749 | ppl 107.6 | wps 5857.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4288 | lr 0.000482917 | gnorm 0.566 | train_wall 327 | gb_free 6.1 | wall 24013
KL Stats: Epoch 67 Divergences: Uniform: 2.766313309675844 Unigram: 2.8126772072280293
2022-02-02 12:52:03 | INFO | fairseq.trainer | begin training epoch 68
2022-02-02 12:52:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 12:53:04 | INFO | train_inner | epoch 068:     12 / 64 loss=6.76, ppl=108.42, wps=5734.7, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4300, lr=0.000482243, gnorm=0.569, train_wall=510, gb_free=6.1, wall=24075
2022-02-02 12:57:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 12:57:59 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 9.345 | ppl 650.47 | wps 7909.7 | wpb 2034.1 | bsz 4 | num_updates 4352 | best_loss 9.232
2022-02-02 12:57:59 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-02-02 12:57:59 | INFO | train | epoch 068 | loss 6.711 | ppl 104.73 | wps 5867.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4352 | lr 0.000479353 | gnorm 0.563 | train_wall 327 | gb_free 6.1 | wall 24369
KL Stats: Epoch 68 Divergences: Uniform: 2.770221429986526 Unigram: 2.82044375350197
2022-02-02 12:57:59 | INFO | fairseq.trainer | begin training epoch 69
2022-02-02 12:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:02:06 | INFO | train_inner | epoch 069:     48 / 64 loss=6.687, ppl=103.06, wps=6034.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4400, lr=0.000476731, gnorm=0.566, train_wall=511, gb_free=6.1, wall=24616
2022-02-02 13:03:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:03:55 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 9.33 | ppl 643.57 | wps 7871.9 | wpb 2034.1 | bsz 4 | num_updates 4416 | best_loss 9.232
2022-02-02 13:03:55 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-02-02 13:03:55 | INFO | train | epoch 069 | loss 6.674 | ppl 102.12 | wps 5860.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4416 | lr 0.000475867 | gnorm 0.573 | train_wall 327 | gb_free 6.1 | wall 24725
KL Stats: Epoch 69 Divergences: Uniform: 2.7908506326764306 Unigram: 2.8514522553760107
2022-02-02 13:03:55 | INFO | fairseq.trainer | begin training epoch 70
2022-02-02 13:03:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:09:51 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 9.349 | ppl 652.17 | wps 7887.5 | wpb 2034.1 | bsz 4 | num_updates 4480 | best_loss 9.232
2022-02-02 13:09:51 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-02-02 13:09:51 | INFO | train | epoch 070 | loss 6.635 | ppl 99.36 | wps 5863.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4480 | lr 0.000472456 | gnorm 0.567 | train_wall 327 | gb_free 6.1 | wall 25082
KL Stats: Epoch 70 Divergences: Uniform: 2.7967332318471474 Unigram: 2.864734191022552
2022-02-02 13:09:51 | INFO | fairseq.trainer | begin training epoch 71
2022-02-02 13:09:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:11:34 | INFO | train_inner | epoch 071:     20 / 64 loss=6.633, ppl=99.25, wps=5736.1, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4500, lr=0.000471405, gnorm=0.57, train_wall=510, gb_free=6.1, wall=25185
2022-02-02 13:15:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:15:48 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 9.357 | ppl 655.54 | wps 7898.4 | wpb 2034.1 | bsz 4 | num_updates 4544 | best_loss 9.232
2022-02-02 13:15:48 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-02-02 13:15:48 | INFO | train | epoch 071 | loss 6.599 | ppl 96.93 | wps 5860.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4544 | lr 0.000469117 | gnorm 0.564 | train_wall 327 | gb_free 6.1 | wall 25438
KL Stats: Epoch 71 Divergences: Uniform: 2.8094766606662307 Unigram: 2.8906740513686016
2022-02-02 13:15:48 | INFO | fairseq.trainer | begin training epoch 72
2022-02-02 13:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:20:36 | INFO | train_inner | epoch 072:     56 / 64 loss=6.585, ppl=96.02, wps=6029.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4600, lr=0.000466252, gnorm=0.566, train_wall=512, gb_free=6.1, wall=25727
2022-02-02 13:21:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:21:44 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 9.33 | ppl 643.72 | wps 7943.2 | wpb 2034.1 | bsz 4 | num_updates 4608 | best_loss 9.232
2022-02-02 13:21:44 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-02-02 13:21:44 | INFO | train | epoch 072 | loss 6.565 | ppl 94.7 | wps 5864.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4608 | lr 0.000465847 | gnorm 0.573 | train_wall 327 | gb_free 6.1 | wall 25794
KL Stats: Epoch 72 Divergences: Uniform: 2.8154324067205097 Unigram: 2.8961960213267957
2022-02-02 13:21:44 | INFO | fairseq.trainer | begin training epoch 73
2022-02-02 13:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:27:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:27:40 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 9.376 | ppl 664.23 | wps 7904.9 | wpb 2034.1 | bsz 4 | num_updates 4672 | best_loss 9.232
2022-02-02 13:27:40 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-02-02 13:27:40 | INFO | train | epoch 073 | loss 6.531 | ppl 92.49 | wps 5862.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4672 | lr 0.000462646 | gnorm 0.576 | train_wall 327 | gb_free 6.1 | wall 26150
KL Stats: Epoch 73 Divergences: Uniform: 2.8189937472608 Unigram: 2.9204242712013255
2022-02-02 13:27:40 | INFO | fairseq.trainer | begin training epoch 74
2022-02-02 13:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:30:04 | INFO | train_inner | epoch 074:     28 / 64 loss=6.518, ppl=91.67, wps=5738.2, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=4700, lr=0.000461266, gnorm=0.577, train_wall=510, gb_free=6.1, wall=26295
2022-02-02 13:33:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:33:37 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 9.387 | ppl 669.48 | wps 7881.4 | wpb 2034.1 | bsz 4 | num_updates 4736 | best_loss 9.232
2022-02-02 13:33:37 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-02-02 13:33:37 | INFO | train | epoch 074 | loss 6.499 | ppl 90.44 | wps 5853.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4736 | lr 0.000459509 | gnorm 0.589 | train_wall 327 | gb_free 6.1 | wall 26507
KL Stats: Epoch 74 Divergences: Uniform: 2.8349536005994556 Unigram: 2.934558519616531
2022-02-02 13:33:37 | INFO | fairseq.trainer | begin training epoch 75
2022-02-02 13:33:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:39:06 | INFO | train_inner | epoch 075:     64 / 64 loss=6.49, ppl=89.9, wps=6020.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=4800, lr=0.000456435, gnorm=0.587, train_wall=511, gb_free=6.1, wall=26836
2022-02-02 13:39:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:39:34 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 9.382 | ppl 667.03 | wps 7887.3 | wpb 2034.1 | bsz 4 | num_updates 4800 | best_loss 9.232
2022-02-02 13:39:34 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-02-02 13:39:34 | INFO | train | epoch 075 | loss 6.467 | ppl 88.46 | wps 5853.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4800 | lr 0.000456435 | gnorm 0.582 | train_wall 327 | gb_free 6.1 | wall 26864
KL Stats: Epoch 75 Divergences: Uniform: 2.8441827408324545 Unigram: 2.9465384556355074
2022-02-02 13:39:34 | INFO | fairseq.trainer | begin training epoch 76
2022-02-02 13:39:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:45:30 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 9.414 | ppl 682.37 | wps 7914.9 | wpb 2034.1 | bsz 4 | num_updates 4864 | best_loss 9.232
2022-02-02 13:45:30 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-02-02 13:45:30 | INFO | train | epoch 076 | loss 6.437 | ppl 86.63 | wps 5862.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4864 | lr 0.000453423 | gnorm 0.6 | train_wall 327 | gb_free 6.1 | wall 27220
KL Stats: Epoch 76 Divergences: Uniform: 2.8584155096671235 Unigram: 2.9643411804610658
2022-02-02 13:45:30 | INFO | fairseq.trainer | begin training epoch 77
2022-02-02 13:45:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:48:35 | INFO | train_inner | epoch 077:     36 / 64 loss=6.416, ppl=85.41, wps=5738.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=4900, lr=0.000451754, gnorm=0.595, train_wall=511, gb_free=6.1, wall=27406
2022-02-02 13:50:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:51:26 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 9.418 | ppl 684.2 | wps 7903.5 | wpb 2034.1 | bsz 4 | num_updates 4928 | best_loss 9.232
2022-02-02 13:51:26 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-02-02 13:51:26 | INFO | train | epoch 077 | loss 6.408 | ppl 84.92 | wps 5865.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4928 | lr 0.000450469 | gnorm 0.6 | train_wall 327 | gb_free 6.1 | wall 27576
KL Stats: Epoch 77 Divergences: Uniform: 2.862509853936173 Unigram: 2.98491346597989
2022-02-02 13:51:26 | INFO | fairseq.trainer | begin training epoch 78
2022-02-02 13:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:56:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 13:57:22 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 9.417 | ppl 683.75 | wps 7879.9 | wpb 2034.1 | bsz 4 | num_updates 4992 | best_loss 9.232
2022-02-02 13:57:22 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-02-02 13:57:22 | INFO | train | epoch 078 | loss 6.378 | ppl 83.17 | wps 5858.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 4992 | lr 0.000447572 | gnorm 0.601 | train_wall 327 | gb_free 6.1 | wall 27933
KL Stats: Epoch 78 Divergences: Uniform: 2.8735109211548773 Unigram: 2.993588578261855
2022-02-02 13:57:22 | INFO | fairseq.trainer | begin training epoch 79
2022-02-02 13:57:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 13:58:04 | INFO | train_inner | epoch 079:      8 / 64 loss=6.388, ppl=83.75, wps=5735.5, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=5000, lr=0.000447214, gnorm=0.607, train_wall=510, gb_free=6.1, wall=27974
2022-02-02 14:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
Traceback (most recent call last):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
2022-02-02 14:03:19 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 9.376 | ppl 664.22 | wps 7899.5 | wpb 2034.1 | bsz 4 | num_updates 5056 | best_loss 9.232
2022-02-02 14:03:19 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-02-02 14:03:19 | INFO | train | epoch 079 | loss 6.351 | ppl 81.62 | wps 5864.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5056 | lr 0.00044473 | gnorm 0.603 | train_wall 327 | gb_free 6.1 | wall 28289
KL Stats: Epoch 79 Divergences: Uniform: 2.880840815600426 Unigram: 3.0128930117678654
2022-02-02 14:03:19 | INFO | fairseq.trainer | begin training epoch 80
2022-02-02 14:03:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:07:07 | INFO | train_inner | epoch 080:     44 / 64 loss=6.334, ppl=80.65, wps=6018.5, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5100, lr=0.000442807, gnorm=0.609, train_wall=513, gb_free=6.1, wall=28517
2022-02-02 14:08:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:09:18 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 9.424 | ppl 686.84 | wps 7753 | wpb 2034.1 | bsz 4 | num_updates 5120 | best_loss 9.232
2022-02-02 14:09:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 5120 updates
2022-02-02 14:09:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt
2022-02-02 14:09:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt
2022-02-02 14:09:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint80.pt (epoch 80 @ 5120 updates, score 9.424) (writing took 3.4619406703859568 seconds)
2022-02-02 14:09:22 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-02-02 14:09:22 | INFO | train | epoch 080 | loss 6.323 | ppl 80.07 | wps 5751.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5120 | lr 0.000441942 | gnorm 0.619 | train_wall 330 | gb_free 6.1 | wall 28652
KL Stats: Epoch 80 Divergences: Uniform: 2.8895744576858404 Unigram: 3.034613179250447
2022-02-02 14:09:22 | INFO | fairseq.trainer | begin training epoch 81
2022-02-02 14:09:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:14:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:15:24 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 9.441 | ppl 695.1 | wps 7748.9 | wpb 2034.1 | bsz 4 | num_updates 5184 | best_loss 9.232
2022-02-02 14:15:24 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-02-02 14:15:24 | INFO | train | epoch 081 | loss 6.296 | ppl 78.57 | wps 5765.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5184 | lr 0.000439205 | gnorm 0.613 | train_wall 332 | gb_free 6.1 | wall 29014
KL Stats: Epoch 81 Divergences: Uniform: 2.903866805767833 Unigram: 3.0448937456289293
2022-02-02 14:15:24 | INFO | fairseq.trainer | begin training epoch 82
2022-02-02 14:15:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:16:48 | INFO | train_inner | epoch 082:     16 / 64 loss=6.301, ppl=78.87, wps=5607.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5200, lr=0.000438529, gnorm=0.613, train_wall=518, gb_free=6.1, wall=29099
2022-02-02 14:20:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:21:27 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 9.485 | ppl 716.37 | wps 7714.1 | wpb 2034.1 | bsz 4 | num_updates 5248 | best_loss 9.232
2022-02-02 14:21:27 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-02-02 14:21:27 | INFO | train | epoch 082 | loss 6.27 | ppl 77.19 | wps 5756.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5248 | lr 0.000436519 | gnorm 0.614 | train_wall 333 | gb_free 6.1 | wall 29377
KL Stats: Epoch 82 Divergences: Uniform: 2.9040142459124394 Unigram: 3.059938159456689
2022-02-02 14:21:27 | INFO | fairseq.trainer | begin training epoch 83
2022-02-02 14:21:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:25:59 | INFO | train_inner | epoch 083:     52 / 64 loss=6.256, ppl=76.42, wps=5926.8, ups=0.18, wpb=32686.1, bsz=63.8, num_updates=5300, lr=0.000434372, gnorm=0.619, train_wall=520, gb_free=6.1, wall=29650
2022-02-02 14:27:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:27:29 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 9.496 | ppl 722.15 | wps 7710.8 | wpb 2034.1 | bsz 4 | num_updates 5312 | best_loss 9.232
2022-02-02 14:27:29 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-02-02 14:27:29 | INFO | train | epoch 083 | loss 6.244 | ppl 75.79 | wps 5757.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5312 | lr 0.000433881 | gnorm 0.627 | train_wall 333 | gb_free 6.1 | wall 29740
KL Stats: Epoch 83 Divergences: Uniform: 2.913725297185404 Unigram: 3.0709923383557842
2022-02-02 14:27:30 | INFO | fairseq.trainer | begin training epoch 84
2022-02-02 14:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:33:33 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 9.474 | ppl 711.31 | wps 7692 | wpb 2034.1 | bsz 4 | num_updates 5376 | best_loss 9.232
2022-02-02 14:33:33 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-02-02 14:33:33 | INFO | train | epoch 084 | loss 6.222 | ppl 74.66 | wps 5752.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5376 | lr 0.000431291 | gnorm 0.648 | train_wall 333 | gb_free 6.1 | wall 30103
KL Stats: Epoch 84 Divergences: Uniform: 2.920557479037214 Unigram: 3.0848418019688824
2022-02-02 14:33:33 | INFO | fairseq.trainer | begin training epoch 85
2022-02-02 14:33:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:35:39 | INFO | train_inner | epoch 085:     24 / 64 loss=6.214, ppl=74.25, wps=5629.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5400, lr=0.000430331, gnorm=0.648, train_wall=520, gb_free=6.1, wall=30229
2022-02-02 14:39:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:39:35 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 9.508 | ppl 728.14 | wps 7712 | wpb 2034.1 | bsz 4 | num_updates 5440 | best_loss 9.232
2022-02-02 14:39:35 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-02-02 14:39:35 | INFO | train | epoch 085 | loss 6.196 | ppl 73.29 | wps 5755.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5440 | lr 0.000428746 | gnorm 0.639 | train_wall 333 | gb_free 6.1 | wall 30466
KL Stats: Epoch 85 Divergences: Uniform: 2.924701630989816 Unigram: 3.1020679498216177
2022-02-02 14:39:36 | INFO | fairseq.trainer | begin training epoch 86
2022-02-02 14:39:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:44:50 | INFO | train_inner | epoch 086:     60 / 64 loss=6.192, ppl=73.13, wps=5925.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=5500, lr=0.000426401, gnorm=0.638, train_wall=520, gb_free=6.1, wall=30781
2022-02-02 14:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:45:38 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 9.465 | ppl 706.72 | wps 7764.9 | wpb 2034.1 | bsz 4 | num_updates 5504 | best_loss 9.232
2022-02-02 14:45:38 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-02-02 14:45:38 | INFO | train | epoch 086 | loss 6.173 | ppl 72.18 | wps 5763.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5504 | lr 0.000426246 | gnorm 0.64 | train_wall 333 | gb_free 6.1 | wall 30828
KL Stats: Epoch 86 Divergences: Uniform: 2.9342950266623467 Unigram: 3.1138233862291482
2022-02-02 14:45:38 | INFO | fairseq.trainer | begin training epoch 87
2022-02-02 14:45:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:51:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:51:40 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 9.532 | ppl 740.28 | wps 7704.6 | wpb 2034.1 | bsz 4 | num_updates 5568 | best_loss 9.232
2022-02-02 14:51:40 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-02-02 14:51:40 | INFO | train | epoch 087 | loss 6.149 | ppl 70.95 | wps 5768.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5568 | lr 0.00042379 | gnorm 0.644 | train_wall 332 | gb_free 6.1 | wall 31191
KL Stats: Epoch 87 Divergences: Uniform: 2.9387296038736412 Unigram: 3.128398265618512
2022-02-02 14:51:40 | INFO | fairseq.trainer | begin training epoch 88
2022-02-02 14:51:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 14:54:28 | INFO | train_inner | epoch 088:     32 / 64 loss=6.133, ppl=70.19, wps=5641.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5600, lr=0.000422577, gnorm=0.64, train_wall=518, gb_free=6.1, wall=31358
2022-02-02 14:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 14:57:42 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 9.536 | ppl 742.32 | wps 7759 | wpb 2034.1 | bsz 4 | num_updates 5632 | best_loss 9.232
2022-02-02 14:57:42 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-02-02 14:57:42 | INFO | train | epoch 088 | loss 6.128 | ppl 69.96 | wps 5762.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5632 | lr 0.000421375 | gnorm 0.642 | train_wall 333 | gb_free 6.1 | wall 31553
KL Stats: Epoch 88 Divergences: Uniform: 2.9487385291604533 Unigram: 3.136831355740428
2022-02-02 14:57:42 | INFO | fairseq.trainer | begin training epoch 89
2022-02-02 14:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:03:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:03:44 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 9.509 | ppl 728.5 | wps 7748.2 | wpb 2034.1 | bsz 4 | num_updates 5696 | best_loss 9.232
2022-02-02 15:03:44 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-02-02 15:03:44 | INFO | train | epoch 089 | loss 6.105 | ppl 68.85 | wps 5769 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5696 | lr 0.000419001 | gnorm 0.641 | train_wall 332 | gb_free 6.1 | wall 31915
KL Stats: Epoch 89 Divergences: Uniform: 2.954720506655392 Unigram: 3.1498722857599306
2022-02-02 15:03:45 | INFO | fairseq.trainer | begin training epoch 90
2022-02-02 15:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:04:06 | INFO | train_inner | epoch 090:      4 / 64 loss=6.122, ppl=69.65, wps=5643.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=5700, lr=0.000418854, gnorm=0.645, train_wall=519, gb_free=6.1, wall=31936
2022-02-02 15:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:09:47 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 9.578 | ppl 764.38 | wps 7746.1 | wpb 2034.1 | bsz 4 | num_updates 5760 | best_loss 9.232
2022-02-02 15:09:47 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-02-02 15:09:47 | INFO | train | epoch 090 | loss 6.084 | ppl 67.83 | wps 5762.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5760 | lr 0.000416667 | gnorm 0.641 | train_wall 332 | gb_free 6.1 | wall 32277
KL Stats: Epoch 90 Divergences: Uniform: 2.958266311574395 Unigram: 3.1603648696430406
2022-02-02 15:09:47 | INFO | fairseq.trainer | begin training epoch 91
2022-02-02 15:09:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:13:16 | INFO | train_inner | epoch 091:     40 / 64 loss=6.063, ppl=66.87, wps=5932.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=5800, lr=0.000415227, gnorm=0.647, train_wall=520, gb_free=6.1, wall=32487
2022-02-02 15:15:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:15:49 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 9.554 | ppl 751.88 | wps 7740.7 | wpb 2034.1 | bsz 4 | num_updates 5824 | best_loss 9.232
2022-02-02 15:15:49 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-02-02 15:15:49 | INFO | train | epoch 091 | loss 6.063 | ppl 66.84 | wps 5767.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5824 | lr 0.000414371 | gnorm 0.655 | train_wall 332 | gb_free 6.1 | wall 32640
KL Stats: Epoch 91 Divergences: Uniform: 2.9606722265786187 Unigram: 3.1830085137659743
2022-02-02 15:15:49 | INFO | fairseq.trainer | begin training epoch 92
2022-02-02 15:15:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:21:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:21:51 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 9.545 | ppl 746.89 | wps 7744.4 | wpb 2034.1 | bsz 4 | num_updates 5888 | best_loss 9.232
2022-02-02 15:21:51 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-02-02 15:21:51 | INFO | train | epoch 092 | loss 6.046 | ppl 66.09 | wps 5768.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5888 | lr 0.000412113 | gnorm 0.687 | train_wall 332 | gb_free 6.1 | wall 33002
KL Stats: Epoch 92 Divergences: Uniform: 2.9687531649457894 Unigram: 3.189278994144147
2022-02-02 15:21:51 | INFO | fairseq.trainer | begin training epoch 93
2022-02-02 15:21:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:22:54 | INFO | train_inner | epoch 093:     12 / 64 loss=6.054, ppl=66.43, wps=5644.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=5900, lr=0.000411693, gnorm=0.676, train_wall=518, gb_free=6.1, wall=33065
2022-02-02 15:27:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:27:53 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 9.532 | ppl 740.12 | wps 7746.6 | wpb 2034.1 | bsz 4 | num_updates 5952 | best_loss 9.232
2022-02-02 15:27:53 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-02-02 15:27:53 | INFO | train | epoch 093 | loss 6.023 | ppl 65.02 | wps 5764.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 5952 | lr 0.000409891 | gnorm 0.659 | train_wall 332 | gb_free 6.1 | wall 33364
KL Stats: Epoch 93 Divergences: Uniform: 2.9849490717258447 Unigram: 3.2019777118075017
2022-02-02 15:27:53 | INFO | fairseq.trainer | begin training epoch 94
2022-02-02 15:27:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:32:05 | INFO | train_inner | epoch 094:     48 / 64 loss=6.012, ppl=64.51, wps=5929.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6000, lr=0.000408248, gnorm=0.667, train_wall=520, gb_free=6.1, wall=33616
2022-02-02 15:33:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:33:56 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 9.63 | ppl 792.32 | wps 7740.6 | wpb 2034.1 | bsz 4 | num_updates 6016 | best_loss 9.232
2022-02-02 15:33:56 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-02-02 15:33:56 | INFO | train | epoch 094 | loss 6.004 | ppl 64.17 | wps 5762.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6016 | lr 0.000407705 | gnorm 0.677 | train_wall 332 | gb_free 6.1 | wall 33726
KL Stats: Epoch 94 Divergences: Uniform: 2.9789358367403507 Unigram: 3.2165215240813763
2022-02-02 15:33:56 | INFO | fairseq.trainer | begin training epoch 95
2022-02-02 15:33:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:39:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:39:58 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 9.563 | ppl 756.31 | wps 7750.7 | wpb 2034.1 | bsz 4 | num_updates 6080 | best_loss 9.232
2022-02-02 15:39:58 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-02-02 15:39:58 | INFO | train | epoch 095 | loss 5.983 | ppl 63.26 | wps 5771 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6080 | lr 0.000405554 | gnorm 0.658 | train_wall 332 | gb_free 6.1 | wall 34088
KL Stats: Epoch 95 Divergences: Uniform: 2.9912440138713974 Unigram: 3.227711906551627
2022-02-02 15:39:58 | INFO | fairseq.trainer | begin training epoch 96
2022-02-02 15:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:41:43 | INFO | train_inner | epoch 096:     20 / 64 loss=5.978, ppl=63.02, wps=5643.4, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6100, lr=0.000404888, gnorm=0.667, train_wall=518, gb_free=6.1, wall=34193
2022-02-02 15:45:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:46:01 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 9.635 | ppl 794.89 | wps 7757.8 | wpb 2034.1 | bsz 4 | num_updates 6144 | best_loss 9.232
2022-02-02 15:46:01 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-02-02 15:46:01 | INFO | train | epoch 096 | loss 5.966 | ppl 62.5 | wps 5755.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6144 | lr 0.000403436 | gnorm 0.686 | train_wall 333 | gb_free 6.1 | wall 34451
KL Stats: Epoch 96 Divergences: Uniform: 2.9886605194606517 Unigram: 3.2443216463961817
2022-02-02 15:46:01 | INFO | fairseq.trainer | begin training epoch 97
2022-02-02 15:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:50:54 | INFO | train_inner | epoch 097:     56 / 64 loss=5.969, ppl=62.62, wps=5926.7, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6200, lr=0.00040161, gnorm=0.679, train_wall=521, gb_free=6.1, wall=34745
2022-02-02 15:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:52:03 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 9.59 | ppl 770.48 | wps 7712.8 | wpb 2034.1 | bsz 4 | num_updates 6208 | best_loss 9.232
2022-02-02 15:52:03 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-02-02 15:52:03 | INFO | train | epoch 097 | loss 5.947 | ppl 61.69 | wps 5763.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6208 | lr 0.000401351 | gnorm 0.677 | train_wall 332 | gb_free 6.1 | wall 34814
KL Stats: Epoch 97 Divergences: Uniform: 2.99899519828495 Unigram: 3.2520551804272904
2022-02-02 15:52:03 | INFO | fairseq.trainer | begin training epoch 98
2022-02-02 15:52:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 15:57:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 15:58:05 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 9.642 | ppl 798.92 | wps 7728.7 | wpb 2034.1 | bsz 4 | num_updates 6272 | best_loss 9.232
2022-02-02 15:58:05 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-02-02 15:58:05 | INFO | train | epoch 098 | loss 5.929 | ppl 60.94 | wps 5768.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6272 | lr 0.000399298 | gnorm 0.691 | train_wall 332 | gb_free 6.1 | wall 35176
KL Stats: Epoch 98 Divergences: Uniform: 2.99909697550432 Unigram: 3.2663341375969805
2022-02-02 15:58:05 | INFO | fairseq.trainer | begin training epoch 99
2022-02-02 15:58:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:00:32 | INFO | train_inner | epoch 099:     28 / 64 loss=5.913, ppl=60.26, wps=5642.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6300, lr=0.00039841, gnorm=0.699, train_wall=518, gb_free=6.1, wall=35323
2022-02-02 16:03:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:04:08 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 9.636 | ppl 795.83 | wps 7708.6 | wpb 2034.1 | bsz 4 | num_updates 6336 | best_loss 9.232
2022-02-02 16:04:08 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-02-02 16:04:08 | INFO | train | epoch 099 | loss 5.912 | ppl 60.21 | wps 5750.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6336 | lr 0.000397276 | gnorm 0.698 | train_wall 333 | gb_free 6.1 | wall 35539
KL Stats: Epoch 99 Divergences: Uniform: 3.0125737270671844 Unigram: 3.279068398041774
2022-02-02 16:04:08 | INFO | fairseq.trainer | begin training epoch 100
2022-02-02 16:04:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:09:43 | INFO | train_inner | epoch 100:     64 / 64 loss=5.915, ppl=60.33, wps=5920.4, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=6400, lr=0.000395285, gnorm=0.689, train_wall=519, gb_free=6.1, wall=35873
2022-02-02 16:09:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:10:11 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 9.585 | ppl 768.12 | wps 7712.3 | wpb 2034.1 | bsz 4 | num_updates 6400 | best_loss 9.232
2022-02-02 16:10:11 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-02-02 16:10:11 | INFO | train | epoch 100 | loss 5.895 | ppl 59.49 | wps 5761.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6400 | lr 0.000395285 | gnorm 0.692 | train_wall 332 | gb_free 6.1 | wall 35901
KL Stats: Epoch 100 Divergences: Uniform: 3.0197107431045174 Unigram: 3.2911315473301697
2022-02-02 16:10:11 | INFO | fairseq.trainer | begin training epoch 101
2022-02-02 16:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:16:13 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 9.637 | ppl 796.29 | wps 7748.1 | wpb 2034.1 | bsz 4 | num_updates 6464 | best_loss 9.232
2022-02-02 16:16:13 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-02-02 16:16:13 | INFO | train | epoch 101 | loss 5.878 | ppl 58.82 | wps 5766.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6464 | lr 0.000393323 | gnorm 0.698 | train_wall 332 | gb_free 6.1 | wall 36264
KL Stats: Epoch 101 Divergences: Uniform: 3.0144030868980654 Unigram: 3.3001726468404136
2022-02-02 16:16:13 | INFO | fairseq.trainer | begin training epoch 102
2022-02-02 16:16:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:19:22 | INFO | train_inner | epoch 102:     36 / 64 loss=5.861, ppl=58.12, wps=5641.5, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=6500, lr=0.000392232, gnorm=0.705, train_wall=520, gb_free=6.1, wall=36452
2022-02-02 16:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:22:16 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 9.619 | ppl 786.24 | wps 7724.7 | wpb 2034.1 | bsz 4 | num_updates 6528 | best_loss 9.232
2022-02-02 16:22:16 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-02-02 16:22:16 | INFO | train | epoch 102 | loss 5.862 | ppl 58.18 | wps 5758.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6528 | lr 0.00039139 | gnorm 0.714 | train_wall 333 | gb_free 6.1 | wall 36626
KL Stats: Epoch 102 Divergences: Uniform: 3.023994308019605 Unigram: 3.3077396100963217
2022-02-02 16:22:16 | INFO | fairseq.trainer | begin training epoch 103
2022-02-02 16:22:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:27:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:28:18 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 9.647 | ppl 801.66 | wps 7712.6 | wpb 2034.1 | bsz 4 | num_updates 6592 | best_loss 9.232
2022-02-02 16:28:18 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-02-02 16:28:18 | INFO | train | epoch 103 | loss 5.847 | ppl 57.56 | wps 5758.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6592 | lr 0.000389486 | gnorm 0.728 | train_wall 333 | gb_free 6.1 | wall 36989
KL Stats: Epoch 103 Divergences: Uniform: 3.029078887083559 Unigram: 3.3186153809970294
2022-02-02 16:28:19 | INFO | fairseq.trainer | begin training epoch 104
2022-02-02 16:28:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:29:01 | INFO | train_inner | epoch 104:      8 / 64 loss=5.855, ppl=57.88, wps=5633.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=6600, lr=0.000389249, gnorm=0.722, train_wall=519, gb_free=6.1, wall=37031
2022-02-02 16:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:34:22 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 9.669 | ppl 814.04 | wps 7702.5 | wpb 2034.1 | bsz 4 | num_updates 6656 | best_loss 9.232
2022-02-02 16:34:22 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-02-02 16:34:22 | INFO | train | epoch 104 | loss 5.831 | ppl 56.93 | wps 5753.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6656 | lr 0.000387609 | gnorm 0.734 | train_wall 333 | gb_free 6.1 | wall 37352
KL Stats: Epoch 104 Divergences: Uniform: 3.0270360859034064 Unigram: 3.331126118997336
2022-02-02 16:34:22 | INFO | fairseq.trainer | begin training epoch 105
2022-02-02 16:34:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:38:12 | INFO | train_inner | epoch 105:     44 / 64 loss=5.821, ppl=56.53, wps=5924.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6700, lr=0.000386334, gnorm=0.734, train_wall=521, gb_free=6.1, wall=37583
2022-02-02 16:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:40:24 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 9.659 | ppl 808.29 | wps 7739.3 | wpb 2034.1 | bsz 4 | num_updates 6720 | best_loss 9.232
2022-02-02 16:40:24 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-02-02 16:40:24 | INFO | train | epoch 105 | loss 5.817 | ppl 56.36 | wps 5763.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6720 | lr 0.000385758 | gnorm 0.732 | train_wall 332 | gb_free 6.1 | wall 37714
KL Stats: Epoch 105 Divergences: Uniform: 3.0356220613836027 Unigram: 3.339916417612481
2022-02-02 16:40:24 | INFO | fairseq.trainer | begin training epoch 106
2022-02-02 16:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:46:26 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 9.649 | ppl 802.94 | wps 7704.3 | wpb 2034.1 | bsz 4 | num_updates 6784 | best_loss 9.232
2022-02-02 16:46:26 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-02-02 16:46:26 | INFO | train | epoch 106 | loss 5.799 | ppl 55.68 | wps 5762.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6784 | lr 0.000383934 | gnorm 0.723 | train_wall 332 | gb_free 6.1 | wall 38077
KL Stats: Epoch 106 Divergences: Uniform: 3.037862236320946 Unigram: 3.3518090891510024
2022-02-02 16:46:26 | INFO | fairseq.trainer | begin training epoch 107
2022-02-02 16:46:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:47:50 | INFO | train_inner | epoch 107:     16 / 64 loss=5.806, ppl=55.96, wps=5638.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=6800, lr=0.000383482, gnorm=0.729, train_wall=519, gb_free=6.1, wall=38161
2022-02-02 16:52:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:52:29 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 9.659 | ppl 808.37 | wps 7748.5 | wpb 2034.1 | bsz 4 | num_updates 6848 | best_loss 9.232
2022-02-02 16:52:29 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-02-02 16:52:29 | INFO | train | epoch 107 | loss 5.784 | ppl 55.11 | wps 5757.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6848 | lr 0.000382136 | gnorm 0.739 | train_wall 333 | gb_free 6.1 | wall 38440
KL Stats: Epoch 107 Divergences: Uniform: 3.044807242013802 Unigram: 3.3632085943454855
2022-02-02 16:52:29 | INFO | fairseq.trainer | begin training epoch 108
2022-02-02 16:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 16:57:02 | INFO | train_inner | epoch 108:     52 / 64 loss=5.776, ppl=54.8, wps=5928.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=6900, lr=0.000380693, gnorm=0.749, train_wall=520, gb_free=6.1, wall=38712
2022-02-02 16:58:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 16:58:31 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 9.682 | ppl 821.34 | wps 7730.4 | wpb 2034.1 | bsz 4 | num_updates 6912 | best_loss 9.232
2022-02-02 16:58:31 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-02-02 16:58:31 | INFO | train | epoch 108 | loss 5.771 | ppl 54.6 | wps 5764.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6912 | lr 0.000380363 | gnorm 0.751 | train_wall 332 | gb_free 6.1 | wall 38802
KL Stats: Epoch 108 Divergences: Uniform: 3.0498018203393333 Unigram: 3.3702291153401096
2022-02-02 16:58:31 | INFO | fairseq.trainer | begin training epoch 109
2022-02-02 16:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:04:34 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 9.675 | ppl 817.32 | wps 7740.8 | wpb 2034.1 | bsz 4 | num_updates 6976 | best_loss 9.232
2022-02-02 17:04:34 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-02-02 17:04:34 | INFO | train | epoch 109 | loss 5.757 | ppl 54.07 | wps 5766.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 6976 | lr 0.000378614 | gnorm 0.729 | train_wall 332 | gb_free 6.1 | wall 39164
KL Stats: Epoch 109 Divergences: Uniform: 3.0605108897737856 Unigram: 3.3821718945695833
2022-02-02 17:04:34 | INFO | fairseq.trainer | begin training epoch 110
2022-02-02 17:04:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:06:39 | INFO | train_inner | epoch 110:     24 / 64 loss=5.748, ppl=53.76, wps=5641.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7000, lr=0.000377964, gnorm=0.735, train_wall=519, gb_free=6.1, wall=39290
2022-02-02 17:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:10:36 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 9.696 | ppl 829.27 | wps 7739.9 | wpb 2034.1 | bsz 4 | num_updates 7040 | best_loss 9.232
2022-02-02 17:10:36 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-02-02 17:10:36 | INFO | train | epoch 110 | loss 5.741 | ppl 53.48 | wps 5764.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7040 | lr 0.000376889 | gnorm 0.754 | train_wall 332 | gb_free 6.1 | wall 39526
KL Stats: Epoch 110 Divergences: Uniform: 3.053136108718445 Unigram: 3.394504077266282
2022-02-02 17:10:36 | INFO | fairseq.trainer | begin training epoch 111
2022-02-02 17:10:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:15:50 | INFO | train_inner | epoch 111:     60 / 64 loss=5.742, ppl=53.51, wps=5931.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=7100, lr=0.000375293, gnorm=0.758, train_wall=520, gb_free=6.1, wall=39841
2022-02-02 17:16:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:16:38 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 9.755 | ppl 864.02 | wps 7753.8 | wpb 2034.1 | bsz 4 | num_updates 7104 | best_loss 9.232
2022-02-02 17:16:38 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-02-02 17:16:38 | INFO | train | epoch 111 | loss 5.73 | ppl 53.06 | wps 5765.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7104 | lr 0.000375188 | gnorm 0.762 | train_wall 332 | gb_free 6.1 | wall 39889
KL Stats: Epoch 111 Divergences: Uniform: 3.0585778651637496 Unigram: 3.4039120966203997
2022-02-02 17:16:38 | INFO | fairseq.trainer | begin training epoch 112
2022-02-02 17:16:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:22:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:22:41 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 9.719 | ppl 842.9 | wps 7731.1 | wpb 2034.1 | bsz 4 | num_updates 7168 | best_loss 9.232
2022-02-02 17:22:41 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-02-02 17:22:41 | INFO | train | epoch 112 | loss 5.715 | ppl 52.52 | wps 5762.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7168 | lr 0.000373509 | gnorm 0.757 | train_wall 332 | gb_free 6.1 | wall 40251
KL Stats: Epoch 112 Divergences: Uniform: 3.0609990467879173 Unigram: 3.410503035273173
2022-02-02 17:22:41 | INFO | fairseq.trainer | begin training epoch 113
2022-02-02 17:22:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:25:28 | INFO | train_inner | epoch 113:     32 / 64 loss=5.702, ppl=52.06, wps=5641.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7200, lr=0.000372678, gnorm=0.759, train_wall=519, gb_free=6.1, wall=40419
2022-02-02 17:28:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:28:43 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 9.752 | ppl 862.36 | wps 7767.4 | wpb 2034.1 | bsz 4 | num_updates 7232 | best_loss 9.232
2022-02-02 17:28:43 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-02-02 17:28:43 | INFO | train | epoch 113 | loss 5.703 | ppl 52.08 | wps 5768 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7232 | lr 0.000371853 | gnorm 0.777 | train_wall 332 | gb_free 6.1 | wall 40613
KL Stats: Epoch 113 Divergences: Uniform: 3.0620876687714857 Unigram: 3.4233757805094105
2022-02-02 17:28:43 | INFO | fairseq.trainer | begin training epoch 114
2022-02-02 17:28:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:34:45 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 9.738 | ppl 853.75 | wps 7757.6 | wpb 2034.1 | bsz 4 | num_updates 7296 | best_loss 9.232
2022-02-02 17:34:45 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-02-02 17:34:45 | INFO | train | epoch 114 | loss 5.691 | ppl 51.66 | wps 5769.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7296 | lr 0.000370218 | gnorm 0.785 | train_wall 332 | gb_free 6.1 | wall 40975
KL Stats: Epoch 114 Divergences: Uniform: 3.0642410035774645 Unigram: 3.423949386403659
2022-02-02 17:34:45 | INFO | fairseq.trainer | begin training epoch 115
2022-02-02 17:34:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:35:06 | INFO | train_inner | epoch 115:      4 / 64 loss=5.705, ppl=52.18, wps=5643.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=7300, lr=0.000370117, gnorm=0.784, train_wall=519, gb_free=6.1, wall=40996
2022-02-02 17:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:40:47 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 9.767 | ppl 871.51 | wps 7737.5 | wpb 2034.1 | bsz 4 | num_updates 7360 | best_loss 9.232
2022-02-02 17:40:47 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-02-02 17:40:47 | INFO | train | epoch 115 | loss 5.676 | ppl 51.14 | wps 5766.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7360 | lr 0.000368605 | gnorm 0.771 | train_wall 332 | gb_free 6.1 | wall 41338
KL Stats: Epoch 115 Divergences: Uniform: 3.0709569171646462 Unigram: 3.440893466558342
2022-02-02 17:40:47 | INFO | fairseq.trainer | begin training epoch 116
2022-02-02 17:40:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:44:16 | INFO | train_inner | epoch 116:     40 / 64 loss=5.662, ppl=50.64, wps=5934.4, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7400, lr=0.000367607, gnorm=0.777, train_wall=520, gb_free=6.1, wall=41547
2022-02-02 17:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:46:49 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 9.756 | ppl 864.64 | wps 7702.9 | wpb 2034.1 | bsz 4 | num_updates 7424 | best_loss 9.232
2022-02-02 17:46:49 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-02-02 17:46:49 | INFO | train | epoch 116 | loss 5.665 | ppl 50.73 | wps 5766.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7424 | lr 0.000367013 | gnorm 0.788 | train_wall 332 | gb_free 6.1 | wall 41700
KL Stats: Epoch 116 Divergences: Uniform: 3.0766382636465184 Unigram: 3.446583256211431
2022-02-02 17:46:49 | INFO | fairseq.trainer | begin training epoch 117
2022-02-02 17:46:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:52:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:52:51 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 9.724 | ppl 845.64 | wps 7762.8 | wpb 2034.1 | bsz 4 | num_updates 7488 | best_loss 9.232
2022-02-02 17:52:51 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-02-02 17:52:51 | INFO | train | epoch 117 | loss 5.653 | ppl 50.31 | wps 5768.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7488 | lr 0.000365441 | gnorm 0.793 | train_wall 332 | gb_free 6.1 | wall 42062
KL Stats: Epoch 117 Divergences: Uniform: 3.07776982065735 Unigram: 3.456432113317294
2022-02-02 17:52:51 | INFO | fairseq.trainer | begin training epoch 118
2022-02-02 17:52:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 17:53:54 | INFO | train_inner | epoch 118:     12 / 64 loss=5.658, ppl=50.49, wps=5642.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7500, lr=0.000365148, gnorm=0.791, train_wall=518, gb_free=6.1, wall=42125
2022-02-02 17:58:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 17:58:54 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 9.74 | ppl 855.23 | wps 7725.4 | wpb 2034.1 | bsz 4 | num_updates 7552 | best_loss 9.232
2022-02-02 17:58:54 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-02-02 17:58:54 | INFO | train | epoch 118 | loss 5.639 | ppl 49.83 | wps 5763.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7552 | lr 0.000363889 | gnorm 0.779 | train_wall 332 | gb_free 6.1 | wall 42424
KL Stats: Epoch 118 Divergences: Uniform: 3.093176144999078 Unigram: 3.46520910102211
2022-02-02 17:58:54 | INFO | fairseq.trainer | begin training epoch 119
2022-02-02 17:58:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:03:05 | INFO | train_inner | epoch 119:     48 / 64 loss=5.633, ppl=49.63, wps=5933.9, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7600, lr=0.000362738, gnorm=0.796, train_wall=520, gb_free=6.1, wall=42676
2022-02-02 18:04:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:04:56 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 9.765 | ppl 869.79 | wps 7739.6 | wpb 2034.1 | bsz 4 | num_updates 7616 | best_loss 9.232
2022-02-02 18:04:56 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-02-02 18:04:56 | INFO | train | epoch 119 | loss 5.629 | ppl 49.49 | wps 5767.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7616 | lr 0.000362357 | gnorm 0.804 | train_wall 332 | gb_free 6.1 | wall 42786
KL Stats: Epoch 119 Divergences: Uniform: 3.087969246621773 Unigram: 3.4751002817115832
2022-02-02 18:04:56 | INFO | fairseq.trainer | begin training epoch 120
2022-02-02 18:04:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:10:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:10:58 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 9.771 | ppl 873.92 | wps 7760.8 | wpb 2034.1 | bsz 4 | num_updates 7680 | best_loss 9.232
2022-02-02 18:10:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 7680 updates
2022-02-02 18:10:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt
2022-02-02 18:11:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt
2022-02-02 18:11:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint120.pt (epoch 120 @ 7680 updates, score 9.771) (writing took 3.8285405756905675 seconds)
2022-02-02 18:11:02 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-02-02 18:11:02 | INFO | train | epoch 120 | loss 5.616 | ppl 49.03 | wps 5707.5 | ups 0.17 | wpb 32634.8 | bsz 63.8 | num_updates 7680 | lr 0.000360844 | gnorm 0.813 | train_wall 332 | gb_free 6.1 | wall 43152
KL Stats: Epoch 120 Divergences: Uniform: 3.086263591323595 Unigram: 3.4838967230179234
2022-02-02 18:11:02 | INFO | fairseq.trainer | begin training epoch 121
2022-02-02 18:11:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:12:46 | INFO | train_inner | epoch 121:     20 / 64 loss=5.617, ppl=49.09, wps=5606.8, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7700, lr=0.000360375, gnorm=0.806, train_wall=518, gb_free=6.1, wall=43257
2022-02-02 18:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:17:04 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 9.775 | ppl 876.13 | wps 7761.2 | wpb 2034.1 | bsz 4 | num_updates 7744 | best_loss 9.232
2022-02-02 18:17:04 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-02-02 18:17:04 | INFO | train | epoch 121 | loss 5.604 | ppl 48.64 | wps 5769 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7744 | lr 0.00035935 | gnorm 0.81 | train_wall 332 | gb_free 6.1 | wall 43514
KL Stats: Epoch 121 Divergences: Uniform: 3.089027172821763 Unigram: 3.4889615913311536
2022-02-02 18:17:04 | INFO | fairseq.trainer | begin training epoch 122
2022-02-02 18:17:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:21:57 | INFO | train_inner | epoch 122:     56 / 64 loss=5.6, ppl=48.51, wps=5932.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=7800, lr=0.000358057, gnorm=0.813, train_wall=520, gb_free=6.1, wall=43808
2022-02-02 18:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:23:06 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 9.751 | ppl 861.59 | wps 7723 | wpb 2034.1 | bsz 4 | num_updates 7808 | best_loss 9.232
2022-02-02 18:23:06 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-02-02 18:23:06 | INFO | train | epoch 122 | loss 5.594 | ppl 48.29 | wps 5762.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7808 | lr 0.000357874 | gnorm 0.814 | train_wall 332 | gb_free 6.1 | wall 43877
KL Stats: Epoch 122 Divergences: Uniform: 3.08613996425312 Unigram: 3.495267424327344
2022-02-02 18:23:06 | INFO | fairseq.trainer | begin training epoch 123
2022-02-02 18:23:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:28:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:29:09 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 9.79 | ppl 885.34 | wps 7742.3 | wpb 2034.1 | bsz 4 | num_updates 7872 | best_loss 9.232
2022-02-02 18:29:09 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-02-02 18:29:09 | INFO | train | epoch 123 | loss 5.583 | ppl 47.94 | wps 5764.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7872 | lr 0.000356416 | gnorm 0.828 | train_wall 332 | gb_free 6.1 | wall 44239
KL Stats: Epoch 123 Divergences: Uniform: 3.0909521209362927 Unigram: 3.5081549954319127
2022-02-02 18:29:09 | INFO | fairseq.trainer | begin training epoch 124
2022-02-02 18:29:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:31:35 | INFO | train_inner | epoch 124:     28 / 64 loss=5.576, ppl=47.71, wps=5638.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=7900, lr=0.000355784, gnorm=0.82, train_wall=519, gb_free=6.1, wall=44386
2022-02-02 18:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:35:11 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 9.791 | ppl 885.65 | wps 7728.3 | wpb 2034.1 | bsz 4 | num_updates 7936 | best_loss 9.232
2022-02-02 18:35:11 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-02-02 18:35:11 | INFO | train | epoch 124 | loss 5.574 | ppl 47.62 | wps 5760.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 7936 | lr 0.000354976 | gnorm 0.814 | train_wall 333 | gb_free 6.1 | wall 44602
KL Stats: Epoch 124 Divergences: Uniform: 3.095706304972615 Unigram: 3.5146868223621217
2022-02-02 18:35:11 | INFO | fairseq.trainer | begin training epoch 125
2022-02-02 18:35:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:40:45 | INFO | train_inner | epoch 125:     64 / 64 loss=5.576, ppl=47.7, wps=5928.9, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=8000, lr=0.000353553, gnorm=0.837, train_wall=519, gb_free=6.1, wall=44936
2022-02-02 18:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:41:14 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 9.837 | ppl 914.54 | wps 7724.4 | wpb 2034.1 | bsz 4 | num_updates 8000 | best_loss 9.232
2022-02-02 18:41:14 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-02-02 18:41:14 | INFO | train | epoch 125 | loss 5.562 | ppl 47.23 | wps 5763.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8000 | lr 0.000353553 | gnorm 0.844 | train_wall 332 | gb_free 6.1 | wall 44964
KL Stats: Epoch 125 Divergences: Uniform: 3.0962104534922945 Unigram: 3.525363623169968
2022-02-02 18:41:14 | INFO | fairseq.trainer | begin training epoch 126
2022-02-02 18:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:47:16 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 9.802 | ppl 892.9 | wps 7710.3 | wpb 2034.1 | bsz 4 | num_updates 8064 | best_loss 9.232
2022-02-02 18:47:16 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-02-02 18:47:16 | INFO | train | epoch 126 | loss 5.549 | ppl 46.82 | wps 5764.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8064 | lr 0.000352148 | gnorm 0.827 | train_wall 332 | gb_free 6.1 | wall 45326
KL Stats: Epoch 126 Divergences: Uniform: 3.1000654537625913 Unigram: 3.5321634618959794
2022-02-02 18:47:16 | INFO | fairseq.trainer | begin training epoch 127
2022-02-02 18:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:50:25 | INFO | train_inner | epoch 127:     36 / 64 loss=5.532, ppl=46.27, wps=5636.7, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=8100, lr=0.000351364, gnorm=0.821, train_wall=520, gb_free=6.1, wall=45516
2022-02-02 18:52:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:53:19 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 9.81 | ppl 897.71 | wps 7733.5 | wpb 2034.1 | bsz 4 | num_updates 8128 | best_loss 9.232
2022-02-02 18:53:19 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-02-02 18:53:19 | INFO | train | epoch 127 | loss 5.537 | ppl 46.44 | wps 5756.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8128 | lr 0.000350758 | gnorm 0.817 | train_wall 333 | gb_free 6.1 | wall 45689
KL Stats: Epoch 127 Divergences: Uniform: 3.1085508344864454 Unigram: 3.54335436374412
2022-02-02 18:53:19 | INFO | fairseq.trainer | begin training epoch 128
2022-02-02 18:53:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 18:58:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 18:59:21 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 9.858 | ppl 928.03 | wps 7732.7 | wpb 2034.1 | bsz 4 | num_updates 8192 | best_loss 9.232
2022-02-02 18:59:21 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-02-02 18:59:21 | INFO | train | epoch 128 | loss 5.529 | ppl 46.17 | wps 5766.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8192 | lr 0.000349386 | gnorm 0.842 | train_wall 332 | gb_free 6.1 | wall 46051
KL Stats: Epoch 128 Divergences: Uniform: 3.1063347125233305 Unigram: 3.5432869415520245
2022-02-02 18:59:21 | INFO | fairseq.trainer | begin training epoch 129
2022-02-02 18:59:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:00:03 | INFO | train_inner | epoch 129:      8 / 64 loss=5.538, ppl=46.48, wps=5641.6, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8200, lr=0.000349215, gnorm=0.84, train_wall=519, gb_free=6.1, wall=46093
2022-02-02 19:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:05:23 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 9.821 | ppl 904.73 | wps 7728.3 | wpb 2034.1 | bsz 4 | num_updates 8256 | best_loss 9.232
2022-02-02 19:05:23 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-02-02 19:05:23 | INFO | train | epoch 129 | loss 5.522 | ppl 45.95 | wps 5762.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8256 | lr 0.000348029 | gnorm 0.875 | train_wall 332 | gb_free 6.1 | wall 46414
KL Stats: Epoch 129 Divergences: Uniform: 3.108201402798791 Unigram: 3.5534303106840484
2022-02-02 19:05:23 | INFO | fairseq.trainer | begin training epoch 130
2022-02-02 19:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:09:14 | INFO | train_inner | epoch 130:     44 / 64 loss=5.513, ppl=45.66, wps=5931.6, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8300, lr=0.000347105, gnorm=0.859, train_wall=520, gb_free=6.1, wall=46644
2022-02-02 19:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:11:26 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 9.817 | ppl 902.26 | wps 7717.5 | wpb 2034.1 | bsz 4 | num_updates 8320 | best_loss 9.232
2022-02-02 19:11:26 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-02-02 19:11:26 | INFO | train | epoch 130 | loss 5.508 | ppl 45.5 | wps 5765.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8320 | lr 0.000346688 | gnorm 0.853 | train_wall 332 | gb_free 6.1 | wall 46776
KL Stats: Epoch 130 Divergences: Uniform: 3.1111196047244896 Unigram: 3.5644848119191366
2022-02-02 19:11:26 | INFO | fairseq.trainer | begin training epoch 131
2022-02-02 19:11:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:17:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:17:28 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 9.861 | ppl 930.03 | wps 7754.9 | wpb 2034.1 | bsz 4 | num_updates 8384 | best_loss 9.232
2022-02-02 19:17:28 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-02-02 19:17:28 | INFO | train | epoch 131 | loss 5.5 | ppl 45.25 | wps 5763.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8384 | lr 0.000345362 | gnorm 0.871 | train_wall 332 | gb_free 6.1 | wall 47139
KL Stats: Epoch 131 Divergences: Uniform: 3.11510739144462 Unigram: 3.568560290537672
2022-02-02 19:17:28 | INFO | fairseq.trainer | begin training epoch 132
2022-02-02 19:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:18:52 | INFO | train_inner | epoch 132:     16 / 64 loss=5.498, ppl=45.2, wps=5638.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8400, lr=0.000345033, gnorm=0.873, train_wall=519, gb_free=6.1, wall=47223
2022-02-02 19:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:23:30 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 9.872 | ppl 937.34 | wps 7750.5 | wpb 2034.1 | bsz 4 | num_updates 8448 | best_loss 9.232
2022-02-02 19:23:30 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-02-02 19:23:30 | INFO | train | epoch 132 | loss 5.491 | ppl 44.98 | wps 5767.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8448 | lr 0.000344051 | gnorm 0.855 | train_wall 332 | gb_free 6.1 | wall 47501
KL Stats: Epoch 132 Divergences: Uniform: 3.119380474513867 Unigram: 3.578053559931024
2022-02-02 19:23:30 | INFO | fairseq.trainer | begin training epoch 133
2022-02-02 19:23:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:28:02 | INFO | train_inner | epoch 133:     52 / 64 loss=5.487, ppl=44.85, wps=5937.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=8500, lr=0.000342997, gnorm=0.857, train_wall=520, gb_free=6.1, wall=47773
2022-02-02 19:29:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:29:32 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 9.871 | ppl 936.56 | wps 7741.1 | wpb 2034.1 | bsz 4 | num_updates 8512 | best_loss 9.232
2022-02-02 19:29:32 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-02-02 19:29:32 | INFO | train | epoch 133 | loss 5.481 | ppl 44.66 | wps 5769.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8512 | lr 0.000342755 | gnorm 0.865 | train_wall 332 | gb_free 6.1 | wall 47863
KL Stats: Epoch 133 Divergences: Uniform: 3.1136993760804414 Unigram: 3.5828875501686026
2022-02-02 19:29:32 | INFO | fairseq.trainer | begin training epoch 134
2022-02-02 19:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:35:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:35:34 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 9.868 | ppl 934.75 | wps 7762 | wpb 2034.1 | bsz 4 | num_updates 8576 | best_loss 9.232
2022-02-02 19:35:34 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-02-02 19:35:34 | INFO | train | epoch 134 | loss 5.472 | ppl 44.39 | wps 5766.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8576 | lr 0.000341474 | gnorm 0.88 | train_wall 332 | gb_free 6.1 | wall 48225
KL Stats: Epoch 134 Divergences: Uniform: 3.1172342598835097 Unigram: 3.5909046123570674
2022-02-02 19:35:34 | INFO | fairseq.trainer | begin training epoch 135
2022-02-02 19:35:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:37:40 | INFO | train_inner | epoch 135:     24 / 64 loss=5.469, ppl=44.28, wps=5643.7, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8600, lr=0.000340997, gnorm=0.881, train_wall=518, gb_free=6.1, wall=48351
2022-02-02 19:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:41:37 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 9.859 | ppl 928.77 | wps 7730.6 | wpb 2034.1 | bsz 4 | num_updates 8640 | best_loss 9.232
2022-02-02 19:41:37 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-02-02 19:41:37 | INFO | train | epoch 135 | loss 5.462 | ppl 44.09 | wps 5766.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8640 | lr 0.000340207 | gnorm 0.908 | train_wall 332 | gb_free 6.1 | wall 48587
KL Stats: Epoch 135 Divergences: Uniform: 3.1202229109542716 Unigram: 3.593254453597257
2022-02-02 19:41:37 | INFO | fairseq.trainer | begin training epoch 136
2022-02-02 19:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:46:51 | INFO | train_inner | epoch 136:     60 / 64 loss=5.464, ppl=44.13, wps=5931.2, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=8700, lr=0.000339032, gnorm=0.901, train_wall=520, gb_free=6.1, wall=48902
2022-02-02 19:47:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:47:39 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 9.896 | ppl 952.64 | wps 7737.4 | wpb 2034.1 | bsz 4 | num_updates 8704 | best_loss 9.232
2022-02-02 19:47:39 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-02-02 19:47:39 | INFO | train | epoch 136 | loss 5.454 | ppl 43.82 | wps 5765.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8704 | lr 0.000338954 | gnorm 0.89 | train_wall 332 | gb_free 6.1 | wall 48949
KL Stats: Epoch 136 Divergences: Uniform: 3.117141742363433 Unigram: 3.5985904574870426
2022-02-02 19:47:39 | INFO | fairseq.trainer | begin training epoch 137
2022-02-02 19:47:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:53:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:53:41 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 9.869 | ppl 934.87 | wps 7754.8 | wpb 2034.1 | bsz 4 | num_updates 8768 | best_loss 9.232
2022-02-02 19:53:41 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-02-02 19:53:41 | INFO | train | epoch 137 | loss 5.446 | ppl 43.59 | wps 5767.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8768 | lr 0.000337715 | gnorm 0.909 | train_wall 332 | gb_free 6.1 | wall 49312
KL Stats: Epoch 137 Divergences: Uniform: 3.1287364930086436 Unigram: 3.6057896965406124
2022-02-02 19:53:41 | INFO | fairseq.trainer | begin training epoch 138
2022-02-02 19:53:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 19:56:28 | INFO | train_inner | epoch 138:     32 / 64 loss=5.435, ppl=43.27, wps=5646.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=8800, lr=0.0003371, gnorm=0.91, train_wall=518, gb_free=6.1, wall=49479
2022-02-02 19:59:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 19:59:42 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 9.874 | ppl 938.17 | wps 7732.2 | wpb 2034.1 | bsz 4 | num_updates 8832 | best_loss 9.232
2022-02-02 19:59:42 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-02-02 19:59:42 | INFO | train | epoch 138 | loss 5.437 | ppl 43.31 | wps 5777.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8832 | lr 0.000336489 | gnorm 0.91 | train_wall 331 | gb_free 6.1 | wall 49673
KL Stats: Epoch 138 Divergences: Uniform: 3.1235128365460363 Unigram: 3.613148677841166
2022-02-02 19:59:42 | INFO | fairseq.trainer | begin training epoch 139
2022-02-02 19:59:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:05:44 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 9.891 | ppl 949.41 | wps 7726.7 | wpb 2034.1 | bsz 4 | num_updates 8896 | best_loss 9.232
2022-02-02 20:05:44 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-02-02 20:05:44 | INFO | train | epoch 139 | loss 5.426 | ppl 43 | wps 5772 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8896 | lr 0.000335276 | gnorm 0.927 | train_wall 332 | gb_free 6.1 | wall 50035
KL Stats: Epoch 139 Divergences: Uniform: 3.1271811115757604 Unigram: 3.620941453121844
2022-02-02 20:05:44 | INFO | fairseq.trainer | begin training epoch 140
2022-02-02 20:05:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:06:05 | INFO | train_inner | epoch 140:      4 / 64 loss=5.438, ppl=43.34, wps=5650, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=8900, lr=0.000335201, gnorm=0.923, train_wall=518, gb_free=6.1, wall=50056
2022-02-02 20:11:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:11:46 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 9.894 | ppl 951.65 | wps 7782.7 | wpb 2034.1 | bsz 4 | num_updates 8960 | best_loss 9.232
2022-02-02 20:11:46 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-02-02 20:11:46 | INFO | train | epoch 140 | loss 5.421 | ppl 42.86 | wps 5778 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 8960 | lr 0.000334077 | gnorm 0.917 | train_wall 332 | gb_free 6.1 | wall 50396
KL Stats: Epoch 140 Divergences: Uniform: 3.1323046248275546 Unigram: 3.6296903589699885
2022-02-02 20:11:46 | INFO | fairseq.trainer | begin training epoch 141
2022-02-02 20:11:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:15:15 | INFO | train_inner | epoch 141:     40 / 64 loss=5.413, ppl=42.59, wps=5945.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9000, lr=0.000333333, gnorm=0.931, train_wall=519, gb_free=6.1, wall=50606
2022-02-02 20:17:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:17:47 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 9.902 | ppl 956.51 | wps 7757.1 | wpb 2034.1 | bsz 4 | num_updates 9024 | best_loss 9.232
2022-02-02 20:17:47 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-02-02 20:17:47 | INFO | train | epoch 141 | loss 5.413 | ppl 42.6 | wps 5777.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9024 | lr 0.00033289 | gnorm 0.951 | train_wall 332 | gb_free 6.1 | wall 50758
KL Stats: Epoch 141 Divergences: Uniform: 3.1337285170912796 Unigram: 3.635190470822906
2022-02-02 20:17:47 | INFO | fairseq.trainer | begin training epoch 142
2022-02-02 20:17:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:23:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:23:49 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 9.865 | ppl 932.26 | wps 7741.1 | wpb 2034.1 | bsz 4 | num_updates 9088 | best_loss 9.232
2022-02-02 20:23:49 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-02-02 20:23:49 | INFO | train | epoch 142 | loss 5.403 | ppl 42.33 | wps 5777.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9088 | lr 0.000331716 | gnorm 0.914 | train_wall 332 | gb_free 6.1 | wall 51119
KL Stats: Epoch 142 Divergences: Uniform: 3.1362389296994335 Unigram: 3.6418004282516634
2022-02-02 20:23:49 | INFO | fairseq.trainer | begin training epoch 143
2022-02-02 20:23:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:24:52 | INFO | train_inner | epoch 143:     12 / 64 loss=5.406, ppl=42.39, wps=5652.6, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9100, lr=0.000331497, gnorm=0.924, train_wall=518, gb_free=6.1, wall=51182
2022-02-02 20:29:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:29:50 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 9.929 | ppl 974.87 | wps 7706.2 | wpb 2034.1 | bsz 4 | num_updates 9152 | best_loss 9.232
2022-02-02 20:29:50 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-02-02 20:29:50 | INFO | train | epoch 143 | loss 5.396 | ppl 42.12 | wps 5778.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9152 | lr 0.000330554 | gnorm 0.943 | train_wall 331 | gb_free 6.1 | wall 51481
KL Stats: Epoch 143 Divergences: Uniform: 3.129225774918246 Unigram: 3.6439080365329546
2022-02-02 20:29:50 | INFO | fairseq.trainer | begin training epoch 144
2022-02-02 20:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:34:01 | INFO | train_inner | epoch 144:     48 / 64 loss=5.393, ppl=42.01, wps=5944.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9200, lr=0.00032969, gnorm=0.939, train_wall=519, gb_free=6.1, wall=51732
2022-02-02 20:35:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:35:52 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 9.937 | ppl 979.94 | wps 7720.6 | wpb 2034.1 | bsz 4 | num_updates 9216 | best_loss 9.232
2022-02-02 20:35:52 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-02-02 20:35:52 | INFO | train | epoch 144 | loss 5.387 | ppl 41.86 | wps 5771.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9216 | lr 0.000329404 | gnorm 0.941 | train_wall 332 | gb_free 6.1 | wall 51843
KL Stats: Epoch 144 Divergences: Uniform: 3.1348659341408314 Unigram: 3.654124170634358
2022-02-02 20:35:52 | INFO | fairseq.trainer | begin training epoch 145
2022-02-02 20:35:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:41:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:41:54 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 9.922 | ppl 970.19 | wps 7735.7 | wpb 2034.1 | bsz 4 | num_updates 9280 | best_loss 9.232
2022-02-02 20:41:54 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-02-02 20:41:54 | INFO | train | epoch 145 | loss 5.376 | ppl 41.52 | wps 5774.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9280 | lr 0.000328266 | gnorm 0.918 | train_wall 332 | gb_free 6.1 | wall 52204
KL Stats: Epoch 145 Divergences: Uniform: 3.13575821181059 Unigram: 3.660983189338586
2022-02-02 20:41:54 | INFO | fairseq.trainer | begin training epoch 146
2022-02-02 20:41:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:43:39 | INFO | train_inner | epoch 146:     20 / 64 loss=5.374, ppl=41.48, wps=5646.5, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9300, lr=0.000327913, gnorm=0.931, train_wall=518, gb_free=6.1, wall=52309
2022-02-02 20:47:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:47:56 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 9.935 | ppl 978.75 | wps 7748.7 | wpb 2034.1 | bsz 4 | num_updates 9344 | best_loss 9.232
2022-02-02 20:47:56 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-02-02 20:47:56 | INFO | train | epoch 146 | loss 5.371 | ppl 41.38 | wps 5767.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9344 | lr 0.00032714 | gnorm 0.956 | train_wall 332 | gb_free 6.1 | wall 52567
KL Stats: Epoch 146 Divergences: Uniform: 3.13568194834222 Unigram: 3.670450375654726
2022-02-02 20:47:56 | INFO | fairseq.trainer | begin training epoch 147
2022-02-02 20:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:52:49 | INFO | train_inner | epoch 147:     56 / 64 loss=5.371, ppl=41.38, wps=5940.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=9400, lr=0.000326164, gnorm=0.947, train_wall=519, gb_free=6.1, wall=52860
2022-02-02 20:53:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 20:53:58 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 9.924 | ppl 971.47 | wps 7747.1 | wpb 2034.1 | bsz 4 | num_updates 9408 | best_loss 9.232
2022-02-02 20:53:58 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-02-02 20:53:58 | INFO | train | epoch 147 | loss 5.363 | ppl 41.16 | wps 5774.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9408 | lr 0.000326025 | gnorm 0.938 | train_wall 332 | gb_free 6.1 | wall 52928
KL Stats: Epoch 147 Divergences: Uniform: 3.1437223892025665 Unigram: 3.6744336662851222
2022-02-02 20:53:58 | INFO | fairseq.trainer | begin training epoch 148
2022-02-02 20:53:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 20:59:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:00:00 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 9.93 | ppl 975.27 | wps 7725.6 | wpb 2034.1 | bsz 4 | num_updates 9472 | best_loss 9.232
2022-02-02 21:00:00 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-02-02 21:00:00 | INFO | train | epoch 148 | loss 5.358 | ppl 41.01 | wps 5771 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9472 | lr 0.000324922 | gnorm 0.981 | train_wall 332 | gb_free 6.1 | wall 53290
KL Stats: Epoch 148 Divergences: Uniform: 3.1439400570052918 Unigram: 3.673605050079779
2022-02-02 21:00:00 | INFO | fairseq.trainer | begin training epoch 149
2022-02-02 21:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:02:26 | INFO | train_inner | epoch 149:     28 / 64 loss=5.353, ppl=40.86, wps=5646.1, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9500, lr=0.000324443, gnorm=0.975, train_wall=518, gb_free=6.1, wall=53437
2022-02-02 21:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:06:02 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 9.973 | ppl 1004.96 | wps 7729.7 | wpb 2034.1 | bsz 4 | num_updates 9536 | best_loss 9.232
2022-02-02 21:06:02 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-02-02 21:06:02 | INFO | train | epoch 149 | loss 5.348 | ppl 40.73 | wps 5762.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9536 | lr 0.00032383 | gnorm 0.976 | train_wall 332 | gb_free 6.1 | wall 53653
KL Stats: Epoch 149 Divergences: Uniform: 3.1461826603623217 Unigram: 3.6855597062159577
2022-02-02 21:06:02 | INFO | fairseq.trainer | begin training epoch 150
2022-02-02 21:06:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:11:35 | INFO | train_inner | epoch 150:     64 / 64 loss=5.352, ppl=40.85, wps=5936.9, ups=0.18, wpb=32600.8, bsz=63.7, num_updates=9600, lr=0.000322749, gnorm=0.978, train_wall=518, gb_free=6.1, wall=53986
2022-02-02 21:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:12:04 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 9.934 | ppl 978.36 | wps 7742.8 | wpb 2034.1 | bsz 4 | num_updates 9600 | best_loss 9.232
2022-02-02 21:12:04 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-02-02 21:12:04 | INFO | train | epoch 150 | loss 5.341 | ppl 40.54 | wps 5776.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9600 | lr 0.000322749 | gnorm 0.978 | train_wall 332 | gb_free 6.1 | wall 54014
KL Stats: Epoch 150 Divergences: Uniform: 3.146319664905614 Unigram: 3.689623131732966
2022-02-02 21:12:04 | INFO | fairseq.trainer | begin training epoch 151
2022-02-02 21:12:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:18:05 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 9.987 | ppl 1014.7 | wps 7749.3 | wpb 2034.1 | bsz 4 | num_updates 9664 | best_loss 9.232
2022-02-02 21:18:05 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-02-02 21:18:05 | INFO | train | epoch 151 | loss 5.334 | ppl 40.35 | wps 5773.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9664 | lr 0.000321678 | gnorm 0.996 | train_wall 332 | gb_free 6.1 | wall 54376
KL Stats: Epoch 151 Divergences: Uniform: 3.1474904738899023 Unigram: 3.6947693249092493
2022-02-02 21:18:05 | INFO | fairseq.trainer | begin training epoch 152
2022-02-02 21:18:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:21:14 | INFO | train_inner | epoch 152:     36 / 64 loss=5.319, ppl=39.93, wps=5650.2, ups=0.17, wpb=32682.8, bsz=63.8, num_updates=9700, lr=0.000321081, gnorm=0.984, train_wall=519, gb_free=6.1, wall=54564
2022-02-02 21:23:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:24:07 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 9.963 | ppl 998.34 | wps 7747.6 | wpb 2034.1 | bsz 4 | num_updates 9728 | best_loss 9.232
2022-02-02 21:24:07 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-02-02 21:24:07 | INFO | train | epoch 152 | loss 5.326 | ppl 40.11 | wps 5772.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9728 | lr 0.000320618 | gnorm 0.96 | train_wall 332 | gb_free 6.1 | wall 54738
KL Stats: Epoch 152 Divergences: Uniform: 3.151611878403123 Unigram: 3.7019710849773815
2022-02-02 21:24:07 | INFO | fairseq.trainer | begin training epoch 153
2022-02-02 21:24:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:29:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:30:09 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 9.97 | ppl 1002.83 | wps 7757.6 | wpb 2034.1 | bsz 4 | num_updates 9792 | best_loss 9.232
2022-02-02 21:30:09 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-02-02 21:30:09 | INFO | train | epoch 153 | loss 5.32 | ppl 39.95 | wps 5772.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9792 | lr 0.000319569 | gnorm 0.989 | train_wall 332 | gb_free 6.1 | wall 55100
KL Stats: Epoch 153 Divergences: Uniform: 3.150531737898595 Unigram: 3.7102250140664634
2022-02-02 21:30:09 | INFO | fairseq.trainer | begin training epoch 154
2022-02-02 21:30:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:30:51 | INFO | train_inner | epoch 154:      8 / 64 loss=5.328, ppl=40.16, wps=5647.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=9800, lr=0.000319438, gnorm=0.979, train_wall=518, gb_free=6.1, wall=55142
2022-02-02 21:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:36:12 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 9.959 | ppl 995.27 | wps 7730.8 | wpb 2034.1 | bsz 4 | num_updates 9856 | best_loss 9.232
2022-02-02 21:36:12 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-02-02 21:36:12 | INFO | train | epoch 154 | loss 5.313 | ppl 39.75 | wps 5758.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9856 | lr 0.000318529 | gnorm 1.001 | train_wall 333 | gb_free 6.1 | wall 55462
KL Stats: Epoch 154 Divergences: Uniform: 3.150990308574502 Unigram: 3.7134454998502293
2022-02-02 21:36:12 | INFO | fairseq.trainer | begin training epoch 155
2022-02-02 21:36:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:40:02 | INFO | train_inner | epoch 155:     44 / 64 loss=5.307, ppl=39.59, wps=5934.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=9900, lr=0.000317821, gnorm=1.003, train_wall=520, gb_free=6.1, wall=55692
2022-02-02 21:41:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:42:13 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 9.97 | ppl 1003 | wps 7788 | wpb 2034.1 | bsz 4 | num_updates 9920 | best_loss 9.232
2022-02-02 21:42:13 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-02-02 21:42:13 | INFO | train | epoch 155 | loss 5.307 | ppl 39.58 | wps 5780.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9920 | lr 0.0003175 | gnorm 1.001 | train_wall 332 | gb_free 6.1 | wall 55824
KL Stats: Epoch 155 Divergences: Uniform: 3.155077223983067 Unigram: 3.7176594581807185
2022-02-02 21:42:13 | INFO | fairseq.trainer | begin training epoch 156
2022-02-02 21:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:47:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:48:15 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 9.936 | ppl 979.77 | wps 7770.9 | wpb 2034.1 | bsz 4 | num_updates 9984 | best_loss 9.232
2022-02-02 21:48:15 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-02-02 21:48:15 | INFO | train | epoch 156 | loss 5.301 | ppl 39.42 | wps 5777.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 9984 | lr 0.000316481 | gnorm 1.018 | train_wall 332 | gb_free 6.1 | wall 56185
KL Stats: Epoch 156 Divergences: Uniform: 3.159726051981588 Unigram: 3.719745385609782
2022-02-02 21:48:15 | INFO | fairseq.trainer | begin training epoch 157
2022-02-02 21:48:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:49:38 | INFO | train_inner | epoch 157:     16 / 64 loss=5.301, ppl=39.42, wps=5653.7, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10000, lr=0.000316228, gnorm=1.024, train_wall=518, gb_free=6.1, wall=56269
2022-02-02 21:53:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 21:54:16 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 9.953 | ppl 990.88 | wps 7720.1 | wpb 2034.1 | bsz 4 | num_updates 10048 | best_loss 9.232
2022-02-02 21:54:16 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-02-02 21:54:16 | INFO | train | epoch 157 | loss 5.291 | ppl 39.16 | wps 5775.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10048 | lr 0.000315472 | gnorm 1.01 | train_wall 332 | gb_free 6.1 | wall 56547
KL Stats: Epoch 157 Divergences: Uniform: 3.161212753519396 Unigram: 3.7292117358206434
2022-02-02 21:54:16 | INFO | fairseq.trainer | begin training epoch 158
2022-02-02 21:54:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 21:58:49 | INFO | train_inner | epoch 158:     52 / 64 loss=5.292, ppl=39.17, wps=5940.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10100, lr=0.000314658, gnorm=1.028, train_wall=519, gb_free=6.1, wall=56819
2022-02-02 21:59:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:00:18 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 9.991 | ppl 1017.59 | wps 7750.7 | wpb 2034.1 | bsz 4 | num_updates 10112 | best_loss 9.232
2022-02-02 22:00:18 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-02-02 22:00:18 | INFO | train | epoch 158 | loss 5.287 | ppl 39.04 | wps 5769 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10112 | lr 0.000314472 | gnorm 1.057 | train_wall 332 | gb_free 6.1 | wall 56909
KL Stats: Epoch 158 Divergences: Uniform: 3.15812009755527 Unigram: 3.7315269902818105
2022-02-02 22:00:18 | INFO | fairseq.trainer | begin training epoch 159
2022-02-02 22:00:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:06:20 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 10 | ppl 1023.81 | wps 7726.2 | wpb 2034.1 | bsz 4 | num_updates 10176 | best_loss 9.232
2022-02-02 22:06:20 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-02-02 22:06:20 | INFO | train | epoch 159 | loss 5.28 | ppl 38.84 | wps 5776 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10176 | lr 0.000313481 | gnorm 1.043 | train_wall 332 | gb_free 6.1 | wall 57270
KL Stats: Epoch 159 Divergences: Uniform: 3.1635435049765595 Unigram: 3.73604023049156
2022-02-02 22:06:20 | INFO | fairseq.trainer | begin training epoch 160
2022-02-02 22:06:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:08:25 | INFO | train_inner | epoch 160:     24 / 64 loss=5.275, ppl=38.73, wps=5651.5, ups=0.17, wpb=32594.2, bsz=63.7, num_updates=10200, lr=0.000313112, gnorm=1.029, train_wall=518, gb_free=6.1, wall=57396
2022-02-02 22:11:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:12:21 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 10.005 | ppl 1027.21 | wps 7752 | wpb 2034.1 | bsz 4 | num_updates 10240 | best_loss 9.232
2022-02-02 22:12:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 10240 updates
2022-02-02 22:12:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt
2022-02-02 22:12:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt
2022-02-02 22:12:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w2-jelinek_0.09_0.01_0.9_#1/checkpoint160.pt (epoch 160 @ 10240 updates, score 10.005) (writing took 3.552611408755183 seconds)
2022-02-02 22:12:25 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-02-02 22:12:25 | INFO | train | epoch 160 | loss 5.272 | ppl 38.64 | wps 5720.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10240 | lr 0.0003125 | gnorm 1.023 | train_wall 332 | gb_free 6.1 | wall 57636
KL Stats: Epoch 160 Divergences: Uniform: 3.158091027631899 Unigram: 3.7383337442048434
2022-02-02 22:12:25 | INFO | fairseq.trainer | begin training epoch 161
2022-02-02 22:12:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:17:39 | INFO | train_inner | epoch 161:     60 / 64 loss=5.276, ppl=38.74, wps=5903.2, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10300, lr=0.000311588, gnorm=1.055, train_wall=519, gb_free=6.1, wall=57950
2022-02-02 22:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:18:27 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 9.949 | ppl 988.5 | wps 7757.7 | wpb 2034.1 | bsz 4 | num_updates 10304 | best_loss 9.232
2022-02-02 22:18:27 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-02-02 22:18:27 | INFO | train | epoch 161 | loss 5.268 | ppl 38.52 | wps 5773.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10304 | lr 0.000311528 | gnorm 1.064 | train_wall 332 | gb_free 6.1 | wall 57997
KL Stats: Epoch 161 Divergences: Uniform: 3.1640368629655358 Unigram: 3.7508463408753334
2022-02-02 22:18:27 | INFO | fairseq.trainer | begin training epoch 162
2022-02-02 22:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:24:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:24:28 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 10.019 | ppl 1037.87 | wps 7742.3 | wpb 2034.1 | bsz 4 | num_updates 10368 | best_loss 9.232
2022-02-02 22:24:28 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-02-02 22:24:28 | INFO | train | epoch 162 | loss 5.263 | ppl 38.39 | wps 5775.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10368 | lr 0.000310565 | gnorm 1.06 | train_wall 332 | gb_free 6.1 | wall 58359
KL Stats: Epoch 162 Divergences: Uniform: 3.161451647454138 Unigram: 3.747309427180927
2022-02-02 22:24:28 | INFO | fairseq.trainer | begin training epoch 163
2022-02-02 22:24:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:27:16 | INFO | train_inner | epoch 163:     32 / 64 loss=5.252, ppl=38.11, wps=5651.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10400, lr=0.000310087, gnorm=1.057, train_wall=518, gb_free=6.1, wall=58526
2022-02-02 22:30:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:30:30 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 9.994 | ppl 1019.97 | wps 7741.3 | wpb 2034.1 | bsz 4 | num_updates 10432 | best_loss 9.232
2022-02-02 22:30:30 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-02-02 22:30:30 | INFO | train | epoch 163 | loss 5.255 | ppl 38.18 | wps 5776.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10432 | lr 0.000309611 | gnorm 1.063 | train_wall 332 | gb_free 6.1 | wall 58720
KL Stats: Epoch 163 Divergences: Uniform: 3.1653385272409142 Unigram: 3.755015727418611
2022-02-02 22:30:30 | INFO | fairseq.trainer | begin training epoch 164
2022-02-02 22:30:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:36:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:36:32 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 10.047 | ppl 1058.08 | wps 7750.4 | wpb 2034.1 | bsz 4 | num_updates 10496 | best_loss 9.232
2022-02-02 22:36:32 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-02-02 22:36:32 | INFO | train | epoch 164 | loss 5.25 | ppl 38.06 | wps 5769.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10496 | lr 0.000308665 | gnorm 1.076 | train_wall 332 | gb_free 6.1 | wall 59082
KL Stats: Epoch 164 Divergences: Uniform: 3.1597667457895495 Unigram: 3.757859644231614
2022-02-02 22:36:32 | INFO | fairseq.trainer | begin training epoch 165
2022-02-02 22:36:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:36:53 | INFO | train_inner | epoch 165:      4 / 64 loss=5.259, ppl=38.31, wps=5648.3, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=10500, lr=0.000308607, gnorm=1.073, train_wall=518, gb_free=6.1, wall=59103
2022-02-02 22:42:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:42:34 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 9.99 | ppl 1017.04 | wps 7777.8 | wpb 2034.1 | bsz 4 | num_updates 10560 | best_loss 9.232
2022-02-02 22:42:34 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-02-02 22:42:34 | INFO | train | epoch 165 | loss 5.242 | ppl 37.84 | wps 5768.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10560 | lr 0.000307729 | gnorm 1.095 | train_wall 332 | gb_free 6.1 | wall 59445
KL Stats: Epoch 165 Divergences: Uniform: 3.173837380043094 Unigram: 3.7673808642614697
2022-02-02 22:42:34 | INFO | fairseq.trainer | begin training epoch 166
2022-02-02 22:42:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:46:03 | INFO | train_inner | epoch 166:     40 / 64 loss=5.233, ppl=37.6, wps=5939.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10600, lr=0.000307148, gnorm=1.116, train_wall=519, gb_free=6.1, wall=59654
2022-02-02 22:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:48:36 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 10.068 | ppl 1073.76 | wps 7737 | wpb 2034.1 | bsz 4 | num_updates 10624 | best_loss 9.232
2022-02-02 22:48:36 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-02-02 22:48:36 | INFO | train | epoch 166 | loss 5.238 | ppl 37.74 | wps 5777.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10624 | lr 0.0003068 | gnorm 1.129 | train_wall 332 | gb_free 6.1 | wall 59806
KL Stats: Epoch 166 Divergences: Uniform: 3.163059958658163 Unigram: 3.7682262214088356
2022-02-02 22:48:36 | INFO | fairseq.trainer | begin training epoch 167
2022-02-02 22:48:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 22:54:37 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 10.019 | ppl 1037.4 | wps 7733.2 | wpb 2034.1 | bsz 4 | num_updates 10688 | best_loss 9.232
2022-02-02 22:54:37 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-02-02 22:54:37 | INFO | train | epoch 167 | loss 5.232 | ppl 37.58 | wps 5775.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10688 | lr 0.00030588 | gnorm 1.077 | train_wall 332 | gb_free 6.1 | wall 60168
KL Stats: Epoch 167 Divergences: Uniform: 3.1616149473550106 Unigram: 3.7763605857498637
2022-02-02 22:54:37 | INFO | fairseq.trainer | begin training epoch 168
2022-02-02 22:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 22:55:40 | INFO | train_inner | epoch 168:     12 / 64 loss=5.237, ppl=37.72, wps=5651.3, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10700, lr=0.000305709, gnorm=1.083, train_wall=518, gb_free=6.1, wall=60231
2022-02-02 23:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:00:39 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 10.02 | ppl 1038.63 | wps 7774.5 | wpb 2034.1 | bsz 4 | num_updates 10752 | best_loss 9.232
2022-02-02 23:00:39 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-02-02 23:00:39 | INFO | train | epoch 168 | loss 5.225 | ppl 37.41 | wps 5773.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10752 | lr 0.000304969 | gnorm 1.102 | train_wall 332 | gb_free 6.1 | wall 60529
KL Stats: Epoch 168 Divergences: Uniform: 3.165521626360301 Unigram: 3.7770522924407133
2022-02-02 23:00:39 | INFO | fairseq.trainer | begin training epoch 169
2022-02-02 23:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:04:50 | INFO | train_inner | epoch 169:     48 / 64 loss=5.221, ppl=37.29, wps=5944.5, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=10800, lr=0.00030429, gnorm=1.106, train_wall=519, gb_free=6.1, wall=60780
2022-02-02 23:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:06:40 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 10.045 | ppl 1056.8 | wps 7776.8 | wpb 2034.1 | bsz 4 | num_updates 10816 | best_loss 9.232
2022-02-02 23:06:40 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-02-02 23:06:40 | INFO | train | epoch 169 | loss 5.219 | ppl 37.25 | wps 5781.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10816 | lr 0.000304065 | gnorm 1.094 | train_wall 331 | gb_free 6.1 | wall 60891
KL Stats: Epoch 169 Divergences: Uniform: 3.1673886120927848 Unigram: 3.7841753629488886
2022-02-02 23:06:40 | INFO | fairseq.trainer | begin training epoch 170
2022-02-02 23:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:12:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:12:41 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 10.029 | ppl 1044.55 | wps 7775 | wpb 2034.1 | bsz 4 | num_updates 10880 | best_loss 9.232
2022-02-02 23:12:41 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-02-02 23:12:41 | INFO | train | epoch 170 | loss 5.214 | ppl 37.12 | wps 5780.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10880 | lr 0.00030317 | gnorm 1.083 | train_wall 331 | gb_free 6.1 | wall 61252
KL Stats: Epoch 170 Divergences: Uniform: 3.1677745606599785 Unigram: 3.790467086179067
2022-02-02 23:12:41 | INFO | fairseq.trainer | begin training epoch 171
2022-02-02 23:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:14:26 | INFO | train_inner | epoch 171:     20 / 64 loss=5.213, ppl=37.09, wps=5654.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=10900, lr=0.000302891, gnorm=1.095, train_wall=518, gb_free=6.1, wall=61357
2022-02-02 23:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:18:44 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 10.06 | ppl 1067.21 | wps 7731.1 | wpb 2034.1 | bsz 4 | num_updates 10944 | best_loss 9.232
2022-02-02 23:18:44 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-02-02 23:18:44 | INFO | train | epoch 171 | loss 5.209 | ppl 37 | wps 5765.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 10944 | lr 0.000302282 | gnorm 1.113 | train_wall 332 | gb_free 6.1 | wall 61614
KL Stats: Epoch 171 Divergences: Uniform: 3.168936115553577 Unigram: 3.79533084043121
2022-02-02 23:18:44 | INFO | fairseq.trainer | begin training epoch 172
2022-02-02 23:18:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:23:36 | INFO | train_inner | epoch 172:     56 / 64 loss=5.207, ppl=36.94, wps=5939.3, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11000, lr=0.000301511, gnorm=1.119, train_wall=519, gb_free=6.1, wall=61907
2022-02-02 23:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:24:45 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 10.035 | ppl 1048.89 | wps 7753.6 | wpb 2034.1 | bsz 4 | num_updates 11008 | best_loss 9.232
2022-02-02 23:24:45 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-02-02 23:24:45 | INFO | train | epoch 172 | loss 5.204 | ppl 36.86 | wps 5780.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11008 | lr 0.000301402 | gnorm 1.138 | train_wall 331 | gb_free 6.1 | wall 61976
KL Stats: Epoch 172 Divergences: Uniform: 3.1734582014841552 Unigram: 3.798861876414503
2022-02-02 23:24:45 | INFO | fairseq.trainer | begin training epoch 173
2022-02-02 23:24:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:30:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:30:46 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 10.036 | ppl 1050.16 | wps 7755.9 | wpb 2034.1 | bsz 4 | num_updates 11072 | best_loss 9.232
2022-02-02 23:30:46 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-02-02 23:30:46 | INFO | train | epoch 173 | loss 5.197 | ppl 36.68 | wps 5782.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11072 | lr 0.000300529 | gnorm 1.164 | train_wall 331 | gb_free 6.1 | wall 62337
KL Stats: Epoch 173 Divergences: Uniform: 3.176570573595964 Unigram: 3.801579080472456
2022-02-02 23:30:46 | INFO | fairseq.trainer | begin training epoch 174
2022-02-02 23:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:33:13 | INFO | train_inner | epoch 174:     28 / 64 loss=5.192, ppl=36.55, wps=5657.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=11100, lr=0.00030015, gnorm=1.146, train_wall=517, gb_free=6.1, wall=62483
2022-02-02 23:36:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:36:48 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 10.008 | ppl 1029.64 | wps 7749.3 | wpb 2034.1 | bsz 4 | num_updates 11136 | best_loss 9.232
2022-02-02 23:36:48 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-02-02 23:36:48 | INFO | train | epoch 174 | loss 5.192 | ppl 36.55 | wps 5775.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11136 | lr 0.000299665 | gnorm 1.13 | train_wall 332 | gb_free 6.1 | wall 62698
KL Stats: Epoch 174 Divergences: Uniform: 3.1779854668017444 Unigram: 3.80670847789055
2022-02-02 23:36:48 | INFO | fairseq.trainer | begin training epoch 175
2022-02-02 23:36:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:42:21 | INFO | train_inner | epoch 175:     64 / 64 loss=5.2, ppl=36.75, wps=5946.8, ups=0.18, wpb=32597.5, bsz=63.7, num_updates=11200, lr=0.000298807, gnorm=1.165, train_wall=517, gb_free=6.1, wall=63031
2022-02-02 23:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:42:49 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 10.04 | ppl 1052.72 | wps 7740.8 | wpb 2034.1 | bsz 4 | num_updates 11200 | best_loss 9.232
2022-02-02 23:42:49 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-02-02 23:42:49 | INFO | train | epoch 175 | loss 5.186 | ppl 36.41 | wps 5783.3 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11200 | lr 0.000298807 | gnorm 1.171 | train_wall 331 | gb_free 6.1 | wall 63060
KL Stats: Epoch 175 Divergences: Uniform: 3.1795582847493624 Unigram: 3.819793555559818
2022-02-02 23:42:49 | INFO | fairseq.trainer | begin training epoch 176
2022-02-02 23:42:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:48:51 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 10.04 | ppl 1053.06 | wps 7759.9 | wpb 2034.1 | bsz 4 | num_updates 11264 | best_loss 9.232
2022-02-02 23:48:51 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-02-02 23:48:51 | INFO | train | epoch 176 | loss 5.184 | ppl 36.34 | wps 5777.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11264 | lr 0.000297957 | gnorm 1.169 | train_wall 332 | gb_free 6.1 | wall 63421
KL Stats: Epoch 176 Divergences: Uniform: 3.178567627404353 Unigram: 3.8177287533078994
2022-02-02 23:48:51 | INFO | fairseq.trainer | begin training epoch 177
2022-02-02 23:48:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-02 23:51:59 | INFO | train_inner | epoch 177:     36 / 64 loss=5.171, ppl=36.03, wps=5652.9, ups=0.17, wpb=32679.4, bsz=63.8, num_updates=11300, lr=0.000297482, gnorm=1.177, train_wall=519, gb_free=6.1, wall=63609
2022-02-02 23:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-02 23:54:52 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 10.035 | ppl 1048.8 | wps 7735 | wpb 2034.1 | bsz 4 | num_updates 11328 | best_loss 9.232
2022-02-02 23:54:52 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-02-02 23:54:52 | INFO | train | epoch 177 | loss 5.176 | ppl 36.14 | wps 5776.5 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11328 | lr 0.000297114 | gnorm 1.168 | train_wall 332 | gb_free 6.1 | wall 63783
KL Stats: Epoch 177 Divergences: Uniform: 3.1763280295182796 Unigram: 3.818039678014018
2022-02-02 23:54:52 | INFO | fairseq.trainer | begin training epoch 178
2022-02-02 23:54:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:00:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:00:54 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 10.032 | ppl 1047.3 | wps 7762.1 | wpb 2034.1 | bsz 4 | num_updates 11392 | best_loss 9.232
2022-02-03 00:00:54 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-02-03 00:00:54 | INFO | train | epoch 178 | loss 5.171 | ppl 36.02 | wps 5777.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11392 | lr 0.000296278 | gnorm 1.193 | train_wall 332 | gb_free 6.1 | wall 64144
KL Stats: Epoch 178 Divergences: Uniform: 3.182082268591727 Unigram: 3.8228206524465858
2022-02-03 00:00:54 | INFO | fairseq.trainer | begin training epoch 179
2022-02-03 00:00:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:01:36 | INFO | train_inner | epoch 179:      8 / 64 loss=5.176, ppl=36.16, wps=5653.2, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11400, lr=0.000296174, gnorm=1.181, train_wall=518, gb_free=6.1, wall=64186
2022-02-03 00:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:06:55 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 10.077 | ppl 1079.78 | wps 7758.9 | wpb 2034.1 | bsz 4 | num_updates 11456 | best_loss 9.232
2022-02-03 00:06:55 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-02-03 00:06:55 | INFO | train | epoch 179 | loss 5.166 | ppl 35.91 | wps 5775.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11456 | lr 0.00029545 | gnorm 1.183 | train_wall 332 | gb_free 6.1 | wall 64506
KL Stats: Epoch 179 Divergences: Uniform: 3.175181185569543 Unigram: 3.8273302032531658
2022-02-03 00:06:55 | INFO | fairseq.trainer | begin training epoch 180
2022-02-03 00:06:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:10:45 | INFO | train_inner | epoch 180:     44 / 64 loss=5.16, ppl=35.76, wps=5944.1, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11500, lr=0.000294884, gnorm=1.188, train_wall=519, gb_free=6.1, wall=64736
2022-02-03 00:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:12:57 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 10.079 | ppl 1081.61 | wps 7753.8 | wpb 2034.1 | bsz 4 | num_updates 11520 | best_loss 9.232
2022-02-03 00:12:57 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-02-03 00:12:57 | INFO | train | epoch 180 | loss 5.162 | ppl 35.81 | wps 5777.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11520 | lr 0.000294628 | gnorm 1.2 | train_wall 332 | gb_free 6.1 | wall 64867
KL Stats: Epoch 180 Divergences: Uniform: 3.1857638887125175 Unigram: 3.831692512544377
2022-02-03 00:12:57 | INFO | fairseq.trainer | begin training epoch 181
2022-02-03 00:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:18:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:18:58 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 10.118 | ppl 1111.58 | wps 7764.2 | wpb 2034.1 | bsz 4 | num_updates 11584 | best_loss 9.232
2022-02-03 00:18:58 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-02-03 00:18:58 | INFO | train | epoch 181 | loss 5.158 | ppl 35.69 | wps 5778.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11584 | lr 0.000293813 | gnorm 1.214 | train_wall 332 | gb_free 6.1 | wall 65229
KL Stats: Epoch 181 Divergences: Uniform: 3.179794970164022 Unigram: 3.8361578506202205
2022-02-03 00:18:58 | INFO | fairseq.trainer | begin training epoch 182
2022-02-03 00:18:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:20:22 | INFO | train_inner | epoch 182:     16 / 64 loss=5.159, ppl=35.73, wps=5655.1, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=11600, lr=0.00029361, gnorm=1.214, train_wall=517, gb_free=6.1, wall=65312
2022-02-03 00:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:25:00 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 10.064 | ppl 1070.51 | wps 7749.8 | wpb 2034.1 | bsz 4 | num_updates 11648 | best_loss 9.232
2022-02-03 00:25:00 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-02-03 00:25:00 | INFO | train | epoch 182 | loss 5.154 | ppl 35.6 | wps 5779.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11648 | lr 0.000293005 | gnorm 1.219 | train_wall 331 | gb_free 6.1 | wall 65590
KL Stats: Epoch 182 Divergences: Uniform: 3.1907782046677426 Unigram: 3.8339811319570463
2022-02-03 00:25:00 | INFO | fairseq.trainer | begin training epoch 183
2022-02-03 00:25:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:29:32 | INFO | train_inner | epoch 183:     52 / 64 loss=5.15, ppl=35.51, wps=5943.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=11700, lr=0.000292353, gnorm=1.196, train_wall=519, gb_free=6.1, wall=65862
2022-02-03 00:30:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:31:01 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 10.038 | ppl 1051.17 | wps 7759 | wpb 2034.1 | bsz 4 | num_updates 11712 | best_loss 9.232
2022-02-03 00:31:01 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-02-03 00:31:01 | INFO | train | epoch 183 | loss 5.146 | ppl 35.4 | wps 5773.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11712 | lr 0.000292203 | gnorm 1.187 | train_wall 332 | gb_free 6.1 | wall 65952
KL Stats: Epoch 183 Divergences: Uniform: 3.1830029696080615 Unigram: 3.844441690076683
2022-02-03 00:31:01 | INFO | fairseq.trainer | begin training epoch 184
2022-02-03 00:31:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:37:03 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 10.112 | ppl 1106.71 | wps 7770.8 | wpb 2034.1 | bsz 4 | num_updates 11776 | best_loss 9.232
2022-02-03 00:37:03 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-02-03 00:37:03 | INFO | train | epoch 184 | loss 5.143 | ppl 35.33 | wps 5776.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11776 | lr 0.000291408 | gnorm 1.258 | train_wall 332 | gb_free 6.1 | wall 66313
KL Stats: Epoch 184 Divergences: Uniform: 3.1879309892548595 Unigram: 3.849236958618435
2022-02-03 00:37:03 | INFO | fairseq.trainer | begin training epoch 185
2022-02-03 00:37:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:39:08 | INFO | train_inner | epoch 185:     24 / 64 loss=5.142, ppl=35.3, wps=5652.4, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=11800, lr=0.000291111, gnorm=1.256, train_wall=518, gb_free=6.1, wall=66439
2022-02-03 00:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:43:04 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 10.103 | ppl 1099.4 | wps 7789.6 | wpb 2034.1 | bsz 4 | num_updates 11840 | best_loss 9.232
2022-02-03 00:43:04 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-02-03 00:43:04 | INFO | train | epoch 185 | loss 5.138 | ppl 35.22 | wps 5780 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11840 | lr 0.000290619 | gnorm 1.262 | train_wall 332 | gb_free 6.1 | wall 66675
KL Stats: Epoch 185 Divergences: Uniform: 3.183308549737909 Unigram: 3.8451794615016213
2022-02-03 00:43:04 | INFO | fairseq.trainer | begin training epoch 186
2022-02-03 00:43:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:48:18 | INFO | train_inner | epoch 186:     60 / 64 loss=5.139, ppl=35.23, wps=5948.8, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=11900, lr=0.000289886, gnorm=1.237, train_wall=519, gb_free=6.1, wall=66988
2022-02-03 00:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:49:06 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 10.133 | ppl 1122.82 | wps 7765.2 | wpb 2034.1 | bsz 4 | num_updates 11904 | best_loss 9.232
2022-02-03 00:49:06 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-02-03 00:49:06 | INFO | train | epoch 186 | loss 5.131 | ppl 35.03 | wps 5781.1 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11904 | lr 0.000289837 | gnorm 1.227 | train_wall 331 | gb_free 6.1 | wall 67036
KL Stats: Epoch 186 Divergences: Uniform: 3.1859677496138437 Unigram: 3.856741773357298
2022-02-03 00:49:06 | INFO | fairseq.trainer | begin training epoch 187
2022-02-03 00:49:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:54:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 00:55:07 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 10.11 | ppl 1104.78 | wps 7774 | wpb 2034.1 | bsz 4 | num_updates 11968 | best_loss 9.232
2022-02-03 00:55:07 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-02-03 00:55:07 | INFO | train | epoch 187 | loss 5.129 | ppl 35 | wps 5778.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 11968 | lr 0.000289061 | gnorm 1.263 | train_wall 332 | gb_free 6.1 | wall 67398
KL Stats: Epoch 187 Divergences: Uniform: 3.1894487272195695 Unigram: 3.8542247434430688
2022-02-03 00:55:07 | INFO | fairseq.trainer | begin training epoch 188
2022-02-03 00:55:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 00:57:54 | INFO | train_inner | epoch 188:     32 / 64 loss=5.121, ppl=34.79, wps=5655, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12000, lr=0.000288675, gnorm=1.245, train_wall=518, gb_free=6.1, wall=67565
2022-02-03 01:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:01:08 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 10.138 | ppl 1126.74 | wps 7755.5 | wpb 2034.1 | bsz 4 | num_updates 12032 | best_loss 9.232
2022-02-03 01:01:08 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-02-03 01:01:08 | INFO | train | epoch 188 | loss 5.124 | ppl 34.87 | wps 5777.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12032 | lr 0.000288291 | gnorm 1.235 | train_wall 332 | gb_free 6.1 | wall 67759
KL Stats: Epoch 188 Divergences: Uniform: 3.1828325682621874 Unigram: 3.8608352849073957
2022-02-03 01:01:08 | INFO | fairseq.trainer | begin training epoch 189
2022-02-03 01:01:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:07:10 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 10.119 | ppl 1112.09 | wps 7765.8 | wpb 2034.1 | bsz 4 | num_updates 12096 | best_loss 9.232
2022-02-03 01:07:10 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-02-03 01:07:10 | INFO | train | epoch 189 | loss 5.119 | ppl 34.76 | wps 5779.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12096 | lr 0.000287527 | gnorm 1.285 | train_wall 331 | gb_free 6.1 | wall 68120
KL Stats: Epoch 189 Divergences: Uniform: 3.1870643564504464 Unigram: 3.868637024007053
2022-02-03 01:07:10 | INFO | fairseq.trainer | begin training epoch 190
2022-02-03 01:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:07:31 | INFO | train_inner | epoch 190:      4 / 64 loss=5.128, ppl=34.98, wps=5653.8, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12100, lr=0.00028748, gnorm=1.276, train_wall=517, gb_free=6.1, wall=68141
2022-02-03 01:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:13:11 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 10.118 | ppl 1111.46 | wps 7779.7 | wpb 2034.1 | bsz 4 | num_updates 12160 | best_loss 9.232
2022-02-03 01:13:11 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-02-03 01:13:11 | INFO | train | epoch 190 | loss 5.114 | ppl 34.62 | wps 5778.4 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12160 | lr 0.00028677 | gnorm 1.298 | train_wall 332 | gb_free 6.1 | wall 68482
KL Stats: Epoch 190 Divergences: Uniform: 3.189726561374046 Unigram: 3.87208328678827
2022-02-03 01:13:11 | INFO | fairseq.trainer | begin training epoch 191
2022-02-03 01:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:16:40 | INFO | train_inner | epoch 191:     40 / 64 loss=5.105, ppl=34.41, wps=5948.8, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12200, lr=0.000286299, gnorm=1.282, train_wall=519, gb_free=6.1, wall=68691
2022-02-03 01:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:19:13 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 10.149 | ppl 1135.25 | wps 7741.4 | wpb 2034.1 | bsz 4 | num_updates 12224 | best_loss 9.232
2022-02-03 01:19:13 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-02-03 01:19:13 | INFO | train | epoch 191 | loss 5.11 | ppl 34.54 | wps 5778 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12224 | lr 0.000286018 | gnorm 1.272 | train_wall 332 | gb_free 6.1 | wall 68843
KL Stats: Epoch 191 Divergences: Uniform: 3.188124397094124 Unigram: 3.8736160583513026
2022-02-03 01:19:13 | INFO | fairseq.trainer | begin training epoch 192
2022-02-03 01:19:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:24:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:25:14 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 10.133 | ppl 1123.04 | wps 7770.4 | wpb 2034.1 | bsz 4 | num_updates 12288 | best_loss 9.232
2022-02-03 01:25:14 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-02-03 01:25:14 | INFO | train | epoch 192 | loss 5.108 | ppl 34.49 | wps 5783.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12288 | lr 0.000285272 | gnorm 1.309 | train_wall 331 | gb_free 6.1 | wall 69204
KL Stats: Epoch 192 Divergences: Uniform: 3.189622769290164 Unigram: 3.8721374051601583
2022-02-03 01:25:14 | INFO | fairseq.trainer | begin training epoch 193
2022-02-03 01:25:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:26:17 | INFO | train_inner | epoch 193:     12 / 64 loss=5.111, ppl=34.57, wps=5656, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12300, lr=0.000285133, gnorm=1.307, train_wall=517, gb_free=6.1, wall=69267
2022-02-03 01:30:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:31:15 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 10.129 | ppl 1119.4 | wps 7764.8 | wpb 2034.1 | bsz 4 | num_updates 12352 | best_loss 9.232
2022-02-03 01:31:15 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-02-03 01:31:15 | INFO | train | epoch 193 | loss 5.103 | ppl 34.36 | wps 5783.8 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12352 | lr 0.000284532 | gnorm 1.307 | train_wall 331 | gb_free 6.1 | wall 69566
KL Stats: Epoch 193 Divergences: Uniform: 3.1931165383225064 Unigram: 3.881724333900692
2022-02-03 01:31:15 | INFO | fairseq.trainer | begin training epoch 194
2022-02-03 01:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:35:26 | INFO | train_inner | epoch 194:     48 / 64 loss=5.101, ppl=34.32, wps=5943.1, ups=0.18, wpb=32679.4, bsz=63.8, num_updates=12400, lr=0.000283981, gnorm=1.306, train_wall=519, gb_free=6.1, wall=69817
2022-02-03 01:36:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:37:17 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 10.138 | ppl 1126.79 | wps 7740.4 | wpb 2034.1 | bsz 4 | num_updates 12416 | best_loss 9.232
2022-02-03 01:37:17 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-02-03 01:37:17 | INFO | train | epoch 194 | loss 5.099 | ppl 34.27 | wps 5768.6 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12416 | lr 0.000283798 | gnorm 1.304 | train_wall 332 | gb_free 6.1 | wall 69928
KL Stats: Epoch 194 Divergences: Uniform: 3.189460727621384 Unigram: 3.878375228859825
2022-02-03 01:37:17 | INFO | fairseq.trainer | begin training epoch 195
2022-02-03 01:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:43:19 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 10.1 | ppl 1097.24 | wps 7765.3 | wpb 2034.1 | bsz 4 | num_updates 12480 | best_loss 9.232
2022-02-03 01:43:19 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-02-03 01:43:19 | INFO | train | epoch 195 | loss 5.092 | ppl 34.1 | wps 5776 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12480 | lr 0.000283069 | gnorm 1.299 | train_wall 332 | gb_free 6.1 | wall 70289
KL Stats: Epoch 195 Divergences: Uniform: 3.1969444619461105 Unigram: 3.8880838632477794
2022-02-03 01:43:19 | INFO | fairseq.trainer | begin training epoch 196
2022-02-03 01:43:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:45:03 | INFO | train_inner | epoch 196:     20 / 64 loss=5.09, ppl=34.07, wps=5650.9, ups=0.17, wpb=32597.5, bsz=63.7, num_updates=12500, lr=0.000282843, gnorm=1.311, train_wall=518, gb_free=6.1, wall=70394
2022-02-03 01:48:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:49:20 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 10.11 | ppl 1105.28 | wps 7751.9 | wpb 2034.1 | bsz 4 | num_updates 12544 | best_loss 9.232
2022-02-03 01:49:20 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-02-03 01:49:20 | INFO | train | epoch 196 | loss 5.09 | ppl 34.07 | wps 5773.7 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12544 | lr 0.000282346 | gnorm 1.386 | train_wall 332 | gb_free 6.1 | wall 70651
KL Stats: Epoch 196 Divergences: Uniform: 3.1908670279168048 Unigram: 3.889422365892108
2022-02-03 01:49:20 | INFO | fairseq.trainer | begin training epoch 197
2022-02-03 01:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 01:54:13 | INFO | train_inner | epoch 197:     56 / 64 loss=5.092, ppl=34.11, wps=5941.3, ups=0.18, wpb=32682.8, bsz=63.8, num_updates=12600, lr=0.000281718, gnorm=1.362, train_wall=519, gb_free=6.1, wall=70944
2022-02-03 01:54:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 01:55:22 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 10.079 | ppl 1081.28 | wps 7753.1 | wpb 2034.1 | bsz 4 | num_updates 12608 | best_loss 9.232
2022-02-03 01:55:22 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-02-03 01:55:22 | INFO | train | epoch 197 | loss 5.084 | ppl 33.93 | wps 5775.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12608 | lr 0.000281629 | gnorm 1.334 | train_wall 332 | gb_free 6.1 | wall 71013
KL Stats: Epoch 197 Divergences: Uniform: 3.197723896832557 Unigram: 3.894040114288059
2022-02-03 01:55:22 | INFO | fairseq.trainer | begin training epoch 198
2022-02-03 01:55:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:00:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:01:24 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 10.181 | ppl 1161.17 | wps 7739.9 | wpb 2034.1 | bsz 4 | num_updates 12672 | best_loss 9.232
2022-02-03 02:01:24 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-02-03 02:01:24 | INFO | train | epoch 198 | loss 5.081 | ppl 33.84 | wps 5772.2 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12672 | lr 0.000280917 | gnorm 1.367 | train_wall 332 | gb_free 6.1 | wall 71374
KL Stats: Epoch 198 Divergences: Uniform: 3.196138985888248 Unigram: 3.900561351962371
2022-02-03 02:01:24 | INFO | fairseq.trainer | begin training epoch 199
2022-02-03 02:01:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-02-03 02:03:51 | INFO | train_inner | epoch 199:     28 / 64 loss=5.076, ppl=33.74, wps=5648.9, ups=0.17, wpb=32600.8, bsz=63.7, num_updates=12700, lr=0.000280607, gnorm=1.378, train_wall=518, gb_free=6.1, wall=71521
2022-02-03 02:06:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-02-03 02:07:26 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 10.126 | ppl 1117.42 | wps 7754.9 | wpb 2034.1 | bsz 4 | num_updates 12736 | best_loss 9.232
2022-02-03 02:07:26 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-02-03 02:07:26 | INFO | train | epoch 199 | loss 5.078 | ppl 33.79 | wps 5768.9 | ups 0.18 | wpb 32634.8 | bsz 63.8 | num_updates 12736 | lr 0.00028021 | gnorm 1.376 | train_wall 332 | gb_free 6.1 | wall 71737
KL Stats: Epoch 199 Divergences: Uniform: 3.200054582997105 Unigram: 3.9032291489815742
2022-02-03 02:07:26 | INFO | fairseq.trainer | begin training epoch 200
2022-02-03 02:07:26 | INFO | fairseq_cli.train | Start iterating over samples
User defined signal 2
