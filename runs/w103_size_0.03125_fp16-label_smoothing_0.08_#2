Sender: LSF System <lsfadmin@eu-g2-10>
Subject: Job 207345749: <w103_size_0.03125_fp16_label_smoothing_0.08_#2> in cluster <euler> Done

Job <w103_size_0.03125_fp16_label_smoothing_0.08_#2> was submitted from host <eu-login-10> by user <andriusb> in cluster <euler> at Sun Mar  6 13:01:51 2022
Job was executed on host(s) <eu-g2-10>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Sun Mar  6 13:02:19 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Sun Mar  6 13:02:19 2022
Terminated at Tue Mar  8 02:43:56 2022
Results reported at Tue Mar  8 02:43:56 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-raw-size-0.03125 --save-dir /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.1 --criterion label_smoothed_cross_entropy --label-smoothing 0.08 --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 128 --seed 66575622 --fp16 --no-epoch-checkpoints --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   143834.38 sec.
    Max Memory :                                 7333 MB
    Average Memory :                             3782.89 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               12667.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   135696 sec.
    Turnaround time :                            135725 sec.

The output (if any) follows:

2022-03-06 13:02:30 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575622, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [128], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.1, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-raw-size-0.03125', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575622, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.08, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-06 13:02:30 | INFO | fairseq.tasks.language_modeling | dictionary: 96056 types
2022-03-06 13:02:32 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(96056, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=96056, bias=False)
  )
)
2022-03-06 13:02:32 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-06 13:02:32 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-06 13:02:32 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2022-03-06 13:02:32 | INFO | fairseq_cli.train | num. shared model params: 68,094,976 (num. trained: 68,094,976)
2022-03-06 13:02:32 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-06 13:02:32 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-raw-size-0.03125/valid
2022-03-06 13:02:35 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-06 13:02:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:35 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-06 13:02:35 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-06 13:02:35 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-06 13:02:35 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-06 13:02:35 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 13:02:35 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 13:02:35 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-06 13:02:35 | INFO | fairseq.data.data_utils | loaded 56,292 examples from: data-bin/wikitext-103-raw-size-0.03125/train
2022-03-06 13:02:35 | INFO | fairseq.trainer | begin training epoch 1
2022-03-06 13:02:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:02:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-06 13:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:02:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 13:02:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 13:04:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-06 13:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:04:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 15.477 | nll_loss 15.314 | ppl 40724.2 | wps 45273.1 | wpb 510.9 | bsz 1 | num_updates 44
2022-03-06 13:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 44 updates
2022-03-06 13:04:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:04:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 1 @ 44 updates, score 15.477) (writing took 4.319634140934795 seconds)
2022-03-06 13:04:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-06 13:04:59 | INFO | train | epoch 001 | loss 16.576 | nll_loss 16.508 | ppl 93169.8 | wps 23687.2 | ups 0.37 | wpb 64781.2 | bsz 126.5 | num_updates 44 | lr 5.5989e-06 | gnorm 4.846 | loss_scale 4 | train_wall 123 | gb_free 8.8 | wall 144
2022-03-06 13:04:59 | INFO | fairseq.trainer | begin training epoch 2
2022-03-06 13:04:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:07:05 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.111 | nll_loss 13.827 | ppl 14535.4 | wps 45320.8 | wpb 510.9 | bsz 1 | num_updates 93 | best_loss 14.111
2022-03-06 13:07:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 93 updates
2022-03-06 13:07:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:07:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 2 @ 93 updates, score 14.111) (writing took 4.551677794661373 seconds)
2022-03-06 13:07:10 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-06 13:07:10 | INFO | train | epoch 002 | loss 14.815 | nll_loss 14.595 | ppl 24754.2 | wps 24395 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 93 | lr 1.17227e-05 | gnorm 2.068 | loss_scale 4 | train_wall 109 | gb_free 8.8 | wall 274
2022-03-06 13:07:10 | INFO | fairseq.trainer | begin training epoch 3
2022-03-06 13:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:07:27 | INFO | train_inner | epoch 003:      7 / 49 loss=15.545, nll_loss=15.387, ppl=42861.7, wps=24190.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=100, lr=1.25975e-05, gnorm=3.243, loss_scale=4, train_wall=247, gb_free=8.8, wall=292
2022-03-06 13:09:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:09:16 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.49 | nll_loss 13.157 | ppl 9133.15 | wps 45339.7 | wpb 510.9 | bsz 1 | num_updates 142 | best_loss 13.49
2022-03-06 13:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 142 updates
2022-03-06 13:09:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:09:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 3 @ 142 updates, score 13.49) (writing took 4.495534454006702 seconds)
2022-03-06 13:09:20 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-06 13:09:20 | INFO | train | epoch 003 | loss 13.931 | nll_loss 13.636 | ppl 12729.3 | wps 24381.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 142 | lr 1.78465e-05 | gnorm 1.306 | loss_scale 4 | train_wall 109 | gb_free 8.8 | wall 405
2022-03-06 13:09:20 | INFO | fairseq.trainer | begin training epoch 4
2022-03-06 13:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:11:26 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.733 | nll_loss 12.329 | ppl 5144.44 | wps 45120.4 | wpb 510.9 | bsz 1 | num_updates 191 | best_loss 12.733
2022-03-06 13:11:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 191 updates
2022-03-06 13:11:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:11:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:11:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 4 @ 191 updates, score 12.733) (writing took 4.61912762792781 seconds)
2022-03-06 13:11:31 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-06 13:11:31 | INFO | train | epoch 004 | loss 13.241 | nll_loss 12.887 | ppl 7574.67 | wps 24343.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 191 | lr 2.39702e-05 | gnorm 1.14 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 535
2022-03-06 13:11:31 | INFO | fairseq.trainer | begin training epoch 5
2022-03-06 13:11:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:11:53 | INFO | train_inner | epoch 005:      9 / 49 loss=13.467, nll_loss=13.132, ppl=8978.38, wps=24411.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=200, lr=2.5095e-05, gnorm=1.19, loss_scale=8, train_wall=222, gb_free=8.8, wall=558
2022-03-06 13:13:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:13:36 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.005 | nll_loss 11.522 | ppl 2939.9 | wps 46100.5 | wpb 510.9 | bsz 1 | num_updates 240 | best_loss 12.005
2022-03-06 13:13:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 240 updates
2022-03-06 13:13:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:13:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 5 @ 240 updates, score 12.005) (writing took 4.4429620751179755 seconds)
2022-03-06 13:13:40 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-06 13:13:40 | INFO | train | epoch 005 | loss 12.442 | nll_loss 12.009 | ppl 4121.72 | wps 24560.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 240 | lr 3.0094e-05 | gnorm 0.905 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 665
2022-03-06 13:13:40 | INFO | fairseq.trainer | begin training epoch 6
2022-03-06 13:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:15:45 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.425 | nll_loss 10.867 | ppl 1867.23 | wps 46085.8 | wpb 510.9 | bsz 1 | num_updates 289 | best_loss 11.425
2022-03-06 13:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 289 updates
2022-03-06 13:15:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:15:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:15:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 6 @ 289 updates, score 11.425) (writing took 4.649585718754679 seconds)
2022-03-06 13:15:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-06 13:15:50 | INFO | train | epoch 006 | loss 11.75 | nll_loss 11.238 | ppl 2414.81 | wps 24498.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 289 | lr 3.62178e-05 | gnorm 0.703 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 795
2022-03-06 13:15:50 | INFO | fairseq.trainer | begin training epoch 7
2022-03-06 13:15:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:16:17 | INFO | train_inner | epoch 007:     11 / 49 loss=11.958, nll_loss=11.469, ppl=2834.95, wps=24562.6, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=300, lr=3.75925e-05, gnorm=0.767, loss_scale=16, train_wall=221, gb_free=8.8, wall=822
2022-03-06 13:17:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:17:55 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.056 | nll_loss 10.433 | ppl 1382.41 | wps 45327.2 | wpb 510.9 | bsz 1 | num_updates 338 | best_loss 11.056
2022-03-06 13:17:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 338 updates
2022-03-06 13:17:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:17:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:18:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 7 @ 338 updates, score 11.056) (writing took 4.498299253638834 seconds)
2022-03-06 13:18:00 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-06 13:18:00 | INFO | train | epoch 007 | loss 11.236 | nll_loss 10.65 | ppl 1607.37 | wps 24405.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 338 | lr 4.23416e-05 | gnorm 0.552 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 925
2022-03-06 13:18:00 | INFO | fairseq.trainer | begin training epoch 8
2022-03-06 13:18:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:20:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:20:06 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.828 | nll_loss 10.155 | ppl 1139.85 | wps 45574.3 | wpb 510.9 | bsz 1 | num_updates 387 | best_loss 10.828
2022-03-06 13:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 387 updates
2022-03-06 13:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:20:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 8 @ 387 updates, score 10.828) (writing took 4.52558866282925 seconds)
2022-03-06 13:20:10 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-06 13:20:10 | INFO | train | epoch 008 | loss 10.918 | nll_loss 10.274 | ppl 1237.89 | wps 24360.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 387 | lr 4.84653e-05 | gnorm 0.464 | loss_scale 16 | train_wall 109 | gb_free 8.8 | wall 1055
2022-03-06 13:20:10 | INFO | fairseq.trainer | begin training epoch 9
2022-03-06 13:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:20:43 | INFO | train_inner | epoch 009:     13 / 49 loss=11.003, nll_loss=10.374, ppl=1327.33, wps=24409.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=400, lr=5.009e-05, gnorm=0.481, loss_scale=16, train_wall=222, gb_free=8.8, wall=1088
2022-03-06 13:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:22:16 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.669 | nll_loss 9.959 | ppl 995.41 | wps 45406.1 | wpb 510.9 | bsz 1 | num_updates 436 | best_loss 10.669
2022-03-06 13:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 436 updates
2022-03-06 13:22:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:22:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 9 @ 436 updates, score 10.669) (writing took 4.501579595729709 seconds)
2022-03-06 13:22:21 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-06 13:22:21 | INFO | train | epoch 009 | loss 10.714 | nll_loss 10.026 | ppl 1042.31 | wps 24367.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 436 | lr 5.45891e-05 | gnorm 0.458 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 1186
2022-03-06 13:22:21 | INFO | fairseq.trainer | begin training epoch 10
2022-03-06 13:22:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:24:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:24:27 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.528 | nll_loss 9.796 | ppl 888.72 | wps 45157.7 | wpb 510.9 | bsz 1 | num_updates 485 | best_loss 10.528
2022-03-06 13:24:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 485 updates
2022-03-06 13:24:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:24:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 10 @ 485 updates, score 10.528) (writing took 4.520908706821501 seconds)
2022-03-06 13:24:31 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-06 13:24:31 | INFO | train | epoch 010 | loss 10.549 | nll_loss 9.83 | ppl 910.31 | wps 24358.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 485 | lr 6.07129e-05 | gnorm 0.482 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 1316
2022-03-06 13:24:31 | INFO | fairseq.trainer | begin training epoch 11
2022-03-06 13:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:25:09 | INFO | train_inner | epoch 011:     15 / 49 loss=10.583, nll_loss=9.87, ppl=936.07, wps=24389.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=500, lr=6.25875e-05, gnorm=0.484, loss_scale=32, train_wall=223, gb_free=8.8, wall=1354
2022-03-06 13:26:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:26:37 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.384 | nll_loss 9.631 | ppl 793.02 | wps 45331.4 | wpb 510.9 | bsz 1 | num_updates 534 | best_loss 10.384
2022-03-06 13:26:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 534 updates
2022-03-06 13:26:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:26:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 11 @ 534 updates, score 10.384) (writing took 4.503410638310015 seconds)
2022-03-06 13:26:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-06 13:26:42 | INFO | train | epoch 011 | loss 10.394 | nll_loss 9.653 | ppl 805.22 | wps 24368.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 534 | lr 6.68367e-05 | gnorm 0.542 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 1446
2022-03-06 13:26:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-06 13:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:27:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:28:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:28:48 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.262 | nll_loss 9.493 | ppl 720.54 | wps 45561.3 | wpb 510.9 | bsz 1 | num_updates 582 | best_loss 10.262
2022-03-06 13:28:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 582 updates
2022-03-06 13:28:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:28:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 12 @ 582 updates, score 10.262) (writing took 4.500943566206843 seconds)
2022-03-06 13:28:52 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-06 13:28:52 | INFO | train | epoch 012 | loss 10.245 | nll_loss 9.485 | ppl 716.79 | wps 23838.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 582 | lr 7.28355e-05 | gnorm 0.615 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 1577
2022-03-06 13:28:52 | INFO | fairseq.trainer | begin training epoch 13
2022-03-06 13:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:29:37 | INFO | train_inner | epoch 013:     18 / 49 loss=10.27, nll_loss=9.513, ppl=730.76, wps=24173.4, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=600, lr=7.5085e-05, gnorm=0.599, loss_scale=32, train_wall=225, gb_free=8.8, wall=1622
2022-03-06 13:30:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:30:58 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.151 | nll_loss 9.371 | ppl 662.32 | wps 45199.6 | wpb 510.9 | bsz 1 | num_updates 631 | best_loss 10.151
2022-03-06 13:30:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 631 updates
2022-03-06 13:30:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:31:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 13 @ 631 updates, score 10.151) (writing took 4.505748567171395 seconds)
2022-03-06 13:31:03 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-06 13:31:03 | INFO | train | epoch 013 | loss 10.107 | nll_loss 9.331 | ppl 643.96 | wps 24360.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 631 | lr 7.89592e-05 | gnorm 0.619 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 1708
2022-03-06 13:31:03 | INFO | fairseq.trainer | begin training epoch 14
2022-03-06 13:31:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:33:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:33:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:33:09 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.051 | nll_loss 9.259 | ppl 612.8 | wps 45414.3 | wpb 510.9 | bsz 1 | num_updates 679 | best_loss 10.051
2022-03-06 13:33:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 679 updates
2022-03-06 13:33:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:33:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:33:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 14 @ 679 updates, score 10.051) (writing took 4.471693895757198 seconds)
2022-03-06 13:33:13 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-06 13:33:13 | INFO | train | epoch 014 | loss 9.975 | nll_loss 9.183 | ppl 581.12 | wps 23871.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 679 | lr 8.4958e-05 | gnorm 0.684 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 1838
2022-03-06 13:33:13 | INFO | fairseq.trainer | begin training epoch 15
2022-03-06 13:33:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:34:06 | INFO | train_inner | epoch 015:     21 / 49 loss=9.989, nll_loss=9.199, ppl=587.59, wps=24174.7, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=700, lr=8.75825e-05, gnorm=0.683, loss_scale=32, train_wall=225, gb_free=8.8, wall=1890
2022-03-06 13:35:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:35:19 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 9.942 | nll_loss 9.134 | ppl 561.85 | wps 45188.1 | wpb 510.9 | bsz 1 | num_updates 728 | best_loss 9.942
2022-03-06 13:35:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 728 updates
2022-03-06 13:35:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:35:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:35:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 15 @ 728 updates, score 9.942) (writing took 4.49216937366873 seconds)
2022-03-06 13:35:24 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-06 13:35:24 | INFO | train | epoch 015 | loss 9.85 | nll_loss 9.042 | ppl 526.99 | wps 24354.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 728 | lr 9.10818e-05 | gnorm 0.741 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 1968
2022-03-06 13:35:24 | INFO | fairseq.trainer | begin training epoch 16
2022-03-06 13:35:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:37:30 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 9.845 | nll_loss 9.016 | ppl 517.77 | wps 45278.4 | wpb 510.9 | bsz 1 | num_updates 777 | best_loss 9.845
2022-03-06 13:37:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 777 updates
2022-03-06 13:37:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:37:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:37:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 16 @ 777 updates, score 9.845) (writing took 4.485582966823131 seconds)
2022-03-06 13:37:34 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-06 13:37:34 | INFO | train | epoch 016 | loss 9.728 | nll_loss 8.904 | ppl 478.9 | wps 24383.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 777 | lr 9.72056e-05 | gnorm 0.798 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 2099
2022-03-06 13:37:34 | INFO | fairseq.trainer | begin training epoch 17
2022-03-06 13:37:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:38:32 | INFO | train_inner | epoch 017:     23 / 49 loss=9.733, nll_loss=8.91, ppl=480.92, wps=24398.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=800, lr=0.00010008, gnorm=0.763, loss_scale=32, train_wall=222, gb_free=8.8, wall=2156
2022-03-06 13:39:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:39:40 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.758 | nll_loss 8.913 | ppl 482.07 | wps 45482.9 | wpb 510.9 | bsz 1 | num_updates 825 | best_loss 9.758
2022-03-06 13:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 825 updates
2022-03-06 13:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 17 @ 825 updates, score 9.758) (writing took 4.545703026931733 seconds)
2022-03-06 13:39:44 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-06 13:39:44 | INFO | train | epoch 017 | loss 9.608 | nll_loss 8.769 | ppl 436.26 | wps 23852.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 825 | lr 0.000103204 | gnorm 0.805 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 2229
2022-03-06 13:39:44 | INFO | fairseq.trainer | begin training epoch 18
2022-03-06 13:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:41:50 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.668 | nll_loss 8.819 | ppl 451.68 | wps 45372.3 | wpb 510.9 | bsz 1 | num_updates 874 | best_loss 9.668
2022-03-06 13:41:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 874 updates
2022-03-06 13:41:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:41:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:41:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 18 @ 874 updates, score 9.668) (writing took 4.469399036839604 seconds)
2022-03-06 13:41:55 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-06 13:41:55 | INFO | train | epoch 018 | loss 9.494 | nll_loss 8.64 | ppl 399.04 | wps 24358.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 874 | lr 0.000109328 | gnorm 0.818 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 2360
2022-03-06 13:41:55 | INFO | fairseq.trainer | begin training epoch 19
2022-03-06 13:41:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:43:00 | INFO | train_inner | epoch 019:     26 / 49 loss=9.493, nll_loss=8.639, ppl=398.61, wps=24169.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=900, lr=0.000112578, gnorm=0.827, loss_scale=32, train_wall=225, gb_free=8.8, wall=2425
2022-03-06 13:43:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:44:01 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 9.594 | nll_loss 8.731 | ppl 424.76 | wps 45422.3 | wpb 510.9 | bsz 1 | num_updates 923 | best_loss 9.594
2022-03-06 13:44:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 923 updates
2022-03-06 13:44:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:44:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 19 @ 923 updates, score 9.594) (writing took 4.480273929890245 seconds)
2022-03-06 13:44:05 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-06 13:44:05 | INFO | train | epoch 019 | loss 9.386 | nll_loss 8.518 | ppl 366.49 | wps 24362.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 923 | lr 0.000115452 | gnorm 0.886 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 2490
2022-03-06 13:44:05 | INFO | fairseq.trainer | begin training epoch 20
2022-03-06 13:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:45:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:46:11 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.526 | nll_loss 8.66 | ppl 404.46 | wps 45436 | wpb 510.9 | bsz 1 | num_updates 971 | best_loss 9.526
2022-03-06 13:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 971 updates
2022-03-06 13:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:46:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 20 @ 971 updates, score 9.526) (writing took 4.491651423275471 seconds)
2022-03-06 13:46:16 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-06 13:46:16 | INFO | train | epoch 020 | loss 9.279 | nll_loss 8.397 | ppl 337.13 | wps 23854.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 971 | lr 0.000121451 | gnorm 0.854 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 2621
2022-03-06 13:46:16 | INFO | fairseq.trainer | begin training epoch 21
2022-03-06 13:46:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:47:28 | INFO | train_inner | epoch 021:     29 / 49 loss=9.273, nll_loss=8.391, ppl=335.6, wps=24168.3, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=1000, lr=0.000125075, gnorm=0.875, loss_scale=32, train_wall=225, gb_free=8.8, wall=2693
2022-03-06 13:48:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:48:22 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.474 | nll_loss 8.593 | ppl 386.1 | wps 45436 | wpb 510.9 | bsz 1 | num_updates 1020 | best_loss 9.474
2022-03-06 13:48:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 1020 updates
2022-03-06 13:48:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:48:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:48:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 21 @ 1020 updates, score 9.474) (writing took 4.483118163887411 seconds)
2022-03-06 13:48:26 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-06 13:48:26 | INFO | train | epoch 021 | loss 9.177 | nll_loss 8.282 | ppl 311.35 | wps 24368.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1020 | lr 0.000127575 | gnorm 0.861 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 2751
2022-03-06 13:48:26 | INFO | fairseq.trainer | begin training epoch 22
2022-03-06 13:48:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:50:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:50:32 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.406 | nll_loss 8.51 | ppl 364.57 | wps 45415 | wpb 510.9 | bsz 1 | num_updates 1069 | best_loss 9.406
2022-03-06 13:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 1069 updates
2022-03-06 13:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:50:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:50:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 22 @ 1069 updates, score 9.406) (writing took 4.4811011967249215 seconds)
2022-03-06 13:50:37 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-06 13:50:37 | INFO | train | epoch 022 | loss 9.08 | nll_loss 8.172 | ppl 288.37 | wps 24339 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1069 | lr 0.000133698 | gnorm 0.9 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 2882
2022-03-06 13:50:37 | INFO | fairseq.trainer | begin training epoch 23
2022-03-06 13:50:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:51:54 | INFO | train_inner | epoch 023:     31 / 49 loss=9.066, nll_loss=8.156, ppl=285.3, wps=24396.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=1100, lr=0.000137573, gnorm=0.888, loss_scale=64, train_wall=222, gb_free=8.8, wall=2959
2022-03-06 13:52:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:52:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:52:43 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.362 | nll_loss 8.466 | ppl 353.51 | wps 45437.2 | wpb 510.9 | bsz 1 | num_updates 1117 | best_loss 9.362
2022-03-06 13:52:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 1117 updates
2022-03-06 13:52:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:52:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 23 @ 1117 updates, score 9.362) (writing took 4.509493794757873 seconds)
2022-03-06 13:52:47 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-06 13:52:47 | INFO | train | epoch 023 | loss 8.982 | nll_loss 8.062 | ppl 267.18 | wps 23874.7 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1117 | lr 0.000139697 | gnorm 0.881 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3012
2022-03-06 13:52:47 | INFO | fairseq.trainer | begin training epoch 24
2022-03-06 13:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:54:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:54:53 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.31 | nll_loss 8.408 | ppl 339.73 | wps 45718.1 | wpb 510.9 | bsz 1 | num_updates 1166 | best_loss 9.31
2022-03-06 13:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 1166 updates
2022-03-06 13:54:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:54:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:54:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 24 @ 1166 updates, score 9.31) (writing took 4.531889597885311 seconds)
2022-03-06 13:54:58 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-06 13:54:58 | INFO | train | epoch 024 | loss 8.889 | nll_loss 7.957 | ppl 248.43 | wps 24354.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1166 | lr 0.000145821 | gnorm 0.863 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3142
2022-03-06 13:54:58 | INFO | fairseq.trainer | begin training epoch 25
2022-03-06 13:54:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:56:23 | INFO | train_inner | epoch 025:     34 / 49 loss=8.873, nll_loss=7.939, ppl=245.38, wps=24169.9, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=1200, lr=0.00015007, gnorm=0.876, loss_scale=32, train_wall=225, gb_free=8.8, wall=3227
2022-03-06 13:56:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:57:04 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.258 | nll_loss 8.339 | ppl 323.7 | wps 45342.4 | wpb 510.9 | bsz 1 | num_updates 1215 | best_loss 9.258
2022-03-06 13:57:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 1215 updates
2022-03-06 13:57:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:57:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:57:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 25 @ 1215 updates, score 9.258) (writing took 4.513579196762294 seconds)
2022-03-06 13:57:08 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-06 13:57:08 | INFO | train | epoch 025 | loss 8.796 | nll_loss 7.851 | ppl 230.91 | wps 24357.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1215 | lr 0.000151945 | gnorm 0.905 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3273
2022-03-06 13:57:08 | INFO | fairseq.trainer | begin training epoch 26
2022-03-06 13:57:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 13:58:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 13:59:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 13:59:14 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.225 | nll_loss 8.302 | ppl 315.67 | wps 44811 | wpb 510.9 | bsz 1 | num_updates 1263 | best_loss 9.225
2022-03-06 13:59:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 1263 updates
2022-03-06 13:59:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:59:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 13:59:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 26 @ 1263 updates, score 9.225) (writing took 4.4589724550023675 seconds)
2022-03-06 13:59:19 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-06 13:59:19 | INFO | train | epoch 026 | loss 8.704 | nll_loss 7.747 | ppl 214.84 | wps 23862.2 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1263 | lr 0.000157943 | gnorm 0.913 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3403
2022-03-06 13:59:19 | INFO | fairseq.trainer | begin training epoch 27
2022-03-06 13:59:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:00:51 | INFO | train_inner | epoch 027:     37 / 49 loss=8.685, nll_loss=7.725, ppl=211.59, wps=24165, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=1300, lr=0.000162568, gnorm=0.923, loss_scale=32, train_wall=225, gb_free=8.8, wall=3496
2022-03-06 14:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:01:25 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.169 | nll_loss 8.24 | ppl 302.29 | wps 45482.5 | wpb 510.9 | bsz 1 | num_updates 1312 | best_loss 9.169
2022-03-06 14:01:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 1312 updates
2022-03-06 14:01:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:01:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:01:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 27 @ 1312 updates, score 9.169) (writing took 4.544905073940754 seconds)
2022-03-06 14:01:29 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-06 14:01:29 | INFO | train | epoch 027 | loss 8.615 | nll_loss 7.647 | ppl 200.41 | wps 24345.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1312 | lr 0.000164067 | gnorm 0.925 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3534
2022-03-06 14:01:29 | INFO | fairseq.trainer | begin training epoch 28
2022-03-06 14:01:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:03:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:03:35 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.124 | nll_loss 8.178 | ppl 289.7 | wps 45493.6 | wpb 510.9 | bsz 1 | num_updates 1361 | best_loss 9.124
2022-03-06 14:03:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 1361 updates
2022-03-06 14:03:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:03:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 28 @ 1361 updates, score 9.124) (writing took 4.501036204397678 seconds)
2022-03-06 14:03:40 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-06 14:03:40 | INFO | train | epoch 028 | loss 8.522 | nll_loss 7.542 | ppl 186.34 | wps 24377.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1361 | lr 0.000170191 | gnorm 0.91 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3664
2022-03-06 14:03:40 | INFO | fairseq.trainer | begin training epoch 29
2022-03-06 14:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:04:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:05:20 | INFO | train_inner | epoch 029:     40 / 49 loss=8.496, nll_loss=7.512, ppl=182.58, wps=24172.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=1400, lr=0.000175065, gnorm=0.927, loss_scale=32, train_wall=225, gb_free=8.8, wall=3764
2022-03-06 14:05:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:05:46 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.097 | nll_loss 8.136 | ppl 281.4 | wps 45268.3 | wpb 510.9 | bsz 1 | num_updates 1409 | best_loss 9.097
2022-03-06 14:05:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 1409 updates
2022-03-06 14:05:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:05:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:05:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 29 @ 1409 updates, score 9.097) (writing took 4.516868237871677 seconds)
2022-03-06 14:05:50 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-06 14:05:50 | INFO | train | epoch 029 | loss 8.431 | nll_loss 7.439 | ppl 173.52 | wps 23844.5 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1409 | lr 0.00017619 | gnorm 0.94 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3795
2022-03-06 14:05:50 | INFO | fairseq.trainer | begin training epoch 30
2022-03-06 14:05:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:07:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:07:56 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.061 | nll_loss 8.093 | ppl 273.05 | wps 45323.5 | wpb 510.9 | bsz 1 | num_updates 1458 | best_loss 9.061
2022-03-06 14:07:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 1458 updates
2022-03-06 14:07:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:07:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:08:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 30 @ 1458 updates, score 9.061) (writing took 4.521345169749111 seconds)
2022-03-06 14:08:01 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-06 14:08:01 | INFO | train | epoch 030 | loss 8.342 | nll_loss 7.338 | ppl 161.83 | wps 24348.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1458 | lr 0.000182314 | gnorm 0.925 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 3925
2022-03-06 14:08:01 | INFO | fairseq.trainer | begin training epoch 31
2022-03-06 14:08:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:09:46 | INFO | train_inner | epoch 031:     42 / 49 loss=8.309, nll_loss=7.301, ppl=157.69, wps=24386.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=1500, lr=0.000187563, gnorm=0.911, loss_scale=64, train_wall=223, gb_free=8.8, wall=4030
2022-03-06 14:09:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:10:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:10:07 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.041 | nll_loss 8.072 | ppl 269.18 | wps 45451.1 | wpb 510.9 | bsz 1 | num_updates 1506 | best_loss 9.041
2022-03-06 14:10:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 1506 updates
2022-03-06 14:10:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:10:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:10:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 31 @ 1506 updates, score 9.041) (writing took 4.541481628082693 seconds)
2022-03-06 14:10:11 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-06 14:10:11 | INFO | train | epoch 031 | loss 8.248 | nll_loss 7.231 | ppl 150.27 | wps 23851.8 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1506 | lr 0.000188312 | gnorm 0.898 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4056
2022-03-06 14:10:11 | INFO | fairseq.trainer | begin training epoch 32
2022-03-06 14:10:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:12:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:12:17 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.011 | nll_loss 8.037 | ppl 262.64 | wps 45474.3 | wpb 510.9 | bsz 1 | num_updates 1555 | best_loss 9.011
2022-03-06 14:12:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 1555 updates
2022-03-06 14:12:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:12:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:12:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 32 @ 1555 updates, score 9.011) (writing took 4.495941916014999 seconds)
2022-03-06 14:12:22 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-06 14:12:22 | INFO | train | epoch 032 | loss 8.16 | nll_loss 7.133 | ppl 140.33 | wps 24368.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1555 | lr 0.000194436 | gnorm 0.953 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4186
2022-03-06 14:12:22 | INFO | fairseq.trainer | begin training epoch 33
2022-03-06 14:12:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:14:14 | INFO | train_inner | epoch 033:     45 / 49 loss=8.123, nll_loss=7.09, ppl=136.29, wps=24177.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=1600, lr=0.00020006, gnorm=0.946, loss_scale=32, train_wall=225, gb_free=8.8, wall=4299
2022-03-06 14:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:14:27 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 8.998 | nll_loss 8.018 | ppl 259.29 | wps 45464 | wpb 510.9 | bsz 1 | num_updates 1604 | best_loss 8.998
2022-03-06 14:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 1604 updates
2022-03-06 14:14:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:14:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 33 @ 1604 updates, score 8.998) (writing took 4.529490349814296 seconds)
2022-03-06 14:14:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-06 14:14:32 | INFO | train | epoch 033 | loss 8.069 | nll_loss 7.029 | ppl 130.6 | wps 24360.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1604 | lr 0.00020056 | gnorm 0.944 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4317
2022-03-06 14:14:32 | INFO | fairseq.trainer | begin training epoch 34
2022-03-06 14:14:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:15:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:16:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:16:38 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 8.979 | nll_loss 7.998 | ppl 255.7 | wps 45382.2 | wpb 510.9 | bsz 1 | num_updates 1652 | best_loss 8.979
2022-03-06 14:16:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 1652 updates
2022-03-06 14:16:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:16:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 34 @ 1652 updates, score 8.979) (writing took 4.49202486872673 seconds)
2022-03-06 14:16:42 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-06 14:16:42 | INFO | train | epoch 034 | loss 7.978 | nll_loss 6.926 | ppl 121.61 | wps 23852.3 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1652 | lr 0.000206559 | gnorm 0.952 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4447
2022-03-06 14:16:42 | INFO | fairseq.trainer | begin training epoch 35
2022-03-06 14:16:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:18:42 | INFO | train_inner | epoch 035:     48 / 49 loss=7.939, nll_loss=6.882, ppl=117.98, wps=24152.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=1700, lr=0.000212558, gnorm=0.954, loss_scale=32, train_wall=225, gb_free=8.8, wall=4567
2022-03-06 14:18:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:18:49 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 8.979 | nll_loss 7.988 | ppl 253.8 | wps 45356.8 | wpb 510.9 | bsz 1 | num_updates 1701 | best_loss 8.979
2022-03-06 14:18:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1701 updates
2022-03-06 14:18:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:18:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 35 @ 1701 updates, score 8.979) (writing took 4.537668076809496 seconds)
2022-03-06 14:18:53 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-06 14:18:53 | INFO | train | epoch 035 | loss 7.892 | nll_loss 6.829 | ppl 113.66 | wps 24327.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1701 | lr 0.000212682 | gnorm 0.96 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4578
2022-03-06 14:18:53 | INFO | fairseq.trainer | begin training epoch 36
2022-03-06 14:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:20:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:20:59 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 8.961 | nll_loss 7.974 | ppl 251.43 | wps 45402.8 | wpb 510.9 | bsz 1 | num_updates 1750 | best_loss 8.961
2022-03-06 14:20:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 1750 updates
2022-03-06 14:20:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:21:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:21:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 36 @ 1750 updates, score 8.961) (writing took 4.583404021337628 seconds)
2022-03-06 14:21:04 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-06 14:21:04 | INFO | train | epoch 036 | loss 7.804 | nll_loss 6.729 | ppl 106.05 | wps 24361 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1750 | lr 0.000218806 | gnorm 1.001 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4708
2022-03-06 14:21:04 | INFO | fairseq.trainer | begin training epoch 37
2022-03-06 14:21:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:21:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:23:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:23:10 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 8.942 | nll_loss 7.943 | ppl 246.03 | wps 45442.7 | wpb 510.9 | bsz 1 | num_updates 1798 | best_loss 8.942
2022-03-06 14:23:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 1798 updates
2022-03-06 14:23:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:23:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 37 @ 1798 updates, score 8.942) (writing took 4.504808102734387 seconds)
2022-03-06 14:23:14 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-06 14:23:14 | INFO | train | epoch 037 | loss 7.715 | nll_loss 6.629 | ppl 98.95 | wps 23850 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1798 | lr 0.000224805 | gnorm 0.974 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4839
2022-03-06 14:23:14 | INFO | fairseq.trainer | begin training epoch 38
2022-03-06 14:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:23:19 | INFO | train_inner | epoch 038:      2 / 49 loss=7.758, nll_loss=6.677, ppl=102.33, wps=23320.7, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=1800, lr=0.000225055, gnorm=0.987, loss_scale=32, train_wall=224, gb_free=8.8, wall=4844
2022-03-06 14:25:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:25:20 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 8.97 | nll_loss 7.974 | ppl 251.38 | wps 45417.5 | wpb 510.9 | bsz 1 | num_updates 1847 | best_loss 8.942
2022-03-06 14:25:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 1847 updates
2022-03-06 14:25:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:25:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:25:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 38 @ 1847 updates, score 8.97) (writing took 2.350663824006915 seconds)
2022-03-06 14:25:23 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-06 14:25:23 | INFO | train | epoch 038 | loss 7.63 | nll_loss 6.532 | ppl 92.53 | wps 24738.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1847 | lr 0.000230929 | gnorm 0.988 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 4967
2022-03-06 14:25:23 | INFO | fairseq.trainer | begin training epoch 39
2022-03-06 14:25:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:27:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:27:28 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 8.937 | nll_loss 7.935 | ppl 244.79 | wps 45310.4 | wpb 510.9 | bsz 1 | num_updates 1895 | best_loss 8.937
2022-03-06 14:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 1895 updates
2022-03-06 14:27:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt
2022-03-06 14:27:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_best.pt (epoch 39 @ 1895 updates, score 8.937) (writing took 4.306048129219562 seconds)
2022-03-06 14:27:33 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-06 14:27:33 | INFO | train | epoch 039 | loss 7.546 | nll_loss 6.437 | ppl 86.61 | wps 23918.9 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 1895 | lr 0.000236928 | gnorm 1.054 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 5097
2022-03-06 14:27:33 | INFO | fairseq.trainer | begin training epoch 40
2022-03-06 14:27:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:27:45 | INFO | train_inner | epoch 040:      5 / 49 loss=7.581, nll_loss=6.476, ppl=88.99, wps=24384.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=1900, lr=0.000237553, gnorm=1.027, loss_scale=32, train_wall=225, gb_free=8.8, wall=5110
2022-03-06 14:29:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:29:39 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 8.968 | nll_loss 7.97 | ppl 250.77 | wps 45170.3 | wpb 510.9 | bsz 1 | num_updates 1944 | best_loss 8.937
2022-03-06 14:29:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 1944 updates
2022-03-06 14:29:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:29:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:29:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 40 @ 1944 updates, score 8.968) (writing took 2.388215555343777 seconds)
2022-03-06 14:29:41 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-06 14:29:41 | INFO | train | epoch 040 | loss 7.461 | nll_loss 6.339 | ppl 80.97 | wps 24752.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1944 | lr 0.000243051 | gnorm 1.018 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 5226
2022-03-06 14:29:41 | INFO | fairseq.trainer | begin training epoch 41
2022-03-06 14:29:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:31:47 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 8.975 | nll_loss 7.968 | ppl 250.39 | wps 45219.4 | wpb 510.9 | bsz 1 | num_updates 1993 | best_loss 8.937
2022-03-06 14:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 1993 updates
2022-03-06 14:31:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:31:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:31:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 41 @ 1993 updates, score 8.975) (writing took 2.369010902941227 seconds)
2022-03-06 14:31:49 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-06 14:31:49 | INFO | train | epoch 041 | loss 7.375 | nll_loss 6.242 | ppl 75.66 | wps 24777.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 1993 | lr 0.000249175 | gnorm 1.002 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 5354
2022-03-06 14:31:49 | INFO | fairseq.trainer | begin training epoch 42
2022-03-06 14:31:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:32:07 | INFO | train_inner | epoch 042:      7 / 49 loss=7.407, nll_loss=6.278, ppl=77.6, wps=24795.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2000, lr=0.00025005, gnorm=1.01, loss_scale=32, train_wall=222, gb_free=8.8, wall=5372
2022-03-06 14:33:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:33:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:33:55 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.009 | nll_loss 8.004 | ppl 256.66 | wps 45347.1 | wpb 510.9 | bsz 1 | num_updates 2041 | best_loss 8.937
2022-03-06 14:33:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 2041 updates
2022-03-06 14:33:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:33:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 42 @ 2041 updates, score 9.009) (writing took 2.4435997791588306 seconds)
2022-03-06 14:33:58 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-06 14:33:58 | INFO | train | epoch 042 | loss 7.295 | nll_loss 6.151 | ppl 71.07 | wps 24252.1 | ups 0.37 | wpb 64844.1 | bsz 126.7 | num_updates 2041 | lr 0.000255174 | gnorm 1.096 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 5482
2022-03-06 14:33:58 | INFO | fairseq.trainer | begin training epoch 43
2022-03-06 14:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:36:04 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.034 | nll_loss 8.037 | ppl 262.73 | wps 44512.3 | wpb 510.9 | bsz 1 | num_updates 2090 | best_loss 8.937
2022-03-06 14:36:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 2090 updates
2022-03-06 14:36:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:36:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:36:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 43 @ 2090 updates, score 9.034) (writing took 2.360484933014959 seconds)
2022-03-06 14:36:06 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-06 14:36:06 | INFO | train | epoch 043 | loss 7.212 | nll_loss 6.056 | ppl 66.55 | wps 24763.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2090 | lr 0.000261298 | gnorm 1.056 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 5611
2022-03-06 14:36:06 | INFO | fairseq.trainer | begin training epoch 44
2022-03-06 14:36:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:36:31 | INFO | train_inner | epoch 044:     10 / 49 loss=7.237, nll_loss=6.085, ppl=67.86, wps=24566.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2100, lr=0.000262548, gnorm=1.06, loss_scale=32, train_wall=225, gb_free=8.8, wall=5636
2022-03-06 14:38:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:38:11 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.083 | nll_loss 8.09 | ppl 272.4 | wps 47055.4 | wpb 510.9 | bsz 1 | num_updates 2139 | best_loss 8.937
2022-03-06 14:38:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 2139 updates
2022-03-06 14:38:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:38:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:38:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 44 @ 2139 updates, score 9.083) (writing took 2.26904864795506 seconds)
2022-03-06 14:38:13 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-06 14:38:13 | INFO | train | epoch 044 | loss 7.125 | nll_loss 5.957 | ppl 62.12 | wps 25045.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2139 | lr 0.000267422 | gnorm 1.032 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 5738
2022-03-06 14:38:13 | INFO | fairseq.trainer | begin training epoch 45
2022-03-06 14:38:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 14:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:40:17 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.132 | nll_loss 8.141 | ppl 282.28 | wps 47138.5 | wpb 510.9 | bsz 1 | num_updates 2187 | best_loss 8.937
2022-03-06 14:40:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 2187 updates
2022-03-06 14:40:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:40:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:40:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 45 @ 2187 updates, score 9.132) (writing took 2.302230440080166 seconds)
2022-03-06 14:40:20 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-06 14:40:20 | INFO | train | epoch 045 | loss 7.044 | nll_loss 5.865 | ppl 58.28 | wps 24532.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2187 | lr 0.00027342 | gnorm 1.053 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 5865
2022-03-06 14:40:20 | INFO | fairseq.trainer | begin training epoch 46
2022-03-06 14:40:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:40:52 | INFO | train_inner | epoch 046:     13 / 49 loss=7.066, nll_loss=5.89, ppl=59.31, wps=24821.3, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2200, lr=0.000275045, gnorm=1.105, loss_scale=32, train_wall=223, gb_free=8.8, wall=5897
2022-03-06 14:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:42:24 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.14 | nll_loss 8.149 | ppl 283.84 | wps 47042.1 | wpb 510.9 | bsz 1 | num_updates 2236 | best_loss 8.937
2022-03-06 14:42:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 2236 updates
2022-03-06 14:42:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:42:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:42:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 46 @ 2236 updates, score 9.14) (writing took 2.304086354095489 seconds)
2022-03-06 14:42:27 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-06 14:42:27 | INFO | train | epoch 046 | loss 6.967 | nll_loss 5.778 | ppl 54.86 | wps 25022.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2236 | lr 0.000279544 | gnorm 1.146 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 5992
2022-03-06 14:42:27 | INFO | fairseq.trainer | begin training epoch 47
2022-03-06 14:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:42:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:44:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:44:31 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.189 | nll_loss 8.197 | ppl 293.48 | wps 46842.9 | wpb 510.9 | bsz 1 | num_updates 2284 | best_loss 8.937
2022-03-06 14:44:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 2284 updates
2022-03-06 14:44:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:44:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:44:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 47 @ 2284 updates, score 9.189) (writing took 2.2595573947764933 seconds)
2022-03-06 14:44:34 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-06 14:44:34 | INFO | train | epoch 047 | loss 6.883 | nll_loss 5.682 | ppl 51.34 | wps 24515.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2284 | lr 0.000285543 | gnorm 1.13 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 6118
2022-03-06 14:44:34 | INFO | fairseq.trainer | begin training epoch 48
2022-03-06 14:44:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:45:13 | INFO | train_inner | epoch 048:     16 / 49 loss=6.898, nll_loss=5.699, ppl=51.94, wps=24844.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=2300, lr=0.000287543, gnorm=1.086, loss_scale=16, train_wall=222, gb_free=8.8, wall=6158
2022-03-06 14:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:46:38 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.184 | nll_loss 8.182 | ppl 290.5 | wps 46977.2 | wpb 510.9 | bsz 1 | num_updates 2333 | best_loss 8.937
2022-03-06 14:46:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 2333 updates
2022-03-06 14:46:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:46:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 48 @ 2333 updates, score 9.184) (writing took 2.2576945209875703 seconds)
2022-03-06 14:46:41 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-06 14:46:41 | INFO | train | epoch 048 | loss 6.811 | nll_loss 5.599 | ppl 48.46 | wps 25038.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2333 | lr 0.000291667 | gnorm 1.186 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 6245
2022-03-06 14:46:41 | INFO | fairseq.trainer | begin training epoch 49
2022-03-06 14:46:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:48:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:48:45 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.232 | nll_loss 8.209 | ppl 295.87 | wps 47014.6 | wpb 510.9 | bsz 1 | num_updates 2382 | best_loss 8.937
2022-03-06 14:48:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 2382 updates
2022-03-06 14:48:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:48:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 49 @ 2382 updates, score 9.232) (writing took 2.229063096921891 seconds)
2022-03-06 14:48:48 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-06 14:48:48 | INFO | train | epoch 049 | loss 6.719 | nll_loss 5.495 | ppl 45.09 | wps 25046.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2382 | lr 0.00029779 | gnorm 1.064 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 6372
2022-03-06 14:48:48 | INFO | fairseq.trainer | begin training epoch 50
2022-03-06 14:48:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:49:32 | INFO | train_inner | epoch 050:     18 / 49 loss=6.736, nll_loss=5.513, ppl=45.67, wps=25107.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=2400, lr=0.00030004, gnorm=1.119, loss_scale=32, train_wall=220, gb_free=8.8, wall=6417
2022-03-06 14:50:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:50:51 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.27 | nll_loss 8.285 | ppl 312.01 | wps 47839.4 | wpb 510.9 | bsz 1 | num_updates 2431 | best_loss 8.937
2022-03-06 14:50:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 2431 updates
2022-03-06 14:50:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:50:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:50:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 50 @ 2431 updates, score 9.27) (writing took 2.257602158933878 seconds)
2022-03-06 14:50:53 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-06 14:50:53 | INFO | train | epoch 050 | loss 6.645 | nll_loss 5.41 | ppl 42.51 | wps 25241.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2431 | lr 0.000303914 | gnorm 1.177 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 6498
2022-03-06 14:50:53 | INFO | fairseq.trainer | begin training epoch 51
2022-03-06 14:50:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:52:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 14:52:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:52:57 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.275 | nll_loss 8.272 | ppl 309.13 | wps 47975.4 | wpb 510.9 | bsz 1 | num_updates 2479 | best_loss 8.937
2022-03-06 14:52:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 2479 updates
2022-03-06 14:52:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:52:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:52:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 51 @ 2479 updates, score 9.275) (writing took 2.3263505026698112 seconds)
2022-03-06 14:52:59 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-06 14:52:59 | INFO | train | epoch 051 | loss 6.564 | nll_loss 5.316 | ppl 39.84 | wps 24742.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2479 | lr 0.000309913 | gnorm 1.207 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 6624
2022-03-06 14:52:59 | INFO | fairseq.trainer | begin training epoch 52
2022-03-06 14:52:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:53:51 | INFO | train_inner | epoch 052:     21 / 49 loss=6.573, nll_loss=5.327, ppl=40.14, wps=25048.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=2500, lr=0.000312538, gnorm=1.198, loss_scale=16, train_wall=221, gb_free=8.8, wall=6675
2022-03-06 14:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:55:03 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.364 | nll_loss 8.36 | ppl 328.48 | wps 46487.7 | wpb 510.9 | bsz 1 | num_updates 2528 | best_loss 8.937
2022-03-06 14:55:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 2528 updates
2022-03-06 14:55:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:55:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:55:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 52 @ 2528 updates, score 9.364) (writing took 2.334988273214549 seconds)
2022-03-06 14:55:06 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-06 14:55:06 | INFO | train | epoch 052 | loss 6.485 | nll_loss 5.226 | ppl 37.43 | wps 25132.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2528 | lr 0.000316037 | gnorm 1.154 | loss_scale 16 | train_wall 107 | gb_free 8.8 | wall 6750
2022-03-06 14:55:06 | INFO | fairseq.trainer | begin training epoch 53
2022-03-06 14:55:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:57:10 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.378 | nll_loss 8.377 | ppl 332.42 | wps 46834.8 | wpb 510.9 | bsz 1 | num_updates 2577 | best_loss 8.937
2022-03-06 14:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 2577 updates
2022-03-06 14:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 53 @ 2577 updates, score 9.378) (writing took 2.310235154815018 seconds)
2022-03-06 14:57:13 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-06 14:57:13 | INFO | train | epoch 053 | loss 6.406 | nll_loss 5.136 | ppl 35.16 | wps 25032.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2577 | lr 0.000322161 | gnorm 1.211 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 6877
2022-03-06 14:57:13 | INFO | fairseq.trainer | begin training epoch 54
2022-03-06 14:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 14:58:10 | INFO | train_inner | epoch 054:     23 / 49 loss=6.411, nll_loss=5.141, ppl=35.29, wps=25071.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=2600, lr=0.000325035, gnorm=1.225, loss_scale=32, train_wall=220, gb_free=8.8, wall=6934
2022-03-06 14:59:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 14:59:17 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.408 | nll_loss 8.396 | ppl 336.78 | wps 46970.5 | wpb 510.9 | bsz 1 | num_updates 2626 | best_loss 8.937
2022-03-06 14:59:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 2626 updates
2022-03-06 14:59:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:59:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 14:59:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 54 @ 2626 updates, score 9.408) (writing took 2.2583159282803535 seconds)
2022-03-06 14:59:20 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-06 14:59:20 | INFO | train | epoch 054 | loss 6.33 | nll_loss 5.048 | ppl 33.09 | wps 25032 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2626 | lr 0.000328284 | gnorm 1.248 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 7004
2022-03-06 14:59:20 | INFO | fairseq.trainer | begin training epoch 55
2022-03-06 14:59:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:00:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:01:24 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.532 | nll_loss 8.545 | ppl 373.57 | wps 47076.1 | wpb 510.9 | bsz 1 | num_updates 2674 | best_loss 8.937
2022-03-06 15:01:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 2674 updates
2022-03-06 15:01:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:01:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 55 @ 2674 updates, score 9.532) (writing took 2.280453183222562 seconds)
2022-03-06 15:01:26 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-06 15:01:26 | INFO | train | epoch 055 | loss 6.243 | nll_loss 4.949 | ppl 30.88 | wps 24549.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2674 | lr 0.000334283 | gnorm 1.202 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7131
2022-03-06 15:01:26 | INFO | fairseq.trainer | begin training epoch 56
2022-03-06 15:01:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:02:31 | INFO | train_inner | epoch 056:     26 / 49 loss=6.248, nll_loss=4.955, ppl=31.02, wps=24835.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=2700, lr=0.000337533, gnorm=1.224, loss_scale=16, train_wall=222, gb_free=8.8, wall=7195
2022-03-06 15:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:03:31 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.483 | nll_loss 8.466 | ppl 353.59 | wps 45836.2 | wpb 510.9 | bsz 1 | num_updates 2723 | best_loss 8.937
2022-03-06 15:03:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 2723 updates
2022-03-06 15:03:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:03:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:03:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 56 @ 2723 updates, score 9.483) (writing took 2.2883797236718237 seconds)
2022-03-06 15:03:34 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-06 15:03:34 | INFO | train | epoch 056 | loss 6.178 | nll_loss 4.874 | ppl 29.33 | wps 25001.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2723 | lr 0.000340407 | gnorm 1.315 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7258
2022-03-06 15:03:34 | INFO | fairseq.trainer | begin training epoch 57
2022-03-06 15:03:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:05:38 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 9.578 | nll_loss 8.566 | ppl 378.89 | wps 46637.5 | wpb 510.9 | bsz 1 | num_updates 2772 | best_loss 8.937
2022-03-06 15:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 2772 updates
2022-03-06 15:05:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:05:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:05:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 57 @ 2772 updates, score 9.578) (writing took 2.396551689133048 seconds)
2022-03-06 15:05:40 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-06 15:05:40 | INFO | train | epoch 057 | loss 6.092 | nll_loss 4.775 | ppl 27.39 | wps 25040.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 2772 | lr 0.000346531 | gnorm 1.208 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 7385
2022-03-06 15:05:40 | INFO | fairseq.trainer | begin training epoch 58
2022-03-06 15:05:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:05:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:06:52 | INFO | train_inner | epoch 058:     29 / 49 loss=6.087, nll_loss=4.77, ppl=27.28, wps=24785.3, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=2800, lr=0.00035003, gnorm=1.249, loss_scale=16, train_wall=223, gb_free=8.8, wall=7457
2022-03-06 15:07:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:07:46 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 9.6 | nll_loss 8.585 | ppl 384.13 | wps 45313.1 | wpb 510.9 | bsz 1 | num_updates 2820 | best_loss 8.937
2022-03-06 15:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 2820 updates
2022-03-06 15:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:07:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:07:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 58 @ 2820 updates, score 9.6) (writing took 2.402359670959413 seconds)
2022-03-06 15:07:48 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-06 15:07:48 | INFO | train | epoch 058 | loss 6.02 | nll_loss 4.692 | ppl 25.85 | wps 24366.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2820 | lr 0.00035253 | gnorm 1.304 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7513
2022-03-06 15:07:48 | INFO | fairseq.trainer | begin training epoch 59
2022-03-06 15:07:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:09:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:09:53 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 9.683 | nll_loss 8.66 | ppl 404.44 | wps 46387.2 | wpb 510.9 | bsz 1 | num_updates 2869 | best_loss 8.937
2022-03-06 15:09:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 2869 updates
2022-03-06 15:09:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:09:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 59 @ 2869 updates, score 9.683) (writing took 2.344758784864098 seconds)
2022-03-06 15:09:56 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-06 15:09:56 | INFO | train | epoch 059 | loss 5.946 | nll_loss 4.608 | ppl 24.39 | wps 24895.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2869 | lr 0.000358653 | gnorm 1.355 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7641
2022-03-06 15:09:56 | INFO | fairseq.trainer | begin training epoch 60
2022-03-06 15:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:11:13 | INFO | train_inner | epoch 060:     31 / 49 loss=5.937, nll_loss=4.596, ppl=24.19, wps=24906.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=2900, lr=0.000362528, gnorm=1.323, loss_scale=32, train_wall=221, gb_free=8.8, wall=7718
2022-03-06 15:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:12:01 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 9.722 | nll_loss 8.719 | ppl 421.35 | wps 46424.9 | wpb 510.9 | bsz 1 | num_updates 2918 | best_loss 8.937
2022-03-06 15:12:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 2918 updates
2022-03-06 15:12:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:12:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:12:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 60 @ 2918 updates, score 9.722) (writing took 2.406900365371257 seconds)
2022-03-06 15:12:03 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-06 15:12:03 | INFO | train | epoch 060 | loss 5.864 | nll_loss 4.513 | ppl 22.83 | wps 24896.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 2918 | lr 0.000364777 | gnorm 1.258 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 7768
2022-03-06 15:12:03 | INFO | fairseq.trainer | begin training epoch 61
2022-03-06 15:12:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:12:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:14:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:14:09 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 9.815 | nll_loss 8.82 | ppl 451.97 | wps 45596.5 | wpb 510.9 | bsz 1 | num_updates 2966 | best_loss 8.937
2022-03-06 15:14:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 2966 updates
2022-03-06 15:14:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:14:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:14:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 61 @ 2966 updates, score 9.815) (writing took 2.352848585229367 seconds)
2022-03-06 15:14:11 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2022-03-06 15:14:11 | INFO | train | epoch 061 | loss 5.79 | nll_loss 4.427 | ppl 21.52 | wps 24387.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 2966 | lr 0.000370776 | gnorm 1.314 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 7896
2022-03-06 15:14:11 | INFO | fairseq.trainer | begin training epoch 62
2022-03-06 15:14:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:15:36 | INFO | train_inner | epoch 062:     34 / 49 loss=5.776, nll_loss=4.412, ppl=21.28, wps=24688.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3000, lr=0.000375025, gnorm=1.32, loss_scale=16, train_wall=223, gb_free=8.8, wall=7980
2022-03-06 15:16:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:16:16 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 9.816 | nll_loss 8.805 | ppl 447.19 | wps 46389.3 | wpb 510.9 | bsz 1 | num_updates 3015 | best_loss 8.937
2022-03-06 15:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 3015 updates
2022-03-06 15:16:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:16:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 62 @ 3015 updates, score 9.816) (writing took 2.3071519397199154 seconds)
2022-03-06 15:16:19 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2022-03-06 15:16:19 | INFO | train | epoch 062 | loss 5.718 | nll_loss 4.345 | ppl 20.32 | wps 24908.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3015 | lr 0.0003769 | gnorm 1.336 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8023
2022-03-06 15:16:19 | INFO | fairseq.trainer | begin training epoch 63
2022-03-06 15:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:18:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:18:24 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 9.888 | nll_loss 8.88 | ppl 471.05 | wps 46079.5 | wpb 510.9 | bsz 1 | num_updates 3064 | best_loss 8.937
2022-03-06 15:18:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 3064 updates
2022-03-06 15:18:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:18:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:18:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 63 @ 3064 updates, score 9.888) (writing took 2.3934278381057084 seconds)
2022-03-06 15:18:27 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2022-03-06 15:18:27 | INFO | train | epoch 063 | loss 5.641 | nll_loss 4.255 | ppl 19.1 | wps 24859.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3064 | lr 0.000383023 | gnorm 1.31 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 8151
2022-03-06 15:18:27 | INFO | fairseq.trainer | begin training epoch 64
2022-03-06 15:18:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:18:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:19:58 | INFO | train_inner | epoch 064:     37 / 49 loss=5.631, nll_loss=4.243, ppl=18.94, wps=24681.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3100, lr=0.000387523, gnorm=1.325, loss_scale=16, train_wall=224, gb_free=8.8, wall=8243
2022-03-06 15:20:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:20:32 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 9.935 | nll_loss 8.919 | ppl 484.2 | wps 45415.7 | wpb 510.9 | bsz 1 | num_updates 3112 | best_loss 8.937
2022-03-06 15:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 3112 updates
2022-03-06 15:20:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:20:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:20:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 64 @ 3112 updates, score 9.935) (writing took 2.3967639938928187 seconds)
2022-03-06 15:20:34 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2022-03-06 15:20:34 | INFO | train | epoch 064 | loss 5.568 | nll_loss 4.171 | ppl 18.01 | wps 24357.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3112 | lr 0.000389022 | gnorm 1.363 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8279
2022-03-06 15:20:34 | INFO | fairseq.trainer | begin training epoch 65
2022-03-06 15:20:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:22:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:22:40 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 9.989 | nll_loss 8.977 | ppl 503.99 | wps 45834.4 | wpb 510.9 | bsz 1 | num_updates 3161 | best_loss 8.937
2022-03-06 15:22:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 3161 updates
2022-03-06 15:22:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:22:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:22:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 65 @ 3161 updates, score 9.989) (writing took 2.330195792019367 seconds)
2022-03-06 15:22:42 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2022-03-06 15:22:42 | INFO | train | epoch 065 | loss 5.499 | nll_loss 4.091 | ppl 17.04 | wps 24918.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3161 | lr 0.000395146 | gnorm 1.38 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8407
2022-03-06 15:22:42 | INFO | fairseq.trainer | begin training epoch 66
2022-03-06 15:22:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:24:19 | INFO | train_inner | epoch 066:     39 / 49 loss=5.476, nll_loss=4.064, ppl=16.73, wps=24923.2, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=3200, lr=0.00040002, gnorm=1.38, loss_scale=32, train_wall=221, gb_free=8.8, wall=8504
2022-03-06 15:24:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:24:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:24:47 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 10.086 | nll_loss 9.069 | ppl 537.27 | wps 46130.3 | wpb 510.9 | bsz 1 | num_updates 3209 | best_loss 8.937
2022-03-06 15:24:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 3209 updates
2022-03-06 15:24:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:24:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 66 @ 3209 updates, score 10.086) (writing took 2.314787961076945 seconds)
2022-03-06 15:24:49 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2022-03-06 15:24:49 | INFO | train | epoch 066 | loss 5.433 | nll_loss 4.014 | ppl 16.16 | wps 24390.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3209 | lr 0.000401145 | gnorm 1.493 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8534
2022-03-06 15:24:49 | INFO | fairseq.trainer | begin training epoch 67
2022-03-06 15:24:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:26:55 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 10.128 | nll_loss 9.119 | ppl 555.87 | wps 45612.1 | wpb 510.9 | bsz 1 | num_updates 3258 | best_loss 8.937
2022-03-06 15:26:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 3258 updates
2022-03-06 15:26:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:26:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:26:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 67 @ 3258 updates, score 10.128) (writing took 2.3720820103771985 seconds)
2022-03-06 15:26:57 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2022-03-06 15:26:57 | INFO | train | epoch 067 | loss 5.35 | nll_loss 3.918 | ppl 15.12 | wps 24878 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3258 | lr 0.000407269 | gnorm 1.252 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8662
2022-03-06 15:26:57 | INFO | fairseq.trainer | begin training epoch 68
2022-03-06 15:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:28:42 | INFO | train_inner | epoch 068:     42 / 49 loss=5.336, nll_loss=3.901, ppl=14.94, wps=24688.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=3300, lr=0.000412518, gnorm=1.418, loss_scale=16, train_wall=223, gb_free=8.8, wall=8766
2022-03-06 15:28:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:29:02 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 10.165 | nll_loss 9.158 | ppl 571.39 | wps 45922.5 | wpb 510.9 | bsz 1 | num_updates 3307 | best_loss 8.937
2022-03-06 15:29:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 3307 updates
2022-03-06 15:29:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:29:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:29:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 68 @ 3307 updates, score 10.165) (writing took 2.3340638540685177 seconds)
2022-03-06 15:29:05 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2022-03-06 15:29:05 | INFO | train | epoch 068 | loss 5.287 | nll_loss 3.845 | ppl 14.37 | wps 24905 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3307 | lr 0.000413392 | gnorm 1.451 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 8790
2022-03-06 15:29:05 | INFO | fairseq.trainer | begin training epoch 69
2022-03-06 15:29:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:31:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:31:10 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 10.307 | nll_loss 9.322 | ppl 640.25 | wps 46784.8 | wpb 510.9 | bsz 1 | num_updates 3356 | best_loss 8.937
2022-03-06 15:31:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 3356 updates
2022-03-06 15:31:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:31:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 69 @ 3356 updates, score 10.307) (writing took 2.3749197381548584 seconds)
2022-03-06 15:31:13 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2022-03-06 15:31:13 | INFO | train | epoch 069 | loss 5.21 | nll_loss 3.756 | ppl 13.51 | wps 24883 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3356 | lr 0.000419516 | gnorm 1.364 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 8917
2022-03-06 15:31:13 | INFO | fairseq.trainer | begin training epoch 70
2022-03-06 15:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:31:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:33:04 | INFO | train_inner | epoch 070:     45 / 49 loss=5.185, nll_loss=3.726, ppl=13.24, wps=24677.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3400, lr=0.000425015, gnorm=1.404, loss_scale=16, train_wall=224, gb_free=8.8, wall=9029
2022-03-06 15:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:33:18 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 10.364 | nll_loss 9.365 | ppl 659.39 | wps 45698.5 | wpb 510.9 | bsz 1 | num_updates 3404 | best_loss 8.937
2022-03-06 15:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 3404 updates
2022-03-06 15:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 70 @ 3404 updates, score 10.364) (writing took 2.4262546529062092 seconds)
2022-03-06 15:33:20 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2022-03-06 15:33:20 | INFO | train | epoch 070 | loss 5.142 | nll_loss 3.676 | ppl 12.78 | wps 24347.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3404 | lr 0.000425515 | gnorm 1.444 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9045
2022-03-06 15:33:20 | INFO | fairseq.trainer | begin training epoch 71
2022-03-06 15:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:34:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 15:35:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:35:26 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 10.439 | nll_loss 9.459 | ppl 703.74 | wps 45809 | wpb 510.9 | bsz 1 | num_updates 3452 | best_loss 8.937
2022-03-06 15:35:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 3452 updates
2022-03-06 15:35:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:35:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 71 @ 3452 updates, score 10.439) (writing took 2.336810511071235 seconds)
2022-03-06 15:35:28 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2022-03-06 15:35:28 | INFO | train | epoch 071 | loss 5.079 | nll_loss 3.603 | ppl 12.15 | wps 24415.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3452 | lr 0.000431514 | gnorm 1.455 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 9173
2022-03-06 15:35:28 | INFO | fairseq.trainer | begin training epoch 72
2022-03-06 15:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:37:27 | INFO | train_inner | epoch 072:     48 / 49 loss=5.058, nll_loss=3.578, ppl=11.94, wps=24685.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3500, lr=0.000437513, gnorm=1.498, loss_scale=8, train_wall=223, gb_free=8.8, wall=9292
2022-03-06 15:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:37:33 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 10.486 | nll_loss 9.495 | ppl 721.75 | wps 46622.5 | wpb 510.9 | bsz 1 | num_updates 3501 | best_loss 8.937
2022-03-06 15:37:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 3501 updates
2022-03-06 15:37:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:37:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 72 @ 3501 updates, score 10.486) (writing took 2.294216109905392 seconds)
2022-03-06 15:37:36 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2022-03-06 15:37:36 | INFO | train | epoch 072 | loss 5.028 | nll_loss 3.542 | ppl 11.65 | wps 24896 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3501 | lr 0.000437637 | gnorm 1.55 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 9300
2022-03-06 15:37:36 | INFO | fairseq.trainer | begin training epoch 73
2022-03-06 15:37:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:39:41 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 10.548 | nll_loss 9.564 | ppl 756.94 | wps 45829.4 | wpb 510.9 | bsz 1 | num_updates 3550 | best_loss 8.937
2022-03-06 15:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 3550 updates
2022-03-06 15:39:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:39:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 73 @ 3550 updates, score 10.548) (writing took 2.381427297834307 seconds)
2022-03-06 15:39:43 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2022-03-06 15:39:43 | INFO | train | epoch 073 | loss 4.941 | nll_loss 3.442 | ppl 10.86 | wps 24880.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3550 | lr 0.000443761 | gnorm 1.333 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 9428
2022-03-06 15:39:43 | INFO | fairseq.trainer | begin training epoch 74
2022-03-06 15:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:41:49 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 10.675 | nll_loss 9.724 | ppl 845.52 | wps 45478 | wpb 510.9 | bsz 1 | num_updates 3599 | best_loss 8.937
2022-03-06 15:41:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 3599 updates
2022-03-06 15:41:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:41:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:41:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 74 @ 3599 updates, score 10.675) (writing took 2.3061503530479968 seconds)
2022-03-06 15:41:51 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2022-03-06 15:41:51 | INFO | train | epoch 074 | loss 4.868 | nll_loss 3.357 | ppl 10.25 | wps 24897.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3599 | lr 0.000449885 | gnorm 1.364 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9556
2022-03-06 15:41:51 | INFO | fairseq.trainer | begin training epoch 75
2022-03-06 15:41:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:41:53 | INFO | train_inner | epoch 075:      1 / 49 loss=4.904, nll_loss=3.4, ppl=10.55, wps=24241.7, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=3600, lr=0.00045001, gnorm=1.355, loss_scale=16, train_wall=220, gb_free=8.8, wall=9558
2022-03-06 15:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:43:56 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 10.71 | nll_loss 9.742 | ppl 856.51 | wps 46202.6 | wpb 510.9 | bsz 1 | num_updates 3648 | best_loss 8.937
2022-03-06 15:43:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 3648 updates
2022-03-06 15:43:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:43:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:43:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 75 @ 3648 updates, score 10.71) (writing took 2.3405318427830935 seconds)
2022-03-06 15:43:58 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2022-03-06 15:43:58 | INFO | train | epoch 075 | loss 4.819 | nll_loss 3.299 | ppl 9.84 | wps 24919.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3648 | lr 0.000456009 | gnorm 1.46 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9683
2022-03-06 15:43:58 | INFO | fairseq.trainer | begin training epoch 76
2022-03-06 15:43:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:45:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 15:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:46:04 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 10.791 | nll_loss 9.815 | ppl 900.6 | wps 44982.3 | wpb 510.9 | bsz 1 | num_updates 3696 | best_loss 8.937
2022-03-06 15:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 3696 updates
2022-03-06 15:46:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 76 @ 3696 updates, score 10.791) (writing took 2.4305645818822086 seconds)
2022-03-06 15:46:06 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2022-03-06 15:46:06 | INFO | train | epoch 076 | loss 4.743 | nll_loss 3.211 | ppl 9.26 | wps 24342.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3696 | lr 0.000462008 | gnorm 1.423 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9811
2022-03-06 15:46:06 | INFO | fairseq.trainer | begin training epoch 77
2022-03-06 15:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:46:16 | INFO | train_inner | epoch 077:      4 / 49 loss=4.776, nll_loss=3.248, ppl=9.5, wps=24681.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3700, lr=0.000462508, gnorm=1.436, loss_scale=16, train_wall=223, gb_free=8.8, wall=9821
2022-03-06 15:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:48:12 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 10.856 | nll_loss 9.879 | ppl 941.54 | wps 44985.3 | wpb 510.9 | bsz 1 | num_updates 3745 | best_loss 8.937
2022-03-06 15:48:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 3745 updates
2022-03-06 15:48:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:48:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:48:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 77 @ 3745 updates, score 10.856) (writing took 2.354910011868924 seconds)
2022-03-06 15:48:14 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2022-03-06 15:48:14 | INFO | train | epoch 077 | loss 4.694 | nll_loss 3.151 | ppl 8.88 | wps 24891 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3745 | lr 0.000468131 | gnorm 1.469 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 9939
2022-03-06 15:48:14 | INFO | fairseq.trainer | begin training epoch 78
2022-03-06 15:48:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:48:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 15:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:50:19 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 11.037 | nll_loss 10.095 | ppl 1093.98 | wps 46568 | wpb 510.9 | bsz 1 | num_updates 3793 | best_loss 8.937
2022-03-06 15:50:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 3793 updates
2022-03-06 15:50:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:50:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 78 @ 3793 updates, score 11.037) (writing took 2.325659568887204 seconds)
2022-03-06 15:50:22 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2022-03-06 15:50:22 | INFO | train | epoch 078 | loss 4.619 | nll_loss 3.065 | ppl 8.37 | wps 24403.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 3793 | lr 0.00047413 | gnorm 1.435 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 10066
2022-03-06 15:50:22 | INFO | fairseq.trainer | begin training epoch 79
2022-03-06 15:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:50:39 | INFO | train_inner | epoch 079:      7 / 49 loss=4.649, nll_loss=3.099, ppl=8.57, wps=24695.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3800, lr=0.000475005, gnorm=1.47, loss_scale=8, train_wall=223, gb_free=8.8, wall=10084
2022-03-06 15:52:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:52:27 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 11.098 | nll_loss 10.145 | ppl 1131.95 | wps 46148.4 | wpb 510.9 | bsz 1 | num_updates 3842 | best_loss 8.937
2022-03-06 15:52:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 3842 updates
2022-03-06 15:52:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:52:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:52:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 79 @ 3842 updates, score 11.098) (writing took 2.399716273881495 seconds)
2022-03-06 15:52:29 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2022-03-06 15:52:29 | INFO | train | epoch 079 | loss 4.567 | nll_loss 3.004 | ppl 8.02 | wps 24861.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3842 | lr 0.000480254 | gnorm 1.491 | loss_scale 8 | train_wall 109 | gb_free 8.8 | wall 10194
2022-03-06 15:52:29 | INFO | fairseq.trainer | begin training epoch 80
2022-03-06 15:52:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:54:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:54:35 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 11.14 | nll_loss 10.166 | ppl 1148.8 | wps 45407.9 | wpb 510.9 | bsz 1 | num_updates 3891 | best_loss 8.937
2022-03-06 15:54:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 3891 updates
2022-03-06 15:54:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:54:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:54:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 80 @ 3891 updates, score 11.14) (writing took 2.364182572811842 seconds)
2022-03-06 15:54:37 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2022-03-06 15:54:37 | INFO | train | epoch 080 | loss 4.503 | nll_loss 2.928 | ppl 7.61 | wps 24900.3 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3891 | lr 0.000486378 | gnorm 1.426 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 10322
2022-03-06 15:54:37 | INFO | fairseq.trainer | begin training epoch 81
2022-03-06 15:54:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:54:59 | INFO | train_inner | epoch 081:      9 / 49 loss=4.523, nll_loss=2.952, ppl=7.74, wps=24913.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=3900, lr=0.000487503, gnorm=1.437, loss_scale=16, train_wall=221, gb_free=8.8, wall=10344
2022-03-06 15:56:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:56:42 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 11.218 | nll_loss 10.265 | ppl 1230.26 | wps 46603.6 | wpb 510.9 | bsz 1 | num_updates 3940 | best_loss 8.937
2022-03-06 15:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 3940 updates
2022-03-06 15:56:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:56:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:56:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 81 @ 3940 updates, score 11.218) (writing took 2.3109432673081756 seconds)
2022-03-06 15:56:44 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2022-03-06 15:56:44 | INFO | train | epoch 081 | loss 4.445 | nll_loss 2.86 | ppl 7.26 | wps 24921.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3940 | lr 0.000492502 | gnorm 1.403 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 10449
2022-03-06 15:56:45 | INFO | fairseq.trainer | begin training epoch 82
2022-03-06 15:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:58:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 15:58:50 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 11.368 | nll_loss 10.415 | ppl 1365.27 | wps 46446 | wpb 510.9 | bsz 1 | num_updates 3989 | best_loss 8.937
2022-03-06 15:58:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 3989 updates
2022-03-06 15:58:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:58:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 15:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 82 @ 3989 updates, score 11.368) (writing took 2.386138787958771 seconds)
2022-03-06 15:58:52 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2022-03-06 15:58:52 | INFO | train | epoch 082 | loss 4.387 | nll_loss 2.793 | ppl 6.93 | wps 24890.2 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 3989 | lr 0.000498625 | gnorm 1.472 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 10577
2022-03-06 15:58:52 | INFO | fairseq.trainer | begin training epoch 83
2022-03-06 15:58:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 15:59:20 | INFO | train_inner | epoch 083:     11 / 49 loss=4.402, nll_loss=2.81, ppl=7.01, wps=24934.5, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4000, lr=0.0005, gnorm=1.43, loss_scale=16, train_wall=221, gb_free=8.8, wall=10604
2022-03-06 15:59:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 16:00:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:00:58 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 11.408 | nll_loss 10.466 | ppl 1414.29 | wps 45590.9 | wpb 510.9 | bsz 1 | num_updates 4037 | best_loss 8.937
2022-03-06 16:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 4037 updates
2022-03-06 16:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:01:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:01:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 83 @ 4037 updates, score 11.408) (writing took 2.347248448058963 seconds)
2022-03-06 16:01:00 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2022-03-06 16:01:00 | INFO | train | epoch 083 | loss 4.327 | nll_loss 2.722 | ppl 6.6 | wps 24372.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 4037 | lr 0.000497703 | gnorm 1.396 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 10705
2022-03-06 16:01:00 | INFO | fairseq.trainer | begin training epoch 84
2022-03-06 16:01:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:03:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:03:05 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 11.407 | nll_loss 10.456 | ppl 1404.9 | wps 46550.1 | wpb 510.9 | bsz 1 | num_updates 4086 | best_loss 8.937
2022-03-06 16:03:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 4086 updates
2022-03-06 16:03:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:03:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 84 @ 4086 updates, score 11.407) (writing took 2.3441188312135637 seconds)
2022-03-06 16:03:07 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2022-03-06 16:03:07 | INFO | train | epoch 084 | loss 4.272 | nll_loss 2.657 | ppl 6.31 | wps 24910.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4086 | lr 0.00049471 | gnorm 1.441 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 10832
2022-03-06 16:03:07 | INFO | fairseq.trainer | begin training epoch 85
2022-03-06 16:03:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:03:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:03:45 | INFO | train_inner | epoch 085:     15 / 49 loss=4.288, nll_loss=2.675, ppl=6.39, wps=24459.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4100, lr=0.000493865, gnorm=1.44, loss_scale=8, train_wall=226, gb_free=8.8, wall=10870
2022-03-06 16:05:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:05:13 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 11.567 | nll_loss 10.668 | ppl 1626.91 | wps 46465 | wpb 510.9 | bsz 1 | num_updates 4134 | best_loss 8.937
2022-03-06 16:05:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 4134 updates
2022-03-06 16:05:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:05:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:05:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 85 @ 4134 updates, score 11.567) (writing took 2.423454688861966 seconds)
2022-03-06 16:05:15 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2022-03-06 16:05:15 | INFO | train | epoch 085 | loss 4.213 | nll_loss 2.588 | ppl 6.01 | wps 24380.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 4134 | lr 0.00049183 | gnorm 1.4 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 10960
2022-03-06 16:05:15 | INFO | fairseq.trainer | begin training epoch 86
2022-03-06 16:05:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:07:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:07:21 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 11.548 | nll_loss 10.597 | ppl 1549.24 | wps 45494.7 | wpb 510.9 | bsz 1 | num_updates 4183 | best_loss 8.937
2022-03-06 16:07:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 86 @ 4183 updates
2022-03-06 16:07:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:07:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 86 @ 4183 updates, score 11.548) (writing took 2.3543235859833658 seconds)
2022-03-06 16:07:23 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)
2022-03-06 16:07:23 | INFO | train | epoch 086 | loss 4.152 | nll_loss 2.517 | ppl 5.72 | wps 24871.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4183 | lr 0.000488941 | gnorm 1.384 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 11088
2022-03-06 16:07:23 | INFO | fairseq.trainer | begin training epoch 87
2022-03-06 16:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:08:05 | INFO | train_inner | epoch 087:     17 / 49 loss=4.158, nll_loss=2.524, ppl=5.75, wps=24911.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4200, lr=0.00048795, gnorm=1.353, loss_scale=8, train_wall=221, gb_free=8.8, wall=11130
2022-03-06 16:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:09:28 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 11.721 | nll_loss 10.79 | ppl 1770.86 | wps 46322.7 | wpb 510.9 | bsz 1 | num_updates 4232 | best_loss 8.937
2022-03-06 16:09:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 87 @ 4232 updates
2022-03-06 16:09:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:09:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 87 @ 4232 updates, score 11.721) (writing took 2.3064282280392945 seconds)
2022-03-06 16:09:31 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)
2022-03-06 16:09:31 | INFO | train | epoch 087 | loss 4.094 | nll_loss 2.449 | ppl 5.46 | wps 24905.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4232 | lr 0.000486102 | gnorm 1.327 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11215
2022-03-06 16:09:31 | INFO | fairseq.trainer | begin training epoch 88
2022-03-06 16:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:11:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:11:36 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 11.771 | nll_loss 10.852 | ppl 1848.56 | wps 46856.5 | wpb 510.9 | bsz 1 | num_updates 4281 | best_loss 8.937
2022-03-06 16:11:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 88 @ 4281 updates
2022-03-06 16:11:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:11:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:11:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 88 @ 4281 updates, score 11.771) (writing took 2.3819060949608684 seconds)
2022-03-06 16:11:38 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)
2022-03-06 16:11:38 | INFO | train | epoch 088 | loss 4.04 | nll_loss 2.386 | ppl 5.23 | wps 24895.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4281 | lr 0.000483312 | gnorm 1.313 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11343
2022-03-06 16:11:38 | INFO | fairseq.trainer | begin training epoch 89
2022-03-06 16:11:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:11:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:12:28 | INFO | train_inner | epoch 089:     20 / 49 loss=4.046, nll_loss=2.393, ppl=5.25, wps=24689.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4300, lr=0.000482243, gnorm=1.331, loss_scale=8, train_wall=224, gb_free=8.8, wall=11393
2022-03-06 16:13:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:13:44 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 11.822 | nll_loss 10.907 | ppl 1920.28 | wps 45683.2 | wpb 510.9 | bsz 1 | num_updates 4329 | best_loss 8.937
2022-03-06 16:13:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 89 @ 4329 updates
2022-03-06 16:13:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:13:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:13:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 89 @ 4329 updates, score 11.822) (writing took 2.3720141141675413 seconds)
2022-03-06 16:13:46 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)
2022-03-06 16:13:46 | INFO | train | epoch 089 | loss 3.989 | nll_loss 2.325 | ppl 5.01 | wps 24355.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 4329 | lr 0.000480625 | gnorm 1.351 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 11471
2022-03-06 16:13:46 | INFO | fairseq.trainer | begin training epoch 90
2022-03-06 16:13:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:15:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:15:51 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 11.936 | nll_loss 11.037 | ppl 2100.64 | wps 46257.7 | wpb 510.9 | bsz 1 | num_updates 4378 | best_loss 8.937
2022-03-06 16:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 90 @ 4378 updates
2022-03-06 16:15:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:15:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:15:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 90 @ 4378 updates, score 11.936) (writing took 2.366879953071475 seconds)
2022-03-06 16:15:54 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)
2022-03-06 16:15:54 | INFO | train | epoch 090 | loss 3.936 | nll_loss 2.264 | ppl 4.8 | wps 24894.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4378 | lr 0.000477928 | gnorm 1.325 | loss_scale 8 | train_wall 108 | gb_free 8.8 | wall 11598
2022-03-06 16:15:54 | INFO | fairseq.trainer | begin training epoch 91
2022-03-06 16:15:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:16:48 | INFO | train_inner | epoch 091:     22 / 49 loss=3.941, nll_loss=2.27, ppl=4.82, wps=24913.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4400, lr=0.000476731, gnorm=1.329, loss_scale=8, train_wall=221, gb_free=8.8, wall=11653
2022-03-06 16:17:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:17:59 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 11.99 | nll_loss 11.109 | ppl 2208.15 | wps 46632.7 | wpb 510.9 | bsz 1 | num_updates 4427 | best_loss 8.937
2022-03-06 16:17:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 91 @ 4427 updates
2022-03-06 16:17:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 91 @ 4427 updates, score 11.99) (writing took 2.357229395303875 seconds)
2022-03-06 16:18:01 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)
2022-03-06 16:18:01 | INFO | train | epoch 091 | loss 3.885 | nll_loss 2.204 | ppl 4.61 | wps 24909 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4427 | lr 0.000475275 | gnorm 1.299 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11726
2022-03-06 16:18:01 | INFO | fairseq.trainer | begin training epoch 92
2022-03-06 16:18:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:20:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:20:06 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 12.004 | nll_loss 11.099 | ppl 2194.23 | wps 45646.5 | wpb 510.9 | bsz 1 | num_updates 4476 | best_loss 8.937
2022-03-06 16:20:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 92 @ 4476 updates
2022-03-06 16:20:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:20:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:20:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 92 @ 4476 updates, score 12.004) (writing took 2.3501883149147034 seconds)
2022-03-06 16:20:09 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)
2022-03-06 16:20:09 | INFO | train | epoch 092 | loss 3.841 | nll_loss 2.152 | ppl 4.45 | wps 24900.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 4476 | lr 0.000472667 | gnorm 1.286 | loss_scale 16 | train_wall 108 | gb_free 8.8 | wall 11854
2022-03-06 16:20:09 | INFO | fairseq.trainer | begin training epoch 93
2022-03-06 16:20:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:21:11 | INFO | train_inner | epoch 093:     24 / 49 loss=3.839, nll_loss=2.15, ppl=4.44, wps=24734.8, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=4500, lr=0.000471405, gnorm=1.275, loss_scale=16, train_wall=223, gb_free=8.8, wall=11915
2022-03-06 16:21:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:22:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:22:21 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 12.094 | nll_loss 11.196 | ppl 2346.14 | wps 40411.5 | wpb 510.9 | bsz 1 | num_updates 4524 | best_loss 8.937
2022-03-06 16:22:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 93 @ 4524 updates
2022-03-06 16:22:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:22:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:22:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 93 @ 4524 updates, score 12.094) (writing took 2.3672094610519707 seconds)
2022-03-06 16:22:24 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)
2022-03-06 16:22:24 | INFO | train | epoch 093 | loss 3.793 | nll_loss 2.096 | ppl 4.28 | wps 23081.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 4524 | lr 0.000470152 | gnorm 1.286 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 11988
2022-03-06 16:22:24 | INFO | fairseq.trainer | begin training epoch 94
2022-03-06 16:22:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:24:39 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 12.204 | nll_loss 11.343 | ppl 2596.91 | wps 39554.7 | wpb 510.9 | bsz 1 | num_updates 4573 | best_loss 8.937
2022-03-06 16:24:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 94 @ 4573 updates
2022-03-06 16:24:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:24:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 94 @ 4573 updates, score 12.204) (writing took 2.422522946726531 seconds)
2022-03-06 16:24:41 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)
2022-03-06 16:24:41 | INFO | train | epoch 094 | loss 3.752 | nll_loss 2.048 | ppl 4.14 | wps 23089.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4573 | lr 0.000467627 | gnorm 1.274 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12126
2022-03-06 16:24:41 | INFO | fairseq.trainer | begin training epoch 95
2022-03-06 16:24:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:25:53 | INFO | train_inner | epoch 095:     27 / 49 loss=3.752, nll_loss=2.049, ppl=4.14, wps=22936.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=4600, lr=0.000466252, gnorm=1.285, loss_scale=8, train_wall=241, gb_free=8.8, wall=12198
2022-03-06 16:26:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:26:56 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 12.117 | nll_loss 11.228 | ppl 2398.27 | wps 39821.4 | wpb 510.9 | bsz 1 | num_updates 4622 | best_loss 8.937
2022-03-06 16:26:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 95 @ 4622 updates
2022-03-06 16:26:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:26:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 95 @ 4622 updates, score 12.117) (writing took 2.4996303860098124 seconds)
2022-03-06 16:26:58 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)
2022-03-06 16:26:58 | INFO | train | epoch 095 | loss 3.707 | nll_loss 1.996 | ppl 3.99 | wps 23173.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4622 | lr 0.000465141 | gnorm 1.24 | loss_scale 8 | train_wall 116 | gb_free 8.8 | wall 12263
2022-03-06 16:26:58 | INFO | fairseq.trainer | begin training epoch 96
2022-03-06 16:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:28:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:29:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:29:13 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 12.197 | nll_loss 11.285 | ppl 2496.15 | wps 40579 | wpb 510.9 | bsz 1 | num_updates 4670 | best_loss 8.937
2022-03-06 16:29:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 96 @ 4670 updates
2022-03-06 16:29:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:29:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 96 @ 4670 updates, score 12.197) (writing took 2.5874234968796372 seconds)
2022-03-06 16:29:15 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)
2022-03-06 16:29:15 | INFO | train | epoch 096 | loss 3.665 | nll_loss 1.947 | ppl 3.86 | wps 22771.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4670 | lr 0.000462745 | gnorm 1.24 | loss_scale 8 | train_wall 116 | gb_free 8.8 | wall 12400
2022-03-06 16:29:15 | INFO | fairseq.trainer | begin training epoch 97
2022-03-06 16:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:30:35 | INFO | train_inner | epoch 097:     30 / 49 loss=3.66, nll_loss=1.941, ppl=3.84, wps=23051.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=4700, lr=0.000461266, gnorm=1.236, loss_scale=8, train_wall=239, gb_free=8.8, wall=12480
2022-03-06 16:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:31:30 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 12.292 | nll_loss 11.422 | ppl 2744.8 | wps 40118.9 | wpb 510.9 | bsz 1 | num_updates 4719 | best_loss 8.937
2022-03-06 16:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 97 @ 4719 updates
2022-03-06 16:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 97 @ 4719 updates, score 12.292) (writing took 2.574105827137828 seconds)
2022-03-06 16:31:32 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)
2022-03-06 16:31:32 | INFO | train | epoch 097 | loss 3.629 | nll_loss 1.904 | ppl 3.74 | wps 23206.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4719 | lr 0.000460336 | gnorm 1.243 | loss_scale 8 | train_wall 116 | gb_free 8.8 | wall 12537
2022-03-06 16:31:32 | INFO | fairseq.trainer | begin training epoch 98
2022-03-06 16:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:33:47 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 12.36 | nll_loss 11.502 | ppl 2901.33 | wps 39673.5 | wpb 510.9 | bsz 1 | num_updates 4768 | best_loss 8.937
2022-03-06 16:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 98 @ 4768 updates
2022-03-06 16:33:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:33:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 98 @ 4768 updates, score 12.36) (writing took 2.4294988941401243 seconds)
2022-03-06 16:33:50 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)
2022-03-06 16:33:50 | INFO | train | epoch 098 | loss 3.589 | nll_loss 1.858 | ppl 3.63 | wps 23111.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4768 | lr 0.000457965 | gnorm 1.203 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12674
2022-03-06 16:33:50 | INFO | fairseq.trainer | begin training epoch 99
2022-03-06 16:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:34:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:35:18 | INFO | train_inner | epoch 099:     33 / 49 loss=3.587, nll_loss=1.855, ppl=3.62, wps=22917.5, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=4800, lr=0.000456435, gnorm=1.224, loss_scale=8, train_wall=241, gb_free=8.8, wall=12763
2022-03-06 16:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:36:05 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 12.428 | nll_loss 11.574 | ppl 3048.36 | wps 40117.6 | wpb 510.9 | bsz 1 | num_updates 4816 | best_loss 8.937
2022-03-06 16:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 99 @ 4816 updates
2022-03-06 16:36:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 99 @ 4816 updates, score 12.428) (writing took 2.6494161523878574 seconds)
2022-03-06 16:36:07 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)
2022-03-06 16:36:07 | INFO | train | epoch 099 | loss 3.549 | nll_loss 1.811 | ppl 3.51 | wps 22596.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 4816 | lr 0.000455677 | gnorm 1.2 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12812
2022-03-06 16:36:07 | INFO | fairseq.trainer | begin training epoch 100
2022-03-06 16:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:38:22 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 12.358 | nll_loss 11.478 | ppl 2852.68 | wps 40618.3 | wpb 510.9 | bsz 1 | num_updates 4865 | best_loss 8.937
2022-03-06 16:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 4865 updates
2022-03-06 16:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:38:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:38:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 100 @ 4865 updates, score 12.358) (writing took 2.6187526248395443 seconds)
2022-03-06 16:38:25 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)
2022-03-06 16:38:25 | INFO | train | epoch 100 | loss 3.516 | nll_loss 1.773 | ppl 3.42 | wps 23111.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4865 | lr 0.000453376 | gnorm 1.208 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 12950
2022-03-06 16:38:25 | INFO | fairseq.trainer | begin training epoch 101
2022-03-06 16:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:39:58 | INFO | train_inner | epoch 101:     35 / 49 loss=3.51, nll_loss=1.766, ppl=3.4, wps=23121.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=4900, lr=0.000451754, gnorm=1.192, loss_scale=8, train_wall=239, gb_free=8.8, wall=13043
2022-03-06 16:40:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:40:40 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 12.419 | nll_loss 11.537 | ppl 2971.89 | wps 40188.8 | wpb 510.9 | bsz 1 | num_updates 4914 | best_loss 8.937
2022-03-06 16:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 101 @ 4914 updates
2022-03-06 16:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:40:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:40:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 101 @ 4914 updates, score 12.419) (writing took 2.4759262460283935 seconds)
2022-03-06 16:40:43 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2022-03-06 16:40:43 | INFO | train | epoch 101 | loss 3.483 | nll_loss 1.734 | ppl 3.33 | wps 23079.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4914 | lr 0.00045111 | gnorm 1.2 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 13087
2022-03-06 16:40:43 | INFO | fairseq.trainer | begin training epoch 102
2022-03-06 16:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:42:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:42:58 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 12.516 | nll_loss 11.663 | ppl 3241.83 | wps 39473.9 | wpb 510.9 | bsz 1 | num_updates 4963 | best_loss 8.937
2022-03-06 16:42:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 102 @ 4963 updates
2022-03-06 16:42:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:43:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:43:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 102 @ 4963 updates, score 12.516) (writing took 2.4418685897253454 seconds)
2022-03-06 16:43:00 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2022-03-06 16:43:00 | INFO | train | epoch 102 | loss 3.447 | nll_loss 1.692 | ppl 3.23 | wps 23118.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 4963 | lr 0.000448878 | gnorm 1.163 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 13225
2022-03-06 16:43:00 | INFO | fairseq.trainer | begin training epoch 103
2022-03-06 16:43:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:44:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:44:42 | INFO | train_inner | epoch 103:     38 / 49 loss=3.439, nll_loss=1.683, ppl=3.21, wps=22916, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=5000, lr=0.000447214, gnorm=1.176, loss_scale=8, train_wall=241, gb_free=8.8, wall=13326
2022-03-06 16:45:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:45:14 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 12.591 | nll_loss 11.754 | ppl 3454.88 | wps 41931.3 | wpb 510.9 | bsz 1 | num_updates 5011 | best_loss 8.937
2022-03-06 16:45:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 103 @ 5011 updates
2022-03-06 16:45:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:45:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 103 @ 5011 updates, score 12.591) (writing took 2.465154069941491 seconds)
2022-03-06 16:45:17 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2022-03-06 16:45:17 | INFO | train | epoch 103 | loss 3.415 | nll_loss 1.656 | ppl 3.15 | wps 22771.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5011 | lr 0.000446722 | gnorm 1.179 | loss_scale 8 | train_wall 116 | gb_free 8.8 | wall 13361
2022-03-06 16:45:17 | INFO | fairseq.trainer | begin training epoch 104
2022-03-06 16:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:47:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:47:29 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 12.622 | nll_loss 11.784 | ppl 3525.86 | wps 40852 | wpb 510.9 | bsz 1 | num_updates 5060 | best_loss 8.937
2022-03-06 16:47:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 104 @ 5060 updates
2022-03-06 16:47:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:47:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 104 @ 5060 updates, score 12.622) (writing took 2.4659834150224924 seconds)
2022-03-06 16:47:32 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2022-03-06 16:47:32 | INFO | train | epoch 104 | loss 3.386 | nll_loss 1.622 | ppl 3.08 | wps 23547.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5060 | lr 0.000444554 | gnorm 1.152 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13496
2022-03-06 16:47:32 | INFO | fairseq.trainer | begin training epoch 105
2022-03-06 16:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:49:17 | INFO | train_inner | epoch 105:     40 / 49 loss=3.377, nll_loss=1.612, ppl=3.06, wps=23584.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=5100, lr=0.000442807, gnorm=1.146, loss_scale=8, train_wall=234, gb_free=8.8, wall=13601
2022-03-06 16:49:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:49:44 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 12.615 | nll_loss 11.765 | ppl 3480.13 | wps 41017.5 | wpb 510.9 | bsz 1 | num_updates 5109 | best_loss 8.937
2022-03-06 16:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 105 @ 5109 updates
2022-03-06 16:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:49:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:49:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 105 @ 5109 updates, score 12.615) (writing took 2.5309584010392427 seconds)
2022-03-06 16:49:47 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2022-03-06 16:49:47 | INFO | train | epoch 105 | loss 3.355 | nll_loss 1.586 | ppl 3 | wps 23511.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5109 | lr 0.000442417 | gnorm 1.139 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13632
2022-03-06 16:49:47 | INFO | fairseq.trainer | begin training epoch 106
2022-03-06 16:49:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:50:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:51:59 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 12.671 | nll_loss 11.827 | ppl 3633.99 | wps 41610 | wpb 510.9 | bsz 1 | num_updates 5157 | best_loss 8.937
2022-03-06 16:51:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 106 @ 5157 updates
2022-03-06 16:51:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:52:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:52:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 106 @ 5157 updates, score 12.671) (writing took 2.511133980937302 seconds)
2022-03-06 16:52:02 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2022-03-06 16:52:02 | INFO | train | epoch 106 | loss 3.326 | nll_loss 1.553 | ppl 2.93 | wps 23087.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 5157 | lr 0.000440353 | gnorm 1.14 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13766
2022-03-06 16:52:02 | INFO | fairseq.trainer | begin training epoch 107
2022-03-06 16:52:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:53:55 | INFO | train_inner | epoch 107:     43 / 49 loss=3.318, nll_loss=1.544, ppl=2.92, wps=23339.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5200, lr=0.000438529, gnorm=1.138, loss_scale=8, train_wall=237, gb_free=8.8, wall=13879
2022-03-06 16:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:54:14 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 12.669 | nll_loss 11.825 | ppl 3628.49 | wps 41307.4 | wpb 510.9 | bsz 1 | num_updates 5206 | best_loss 8.937
2022-03-06 16:54:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 107 @ 5206 updates
2022-03-06 16:54:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:54:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:54:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 107 @ 5206 updates, score 12.669) (writing took 2.4500239794142544 seconds)
2022-03-06 16:54:17 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2022-03-06 16:54:17 | INFO | train | epoch 107 | loss 3.299 | nll_loss 1.521 | ppl 2.87 | wps 23521.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5206 | lr 0.000438276 | gnorm 1.125 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 13902
2022-03-06 16:54:17 | INFO | fairseq.trainer | begin training epoch 108
2022-03-06 16:54:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:56:30 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 12.799 | nll_loss 11.977 | ppl 4030.68 | wps 41540.8 | wpb 510.9 | bsz 1 | num_updates 5255 | best_loss 8.937
2022-03-06 16:56:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 108 @ 5255 updates
2022-03-06 16:56:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:56:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:56:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 108 @ 5255 updates, score 12.799) (writing took 2.4162412770092487 seconds)
2022-03-06 16:56:32 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2022-03-06 16:56:32 | INFO | train | epoch 108 | loss 3.272 | nll_loss 1.49 | ppl 2.81 | wps 23508.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5255 | lr 0.000436228 | gnorm 1.07 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 14037
2022-03-06 16:56:32 | INFO | fairseq.trainer | begin training epoch 109
2022-03-06 16:56:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 16:57:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 16:58:33 | INFO | train_inner | epoch 109:     46 / 49 loss=3.263, nll_loss=1.48, ppl=2.79, wps=23296, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5300, lr=0.000434372, gnorm=1.1, loss_scale=8, train_wall=237, gb_free=8.8, wall=14158
2022-03-06 16:58:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 16:58:45 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 12.811 | nll_loss 11.987 | ppl 4058.56 | wps 39644.6 | wpb 510.9 | bsz 1 | num_updates 5303 | best_loss 8.937
2022-03-06 16:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 109 @ 5303 updates
2022-03-06 16:58:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:58:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 16:58:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 109 @ 5303 updates, score 12.811) (writing took 2.495412277057767 seconds)
2022-03-06 16:58:48 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2022-03-06 16:58:48 | INFO | train | epoch 109 | loss 3.247 | nll_loss 1.462 | ppl 2.75 | wps 22926.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5303 | lr 0.000434249 | gnorm 1.127 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 14172
2022-03-06 16:58:48 | INFO | fairseq.trainer | begin training epoch 110
2022-03-06 16:58:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:00:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:01:03 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 12.833 | nll_loss 11.998 | ppl 4090.78 | wps 40357.4 | wpb 510.9 | bsz 1 | num_updates 5352 | best_loss 8.937
2022-03-06 17:01:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 110 @ 5352 updates
2022-03-06 17:01:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:01:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 110 @ 5352 updates, score 12.833) (writing took 2.4648414659313858 seconds)
2022-03-06 17:01:05 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2022-03-06 17:01:05 | INFO | train | epoch 110 | loss 3.223 | nll_loss 1.435 | ppl 2.7 | wps 23074.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5352 | lr 0.000432257 | gnorm 1.105 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14310
2022-03-06 17:01:05 | INFO | fairseq.trainer | begin training epoch 111
2022-03-06 17:01:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:03:14 | INFO | train_inner | epoch 111:     48 / 49 loss=3.213, nll_loss=1.423, ppl=2.68, wps=23111.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5400, lr=0.000430331, gnorm=1.1, loss_scale=16, train_wall=239, gb_free=8.8, wall=14438
2022-03-06 17:03:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:03:21 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 12.909 | nll_loss 12.088 | ppl 4352.9 | wps 40394.6 | wpb 510.9 | bsz 1 | num_updates 5401 | best_loss 8.937
2022-03-06 17:03:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 111 @ 5401 updates
2022-03-06 17:03:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:03:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:03:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 111 @ 5401 updates, score 12.909) (writing took 2.446230622008443 seconds)
2022-03-06 17:03:23 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2022-03-06 17:03:23 | INFO | train | epoch 111 | loss 3.199 | nll_loss 1.406 | ppl 2.65 | wps 23102.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5401 | lr 0.000430292 | gnorm 1.094 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 14448
2022-03-06 17:03:23 | INFO | fairseq.trainer | begin training epoch 112
2022-03-06 17:03:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:05:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:05:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:05:38 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 12.86 | nll_loss 12.03 | ppl 4183.35 | wps 39875.4 | wpb 510.9 | bsz 1 | num_updates 5449 | best_loss 8.937
2022-03-06 17:05:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 112 @ 5449 updates
2022-03-06 17:05:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:05:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:05:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 112 @ 5449 updates, score 12.86) (writing took 2.4798896592110395 seconds)
2022-03-06 17:05:41 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2022-03-06 17:05:41 | INFO | train | epoch 112 | loss 3.172 | nll_loss 1.376 | ppl 2.6 | wps 22603.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 5449 | lr 0.000428392 | gnorm 1.062 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14585
2022-03-06 17:05:41 | INFO | fairseq.trainer | begin training epoch 113
2022-03-06 17:05:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:07:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:07:56 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 12.836 | nll_loss 12.017 | ppl 4143.12 | wps 40403.1 | wpb 510.9 | bsz 1 | num_updates 5498 | best_loss 8.937
2022-03-06 17:07:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 113 @ 5498 updates
2022-03-06 17:07:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:07:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:07:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 113 @ 5498 updates, score 12.836) (writing took 2.524170956108719 seconds)
2022-03-06 17:07:58 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2022-03-06 17:07:58 | INFO | train | epoch 113 | loss 3.153 | nll_loss 1.354 | ppl 2.56 | wps 23097 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5498 | lr 0.000426479 | gnorm 1.057 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14723
2022-03-06 17:07:58 | INFO | fairseq.trainer | begin training epoch 114
2022-03-06 17:07:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:08:04 | INFO | train_inner | epoch 114:      2 / 49 loss=3.162, nll_loss=1.364, ppl=2.57, wps=22253.8, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=5500, lr=0.000426401, gnorm=1.062, loss_scale=8, train_wall=240, gb_free=8.8, wall=14729
2022-03-06 17:10:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:10:13 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 12.903 | nll_loss 12.07 | ppl 4299.5 | wps 40004.5 | wpb 510.9 | bsz 1 | num_updates 5547 | best_loss 8.937
2022-03-06 17:10:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 114 @ 5547 updates
2022-03-06 17:10:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:10:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:10:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 114 @ 5547 updates, score 12.903) (writing took 2.543101067189127 seconds)
2022-03-06 17:10:16 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2022-03-06 17:10:16 | INFO | train | epoch 114 | loss 3.133 | nll_loss 1.332 | ppl 2.52 | wps 23085.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5547 | lr 0.000424591 | gnorm 1.071 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 14861
2022-03-06 17:10:16 | INFO | fairseq.trainer | begin training epoch 115
2022-03-06 17:10:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:12:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:12:31 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 12.832 | nll_loss 11.992 | ppl 4074.73 | wps 39820.8 | wpb 510.9 | bsz 1 | num_updates 5596 | best_loss 8.937
2022-03-06 17:12:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 115 @ 5596 updates
2022-03-06 17:12:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:12:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:12:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 115 @ 5596 updates, score 12.832) (writing took 2.568320251069963 seconds)
2022-03-06 17:12:34 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2022-03-06 17:12:34 | INFO | train | epoch 115 | loss 3.108 | nll_loss 1.303 | ppl 2.47 | wps 23057.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5596 | lr 0.000422728 | gnorm 1.038 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 14999
2022-03-06 17:12:34 | INFO | fairseq.trainer | begin training epoch 116
2022-03-06 17:12:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:12:45 | INFO | train_inner | epoch 116:      4 / 49 loss=3.118, nll_loss=1.315, ppl=2.49, wps=23093.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5600, lr=0.000422577, gnorm=1.054, loss_scale=16, train_wall=239, gb_free=8.8, wall=15009
2022-03-06 17:14:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:14:49 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 12.954 | nll_loss 12.145 | ppl 4529.51 | wps 40531 | wpb 510.9 | bsz 1 | num_updates 5645 | best_loss 8.937
2022-03-06 17:14:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 116 @ 5645 updates
2022-03-06 17:14:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:14:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 116 @ 5645 updates, score 12.954) (writing took 2.4994214340113103 seconds)
2022-03-06 17:14:52 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2022-03-06 17:14:52 | INFO | train | epoch 116 | loss 3.093 | nll_loss 1.286 | ppl 2.44 | wps 23066 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5645 | lr 0.000420889 | gnorm 1.054 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 15136
2022-03-06 17:14:52 | INFO | fairseq.trainer | begin training epoch 117
2022-03-06 17:14:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:17:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:17:07 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 12.881 | nll_loss 12.055 | ppl 4256.08 | wps 39589.9 | wpb 510.9 | bsz 1 | num_updates 5694 | best_loss 8.937
2022-03-06 17:17:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 117 @ 5694 updates
2022-03-06 17:17:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:17:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:17:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 117 @ 5694 updates, score 12.881) (writing took 2.447469845879823 seconds)
2022-03-06 17:17:10 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2022-03-06 17:17:10 | INFO | train | epoch 117 | loss 3.07 | nll_loss 1.26 | ppl 2.4 | wps 23044.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5694 | lr 0.000419075 | gnorm 1.028 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 15274
2022-03-06 17:17:10 | INFO | fairseq.trainer | begin training epoch 118
2022-03-06 17:17:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:17:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:17:28 | INFO | train_inner | epoch 118:      7 / 49 loss=3.079, nll_loss=1.27, ppl=2.41, wps=22873.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=5700, lr=0.000418854, gnorm=1.038, loss_scale=16, train_wall=242, gb_free=8.8, wall=15293
2022-03-06 17:19:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:19:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:19:25 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 13.055 | nll_loss 12.243 | ppl 4847.2 | wps 40128.4 | wpb 510.9 | bsz 1 | num_updates 5741 | best_loss 8.937
2022-03-06 17:19:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 118 @ 5741 updates
2022-03-06 17:19:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:19:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:19:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 118 @ 5741 updates, score 13.055) (writing took 2.4530535200610757 seconds)
2022-03-06 17:19:27 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2022-03-06 17:19:27 | INFO | train | epoch 118 | loss 3.049 | nll_loss 1.237 | ppl 2.36 | wps 22157.1 | ups 0.34 | wpb 64829.4 | bsz 126.6 | num_updates 5741 | lr 0.000417356 | gnorm 1.023 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 15412
2022-03-06 17:19:27 | INFO | fairseq.trainer | begin training epoch 119
2022-03-06 17:19:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:21:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:21:42 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 12.998 | nll_loss 12.198 | ppl 4697.22 | wps 40067.6 | wpb 510.9 | bsz 1 | num_updates 5790 | best_loss 8.937
2022-03-06 17:21:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 119 @ 5790 updates
2022-03-06 17:21:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:21:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:21:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 119 @ 5790 updates, score 12.998) (writing took 2.3947583930566907 seconds)
2022-03-06 17:21:44 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2022-03-06 17:21:44 | INFO | train | epoch 119 | loss 3.033 | nll_loss 1.219 | ppl 2.33 | wps 23138.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5790 | lr 0.000415586 | gnorm 0.999 | loss_scale 8 | train_wall 117 | gb_free 8.8 | wall 15549
2022-03-06 17:21:44 | INFO | fairseq.trainer | begin training epoch 120
2022-03-06 17:21:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:22:11 | INFO | train_inner | epoch 120:     10 / 49 loss=3.036, nll_loss=1.222, ppl=2.33, wps=22930.5, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=5800, lr=0.000415227, gnorm=1.009, loss_scale=8, train_wall=241, gb_free=8.8, wall=15576
2022-03-06 17:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:23:58 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 12.966 | nll_loss 12.155 | ppl 4561.78 | wps 41588.8 | wpb 510.9 | bsz 1 | num_updates 5839 | best_loss 8.937
2022-03-06 17:23:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 120 @ 5839 updates
2022-03-06 17:23:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:24:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:24:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 120 @ 5839 updates, score 12.966) (writing took 2.5546458372846246 seconds)
2022-03-06 17:24:00 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2022-03-06 17:24:00 | INFO | train | epoch 120 | loss 3.015 | nll_loss 1.199 | ppl 2.3 | wps 23403.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5839 | lr 0.000413838 | gnorm 1.011 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 15685
2022-03-06 17:24:00 | INFO | fairseq.trainer | begin training epoch 121
2022-03-06 17:24:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:26:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:26:13 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 12.992 | nll_loss 12.193 | ppl 4683.59 | wps 41821.4 | wpb 510.9 | bsz 1 | num_updates 5888 | best_loss 8.937
2022-03-06 17:26:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 121 @ 5888 updates
2022-03-06 17:26:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:26:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 121 @ 5888 updates, score 12.992) (writing took 2.4296481139026582 seconds)
2022-03-06 17:26:15 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2022-03-06 17:26:15 | INFO | train | epoch 121 | loss 2.997 | nll_loss 1.179 | ppl 2.26 | wps 23522.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5888 | lr 0.000412113 | gnorm 0.988 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 15820
2022-03-06 17:26:15 | INFO | fairseq.trainer | begin training epoch 122
2022-03-06 17:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:26:47 | INFO | train_inner | epoch 122:     12 / 49 loss=3.002, nll_loss=1.184, ppl=2.27, wps=23534.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=5900, lr=0.000411693, gnorm=0.992, loss_scale=16, train_wall=235, gb_free=8.8, wall=15852
2022-03-06 17:28:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:28:28 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 12.992 | nll_loss 12.191 | ppl 4674.54 | wps 40884.9 | wpb 510.9 | bsz 1 | num_updates 5937 | best_loss 8.937
2022-03-06 17:28:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 122 @ 5937 updates
2022-03-06 17:28:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:28:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:28:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 122 @ 5937 updates, score 12.992) (writing took 2.4690942522138357 seconds)
2022-03-06 17:28:30 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2022-03-06 17:28:30 | INFO | train | epoch 122 | loss 2.983 | nll_loss 1.163 | ppl 2.24 | wps 23512.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 5937 | lr 0.000410409 | gnorm 1.003 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 15955
2022-03-06 17:28:30 | INFO | fairseq.trainer | begin training epoch 123
2022-03-06 17:28:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:28:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-06 17:30:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:30:43 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 12.993 | nll_loss 12.195 | ppl 4690.4 | wps 41607.6 | wpb 510.9 | bsz 1 | num_updates 5985 | best_loss 8.937
2022-03-06 17:30:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 123 @ 5985 updates
2022-03-06 17:30:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:30:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 123 @ 5985 updates, score 12.993) (writing took 2.389564848970622 seconds)
2022-03-06 17:30:46 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2022-03-06 17:30:46 | INFO | train | epoch 123 | loss 2.967 | nll_loss 1.146 | ppl 2.21 | wps 23026.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 5985 | lr 0.00040876 | gnorm 0.986 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 16090
2022-03-06 17:30:46 | INFO | fairseq.trainer | begin training epoch 124
2022-03-06 17:30:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:31:25 | INFO | train_inner | epoch 124:     15 / 49 loss=2.97, nll_loss=1.149, ppl=2.22, wps=23313.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=6000, lr=0.000408248, gnorm=0.996, loss_scale=8, train_wall=237, gb_free=8.8, wall=16130
2022-03-06 17:32:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:32:58 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 13.069 | nll_loss 12.274 | ppl 4951.62 | wps 41196.8 | wpb 510.9 | bsz 1 | num_updates 6034 | best_loss 8.937
2022-03-06 17:32:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 124 @ 6034 updates
2022-03-06 17:32:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:33:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 124 @ 6034 updates, score 13.069) (writing took 2.5059869680553675 seconds)
2022-03-06 17:33:01 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2022-03-06 17:33:01 | INFO | train | epoch 124 | loss 2.949 | nll_loss 1.126 | ppl 2.18 | wps 23506.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6034 | lr 0.000407096 | gnorm 0.955 | loss_scale 8 | train_wall 115 | gb_free 8.8 | wall 16226
2022-03-06 17:33:01 | INFO | fairseq.trainer | begin training epoch 125
2022-03-06 17:33:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:35:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:35:13 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 13.029 | nll_loss 12.237 | ppl 4826.76 | wps 41535.2 | wpb 510.9 | bsz 1 | num_updates 6083 | best_loss 8.937
2022-03-06 17:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 125 @ 6083 updates
2022-03-06 17:35:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:35:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:35:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 125 @ 6083 updates, score 13.029) (writing took 2.589054578449577 seconds)
2022-03-06 17:35:16 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2022-03-06 17:35:16 | INFO | train | epoch 125 | loss 2.935 | nll_loss 1.111 | ppl 2.16 | wps 23522.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6083 | lr 0.000405454 | gnorm 0.97 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 16361
2022-03-06 17:35:16 | INFO | fairseq.trainer | begin training epoch 126
2022-03-06 17:35:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:36:01 | INFO | train_inner | epoch 126:     17 / 49 loss=2.938, nll_loss=1.114, ppl=2.17, wps=23553.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=6100, lr=0.000404888, gnorm=0.963, loss_scale=16, train_wall=234, gb_free=8.8, wall=16405
2022-03-06 17:37:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:37:30 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 13.064 | nll_loss 12.276 | ppl 4960.72 | wps 40380 | wpb 510.9 | bsz 1 | num_updates 6132 | best_loss 8.937
2022-03-06 17:37:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 126 @ 6132 updates
2022-03-06 17:37:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:37:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 126 @ 6132 updates, score 13.064) (writing took 2.6255060601979494 seconds)
2022-03-06 17:37:33 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2022-03-06 17:37:33 | INFO | train | epoch 126 | loss 2.921 | nll_loss 1.096 | ppl 2.14 | wps 23235.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6132 | lr 0.00040383 | gnorm 0.955 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 16497
2022-03-06 17:37:33 | INFO | fairseq.trainer | begin training epoch 127
2022-03-06 17:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:39:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:39:48 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 13.015 | nll_loss 12.208 | ppl 4730.91 | wps 39968.9 | wpb 510.9 | bsz 1 | num_updates 6181 | best_loss 8.937
2022-03-06 17:39:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 127 @ 6181 updates
2022-03-06 17:39:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:39:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:39:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 127 @ 6181 updates, score 13.015) (writing took 2.7534538842737675 seconds)
2022-03-06 17:39:51 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2022-03-06 17:39:51 | INFO | train | epoch 127 | loss 2.905 | nll_loss 1.078 | ppl 2.11 | wps 23038.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6181 | lr 0.000402226 | gnorm 0.944 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16635
2022-03-06 17:39:51 | INFO | fairseq.trainer | begin training epoch 128
2022-03-06 17:39:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:40:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:40:44 | INFO | train_inner | epoch 128:     20 / 49 loss=2.906, nll_loss=1.079, ppl=2.11, wps=22865.5, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=6200, lr=0.00040161, gnorm=0.947, loss_scale=16, train_wall=241, gb_free=8.8, wall=16689
2022-03-06 17:42:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:42:06 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 13.098 | nll_loss 12.314 | ppl 5090.37 | wps 40584.7 | wpb 510.9 | bsz 1 | num_updates 6229 | best_loss 8.937
2022-03-06 17:42:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 128 @ 6229 updates
2022-03-06 17:42:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:42:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:42:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 128 @ 6229 updates, score 13.098) (writing took 2.585218207910657 seconds)
2022-03-06 17:42:08 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2022-03-06 17:42:08 | INFO | train | epoch 128 | loss 2.892 | nll_loss 1.063 | ppl 2.09 | wps 22579.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6229 | lr 0.000400674 | gnorm 0.94 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16773
2022-03-06 17:42:08 | INFO | fairseq.trainer | begin training epoch 129
2022-03-06 17:42:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:44:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:44:24 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 13.059 | nll_loss 12.276 | ppl 4961.08 | wps 40237.2 | wpb 510.9 | bsz 1 | num_updates 6278 | best_loss 8.937
2022-03-06 17:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 129 @ 6278 updates
2022-03-06 17:44:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:44:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:44:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 129 @ 6278 updates, score 13.059) (writing took 2.728701521176845 seconds)
2022-03-06 17:44:26 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2022-03-06 17:44:26 | INFO | train | epoch 129 | loss 2.88 | nll_loss 1.051 | ppl 2.07 | wps 23032.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6278 | lr 0.000399107 | gnorm 0.951 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 16911
2022-03-06 17:44:26 | INFO | fairseq.trainer | begin training epoch 130
2022-03-06 17:44:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:45:25 | INFO | train_inner | epoch 130:     22 / 49 loss=2.88, nll_loss=1.052, ppl=2.07, wps=23072.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=6300, lr=0.00039841, gnorm=0.934, loss_scale=16, train_wall=239, gb_free=8.8, wall=16970
2022-03-06 17:46:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:46:42 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 13.1 | nll_loss 12.315 | ppl 5096.05 | wps 39745.4 | wpb 510.9 | bsz 1 | num_updates 6327 | best_loss 8.937
2022-03-06 17:46:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 130 @ 6327 updates
2022-03-06 17:46:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:46:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:46:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 130 @ 6327 updates, score 13.1) (writing took 2.479272190015763 seconds)
2022-03-06 17:46:44 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2022-03-06 17:46:44 | INFO | train | epoch 130 | loss 2.865 | nll_loss 1.035 | ppl 2.05 | wps 23096.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6327 | lr 0.000397559 | gnorm 0.931 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 17049
2022-03-06 17:46:44 | INFO | fairseq.trainer | begin training epoch 131
2022-03-06 17:46:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:46:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:48:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:48:59 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 13.053 | nll_loss 12.271 | ppl 4942.58 | wps 40262.5 | wpb 510.9 | bsz 1 | num_updates 6375 | best_loss 8.937
2022-03-06 17:48:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 131 @ 6375 updates
2022-03-06 17:48:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:49:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:49:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 131 @ 6375 updates, score 13.053) (writing took 2.4584669577889144 seconds)
2022-03-06 17:49:02 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2022-03-06 17:49:02 | INFO | train | epoch 131 | loss 2.85 | nll_loss 1.019 | ppl 2.03 | wps 22607.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6375 | lr 0.000396059 | gnorm 0.902 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17186
2022-03-06 17:49:02 | INFO | fairseq.trainer | begin training epoch 132
2022-03-06 17:49:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:50:08 | INFO | train_inner | epoch 132:     25 / 49 loss=2.853, nll_loss=1.022, ppl=2.03, wps=22919, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=6400, lr=0.000395285, gnorm=0.927, loss_scale=16, train_wall=241, gb_free=8.8, wall=17253
2022-03-06 17:51:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:51:17 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 13.147 | nll_loss 12.363 | ppl 5266.63 | wps 40016.4 | wpb 510.9 | bsz 1 | num_updates 6424 | best_loss 8.937
2022-03-06 17:51:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 132 @ 6424 updates
2022-03-06 17:51:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:51:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:51:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 132 @ 6424 updates, score 13.147) (writing took 2.5476725031621754 seconds)
2022-03-06 17:51:19 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2022-03-06 17:51:19 | INFO | train | epoch 132 | loss 2.843 | nll_loss 1.012 | ppl 2.02 | wps 23107.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6424 | lr 0.000394546 | gnorm 0.924 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17324
2022-03-06 17:51:19 | INFO | fairseq.trainer | begin training epoch 133
2022-03-06 17:51:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:52:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:53:34 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 13.14 | nll_loss 12.363 | ppl 5268.83 | wps 39950.2 | wpb 510.9 | bsz 1 | num_updates 6472 | best_loss 8.937
2022-03-06 17:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 133 @ 6472 updates
2022-03-06 17:53:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:53:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:53:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 133 @ 6472 updates, score 13.14) (writing took 2.507871627341956 seconds)
2022-03-06 17:53:37 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2022-03-06 17:53:37 | INFO | train | epoch 133 | loss 2.829 | nll_loss 0.997 | ppl 2 | wps 22608.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6472 | lr 0.00039308 | gnorm 0.903 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17462
2022-03-06 17:53:37 | INFO | fairseq.trainer | begin training epoch 134
2022-03-06 17:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:54:52 | INFO | train_inner | epoch 134:     28 / 49 loss=2.829, nll_loss=0.997, ppl=2, wps=22905.2, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=6500, lr=0.000392232, gnorm=0.903, loss_scale=16, train_wall=241, gb_free=8.8, wall=17536
2022-03-06 17:55:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:55:52 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 13.158 | nll_loss 12.389 | ppl 5364.22 | wps 40406.5 | wpb 510.9 | bsz 1 | num_updates 6521 | best_loss 8.937
2022-03-06 17:55:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 134 @ 6521 updates
2022-03-06 17:55:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:55:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:55:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 134 @ 6521 updates, score 13.158) (writing took 2.503331370651722 seconds)
2022-03-06 17:55:54 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2022-03-06 17:55:54 | INFO | train | epoch 134 | loss 2.817 | nll_loss 0.984 | ppl 1.98 | wps 23121.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6521 | lr 0.0003916 | gnorm 0.9 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17599
2022-03-06 17:55:54 | INFO | fairseq.trainer | begin training epoch 135
2022-03-06 17:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 17:58:09 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 13.201 | nll_loss 12.427 | ppl 5507.84 | wps 40162.1 | wpb 510.9 | bsz 1 | num_updates 6570 | best_loss 8.937
2022-03-06 17:58:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 135 @ 6570 updates
2022-03-06 17:58:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:58:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 17:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 135 @ 6570 updates, score 13.201) (writing took 2.5189907788299024 seconds)
2022-03-06 17:58:12 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2022-03-06 17:58:12 | INFO | train | epoch 135 | loss 2.807 | nll_loss 0.973 | ppl 1.96 | wps 23137.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6570 | lr 0.000390137 | gnorm 0.897 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 17736
2022-03-06 17:58:12 | INFO | fairseq.trainer | begin training epoch 136
2022-03-06 17:58:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 17:58:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 17:59:34 | INFO | train_inner | epoch 136:     31 / 49 loss=2.806, nll_loss=0.971, ppl=1.96, wps=22951.5, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=6600, lr=0.000389249, gnorm=0.896, loss_scale=16, train_wall=241, gb_free=8.8, wall=17819
2022-03-06 18:00:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:00:26 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 13.128 | nll_loss 12.356 | ppl 5243.83 | wps 42232.1 | wpb 510.9 | bsz 1 | num_updates 6618 | best_loss 8.937
2022-03-06 18:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 136 @ 6618 updates
2022-03-06 18:00:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:00:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:00:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 136 @ 6618 updates, score 13.128) (writing took 2.5206815996207297 seconds)
2022-03-06 18:00:28 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2022-03-06 18:00:28 | INFO | train | epoch 136 | loss 2.796 | nll_loss 0.961 | ppl 1.95 | wps 22814.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 6618 | lr 0.00038872 | gnorm 0.892 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 17873
2022-03-06 18:00:28 | INFO | fairseq.trainer | begin training epoch 137
2022-03-06 18:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:02:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:02:41 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 13.141 | nll_loss 12.363 | ppl 5267.72 | wps 41039.7 | wpb 510.9 | bsz 1 | num_updates 6667 | best_loss 8.937
2022-03-06 18:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 137 @ 6667 updates
2022-03-06 18:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 137 @ 6667 updates, score 13.141) (writing took 2.3996674371883273 seconds)
2022-03-06 18:02:43 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2022-03-06 18:02:43 | INFO | train | epoch 137 | loss 2.785 | nll_loss 0.951 | ppl 1.93 | wps 23575.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6667 | lr 0.000387289 | gnorm 0.899 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 18008
2022-03-06 18:02:43 | INFO | fairseq.trainer | begin training epoch 138
2022-03-06 18:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:04:09 | INFO | train_inner | epoch 138:     33 / 49 loss=2.784, nll_loss=0.949, ppl=1.93, wps=23605.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=6700, lr=0.000386334, gnorm=0.884, loss_scale=16, train_wall=234, gb_free=8.8, wall=18094
2022-03-06 18:04:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:04:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:04:55 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 13.135 | nll_loss 12.361 | ppl 5259.78 | wps 42152.1 | wpb 510.9 | bsz 1 | num_updates 6715 | best_loss 8.937
2022-03-06 18:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 138 @ 6715 updates
2022-03-06 18:04:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 138 @ 6715 updates, score 13.135) (writing took 2.5681920587085187 seconds)
2022-03-06 18:04:57 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2022-03-06 18:04:57 | INFO | train | epoch 138 | loss 2.774 | nll_loss 0.938 | ppl 1.92 | wps 23204.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 6715 | lr 0.000385902 | gnorm 0.872 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 18142
2022-03-06 18:04:57 | INFO | fairseq.trainer | begin training epoch 139
2022-03-06 18:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:07:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:07:09 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 13.169 | nll_loss 12.391 | ppl 5370.71 | wps 41483.4 | wpb 510.9 | bsz 1 | num_updates 6764 | best_loss 8.937
2022-03-06 18:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 139 @ 6764 updates
2022-03-06 18:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 139 @ 6764 updates, score 13.169) (writing took 2.421535524073988 seconds)
2022-03-06 18:07:11 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2022-03-06 18:07:11 | INFO | train | epoch 139 | loss 2.764 | nll_loss 0.929 | ppl 1.9 | wps 23718.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 6764 | lr 0.000384502 | gnorm 0.863 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 18276
2022-03-06 18:07:11 | INFO | fairseq.trainer | begin training epoch 140
2022-03-06 18:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:08:45 | INFO | train_inner | epoch 140:     36 / 49 loss=2.762, nll_loss=0.926, ppl=1.9, wps=23484.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=6800, lr=0.000383482, gnorm=0.861, loss_scale=16, train_wall=235, gb_free=8.8, wall=18370
2022-03-06 18:09:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:09:23 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 13.261 | nll_loss 12.52 | ppl 5871.68 | wps 41344.2 | wpb 510.9 | bsz 1 | num_updates 6813 | best_loss 8.937
2022-03-06 18:09:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 140 @ 6813 updates
2022-03-06 18:09:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:09:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 140 @ 6813 updates, score 13.261) (writing took 2.531715478748083 seconds)
2022-03-06 18:09:26 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2022-03-06 18:09:26 | INFO | train | epoch 140 | loss 2.754 | nll_loss 0.917 | ppl 1.89 | wps 23556.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6813 | lr 0.000383116 | gnorm 0.847 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 18411
2022-03-06 18:09:26 | INFO | fairseq.trainer | begin training epoch 141
2022-03-06 18:09:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:11:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:11:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:11:39 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 13.161 | nll_loss 12.398 | ppl 5395.38 | wps 41338.4 | wpb 510.9 | bsz 1 | num_updates 6861 | best_loss 8.937
2022-03-06 18:11:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 141 @ 6861 updates
2022-03-06 18:11:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:11:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 141 @ 6861 updates, score 13.161) (writing took 2.3896976127289236 seconds)
2022-03-06 18:11:41 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2022-03-06 18:11:41 | INFO | train | epoch 141 | loss 2.746 | nll_loss 0.909 | ppl 1.88 | wps 23056.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 6861 | lr 0.000381774 | gnorm 0.861 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 18546
2022-03-06 18:11:41 | INFO | fairseq.trainer | begin training epoch 142
2022-03-06 18:11:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:13:23 | INFO | train_inner | epoch 142:     39 / 49 loss=2.744, nll_loss=0.907, ppl=1.88, wps=23338.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=6900, lr=0.000380693, gnorm=0.867, loss_scale=16, train_wall=237, gb_free=8.8, wall=18648
2022-03-06 18:13:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:13:54 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 13.163 | nll_loss 12.395 | ppl 5384.34 | wps 40236.1 | wpb 510.9 | bsz 1 | num_updates 6910 | best_loss 8.937
2022-03-06 18:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 142 @ 6910 updates
2022-03-06 18:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:13:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:13:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 142 @ 6910 updates, score 13.163) (writing took 2.5338825592771173 seconds)
2022-03-06 18:13:56 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2022-03-06 18:13:56 | INFO | train | epoch 142 | loss 2.736 | nll_loss 0.899 | ppl 1.86 | wps 23474.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6910 | lr 0.000380418 | gnorm 0.87 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 18681
2022-03-06 18:13:56 | INFO | fairseq.trainer | begin training epoch 143
2022-03-06 18:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:16:11 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 13.184 | nll_loss 12.421 | ppl 5482.85 | wps 40291.9 | wpb 510.9 | bsz 1 | num_updates 6959 | best_loss 8.937
2022-03-06 18:16:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 143 @ 6959 updates
2022-03-06 18:16:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:16:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:16:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 143 @ 6959 updates, score 13.184) (writing took 2.5129373031668365 seconds)
2022-03-06 18:16:14 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2022-03-06 18:16:14 | INFO | train | epoch 143 | loss 2.726 | nll_loss 0.888 | ppl 1.85 | wps 23106.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 6959 | lr 0.000379076 | gnorm 0.843 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 18819
2022-03-06 18:16:14 | INFO | fairseq.trainer | begin training epoch 144
2022-03-06 18:16:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:17:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:18:06 | INFO | train_inner | epoch 144:     42 / 49 loss=2.723, nll_loss=0.885, ppl=1.85, wps=22929.3, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7000, lr=0.000377964, gnorm=0.834, loss_scale=16, train_wall=241, gb_free=8.8, wall=18931
2022-03-06 18:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:18:29 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 13.188 | nll_loss 12.416 | ppl 5466.63 | wps 39571.6 | wpb 510.9 | bsz 1 | num_updates 7007 | best_loss 8.937
2022-03-06 18:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 144 @ 7007 updates
2022-03-06 18:18:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:18:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 144 @ 7007 updates, score 13.188) (writing took 2.5719005251303315 seconds)
2022-03-06 18:18:32 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2022-03-06 18:18:32 | INFO | train | epoch 144 | loss 2.715 | nll_loss 0.877 | ppl 1.84 | wps 22581.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7007 | lr 0.000377776 | gnorm 0.822 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 18957
2022-03-06 18:18:32 | INFO | fairseq.trainer | begin training epoch 145
2022-03-06 18:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:20:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:20:47 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 13.189 | nll_loss 12.433 | ppl 5529.02 | wps 40292.3 | wpb 510.9 | bsz 1 | num_updates 7056 | best_loss 8.937
2022-03-06 18:20:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 145 @ 7056 updates
2022-03-06 18:20:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:20:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:20:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 145 @ 7056 updates, score 13.189) (writing took 2.5051571638323367 seconds)
2022-03-06 18:20:49 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2022-03-06 18:20:49 | INFO | train | epoch 145 | loss 2.711 | nll_loss 0.873 | ppl 1.83 | wps 23079.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7056 | lr 0.000376462 | gnorm 0.843 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19094
2022-03-06 18:20:49 | INFO | fairseq.trainer | begin training epoch 146
2022-03-06 18:20:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:22:47 | INFO | train_inner | epoch 146:     44 / 49 loss=2.707, nll_loss=0.869, ppl=1.83, wps=23107.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7100, lr=0.000375293, gnorm=0.835, loss_scale=16, train_wall=239, gb_free=8.8, wall=19212
2022-03-06 18:22:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:23:04 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 13.181 | nll_loss 12.421 | ppl 5485.39 | wps 40219.6 | wpb 510.9 | bsz 1 | num_updates 7105 | best_loss 8.937
2022-03-06 18:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 146 @ 7105 updates
2022-03-06 18:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:23:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 146 @ 7105 updates, score 13.181) (writing took 2.5334928589873016 seconds)
2022-03-06 18:23:07 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2022-03-06 18:23:07 | INFO | train | epoch 146 | loss 2.7 | nll_loss 0.862 | ppl 1.82 | wps 23105.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7105 | lr 0.000375161 | gnorm 0.829 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19232
2022-03-06 18:23:07 | INFO | fairseq.trainer | begin training epoch 147
2022-03-06 18:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:24:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:25:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:25:22 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 13.238 | nll_loss 12.488 | ppl 5744.44 | wps 39729.2 | wpb 510.9 | bsz 1 | num_updates 7153 | best_loss 8.937
2022-03-06 18:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 147 @ 7153 updates
2022-03-06 18:25:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:25:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 147 @ 7153 updates, score 13.238) (writing took 2.4971685842610896 seconds)
2022-03-06 18:25:25 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2022-03-06 18:25:25 | INFO | train | epoch 147 | loss 2.69 | nll_loss 0.852 | ppl 1.81 | wps 22634.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7153 | lr 0.0003739 | gnorm 0.826 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19369
2022-03-06 18:25:25 | INFO | fairseq.trainer | begin training epoch 148
2022-03-06 18:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:27:30 | INFO | train_inner | epoch 148:     47 / 49 loss=2.689, nll_loss=0.851, ppl=1.8, wps=22924.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7200, lr=0.000372678, gnorm=0.822, loss_scale=16, train_wall=241, gb_free=8.8, wall=19495
2022-03-06 18:27:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:27:39 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 13.133 | nll_loss 12.37 | ppl 5292.42 | wps 40342.2 | wpb 510.9 | bsz 1 | num_updates 7202 | best_loss 8.937
2022-03-06 18:27:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 148 @ 7202 updates
2022-03-06 18:27:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:27:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:27:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 148 @ 7202 updates, score 13.133) (writing took 2.34090122487396 seconds)
2022-03-06 18:27:42 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2022-03-06 18:27:42 | INFO | train | epoch 148 | loss 2.684 | nll_loss 0.846 | ppl 1.8 | wps 23147.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7202 | lr 0.000372626 | gnorm 0.811 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19507
2022-03-06 18:27:42 | INFO | fairseq.trainer | begin training epoch 149
2022-03-06 18:27:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:29:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:29:57 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 13.243 | nll_loss 12.501 | ppl 5797.54 | wps 40558.2 | wpb 510.9 | bsz 1 | num_updates 7251 | best_loss 8.937
2022-03-06 18:29:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 149 @ 7251 updates
2022-03-06 18:29:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:29:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:30:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 149 @ 7251 updates, score 13.243) (writing took 2.4367190590128303 seconds)
2022-03-06 18:30:00 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2022-03-06 18:30:00 | INFO | train | epoch 149 | loss 2.676 | nll_loss 0.837 | ppl 1.79 | wps 23083.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7251 | lr 0.000371365 | gnorm 0.807 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19644
2022-03-06 18:30:00 | INFO | fairseq.trainer | begin training epoch 150
2022-03-06 18:30:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:30:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:32:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:32:15 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 13.212 | nll_loss 12.459 | ppl 5631.49 | wps 40151.7 | wpb 510.9 | bsz 1 | num_updates 7299 | best_loss 8.937
2022-03-06 18:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 150 @ 7299 updates
2022-03-06 18:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 150 @ 7299 updates, score 13.212) (writing took 2.452141768299043 seconds)
2022-03-06 18:32:17 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2022-03-06 18:32:17 | INFO | train | epoch 150 | loss 2.666 | nll_loss 0.828 | ppl 1.78 | wps 22622.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7299 | lr 0.000370142 | gnorm 0.812 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19782
2022-03-06 18:32:17 | INFO | fairseq.trainer | begin training epoch 151
2022-03-06 18:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:32:20 | INFO | train_inner | epoch 151:      1 / 49 loss=2.671, nll_loss=0.833, ppl=1.78, wps=22260.8, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=7300, lr=0.000370117, gnorm=0.811, loss_scale=16, train_wall=240, gb_free=8.8, wall=19785
2022-03-06 18:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:34:32 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 13.156 | nll_loss 12.406 | ppl 5425.84 | wps 40338.2 | wpb 510.9 | bsz 1 | num_updates 7348 | best_loss 8.937
2022-03-06 18:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 151 @ 7348 updates
2022-03-06 18:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 151 @ 7348 updates, score 13.156) (writing took 2.5365856769494712 seconds)
2022-03-06 18:34:35 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)
2022-03-06 18:34:35 | INFO | train | epoch 151 | loss 2.658 | nll_loss 0.819 | ppl 1.76 | wps 23083.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7348 | lr 0.000368906 | gnorm 0.786 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 19920
2022-03-06 18:34:35 | INFO | fairseq.trainer | begin training epoch 152
2022-03-06 18:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:36:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:36:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:36:50 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 13.207 | nll_loss 12.456 | ppl 5617.62 | wps 39876.8 | wpb 510.9 | bsz 1 | num_updates 7396 | best_loss 8.937
2022-03-06 18:36:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 152 @ 7396 updates
2022-03-06 18:36:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:36:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:36:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 152 @ 7396 updates, score 13.207) (writing took 2.448260677047074 seconds)
2022-03-06 18:36:52 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)
2022-03-06 18:36:52 | INFO | train | epoch 152 | loss 2.652 | nll_loss 0.814 | ppl 1.76 | wps 22680.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7396 | lr 0.000367707 | gnorm 0.795 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20057
2022-03-06 18:36:52 | INFO | fairseq.trainer | begin training epoch 153
2022-03-06 18:36:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:37:03 | INFO | train_inner | epoch 153:      4 / 49 loss=2.654, nll_loss=0.816, ppl=1.76, wps=22933.9, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7400, lr=0.000367607, gnorm=0.791, loss_scale=16, train_wall=241, gb_free=8.8, wall=20068
2022-03-06 18:39:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:39:06 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 13.194 | nll_loss 12.452 | ppl 5602.62 | wps 40818.2 | wpb 510.9 | bsz 1 | num_updates 7445 | best_loss 8.937
2022-03-06 18:39:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 153 @ 7445 updates
2022-03-06 18:39:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 153 @ 7445 updates, score 13.194) (writing took 2.5234775100834668 seconds)
2022-03-06 18:39:09 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)
2022-03-06 18:39:09 | INFO | train | epoch 153 | loss 2.647 | nll_loss 0.809 | ppl 1.75 | wps 23266.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7445 | lr 0.000366495 | gnorm 0.799 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 20193
2022-03-06 18:39:09 | INFO | fairseq.trainer | begin training epoch 154
2022-03-06 18:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:41:23 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 13.15 | nll_loss 12.399 | ppl 5399.78 | wps 39639 | wpb 510.9 | bsz 1 | num_updates 7494 | best_loss 8.937
2022-03-06 18:41:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 154 @ 7494 updates
2022-03-06 18:41:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 154 @ 7494 updates, score 13.15) (writing took 2.5001387428492308 seconds)
2022-03-06 18:41:26 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)
2022-03-06 18:41:26 | INFO | train | epoch 154 | loss 2.638 | nll_loss 0.8 | ppl 1.74 | wps 23139.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7494 | lr 0.000365295 | gnorm 0.791 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20331
2022-03-06 18:41:26 | INFO | fairseq.trainer | begin training epoch 155
2022-03-06 18:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:41:42 | INFO | train_inner | epoch 155:      6 / 49 loss=2.641, nll_loss=0.803, ppl=1.75, wps=23227.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7500, lr=0.000365148, gnorm=0.794, loss_scale=16, train_wall=238, gb_free=8.8, wall=20347
2022-03-06 18:43:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:43:41 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 13.318 | nll_loss 12.593 | ppl 6176.65 | wps 40134.6 | wpb 510.9 | bsz 1 | num_updates 7542 | best_loss 8.937
2022-03-06 18:43:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 155 @ 7542 updates
2022-03-06 18:43:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:43:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:43:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 155 @ 7542 updates, score 13.318) (writing took 2.6435527210123837 seconds)
2022-03-06 18:43:43 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)
2022-03-06 18:43:43 | INFO | train | epoch 155 | loss 2.63 | nll_loss 0.792 | ppl 1.73 | wps 22672.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7542 | lr 0.00036413 | gnorm 0.785 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20468
2022-03-06 18:43:43 | INFO | fairseq.trainer | begin training epoch 156
2022-03-06 18:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:45:58 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 13.135 | nll_loss 12.38 | ppl 5330.1 | wps 40097 | wpb 510.9 | bsz 1 | num_updates 7591 | best_loss 8.937
2022-03-06 18:45:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 156 @ 7591 updates
2022-03-06 18:45:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:46:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:46:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 156 @ 7591 updates, score 13.135) (writing took 2.4284733599051833 seconds)
2022-03-06 18:46:00 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)
2022-03-06 18:46:00 | INFO | train | epoch 156 | loss 2.622 | nll_loss 0.783 | ppl 1.72 | wps 23193.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7591 | lr 0.000362953 | gnorm 0.776 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 20605
2022-03-06 18:46:00 | INFO | fairseq.trainer | begin training epoch 157
2022-03-06 18:46:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:46:24 | INFO | train_inner | epoch 157:      9 / 49 loss=2.624, nll_loss=0.785, ppl=1.72, wps=22987.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7600, lr=0.000362738, gnorm=0.78, loss_scale=16, train_wall=240, gb_free=8.8, wall=20629
2022-03-06 18:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:48:15 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 13.158 | nll_loss 12.413 | ppl 5454.07 | wps 40499.4 | wpb 510.9 | bsz 1 | num_updates 7640 | best_loss 8.937
2022-03-06 18:48:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 157 @ 7640 updates
2022-03-06 18:48:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 157 @ 7640 updates, score 13.158) (writing took 2.6195548488758504 seconds)
2022-03-06 18:48:18 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)
2022-03-06 18:48:18 | INFO | train | epoch 157 | loss 2.618 | nll_loss 0.78 | ppl 1.72 | wps 23133.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7640 | lr 0.000361787 | gnorm 0.772 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 20742
2022-03-06 18:48:18 | INFO | fairseq.trainer | begin training epoch 158
2022-03-06 18:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:50:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:50:32 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 13.274 | nll_loss 12.547 | ppl 5983.15 | wps 40664.2 | wpb 510.9 | bsz 1 | num_updates 7689 | best_loss 8.937
2022-03-06 18:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 158 @ 7689 updates
2022-03-06 18:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:50:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 158 @ 7689 updates, score 13.274) (writing took 2.52923217555508 seconds)
2022-03-06 18:50:35 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)
2022-03-06 18:50:35 | INFO | train | epoch 158 | loss 2.609 | nll_loss 0.771 | ppl 1.71 | wps 23209.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7689 | lr 0.000360633 | gnorm 0.75 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 20879
2022-03-06 18:50:35 | INFO | fairseq.trainer | begin training epoch 159
2022-03-06 18:50:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:51:04 | INFO | train_inner | epoch 159:     11 / 49 loss=2.612, nll_loss=0.774, ppl=1.71, wps=23194.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=7700, lr=0.000360375, gnorm=0.758, loss_scale=32, train_wall=238, gb_free=8.8, wall=20909
2022-03-06 18:51:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:52:49 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 13.218 | nll_loss 12.492 | ppl 5761.31 | wps 40148.7 | wpb 510.9 | bsz 1 | num_updates 7737 | best_loss 8.937
2022-03-06 18:52:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 159 @ 7737 updates
2022-03-06 18:52:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:52:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:52:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 159 @ 7737 updates, score 13.218) (writing took 2.4328280040062964 seconds)
2022-03-06 18:52:52 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)
2022-03-06 18:52:52 | INFO | train | epoch 159 | loss 2.605 | nll_loss 0.767 | ppl 1.7 | wps 22663.7 | ups 0.35 | wpb 64853.3 | bsz 126.7 | num_updates 7737 | lr 0.000359512 | gnorm 0.764 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21017
2022-03-06 18:52:52 | INFO | fairseq.trainer | begin training epoch 160
2022-03-06 18:52:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:55:07 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 13.223 | nll_loss 12.485 | ppl 5732.46 | wps 39949.4 | wpb 510.9 | bsz 1 | num_updates 7786 | best_loss 8.937
2022-03-06 18:55:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 160 @ 7786 updates
2022-03-06 18:55:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:55:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:55:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 160 @ 7786 updates, score 13.223) (writing took 2.5013346220366657 seconds)
2022-03-06 18:55:09 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)
2022-03-06 18:55:09 | INFO | train | epoch 160 | loss 2.6 | nll_loss 0.762 | ppl 1.7 | wps 23159.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7786 | lr 0.000358379 | gnorm 0.765 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21154
2022-03-06 18:55:09 | INFO | fairseq.trainer | begin training epoch 161
2022-03-06 18:55:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:55:47 | INFO | train_inner | epoch 161:     14 / 49 loss=2.601, nll_loss=0.763, ppl=1.7, wps=22955.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7800, lr=0.000358057, gnorm=0.765, loss_scale=16, train_wall=241, gb_free=8.8, wall=21191
2022-03-06 18:57:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 18:57:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:57:24 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 13.099 | nll_loss 12.357 | ppl 5244.38 | wps 40148.4 | wpb 510.9 | bsz 1 | num_updates 7834 | best_loss 8.937
2022-03-06 18:57:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 161 @ 7834 updates
2022-03-06 18:57:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:57:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:57:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 161 @ 7834 updates, score 13.099) (writing took 2.4914057361893356 seconds)
2022-03-06 18:57:26 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)
2022-03-06 18:57:26 | INFO | train | epoch 161 | loss 2.591 | nll_loss 0.753 | ppl 1.68 | wps 22678.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 7834 | lr 0.00035728 | gnorm 0.752 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21291
2022-03-06 18:57:26 | INFO | fairseq.trainer | begin training epoch 162
2022-03-06 18:57:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 18:59:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 18:59:41 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 13.29 | nll_loss 12.559 | ppl 6033.08 | wps 39592.5 | wpb 510.9 | bsz 1 | num_updates 7883 | best_loss 8.937
2022-03-06 18:59:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 162 @ 7883 updates
2022-03-06 18:59:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:59:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 18:59:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 162 @ 7883 updates, score 13.29) (writing took 2.46076267817989 seconds)
2022-03-06 18:59:44 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)
2022-03-06 18:59:44 | INFO | train | epoch 162 | loss 2.586 | nll_loss 0.749 | ppl 1.68 | wps 23148.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7883 | lr 0.000356167 | gnorm 0.748 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21428
2022-03-06 18:59:44 | INFO | fairseq.trainer | begin training epoch 163
2022-03-06 18:59:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:00:29 | INFO | train_inner | epoch 163:     17 / 49 loss=2.586, nll_loss=0.749, ppl=1.68, wps=22971.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=7900, lr=0.000355784, gnorm=0.743, loss_scale=16, train_wall=240, gb_free=8.8, wall=21474
2022-03-06 19:01:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:01:58 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 13.236 | nll_loss 12.508 | ppl 5825.5 | wps 40261.1 | wpb 510.9 | bsz 1 | num_updates 7932 | best_loss 8.937
2022-03-06 19:01:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 163 @ 7932 updates
2022-03-06 19:01:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:02:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 163 @ 7932 updates, score 13.236) (writing took 2.6018742099404335 seconds)
2022-03-06 19:02:01 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)
2022-03-06 19:02:01 | INFO | train | epoch 163 | loss 2.58 | nll_loss 0.742 | ppl 1.67 | wps 23131.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7932 | lr 0.000355066 | gnorm 0.74 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 21566
2022-03-06 19:02:01 | INFO | fairseq.trainer | begin training epoch 164
2022-03-06 19:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:04:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:04:14 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 13.267 | nll_loss 12.544 | ppl 5973.07 | wps 41393.2 | wpb 510.9 | bsz 1 | num_updates 7981 | best_loss 8.937
2022-03-06 19:04:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 164 @ 7981 updates
2022-03-06 19:04:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:04:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:04:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 164 @ 7981 updates, score 13.267) (writing took 2.4909618459641933 seconds)
2022-03-06 19:04:17 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)
2022-03-06 19:04:17 | INFO | train | epoch 164 | loss 2.575 | nll_loss 0.739 | ppl 1.67 | wps 23409.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 7981 | lr 0.000353974 | gnorm 0.764 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 21702
2022-03-06 19:04:17 | INFO | fairseq.trainer | begin training epoch 165
2022-03-06 19:04:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:05:07 | INFO | train_inner | epoch 165:     19 / 49 loss=2.575, nll_loss=0.738, ppl=1.67, wps=23354.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=8000, lr=0.000353553, gnorm=0.75, loss_scale=32, train_wall=236, gb_free=8.8, wall=21751
2022-03-06 19:06:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:06:29 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 13.187 | nll_loss 12.457 | ppl 5622.2 | wps 41437.2 | wpb 510.9 | bsz 1 | num_updates 8030 | best_loss 8.937
2022-03-06 19:06:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 165 @ 8030 updates
2022-03-06 19:06:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:06:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:06:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 165 @ 8030 updates, score 13.187) (writing took 2.4760741316713393 seconds)
2022-03-06 19:06:32 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)
2022-03-06 19:06:32 | INFO | train | epoch 165 | loss 2.567 | nll_loss 0.731 | ppl 1.66 | wps 23572.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8030 | lr 0.000352892 | gnorm 0.727 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 21836
2022-03-06 19:06:32 | INFO | fairseq.trainer | begin training epoch 166
2022-03-06 19:06:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:06:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:08:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:08:44 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 13.271 | nll_loss 12.545 | ppl 5975.8 | wps 42041.9 | wpb 510.9 | bsz 1 | num_updates 8078 | best_loss 8.937
2022-03-06 19:08:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 166 @ 8078 updates
2022-03-06 19:08:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 166 @ 8078 updates, score 13.271) (writing took 2.337867346126586 seconds)
2022-03-06 19:08:46 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)
2022-03-06 19:08:46 | INFO | train | epoch 166 | loss 2.561 | nll_loss 0.724 | ppl 1.65 | wps 23139.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 8078 | lr 0.000351842 | gnorm 0.738 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 21971
2022-03-06 19:08:46 | INFO | fairseq.trainer | begin training epoch 167
2022-03-06 19:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:09:44 | INFO | train_inner | epoch 167:     22 / 49 loss=2.562, nll_loss=0.725, ppl=1.65, wps=23415.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8100, lr=0.000351364, gnorm=0.734, loss_scale=16, train_wall=236, gb_free=8.8, wall=22029
2022-03-06 19:10:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:10:58 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 13.303 | nll_loss 12.587 | ppl 6153.72 | wps 41298.8 | wpb 510.9 | bsz 1 | num_updates 8127 | best_loss 8.937
2022-03-06 19:10:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 167 @ 8127 updates
2022-03-06 19:10:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:11:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:11:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 167 @ 8127 updates, score 13.303) (writing took 2.4432718181051314 seconds)
2022-03-06 19:11:01 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)
2022-03-06 19:11:01 | INFO | train | epoch 167 | loss 2.556 | nll_loss 0.72 | ppl 1.65 | wps 23577.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8127 | lr 0.00035078 | gnorm 0.727 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 22106
2022-03-06 19:11:01 | INFO | fairseq.trainer | begin training epoch 168
2022-03-06 19:11:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:13:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:13:13 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 13.316 | nll_loss 12.603 | ppl 6221.61 | wps 42066.4 | wpb 510.9 | bsz 1 | num_updates 8176 | best_loss 8.937
2022-03-06 19:13:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 168 @ 8176 updates
2022-03-06 19:13:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:13:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:13:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 168 @ 8176 updates, score 13.316) (writing took 2.501198995858431 seconds)
2022-03-06 19:13:15 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)
2022-03-06 19:13:15 | INFO | train | epoch 168 | loss 2.553 | nll_loss 0.717 | ppl 1.64 | wps 23637 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8176 | lr 0.000349727 | gnorm 0.735 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 22240
2022-03-06 19:13:15 | INFO | fairseq.trainer | begin training epoch 169
2022-03-06 19:13:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:13:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:14:21 | INFO | train_inner | epoch 169:     25 / 49 loss=2.551, nll_loss=0.715, ppl=1.64, wps=23410.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=8200, lr=0.000349215, gnorm=0.729, loss_scale=16, train_wall=236, gb_free=8.8, wall=22306
2022-03-06 19:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:15:28 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 13.232 | nll_loss 12.512 | ppl 5841.73 | wps 41054.2 | wpb 510.9 | bsz 1 | num_updates 8224 | best_loss 8.937
2022-03-06 19:15:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 169 @ 8224 updates
2022-03-06 19:15:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:15:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:15:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 169 @ 8224 updates, score 13.232) (writing took 2.377517190761864 seconds)
2022-03-06 19:15:30 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)
2022-03-06 19:15:30 | INFO | train | epoch 169 | loss 2.544 | nll_loss 0.708 | ppl 1.63 | wps 23099 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 8224 | lr 0.000348705 | gnorm 0.719 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 22375
2022-03-06 19:15:30 | INFO | fairseq.trainer | begin training epoch 170
2022-03-06 19:15:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:17:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:17:44 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 13.232 | nll_loss 12.51 | ppl 5832.35 | wps 40042.6 | wpb 510.9 | bsz 1 | num_updates 8273 | best_loss 8.937
2022-03-06 19:17:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 170 @ 8273 updates
2022-03-06 19:17:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 170 @ 8273 updates, score 13.232) (writing took 2.5167000368237495 seconds)
2022-03-06 19:17:46 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)
2022-03-06 19:17:46 | INFO | train | epoch 170 | loss 2.541 | nll_loss 0.706 | ppl 1.63 | wps 23322.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8273 | lr 0.000347671 | gnorm 0.731 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 22511
2022-03-06 19:17:46 | INFO | fairseq.trainer | begin training epoch 171
2022-03-06 19:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:18:59 | INFO | train_inner | epoch 171:     27 / 49 loss=2.541, nll_loss=0.705, ppl=1.63, wps=23368, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=8300, lr=0.000347105, gnorm=0.729, loss_scale=16, train_wall=236, gb_free=8.8, wall=22583
2022-03-06 19:19:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:19:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:20:01 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 13.199 | nll_loss 12.476 | ppl 5696.19 | wps 40217.9 | wpb 510.9 | bsz 1 | num_updates 8321 | best_loss 8.937
2022-03-06 19:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 171 @ 8321 updates
2022-03-06 19:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:20:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:20:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 171 @ 8321 updates, score 13.199) (writing took 2.4252853891812265 seconds)
2022-03-06 19:20:04 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)
2022-03-06 19:20:04 | INFO | train | epoch 171 | loss 2.538 | nll_loss 0.703 | ppl 1.63 | wps 22633.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8321 | lr 0.000346667 | gnorm 0.749 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22649
2022-03-06 19:20:04 | INFO | fairseq.trainer | begin training epoch 172
2022-03-06 19:20:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:22:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:22:19 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 13.16 | nll_loss 12.439 | ppl 5554.41 | wps 39816 | wpb 510.9 | bsz 1 | num_updates 8370 | best_loss 8.937
2022-03-06 19:22:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 172 @ 8370 updates
2022-03-06 19:22:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:22:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:22:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 172 @ 8370 updates, score 13.16) (writing took 2.5937273567542434 seconds)
2022-03-06 19:22:22 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)
2022-03-06 19:22:22 | INFO | train | epoch 172 | loss 2.531 | nll_loss 0.696 | ppl 1.62 | wps 23067.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8370 | lr 0.000345651 | gnorm 0.712 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22786
2022-03-06 19:22:22 | INFO | fairseq.trainer | begin training epoch 173
2022-03-06 19:22:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:23:42 | INFO | train_inner | epoch 173:     30 / 49 loss=2.531, nll_loss=0.696, ppl=1.62, wps=22891.7, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=8400, lr=0.000345033, gnorm=0.723, loss_scale=16, train_wall=241, gb_free=8.8, wall=22867
2022-03-06 19:24:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:24:37 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 13.228 | nll_loss 12.51 | ppl 5834.86 | wps 40150.8 | wpb 510.9 | bsz 1 | num_updates 8419 | best_loss 8.937
2022-03-06 19:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 173 @ 8419 updates
2022-03-06 19:24:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:24:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:24:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 173 @ 8419 updates, score 13.228) (writing took 2.4420378180220723 seconds)
2022-03-06 19:24:39 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)
2022-03-06 19:24:39 | INFO | train | epoch 173 | loss 2.525 | nll_loss 0.69 | ppl 1.61 | wps 23105.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8419 | lr 0.000344643 | gnorm 0.716 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 22924
2022-03-06 19:24:39 | INFO | fairseq.trainer | begin training epoch 174
2022-03-06 19:24:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:25:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:26:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:26:54 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 13.228 | nll_loss 12.508 | ppl 5824.6 | wps 39642 | wpb 510.9 | bsz 1 | num_updates 8467 | best_loss 8.937
2022-03-06 19:26:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 174 @ 8467 updates
2022-03-06 19:26:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:26:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:26:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 174 @ 8467 updates, score 13.228) (writing took 2.429899745155126 seconds)
2022-03-06 19:26:57 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)
2022-03-06 19:26:57 | INFO | train | epoch 174 | loss 2.52 | nll_loss 0.686 | ppl 1.61 | wps 22640.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8467 | lr 0.000343665 | gnorm 0.713 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23061
2022-03-06 19:26:57 | INFO | fairseq.trainer | begin training epoch 175
2022-03-06 19:26:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:28:25 | INFO | train_inner | epoch 175:     33 / 49 loss=2.52, nll_loss=0.685, ppl=1.61, wps=22908.2, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=8500, lr=0.000342997, gnorm=0.714, loss_scale=16, train_wall=241, gb_free=8.8, wall=23150
2022-03-06 19:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:29:12 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 13.271 | nll_loss 12.561 | ppl 6042.07 | wps 40301.3 | wpb 510.9 | bsz 1 | num_updates 8516 | best_loss 8.937
2022-03-06 19:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 175 @ 8516 updates
2022-03-06 19:29:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:29:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 175 @ 8516 updates, score 13.271) (writing took 2.589316195808351 seconds)
2022-03-06 19:29:15 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)
2022-03-06 19:29:15 | INFO | train | epoch 175 | loss 2.517 | nll_loss 0.682 | ppl 1.6 | wps 23056.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8516 | lr 0.000342675 | gnorm 0.717 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23199
2022-03-06 19:29:15 | INFO | fairseq.trainer | begin training epoch 176
2022-03-06 19:29:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:31:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:31:30 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 13.222 | nll_loss 12.509 | ppl 5829.37 | wps 40257 | wpb 510.9 | bsz 1 | num_updates 8565 | best_loss 8.937
2022-03-06 19:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 176 @ 8565 updates
2022-03-06 19:31:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:31:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 176 @ 8565 updates, score 13.222) (writing took 2.5570362112484872 seconds)
2022-03-06 19:31:32 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)
2022-03-06 19:31:32 | INFO | train | epoch 176 | loss 2.511 | nll_loss 0.677 | ppl 1.6 | wps 23093.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8565 | lr 0.000341693 | gnorm 0.707 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23337
2022-03-06 19:31:32 | INFO | fairseq.trainer | begin training epoch 177
2022-03-06 19:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:33:06 | INFO | train_inner | epoch 177:     35 / 49 loss=2.51, nll_loss=0.676, ppl=1.6, wps=23112, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8600, lr=0.000340997, gnorm=0.703, loss_scale=32, train_wall=239, gb_free=8.8, wall=23431
2022-03-06 19:33:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:33:47 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 13.18 | nll_loss 12.469 | ppl 5669.44 | wps 39909.8 | wpb 510.9 | bsz 1 | num_updates 8614 | best_loss 8.937
2022-03-06 19:33:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 177 @ 8614 updates
2022-03-06 19:33:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:33:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:33:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 177 @ 8614 updates, score 13.18) (writing took 2.4581826999783516 seconds)
2022-03-06 19:33:50 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)
2022-03-06 19:33:50 | INFO | train | epoch 177 | loss 2.505 | nll_loss 0.671 | ppl 1.59 | wps 23100.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8614 | lr 0.00034072 | gnorm 0.685 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 23474
2022-03-06 19:33:50 | INFO | fairseq.trainer | begin training epoch 178
2022-03-06 19:33:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:34:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:35:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:36:05 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 13.212 | nll_loss 12.496 | ppl 5777.51 | wps 40901.6 | wpb 510.9 | bsz 1 | num_updates 8662 | best_loss 8.937
2022-03-06 19:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 178 @ 8662 updates
2022-03-06 19:36:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:36:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:36:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 178 @ 8662 updates, score 13.212) (writing took 2.579082138836384 seconds)
2022-03-06 19:36:07 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)
2022-03-06 19:36:07 | INFO | train | epoch 178 | loss 2.502 | nll_loss 0.669 | ppl 1.59 | wps 22606 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 8662 | lr 0.000339775 | gnorm 0.689 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23612
2022-03-06 19:36:07 | INFO | fairseq.trainer | begin training epoch 179
2022-03-06 19:36:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:37:49 | INFO | train_inner | epoch 179:     38 / 49 loss=2.502, nll_loss=0.669, ppl=1.59, wps=22921.5, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=8700, lr=0.000339032, gnorm=0.694, loss_scale=16, train_wall=241, gb_free=8.8, wall=23714
2022-03-06 19:38:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:38:22 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 13.218 | nll_loss 12.511 | ppl 5838.4 | wps 39954.7 | wpb 510.9 | bsz 1 | num_updates 8711 | best_loss 8.937
2022-03-06 19:38:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 179 @ 8711 updates
2022-03-06 19:38:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:38:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:38:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 179 @ 8711 updates, score 13.218) (writing took 2.4766504550352693 seconds)
2022-03-06 19:38:25 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)
2022-03-06 19:38:25 | INFO | train | epoch 179 | loss 2.5 | nll_loss 0.667 | ppl 1.59 | wps 23157.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8711 | lr 0.000338818 | gnorm 0.704 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 23749
2022-03-06 19:38:25 | INFO | fairseq.trainer | begin training epoch 180
2022-03-06 19:38:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:40:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:40:39 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 13.193 | nll_loss 12.481 | ppl 5718.29 | wps 41252.9 | wpb 510.9 | bsz 1 | num_updates 8760 | best_loss 8.937
2022-03-06 19:40:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 180 @ 8760 updates
2022-03-06 19:40:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:40:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 180 @ 8760 updates, score 13.193) (writing took 2.5433848099783063 seconds)
2022-03-06 19:40:41 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)
2022-03-06 19:40:41 | INFO | train | epoch 180 | loss 2.494 | nll_loss 0.661 | ppl 1.58 | wps 23240.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8760 | lr 0.000337869 | gnorm 0.691 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 23886
2022-03-06 19:40:41 | INFO | fairseq.trainer | begin training epoch 181
2022-03-06 19:40:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:42:26 | INFO | train_inner | epoch 181:     40 / 49 loss=2.492, nll_loss=0.66, ppl=1.58, wps=23415.8, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=8800, lr=0.0003371, gnorm=0.69, loss_scale=32, train_wall=236, gb_free=8.8, wall=23991
2022-03-06 19:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:42:53 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 13.208 | nll_loss 12.498 | ppl 5784.9 | wps 42317.4 | wpb 510.9 | bsz 1 | num_updates 8809 | best_loss 8.937
2022-03-06 19:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 181 @ 8809 updates
2022-03-06 19:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:42:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 181 @ 8809 updates, score 13.208) (writing took 2.4608545191586018 seconds)
2022-03-06 19:42:56 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)
2022-03-06 19:42:56 | INFO | train | epoch 181 | loss 2.488 | nll_loss 0.656 | ppl 1.58 | wps 23686.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 8809 | lr 0.000336928 | gnorm 0.689 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 24020
2022-03-06 19:42:56 | INFO | fairseq.trainer | begin training epoch 182
2022-03-06 19:42:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:45:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:45:07 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 13.253 | nll_loss 12.544 | ppl 5971.5 | wps 41370 | wpb 510.9 | bsz 1 | num_updates 8858 | best_loss 8.937
2022-03-06 19:45:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 182 @ 8858 updates
2022-03-06 19:45:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:45:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:45:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 182 @ 8858 updates, score 13.253) (writing took 2.5094632329419255 seconds)
2022-03-06 19:45:10 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)
2022-03-06 19:45:10 | INFO | train | epoch 182 | loss 2.485 | nll_loss 0.652 | ppl 1.57 | wps 23688 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 8858 | lr 0.000335994 | gnorm 0.677 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 24154
2022-03-06 19:45:10 | INFO | fairseq.trainer | begin training epoch 183
2022-03-06 19:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:45:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:47:02 | INFO | train_inner | epoch 183:     43 / 49 loss=2.483, nll_loss=0.651, ppl=1.57, wps=23509.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=8900, lr=0.000335201, gnorm=0.676, loss_scale=16, train_wall=235, gb_free=8.8, wall=24266
2022-03-06 19:47:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:47:22 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 13.219 | nll_loss 12.513 | ppl 5844.06 | wps 41814.5 | wpb 510.9 | bsz 1 | num_updates 8906 | best_loss 8.937
2022-03-06 19:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 183 @ 8906 updates
2022-03-06 19:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:47:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:47:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 183 @ 8906 updates, score 13.219) (writing took 2.40140626905486 seconds)
2022-03-06 19:47:24 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)
2022-03-06 19:47:24 | INFO | train | epoch 183 | loss 2.479 | nll_loss 0.647 | ppl 1.57 | wps 23200.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 8906 | lr 0.000335088 | gnorm 0.665 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 24289
2022-03-06 19:47:24 | INFO | fairseq.trainer | begin training epoch 184
2022-03-06 19:47:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:49:36 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 13.248 | nll_loss 12.552 | ppl 6006.04 | wps 41368.7 | wpb 510.9 | bsz 1 | num_updates 8955 | best_loss 8.937
2022-03-06 19:49:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 184 @ 8955 updates
2022-03-06 19:49:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:49:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:49:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 184 @ 8955 updates, score 13.248) (writing took 2.338528325781226 seconds)
2022-03-06 19:49:39 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)
2022-03-06 19:49:39 | INFO | train | epoch 184 | loss 2.477 | nll_loss 0.646 | ppl 1.56 | wps 23594 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 8955 | lr 0.00033417 | gnorm 0.682 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 24423
2022-03-06 19:49:39 | INFO | fairseq.trainer | begin training epoch 185
2022-03-06 19:49:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:51:37 | INFO | train_inner | epoch 185:     45 / 49 loss=2.475, nll_loss=0.644, ppl=1.56, wps=23598.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9000, lr=0.000333333, gnorm=0.668, loss_scale=32, train_wall=234, gb_free=8.8, wall=24541
2022-03-06 19:51:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:51:51 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 13.153 | nll_loss 12.435 | ppl 5538.86 | wps 41665.4 | wpb 510.9 | bsz 1 | num_updates 9004 | best_loss 8.937
2022-03-06 19:51:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 185 @ 9004 updates
2022-03-06 19:51:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:51:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:51:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 185 @ 9004 updates, score 13.153) (writing took 2.4367804410867393 seconds)
2022-03-06 19:51:54 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)
2022-03-06 19:51:54 | INFO | train | epoch 185 | loss 2.472 | nll_loss 0.641 | ppl 1.56 | wps 23546.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9004 | lr 0.000333259 | gnorm 0.659 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 24558
2022-03-06 19:51:54 | INFO | fairseq.trainer | begin training epoch 186
2022-03-06 19:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:53:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 19:54:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:54:06 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 13.262 | nll_loss 12.561 | ppl 6042.13 | wps 39495.9 | wpb 510.9 | bsz 1 | num_updates 9052 | best_loss 8.937
2022-03-06 19:54:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 186 @ 9052 updates
2022-03-06 19:54:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:54:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:54:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 186 @ 9052 updates, score 13.262) (writing took 2.4485395662486553 seconds)
2022-03-06 19:54:09 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)
2022-03-06 19:54:09 | INFO | train | epoch 186 | loss 2.47 | nll_loss 0.64 | ppl 1.56 | wps 23055.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 9052 | lr 0.000332375 | gnorm 0.688 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 24693
2022-03-06 19:54:09 | INFO | fairseq.trainer | begin training epoch 187
2022-03-06 19:54:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:56:17 | INFO | train_inner | epoch 187:     48 / 49 loss=2.469, nll_loss=0.639, ppl=1.56, wps=23163.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9100, lr=0.000331497, gnorm=0.685, loss_scale=16, train_wall=239, gb_free=8.8, wall=24821
2022-03-06 19:56:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:56:24 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 13.213 | nll_loss 12.505 | ppl 5812.73 | wps 40229.1 | wpb 510.9 | bsz 1 | num_updates 9101 | best_loss 8.937
2022-03-06 19:56:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 187 @ 9101 updates
2022-03-06 19:56:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:56:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 187 @ 9101 updates, score 13.213) (writing took 2.5433963760733604 seconds)
2022-03-06 19:56:26 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)
2022-03-06 19:56:26 | INFO | train | epoch 187 | loss 2.466 | nll_loss 0.636 | ppl 1.55 | wps 23113.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9101 | lr 0.000331479 | gnorm 0.68 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 24831
2022-03-06 19:56:26 | INFO | fairseq.trainer | begin training epoch 188
2022-03-06 19:56:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 19:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 19:58:41 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 13.205 | nll_loss 12.495 | ppl 5771.85 | wps 40400.6 | wpb 510.9 | bsz 1 | num_updates 9150 | best_loss 8.937
2022-03-06 19:58:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 188 @ 9150 updates
2022-03-06 19:58:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:58:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 19:58:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 188 @ 9150 updates, score 13.205) (writing took 2.5700680520385504 seconds)
2022-03-06 19:58:44 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)
2022-03-06 19:58:44 | INFO | train | epoch 188 | loss 2.462 | nll_loss 0.632 | ppl 1.55 | wps 23057.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9150 | lr 0.00033059 | gnorm 0.68 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 24969
2022-03-06 19:58:44 | INFO | fairseq.trainer | begin training epoch 189
2022-03-06 19:58:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:00:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:00:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:00:59 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 13.154 | nll_loss 12.45 | ppl 5597.02 | wps 39812.6 | wpb 510.9 | bsz 1 | num_updates 9198 | best_loss 8.937
2022-03-06 20:00:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 189 @ 9198 updates
2022-03-06 20:00:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:01:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 189 @ 9198 updates, score 13.154) (writing took 2.445944942999631 seconds)
2022-03-06 20:01:02 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)
2022-03-06 20:01:02 | INFO | train | epoch 189 | loss 2.456 | nll_loss 0.626 | ppl 1.54 | wps 22615.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9198 | lr 0.000329726 | gnorm 0.669 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25106
2022-03-06 20:01:02 | INFO | fairseq.trainer | begin training epoch 190
2022-03-06 20:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:01:07 | INFO | train_inner | epoch 190:      2 / 49 loss=2.459, nll_loss=0.629, ppl=1.55, wps=22235.8, ups=0.34, wpb=64544.1, bsz=126.1, num_updates=9200, lr=0.00032969, gnorm=0.676, loss_scale=16, train_wall=240, gb_free=8.8, wall=25112
2022-03-06 20:03:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:03:17 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 13.308 | nll_loss 12.618 | ppl 6287.24 | wps 40297.7 | wpb 510.9 | bsz 1 | num_updates 9247 | best_loss 8.937
2022-03-06 20:03:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 190 @ 9247 updates
2022-03-06 20:03:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:03:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:03:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 190 @ 9247 updates, score 13.308) (writing took 2.5045272898860276 seconds)
2022-03-06 20:03:19 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)
2022-03-06 20:03:19 | INFO | train | epoch 190 | loss 2.453 | nll_loss 0.623 | ppl 1.54 | wps 23082.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9247 | lr 0.000328851 | gnorm 0.671 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25244
2022-03-06 20:03:19 | INFO | fairseq.trainer | begin training epoch 191
2022-03-06 20:03:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:05:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:05:34 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 13.214 | nll_loss 12.503 | ppl 5806.24 | wps 39962.4 | wpb 510.9 | bsz 1 | num_updates 9296 | best_loss 8.937
2022-03-06 20:05:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 191 @ 9296 updates
2022-03-06 20:05:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:05:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:05:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 191 @ 9296 updates, score 13.214) (writing took 2.4950600950978696 seconds)
2022-03-06 20:05:37 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)
2022-03-06 20:05:37 | INFO | train | epoch 191 | loss 2.45 | nll_loss 0.621 | ppl 1.54 | wps 23139.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9296 | lr 0.000327983 | gnorm 0.665 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25381
2022-03-06 20:05:37 | INFO | fairseq.trainer | begin training epoch 192
2022-03-06 20:05:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:05:47 | INFO | train_inner | epoch 192:      4 / 49 loss=2.451, nll_loss=0.621, ppl=1.54, wps=23143.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=9300, lr=0.000327913, gnorm=0.667, loss_scale=16, train_wall=239, gb_free=8.8, wall=25392
2022-03-06 20:07:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:07:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:07:52 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 13.196 | nll_loss 12.483 | ppl 5725.53 | wps 39972.2 | wpb 510.9 | bsz 1 | num_updates 9344 | best_loss 8.937
2022-03-06 20:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 192 @ 9344 updates
2022-03-06 20:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:07:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:07:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 192 @ 9344 updates, score 13.196) (writing took 2.496448695193976 seconds)
2022-03-06 20:07:54 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)
2022-03-06 20:07:54 | INFO | train | epoch 192 | loss 2.444 | nll_loss 0.614 | ppl 1.53 | wps 22635.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9344 | lr 0.00032714 | gnorm 0.654 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25519
2022-03-06 20:07:54 | INFO | fairseq.trainer | begin training epoch 193
2022-03-06 20:07:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:10:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:10:09 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 13.221 | nll_loss 12.522 | ppl 5881.02 | wps 40125.3 | wpb 510.9 | bsz 1 | num_updates 9393 | best_loss 8.937
2022-03-06 20:10:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 193 @ 9393 updates
2022-03-06 20:10:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:10:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 193 @ 9393 updates, score 13.221) (writing took 2.557505447883159 seconds)
2022-03-06 20:10:12 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)
2022-03-06 20:10:12 | INFO | train | epoch 193 | loss 2.442 | nll_loss 0.613 | ppl 1.53 | wps 23099.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9393 | lr 0.000326286 | gnorm 0.648 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25656
2022-03-06 20:10:12 | INFO | fairseq.trainer | begin training epoch 194
2022-03-06 20:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:10:30 | INFO | train_inner | epoch 194:      7 / 49 loss=2.442, nll_loss=0.613, ppl=1.53, wps=22916.1, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=9400, lr=0.000326164, gnorm=0.65, loss_scale=16, train_wall=241, gb_free=8.8, wall=25675
2022-03-06 20:12:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:12:26 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 13.262 | nll_loss 12.569 | ppl 6075.07 | wps 39735.2 | wpb 510.9 | bsz 1 | num_updates 9442 | best_loss 8.937
2022-03-06 20:12:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 194 @ 9442 updates
2022-03-06 20:12:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:12:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:12:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 194 @ 9442 updates, score 13.262) (writing took 2.399421805050224 seconds)
2022-03-06 20:12:29 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)
2022-03-06 20:12:29 | INFO | train | epoch 194 | loss 2.439 | nll_loss 0.611 | ppl 1.53 | wps 23161.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9442 | lr 0.000325438 | gnorm 0.656 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25794
2022-03-06 20:12:29 | INFO | fairseq.trainer | begin training epoch 195
2022-03-06 20:12:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:13:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:14:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:14:44 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 13.2 | nll_loss 12.504 | ppl 5810.43 | wps 40464.2 | wpb 510.9 | bsz 1 | num_updates 9490 | best_loss 8.937
2022-03-06 20:14:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 195 @ 9490 updates
2022-03-06 20:14:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:14:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 195 @ 9490 updates, score 13.2) (writing took 2.527409581001848 seconds)
2022-03-06 20:14:46 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)
2022-03-06 20:14:46 | INFO | train | epoch 195 | loss 2.434 | nll_loss 0.606 | ppl 1.52 | wps 22637.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 9490 | lr 0.000324614 | gnorm 0.646 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 25931
2022-03-06 20:14:46 | INFO | fairseq.trainer | begin training epoch 196
2022-03-06 20:14:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:15:13 | INFO | train_inner | epoch 196:     10 / 49 loss=2.436, nll_loss=0.608, ppl=1.52, wps=22949.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=9500, lr=0.000324443, gnorm=0.652, loss_scale=16, train_wall=241, gb_free=8.8, wall=25958
2022-03-06 20:16:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:17:01 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 13.215 | nll_loss 12.519 | ppl 5868.81 | wps 39595.3 | wpb 510.9 | bsz 1 | num_updates 9539 | best_loss 8.937
2022-03-06 20:17:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 196 @ 9539 updates
2022-03-06 20:17:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:17:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:17:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 196 @ 9539 updates, score 13.215) (writing took 2.433336399961263 seconds)
2022-03-06 20:17:03 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)
2022-03-06 20:17:03 | INFO | train | epoch 196 | loss 2.433 | nll_loss 0.605 | ppl 1.52 | wps 23187 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9539 | lr 0.000323779 | gnorm 0.65 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 26068
2022-03-06 20:17:03 | INFO | fairseq.trainer | begin training epoch 197
2022-03-06 20:17:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:19:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:19:17 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 13.159 | nll_loss 12.453 | ppl 5607.69 | wps 41136.5 | wpb 510.9 | bsz 1 | num_updates 9588 | best_loss 8.937
2022-03-06 20:19:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 197 @ 9588 updates
2022-03-06 20:19:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:19:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:19:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 197 @ 9588 updates, score 13.159) (writing took 2.486789226066321 seconds)
2022-03-06 20:19:19 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)
2022-03-06 20:19:19 | INFO | train | epoch 197 | loss 2.428 | nll_loss 0.6 | ppl 1.52 | wps 23412.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9588 | lr 0.000322951 | gnorm 0.631 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 26204
2022-03-06 20:19:19 | INFO | fairseq.trainer | begin training epoch 198
2022-03-06 20:19:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:19:51 | INFO | train_inner | epoch 198:     12 / 49 loss=2.429, nll_loss=0.601, ppl=1.52, wps=23365.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=9600, lr=0.000322749, gnorm=0.636, loss_scale=32, train_wall=236, gb_free=8.8, wall=26235
2022-03-06 20:21:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:21:32 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 13.286 | nll_loss 12.604 | ppl 6224.77 | wps 41175.6 | wpb 510.9 | bsz 1 | num_updates 9637 | best_loss 8.937
2022-03-06 20:21:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 198 @ 9637 updates
2022-03-06 20:21:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:21:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 198 @ 9637 updates, score 13.286) (writing took 2.5850285799242556 seconds)
2022-03-06 20:21:34 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)
2022-03-06 20:21:34 | INFO | train | epoch 198 | loss 2.425 | nll_loss 0.598 | ppl 1.51 | wps 23511 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9637 | lr 0.000322128 | gnorm 0.657 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 26339
2022-03-06 20:21:34 | INFO | fairseq.trainer | begin training epoch 199
2022-03-06 20:21:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:23:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:23:46 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 13.221 | nll_loss 12.525 | ppl 5893.45 | wps 41320.5 | wpb 510.9 | bsz 1 | num_updates 9686 | best_loss 8.937
2022-03-06 20:23:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 199 @ 9686 updates
2022-03-06 20:23:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:23:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:23:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 199 @ 9686 updates, score 13.221) (writing took 2.4548713746480644 seconds)
2022-03-06 20:23:49 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)
2022-03-06 20:23:49 | INFO | train | epoch 199 | loss 2.421 | nll_loss 0.595 | ppl 1.51 | wps 23609.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9686 | lr 0.000321313 | gnorm 0.637 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 26474
2022-03-06 20:23:49 | INFO | fairseq.trainer | begin training epoch 200
2022-03-06 20:23:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:24:26 | INFO | train_inner | epoch 200:     14 / 49 loss=2.422, nll_loss=0.596, ppl=1.51, wps=23590, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=9700, lr=0.000321081, gnorm=0.648, loss_scale=32, train_wall=234, gb_free=8.8, wall=26510
2022-03-06 20:25:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:25:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:26:01 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 13.287 | nll_loss 12.604 | ppl 6225.44 | wps 42442.7 | wpb 510.9 | bsz 1 | num_updates 9734 | best_loss 8.937
2022-03-06 20:26:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 200 @ 9734 updates
2022-03-06 20:26:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:26:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:26:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 200 @ 9734 updates, score 13.287) (writing took 2.4803388342261314 seconds)
2022-03-06 20:26:04 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)
2022-03-06 20:26:04 | INFO | train | epoch 200 | loss 2.418 | nll_loss 0.592 | ppl 1.51 | wps 23118.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 9734 | lr 0.000320519 | gnorm 0.633 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 26608
2022-03-06 20:26:04 | INFO | fairseq.trainer | begin training epoch 201
2022-03-06 20:26:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:28:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:28:16 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 13.262 | nll_loss 12.574 | ppl 6098.71 | wps 41197.8 | wpb 510.9 | bsz 1 | num_updates 9783 | best_loss 8.937
2022-03-06 20:28:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 201 @ 9783 updates
2022-03-06 20:28:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 201 @ 9783 updates, score 13.262) (writing took 2.4775896067731082 seconds)
2022-03-06 20:28:18 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)
2022-03-06 20:28:18 | INFO | train | epoch 201 | loss 2.415 | nll_loss 0.589 | ppl 1.5 | wps 23584.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9783 | lr 0.000319716 | gnorm 0.632 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 26743
2022-03-06 20:28:18 | INFO | fairseq.trainer | begin training epoch 202
2022-03-06 20:28:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:29:03 | INFO | train_inner | epoch 202:     17 / 49 loss=2.415, nll_loss=0.589, ppl=1.5, wps=23405.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=9800, lr=0.000319438, gnorm=0.632, loss_scale=32, train_wall=236, gb_free=8.8, wall=26788
2022-03-06 20:29:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:30:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:30:31 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 13.309 | nll_loss 12.631 | ppl 6345.41 | wps 41377.4 | wpb 510.9 | bsz 1 | num_updates 9831 | best_loss 8.937
2022-03-06 20:30:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 202 @ 9831 updates
2022-03-06 20:30:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:30:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:30:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 202 @ 9831 updates, score 13.309) (writing took 2.4436742262914777 seconds)
2022-03-06 20:30:33 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)
2022-03-06 20:30:33 | INFO | train | epoch 202 | loss 2.414 | nll_loss 0.588 | ppl 1.5 | wps 23071.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 9831 | lr 0.000318934 | gnorm 0.65 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 26878
2022-03-06 20:30:33 | INFO | fairseq.trainer | begin training epoch 203
2022-03-06 20:30:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:32:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:32:47 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 13.337 | nll_loss 12.654 | ppl 6447.22 | wps 39572.4 | wpb 510.9 | bsz 1 | num_updates 9880 | best_loss 8.937
2022-03-06 20:32:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 203 @ 9880 updates
2022-03-06 20:32:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:32:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:32:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 203 @ 9880 updates, score 13.337) (writing took 2.4310142938047647 seconds)
2022-03-06 20:32:49 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)
2022-03-06 20:32:49 | INFO | train | epoch 203 | loss 2.408 | nll_loss 0.583 | ppl 1.5 | wps 23331.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9880 | lr 0.000318142 | gnorm 0.632 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 27014
2022-03-06 20:32:49 | INFO | fairseq.trainer | begin training epoch 204
2022-03-06 20:32:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:33:43 | INFO | train_inner | epoch 204:     20 / 49 loss=2.41, nll_loss=0.584, ppl=1.5, wps=23147.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=9900, lr=0.000317821, gnorm=0.633, loss_scale=16, train_wall=239, gb_free=8.8, wall=27068
2022-03-06 20:34:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:35:05 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 13.255 | nll_loss 12.573 | ppl 6091.23 | wps 39824.8 | wpb 510.9 | bsz 1 | num_updates 9929 | best_loss 8.937
2022-03-06 20:35:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 204 @ 9929 updates
2022-03-06 20:35:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:35:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:35:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 204 @ 9929 updates, score 13.255) (writing took 2.467901297379285 seconds)
2022-03-06 20:35:07 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)
2022-03-06 20:35:07 | INFO | train | epoch 204 | loss 2.406 | nll_loss 0.581 | ppl 1.5 | wps 23075.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9929 | lr 0.000317356 | gnorm 0.616 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 27152
2022-03-06 20:35:07 | INFO | fairseq.trainer | begin training epoch 205
2022-03-06 20:35:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:37:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:37:22 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 13.293 | nll_loss 12.606 | ppl 6233.56 | wps 40193.8 | wpb 510.9 | bsz 1 | num_updates 9978 | best_loss 8.937
2022-03-06 20:37:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 205 @ 9978 updates
2022-03-06 20:37:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:37:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 205 @ 9978 updates, score 13.293) (writing took 2.4640493667684495 seconds)
2022-03-06 20:37:25 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)
2022-03-06 20:37:25 | INFO | train | epoch 205 | loss 2.403 | nll_loss 0.578 | ppl 1.49 | wps 23114.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 9978 | lr 0.000316576 | gnorm 0.625 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27289
2022-03-06 20:37:25 | INFO | fairseq.trainer | begin training epoch 206
2022-03-06 20:37:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:38:23 | INFO | train_inner | epoch 206:     22 / 49 loss=2.403, nll_loss=0.578, ppl=1.49, wps=23141.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=10000, lr=0.000316228, gnorm=0.627, loss_scale=32, train_wall=239, gb_free=8.8, wall=27348
2022-03-06 20:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:39:40 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 13.282 | nll_loss 12.596 | ppl 6192.58 | wps 39885.6 | wpb 510.9 | bsz 1 | num_updates 10027 | best_loss 8.937
2022-03-06 20:39:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 206 @ 10027 updates
2022-03-06 20:39:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:39:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 206 @ 10027 updates, score 13.282) (writing took 2.422035295981914 seconds)
2022-03-06 20:39:42 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)
2022-03-06 20:39:42 | INFO | train | epoch 206 | loss 2.4 | nll_loss 0.575 | ppl 1.49 | wps 23127.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10027 | lr 0.000315802 | gnorm 0.629 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27427
2022-03-06 20:39:42 | INFO | fairseq.trainer | begin training epoch 207
2022-03-06 20:39:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:41:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:41:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:41:57 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 13.182 | nll_loss 12.489 | ppl 5747.07 | wps 40405.1 | wpb 510.9 | bsz 1 | num_updates 10075 | best_loss 8.937
2022-03-06 20:41:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 207 @ 10075 updates
2022-03-06 20:41:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:42:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:42:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 207 @ 10075 updates, score 13.182) (writing took 2.5449933442287147 seconds)
2022-03-06 20:42:00 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)
2022-03-06 20:42:00 | INFO | train | epoch 207 | loss 2.396 | nll_loss 0.572 | ppl 1.49 | wps 22613.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10075 | lr 0.000315049 | gnorm 0.626 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27564
2022-03-06 20:42:00 | INFO | fairseq.trainer | begin training epoch 208
2022-03-06 20:42:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:43:07 | INFO | train_inner | epoch 208:     25 / 49 loss=2.397, nll_loss=0.573, ppl=1.49, wps=22914.3, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=10100, lr=0.000314658, gnorm=0.626, loss_scale=32, train_wall=241, gb_free=8.8, wall=27631
2022-03-06 20:44:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:44:15 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 13.28 | nll_loss 12.602 | ppl 6218.62 | wps 39463.2 | wpb 510.9 | bsz 1 | num_updates 10124 | best_loss 8.937
2022-03-06 20:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 208 @ 10124 updates
2022-03-06 20:44:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:44:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:44:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 208 @ 10124 updates, score 13.28) (writing took 2.4670513910241425 seconds)
2022-03-06 20:44:17 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)
2022-03-06 20:44:17 | INFO | train | epoch 208 | loss 2.396 | nll_loss 0.572 | ppl 1.49 | wps 23083.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10124 | lr 0.000314285 | gnorm 0.624 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27702
2022-03-06 20:44:17 | INFO | fairseq.trainer | begin training epoch 209
2022-03-06 20:44:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:46:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:46:32 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 13.273 | nll_loss 12.584 | ppl 6141.97 | wps 39917.5 | wpb 510.9 | bsz 1 | num_updates 10173 | best_loss 8.937
2022-03-06 20:46:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 209 @ 10173 updates
2022-03-06 20:46:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:46:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 209 @ 10173 updates, score 13.273) (writing took 2.5878993114456534 seconds)
2022-03-06 20:46:35 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)
2022-03-06 20:46:35 | INFO | train | epoch 209 | loss 2.392 | nll_loss 0.568 | ppl 1.48 | wps 23080 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10173 | lr 0.000313527 | gnorm 0.612 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27840
2022-03-06 20:46:35 | INFO | fairseq.trainer | begin training epoch 210
2022-03-06 20:46:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:47:47 | INFO | train_inner | epoch 210:     27 / 49 loss=2.391, nll_loss=0.568, ppl=1.48, wps=23111.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10200, lr=0.000313112, gnorm=0.611, loss_scale=64, train_wall=239, gb_free=8.8, wall=27912
2022-03-06 20:47:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:48:50 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 13.278 | nll_loss 12.591 | ppl 6170.61 | wps 40232.7 | wpb 510.9 | bsz 1 | num_updates 10221 | best_loss 8.937
2022-03-06 20:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 210 @ 10221 updates
2022-03-06 20:48:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:48:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:48:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 210 @ 10221 updates, score 13.278) (writing took 2.437625499907881 seconds)
2022-03-06 20:48:53 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)
2022-03-06 20:48:53 | INFO | train | epoch 210 | loss 2.388 | nll_loss 0.565 | ppl 1.48 | wps 22643.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10221 | lr 0.00031279 | gnorm 0.611 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 27977
2022-03-06 20:48:53 | INFO | fairseq.trainer | begin training epoch 211
2022-03-06 20:48:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:51:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:51:08 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 13.368 | nll_loss 12.692 | ppl 6616.51 | wps 39838 | wpb 510.9 | bsz 1 | num_updates 10270 | best_loss 8.937
2022-03-06 20:51:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 211 @ 10270 updates
2022-03-06 20:51:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:51:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:51:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 211 @ 10270 updates, score 13.368) (writing took 2.4115452761761844 seconds)
2022-03-06 20:51:10 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)
2022-03-06 20:51:10 | INFO | train | epoch 211 | loss 2.385 | nll_loss 0.562 | ppl 1.48 | wps 23094.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10270 | lr 0.000312043 | gnorm 0.606 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 28115
2022-03-06 20:51:10 | INFO | fairseq.trainer | begin training epoch 212
2022-03-06 20:51:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:52:30 | INFO | train_inner | epoch 212:     30 / 49 loss=2.386, nll_loss=0.563, ppl=1.48, wps=22916.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=10300, lr=0.000311588, gnorm=0.614, loss_scale=32, train_wall=241, gb_free=8.8, wall=28195
2022-03-06 20:53:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:53:25 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 13.28 | nll_loss 12.601 | ppl 6210.88 | wps 40821.8 | wpb 510.9 | bsz 1 | num_updates 10319 | best_loss 8.937
2022-03-06 20:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 212 @ 10319 updates
2022-03-06 20:53:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:53:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:53:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 212 @ 10319 updates, score 13.28) (writing took 2.62985966168344 seconds)
2022-03-06 20:53:28 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)
2022-03-06 20:53:28 | INFO | train | epoch 212 | loss 2.384 | nll_loss 0.561 | ppl 1.48 | wps 23107.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10319 | lr 0.000311301 | gnorm 0.62 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 28252
2022-03-06 20:53:28 | INFO | fairseq.trainer | begin training epoch 213
2022-03-06 20:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:53:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 20:55:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:55:42 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 13.301 | nll_loss 12.622 | ppl 6302.29 | wps 41379.3 | wpb 510.9 | bsz 1 | num_updates 10367 | best_loss 8.937
2022-03-06 20:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 213 @ 10367 updates
2022-03-06 20:55:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:55:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:55:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 213 @ 10367 updates, score 13.301) (writing took 2.4504914986900985 seconds)
2022-03-06 20:55:45 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)
2022-03-06 20:55:45 | INFO | train | epoch 213 | loss 2.381 | nll_loss 0.559 | ppl 1.47 | wps 22748 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10367 | lr 0.00031058 | gnorm 0.612 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 28389
2022-03-06 20:55:45 | INFO | fairseq.trainer | begin training epoch 214
2022-03-06 20:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 20:56:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 20:57:15 | INFO | train_inner | epoch 214:     34 / 49 loss=2.38, nll_loss=0.558, ppl=1.47, wps=22807.1, ups=0.35, wpb=64867.4, bsz=126.7, num_updates=10400, lr=0.000310087, gnorm=0.614, loss_scale=16, train_wall=242, gb_free=8.8, wall=28479
2022-03-06 20:57:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 20:57:59 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 13.328 | nll_loss 12.663 | ppl 6486.92 | wps 40043 | wpb 510.9 | bsz 1 | num_updates 10415 | best_loss 8.937
2022-03-06 20:57:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 214 @ 10415 updates
2022-03-06 20:57:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:58:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 20:58:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 214 @ 10415 updates, score 13.328) (writing took 2.490496793296188 seconds)
2022-03-06 20:58:01 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)
2022-03-06 20:58:01 | INFO | train | epoch 214 | loss 2.377 | nll_loss 0.555 | ppl 1.47 | wps 22751.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10415 | lr 0.000309863 | gnorm 0.607 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 28526
2022-03-06 20:58:01 | INFO | fairseq.trainer | begin training epoch 215
2022-03-06 20:58:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:00:16 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 13.247 | nll_loss 12.567 | ppl 6068.43 | wps 40667.2 | wpb 510.9 | bsz 1 | num_updates 10464 | best_loss 8.937
2022-03-06 21:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 215 @ 10464 updates
2022-03-06 21:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:00:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 215 @ 10464 updates, score 13.247) (writing took 2.5342738800682127 seconds)
2022-03-06 21:00:19 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)
2022-03-06 21:00:19 | INFO | train | epoch 215 | loss 2.376 | nll_loss 0.554 | ppl 1.47 | wps 23153.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10464 | lr 0.000309137 | gnorm 0.611 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 28663
2022-03-06 21:00:19 | INFO | fairseq.trainer | begin training epoch 216
2022-03-06 21:00:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:01:54 | INFO | train_inner | epoch 216:     36 / 49 loss=2.375, nll_loss=0.553, ppl=1.47, wps=23194.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10500, lr=0.000308607, gnorm=0.606, loss_scale=16, train_wall=238, gb_free=8.8, wall=28759
2022-03-06 21:02:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:02:33 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 13.257 | nll_loss 12.576 | ppl 6106.53 | wps 40145.2 | wpb 510.9 | bsz 1 | num_updates 10513 | best_loss 8.937
2022-03-06 21:02:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 216 @ 10513 updates
2022-03-06 21:02:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:02:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:02:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 216 @ 10513 updates, score 13.257) (writing took 2.5313139031641185 seconds)
2022-03-06 21:02:36 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)
2022-03-06 21:02:36 | INFO | train | epoch 216 | loss 2.372 | nll_loss 0.551 | ppl 1.47 | wps 23156.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10513 | lr 0.000308416 | gnorm 0.601 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 28801
2022-03-06 21:02:36 | INFO | fairseq.trainer | begin training epoch 217
2022-03-06 21:02:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:04:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:04:51 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 13.323 | nll_loss 12.648 | ppl 6420.05 | wps 39389 | wpb 510.9 | bsz 1 | num_updates 10562 | best_loss 8.937
2022-03-06 21:04:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 217 @ 10562 updates
2022-03-06 21:04:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:04:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:04:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 217 @ 10562 updates, score 13.323) (writing took 2.523293477948755 seconds)
2022-03-06 21:04:53 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)
2022-03-06 21:04:53 | INFO | train | epoch 217 | loss 2.369 | nll_loss 0.548 | ppl 1.46 | wps 23132.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10562 | lr 0.0003077 | gnorm 0.605 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 28938
2022-03-06 21:04:53 | INFO | fairseq.trainer | begin training epoch 218
2022-03-06 21:04:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:06:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:06:37 | INFO | train_inner | epoch 218:     39 / 49 loss=2.368, nll_loss=0.548, ppl=1.46, wps=22952.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=10600, lr=0.000307148, gnorm=0.602, loss_scale=16, train_wall=241, gb_free=8.8, wall=29042
2022-03-06 21:07:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:07:08 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 13.308 | nll_loss 12.631 | ppl 6344.97 | wps 40374.6 | wpb 510.9 | bsz 1 | num_updates 10610 | best_loss 8.937
2022-03-06 21:07:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 218 @ 10610 updates
2022-03-06 21:07:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:07:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 218 @ 10610 updates, score 13.308) (writing took 2.495500607881695 seconds)
2022-03-06 21:07:10 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)
2022-03-06 21:07:10 | INFO | train | epoch 218 | loss 2.367 | nll_loss 0.547 | ppl 1.46 | wps 22725.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10610 | lr 0.000307003 | gnorm 0.61 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29075
2022-03-06 21:07:10 | INFO | fairseq.trainer | begin training epoch 219
2022-03-06 21:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:09:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:09:25 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 13.25 | nll_loss 12.578 | ppl 6114.47 | wps 40122.7 | wpb 510.9 | bsz 1 | num_updates 10659 | best_loss 8.937
2022-03-06 21:09:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 219 @ 10659 updates
2022-03-06 21:09:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:09:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 219 @ 10659 updates, score 13.25) (writing took 2.4003440742380917 seconds)
2022-03-06 21:09:27 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)
2022-03-06 21:09:27 | INFO | train | epoch 219 | loss 2.365 | nll_loss 0.544 | ppl 1.46 | wps 23206.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10659 | lr 0.000306296 | gnorm 0.595 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29212
2022-03-06 21:09:27 | INFO | fairseq.trainer | begin training epoch 220
2022-03-06 21:09:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:11:16 | INFO | train_inner | epoch 220:     41 / 49 loss=2.365, nll_loss=0.544, ppl=1.46, wps=23232.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10700, lr=0.000305709, gnorm=0.599, loss_scale=16, train_wall=238, gb_free=8.8, wall=29321
2022-03-06 21:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:11:42 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 13.269 | nll_loss 12.594 | ppl 6181.06 | wps 40580.2 | wpb 510.9 | bsz 1 | num_updates 10708 | best_loss 8.937
2022-03-06 21:11:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 220 @ 10708 updates
2022-03-06 21:11:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 220 @ 10708 updates, score 13.269) (writing took 2.4490252947434783 seconds)
2022-03-06 21:11:44 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)
2022-03-06 21:11:44 | INFO | train | epoch 220 | loss 2.362 | nll_loss 0.542 | ppl 1.46 | wps 23199.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10708 | lr 0.000305595 | gnorm 0.593 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29349
2022-03-06 21:11:44 | INFO | fairseq.trainer | begin training epoch 221
2022-03-06 21:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:13:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:13:59 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 13.25 | nll_loss 12.57 | ppl 6080.27 | wps 40352 | wpb 510.9 | bsz 1 | num_updates 10757 | best_loss 8.937
2022-03-06 21:13:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 221 @ 10757 updates
2022-03-06 21:13:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:14:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 221 @ 10757 updates, score 13.25) (writing took 2.462326080072671 seconds)
2022-03-06 21:14:01 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)
2022-03-06 21:14:01 | INFO | train | epoch 221 | loss 2.361 | nll_loss 0.541 | ppl 1.46 | wps 23171.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10757 | lr 0.000304898 | gnorm 0.596 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 29486
2022-03-06 21:14:01 | INFO | fairseq.trainer | begin training epoch 222
2022-03-06 21:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:15:56 | INFO | train_inner | epoch 222:     43 / 49 loss=2.36, nll_loss=0.54, ppl=1.45, wps=23204.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10800, lr=0.00030429, gnorm=0.594, loss_scale=32, train_wall=238, gb_free=8.8, wall=29601
2022-03-06 21:16:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:16:16 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 13.237 | nll_loss 12.563 | ppl 6052.49 | wps 40096.5 | wpb 510.9 | bsz 1 | num_updates 10806 | best_loss 8.937
2022-03-06 21:16:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 222 @ 10806 updates
2022-03-06 21:16:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:16:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:16:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 222 @ 10806 updates, score 13.237) (writing took 2.53260928299278 seconds)
2022-03-06 21:16:19 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)
2022-03-06 21:16:19 | INFO | train | epoch 222 | loss 2.358 | nll_loss 0.539 | ppl 1.45 | wps 23146 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10806 | lr 0.000304206 | gnorm 0.591 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 29623
2022-03-06 21:16:19 | INFO | fairseq.trainer | begin training epoch 223
2022-03-06 21:16:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:17:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:18:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:18:33 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 13.177 | nll_loss 12.495 | ppl 5771.78 | wps 40310.9 | wpb 510.9 | bsz 1 | num_updates 10854 | best_loss 8.937
2022-03-06 21:18:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 223 @ 10854 updates
2022-03-06 21:18:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:18:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 223 @ 10854 updates, score 13.177) (writing took 2.4464643439278007 seconds)
2022-03-06 21:18:35 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)
2022-03-06 21:18:35 | INFO | train | epoch 223 | loss 2.356 | nll_loss 0.536 | ppl 1.45 | wps 22736.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 10854 | lr 0.000303532 | gnorm 0.6 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29760
2022-03-06 21:18:35 | INFO | fairseq.trainer | begin training epoch 224
2022-03-06 21:18:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:20:38 | INFO | train_inner | epoch 224:     46 / 49 loss=2.355, nll_loss=0.536, ppl=1.45, wps=23030.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=10900, lr=0.000302891, gnorm=0.594, loss_scale=16, train_wall=240, gb_free=8.8, wall=29882
2022-03-06 21:20:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:20:50 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 13.28 | nll_loss 12.607 | ppl 6237.9 | wps 40120.3 | wpb 510.9 | bsz 1 | num_updates 10903 | best_loss 8.937
2022-03-06 21:20:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 224 @ 10903 updates
2022-03-06 21:20:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:20:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:20:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 224 @ 10903 updates, score 13.28) (writing took 2.441919006872922 seconds)
2022-03-06 21:20:52 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)
2022-03-06 21:20:52 | INFO | train | epoch 224 | loss 2.352 | nll_loss 0.534 | ppl 1.45 | wps 23261.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10903 | lr 0.00030285 | gnorm 0.588 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 29897
2022-03-06 21:20:52 | INFO | fairseq.trainer | begin training epoch 225
2022-03-06 21:20:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:22:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:23:04 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 13.269 | nll_loss 12.594 | ppl 6181.05 | wps 42543.4 | wpb 510.9 | bsz 1 | num_updates 10952 | best_loss 8.937
2022-03-06 21:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 225 @ 10952 updates
2022-03-06 21:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:23:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:23:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 225 @ 10952 updates, score 13.269) (writing took 2.461163796018809 seconds)
2022-03-06 21:23:07 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)
2022-03-06 21:23:07 | INFO | train | epoch 225 | loss 2.351 | nll_loss 0.532 | ppl 1.45 | wps 23634 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 10952 | lr 0.000302171 | gnorm 0.598 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 30031
2022-03-06 21:23:07 | INFO | fairseq.trainer | begin training epoch 226
2022-03-06 21:23:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:25:11 | INFO | train_inner | epoch 226:     48 / 49 loss=2.35, nll_loss=0.531, ppl=1.45, wps=23685.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=11000, lr=0.000301511, gnorm=0.593, loss_scale=32, train_wall=233, gb_free=8.8, wall=30156
2022-03-06 21:25:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:25:18 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 13.223 | nll_loss 12.542 | ppl 5962.97 | wps 41547.9 | wpb 510.9 | bsz 1 | num_updates 11001 | best_loss 8.937
2022-03-06 21:25:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 226 @ 11001 updates
2022-03-06 21:25:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:25:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:25:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 226 @ 11001 updates, score 13.223) (writing took 2.4633480911143124 seconds)
2022-03-06 21:25:20 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)
2022-03-06 21:25:20 | INFO | train | epoch 226 | loss 2.348 | nll_loss 0.53 | ppl 1.44 | wps 23726.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11001 | lr 0.000301498 | gnorm 0.588 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 30165
2022-03-06 21:25:21 | INFO | fairseq.trainer | begin training epoch 227
2022-03-06 21:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:27:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:27:33 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 13.252 | nll_loss 12.578 | ppl 6115.46 | wps 41953.1 | wpb 510.9 | bsz 1 | num_updates 11050 | best_loss 8.937
2022-03-06 21:27:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 227 @ 11050 updates
2022-03-06 21:27:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:27:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 227 @ 11050 updates, score 13.252) (writing took 2.5317742098122835 seconds)
2022-03-06 21:27:35 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)
2022-03-06 21:27:35 | INFO | train | epoch 227 | loss 2.345 | nll_loss 0.527 | ppl 1.44 | wps 23584.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11050 | lr 0.000300828 | gnorm 0.577 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 30300
2022-03-06 21:27:35 | INFO | fairseq.trainer | begin training epoch 228
2022-03-06 21:27:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:29:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:29:48 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 13.188 | nll_loss 12.507 | ppl 5820.99 | wps 41247.8 | wpb 510.9 | bsz 1 | num_updates 11098 | best_loss 8.937
2022-03-06 21:29:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 228 @ 11098 updates
2022-03-06 21:29:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:29:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:29:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 228 @ 11098 updates, score 13.188) (writing took 2.3836492807604373 seconds)
2022-03-06 21:29:50 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)
2022-03-06 21:29:50 | INFO | train | epoch 228 | loss 2.343 | nll_loss 0.525 | ppl 1.44 | wps 23113.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 11098 | lr 0.000300177 | gnorm 0.582 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 30435
2022-03-06 21:29:50 | INFO | fairseq.trainer | begin training epoch 229
2022-03-06 21:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:29:55 | INFO | train_inner | epoch 229:      2 / 49 loss=2.344, nll_loss=0.526, ppl=1.44, wps=22735.3, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=11100, lr=0.00030015, gnorm=0.582, loss_scale=32, train_wall=235, gb_free=8.8, wall=30440
2022-03-06 21:31:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:32:02 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 13.269 | nll_loss 12.601 | ppl 6213.17 | wps 41779.2 | wpb 510.9 | bsz 1 | num_updates 11147 | best_loss 8.937
2022-03-06 21:32:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 229 @ 11147 updates
2022-03-06 21:32:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:32:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:32:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 229 @ 11147 updates, score 13.269) (writing took 2.5659891329705715 seconds)
2022-03-06 21:32:05 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)
2022-03-06 21:32:05 | INFO | train | epoch 229 | loss 2.342 | nll_loss 0.525 | ppl 1.44 | wps 23566.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11147 | lr 0.000299517 | gnorm 0.588 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 30570
2022-03-06 21:32:05 | INFO | fairseq.trainer | begin training epoch 230
2022-03-06 21:32:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:34:17 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 13.287 | nll_loss 12.62 | ppl 6294 | wps 42014 | wpb 510.9 | bsz 1 | num_updates 11196 | best_loss 8.937
2022-03-06 21:34:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 230 @ 11196 updates
2022-03-06 21:34:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 230 @ 11196 updates, score 13.287) (writing took 2.3740361989475787 seconds)
2022-03-06 21:34:19 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)
2022-03-06 21:34:19 | INFO | train | epoch 230 | loss 2.339 | nll_loss 0.522 | ppl 1.44 | wps 23597.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11196 | lr 0.000298861 | gnorm 0.578 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 30704
2022-03-06 21:34:19 | INFO | fairseq.trainer | begin training epoch 231
2022-03-06 21:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:34:30 | INFO | train_inner | epoch 231:      4 / 49 loss=2.34, nll_loss=0.523, ppl=1.44, wps=23601.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11200, lr=0.000298807, gnorm=0.582, loss_scale=32, train_wall=234, gb_free=8.8, wall=30715
2022-03-06 21:35:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 21:36:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:36:34 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 13.269 | nll_loss 12.6 | ppl 6209.4 | wps 39788.6 | wpb 510.9 | bsz 1 | num_updates 11244 | best_loss 8.937
2022-03-06 21:36:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 231 @ 11244 updates
2022-03-06 21:36:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:36:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:36:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 231 @ 11244 updates, score 13.269) (writing took 2.531671468168497 seconds)
2022-03-06 21:36:37 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)
2022-03-06 21:36:37 | INFO | train | epoch 231 | loss 2.337 | nll_loss 0.52 | ppl 1.43 | wps 22649.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 11244 | lr 0.000298222 | gnorm 0.582 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 30842
2022-03-06 21:36:37 | INFO | fairseq.trainer | begin training epoch 232
2022-03-06 21:36:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:38:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:38:52 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 13.276 | nll_loss 12.602 | ppl 6217.98 | wps 40607.6 | wpb 510.9 | bsz 1 | num_updates 11293 | best_loss 8.937
2022-03-06 21:38:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 232 @ 11293 updates
2022-03-06 21:38:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:38:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:38:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 232 @ 11293 updates, score 13.276) (writing took 2.565891945268959 seconds)
2022-03-06 21:38:54 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)
2022-03-06 21:38:54 | INFO | train | epoch 232 | loss 2.334 | nll_loss 0.518 | ppl 1.43 | wps 23120.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11293 | lr 0.000297574 | gnorm 0.562 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 30979
2022-03-06 21:38:54 | INFO | fairseq.trainer | begin training epoch 233
2022-03-06 21:38:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:39:13 | INFO | train_inner | epoch 233:      7 / 49 loss=2.335, nll_loss=0.519, ppl=1.43, wps=22932.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=11300, lr=0.000297482, gnorm=0.575, loss_scale=16, train_wall=241, gb_free=8.8, wall=30998
2022-03-06 21:41:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:41:09 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 13.348 | nll_loss 12.681 | ppl 6566.01 | wps 39837 | wpb 510.9 | bsz 1 | num_updates 11342 | best_loss 8.937
2022-03-06 21:41:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 233 @ 11342 updates
2022-03-06 21:41:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:41:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:41:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 233 @ 11342 updates, score 13.348) (writing took 2.5868075862526894 seconds)
2022-03-06 21:41:12 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)
2022-03-06 21:41:12 | INFO | train | epoch 233 | loss 2.333 | nll_loss 0.516 | ppl 1.43 | wps 23097.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11342 | lr 0.000296931 | gnorm 0.584 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 31117
2022-03-06 21:41:12 | INFO | fairseq.trainer | begin training epoch 234
2022-03-06 21:41:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:43:27 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 13.274 | nll_loss 12.61 | ppl 6250.1 | wps 40621.3 | wpb 510.9 | bsz 1 | num_updates 11391 | best_loss 8.937
2022-03-06 21:43:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 234 @ 11391 updates
2022-03-06 21:43:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:43:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 234 @ 11391 updates, score 13.274) (writing took 2.5467607122845948 seconds)
2022-03-06 21:43:29 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)
2022-03-06 21:43:29 | INFO | train | epoch 234 | loss 2.331 | nll_loss 0.515 | ppl 1.43 | wps 23113.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11391 | lr 0.000296291 | gnorm 0.576 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31254
2022-03-06 21:43:29 | INFO | fairseq.trainer | begin training epoch 235
2022-03-06 21:43:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:43:53 | INFO | train_inner | epoch 235:      9 / 49 loss=2.331, nll_loss=0.515, ppl=1.43, wps=23137.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11400, lr=0.000296174, gnorm=0.575, loss_scale=32, train_wall=239, gb_free=8.8, wall=31278
2022-03-06 21:45:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:45:44 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 13.205 | nll_loss 12.527 | ppl 5901.86 | wps 40741.4 | wpb 510.9 | bsz 1 | num_updates 11440 | best_loss 8.937
2022-03-06 21:45:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 235 @ 11440 updates
2022-03-06 21:45:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:45:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 235 @ 11440 updates, score 13.205) (writing took 2.5227295332588255 seconds)
2022-03-06 21:45:47 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)
2022-03-06 21:45:47 | INFO | train | epoch 235 | loss 2.328 | nll_loss 0.512 | ppl 1.43 | wps 23155.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11440 | lr 0.000295656 | gnorm 0.564 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31391
2022-03-06 21:45:47 | INFO | fairseq.trainer | begin training epoch 236
2022-03-06 21:45:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:47:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:47:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:48:02 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 13.351 | nll_loss 12.696 | ppl 6634 | wps 39712.3 | wpb 510.9 | bsz 1 | num_updates 11488 | best_loss 8.937
2022-03-06 21:48:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 236 @ 11488 updates
2022-03-06 21:48:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:48:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:48:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 236 @ 11488 updates, score 13.351) (writing took 2.523560786154121 seconds)
2022-03-06 21:48:04 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)
2022-03-06 21:48:04 | INFO | train | epoch 236 | loss 2.326 | nll_loss 0.511 | ppl 1.42 | wps 22597.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 11488 | lr 0.000295038 | gnorm 0.572 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31529
2022-03-06 21:48:04 | INFO | fairseq.trainer | begin training epoch 237
2022-03-06 21:48:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:48:37 | INFO | train_inner | epoch 237:     12 / 49 loss=2.327, nll_loss=0.511, ppl=1.43, wps=22912.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=11500, lr=0.000294884, gnorm=0.571, loss_scale=32, train_wall=241, gb_free=8.8, wall=31561
2022-03-06 21:50:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:50:20 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 13.232 | nll_loss 12.559 | ppl 6036.31 | wps 39636 | wpb 510.9 | bsz 1 | num_updates 11537 | best_loss 8.937
2022-03-06 21:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 237 @ 11537 updates
2022-03-06 21:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 237 @ 11537 updates, score 13.232) (writing took 2.521681087091565 seconds)
2022-03-06 21:50:22 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)
2022-03-06 21:50:22 | INFO | train | epoch 237 | loss 2.323 | nll_loss 0.508 | ppl 1.42 | wps 23064.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11537 | lr 0.000294411 | gnorm 0.566 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31667
2022-03-06 21:50:22 | INFO | fairseq.trainer | begin training epoch 238
2022-03-06 21:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:52:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:52:37 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 13.299 | nll_loss 12.637 | ppl 6369.69 | wps 39926.9 | wpb 510.9 | bsz 1 | num_updates 11586 | best_loss 8.937
2022-03-06 21:52:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 238 @ 11586 updates
2022-03-06 21:52:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:52:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 238 @ 11586 updates, score 13.299) (writing took 2.5547994850203395 seconds)
2022-03-06 21:52:40 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)
2022-03-06 21:52:40 | INFO | train | epoch 238 | loss 2.321 | nll_loss 0.506 | ppl 1.42 | wps 23109.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11586 | lr 0.000293787 | gnorm 0.557 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31804
2022-03-06 21:52:40 | INFO | fairseq.trainer | begin training epoch 239
2022-03-06 21:52:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:53:17 | INFO | train_inner | epoch 239:     14 / 49 loss=2.321, nll_loss=0.506, ppl=1.42, wps=23131.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11600, lr=0.00029361, gnorm=0.557, loss_scale=32, train_wall=238, gb_free=8.8, wall=31842
2022-03-06 21:53:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 21:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:54:55 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 13.224 | nll_loss 12.552 | ppl 6006.72 | wps 39872.5 | wpb 510.9 | bsz 1 | num_updates 11634 | best_loss 8.937
2022-03-06 21:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 239 @ 11634 updates
2022-03-06 21:54:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:54:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:54:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 239 @ 11634 updates, score 13.224) (writing took 2.5498502450063825 seconds)
2022-03-06 21:54:57 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)
2022-03-06 21:54:57 | INFO | train | epoch 239 | loss 2.321 | nll_loss 0.506 | ppl 1.42 | wps 22660.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 11634 | lr 0.000293181 | gnorm 0.565 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 31942
2022-03-06 21:54:57 | INFO | fairseq.trainer | begin training epoch 240
2022-03-06 21:54:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:57:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:57:12 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 13.286 | nll_loss 12.622 | ppl 6303.31 | wps 40197.6 | wpb 510.9 | bsz 1 | num_updates 11683 | best_loss 8.937
2022-03-06 21:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 240 @ 11683 updates
2022-03-06 21:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:57:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 240 @ 11683 updates, score 13.286) (writing took 2.4021113980561495 seconds)
2022-03-06 21:57:14 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)
2022-03-06 21:57:14 | INFO | train | epoch 240 | loss 2.319 | nll_loss 0.505 | ppl 1.42 | wps 23172.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11683 | lr 0.000292565 | gnorm 0.567 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 32079
2022-03-06 21:57:14 | INFO | fairseq.trainer | begin training epoch 241
2022-03-06 21:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:58:00 | INFO | train_inner | epoch 241:     17 / 49 loss=2.319, nll_loss=0.505, ppl=1.42, wps=22956.8, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=11700, lr=0.000292353, gnorm=0.567, loss_scale=32, train_wall=241, gb_free=8.8, wall=32124
2022-03-06 21:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 21:59:28 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 13.278 | nll_loss 12.611 | ppl 6255.98 | wps 41017.6 | wpb 510.9 | bsz 1 | num_updates 11732 | best_loss 8.937
2022-03-06 21:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 241 @ 11732 updates
2022-03-06 21:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:59:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 21:59:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 241 @ 11732 updates, score 13.278) (writing took 2.45065725594759 seconds)
2022-03-06 21:59:30 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)
2022-03-06 21:59:30 | INFO | train | epoch 241 | loss 2.317 | nll_loss 0.503 | ppl 1.42 | wps 23398.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11732 | lr 0.000291954 | gnorm 0.559 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 32215
2022-03-06 21:59:30 | INFO | fairseq.trainer | begin training epoch 242
2022-03-06 21:59:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 21:59:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:01:42 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 13.225 | nll_loss 12.558 | ppl 6030.14 | wps 41584.5 | wpb 510.9 | bsz 1 | num_updates 11780 | best_loss 8.937
2022-03-06 22:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 242 @ 11780 updates
2022-03-06 22:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:01:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:01:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 242 @ 11780 updates, score 13.225) (writing took 2.467994042672217 seconds)
2022-03-06 22:01:45 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)
2022-03-06 22:01:45 | INFO | train | epoch 242 | loss 2.314 | nll_loss 0.501 | ppl 1.42 | wps 23084.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 11780 | lr 0.000291358 | gnorm 0.564 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 32350
2022-03-06 22:01:45 | INFO | fairseq.trainer | begin training epoch 243
2022-03-06 22:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:02:37 | INFO | train_inner | epoch 243:     20 / 49 loss=2.314, nll_loss=0.501, ppl=1.42, wps=23369.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=11800, lr=0.000291111, gnorm=0.559, loss_scale=32, train_wall=236, gb_free=8.8, wall=32402
2022-03-06 22:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:03:57 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 13.233 | nll_loss 12.568 | ppl 6073.67 | wps 42688.6 | wpb 510.9 | bsz 1 | num_updates 11829 | best_loss 8.937
2022-03-06 22:03:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 243 @ 11829 updates
2022-03-06 22:03:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:03:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:03:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 243 @ 11829 updates, score 13.233) (writing took 2.3430448309518397 seconds)
2022-03-06 22:03:59 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)
2022-03-06 22:03:59 | INFO | train | epoch 243 | loss 2.313 | nll_loss 0.5 | ppl 1.41 | wps 23710 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 11829 | lr 0.000290754 | gnorm 0.564 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 32484
2022-03-06 22:03:59 | INFO | fairseq.trainer | begin training epoch 244
2022-03-06 22:03:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:05:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:05:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:06:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:06:10 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 13.26 | nll_loss 12.592 | ppl 6174.44 | wps 41552.9 | wpb 510.9 | bsz 1 | num_updates 11876 | best_loss 8.937
2022-03-06 22:06:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 244 @ 11876 updates
2022-03-06 22:06:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:06:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:06:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 244 @ 11876 updates, score 13.26) (writing took 2.403858905658126 seconds)
2022-03-06 22:06:13 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)
2022-03-06 22:06:13 | INFO | train | epoch 244 | loss 2.31 | nll_loss 0.497 | ppl 1.41 | wps 22745.5 | ups 0.35 | wpb 64829.4 | bsz 126.6 | num_updates 11876 | lr 0.000290178 | gnorm 0.557 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 32618
2022-03-06 22:06:13 | INFO | fairseq.trainer | begin training epoch 245
2022-03-06 22:06:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:07:15 | INFO | train_inner | epoch 245:     24 / 49 loss=2.31, nll_loss=0.498, ppl=1.41, wps=23315.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=11900, lr=0.000289886, gnorm=0.562, loss_scale=16, train_wall=237, gb_free=8.8, wall=32680
2022-03-06 22:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:08:25 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 13.261 | nll_loss 12.601 | ppl 6213.26 | wps 41833.9 | wpb 510.9 | bsz 1 | num_updates 11925 | best_loss 8.937
2022-03-06 22:08:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 245 @ 11925 updates
2022-03-06 22:08:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:08:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 245 @ 11925 updates, score 13.261) (writing took 2.532012863084674 seconds)
2022-03-06 22:08:27 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)
2022-03-06 22:08:27 | INFO | train | epoch 245 | loss 2.309 | nll_loss 0.496 | ppl 1.41 | wps 23666.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11925 | lr 0.000289581 | gnorm 0.557 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 32752
2022-03-06 22:08:27 | INFO | fairseq.trainer | begin training epoch 246
2022-03-06 22:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:10:39 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 13.26 | nll_loss 12.601 | ppl 6214.31 | wps 41219.7 | wpb 510.9 | bsz 1 | num_updates 11974 | best_loss 8.937
2022-03-06 22:10:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 246 @ 11974 updates
2022-03-06 22:10:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 246 @ 11974 updates, score 13.26) (writing took 2.498460997827351 seconds)
2022-03-06 22:10:42 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)
2022-03-06 22:10:42 | INFO | train | epoch 246 | loss 2.306 | nll_loss 0.494 | ppl 1.41 | wps 23644.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 11974 | lr 0.000288988 | gnorm 0.549 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 32886
2022-03-06 22:10:42 | INFO | fairseq.trainer | begin training epoch 247
2022-03-06 22:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:11:49 | INFO | train_inner | epoch 247:     26 / 49 loss=2.307, nll_loss=0.494, ppl=1.41, wps=23688.7, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=12000, lr=0.000288675, gnorm=0.553, loss_scale=32, train_wall=233, gb_free=8.8, wall=32954
2022-03-06 22:12:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:12:54 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 13.223 | nll_loss 12.555 | ppl 6019.71 | wps 40675.1 | wpb 510.9 | bsz 1 | num_updates 12023 | best_loss 8.937
2022-03-06 22:12:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 247 @ 12023 updates
2022-03-06 22:12:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:12:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:12:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 247 @ 12023 updates, score 13.223) (writing took 2.3977066790685058 seconds)
2022-03-06 22:12:57 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)
2022-03-06 22:12:57 | INFO | train | epoch 247 | loss 2.305 | nll_loss 0.493 | ppl 1.41 | wps 23536.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12023 | lr 0.000288399 | gnorm 0.555 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 33021
2022-03-06 22:12:57 | INFO | fairseq.trainer | begin training epoch 248
2022-03-06 22:12:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:15:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:15:11 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 13.182 | nll_loss 12.51 | ppl 5832.08 | wps 40086.5 | wpb 510.9 | bsz 1 | num_updates 12072 | best_loss 8.937
2022-03-06 22:15:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 248 @ 12072 updates
2022-03-06 22:15:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 248 @ 12072 updates, score 13.182) (writing took 2.532958067022264 seconds)
2022-03-06 22:15:14 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)
2022-03-06 22:15:14 | INFO | train | epoch 248 | loss 2.304 | nll_loss 0.492 | ppl 1.41 | wps 23169.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12072 | lr 0.000287813 | gnorm 0.558 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 33158
2022-03-06 22:15:14 | INFO | fairseq.trainer | begin training epoch 249
2022-03-06 22:15:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:16:28 | INFO | train_inner | epoch 249:     28 / 49 loss=2.304, nll_loss=0.492, ppl=1.41, wps=23255.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=12100, lr=0.00028748, gnorm=0.553, loss_scale=32, train_wall=237, gb_free=8.8, wall=33233
2022-03-06 22:17:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:17:28 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 13.229 | nll_loss 12.569 | ppl 6077.02 | wps 40014.2 | wpb 510.9 | bsz 1 | num_updates 12121 | best_loss 8.937
2022-03-06 22:17:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 249 @ 12121 updates
2022-03-06 22:17:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:17:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 249 @ 12121 updates, score 13.229) (writing took 2.4827527781017125 seconds)
2022-03-06 22:17:31 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)
2022-03-06 22:17:31 | INFO | train | epoch 249 | loss 2.301 | nll_loss 0.49 | ppl 1.4 | wps 23188.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12121 | lr 0.000287231 | gnorm 0.547 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 33296
2022-03-06 22:17:31 | INFO | fairseq.trainer | begin training epoch 250
2022-03-06 22:17:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:17:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:19:45 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 13.265 | nll_loss 12.602 | ppl 6218.2 | wps 40792.1 | wpb 510.9 | bsz 1 | num_updates 12169 | best_loss 8.937
2022-03-06 22:19:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 250 @ 12169 updates
2022-03-06 22:19:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:19:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:19:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 250 @ 12169 updates, score 13.265) (writing took 2.3636226118542254 seconds)
2022-03-06 22:19:47 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)
2022-03-06 22:19:47 | INFO | train | epoch 250 | loss 2.3 | nll_loss 0.488 | ppl 1.4 | wps 22807.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12169 | lr 0.000286664 | gnorm 0.564 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 33432
2022-03-06 22:19:47 | INFO | fairseq.trainer | begin training epoch 251
2022-03-06 22:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:19:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 22:21:12 | INFO | train_inner | epoch 251:     32 / 49 loss=2.299, nll_loss=0.488, ppl=1.4, wps=22827.4, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=12200, lr=0.000286299, gnorm=0.558, loss_scale=16, train_wall=242, gb_free=8.8, wall=33517
2022-03-06 22:21:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:22:02 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 13.243 | nll_loss 12.582 | ppl 6132.19 | wps 40632.7 | wpb 510.9 | bsz 1 | num_updates 12217 | best_loss 8.937
2022-03-06 22:22:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 251 @ 12217 updates
2022-03-06 22:22:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:22:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:22:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 251 @ 12217 updates, score 13.243) (writing took 2.4377897325903177 seconds)
2022-03-06 22:22:04 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)
2022-03-06 22:22:04 | INFO | train | epoch 251 | loss 2.297 | nll_loss 0.486 | ppl 1.4 | wps 22758.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12217 | lr 0.0002861 | gnorm 0.549 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 33569
2022-03-06 22:22:04 | INFO | fairseq.trainer | begin training epoch 252
2022-03-06 22:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:24:18 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 13.245 | nll_loss 12.578 | ppl 6113.11 | wps 39457.1 | wpb 510.9 | bsz 1 | num_updates 12266 | best_loss 8.937
2022-03-06 22:24:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 252 @ 12266 updates
2022-03-06 22:24:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 252 @ 12266 updates, score 13.245) (writing took 2.480510982684791 seconds)
2022-03-06 22:24:21 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)
2022-03-06 22:24:21 | INFO | train | epoch 252 | loss 2.295 | nll_loss 0.484 | ppl 1.4 | wps 23219.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12266 | lr 0.000285528 | gnorm 0.536 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 33706
2022-03-06 22:24:21 | INFO | fairseq.trainer | begin training epoch 253
2022-03-06 22:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:25:51 | INFO | train_inner | epoch 253:     34 / 49 loss=2.296, nll_loss=0.485, ppl=1.4, wps=23268.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=12300, lr=0.000285133, gnorm=0.541, loss_scale=32, train_wall=237, gb_free=8.8, wall=33796
2022-03-06 22:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:26:35 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 13.214 | nll_loss 12.555 | ppl 6016.35 | wps 40483.1 | wpb 510.9 | bsz 1 | num_updates 12315 | best_loss 8.937
2022-03-06 22:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 253 @ 12315 updates
2022-03-06 22:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:26:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:26:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 253 @ 12315 updates, score 13.214) (writing took 2.427457603625953 seconds)
2022-03-06 22:26:38 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)
2022-03-06 22:26:38 | INFO | train | epoch 253 | loss 2.295 | nll_loss 0.485 | ppl 1.4 | wps 23234.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12315 | lr 0.000284959 | gnorm 0.549 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 33842
2022-03-06 22:26:38 | INFO | fairseq.trainer | begin training epoch 254
2022-03-06 22:26:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:28:52 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 13.234 | nll_loss 12.572 | ppl 6089.06 | wps 40858.7 | wpb 510.9 | bsz 1 | num_updates 12364 | best_loss 8.937
2022-03-06 22:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 254 @ 12364 updates
2022-03-06 22:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:28:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:28:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 254 @ 12364 updates, score 13.234) (writing took 2.429994323756546 seconds)
2022-03-06 22:28:54 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)
2022-03-06 22:28:54 | INFO | train | epoch 254 | loss 2.292 | nll_loss 0.482 | ppl 1.4 | wps 23246.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12364 | lr 0.000284394 | gnorm 0.539 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 33979
2022-03-06 22:28:54 | INFO | fairseq.trainer | begin training epoch 255
2022-03-06 22:28:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:30:30 | INFO | train_inner | epoch 255:     36 / 49 loss=2.292, nll_loss=0.482, ppl=1.4, wps=23248.4, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=12400, lr=0.000283981, gnorm=0.542, loss_scale=32, train_wall=238, gb_free=8.8, wall=34075
2022-03-06 22:31:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:31:09 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 13.292 | nll_loss 12.633 | ppl 6351.76 | wps 40840.3 | wpb 510.9 | bsz 1 | num_updates 12413 | best_loss 8.937
2022-03-06 22:31:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 255 @ 12413 updates
2022-03-06 22:31:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:31:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:31:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 255 @ 12413 updates, score 13.292) (writing took 2.560944473836571 seconds)
2022-03-06 22:31:11 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)
2022-03-06 22:31:11 | INFO | train | epoch 255 | loss 2.291 | nll_loss 0.481 | ppl 1.4 | wps 23197.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12413 | lr 0.000283832 | gnorm 0.543 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 34116
2022-03-06 22:31:11 | INFO | fairseq.trainer | begin training epoch 256
2022-03-06 22:31:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:31:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:33:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:33:26 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 13.282 | nll_loss 12.613 | ppl 6265.65 | wps 40272.9 | wpb 510.9 | bsz 1 | num_updates 12461 | best_loss 8.937
2022-03-06 22:33:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 256 @ 12461 updates
2022-03-06 22:33:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:33:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:33:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 256 @ 12461 updates, score 13.282) (writing took 2.4635642152279615 seconds)
2022-03-06 22:33:28 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)
2022-03-06 22:33:28 | INFO | train | epoch 256 | loss 2.288 | nll_loss 0.478 | ppl 1.39 | wps 22756.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12461 | lr 0.000283285 | gnorm 0.535 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 34253
2022-03-06 22:33:28 | INFO | fairseq.trainer | begin training epoch 257
2022-03-06 22:33:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:35:11 | INFO | train_inner | epoch 257:     39 / 49 loss=2.289, nll_loss=0.479, ppl=1.39, wps=23071.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=12500, lr=0.000282843, gnorm=0.542, loss_scale=32, train_wall=239, gb_free=8.8, wall=34356
2022-03-06 22:35:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:35:42 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 13.257 | nll_loss 12.598 | ppl 6198.98 | wps 40399.5 | wpb 510.9 | bsz 1 | num_updates 12510 | best_loss 8.937
2022-03-06 22:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 257 @ 12510 updates
2022-03-06 22:35:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:35:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:35:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 257 @ 12510 updates, score 13.257) (writing took 2.4707926642149687 seconds)
2022-03-06 22:35:45 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)
2022-03-06 22:35:45 | INFO | train | epoch 257 | loss 2.288 | nll_loss 0.478 | ppl 1.39 | wps 23258.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12510 | lr 0.00028273 | gnorm 0.555 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 34390
2022-03-06 22:35:45 | INFO | fairseq.trainer | begin training epoch 258
2022-03-06 22:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:37:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:37:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:37:57 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 13.255 | nll_loss 12.59 | ppl 6166.67 | wps 41769.4 | wpb 510.9 | bsz 1 | num_updates 12558 | best_loss 8.937
2022-03-06 22:37:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 258 @ 12558 updates
2022-03-06 22:37:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:37:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:37:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 258 @ 12558 updates, score 13.255) (writing took 2.5178027129732072 seconds)
2022-03-06 22:37:59 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)
2022-03-06 22:37:59 | INFO | train | epoch 258 | loss 2.285 | nll_loss 0.476 | ppl 1.39 | wps 23155.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 12558 | lr 0.000282189 | gnorm 0.535 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 34524
2022-03-06 22:37:59 | INFO | fairseq.trainer | begin training epoch 259
2022-03-06 22:37:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:39:49 | INFO | train_inner | epoch 259:     42 / 49 loss=2.286, nll_loss=0.477, ppl=1.39, wps=23388.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=12600, lr=0.000281718, gnorm=0.541, loss_scale=32, train_wall=236, gb_free=8.8, wall=34634
2022-03-06 22:40:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:40:11 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 13.183 | nll_loss 12.521 | ppl 5875.82 | wps 42271.5 | wpb 510.9 | bsz 1 | num_updates 12607 | best_loss 8.937
2022-03-06 22:40:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 259 @ 12607 updates
2022-03-06 22:40:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:40:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:40:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 259 @ 12607 updates, score 13.183) (writing took 2.3132823649793863 seconds)
2022-03-06 22:40:13 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)
2022-03-06 22:40:13 | INFO | train | epoch 259 | loss 2.284 | nll_loss 0.476 | ppl 1.39 | wps 23712.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12607 | lr 0.00028164 | gnorm 0.545 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 34658
2022-03-06 22:40:13 | INFO | fairseq.trainer | begin training epoch 260
2022-03-06 22:40:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:42:25 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 13.257 | nll_loss 12.598 | ppl 6200.87 | wps 42570.9 | wpb 510.9 | bsz 1 | num_updates 12656 | best_loss 8.937
2022-03-06 22:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 260 @ 12656 updates
2022-03-06 22:42:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:42:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:42:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 260 @ 12656 updates, score 13.257) (writing took 2.4262799550779164 seconds)
2022-03-06 22:42:27 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)
2022-03-06 22:42:27 | INFO | train | epoch 260 | loss 2.282 | nll_loss 0.474 | ppl 1.39 | wps 23730.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12656 | lr 0.000281094 | gnorm 0.534 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 34792
2022-03-06 22:42:27 | INFO | fairseq.trainer | begin training epoch 261
2022-03-06 22:42:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:43:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:44:25 | INFO | train_inner | epoch 261:     45 / 49 loss=2.281, nll_loss=0.473, ppl=1.39, wps=23525.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=12700, lr=0.000280607, gnorm=0.535, loss_scale=32, train_wall=235, gb_free=8.8, wall=34909
2022-03-06 22:44:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:44:39 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 13.251 | nll_loss 12.595 | ppl 6187 | wps 41018.5 | wpb 510.9 | bsz 1 | num_updates 12704 | best_loss 8.937
2022-03-06 22:44:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 261 @ 12704 updates
2022-03-06 22:44:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:44:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:44:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 261 @ 12704 updates, score 13.251) (writing took 2.437158979009837 seconds)
2022-03-06 22:44:42 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)
2022-03-06 22:44:42 | INFO | train | epoch 261 | loss 2.28 | nll_loss 0.472 | ppl 1.39 | wps 23171.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 12704 | lr 0.000280563 | gnorm 0.531 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 34926
2022-03-06 22:44:42 | INFO | fairseq.trainer | begin training epoch 262
2022-03-06 22:44:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:46:53 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 13.288 | nll_loss 12.638 | ppl 6373.69 | wps 41719 | wpb 510.9 | bsz 1 | num_updates 12753 | best_loss 8.937
2022-03-06 22:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 262 @ 12753 updates
2022-03-06 22:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:46:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 262 @ 12753 updates, score 13.288) (writing took 2.3819544799625874 seconds)
2022-03-06 22:46:56 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)
2022-03-06 22:46:56 | INFO | train | epoch 262 | loss 2.279 | nll_loss 0.471 | ppl 1.39 | wps 23674.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12753 | lr 0.000280023 | gnorm 0.531 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 35060
2022-03-06 22:46:56 | INFO | fairseq.trainer | begin training epoch 263
2022-03-06 22:46:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:48:58 | INFO | train_inner | epoch 263:     47 / 49 loss=2.279, nll_loss=0.471, ppl=1.39, wps=23703.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=12800, lr=0.000279508, gnorm=0.532, loss_scale=32, train_wall=233, gb_free=8.8, wall=35183
2022-03-06 22:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:49:07 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 13.223 | nll_loss 12.56 | ppl 6038.61 | wps 42469.4 | wpb 510.9 | bsz 1 | num_updates 12802 | best_loss 8.937
2022-03-06 22:49:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 263 @ 12802 updates
2022-03-06 22:49:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:49:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 263 @ 12802 updates, score 13.223) (writing took 2.333675933070481 seconds)
2022-03-06 22:49:10 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)
2022-03-06 22:49:10 | INFO | train | epoch 263 | loss 2.278 | nll_loss 0.471 | ppl 1.39 | wps 23716.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 12802 | lr 0.000279487 | gnorm 0.533 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 35194
2022-03-06 22:49:10 | INFO | fairseq.trainer | begin training epoch 264
2022-03-06 22:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:49:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:51:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:51:23 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 13.264 | nll_loss 12.606 | ppl 6235.02 | wps 40787.6 | wpb 510.9 | bsz 1 | num_updates 12850 | best_loss 8.937
2022-03-06 22:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 264 @ 12850 updates
2022-03-06 22:51:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:51:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:51:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 264 @ 12850 updates, score 13.264) (writing took 2.557574677746743 seconds)
2022-03-06 22:51:26 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)
2022-03-06 22:51:26 | INFO | train | epoch 264 | loss 2.277 | nll_loss 0.469 | ppl 1.38 | wps 22881 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12850 | lr 0.000278964 | gnorm 0.533 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 35331
2022-03-06 22:51:26 | INFO | fairseq.trainer | begin training epoch 265
2022-03-06 22:51:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:53:40 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 13.235 | nll_loss 12.57 | ppl 6078.72 | wps 40575 | wpb 510.9 | bsz 1 | num_updates 12899 | best_loss 8.937
2022-03-06 22:53:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 265 @ 12899 updates
2022-03-06 22:53:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:53:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:53:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 265 @ 12899 updates, score 13.235) (writing took 2.4576142663136125 seconds)
2022-03-06 22:53:43 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)
2022-03-06 22:53:43 | INFO | train | epoch 265 | loss 2.275 | nll_loss 0.468 | ppl 1.38 | wps 23245 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12899 | lr 0.000278434 | gnorm 0.529 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 35467
2022-03-06 22:53:43 | INFO | fairseq.trainer | begin training epoch 266
2022-03-06 22:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:53:45 | INFO | train_inner | epoch 266:      1 / 49 loss=2.276, nll_loss=0.468, ppl=1.38, wps=22486.7, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=12900, lr=0.000278423, gnorm=0.533, loss_scale=32, train_wall=238, gb_free=8.8, wall=35470
2022-03-06 22:55:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 22:55:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:55:57 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 13.268 | nll_loss 12.613 | ppl 6263.69 | wps 40426.2 | wpb 510.9 | bsz 1 | num_updates 12947 | best_loss 8.937
2022-03-06 22:55:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 266 @ 12947 updates
2022-03-06 22:55:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:56:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:56:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 266 @ 12947 updates, score 13.268) (writing took 2.4977949699386954 seconds)
2022-03-06 22:56:00 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)
2022-03-06 22:56:00 | INFO | train | epoch 266 | loss 2.273 | nll_loss 0.466 | ppl 1.38 | wps 22706.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 12947 | lr 0.000277917 | gnorm 0.524 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 35604
2022-03-06 22:56:00 | INFO | fairseq.trainer | begin training epoch 267
2022-03-06 22:56:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:58:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 22:58:14 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 13.355 | nll_loss 12.707 | ppl 6687.02 | wps 40610.4 | wpb 510.9 | bsz 1 | num_updates 12996 | best_loss 8.937
2022-03-06 22:58:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 267 @ 12996 updates
2022-03-06 22:58:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:58:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 22:58:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 267 @ 12996 updates, score 13.355) (writing took 2.4857402653433383 seconds)
2022-03-06 22:58:16 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)
2022-03-06 22:58:16 | INFO | train | epoch 267 | loss 2.272 | nll_loss 0.465 | ppl 1.38 | wps 23251 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 12996 | lr 0.000277393 | gnorm 0.531 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 35741
2022-03-06 22:58:16 | INFO | fairseq.trainer | begin training epoch 268
2022-03-06 22:58:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 22:58:27 | INFO | train_inner | epoch 268:      4 / 49 loss=2.272, nll_loss=0.465, ppl=1.38, wps=23029.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13000, lr=0.00027735, gnorm=0.528, loss_scale=32, train_wall=240, gb_free=8.8, wall=35752
2022-03-06 23:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:00:29 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 13.266 | nll_loss 12.613 | ppl 6263.21 | wps 41235.6 | wpb 510.9 | bsz 1 | num_updates 13045 | best_loss 8.937
2022-03-06 23:00:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 268 @ 13045 updates
2022-03-06 23:00:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:00:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 268 @ 13045 updates, score 13.266) (writing took 2.3935794131830335 seconds)
2022-03-06 23:00:32 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)
2022-03-06 23:00:32 | INFO | train | epoch 268 | loss 2.27 | nll_loss 0.464 | ppl 1.38 | wps 23458.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13045 | lr 0.000276871 | gnorm 0.526 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 35876
2022-03-06 23:00:32 | INFO | fairseq.trainer | begin training epoch 269
2022-03-06 23:00:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:01:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:02:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:02:45 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 13.31 | nll_loss 12.657 | ppl 6459.85 | wps 40884.2 | wpb 510.9 | bsz 1 | num_updates 13093 | best_loss 8.937
2022-03-06 23:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 269 @ 13093 updates
2022-03-06 23:02:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:02:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 269 @ 13093 updates, score 13.31) (writing took 2.4330839258618653 seconds)
2022-03-06 23:02:47 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)
2022-03-06 23:02:47 | INFO | train | epoch 269 | loss 2.268 | nll_loss 0.462 | ppl 1.38 | wps 22946.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13093 | lr 0.000276363 | gnorm 0.522 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 36012
2022-03-06 23:02:47 | INFO | fairseq.trainer | begin training epoch 270
2022-03-06 23:02:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:03:06 | INFO | train_inner | epoch 270:      7 / 49 loss=2.269, nll_loss=0.462, ppl=1.38, wps=23257.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13100, lr=0.000276289, gnorm=0.524, loss_scale=32, train_wall=238, gb_free=8.8, wall=36031
2022-03-06 23:03:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:05:01 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 13.338 | nll_loss 12.685 | ppl 6584.07 | wps 40824.6 | wpb 510.9 | bsz 1 | num_updates 13141 | best_loss 8.937
2022-03-06 23:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 270 @ 13141 updates
2022-03-06 23:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:05:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 270 @ 13141 updates, score 13.338) (writing took 2.4010722530074418 seconds)
2022-03-06 23:05:04 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)
2022-03-06 23:05:04 | INFO | train | epoch 270 | loss 2.268 | nll_loss 0.462 | ppl 1.38 | wps 22849.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13141 | lr 0.000275858 | gnorm 0.54 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 36148
2022-03-06 23:05:04 | INFO | fairseq.trainer | begin training epoch 271
2022-03-06 23:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:07:18 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 13.319 | nll_loss 12.667 | ppl 6503.41 | wps 40012.8 | wpb 510.9 | bsz 1 | num_updates 13190 | best_loss 8.937
2022-03-06 23:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 271 @ 13190 updates
2022-03-06 23:07:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:07:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:07:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 271 @ 13190 updates, score 13.319) (writing took 2.4832494342699647 seconds)
2022-03-06 23:07:21 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)
2022-03-06 23:07:21 | INFO | train | epoch 271 | loss 2.266 | nll_loss 0.46 | ppl 1.38 | wps 23162.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13190 | lr 0.000275345 | gnorm 0.518 | loss_scale 16 | train_wall 117 | gb_free 8.8 | wall 36286
2022-03-06 23:07:21 | INFO | fairseq.trainer | begin training epoch 272
2022-03-06 23:07:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:07:47 | INFO | train_inner | epoch 272:     10 / 49 loss=2.266, nll_loss=0.461, ppl=1.38, wps=23044.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13200, lr=0.000275241, gnorm=0.53, loss_scale=16, train_wall=240, gb_free=8.8, wall=36312
2022-03-06 23:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:09:35 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 13.285 | nll_loss 12.638 | ppl 6374.76 | wps 40388.1 | wpb 510.9 | bsz 1 | num_updates 13239 | best_loss 8.937
2022-03-06 23:09:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 272 @ 13239 updates
2022-03-06 23:09:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:09:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:09:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 272 @ 13239 updates, score 13.285) (writing took 2.4370485870167613 seconds)
2022-03-06 23:09:37 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)
2022-03-06 23:09:37 | INFO | train | epoch 272 | loss 2.264 | nll_loss 0.459 | ppl 1.37 | wps 23260.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13239 | lr 0.000274835 | gnorm 0.531 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 36422
2022-03-06 23:09:37 | INFO | fairseq.trainer | begin training epoch 273
2022-03-06 23:09:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:11:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:11:52 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 13.335 | nll_loss 12.69 | ppl 6607.93 | wps 40294.9 | wpb 510.9 | bsz 1 | num_updates 13288 | best_loss 8.937
2022-03-06 23:11:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 273 @ 13288 updates
2022-03-06 23:11:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:11:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:11:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 273 @ 13288 updates, score 13.335) (writing took 2.410820872988552 seconds)
2022-03-06 23:11:54 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)
2022-03-06 23:11:54 | INFO | train | epoch 273 | loss 2.263 | nll_loss 0.458 | ppl 1.37 | wps 23282.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13288 | lr 0.000274328 | gnorm 0.521 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 36559
2022-03-06 23:11:54 | INFO | fairseq.trainer | begin training epoch 274
2022-03-06 23:11:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:12:26 | INFO | train_inner | epoch 274:     12 / 49 loss=2.264, nll_loss=0.458, ppl=1.37, wps=23300.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13300, lr=0.000274204, gnorm=0.525, loss_scale=32, train_wall=237, gb_free=8.8, wall=36591
2022-03-06 23:14:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:14:08 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 13.242 | nll_loss 12.591 | ppl 6169.68 | wps 41863.7 | wpb 510.9 | bsz 1 | num_updates 13337 | best_loss 8.937
2022-03-06 23:14:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 274 @ 13337 updates
2022-03-06 23:14:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:14:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:14:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 274 @ 13337 updates, score 13.242) (writing took 2.404219839721918 seconds)
2022-03-06 23:14:10 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)
2022-03-06 23:14:10 | INFO | train | epoch 274 | loss 2.261 | nll_loss 0.457 | ppl 1.37 | wps 23340.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13337 | lr 0.000273824 | gnorm 0.518 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 36695
2022-03-06 23:14:10 | INFO | fairseq.trainer | begin training epoch 275
2022-03-06 23:14:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:15:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:16:23 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 13.191 | nll_loss 12.534 | ppl 5932.61 | wps 39225.3 | wpb 510.9 | bsz 1 | num_updates 13385 | best_loss 8.937
2022-03-06 23:16:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 275 @ 13385 updates
2022-03-06 23:16:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:16:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:16:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 275 @ 13385 updates, score 13.191) (writing took 2.618636861909181 seconds)
2022-03-06 23:16:26 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)
2022-03-06 23:16:26 | INFO | train | epoch 275 | loss 2.259 | nll_loss 0.455 | ppl 1.37 | wps 22906.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13385 | lr 0.000273332 | gnorm 0.528 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 36831
2022-03-06 23:16:26 | INFO | fairseq.trainer | begin training epoch 276
2022-03-06 23:16:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:17:06 | INFO | train_inner | epoch 276:     15 / 49 loss=2.26, nll_loss=0.455, ppl=1.37, wps=23169.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13400, lr=0.000273179, gnorm=0.523, loss_scale=32, train_wall=238, gb_free=8.8, wall=36871
2022-03-06 23:18:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:18:40 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 13.363 | nll_loss 12.718 | ppl 6735.72 | wps 40345.2 | wpb 510.9 | bsz 1 | num_updates 13434 | best_loss 8.937
2022-03-06 23:18:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 276 @ 13434 updates
2022-03-06 23:18:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:18:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:18:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 276 @ 13434 updates, score 13.363) (writing took 2.4197768713347614 seconds)
2022-03-06 23:18:43 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)
2022-03-06 23:18:43 | INFO | train | epoch 276 | loss 2.258 | nll_loss 0.454 | ppl 1.37 | wps 23267.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13434 | lr 0.000272833 | gnorm 0.519 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 36967
2022-03-06 23:18:43 | INFO | fairseq.trainer | begin training epoch 277
2022-03-06 23:18:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:20:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:20:57 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 13.276 | nll_loss 12.621 | ppl 6297.56 | wps 40676.7 | wpb 510.9 | bsz 1 | num_updates 13483 | best_loss 8.937
2022-03-06 23:20:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 277 @ 13483 updates
2022-03-06 23:20:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:20:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:20:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 277 @ 13483 updates, score 13.276) (writing took 2.5540937930345535 seconds)
2022-03-06 23:20:59 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)
2022-03-06 23:20:59 | INFO | train | epoch 277 | loss 2.257 | nll_loss 0.454 | ppl 1.37 | wps 23256.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13483 | lr 0.000272337 | gnorm 0.529 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37104
2022-03-06 23:20:59 | INFO | fairseq.trainer | begin training epoch 278
2022-03-06 23:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:21:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:21:47 | INFO | train_inner | epoch 278:     18 / 49 loss=2.257, nll_loss=0.453, ppl=1.37, wps=23080.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=13500, lr=0.000272166, gnorm=0.522, loss_scale=32, train_wall=239, gb_free=8.8, wall=37152
2022-03-06 23:23:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:23:13 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 13.298 | nll_loss 12.653 | ppl 6440.11 | wps 40289.8 | wpb 510.9 | bsz 1 | num_updates 13531 | best_loss 8.937
2022-03-06 23:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 278 @ 13531 updates
2022-03-06 23:23:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 278 @ 13531 updates, score 13.298) (writing took 2.383324825204909 seconds)
2022-03-06 23:23:16 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)
2022-03-06 23:23:16 | INFO | train | epoch 278 | loss 2.255 | nll_loss 0.451 | ppl 1.37 | wps 22804.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13531 | lr 0.000271854 | gnorm 0.521 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37240
2022-03-06 23:23:16 | INFO | fairseq.trainer | begin training epoch 279
2022-03-06 23:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:25:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:25:30 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 13.261 | nll_loss 12.608 | ppl 6243.07 | wps 40489 | wpb 510.9 | bsz 1 | num_updates 13580 | best_loss 8.937
2022-03-06 23:25:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 279 @ 13580 updates
2022-03-06 23:25:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:25:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:25:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 279 @ 13580 updates, score 13.261) (writing took 2.4445572826080024 seconds)
2022-03-06 23:25:32 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)
2022-03-06 23:25:32 | INFO | train | epoch 279 | loss 2.254 | nll_loss 0.451 | ppl 1.37 | wps 23285.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13580 | lr 0.000271363 | gnorm 0.518 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37377
2022-03-06 23:25:32 | INFO | fairseq.trainer | begin training epoch 280
2022-03-06 23:25:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:26:25 | INFO | train_inner | epoch 280:     20 / 49 loss=2.254, nll_loss=0.45, ppl=1.37, wps=23297.7, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=13600, lr=0.000271163, gnorm=0.516, loss_scale=32, train_wall=237, gb_free=8.8, wall=37430
2022-03-06 23:27:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:27:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:27:46 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 13.284 | nll_loss 12.638 | ppl 6374.37 | wps 40526.7 | wpb 510.9 | bsz 1 | num_updates 13628 | best_loss 8.937
2022-03-06 23:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 280 @ 13628 updates
2022-03-06 23:27:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:27:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:27:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 280 @ 13628 updates, score 13.284) (writing took 2.4846865427680314 seconds)
2022-03-06 23:27:49 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)
2022-03-06 23:27:49 | INFO | train | epoch 280 | loss 2.251 | nll_loss 0.448 | ppl 1.36 | wps 22783.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13628 | lr 0.000270884 | gnorm 0.504 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37514
2022-03-06 23:27:49 | INFO | fairseq.trainer | begin training epoch 281
2022-03-06 23:27:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:30:03 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 13.298 | nll_loss 12.645 | ppl 6406.3 | wps 40632.5 | wpb 510.9 | bsz 1 | num_updates 13677 | best_loss 8.937
2022-03-06 23:30:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 281 @ 13677 updates
2022-03-06 23:30:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 281 @ 13677 updates, score 13.298) (writing took 2.509671646170318 seconds)
2022-03-06 23:30:05 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)
2022-03-06 23:30:05 | INFO | train | epoch 281 | loss 2.252 | nll_loss 0.449 | ppl 1.36 | wps 23257.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13677 | lr 0.000270399 | gnorm 0.516 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37650
2022-03-06 23:30:05 | INFO | fairseq.trainer | begin training epoch 282
2022-03-06 23:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:31:06 | INFO | train_inner | epoch 282:     23 / 49 loss=2.251, nll_loss=0.448, ppl=1.36, wps=23084.8, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=13700, lr=0.000270172, gnorm=0.512, loss_scale=32, train_wall=239, gb_free=8.8, wall=37711
2022-03-06 23:32:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:32:20 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 13.248 | nll_loss 12.594 | ppl 6181.05 | wps 40015.7 | wpb 510.9 | bsz 1 | num_updates 13726 | best_loss 8.937
2022-03-06 23:32:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 282 @ 13726 updates
2022-03-06 23:32:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:32:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:32:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 282 @ 13726 updates, score 13.248) (writing took 2.449278228916228 seconds)
2022-03-06 23:32:22 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)
2022-03-06 23:32:22 | INFO | train | epoch 282 | loss 2.25 | nll_loss 0.447 | ppl 1.36 | wps 23260 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13726 | lr 0.000269916 | gnorm 0.508 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37787
2022-03-06 23:32:22 | INFO | fairseq.trainer | begin training epoch 283
2022-03-06 23:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:33:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:34:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:34:36 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 13.293 | nll_loss 12.648 | ppl 6419.96 | wps 41256.9 | wpb 510.9 | bsz 1 | num_updates 13774 | best_loss 8.937
2022-03-06 23:34:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 283 @ 13774 updates
2022-03-06 23:34:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:34:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:34:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 283 @ 13774 updates, score 13.293) (writing took 2.475386992096901 seconds)
2022-03-06 23:34:39 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)
2022-03-06 23:34:39 | INFO | train | epoch 283 | loss 2.249 | nll_loss 0.447 | ppl 1.36 | wps 22788 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 13774 | lr 0.000269445 | gnorm 0.514 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 37923
2022-03-06 23:34:39 | INFO | fairseq.trainer | begin training epoch 284
2022-03-06 23:34:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:35:48 | INFO | train_inner | epoch 284:     26 / 49 loss=2.249, nll_loss=0.446, ppl=1.36, wps=23051.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13800, lr=0.000269191, gnorm=0.51, loss_scale=32, train_wall=240, gb_free=8.8, wall=37992
2022-03-06 23:36:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:36:53 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 13.311 | nll_loss 12.662 | ppl 6483.16 | wps 39876.5 | wpb 510.9 | bsz 1 | num_updates 13823 | best_loss 8.937
2022-03-06 23:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 284 @ 13823 updates
2022-03-06 23:36:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:36:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:36:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 284 @ 13823 updates, score 13.311) (writing took 2.476359076332301 seconds)
2022-03-06 23:36:55 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)
2022-03-06 23:36:55 | INFO | train | epoch 284 | loss 2.247 | nll_loss 0.445 | ppl 1.36 | wps 23249.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13823 | lr 0.000268967 | gnorm 0.514 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 38060
2022-03-06 23:36:55 | INFO | fairseq.trainer | begin training epoch 285
2022-03-06 23:36:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:39:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:39:09 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 13.256 | nll_loss 12.609 | ppl 6245.51 | wps 40996.5 | wpb 510.9 | bsz 1 | num_updates 13872 | best_loss 8.937
2022-03-06 23:39:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 285 @ 13872 updates
2022-03-06 23:39:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:39:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:39:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 285 @ 13872 updates, score 13.256) (writing took 2.496366990264505 seconds)
2022-03-06 23:39:12 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)
2022-03-06 23:39:12 | INFO | train | epoch 285 | loss 2.247 | nll_loss 0.445 | ppl 1.36 | wps 23326.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 13872 | lr 0.000268491 | gnorm 0.514 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 38196
2022-03-06 23:39:12 | INFO | fairseq.trainer | begin training epoch 286
2022-03-06 23:39:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:39:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:40:28 | INFO | train_inner | epoch 286:     29 / 49 loss=2.246, nll_loss=0.444, ppl=1.36, wps=23131.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=13900, lr=0.000268221, gnorm=0.509, loss_scale=32, train_wall=239, gb_free=8.8, wall=38273
2022-03-06 23:41:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:41:24 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 13.218 | nll_loss 12.564 | ppl 6056.27 | wps 41869.6 | wpb 510.9 | bsz 1 | num_updates 13920 | best_loss 8.937
2022-03-06 23:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 286 @ 13920 updates
2022-03-06 23:41:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:41:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:41:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 286 @ 13920 updates, score 13.218) (writing took 2.394103732891381 seconds)
2022-03-06 23:41:27 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)
2022-03-06 23:41:27 | INFO | train | epoch 286 | loss 2.244 | nll_loss 0.442 | ppl 1.36 | wps 23026.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 13920 | lr 0.000268028 | gnorm 0.5 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 38332
2022-03-06 23:41:27 | INFO | fairseq.trainer | begin training epoch 287
2022-03-06 23:41:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:43:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:43:38 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 13.372 | nll_loss 12.734 | ppl 6813.08 | wps 42703.3 | wpb 510.9 | bsz 1 | num_updates 13969 | best_loss 8.937
2022-03-06 23:43:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 287 @ 13969 updates
2022-03-06 23:43:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:43:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:43:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 287 @ 13969 updates, score 13.372) (writing took 2.5340739032253623 seconds)
2022-03-06 23:43:41 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)
2022-03-06 23:43:41 | INFO | train | epoch 287 | loss 2.244 | nll_loss 0.442 | ppl 1.36 | wps 23682.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 13969 | lr 0.000267558 | gnorm 0.516 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 38466
2022-03-06 23:43:41 | INFO | fairseq.trainer | begin training epoch 288
2022-03-06 23:43:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:45:02 | INFO | train_inner | epoch 288:     31 / 49 loss=2.243, nll_loss=0.442, ppl=1.36, wps=23701.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=14000, lr=0.000267261, gnorm=0.511, loss_scale=32, train_wall=233, gb_free=8.8, wall=38547
2022-03-06 23:45:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:45:53 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 13.201 | nll_loss 12.548 | ppl 5989.95 | wps 41957.5 | wpb 510.9 | bsz 1 | num_updates 14017 | best_loss 8.937
2022-03-06 23:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 288 @ 14017 updates
2022-03-06 23:45:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 288 @ 14017 updates, score 13.201) (writing took 2.4689262518659234 seconds)
2022-03-06 23:45:55 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)
2022-03-06 23:45:55 | INFO | train | epoch 288 | loss 2.242 | nll_loss 0.441 | ppl 1.36 | wps 23195.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 14017 | lr 0.000267099 | gnorm 0.501 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 38600
2022-03-06 23:45:55 | INFO | fairseq.trainer | begin training epoch 289
2022-03-06 23:45:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:48:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:48:07 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 13.259 | nll_loss 12.616 | ppl 6276.03 | wps 41423.6 | wpb 510.9 | bsz 1 | num_updates 14066 | best_loss 8.937
2022-03-06 23:48:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 289 @ 14066 updates
2022-03-06 23:48:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:48:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:48:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 289 @ 14066 updates, score 13.259) (writing took 2.453894038219005 seconds)
2022-03-06 23:48:09 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)
2022-03-06 23:48:09 | INFO | train | epoch 289 | loss 2.241 | nll_loss 0.44 | ppl 1.36 | wps 23665.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14066 | lr 0.000266633 | gnorm 0.508 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 38734
2022-03-06 23:48:09 | INFO | fairseq.trainer | begin training epoch 290
2022-03-06 23:48:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:49:38 | INFO | train_inner | epoch 290:     34 / 49 loss=2.241, nll_loss=0.44, ppl=1.36, wps=23485.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14100, lr=0.000266312, gnorm=0.504, loss_scale=32, train_wall=235, gb_free=8.8, wall=38823
2022-03-06 23:50:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:50:21 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 13.218 | nll_loss 12.562 | ppl 6047.32 | wps 41759.3 | wpb 510.9 | bsz 1 | num_updates 14115 | best_loss 8.937
2022-03-06 23:50:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 290 @ 14115 updates
2022-03-06 23:50:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 290 @ 14115 updates, score 13.218) (writing took 2.493707842193544 seconds)
2022-03-06 23:50:24 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)
2022-03-06 23:50:24 | INFO | train | epoch 290 | loss 2.24 | nll_loss 0.439 | ppl 1.36 | wps 23661.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14115 | lr 0.00026617 | gnorm 0.509 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 38868
2022-03-06 23:50:24 | INFO | fairseq.trainer | begin training epoch 291
2022-03-06 23:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:51:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-06 23:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:52:36 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 13.187 | nll_loss 12.534 | ppl 5930.5 | wps 41973.3 | wpb 510.9 | bsz 1 | num_updates 14163 | best_loss 8.937
2022-03-06 23:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 291 @ 14163 updates
2022-03-06 23:52:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:52:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:52:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 291 @ 14163 updates, score 13.187) (writing took 2.4238760038278997 seconds)
2022-03-06 23:52:38 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)
2022-03-06 23:52:38 | INFO | train | epoch 291 | loss 2.239 | nll_loss 0.439 | ppl 1.36 | wps 23194.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 14163 | lr 0.000265719 | gnorm 0.508 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 39003
2022-03-06 23:52:38 | INFO | fairseq.trainer | begin training epoch 292
2022-03-06 23:52:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:54:16 | INFO | train_inner | epoch 292:     37 / 49 loss=2.238, nll_loss=0.438, ppl=1.35, wps=23352.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=14200, lr=0.000265372, gnorm=0.506, loss_scale=32, train_wall=237, gb_free=8.8, wall=39101
2022-03-06 23:54:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:54:52 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 13.272 | nll_loss 12.625 | ppl 6315.8 | wps 41042.9 | wpb 510.9 | bsz 1 | num_updates 14212 | best_loss 8.937
2022-03-06 23:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 292 @ 14212 updates
2022-03-06 23:54:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:54:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:54:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 292 @ 14212 updates, score 13.272) (writing took 2.498544469010085 seconds)
2022-03-06 23:54:54 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)
2022-03-06 23:54:54 | INFO | train | epoch 292 | loss 2.236 | nll_loss 0.436 | ppl 1.35 | wps 23297.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14212 | lr 0.00026526 | gnorm 0.496 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 39139
2022-03-06 23:54:54 | INFO | fairseq.trainer | begin training epoch 293
2022-03-06 23:54:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:56:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-06 23:57:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:57:09 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 13.317 | nll_loss 12.672 | ppl 6524.91 | wps 40362.3 | wpb 510.9 | bsz 1 | num_updates 14260 | best_loss 8.937
2022-03-06 23:57:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 293 @ 14260 updates
2022-03-06 23:57:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 293 @ 14260 updates, score 13.317) (writing took 2.499366879928857 seconds)
2022-03-06 23:57:11 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)
2022-03-06 23:57:11 | INFO | train | epoch 293 | loss 2.236 | nll_loss 0.436 | ppl 1.35 | wps 22754.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 14260 | lr 0.000264814 | gnorm 0.511 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 39276
2022-03-06 23:57:11 | INFO | fairseq.trainer | begin training epoch 294
2022-03-06 23:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-06 23:58:57 | INFO | train_inner | epoch 294:     40 / 49 loss=2.236, nll_loss=0.436, ppl=1.35, wps=23045.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=14300, lr=0.000264443, gnorm=0.507, loss_scale=16, train_wall=240, gb_free=8.8, wall=39382
2022-03-06 23:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-06 23:59:26 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 13.249 | nll_loss 12.603 | ppl 6222.6 | wps 40764.6 | wpb 510.9 | bsz 1 | num_updates 14309 | best_loss 8.937
2022-03-06 23:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 294 @ 14309 updates
2022-03-06 23:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-06 23:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 294 @ 14309 updates, score 13.249) (writing took 2.5485152769833803 seconds)
2022-03-06 23:59:28 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)
2022-03-06 23:59:28 | INFO | train | epoch 294 | loss 2.235 | nll_loss 0.435 | ppl 1.35 | wps 23204.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14309 | lr 0.00026436 | gnorm 0.506 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 39413
2022-03-06 23:59:28 | INFO | fairseq.trainer | begin training epoch 295
2022-03-06 23:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:01:42 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 13.318 | nll_loss 12.674 | ppl 6534.11 | wps 40818.8 | wpb 510.9 | bsz 1 | num_updates 14358 | best_loss 8.937
2022-03-07 00:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 295 @ 14358 updates
2022-03-07 00:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:01:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:01:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 295 @ 14358 updates, score 13.318) (writing took 2.5524402451701462 seconds)
2022-03-07 00:01:45 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)
2022-03-07 00:01:45 | INFO | train | epoch 295 | loss 2.234 | nll_loss 0.434 | ppl 1.35 | wps 23208.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14358 | lr 0.000263908 | gnorm 0.509 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 39550
2022-03-07 00:01:45 | INFO | fairseq.trainer | begin training epoch 296
2022-03-07 00:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:03:36 | INFO | train_inner | epoch 296:     42 / 49 loss=2.233, nll_loss=0.434, ppl=1.35, wps=23246.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14400, lr=0.000263523, gnorm=0.502, loss_scale=32, train_wall=237, gb_free=8.8, wall=39661
2022-03-07 00:03:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:03:59 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 13.307 | nll_loss 12.663 | ppl 6487.36 | wps 40670.9 | wpb 510.9 | bsz 1 | num_updates 14407 | best_loss 8.937
2022-03-07 00:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 296 @ 14407 updates
2022-03-07 00:03:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 296 @ 14407 updates, score 13.307) (writing took 2.353069413919002 seconds)
2022-03-07 00:04:02 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)
2022-03-07 00:04:02 | INFO | train | epoch 296 | loss 2.232 | nll_loss 0.433 | ppl 1.35 | wps 23287.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14407 | lr 0.000263459 | gnorm 0.493 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 39686
2022-03-07 00:04:02 | INFO | fairseq.trainer | begin training epoch 297
2022-03-07 00:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:06:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:06:16 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 13.26 | nll_loss 12.614 | ppl 6268.01 | wps 40875.4 | wpb 510.9 | bsz 1 | num_updates 14456 | best_loss 8.937
2022-03-07 00:06:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 297 @ 14456 updates
2022-03-07 00:06:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:06:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 297 @ 14456 updates, score 13.26) (writing took 2.6282030562870204 seconds)
2022-03-07 00:06:18 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)
2022-03-07 00:06:18 | INFO | train | epoch 297 | loss 2.231 | nll_loss 0.432 | ppl 1.35 | wps 23235.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14456 | lr 0.000263012 | gnorm 0.503 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 39823
2022-03-07 00:06:18 | INFO | fairseq.trainer | begin training epoch 298
2022-03-07 00:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:08:15 | INFO | train_inner | epoch 298:     44 / 49 loss=2.231, nll_loss=0.432, ppl=1.35, wps=23293.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=14500, lr=0.000262613, gnorm=0.503, loss_scale=32, train_wall=237, gb_free=8.8, wall=39940
2022-03-07 00:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:08:33 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 13.202 | nll_loss 12.548 | ppl 5989.04 | wps 39889.8 | wpb 510.9 | bsz 1 | num_updates 14505 | best_loss 8.937
2022-03-07 00:08:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 298 @ 14505 updates
2022-03-07 00:08:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:08:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:08:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 298 @ 14505 updates, score 13.202) (writing took 2.6045869439840317 seconds)
2022-03-07 00:08:35 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)
2022-03-07 00:08:35 | INFO | train | epoch 298 | loss 2.231 | nll_loss 0.432 | ppl 1.35 | wps 23225.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14505 | lr 0.000262568 | gnorm 0.505 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 39960
2022-03-07 00:08:35 | INFO | fairseq.trainer | begin training epoch 299
2022-03-07 00:08:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:08:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:10:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:10:49 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 13.181 | nll_loss 12.532 | ppl 5921.65 | wps 40240.2 | wpb 510.9 | bsz 1 | num_updates 14553 | best_loss 8.937
2022-03-07 00:10:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 299 @ 14553 updates
2022-03-07 00:10:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:10:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:10:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 299 @ 14553 updates, score 13.181) (writing took 2.425288180820644 seconds)
2022-03-07 00:10:52 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)
2022-03-07 00:10:52 | INFO | train | epoch 299 | loss 2.229 | nll_loss 0.43 | ppl 1.35 | wps 22762.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 14553 | lr 0.000262134 | gnorm 0.499 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 40097
2022-03-07 00:10:52 | INFO | fairseq.trainer | begin training epoch 300
2022-03-07 00:10:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:12:57 | INFO | train_inner | epoch 300:     47 / 49 loss=2.229, nll_loss=0.43, ppl=1.35, wps=23019.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=14600, lr=0.000261712, gnorm=0.499, loss_scale=32, train_wall=240, gb_free=8.8, wall=40222
2022-03-07 00:13:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:13:06 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 13.321 | nll_loss 12.681 | ppl 6568.58 | wps 40944.9 | wpb 510.9 | bsz 1 | num_updates 14602 | best_loss 8.937
2022-03-07 00:13:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 300 @ 14602 updates
2022-03-07 00:13:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:13:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:13:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 300 @ 14602 updates, score 13.321) (writing took 2.395306891296059 seconds)
2022-03-07 00:13:08 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)
2022-03-07 00:13:08 | INFO | train | epoch 300 | loss 2.227 | nll_loss 0.429 | ppl 1.35 | wps 23262.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14602 | lr 0.000261694 | gnorm 0.497 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 40233
2022-03-07 00:13:08 | INFO | fairseq.trainer | begin training epoch 301
2022-03-07 00:13:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:14:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:15:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:15:23 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 13.32 | nll_loss 12.682 | ppl 6573.37 | wps 40851.4 | wpb 510.9 | bsz 1 | num_updates 14650 | best_loss 8.937
2022-03-07 00:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 301 @ 14650 updates
2022-03-07 00:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:15:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:15:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 301 @ 14650 updates, score 13.32) (writing took 2.5542398327961564 seconds)
2022-03-07 00:15:25 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)
2022-03-07 00:15:25 | INFO | train | epoch 301 | loss 2.226 | nll_loss 0.428 | ppl 1.35 | wps 22767.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 14650 | lr 0.000261265 | gnorm 0.492 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 40370
2022-03-07 00:15:25 | INFO | fairseq.trainer | begin training epoch 302
2022-03-07 00:15:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:17:38 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 13.218 | nll_loss 12.567 | ppl 6069.34 | wps 42943.2 | wpb 510.9 | bsz 1 | num_updates 14699 | best_loss 8.937
2022-03-07 00:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 302 @ 14699 updates
2022-03-07 00:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 302 @ 14699 updates, score 13.218) (writing took 2.525935939978808 seconds)
2022-03-07 00:17:41 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)
2022-03-07 00:17:41 | INFO | train | epoch 302 | loss 2.226 | nll_loss 0.428 | ppl 1.35 | wps 23452.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14699 | lr 0.000260829 | gnorm 0.507 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 40505
2022-03-07 00:17:41 | INFO | fairseq.trainer | begin training epoch 303
2022-03-07 00:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:17:43 | INFO | train_inner | epoch 303:      1 / 49 loss=2.226, nll_loss=0.428, ppl=1.35, wps=22517.9, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=14700, lr=0.00026082, gnorm=0.5, loss_scale=32, train_wall=238, gb_free=8.8, wall=40508
2022-03-07 00:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:19:52 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 13.183 | nll_loss 12.532 | ppl 5924.26 | wps 41824.2 | wpb 510.9 | bsz 1 | num_updates 14748 | best_loss 8.937
2022-03-07 00:19:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 303 @ 14748 updates
2022-03-07 00:19:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 303 @ 14748 updates, score 13.183) (writing took 2.4469394362531602 seconds)
2022-03-07 00:19:55 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)
2022-03-07 00:19:55 | INFO | train | epoch 303 | loss 2.223 | nll_loss 0.425 | ppl 1.34 | wps 23679.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14748 | lr 0.000260395 | gnorm 0.498 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 40640
2022-03-07 00:19:55 | INFO | fairseq.trainer | begin training epoch 304
2022-03-07 00:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:20:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:22:07 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 13.245 | nll_loss 12.604 | ppl 6226.23 | wps 42192.2 | wpb 510.9 | bsz 1 | num_updates 14796 | best_loss 8.937
2022-03-07 00:22:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 304 @ 14796 updates
2022-03-07 00:22:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:22:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:22:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 304 @ 14796 updates, score 13.245) (writing took 2.4408750431612134 seconds)
2022-03-07 00:22:09 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)
2022-03-07 00:22:09 | INFO | train | epoch 304 | loss 2.222 | nll_loss 0.425 | ppl 1.34 | wps 23195.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 14796 | lr 0.000259973 | gnorm 0.49 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 40774
2022-03-07 00:22:09 | INFO | fairseq.trainer | begin training epoch 305
2022-03-07 00:22:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:22:20 | INFO | train_inner | epoch 305:      4 / 49 loss=2.223, nll_loss=0.425, ppl=1.34, wps=23488.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=14800, lr=0.000259938, gnorm=0.494, loss_scale=32, train_wall=235, gb_free=8.8, wall=40784
2022-03-07 00:24:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:24:21 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 13.265 | nll_loss 12.62 | ppl 6294.39 | wps 41878.1 | wpb 510.9 | bsz 1 | num_updates 14845 | best_loss 8.937
2022-03-07 00:24:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 305 @ 14845 updates
2022-03-07 00:24:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:24:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 305 @ 14845 updates, score 13.265) (writing took 2.3795655528083444 seconds)
2022-03-07 00:24:23 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)
2022-03-07 00:24:23 | INFO | train | epoch 305 | loss 2.222 | nll_loss 0.424 | ppl 1.34 | wps 23707.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 14845 | lr 0.000259543 | gnorm 0.491 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 40908
2022-03-07 00:24:23 | INFO | fairseq.trainer | begin training epoch 306
2022-03-07 00:24:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:26:35 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 13.358 | nll_loss 12.715 | ppl 6725.26 | wps 42319.8 | wpb 510.9 | bsz 1 | num_updates 14893 | best_loss 8.937
2022-03-07 00:26:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 306 @ 14893 updates
2022-03-07 00:26:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:26:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:26:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 306 @ 14893 updates, score 13.358) (writing took 2.3588610948063433 seconds)
2022-03-07 00:26:37 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)
2022-03-07 00:26:37 | INFO | train | epoch 306 | loss 2.22 | nll_loss 0.423 | ppl 1.34 | wps 23216.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 14893 | lr 0.000259125 | gnorm 0.488 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 41042
2022-03-07 00:26:37 | INFO | fairseq.trainer | begin training epoch 307
2022-03-07 00:26:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:26:56 | INFO | train_inner | epoch 307:      7 / 49 loss=2.221, nll_loss=0.423, ppl=1.34, wps=23504.3, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=14900, lr=0.000259064, gnorm=0.49, loss_scale=32, train_wall=235, gb_free=8.8, wall=41060
2022-03-07 00:28:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:28:49 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 13.32 | nll_loss 12.677 | ppl 6547.23 | wps 40367.2 | wpb 510.9 | bsz 1 | num_updates 14942 | best_loss 8.937
2022-03-07 00:28:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 307 @ 14942 updates
2022-03-07 00:28:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:28:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:28:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 307 @ 14942 updates, score 13.32) (writing took 2.625131367240101 seconds)
2022-03-07 00:28:52 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)
2022-03-07 00:28:52 | INFO | train | epoch 307 | loss 2.22 | nll_loss 0.423 | ppl 1.34 | wps 23633.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14942 | lr 0.0002587 | gnorm 0.49 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 41176
2022-03-07 00:28:52 | INFO | fairseq.trainer | begin training epoch 308
2022-03-07 00:28:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:30:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:31:04 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 13.28 | nll_loss 12.636 | ppl 6365.51 | wps 40563.2 | wpb 510.9 | bsz 1 | num_updates 14991 | best_loss 8.937
2022-03-07 00:31:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 308 @ 14991 updates
2022-03-07 00:31:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:31:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:31:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 308 @ 14991 updates, score 13.28) (writing took 2.3998375688679516 seconds)
2022-03-07 00:31:06 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)
2022-03-07 00:31:06 | INFO | train | epoch 308 | loss 2.219 | nll_loss 0.423 | ppl 1.34 | wps 23600.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 14991 | lr 0.000258276 | gnorm 0.495 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 41311
2022-03-07 00:31:06 | INFO | fairseq.trainer | begin training epoch 309
2022-03-07 00:31:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:31:30 | INFO | train_inner | epoch 309:      9 / 49 loss=2.219, nll_loss=0.422, ppl=1.34, wps=23613.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=15000, lr=0.000258199, gnorm=0.492, loss_scale=32, train_wall=234, gb_free=8.8, wall=41335
2022-03-07 00:32:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:33:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:33:21 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 13.182 | nll_loss 12.533 | ppl 5928.05 | wps 40810 | wpb 510.9 | bsz 1 | num_updates 15039 | best_loss 8.937
2022-03-07 00:33:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 309 @ 15039 updates
2022-03-07 00:33:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:33:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:33:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 309 @ 15039 updates, score 13.182) (writing took 2.4862697441130877 seconds)
2022-03-07 00:33:23 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)
2022-03-07 00:33:23 | INFO | train | epoch 309 | loss 2.217 | nll_loss 0.421 | ppl 1.34 | wps 22766.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15039 | lr 0.000257864 | gnorm 0.495 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 41448
2022-03-07 00:33:23 | INFO | fairseq.trainer | begin training epoch 310
2022-03-07 00:33:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:35:37 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 13.272 | nll_loss 12.627 | ppl 6325.22 | wps 41056.7 | wpb 510.9 | bsz 1 | num_updates 15088 | best_loss 8.937
2022-03-07 00:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 310 @ 15088 updates
2022-03-07 00:35:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:35:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 310 @ 15088 updates, score 13.272) (writing took 2.3945937417447567 seconds)
2022-03-07 00:35:40 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)
2022-03-07 00:35:40 | INFO | train | epoch 310 | loss 2.217 | nll_loss 0.42 | ppl 1.34 | wps 23255.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15088 | lr 0.000257445 | gnorm 0.484 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 41584
2022-03-07 00:35:40 | INFO | fairseq.trainer | begin training epoch 311
2022-03-07 00:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:36:12 | INFO | train_inner | epoch 311:     12 / 49 loss=2.217, nll_loss=0.421, ppl=1.34, wps=23059, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15100, lr=0.000257343, gnorm=0.489, loss_scale=32, train_wall=240, gb_free=8.8, wall=41616
2022-03-07 00:37:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:37:53 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 13.405 | nll_loss 12.774 | ppl 7006.13 | wps 41282.8 | wpb 510.9 | bsz 1 | num_updates 15137 | best_loss 8.937
2022-03-07 00:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 311 @ 15137 updates
2022-03-07 00:37:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:37:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 311 @ 15137 updates, score 13.405) (writing took 2.389003320131451 seconds)
2022-03-07 00:37:56 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)
2022-03-07 00:37:56 | INFO | train | epoch 311 | loss 2.216 | nll_loss 0.42 | ppl 1.34 | wps 23369.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15137 | lr 0.000257028 | gnorm 0.496 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 41720
2022-03-07 00:37:56 | INFO | fairseq.trainer | begin training epoch 312
2022-03-07 00:37:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:38:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:40:09 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 13.284 | nll_loss 12.639 | ppl 6379.61 | wps 40658.7 | wpb 510.9 | bsz 1 | num_updates 15185 | best_loss 8.937
2022-03-07 00:40:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 312 @ 15185 updates
2022-03-07 00:40:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:40:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:40:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 312 @ 15185 updates, score 13.284) (writing took 2.4747148170135915 seconds)
2022-03-07 00:40:12 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)
2022-03-07 00:40:12 | INFO | train | epoch 312 | loss 2.213 | nll_loss 0.418 | ppl 1.34 | wps 22846.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15185 | lr 0.000256621 | gnorm 0.491 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 41857
2022-03-07 00:40:12 | INFO | fairseq.trainer | begin training epoch 313
2022-03-07 00:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:40:51 | INFO | train_inner | epoch 313:     15 / 49 loss=2.214, nll_loss=0.418, ppl=1.34, wps=23181.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15200, lr=0.000256495, gnorm=0.492, loss_scale=32, train_wall=238, gb_free=8.8, wall=41896
2022-03-07 00:42:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:42:25 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 13.312 | nll_loss 12.679 | ppl 6556.32 | wps 40881.7 | wpb 510.9 | bsz 1 | num_updates 15234 | best_loss 8.937
2022-03-07 00:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 313 @ 15234 updates
2022-03-07 00:42:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:42:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 313 @ 15234 updates, score 13.312) (writing took 2.4233180340379477 seconds)
2022-03-07 00:42:28 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)
2022-03-07 00:42:28 | INFO | train | epoch 313 | loss 2.213 | nll_loss 0.418 | ppl 1.34 | wps 23416 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15234 | lr 0.000256208 | gnorm 0.485 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 41992
2022-03-07 00:42:28 | INFO | fairseq.trainer | begin training epoch 314
2022-03-07 00:42:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:44:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:44:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:44:42 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 13.277 | nll_loss 12.636 | ppl 6365.77 | wps 39791.6 | wpb 510.9 | bsz 1 | num_updates 15282 | best_loss 8.937
2022-03-07 00:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 314 @ 15282 updates
2022-03-07 00:44:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:44:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 314 @ 15282 updates, score 13.277) (writing took 2.4558979752473533 seconds)
2022-03-07 00:44:45 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)
2022-03-07 00:44:45 | INFO | train | epoch 314 | loss 2.211 | nll_loss 0.416 | ppl 1.33 | wps 22709.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15282 | lr 0.000255806 | gnorm 0.483 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 42129
2022-03-07 00:44:45 | INFO | fairseq.trainer | begin training epoch 315
2022-03-07 00:44:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:45:33 | INFO | train_inner | epoch 315:     18 / 49 loss=2.212, nll_loss=0.416, ppl=1.33, wps=23078.7, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=15300, lr=0.000255655, gnorm=0.483, loss_scale=32, train_wall=239, gb_free=8.8, wall=42177
2022-03-07 00:46:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:46:59 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 13.275 | nll_loss 12.637 | ppl 6368.04 | wps 40715.7 | wpb 510.9 | bsz 1 | num_updates 15331 | best_loss 8.937
2022-03-07 00:46:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 315 @ 15331 updates
2022-03-07 00:46:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 315 @ 15331 updates, score 13.275) (writing took 2.4662572788074613 seconds)
2022-03-07 00:47:01 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)
2022-03-07 00:47:01 | INFO | train | epoch 315 | loss 2.211 | nll_loss 0.416 | ppl 1.33 | wps 23243.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15331 | lr 0.000255396 | gnorm 0.487 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 42266
2022-03-07 00:47:01 | INFO | fairseq.trainer | begin training epoch 316
2022-03-07 00:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:49:16 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 13.266 | nll_loss 12.619 | ppl 6292.02 | wps 39594.7 | wpb 510.9 | bsz 1 | num_updates 15380 | best_loss 8.937
2022-03-07 00:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 316 @ 15380 updates
2022-03-07 00:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:49:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 316 @ 15380 updates, score 13.266) (writing took 2.6184762329794466 seconds)
2022-03-07 00:49:18 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)
2022-03-07 00:49:18 | INFO | train | epoch 316 | loss 2.211 | nll_loss 0.416 | ppl 1.33 | wps 23195.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15380 | lr 0.000254989 | gnorm 0.489 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 42403
2022-03-07 00:49:18 | INFO | fairseq.trainer | begin training epoch 317
2022-03-07 00:49:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:50:12 | INFO | train_inner | epoch 317:     20 / 49 loss=2.211, nll_loss=0.416, ppl=1.33, wps=23253.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15400, lr=0.000254824, gnorm=0.487, loss_scale=32, train_wall=237, gb_free=8.8, wall=42456
2022-03-07 00:50:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:51:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:51:33 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 13.296 | nll_loss 12.655 | ppl 6451.58 | wps 40362.2 | wpb 510.9 | bsz 1 | num_updates 15428 | best_loss 8.937
2022-03-07 00:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 317 @ 15428 updates
2022-03-07 00:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 317 @ 15428 updates, score 13.296) (writing took 2.3732935269363225 seconds)
2022-03-07 00:51:35 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)
2022-03-07 00:51:35 | INFO | train | epoch 317 | loss 2.209 | nll_loss 0.415 | ppl 1.33 | wps 22800.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15428 | lr 0.000254592 | gnorm 0.483 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 42540
2022-03-07 00:51:35 | INFO | fairseq.trainer | begin training epoch 318
2022-03-07 00:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:53:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:53:49 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 13.298 | nll_loss 12.66 | ppl 6473.86 | wps 40498.5 | wpb 510.9 | bsz 1 | num_updates 15477 | best_loss 8.937
2022-03-07 00:53:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 318 @ 15477 updates
2022-03-07 00:53:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:53:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 318 @ 15477 updates, score 13.298) (writing took 2.450868973042816 seconds)
2022-03-07 00:53:52 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)
2022-03-07 00:53:52 | INFO | train | epoch 318 | loss 2.209 | nll_loss 0.414 | ppl 1.33 | wps 23229.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15477 | lr 0.000254189 | gnorm 0.491 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 42677
2022-03-07 00:53:52 | INFO | fairseq.trainer | begin training epoch 319
2022-03-07 00:53:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:54:52 | INFO | train_inner | epoch 319:     23 / 49 loss=2.208, nll_loss=0.414, ppl=1.33, wps=23143.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15500, lr=0.000254, gnorm=0.487, loss_scale=32, train_wall=239, gb_free=8.8, wall=42737
2022-03-07 00:55:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:56:04 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 13.206 | nll_loss 12.568 | ppl 6072.16 | wps 41924.9 | wpb 510.9 | bsz 1 | num_updates 15526 | best_loss 8.937
2022-03-07 00:56:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 319 @ 15526 updates
2022-03-07 00:56:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:56:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:56:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 319 @ 15526 updates, score 13.206) (writing took 2.3282980490475893 seconds)
2022-03-07 00:56:06 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)
2022-03-07 00:56:06 | INFO | train | epoch 319 | loss 2.207 | nll_loss 0.413 | ppl 1.33 | wps 23679.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15526 | lr 0.000253787 | gnorm 0.482 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 42811
2022-03-07 00:56:06 | INFO | fairseq.trainer | begin training epoch 320
2022-03-07 00:56:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:56:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 00:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 00:58:18 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 13.312 | nll_loss 12.674 | ppl 6533.04 | wps 42276.5 | wpb 510.9 | bsz 1 | num_updates 15574 | best_loss 8.937
2022-03-07 00:58:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 320 @ 15574 updates
2022-03-07 00:58:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 00:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 320 @ 15574 updates, score 13.312) (writing took 2.3963036881759763 seconds)
2022-03-07 00:58:20 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)
2022-03-07 00:58:20 | INFO | train | epoch 320 | loss 2.206 | nll_loss 0.412 | ppl 1.33 | wps 23190.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 15574 | lr 0.000253396 | gnorm 0.481 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 42945
2022-03-07 00:58:20 | INFO | fairseq.trainer | begin training epoch 321
2022-03-07 00:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 00:59:28 | INFO | train_inner | epoch 321:     26 / 49 loss=2.207, nll_loss=0.413, ppl=1.33, wps=23482.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15600, lr=0.000253185, gnorm=0.483, loss_scale=32, train_wall=236, gb_free=8.8, wall=43013
2022-03-07 01:00:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:00:32 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 13.33 | nll_loss 12.696 | ppl 6634.58 | wps 41090.4 | wpb 510.9 | bsz 1 | num_updates 15623 | best_loss 8.937
2022-03-07 01:00:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 321 @ 15623 updates
2022-03-07 01:00:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 321 @ 15623 updates, score 13.33) (writing took 2.4873163388110697 seconds)
2022-03-07 01:00:35 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)
2022-03-07 01:00:35 | INFO | train | epoch 321 | loss 2.206 | nll_loss 0.412 | ppl 1.33 | wps 23644.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15623 | lr 0.000252998 | gnorm 0.483 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 43079
2022-03-07 01:00:35 | INFO | fairseq.trainer | begin training epoch 322
2022-03-07 01:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:02:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:02:46 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 13.284 | nll_loss 12.647 | ppl 6413.26 | wps 41915.9 | wpb 510.9 | bsz 1 | num_updates 15671 | best_loss 8.937
2022-03-07 01:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 322 @ 15671 updates
2022-03-07 01:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 322 @ 15671 updates, score 13.284) (writing took 2.401335811242461 seconds)
2022-03-07 01:02:49 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)
2022-03-07 01:02:49 | INFO | train | epoch 322 | loss 2.204 | nll_loss 0.41 | ppl 1.33 | wps 23225 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 15671 | lr 0.000252611 | gnorm 0.48 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 43213
2022-03-07 01:02:49 | INFO | fairseq.trainer | begin training epoch 323
2022-03-07 01:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:04:04 | INFO | train_inner | epoch 323:     29 / 49 loss=2.204, nll_loss=0.41, ppl=1.33, wps=23491.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=15700, lr=0.000252377, gnorm=0.479, loss_scale=32, train_wall=235, gb_free=8.8, wall=43289
2022-03-07 01:04:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:05:00 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 13.26 | nll_loss 12.619 | ppl 6289.22 | wps 40848.7 | wpb 510.9 | bsz 1 | num_updates 15720 | best_loss 8.937
2022-03-07 01:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 323 @ 15720 updates
2022-03-07 01:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 323 @ 15720 updates, score 13.26) (writing took 2.4033044050447643 seconds)
2022-03-07 01:05:03 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)
2022-03-07 01:05:03 | INFO | train | epoch 323 | loss 2.203 | nll_loss 0.41 | ppl 1.33 | wps 23688.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15720 | lr 0.000252217 | gnorm 0.484 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 43348
2022-03-07 01:05:03 | INFO | fairseq.trainer | begin training epoch 324
2022-03-07 01:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:07:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:07:14 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 13.388 | nll_loss 12.76 | ppl 6937.45 | wps 41998.4 | wpb 510.9 | bsz 1 | num_updates 15769 | best_loss 8.937
2022-03-07 01:07:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 324 @ 15769 updates
2022-03-07 01:07:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:07:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:07:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 324 @ 15769 updates, score 13.388) (writing took 2.477673049084842 seconds)
2022-03-07 01:07:17 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)
2022-03-07 01:07:17 | INFO | train | epoch 324 | loss 2.202 | nll_loss 0.409 | ppl 1.33 | wps 23731.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 15769 | lr 0.000251824 | gnorm 0.485 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 43481
2022-03-07 01:07:17 | INFO | fairseq.trainer | begin training epoch 325
2022-03-07 01:07:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:08:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:08:41 | INFO | train_inner | epoch 325:     32 / 49 loss=2.203, nll_loss=0.409, ppl=1.33, wps=23431.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15800, lr=0.000251577, gnorm=0.484, loss_scale=32, train_wall=236, gb_free=8.8, wall=43566
2022-03-07 01:09:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:09:30 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 13.314 | nll_loss 12.678 | ppl 6555.47 | wps 40039.5 | wpb 510.9 | bsz 1 | num_updates 15817 | best_loss 8.937
2022-03-07 01:09:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 325 @ 15817 updates
2022-03-07 01:09:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:09:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:09:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 325 @ 15817 updates, score 13.314) (writing took 2.4962980337440968 seconds)
2022-03-07 01:09:33 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)
2022-03-07 01:09:33 | INFO | train | epoch 325 | loss 2.201 | nll_loss 0.408 | ppl 1.33 | wps 22873.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15817 | lr 0.000251442 | gnorm 0.476 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 43618
2022-03-07 01:09:33 | INFO | fairseq.trainer | begin training epoch 326
2022-03-07 01:09:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:11:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:11:47 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 13.405 | nll_loss 12.778 | ppl 7023.05 | wps 39975.4 | wpb 510.9 | bsz 1 | num_updates 15866 | best_loss 8.937
2022-03-07 01:11:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 326 @ 15866 updates
2022-03-07 01:11:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:11:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:11:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 326 @ 15866 updates, score 13.405) (writing took 2.574395307339728 seconds)
2022-03-07 01:11:50 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)
2022-03-07 01:11:50 | INFO | train | epoch 326 | loss 2.201 | nll_loss 0.408 | ppl 1.33 | wps 23177 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15866 | lr 0.000251053 | gnorm 0.483 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 43755
2022-03-07 01:11:50 | INFO | fairseq.trainer | begin training epoch 327
2022-03-07 01:11:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:13:20 | INFO | train_inner | epoch 327:     34 / 49 loss=2.2, nll_loss=0.408, ppl=1.33, wps=23246, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=15900, lr=0.000250785, gnorm=0.482, loss_scale=32, train_wall=237, gb_free=8.8, wall=43845
2022-03-07 01:13:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:14:04 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 13.363 | nll_loss 12.733 | ppl 6807.45 | wps 40224.1 | wpb 510.9 | bsz 1 | num_updates 15915 | best_loss 8.937
2022-03-07 01:14:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 327 @ 15915 updates
2022-03-07 01:14:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:14:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:14:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 327 @ 15915 updates, score 13.363) (writing took 2.4542995849624276 seconds)
2022-03-07 01:14:07 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)
2022-03-07 01:14:07 | INFO | train | epoch 327 | loss 2.2 | nll_loss 0.407 | ppl 1.33 | wps 23242.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 15915 | lr 0.000250667 | gnorm 0.484 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 43891
2022-03-07 01:14:07 | INFO | fairseq.trainer | begin training epoch 328
2022-03-07 01:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:14:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:16:21 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 13.242 | nll_loss 12.601 | ppl 6210.96 | wps 40206.8 | wpb 510.9 | bsz 1 | num_updates 15963 | best_loss 8.937
2022-03-07 01:16:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 328 @ 15963 updates
2022-03-07 01:16:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:16:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 328 @ 15963 updates, score 13.242) (writing took 2.42205108422786 seconds)
2022-03-07 01:16:23 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)
2022-03-07 01:16:23 | INFO | train | epoch 328 | loss 2.199 | nll_loss 0.406 | ppl 1.33 | wps 22747.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 15963 | lr 0.00025029 | gnorm 0.476 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44028
2022-03-07 01:16:23 | INFO | fairseq.trainer | begin training epoch 329
2022-03-07 01:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:18:02 | INFO | train_inner | epoch 329:     37 / 49 loss=2.199, nll_loss=0.406, ppl=1.33, wps=23042.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16000, lr=0.00025, gnorm=0.477, loss_scale=32, train_wall=240, gb_free=8.8, wall=44126
2022-03-07 01:18:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:18:38 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 13.254 | nll_loss 12.618 | ppl 6284.25 | wps 40350.7 | wpb 510.9 | bsz 1 | num_updates 16012 | best_loss 8.937
2022-03-07 01:18:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 329 @ 16012 updates
2022-03-07 01:18:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:18:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:18:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 329 @ 16012 updates, score 13.254) (writing took 2.375669276807457 seconds)
2022-03-07 01:18:40 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)
2022-03-07 01:18:40 | INFO | train | epoch 329 | loss 2.198 | nll_loss 0.405 | ppl 1.32 | wps 23268 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16012 | lr 0.000249906 | gnorm 0.477 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44165
2022-03-07 01:18:40 | INFO | fairseq.trainer | begin training epoch 330
2022-03-07 01:18:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:20:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:20:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:20:55 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 13.306 | nll_loss 12.676 | ppl 6542.62 | wps 38983.2 | wpb 510.9 | bsz 1 | num_updates 16060 | best_loss 8.937
2022-03-07 01:20:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 330 @ 16060 updates
2022-03-07 01:20:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:20:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:20:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 330 @ 16060 updates, score 13.306) (writing took 2.486944089643657 seconds)
2022-03-07 01:20:57 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)
2022-03-07 01:20:57 | INFO | train | epoch 330 | loss 2.197 | nll_loss 0.404 | ppl 1.32 | wps 22687.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16060 | lr 0.000249533 | gnorm 0.48 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44302
2022-03-07 01:20:57 | INFO | fairseq.trainer | begin training epoch 331
2022-03-07 01:20:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:22:44 | INFO | train_inner | epoch 331:     40 / 49 loss=2.197, nll_loss=0.405, ppl=1.32, wps=23017.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=16100, lr=0.000249222, gnorm=0.478, loss_scale=32, train_wall=240, gb_free=8.8, wall=44408
2022-03-07 01:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:23:12 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 13.254 | nll_loss 12.616 | ppl 6277.35 | wps 40047.6 | wpb 510.9 | bsz 1 | num_updates 16109 | best_loss 8.937
2022-03-07 01:23:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 331 @ 16109 updates
2022-03-07 01:23:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:23:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 331 @ 16109 updates, score 13.254) (writing took 2.5204069390892982 seconds)
2022-03-07 01:23:14 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)
2022-03-07 01:23:14 | INFO | train | epoch 331 | loss 2.196 | nll_loss 0.404 | ppl 1.32 | wps 23219.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16109 | lr 0.000249153 | gnorm 0.474 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44439
2022-03-07 01:23:14 | INFO | fairseq.trainer | begin training epoch 332
2022-03-07 01:23:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:25:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:25:29 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 13.349 | nll_loss 12.72 | ppl 6748.94 | wps 40328.7 | wpb 510.9 | bsz 1 | num_updates 16158 | best_loss 8.937
2022-03-07 01:25:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 332 @ 16158 updates
2022-03-07 01:25:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:25:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:25:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 332 @ 16158 updates, score 13.349) (writing took 2.5562542639672756 seconds)
2022-03-07 01:25:31 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)
2022-03-07 01:25:31 | INFO | train | epoch 332 | loss 2.195 | nll_loss 0.403 | ppl 1.32 | wps 23163.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16158 | lr 0.000248775 | gnorm 0.479 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 44576
2022-03-07 01:25:31 | INFO | fairseq.trainer | begin training epoch 333
2022-03-07 01:25:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:26:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:27:26 | INFO | train_inner | epoch 333:     43 / 49 loss=2.195, nll_loss=0.403, ppl=1.32, wps=23003.9, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=16200, lr=0.000248452, gnorm=0.474, loss_scale=32, train_wall=240, gb_free=8.8, wall=44690
2022-03-07 01:27:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:27:46 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 13.209 | nll_loss 12.568 | ppl 6073.6 | wps 40319.8 | wpb 510.9 | bsz 1 | num_updates 16206 | best_loss 8.937
2022-03-07 01:27:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 333 @ 16206 updates
2022-03-07 01:27:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:27:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:27:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 333 @ 16206 updates, score 13.209) (writing took 2.4757253886200488 seconds)
2022-03-07 01:27:48 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)
2022-03-07 01:27:48 | INFO | train | epoch 333 | loss 2.193 | nll_loss 0.401 | ppl 1.32 | wps 22755.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16206 | lr 0.000248406 | gnorm 0.469 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44713
2022-03-07 01:27:48 | INFO | fairseq.trainer | begin training epoch 334
2022-03-07 01:27:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:30:02 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 13.209 | nll_loss 12.571 | ppl 6083.85 | wps 40975.8 | wpb 510.9 | bsz 1 | num_updates 16255 | best_loss 8.937
2022-03-07 01:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 334 @ 16255 updates
2022-03-07 01:30:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:30:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 334 @ 16255 updates, score 13.209) (writing took 2.5223433459177613 seconds)
2022-03-07 01:30:05 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)
2022-03-07 01:30:05 | INFO | train | epoch 334 | loss 2.193 | nll_loss 0.401 | ppl 1.32 | wps 23269.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16255 | lr 0.000248031 | gnorm 0.471 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44849
2022-03-07 01:30:05 | INFO | fairseq.trainer | begin training epoch 335
2022-03-07 01:30:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:04 | INFO | train_inner | epoch 335:     45 / 49 loss=2.192, nll_loss=0.401, ppl=1.32, wps=23331.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16300, lr=0.000247689, gnorm=0.473, loss_scale=32, train_wall=237, gb_free=8.8, wall=44968
2022-03-07 01:32:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:32:18 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 13.215 | nll_loss 12.579 | ppl 6120.14 | wps 41648.1 | wpb 510.9 | bsz 1 | num_updates 16304 | best_loss 8.937
2022-03-07 01:32:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 335 @ 16304 updates
2022-03-07 01:32:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:32:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:32:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 335 @ 16304 updates, score 13.215) (writing took 2.7337623592466116 seconds)
2022-03-07 01:32:21 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)
2022-03-07 01:32:21 | INFO | train | epoch 335 | loss 2.192 | nll_loss 0.401 | ppl 1.32 | wps 23342.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16304 | lr 0.000247658 | gnorm 0.476 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 44986
2022-03-07 01:32:21 | INFO | fairseq.trainer | begin training epoch 336
2022-03-07 01:32:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:32:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:34:34 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 13.275 | nll_loss 12.639 | ppl 6377.29 | wps 40923.5 | wpb 510.9 | bsz 1 | num_updates 16352 | best_loss 8.937
2022-03-07 01:34:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 336 @ 16352 updates
2022-03-07 01:34:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:34:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:34:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 336 @ 16352 updates, score 13.275) (writing took 2.5193743938580155 seconds)
2022-03-07 01:34:36 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)
2022-03-07 01:34:36 | INFO | train | epoch 336 | loss 2.19 | nll_loss 0.399 | ppl 1.32 | wps 22954.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16352 | lr 0.000247295 | gnorm 0.475 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 45121
2022-03-07 01:34:36 | INFO | fairseq.trainer | begin training epoch 337
2022-03-07 01:34:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:36:44 | INFO | train_inner | epoch 337:     48 / 49 loss=2.19, nll_loss=0.399, ppl=1.32, wps=23169.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16400, lr=0.000246932, gnorm=0.472, loss_scale=32, train_wall=238, gb_free=8.8, wall=45248
2022-03-07 01:36:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:36:50 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 13.253 | nll_loss 12.611 | ppl 6257.38 | wps 40518.3 | wpb 510.9 | bsz 1 | num_updates 16401 | best_loss 8.937
2022-03-07 01:36:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 337 @ 16401 updates
2022-03-07 01:36:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:36:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:36:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 337 @ 16401 updates, score 13.253) (writing took 2.447989366017282 seconds)
2022-03-07 01:36:53 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)
2022-03-07 01:36:53 | INFO | train | epoch 337 | loss 2.19 | nll_loss 0.399 | ppl 1.32 | wps 23299.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16401 | lr 0.000246925 | gnorm 0.469 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45258
2022-03-07 01:36:53 | INFO | fairseq.trainer | begin training epoch 338
2022-03-07 01:36:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:38:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:39:07 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 13.226 | nll_loss 12.589 | ppl 6160.26 | wps 40618.3 | wpb 510.9 | bsz 1 | num_updates 16449 | best_loss 8.937
2022-03-07 01:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 338 @ 16449 updates
2022-03-07 01:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 338 @ 16449 updates, score 13.226) (writing took 2.530761791858822 seconds)
2022-03-07 01:39:09 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)
2022-03-07 01:39:09 | INFO | train | epoch 338 | loss 2.189 | nll_loss 0.398 | ppl 1.32 | wps 22775.2 | ups 0.35 | wpb 64853.3 | bsz 126.7 | num_updates 16449 | lr 0.000246564 | gnorm 0.472 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45394
2022-03-07 01:39:10 | INFO | fairseq.trainer | begin training epoch 339
2022-03-07 01:39:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:41:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:41:24 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 13.278 | nll_loss 12.643 | ppl 6394.79 | wps 39426 | wpb 510.9 | bsz 1 | num_updates 16498 | best_loss 8.937
2022-03-07 01:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 339 @ 16498 updates
2022-03-07 01:41:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:41:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:41:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 339 @ 16498 updates, score 13.278) (writing took 2.46860090829432 seconds)
2022-03-07 01:41:26 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)
2022-03-07 01:41:26 | INFO | train | epoch 339 | loss 2.188 | nll_loss 0.398 | ppl 1.32 | wps 23267.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16498 | lr 0.000246198 | gnorm 0.465 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45531
2022-03-07 01:41:26 | INFO | fairseq.trainer | begin training epoch 340
2022-03-07 01:41:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:41:32 | INFO | train_inner | epoch 340:      2 / 49 loss=2.189, nll_loss=0.398, ppl=1.32, wps=22417.1, ups=0.35, wpb=64548.5, bsz=126.1, num_updates=16500, lr=0.000246183, gnorm=0.47, loss_scale=32, train_wall=238, gb_free=8.8, wall=45536
2022-03-07 01:43:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:43:40 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 13.23 | nll_loss 12.594 | ppl 6181.93 | wps 42223.1 | wpb 510.9 | bsz 1 | num_updates 16547 | best_loss 8.937
2022-03-07 01:43:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 340 @ 16547 updates
2022-03-07 01:43:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:43:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:43:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 340 @ 16547 updates, score 13.23) (writing took 2.4358672848902643 seconds)
2022-03-07 01:43:43 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)
2022-03-07 01:43:43 | INFO | train | epoch 340 | loss 2.187 | nll_loss 0.397 | ppl 1.32 | wps 23293 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16547 | lr 0.000245833 | gnorm 0.469 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45667
2022-03-07 01:43:43 | INFO | fairseq.trainer | begin training epoch 341
2022-03-07 01:43:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:44:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:45:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:45:56 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 13.391 | nll_loss 12.769 | ppl 6979.55 | wps 41242 | wpb 510.9 | bsz 1 | num_updates 16595 | best_loss 8.937
2022-03-07 01:45:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 341 @ 16595 updates
2022-03-07 01:45:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 341 @ 16595 updates, score 13.391) (writing took 2.4146873243153095 seconds)
2022-03-07 01:45:59 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)
2022-03-07 01:45:59 | INFO | train | epoch 341 | loss 2.187 | nll_loss 0.397 | ppl 1.32 | wps 22846.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16595 | lr 0.000245477 | gnorm 0.471 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45804
2022-03-07 01:45:59 | INFO | fairseq.trainer | begin training epoch 342
2022-03-07 01:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:46:12 | INFO | train_inner | epoch 342:      5 / 49 loss=2.187, nll_loss=0.397, ppl=1.32, wps=23121.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16600, lr=0.00024544, gnorm=0.47, loss_scale=32, train_wall=239, gb_free=8.8, wall=45817
2022-03-07 01:48:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:48:13 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 13.207 | nll_loss 12.565 | ppl 6057.71 | wps 40963.3 | wpb 510.9 | bsz 1 | num_updates 16644 | best_loss 8.937
2022-03-07 01:48:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 342 @ 16644 updates
2022-03-07 01:48:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:48:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:48:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 342 @ 16644 updates, score 13.207) (writing took 2.4462928092107177 seconds)
2022-03-07 01:48:15 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)
2022-03-07 01:48:15 | INFO | train | epoch 342 | loss 2.186 | nll_loss 0.396 | ppl 1.32 | wps 23330.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16644 | lr 0.000245116 | gnorm 0.469 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 45940
2022-03-07 01:48:15 | INFO | fairseq.trainer | begin training epoch 343
2022-03-07 01:48:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:50:29 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 13.307 | nll_loss 12.678 | ppl 6555.28 | wps 40499.9 | wpb 510.9 | bsz 1 | num_updates 16693 | best_loss 8.937
2022-03-07 01:50:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 343 @ 16693 updates
2022-03-07 01:50:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:50:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:50:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 343 @ 16693 updates, score 13.307) (writing took 2.4282353846356273 seconds)
2022-03-07 01:50:31 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)
2022-03-07 01:50:31 | INFO | train | epoch 343 | loss 2.185 | nll_loss 0.395 | ppl 1.31 | wps 23307.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16693 | lr 0.000244756 | gnorm 0.467 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 46076
2022-03-07 01:50:31 | INFO | fairseq.trainer | begin training epoch 344
2022-03-07 01:50:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:50:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:50:53 | INFO | train_inner | epoch 344:      8 / 49 loss=2.185, nll_loss=0.395, ppl=1.32, wps=23113.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16700, lr=0.000244704, gnorm=0.468, loss_scale=32, train_wall=239, gb_free=8.8, wall=46098
2022-03-07 01:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:52:45 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 13.312 | nll_loss 12.68 | ppl 6562.6 | wps 40524.6 | wpb 510.9 | bsz 1 | num_updates 16741 | best_loss 8.937
2022-03-07 01:52:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 344 @ 16741 updates
2022-03-07 01:52:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:52:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:52:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 344 @ 16741 updates, score 13.312) (writing took 2.4958084947429597 seconds)
2022-03-07 01:52:48 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)
2022-03-07 01:52:48 | INFO | train | epoch 344 | loss 2.184 | nll_loss 0.395 | ppl 1.31 | wps 22780.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16741 | lr 0.000244405 | gnorm 0.462 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 46213
2022-03-07 01:52:48 | INFO | fairseq.trainer | begin training epoch 345
2022-03-07 01:52:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:54:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:55:02 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 13.33 | nll_loss 12.695 | ppl 6630.03 | wps 40003.7 | wpb 510.9 | bsz 1 | num_updates 16790 | best_loss 8.937
2022-03-07 01:55:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 345 @ 16790 updates
2022-03-07 01:55:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:55:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:55:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 345 @ 16790 updates, score 13.33) (writing took 2.449848535005003 seconds)
2022-03-07 01:55:04 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)
2022-03-07 01:55:04 | INFO | train | epoch 345 | loss 2.183 | nll_loss 0.394 | ppl 1.31 | wps 23277.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16790 | lr 0.000244048 | gnorm 0.463 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 46349
2022-03-07 01:55:05 | INFO | fairseq.trainer | begin training epoch 346
2022-03-07 01:55:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:55:31 | INFO | train_inner | epoch 346:     10 / 49 loss=2.183, nll_loss=0.394, ppl=1.31, wps=23312.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=16800, lr=0.000243975, gnorm=0.461, loss_scale=32, train_wall=237, gb_free=8.8, wall=46376
2022-03-07 01:56:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 01:57:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:57:18 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 13.296 | nll_loss 12.664 | ppl 6489.02 | wps 40500.6 | wpb 510.9 | bsz 1 | num_updates 16838 | best_loss 8.937
2022-03-07 01:57:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 346 @ 16838 updates
2022-03-07 01:57:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 346 @ 16838 updates, score 13.296) (writing took 2.4076307928189635 seconds)
2022-03-07 01:57:21 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)
2022-03-07 01:57:21 | INFO | train | epoch 346 | loss 2.182 | nll_loss 0.393 | ppl 1.31 | wps 22870.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 16838 | lr 0.0002437 | gnorm 0.467 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 46485
2022-03-07 01:57:21 | INFO | fairseq.trainer | begin training epoch 347
2022-03-07 01:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 01:59:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 01:59:33 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 13.326 | nll_loss 12.698 | ppl 6643.35 | wps 42362.6 | wpb 510.9 | bsz 1 | num_updates 16887 | best_loss 8.937
2022-03-07 01:59:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 347 @ 16887 updates
2022-03-07 01:59:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:59:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 01:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 347 @ 16887 updates, score 13.326) (writing took 2.42133621359244 seconds)
2022-03-07 01:59:35 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)
2022-03-07 01:59:35 | INFO | train | epoch 347 | loss 2.182 | nll_loss 0.393 | ppl 1.31 | wps 23579.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 16887 | lr 0.000243346 | gnorm 0.462 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 46620
2022-03-07 01:59:35 | INFO | fairseq.trainer | begin training epoch 348
2022-03-07 01:59:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:00:09 | INFO | train_inner | epoch 348:     13 / 49 loss=2.182, nll_loss=0.393, ppl=1.31, wps=23308.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=16900, lr=0.000243252, gnorm=0.463, loss_scale=32, train_wall=237, gb_free=8.8, wall=46654
2022-03-07 02:01:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:01:47 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 13.333 | nll_loss 12.705 | ppl 6676.42 | wps 41532.9 | wpb 510.9 | bsz 1 | num_updates 16936 | best_loss 8.937
2022-03-07 02:01:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 348 @ 16936 updates
2022-03-07 02:01:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:01:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:01:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 348 @ 16936 updates, score 13.333) (writing took 2.332657853141427 seconds)
2022-03-07 02:01:49 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)
2022-03-07 02:01:49 | INFO | train | epoch 348 | loss 2.181 | nll_loss 0.392 | ppl 1.31 | wps 23717.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 16936 | lr 0.000242993 | gnorm 0.46 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 46754
2022-03-07 02:01:49 | INFO | fairseq.trainer | begin training epoch 349
2022-03-07 02:01:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:02:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:04:01 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 13.375 | nll_loss 12.747 | ppl 6872.33 | wps 42791.6 | wpb 510.9 | bsz 1 | num_updates 16984 | best_loss 8.937
2022-03-07 02:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 349 @ 16984 updates
2022-03-07 02:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:04:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 349 @ 16984 updates, score 13.375) (writing took 2.566693887580186 seconds)
2022-03-07 02:04:04 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)
2022-03-07 02:04:04 | INFO | train | epoch 349 | loss 2.179 | nll_loss 0.391 | ppl 1.31 | wps 23197.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 16984 | lr 0.00024265 | gnorm 0.461 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 46888
2022-03-07 02:04:04 | INFO | fairseq.trainer | begin training epoch 350
2022-03-07 02:04:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:04:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:04:48 | INFO | train_inner | epoch 350:     17 / 49 loss=2.18, nll_loss=0.391, ppl=1.31, wps=23288.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=17000, lr=0.000242536, gnorm=0.462, loss_scale=16, train_wall=237, gb_free=8.8, wall=46933
2022-03-07 02:06:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:06:15 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 13.261 | nll_loss 12.626 | ppl 6320.62 | wps 42522.7 | wpb 510.9 | bsz 1 | num_updates 17032 | best_loss 8.937
2022-03-07 02:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 350 @ 17032 updates
2022-03-07 02:06:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:06:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 350 @ 17032 updates, score 13.261) (writing took 2.446131878066808 seconds)
2022-03-07 02:06:18 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)
2022-03-07 02:06:18 | INFO | train | epoch 350 | loss 2.179 | nll_loss 0.391 | ppl 1.31 | wps 23212.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17032 | lr 0.000242308 | gnorm 0.462 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 47022
2022-03-07 02:06:18 | INFO | fairseq.trainer | begin training epoch 351
2022-03-07 02:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:08:29 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 13.322 | nll_loss 12.692 | ppl 6618.36 | wps 42350.1 | wpb 510.9 | bsz 1 | num_updates 17081 | best_loss 8.937
2022-03-07 02:08:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 351 @ 17081 updates
2022-03-07 02:08:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:08:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:08:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 351 @ 17081 updates, score 13.322) (writing took 2.456584297120571 seconds)
2022-03-07 02:08:32 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)
2022-03-07 02:08:32 | INFO | train | epoch 351 | loss 2.178 | nll_loss 0.39 | ppl 1.31 | wps 23700.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17081 | lr 0.00024196 | gnorm 0.458 | loss_scale 16 | train_wall 114 | gb_free 8.8 | wall 47156
2022-03-07 02:08:32 | INFO | fairseq.trainer | begin training epoch 352
2022-03-07 02:08:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:09:21 | INFO | train_inner | epoch 352:     19 / 49 loss=2.178, nll_loss=0.39, ppl=1.31, wps=23728.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=17100, lr=0.000241825, gnorm=0.457, loss_scale=16, train_wall=233, gb_free=8.8, wall=47206
2022-03-07 02:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:10:44 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 13.307 | nll_loss 12.67 | ppl 6515.88 | wps 40557.6 | wpb 510.9 | bsz 1 | num_updates 17130 | best_loss 8.937
2022-03-07 02:10:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 352 @ 17130 updates
2022-03-07 02:10:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:10:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 352 @ 17130 updates, score 13.307) (writing took 2.3650016910396516 seconds)
2022-03-07 02:10:46 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)
2022-03-07 02:10:46 | INFO | train | epoch 352 | loss 2.178 | nll_loss 0.39 | ppl 1.31 | wps 23673.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17130 | lr 0.000241614 | gnorm 0.463 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 47291
2022-03-07 02:10:46 | INFO | fairseq.trainer | begin training epoch 353
2022-03-07 02:10:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:12:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:13:00 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 13.313 | nll_loss 12.682 | ppl 6573.58 | wps 40591.6 | wpb 510.9 | bsz 1 | num_updates 17179 | best_loss 8.937
2022-03-07 02:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 353 @ 17179 updates
2022-03-07 02:13:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:13:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 353 @ 17179 updates, score 13.313) (writing took 2.5515810679644346 seconds)
2022-03-07 02:13:03 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)
2022-03-07 02:13:03 | INFO | train | epoch 353 | loss 2.178 | nll_loss 0.39 | ppl 1.31 | wps 23196.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17179 | lr 0.000241269 | gnorm 0.466 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 47428
2022-03-07 02:13:03 | INFO | fairseq.trainer | begin training epoch 354
2022-03-07 02:13:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:13:59 | INFO | train_inner | epoch 354:     21 / 49 loss=2.177, nll_loss=0.389, ppl=1.31, wps=23372.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17200, lr=0.000241121, gnorm=0.467, loss_scale=32, train_wall=236, gb_free=8.8, wall=47484
2022-03-07 02:14:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 02:15:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:15:17 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 13.312 | nll_loss 12.686 | ppl 6587.61 | wps 40030.2 | wpb 510.9 | bsz 1 | num_updates 17227 | best_loss 8.937
2022-03-07 02:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 354 @ 17227 updates
2022-03-07 02:15:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:15:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:15:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 354 @ 17227 updates, score 13.312) (writing took 2.4750715820118785 seconds)
2022-03-07 02:15:20 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)
2022-03-07 02:15:20 | INFO | train | epoch 354 | loss 2.177 | nll_loss 0.389 | ppl 1.31 | wps 22746.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 17227 | lr 0.000240932 | gnorm 0.468 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 47565
2022-03-07 02:15:20 | INFO | fairseq.trainer | begin training epoch 355
2022-03-07 02:15:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:17:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:17:33 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 13.323 | nll_loss 12.69 | ppl 6607.19 | wps 40997.2 | wpb 510.9 | bsz 1 | num_updates 17276 | best_loss 8.937
2022-03-07 02:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 355 @ 17276 updates
2022-03-07 02:17:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:17:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:17:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 355 @ 17276 updates, score 13.323) (writing took 2.459245929028839 seconds)
2022-03-07 02:17:36 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)
2022-03-07 02:17:36 | INFO | train | epoch 355 | loss 2.175 | nll_loss 0.388 | ppl 1.31 | wps 23375.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17276 | lr 0.00024059 | gnorm 0.463 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 47701
2022-03-07 02:17:36 | INFO | fairseq.trainer | begin training epoch 356
2022-03-07 02:17:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:18:39 | INFO | train_inner | epoch 356:     24 / 49 loss=2.175, nll_loss=0.388, ppl=1.31, wps=23140.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=17300, lr=0.000240424, gnorm=0.466, loss_scale=16, train_wall=239, gb_free=8.8, wall=47764
2022-03-07 02:19:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:19:49 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 13.377 | nll_loss 12.752 | ppl 6897.5 | wps 41147.4 | wpb 510.9 | bsz 1 | num_updates 17325 | best_loss 8.937
2022-03-07 02:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 356 @ 17325 updates
2022-03-07 02:19:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:19:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 356 @ 17325 updates, score 13.377) (writing took 2.468269946053624 seconds)
2022-03-07 02:19:52 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)
2022-03-07 02:19:52 | INFO | train | epoch 356 | loss 2.175 | nll_loss 0.387 | ppl 1.31 | wps 23401.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17325 | lr 0.00024025 | gnorm 0.467 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 47836
2022-03-07 02:19:52 | INFO | fairseq.trainer | begin training epoch 357
2022-03-07 02:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:22:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:22:05 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 13.263 | nll_loss 12.63 | ppl 6340.24 | wps 40506.4 | wpb 510.9 | bsz 1 | num_updates 17374 | best_loss 8.937
2022-03-07 02:22:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 357 @ 17374 updates
2022-03-07 02:22:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:22:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:22:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 357 @ 17374 updates, score 13.263) (writing took 2.393547500949353 seconds)
2022-03-07 02:22:08 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)
2022-03-07 02:22:08 | INFO | train | epoch 357 | loss 2.173 | nll_loss 0.386 | ppl 1.31 | wps 23315.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17374 | lr 0.000239911 | gnorm 0.456 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 47973
2022-03-07 02:22:08 | INFO | fairseq.trainer | begin training epoch 358
2022-03-07 02:22:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:23:17 | INFO | train_inner | epoch 358:     26 / 49 loss=2.173, nll_loss=0.386, ppl=1.31, wps=23343.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17400, lr=0.000239732, gnorm=0.459, loss_scale=32, train_wall=237, gb_free=8.8, wall=48042
2022-03-07 02:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:24:22 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 13.361 | nll_loss 12.741 | ppl 6843.93 | wps 40584.9 | wpb 510.9 | bsz 1 | num_updates 17423 | best_loss 8.937
2022-03-07 02:24:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 17423 updates
2022-03-07 02:24:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:24:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:24:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 358 @ 17423 updates, score 13.361) (writing took 2.5575728621333838 seconds)
2022-03-07 02:24:25 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)
2022-03-07 02:24:25 | INFO | train | epoch 358 | loss 2.174 | nll_loss 0.387 | ppl 1.31 | wps 23195.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17423 | lr 0.000239573 | gnorm 0.461 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 48110
2022-03-07 02:24:25 | INFO | fairseq.trainer | begin training epoch 359
2022-03-07 02:24:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:26:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:26:39 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 13.305 | nll_loss 12.675 | ppl 6540.58 | wps 40503.2 | wpb 510.9 | bsz 1 | num_updates 17472 | best_loss 8.937
2022-03-07 02:26:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 17472 updates
2022-03-07 02:26:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:26:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 359 @ 17472 updates, score 13.305) (writing took 2.4085932318121195 seconds)
2022-03-07 02:26:42 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)
2022-03-07 02:26:42 | INFO | train | epoch 359 | loss 2.173 | nll_loss 0.386 | ppl 1.31 | wps 23229.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17472 | lr 0.000239237 | gnorm 0.462 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 48246
2022-03-07 02:26:42 | INFO | fairseq.trainer | begin training epoch 360
2022-03-07 02:26:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:26:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:27:59 | INFO | train_inner | epoch 360:     29 / 49 loss=2.173, nll_loss=0.386, ppl=1.31, wps=23012.2, ups=0.35, wpb=64876.2, bsz=126.7, num_updates=17500, lr=0.000239046, gnorm=0.46, loss_scale=32, train_wall=240, gb_free=8.8, wall=48324
2022-03-07 02:28:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:28:56 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 13.398 | nll_loss 12.774 | ppl 7004.9 | wps 40643.3 | wpb 510.9 | bsz 1 | num_updates 17520 | best_loss 8.937
2022-03-07 02:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 17520 updates
2022-03-07 02:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 360 @ 17520 updates, score 13.398) (writing took 2.5120573369786143 seconds)
2022-03-07 02:28:59 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)
2022-03-07 02:28:59 | INFO | train | epoch 360 | loss 2.17 | nll_loss 0.383 | ppl 1.3 | wps 22736.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 17520 | lr 0.000238909 | gnorm 0.457 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 48383
2022-03-07 02:28:59 | INFO | fairseq.trainer | begin training epoch 361
2022-03-07 02:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:31:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:31:13 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 13.343 | nll_loss 12.718 | ppl 6736.68 | wps 41458.1 | wpb 510.9 | bsz 1 | num_updates 17569 | best_loss 8.937
2022-03-07 02:31:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 17569 updates
2022-03-07 02:31:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:31:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:31:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 361 @ 17569 updates, score 13.343) (writing took 2.487696876283735 seconds)
2022-03-07 02:31:15 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)
2022-03-07 02:31:15 | INFO | train | epoch 361 | loss 2.171 | nll_loss 0.384 | ppl 1.31 | wps 23275.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17569 | lr 0.000238576 | gnorm 0.458 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 48520
2022-03-07 02:31:15 | INFO | fairseq.trainer | begin training epoch 362
2022-03-07 02:31:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:32:37 | INFO | train_inner | epoch 362:     31 / 49 loss=2.17, nll_loss=0.384, ppl=1.3, wps=23296.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=17600, lr=0.000238366, gnorm=0.457, loss_scale=32, train_wall=237, gb_free=8.8, wall=48602
2022-03-07 02:32:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:33:29 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 13.367 | nll_loss 12.742 | ppl 6850.35 | wps 39185.2 | wpb 510.9 | bsz 1 | num_updates 17617 | best_loss 8.937
2022-03-07 02:33:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 17617 updates
2022-03-07 02:33:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:33:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 362 @ 17617 updates, score 13.367) (writing took 2.4735620748251677 seconds)
2022-03-07 02:33:32 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)
2022-03-07 02:33:32 | INFO | train | epoch 362 | loss 2.169 | nll_loss 0.383 | ppl 1.3 | wps 22760.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 17617 | lr 0.000238251 | gnorm 0.452 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 48657
2022-03-07 02:33:32 | INFO | fairseq.trainer | begin training epoch 363
2022-03-07 02:33:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:35:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:35:44 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 13.31 | nll_loss 12.679 | ppl 6559.14 | wps 41743.7 | wpb 510.9 | bsz 1 | num_updates 17666 | best_loss 8.937
2022-03-07 02:35:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 17666 updates
2022-03-07 02:35:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:35:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:35:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 363 @ 17666 updates, score 13.31) (writing took 2.3695482108742 seconds)
2022-03-07 02:35:46 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)
2022-03-07 02:35:46 | INFO | train | epoch 363 | loss 2.169 | nll_loss 0.383 | ppl 1.3 | wps 23637.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17666 | lr 0.00023792 | gnorm 0.452 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 48791
2022-03-07 02:35:46 | INFO | fairseq.trainer | begin training epoch 364
2022-03-07 02:35:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:37:15 | INFO | train_inner | epoch 364:     34 / 49 loss=2.169, nll_loss=0.383, ppl=1.3, wps=23373.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=17700, lr=0.000237691, gnorm=0.454, loss_scale=32, train_wall=236, gb_free=8.8, wall=48880
2022-03-07 02:37:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:37:58 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 13.294 | nll_loss 12.67 | ppl 6516.3 | wps 41851.3 | wpb 510.9 | bsz 1 | num_updates 17715 | best_loss 8.937
2022-03-07 02:37:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 17715 updates
2022-03-07 02:37:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:38:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:38:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 364 @ 17715 updates, score 13.294) (writing took 2.4071962046436965 seconds)
2022-03-07 02:38:00 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)
2022-03-07 02:38:00 | INFO | train | epoch 364 | loss 2.169 | nll_loss 0.383 | ppl 1.3 | wps 23692.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17715 | lr 0.000237591 | gnorm 0.455 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 48925
2022-03-07 02:38:00 | INFO | fairseq.trainer | begin training epoch 365
2022-03-07 02:38:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:39:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:40:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:40:12 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 13.462 | nll_loss 12.844 | ppl 7351.63 | wps 42006.7 | wpb 510.9 | bsz 1 | num_updates 17763 | best_loss 8.937
2022-03-07 02:40:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 17763 updates
2022-03-07 02:40:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:40:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:40:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 365 @ 17763 updates, score 13.462) (writing took 2.402338573243469 seconds)
2022-03-07 02:40:14 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)
2022-03-07 02:40:14 | INFO | train | epoch 365 | loss 2.168 | nll_loss 0.383 | ppl 1.3 | wps 23234.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17763 | lr 0.000237269 | gnorm 0.459 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 49059
2022-03-07 02:40:14 | INFO | fairseq.trainer | begin training epoch 366
2022-03-07 02:40:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:41:51 | INFO | train_inner | epoch 366:     37 / 49 loss=2.168, nll_loss=0.382, ppl=1.3, wps=23508.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17800, lr=0.000237023, gnorm=0.457, loss_scale=32, train_wall=235, gb_free=8.8, wall=49156
2022-03-07 02:42:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:42:26 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 13.354 | nll_loss 12.726 | ppl 6775.27 | wps 42670.7 | wpb 510.9 | bsz 1 | num_updates 17812 | best_loss 8.937
2022-03-07 02:42:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 17812 updates
2022-03-07 02:42:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:42:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:42:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 366 @ 17812 updates, score 13.354) (writing took 2.6308709639124572 seconds)
2022-03-07 02:42:29 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)
2022-03-07 02:42:29 | INFO | train | epoch 366 | loss 2.167 | nll_loss 0.381 | ppl 1.3 | wps 23673.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17812 | lr 0.000236943 | gnorm 0.456 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 49193
2022-03-07 02:42:29 | INFO | fairseq.trainer | begin training epoch 367
2022-03-07 02:42:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:44:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:44:40 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 13.309 | nll_loss 12.683 | ppl 6573.87 | wps 42042.8 | wpb 510.9 | bsz 1 | num_updates 17861 | best_loss 8.937
2022-03-07 02:44:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 17861 updates
2022-03-07 02:44:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:44:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:44:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 367 @ 17861 updates, score 13.309) (writing took 2.445796743966639 seconds)
2022-03-07 02:44:43 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)
2022-03-07 02:44:43 | INFO | train | epoch 367 | loss 2.167 | nll_loss 0.381 | ppl 1.3 | wps 23702.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 17861 | lr 0.000236618 | gnorm 0.454 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 49328
2022-03-07 02:44:43 | INFO | fairseq.trainer | begin training epoch 368
2022-03-07 02:44:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:45:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:46:27 | INFO | train_inner | epoch 368:     40 / 49 loss=2.166, nll_loss=0.381, ppl=1.3, wps=23504.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=17900, lr=0.00023636, gnorm=0.451, loss_scale=32, train_wall=235, gb_free=8.8, wall=49432
2022-03-07 02:46:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:46:54 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 13.3 | nll_loss 12.668 | ppl 6509.68 | wps 42174.6 | wpb 510.9 | bsz 1 | num_updates 17909 | best_loss 8.937
2022-03-07 02:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 17909 updates
2022-03-07 02:46:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:46:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:46:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 368 @ 17909 updates, score 13.3) (writing took 2.519249217119068 seconds)
2022-03-07 02:46:57 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)
2022-03-07 02:46:57 | INFO | train | epoch 368 | loss 2.165 | nll_loss 0.38 | ppl 1.3 | wps 23216.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 17909 | lr 0.0002363 | gnorm 0.449 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 49462
2022-03-07 02:46:57 | INFO | fairseq.trainer | begin training epoch 369
2022-03-07 02:46:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:49:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:49:10 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 13.31 | nll_loss 12.679 | ppl 6559.49 | wps 40036.3 | wpb 510.9 | bsz 1 | num_updates 17958 | best_loss 8.937
2022-03-07 02:49:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 17958 updates
2022-03-07 02:49:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:49:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:49:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 369 @ 17958 updates, score 13.31) (writing took 2.43146168300882 seconds)
2022-03-07 02:49:13 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)
2022-03-07 02:49:13 | INFO | train | epoch 369 | loss 2.164 | nll_loss 0.379 | ppl 1.3 | wps 23423.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 17958 | lr 0.000235978 | gnorm 0.462 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 49597
2022-03-07 02:49:13 | INFO | fairseq.trainer | begin training epoch 370
2022-03-07 02:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:50:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:51:07 | INFO | train_inner | epoch 370:     43 / 49 loss=2.164, nll_loss=0.379, ppl=1.3, wps=23177.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=18000, lr=0.000235702, gnorm=0.456, loss_scale=32, train_wall=238, gb_free=8.8, wall=49712
2022-03-07 02:51:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:51:27 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 13.233 | nll_loss 12.599 | ppl 6204.19 | wps 40687.8 | wpb 510.9 | bsz 1 | num_updates 18006 | best_loss 8.937
2022-03-07 02:51:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 18006 updates
2022-03-07 02:51:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:51:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 370 @ 18006 updates, score 13.233) (writing took 2.4774629748426378 seconds)
2022-03-07 02:51:29 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)
2022-03-07 02:51:29 | INFO | train | epoch 370 | loss 2.163 | nll_loss 0.378 | ppl 1.3 | wps 22751.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18006 | lr 0.000235663 | gnorm 0.45 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 49734
2022-03-07 02:51:29 | INFO | fairseq.trainer | begin training epoch 371
2022-03-07 02:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:53:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:53:44 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 13.311 | nll_loss 12.686 | ppl 6590.26 | wps 39239.1 | wpb 510.9 | bsz 1 | num_updates 18055 | best_loss 8.937
2022-03-07 02:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 18055 updates
2022-03-07 02:53:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:53:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:53:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 371 @ 18055 updates, score 13.311) (writing took 2.430178356356919 seconds)
2022-03-07 02:53:46 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)
2022-03-07 02:53:46 | INFO | train | epoch 371 | loss 2.163 | nll_loss 0.378 | ppl 1.3 | wps 23200.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18055 | lr 0.000235343 | gnorm 0.448 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 49871
2022-03-07 02:53:46 | INFO | fairseq.trainer | begin training epoch 372
2022-03-07 02:53:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:55:46 | INFO | train_inner | epoch 372:     45 / 49 loss=2.163, nll_loss=0.378, ppl=1.3, wps=23262.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=18100, lr=0.00023505, gnorm=0.449, loss_scale=32, train_wall=237, gb_free=8.8, wall=49990
2022-03-07 02:55:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:56:00 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 13.316 | nll_loss 12.695 | ppl 6630.57 | wps 40370.6 | wpb 510.9 | bsz 1 | num_updates 18104 | best_loss 8.937
2022-03-07 02:56:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 18104 updates
2022-03-07 02:56:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:56:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 372 @ 18104 updates, score 13.316) (writing took 2.4552669869735837 seconds)
2022-03-07 02:56:03 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)
2022-03-07 02:56:03 | INFO | train | epoch 372 | loss 2.163 | nll_loss 0.378 | ppl 1.3 | wps 23265.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18104 | lr 0.000235024 | gnorm 0.449 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50008
2022-03-07 02:56:03 | INFO | fairseq.trainer | begin training epoch 373
2022-03-07 02:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 02:57:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 02:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 02:58:17 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 13.325 | nll_loss 12.702 | ppl 6661.08 | wps 40509.8 | wpb 510.9 | bsz 1 | num_updates 18152 | best_loss 8.937
2022-03-07 02:58:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 18152 updates
2022-03-07 02:58:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:58:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 02:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 373 @ 18152 updates, score 13.325) (writing took 2.4362766966223717 seconds)
2022-03-07 02:58:20 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)
2022-03-07 02:58:20 | INFO | train | epoch 373 | loss 2.162 | nll_loss 0.377 | ppl 1.3 | wps 22783.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18152 | lr 0.000234713 | gnorm 0.453 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50144
2022-03-07 02:58:20 | INFO | fairseq.trainer | begin training epoch 374
2022-03-07 02:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:00:27 | INFO | train_inner | epoch 374:     48 / 49 loss=2.162, nll_loss=0.377, ppl=1.3, wps=23083.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=18200, lr=0.000234404, gnorm=0.449, loss_scale=32, train_wall=239, gb_free=8.8, wall=50271
2022-03-07 03:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:00:33 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 13.25 | nll_loss 12.618 | ppl 6286.45 | wps 41396.4 | wpb 510.9 | bsz 1 | num_updates 18201 | best_loss 8.937
2022-03-07 03:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 18201 updates
2022-03-07 03:00:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:00:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:00:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 374 @ 18201 updates, score 13.25) (writing took 2.4313218952156603 seconds)
2022-03-07 03:00:36 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)
2022-03-07 03:00:36 | INFO | train | epoch 374 | loss 2.161 | nll_loss 0.377 | ppl 1.3 | wps 23301.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18201 | lr 0.000234397 | gnorm 0.445 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50281
2022-03-07 03:00:36 | INFO | fairseq.trainer | begin training epoch 375
2022-03-07 03:00:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:02:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:02:50 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 13.283 | nll_loss 12.651 | ppl 6431.33 | wps 40638.1 | wpb 510.9 | bsz 1 | num_updates 18250 | best_loss 8.937
2022-03-07 03:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 18250 updates
2022-03-07 03:02:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 375 @ 18250 updates, score 13.283) (writing took 2.428828564938158 seconds)
2022-03-07 03:02:53 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)
2022-03-07 03:02:53 | INFO | train | epoch 375 | loss 2.161 | nll_loss 0.377 | ppl 1.3 | wps 23230.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18250 | lr 0.000234082 | gnorm 0.45 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50417
2022-03-07 03:02:53 | INFO | fairseq.trainer | begin training epoch 376
2022-03-07 03:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:03:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:05:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:05:07 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 13.333 | nll_loss 12.708 | ppl 6690.54 | wps 40162.1 | wpb 510.9 | bsz 1 | num_updates 18298 | best_loss 8.937
2022-03-07 03:05:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 18298 updates
2022-03-07 03:05:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:05:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 376 @ 18298 updates, score 13.333) (writing took 2.5565165858715773 seconds)
2022-03-07 03:05:10 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)
2022-03-07 03:05:10 | INFO | train | epoch 376 | loss 2.159 | nll_loss 0.375 | ppl 1.3 | wps 22706.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18298 | lr 0.000233775 | gnorm 0.445 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50555
2022-03-07 03:05:10 | INFO | fairseq.trainer | begin training epoch 377
2022-03-07 03:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:05:15 | INFO | train_inner | epoch 377:      2 / 49 loss=2.16, nll_loss=0.376, ppl=1.3, wps=22377.5, ups=0.35, wpb=64539.7, bsz=126.1, num_updates=18300, lr=0.000233762, gnorm=0.448, loss_scale=32, train_wall=239, gb_free=8.8, wall=50560
2022-03-07 03:07:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:07:24 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 13.297 | nll_loss 12.669 | ppl 6510.89 | wps 40702.7 | wpb 510.9 | bsz 1 | num_updates 18347 | best_loss 8.937
2022-03-07 03:07:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 18347 updates
2022-03-07 03:07:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:07:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 377 @ 18347 updates, score 13.297) (writing took 2.601191831752658 seconds)
2022-03-07 03:07:27 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)
2022-03-07 03:07:27 | INFO | train | epoch 377 | loss 2.159 | nll_loss 0.376 | ppl 1.3 | wps 23210.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18347 | lr 0.000233463 | gnorm 0.449 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50691
2022-03-07 03:07:27 | INFO | fairseq.trainer | begin training epoch 378
2022-03-07 03:07:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:09:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:09:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:09:41 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 13.358 | nll_loss 12.735 | ppl 6816.91 | wps 40489.5 | wpb 510.9 | bsz 1 | num_updates 18395 | best_loss 8.937
2022-03-07 03:09:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 18395 updates
2022-03-07 03:09:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:09:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:09:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 378 @ 18395 updates, score 13.358) (writing took 2.4483412439003587 seconds)
2022-03-07 03:09:43 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)
2022-03-07 03:09:43 | INFO | train | epoch 378 | loss 2.158 | nll_loss 0.374 | ppl 1.3 | wps 22807.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18395 | lr 0.000233158 | gnorm 0.442 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50828
2022-03-07 03:09:43 | INFO | fairseq.trainer | begin training epoch 379
2022-03-07 03:09:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:09:57 | INFO | train_inner | epoch 379:      5 / 49 loss=2.158, nll_loss=0.375, ppl=1.3, wps=23057.8, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=18400, lr=0.000233126, gnorm=0.445, loss_scale=32, train_wall=240, gb_free=8.8, wall=50841
2022-03-07 03:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:11:57 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 13.241 | nll_loss 12.608 | ppl 6242.32 | wps 42075 | wpb 510.9 | bsz 1 | num_updates 18444 | best_loss 8.937
2022-03-07 03:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 18444 updates
2022-03-07 03:11:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:11:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:11:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 379 @ 18444 updates, score 13.241) (writing took 2.385107684414834 seconds)
2022-03-07 03:11:59 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)
2022-03-07 03:11:59 | INFO | train | epoch 379 | loss 2.159 | nll_loss 0.375 | ppl 1.3 | wps 23357.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18444 | lr 0.000232848 | gnorm 0.459 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 50964
2022-03-07 03:11:59 | INFO | fairseq.trainer | begin training epoch 380
2022-03-07 03:11:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:14:11 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 13.334 | nll_loss 12.708 | ppl 6691.71 | wps 42052.8 | wpb 510.9 | bsz 1 | num_updates 18493 | best_loss 8.937
2022-03-07 03:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 18493 updates
2022-03-07 03:14:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:14:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:14:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 380 @ 18493 updates, score 13.334) (writing took 2.5539381420239806 seconds)
2022-03-07 03:14:13 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)
2022-03-07 03:14:13 | INFO | train | epoch 380 | loss 2.157 | nll_loss 0.374 | ppl 1.3 | wps 23676.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18493 | lr 0.000232539 | gnorm 0.452 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51098
2022-03-07 03:14:13 | INFO | fairseq.trainer | begin training epoch 381
2022-03-07 03:14:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:14:32 | INFO | train_inner | epoch 381:      7 / 49 loss=2.158, nll_loss=0.374, ppl=1.3, wps=23559.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=18500, lr=0.000232495, gnorm=0.456, loss_scale=32, train_wall=235, gb_free=8.8, wall=51117
2022-03-07 03:15:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:16:25 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 13.342 | nll_loss 12.721 | ppl 6749.98 | wps 42285.1 | wpb 510.9 | bsz 1 | num_updates 18541 | best_loss 8.937
2022-03-07 03:16:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 18541 updates
2022-03-07 03:16:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:16:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 381 @ 18541 updates, score 13.342) (writing took 2.4482344961725175 seconds)
2022-03-07 03:16:27 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)
2022-03-07 03:16:27 | INFO | train | epoch 381 | loss 2.156 | nll_loss 0.373 | ppl 1.29 | wps 23227.4 | ups 0.36 | wpb 64853.3 | bsz 126.7 | num_updates 18541 | lr 0.000232238 | gnorm 0.448 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51232
2022-03-07 03:16:27 | INFO | fairseq.trainer | begin training epoch 382
2022-03-07 03:16:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:18:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:18:39 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 13.299 | nll_loss 12.672 | ppl 6526.98 | wps 41450.6 | wpb 510.9 | bsz 1 | num_updates 18590 | best_loss 8.937
2022-03-07 03:18:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 18590 updates
2022-03-07 03:18:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:18:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:18:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 382 @ 18590 updates, score 13.299) (writing took 2.3828873517923057 seconds)
2022-03-07 03:18:42 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)
2022-03-07 03:18:42 | INFO | train | epoch 382 | loss 2.156 | nll_loss 0.373 | ppl 1.3 | wps 23704.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18590 | lr 0.000231932 | gnorm 0.443 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51366
2022-03-07 03:18:42 | INFO | fairseq.trainer | begin training epoch 383
2022-03-07 03:18:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:19:08 | INFO | train_inner | epoch 383:     10 / 49 loss=2.156, nll_loss=0.373, ppl=1.29, wps=23516.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=18600, lr=0.000231869, gnorm=0.444, loss_scale=32, train_wall=235, gb_free=8.8, wall=51393
2022-03-07 03:20:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:20:53 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 13.354 | nll_loss 12.733 | ppl 6807.67 | wps 42751.6 | wpb 510.9 | bsz 1 | num_updates 18639 | best_loss 8.937
2022-03-07 03:20:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 18639 updates
2022-03-07 03:20:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:20:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:20:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 383 @ 18639 updates, score 13.354) (writing took 2.399261032231152 seconds)
2022-03-07 03:20:56 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)
2022-03-07 03:20:56 | INFO | train | epoch 383 | loss 2.155 | nll_loss 0.373 | ppl 1.29 | wps 23696.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 18639 | lr 0.000231627 | gnorm 0.446 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 51500
2022-03-07 03:20:56 | INFO | fairseq.trainer | begin training epoch 384
2022-03-07 03:20:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:20:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:23:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:23:07 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 13.328 | nll_loss 12.704 | ppl 6672.62 | wps 41627.9 | wpb 510.9 | bsz 1 | num_updates 18687 | best_loss 8.937
2022-03-07 03:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 18687 updates
2022-03-07 03:23:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:23:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 384 @ 18687 updates, score 13.328) (writing took 2.4246558230370283 seconds)
2022-03-07 03:23:10 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)
2022-03-07 03:23:10 | INFO | train | epoch 384 | loss 2.154 | nll_loss 0.371 | ppl 1.29 | wps 23193.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 18687 | lr 0.000231329 | gnorm 0.446 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51635
2022-03-07 03:23:10 | INFO | fairseq.trainer | begin training epoch 385
2022-03-07 03:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:23:44 | INFO | train_inner | epoch 385:     13 / 49 loss=2.154, nll_loss=0.372, ppl=1.29, wps=23481.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=18700, lr=0.000231249, gnorm=0.444, loss_scale=32, train_wall=236, gb_free=8.8, wall=51669
2022-03-07 03:25:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:25:22 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 13.268 | nll_loss 12.646 | ppl 6408.73 | wps 41511.4 | wpb 510.9 | bsz 1 | num_updates 18736 | best_loss 8.937
2022-03-07 03:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 18736 updates
2022-03-07 03:25:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 385 @ 18736 updates, score 13.268) (writing took 2.483631875831634 seconds)
2022-03-07 03:25:24 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)
2022-03-07 03:25:24 | INFO | train | epoch 385 | loss 2.153 | nll_loss 0.371 | ppl 1.29 | wps 23607.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18736 | lr 0.000231026 | gnorm 0.443 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 51769
2022-03-07 03:25:25 | INFO | fairseq.trainer | begin training epoch 386
2022-03-07 03:25:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:26:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:27:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:27:39 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 13.373 | nll_loss 12.753 | ppl 6903.69 | wps 40546.8 | wpb 510.9 | bsz 1 | num_updates 18784 | best_loss 8.937
2022-03-07 03:27:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 18784 updates
2022-03-07 03:27:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:27:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:27:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 386 @ 18784 updates, score 13.373) (writing took 2.402734413743019 seconds)
2022-03-07 03:27:41 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)
2022-03-07 03:27:41 | INFO | train | epoch 386 | loss 2.153 | nll_loss 0.371 | ppl 1.29 | wps 22751.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18784 | lr 0.000230731 | gnorm 0.443 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 51906
2022-03-07 03:27:41 | INFO | fairseq.trainer | begin training epoch 387
2022-03-07 03:27:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:28:24 | INFO | train_inner | epoch 387:     16 / 49 loss=2.153, nll_loss=0.371, ppl=1.29, wps=23183.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=18800, lr=0.000230633, gnorm=0.445, loss_scale=32, train_wall=239, gb_free=8.8, wall=51949
2022-03-07 03:29:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:29:56 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 13.302 | nll_loss 12.674 | ppl 6533.32 | wps 40550.6 | wpb 510.9 | bsz 1 | num_updates 18833 | best_loss 8.937
2022-03-07 03:29:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 18833 updates
2022-03-07 03:29:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:29:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:29:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 387 @ 18833 updates, score 13.302) (writing took 2.398361961822957 seconds)
2022-03-07 03:29:58 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)
2022-03-07 03:29:58 | INFO | train | epoch 387 | loss 2.153 | nll_loss 0.37 | ppl 1.29 | wps 23234.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18833 | lr 0.000230431 | gnorm 0.44 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 52043
2022-03-07 03:29:58 | INFO | fairseq.trainer | begin training epoch 388
2022-03-07 03:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:32:12 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 13.372 | nll_loss 12.751 | ppl 6893.8 | wps 40801.9 | wpb 510.9 | bsz 1 | num_updates 18882 | best_loss 8.937
2022-03-07 03:32:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 18882 updates
2022-03-07 03:32:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:32:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:32:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 388 @ 18882 updates, score 13.372) (writing took 2.4743107208050787 seconds)
2022-03-07 03:32:15 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)
2022-03-07 03:32:15 | INFO | train | epoch 388 | loss 2.152 | nll_loss 0.37 | ppl 1.29 | wps 23232.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18882 | lr 0.000230131 | gnorm 0.446 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 52180
2022-03-07 03:32:15 | INFO | fairseq.trainer | begin training epoch 389
2022-03-07 03:32:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:32:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:33:06 | INFO | train_inner | epoch 389:     19 / 49 loss=2.152, nll_loss=0.37, ppl=1.29, wps=23025.8, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=18900, lr=0.000230022, gnorm=0.442, loss_scale=32, train_wall=240, gb_free=8.8, wall=52230
2022-03-07 03:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:34:29 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 13.293 | nll_loss 12.67 | ppl 6518.78 | wps 40992 | wpb 510.9 | bsz 1 | num_updates 18930 | best_loss 8.937
2022-03-07 03:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 18930 updates
2022-03-07 03:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:34:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:34:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 389 @ 18930 updates, score 13.293) (writing took 2.5444364082068205 seconds)
2022-03-07 03:34:32 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)
2022-03-07 03:34:32 | INFO | train | epoch 389 | loss 2.151 | nll_loss 0.369 | ppl 1.29 | wps 22748.3 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 18930 | lr 0.00022984 | gnorm 0.444 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 52316
2022-03-07 03:34:32 | INFO | fairseq.trainer | begin training epoch 390
2022-03-07 03:34:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:36:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:36:46 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 13.291 | nll_loss 12.668 | ppl 6509.05 | wps 40575.6 | wpb 510.9 | bsz 1 | num_updates 18979 | best_loss 8.937
2022-03-07 03:36:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 18979 updates
2022-03-07 03:36:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:36:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:36:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 390 @ 18979 updates, score 13.291) (writing took 2.5815627020783722 seconds)
2022-03-07 03:36:49 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)
2022-03-07 03:36:49 | INFO | train | epoch 390 | loss 2.151 | nll_loss 0.369 | ppl 1.29 | wps 23215.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 18979 | lr 0.000229543 | gnorm 0.443 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 52453
2022-03-07 03:36:49 | INFO | fairseq.trainer | begin training epoch 391
2022-03-07 03:36:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:37:44 | INFO | train_inner | epoch 391:     21 / 49 loss=2.151, nll_loss=0.369, ppl=1.29, wps=23268.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19000, lr=0.000229416, gnorm=0.445, loss_scale=32, train_wall=237, gb_free=8.8, wall=52509
2022-03-07 03:38:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:38:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:39:03 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 13.346 | nll_loss 12.722 | ppl 6758.02 | wps 40397.8 | wpb 510.9 | bsz 1 | num_updates 19027 | best_loss 8.937
2022-03-07 03:39:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 19027 updates
2022-03-07 03:39:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:39:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:39:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 391 @ 19027 updates, score 13.346) (writing took 2.4772584890015423 seconds)
2022-03-07 03:39:05 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)
2022-03-07 03:39:05 | INFO | train | epoch 391 | loss 2.151 | nll_loss 0.369 | ppl 1.29 | wps 22776.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19027 | lr 0.000229253 | gnorm 0.447 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 52590
2022-03-07 03:39:05 | INFO | fairseq.trainer | begin training epoch 392
2022-03-07 03:39:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:41:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:41:20 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 13.346 | nll_loss 12.725 | ppl 6772.21 | wps 40386.1 | wpb 510.9 | bsz 1 | num_updates 19076 | best_loss 8.937
2022-03-07 03:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 19076 updates
2022-03-07 03:41:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:41:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:41:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 392 @ 19076 updates, score 13.346) (writing took 2.5316276042722166 seconds)
2022-03-07 03:41:22 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)
2022-03-07 03:41:22 | INFO | train | epoch 392 | loss 2.15 | nll_loss 0.368 | ppl 1.29 | wps 23174 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19076 | lr 0.000228958 | gnorm 0.443 | loss_scale 32 | train_wall 117 | gb_free 8.8 | wall 52727
2022-03-07 03:41:22 | INFO | fairseq.trainer | begin training epoch 393
2022-03-07 03:41:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:42:26 | INFO | train_inner | epoch 393:     24 / 49 loss=2.149, nll_loss=0.368, ppl=1.29, wps=23010.2, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=19100, lr=0.000228814, gnorm=0.443, loss_scale=32, train_wall=240, gb_free=8.8, wall=52791
2022-03-07 03:43:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:43:37 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 13.32 | nll_loss 12.698 | ppl 6646.69 | wps 40419.3 | wpb 510.9 | bsz 1 | num_updates 19125 | best_loss 8.937
2022-03-07 03:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 19125 updates
2022-03-07 03:43:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:43:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:43:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 393 @ 19125 updates, score 13.32) (writing took 2.4169314056634903 seconds)
2022-03-07 03:43:39 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)
2022-03-07 03:43:39 | INFO | train | epoch 393 | loss 2.148 | nll_loss 0.367 | ppl 1.29 | wps 23217.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19125 | lr 0.000228665 | gnorm 0.441 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 52864
2022-03-07 03:43:39 | INFO | fairseq.trainer | begin training epoch 394
2022-03-07 03:43:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:44:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:45:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:45:53 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 13.348 | nll_loss 12.729 | ppl 6790.92 | wps 40594.2 | wpb 510.9 | bsz 1 | num_updates 19173 | best_loss 8.937
2022-03-07 03:45:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 19173 updates
2022-03-07 03:45:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:45:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:45:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 394 @ 19173 updates, score 13.348) (writing took 2.557910663075745 seconds)
2022-03-07 03:45:55 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)
2022-03-07 03:45:55 | INFO | train | epoch 394 | loss 2.147 | nll_loss 0.366 | ppl 1.29 | wps 22847.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19173 | lr 0.000228378 | gnorm 0.433 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53000
2022-03-07 03:45:56 | INFO | fairseq.trainer | begin training epoch 395
2022-03-07 03:45:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:47:07 | INFO | train_inner | epoch 395:     27 / 49 loss=2.148, nll_loss=0.366, ppl=1.29, wps=23136.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=19200, lr=0.000228218, gnorm=0.436, loss_scale=32, train_wall=239, gb_free=8.8, wall=53071
2022-03-07 03:48:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:48:09 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 13.335 | nll_loss 12.717 | ppl 6733.69 | wps 42330.1 | wpb 510.9 | bsz 1 | num_updates 19222 | best_loss 8.937
2022-03-07 03:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 19222 updates
2022-03-07 03:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:48:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:48:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 395 @ 19222 updates, score 13.335) (writing took 2.651851783040911 seconds)
2022-03-07 03:48:11 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)
2022-03-07 03:48:11 | INFO | train | epoch 395 | loss 2.147 | nll_loss 0.366 | ppl 1.29 | wps 23420.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19222 | lr 0.000228087 | gnorm 0.437 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 53136
2022-03-07 03:48:11 | INFO | fairseq.trainer | begin training epoch 396
2022-03-07 03:48:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:50:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:50:24 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 13.319 | nll_loss 12.698 | ppl 6646.9 | wps 41711.2 | wpb 510.9 | bsz 1 | num_updates 19271 | best_loss 8.937
2022-03-07 03:50:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 19271 updates
2022-03-07 03:50:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:50:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:50:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 396 @ 19271 updates, score 13.319) (writing took 2.355809514410794 seconds)
2022-03-07 03:50:26 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)
2022-03-07 03:50:26 | INFO | train | epoch 396 | loss 2.146 | nll_loss 0.365 | ppl 1.29 | wps 23519 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19271 | lr 0.000227797 | gnorm 0.437 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 53271
2022-03-07 03:50:26 | INFO | fairseq.trainer | begin training epoch 397
2022-03-07 03:50:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:50:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:51:45 | INFO | train_inner | epoch 397:     30 / 49 loss=2.147, nll_loss=0.366, ppl=1.29, wps=23350.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19300, lr=0.000227626, gnorm=0.441, loss_scale=32, train_wall=237, gb_free=8.8, wall=53349
2022-03-07 03:52:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:52:39 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 13.315 | nll_loss 12.694 | ppl 6626.8 | wps 40758 | wpb 510.9 | bsz 1 | num_updates 19319 | best_loss 8.937
2022-03-07 03:52:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 19319 updates
2022-03-07 03:52:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:52:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:52:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 397 @ 19319 updates, score 13.315) (writing took 2.5006490242667496 seconds)
2022-03-07 03:52:41 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)
2022-03-07 03:52:41 | INFO | train | epoch 397 | loss 2.147 | nll_loss 0.366 | ppl 1.29 | wps 23108.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 19319 | lr 0.000227514 | gnorm 0.445 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 53406
2022-03-07 03:52:41 | INFO | fairseq.trainer | begin training epoch 398
2022-03-07 03:52:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:54:55 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 13.218 | nll_loss 12.59 | ppl 6166.11 | wps 41854.9 | wpb 510.9 | bsz 1 | num_updates 19368 | best_loss 8.937
2022-03-07 03:54:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 19368 updates
2022-03-07 03:54:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:54:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:54:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 398 @ 19368 updates, score 13.218) (writing took 2.50521705718711 seconds)
2022-03-07 03:54:57 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)
2022-03-07 03:54:57 | INFO | train | epoch 398 | loss 2.146 | nll_loss 0.365 | ppl 1.29 | wps 23342.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19368 | lr 0.000227226 | gnorm 0.445 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53542
2022-03-07 03:54:57 | INFO | fairseq.trainer | begin training epoch 399
2022-03-07 03:54:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:56:22 | INFO | train_inner | epoch 399:     32 / 49 loss=2.146, nll_loss=0.365, ppl=1.29, wps=23411.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19400, lr=0.000227038, gnorm=0.439, loss_scale=32, train_wall=236, gb_free=8.8, wall=53626
2022-03-07 03:56:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 03:57:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:57:10 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 13.299 | nll_loss 12.675 | ppl 6537.47 | wps 41550.6 | wpb 510.9 | bsz 1 | num_updates 19416 | best_loss 8.937
2022-03-07 03:57:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 19416 updates
2022-03-07 03:57:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:57:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 399 @ 19416 updates, score 13.299) (writing took 2.540675459895283 seconds)
2022-03-07 03:57:13 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)
2022-03-07 03:57:13 | INFO | train | epoch 399 | loss 2.145 | nll_loss 0.364 | ppl 1.29 | wps 22929.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19416 | lr 0.000226945 | gnorm 0.431 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 53678
2022-03-07 03:57:13 | INFO | fairseq.trainer | begin training epoch 400
2022-03-07 03:57:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 03:59:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 03:59:26 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 13.272 | nll_loss 12.648 | ppl 6416.95 | wps 41603.9 | wpb 510.9 | bsz 1 | num_updates 19465 | best_loss 8.937
2022-03-07 03:59:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 19465 updates
2022-03-07 03:59:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:59:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 03:59:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 400 @ 19465 updates, score 13.272) (writing took 2.386828415095806 seconds)
2022-03-07 03:59:28 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)
2022-03-07 03:59:28 | INFO | train | epoch 400 | loss 2.145 | nll_loss 0.364 | ppl 1.29 | wps 23464 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19465 | lr 0.000226659 | gnorm 0.434 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 53813
2022-03-07 03:59:28 | INFO | fairseq.trainer | begin training epoch 401
2022-03-07 03:59:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:01:01 | INFO | train_inner | epoch 401:     35 / 49 loss=2.145, nll_loss=0.364, ppl=1.29, wps=23214.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19500, lr=0.000226455, gnorm=0.439, loss_scale=32, train_wall=238, gb_free=8.8, wall=53906
2022-03-07 04:01:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:01:42 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 13.334 | nll_loss 12.718 | ppl 6736.94 | wps 40505.4 | wpb 510.9 | bsz 1 | num_updates 19514 | best_loss 8.937
2022-03-07 04:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 19514 updates
2022-03-07 04:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:01:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:01:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 401 @ 19514 updates, score 13.334) (writing took 2.4017738080583513 seconds)
2022-03-07 04:01:45 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)
2022-03-07 04:01:45 | INFO | train | epoch 401 | loss 2.144 | nll_loss 0.364 | ppl 1.29 | wps 23312.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19514 | lr 0.000226374 | gnorm 0.444 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 53949
2022-03-07 04:01:45 | INFO | fairseq.trainer | begin training epoch 402
2022-03-07 04:01:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:02:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:03:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:03:59 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 13.324 | nll_loss 12.702 | ppl 6665.23 | wps 40584.6 | wpb 510.9 | bsz 1 | num_updates 19562 | best_loss 8.937
2022-03-07 04:03:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 19562 updates
2022-03-07 04:03:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:04:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:04:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 402 @ 19562 updates, score 13.324) (writing took 2.508792283013463 seconds)
2022-03-07 04:04:01 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)
2022-03-07 04:04:01 | INFO | train | epoch 402 | loss 2.143 | nll_loss 0.363 | ppl 1.29 | wps 22816.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19562 | lr 0.000226096 | gnorm 0.435 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54086
2022-03-07 04:04:01 | INFO | fairseq.trainer | begin training epoch 403
2022-03-07 04:04:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:05:42 | INFO | train_inner | epoch 403:     38 / 49 loss=2.143, nll_loss=0.363, ppl=1.29, wps=23098.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19600, lr=0.000225877, gnorm=0.436, loss_scale=32, train_wall=239, gb_free=8.8, wall=54187
2022-03-07 04:06:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:06:15 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 13.35 | nll_loss 12.728 | ppl 6785.18 | wps 40032.5 | wpb 510.9 | bsz 1 | num_updates 19611 | best_loss 8.937
2022-03-07 04:06:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 19611 updates
2022-03-07 04:06:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:06:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:06:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 403 @ 19611 updates, score 13.35) (writing took 2.3967611980624497 seconds)
2022-03-07 04:06:18 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)
2022-03-07 04:06:18 | INFO | train | epoch 403 | loss 2.143 | nll_loss 0.363 | ppl 1.29 | wps 23294.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19611 | lr 0.000225814 | gnorm 0.437 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54222
2022-03-07 04:06:18 | INFO | fairseq.trainer | begin training epoch 404
2022-03-07 04:06:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:08:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:08:32 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 13.337 | nll_loss 12.72 | ppl 6748.69 | wps 40332.4 | wpb 510.9 | bsz 1 | num_updates 19660 | best_loss 8.937
2022-03-07 04:08:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 19660 updates
2022-03-07 04:08:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:08:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:08:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 404 @ 19660 updates, score 13.337) (writing took 2.4192411843687296 seconds)
2022-03-07 04:08:34 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)
2022-03-07 04:08:34 | INFO | train | epoch 404 | loss 2.142 | nll_loss 0.362 | ppl 1.29 | wps 23278.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19660 | lr 0.000225532 | gnorm 0.436 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54359
2022-03-07 04:08:34 | INFO | fairseq.trainer | begin training epoch 405
2022-03-07 04:08:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:10:23 | INFO | train_inner | epoch 405:     41 / 49 loss=2.142, nll_loss=0.362, ppl=1.29, wps=23090.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19700, lr=0.000225303, gnorm=0.437, loss_scale=32, train_wall=239, gb_free=8.8, wall=54468
2022-03-07 04:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:10:48 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 13.306 | nll_loss 12.684 | ppl 6580.54 | wps 40751.7 | wpb 510.9 | bsz 1 | num_updates 19708 | best_loss 8.937
2022-03-07 04:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 19708 updates
2022-03-07 04:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:10:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:10:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 405 @ 19708 updates, score 13.306) (writing took 2.4106266759335995 seconds)
2022-03-07 04:10:51 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)
2022-03-07 04:10:51 | INFO | train | epoch 405 | loss 2.142 | nll_loss 0.362 | ppl 1.29 | wps 22801.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19708 | lr 0.000225257 | gnorm 0.437 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 54495
2022-03-07 04:10:51 | INFO | fairseq.trainer | begin training epoch 406
2022-03-07 04:10:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:12:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-07 04:12:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:13:05 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 13.4 | nll_loss 12.785 | ppl 7057.15 | wps 40987.5 | wpb 510.9 | bsz 1 | num_updates 19756 | best_loss 8.937
2022-03-07 04:13:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 19756 updates
2022-03-07 04:13:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:13:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:13:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 406 @ 19756 updates, score 13.4) (writing took 2.4812020999379456 seconds)
2022-03-07 04:13:07 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)
2022-03-07 04:13:07 | INFO | train | epoch 406 | loss 2.141 | nll_loss 0.362 | ppl 1.28 | wps 22807.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 19756 | lr 0.000224983 | gnorm 0.438 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 54632
2022-03-07 04:13:07 | INFO | fairseq.trainer | begin training epoch 407
2022-03-07 04:13:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:15:03 | INFO | train_inner | epoch 407:     44 / 49 loss=2.141, nll_loss=0.361, ppl=1.28, wps=23127.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19800, lr=0.000224733, gnorm=0.437, loss_scale=16, train_wall=239, gb_free=8.8, wall=54748
2022-03-07 04:15:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:15:21 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 13.336 | nll_loss 12.725 | ppl 6769.78 | wps 40733.2 | wpb 510.9 | bsz 1 | num_updates 19805 | best_loss 8.937
2022-03-07 04:15:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 19805 updates
2022-03-07 04:15:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:15:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:15:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 407 @ 19805 updates, score 13.336) (writing took 2.4011638308875263 seconds)
2022-03-07 04:15:23 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)
2022-03-07 04:15:23 | INFO | train | epoch 407 | loss 2.14 | nll_loss 0.361 | ppl 1.28 | wps 23365.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19805 | lr 0.000224705 | gnorm 0.438 | loss_scale 16 | train_wall 116 | gb_free 8.8 | wall 54768
2022-03-07 04:15:23 | INFO | fairseq.trainer | begin training epoch 408
2022-03-07 04:15:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:17:36 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 13.352 | nll_loss 12.729 | ppl 6790.45 | wps 41528.4 | wpb 510.9 | bsz 1 | num_updates 19854 | best_loss 8.937
2022-03-07 04:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 19854 updates
2022-03-07 04:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:17:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:17:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 408 @ 19854 updates, score 13.352) (writing took 2.537813851144165 seconds)
2022-03-07 04:17:39 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)
2022-03-07 04:17:39 | INFO | train | epoch 408 | loss 2.14 | nll_loss 0.361 | ppl 1.28 | wps 23399.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 19854 | lr 0.000224427 | gnorm 0.431 | loss_scale 16 | train_wall 115 | gb_free 8.8 | wall 54904
2022-03-07 04:17:39 | INFO | fairseq.trainer | begin training epoch 409
2022-03-07 04:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:19:39 | INFO | train_inner | epoch 409:     46 / 49 loss=2.139, nll_loss=0.36, ppl=1.28, wps=23559.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=19900, lr=0.000224168, gnorm=0.431, loss_scale=32, train_wall=234, gb_free=8.8, wall=55023
2022-03-07 04:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:19:50 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 13.365 | nll_loss 12.751 | ppl 6894.76 | wps 41708.3 | wpb 510.9 | bsz 1 | num_updates 19903 | best_loss 8.937
2022-03-07 04:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 19903 updates
2022-03-07 04:19:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:19:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:19:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 409 @ 19903 updates, score 13.365) (writing took 2.3712091436609626 seconds)
2022-03-07 04:19:53 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)
2022-03-07 04:19:53 | INFO | train | epoch 409 | loss 2.139 | nll_loss 0.359 | ppl 1.28 | wps 23717.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19903 | lr 0.000224151 | gnorm 0.431 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 55038
2022-03-07 04:19:53 | INFO | fairseq.trainer | begin training epoch 410
2022-03-07 04:19:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:21:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:22:04 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 13.359 | nll_loss 12.743 | ppl 6853.39 | wps 42341 | wpb 510.9 | bsz 1 | num_updates 19952 | best_loss 8.937
2022-03-07 04:22:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 19952 updates
2022-03-07 04:22:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:22:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:22:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 410 @ 19952 updates, score 13.359) (writing took 2.5024358318187296 seconds)
2022-03-07 04:22:07 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)
2022-03-07 04:22:07 | INFO | train | epoch 410 | loss 2.139 | nll_loss 0.36 | ppl 1.28 | wps 23713 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 19952 | lr 0.000223876 | gnorm 0.436 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 55172
2022-03-07 04:22:07 | INFO | fairseq.trainer | begin training epoch 411
2022-03-07 04:22:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:24:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:24:13 | INFO | train_inner | epoch 411:     49 / 49 loss=2.139, nll_loss=0.36, ppl=1.28, wps=23517.8, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=20000, lr=0.000223607, gnorm=0.437, loss_scale=32, train_wall=234, gb_free=8.8, wall=55298
2022-03-07 04:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:24:18 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 13.371 | nll_loss 12.75 | ppl 6890.63 | wps 42061.2 | wpb 510.9 | bsz 1 | num_updates 20000 | best_loss 8.937
2022-03-07 04:24:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 20000 updates
2022-03-07 04:24:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:24:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:24:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 411 @ 20000 updates, score 13.371) (writing took 2.357381759211421 seconds)
2022-03-07 04:24:21 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)
2022-03-07 04:24:21 | INFO | train | epoch 411 | loss 2.138 | nll_loss 0.36 | ppl 1.28 | wps 23245.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20000 | lr 0.000223607 | gnorm 0.435 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 55306
2022-03-07 04:24:21 | INFO | fairseq.trainer | begin training epoch 412
2022-03-07 04:24:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:26:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:26:33 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 13.336 | nll_loss 12.717 | ppl 6734.35 | wps 41228.6 | wpb 510.9 | bsz 1 | num_updates 20049 | best_loss 8.937
2022-03-07 04:26:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 20049 updates
2022-03-07 04:26:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:26:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:26:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 412 @ 20049 updates, score 13.336) (writing took 2.442102316301316 seconds)
2022-03-07 04:26:35 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)
2022-03-07 04:26:35 | INFO | train | epoch 412 | loss 2.137 | nll_loss 0.358 | ppl 1.28 | wps 23666.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20049 | lr 0.000223333 | gnorm 0.426 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 55440
2022-03-07 04:26:35 | INFO | fairseq.trainer | begin training epoch 413
2022-03-07 04:26:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:28:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:28:47 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 13.269 | nll_loss 12.646 | ppl 6408.56 | wps 41989.8 | wpb 510.9 | bsz 1 | num_updates 20098 | best_loss 8.937
2022-03-07 04:28:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 20098 updates
2022-03-07 04:28:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:28:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:28:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 413 @ 20098 updates, score 13.269) (writing took 2.455686775036156 seconds)
2022-03-07 04:28:49 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)
2022-03-07 04:28:49 | INFO | train | epoch 413 | loss 2.138 | nll_loss 0.359 | ppl 1.28 | wps 23711.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20098 | lr 0.000223061 | gnorm 0.442 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 55574
2022-03-07 04:28:49 | INFO | fairseq.trainer | begin training epoch 414
2022-03-07 04:28:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:28:54 | INFO | train_inner | epoch 414:      2 / 49 loss=2.137, nll_loss=0.359, ppl=1.28, wps=23067.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=20100, lr=0.00022305, gnorm=0.434, loss_scale=32, train_wall=233, gb_free=8.8, wall=55579
2022-03-07 04:30:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:30:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:31:03 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 13.434 | nll_loss 12.822 | ppl 7239.28 | wps 40690.8 | wpb 510.9 | bsz 1 | num_updates 20146 | best_loss 8.937
2022-03-07 04:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 20146 updates
2022-03-07 04:31:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:31:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 414 @ 20146 updates, score 13.434) (writing took 2.5470146308653057 seconds)
2022-03-07 04:31:05 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)
2022-03-07 04:31:05 | INFO | train | epoch 414 | loss 2.136 | nll_loss 0.357 | ppl 1.28 | wps 22820.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 20146 | lr 0.000222795 | gnorm 0.436 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 55710
2022-03-07 04:31:05 | INFO | fairseq.trainer | begin training epoch 415
2022-03-07 04:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:33:20 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 13.397 | nll_loss 12.78 | ppl 7033.19 | wps 39987.4 | wpb 510.9 | bsz 1 | num_updates 20195 | best_loss 8.937
2022-03-07 04:33:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 20195 updates
2022-03-07 04:33:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:33:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:33:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 415 @ 20195 updates, score 13.397) (writing took 2.4516912791877985 seconds)
2022-03-07 04:33:22 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)
2022-03-07 04:33:22 | INFO | train | epoch 415 | loss 2.135 | nll_loss 0.357 | ppl 1.28 | wps 23247.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20195 | lr 0.000222525 | gnorm 0.43 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 55847
2022-03-07 04:33:22 | INFO | fairseq.trainer | begin training epoch 416
2022-03-07 04:33:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:33:36 | INFO | train_inner | epoch 416:      5 / 49 loss=2.135, nll_loss=0.357, ppl=1.28, wps=23075.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=20200, lr=0.000222497, gnorm=0.433, loss_scale=32, train_wall=239, gb_free=8.8, wall=55860
2022-03-07 04:35:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:35:36 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 13.317 | nll_loss 12.696 | ppl 6637.62 | wps 41146.2 | wpb 510.9 | bsz 1 | num_updates 20244 | best_loss 8.937
2022-03-07 04:35:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 20244 updates
2022-03-07 04:35:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:35:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:35:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 416 @ 20244 updates, score 13.317) (writing took 2.523547973949462 seconds)
2022-03-07 04:35:39 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)
2022-03-07 04:35:39 | INFO | train | epoch 416 | loss 2.136 | nll_loss 0.358 | ppl 1.28 | wps 23235.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20244 | lr 0.000222255 | gnorm 0.432 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 55984
2022-03-07 04:35:39 | INFO | fairseq.trainer | begin training epoch 417
2022-03-07 04:35:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:36:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:37:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:37:52 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 13.307 | nll_loss 12.686 | ppl 6589.38 | wps 40736.5 | wpb 510.9 | bsz 1 | num_updates 20292 | best_loss 8.937
2022-03-07 04:37:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 20292 updates
2022-03-07 04:37:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:37:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:37:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 417 @ 20292 updates, score 13.307) (writing took 2.5985133359208703 seconds)
2022-03-07 04:37:55 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)
2022-03-07 04:37:55 | INFO | train | epoch 417 | loss 2.135 | nll_loss 0.357 | ppl 1.28 | wps 22909.2 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 20292 | lr 0.000221992 | gnorm 0.431 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56120
2022-03-07 04:37:55 | INFO | fairseq.trainer | begin training epoch 418
2022-03-07 04:37:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:38:16 | INFO | train_inner | epoch 418:      8 / 49 loss=2.135, nll_loss=0.357, ppl=1.28, wps=23143.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=20300, lr=0.000221948, gnorm=0.432, loss_scale=32, train_wall=239, gb_free=8.8, wall=56141
2022-03-07 04:40:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:40:07 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 13.31 | nll_loss 12.69 | ppl 6608.44 | wps 41827.8 | wpb 510.9 | bsz 1 | num_updates 20341 | best_loss 8.937
2022-03-07 04:40:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 20341 updates
2022-03-07 04:40:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:40:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:40:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 418 @ 20341 updates, score 13.31) (writing took 2.561129721812904 seconds)
2022-03-07 04:40:10 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)
2022-03-07 04:40:10 | INFO | train | epoch 418 | loss 2.135 | nll_loss 0.357 | ppl 1.28 | wps 23550.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20341 | lr 0.000221725 | gnorm 0.434 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56255
2022-03-07 04:40:10 | INFO | fairseq.trainer | begin training epoch 419
2022-03-07 04:40:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:42:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:42:22 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 13.269 | nll_loss 12.645 | ppl 6404.99 | wps 41314.6 | wpb 510.9 | bsz 1 | num_updates 20390 | best_loss 8.937
2022-03-07 04:42:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 20390 updates
2022-03-07 04:42:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:42:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:42:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 419 @ 20390 updates, score 13.269) (writing took 2.3613526611588895 seconds)
2022-03-07 04:42:25 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)
2022-03-07 04:42:25 | INFO | train | epoch 419 | loss 2.134 | nll_loss 0.356 | ppl 1.28 | wps 23531.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20390 | lr 0.000221458 | gnorm 0.434 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 56390
2022-03-07 04:42:25 | INFO | fairseq.trainer | begin training epoch 420
2022-03-07 04:42:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:42:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:42:54 | INFO | train_inner | epoch 420:     11 / 49 loss=2.134, nll_loss=0.356, ppl=1.28, wps=23339.6, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=20400, lr=0.000221404, gnorm=0.435, loss_scale=32, train_wall=237, gb_free=8.8, wall=56418
2022-03-07 04:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:44:37 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 13.3 | nll_loss 12.682 | ppl 6569.86 | wps 41565.5 | wpb 510.9 | bsz 1 | num_updates 20438 | best_loss 8.937
2022-03-07 04:44:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 20438 updates
2022-03-07 04:44:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:44:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:44:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 420 @ 20438 updates, score 13.3) (writing took 2.3412628592923284 seconds)
2022-03-07 04:44:40 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)
2022-03-07 04:44:40 | INFO | train | epoch 420 | loss 2.133 | nll_loss 0.355 | ppl 1.28 | wps 23060.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20438 | lr 0.000221198 | gnorm 0.437 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56525
2022-03-07 04:44:40 | INFO | fairseq.trainer | begin training epoch 421
2022-03-07 04:44:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:46:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:46:52 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 13.354 | nll_loss 12.738 | ppl 6832.13 | wps 41367.4 | wpb 510.9 | bsz 1 | num_updates 20487 | best_loss 8.937
2022-03-07 04:46:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 20487 updates
2022-03-07 04:46:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 421 @ 20487 updates, score 13.354) (writing took 2.383460225071758 seconds)
2022-03-07 04:46:55 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)
2022-03-07 04:46:55 | INFO | train | epoch 421 | loss 2.131 | nll_loss 0.354 | ppl 1.28 | wps 23552.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20487 | lr 0.000220933 | gnorm 0.425 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56659
2022-03-07 04:46:55 | INFO | fairseq.trainer | begin training epoch 422
2022-03-07 04:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:47:29 | INFO | train_inner | epoch 422:     13 / 49 loss=2.132, nll_loss=0.354, ppl=1.28, wps=23560.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=20500, lr=0.000220863, gnorm=0.43, loss_scale=32, train_wall=235, gb_free=8.8, wall=56694
2022-03-07 04:48:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:49:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:49:08 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 13.337 | nll_loss 12.722 | ppl 6754.89 | wps 41413.7 | wpb 510.9 | bsz 1 | num_updates 20535 | best_loss 8.937
2022-03-07 04:49:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 20535 updates
2022-03-07 04:49:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:49:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:49:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 422 @ 20535 updates, score 13.337) (writing took 2.5532666090875864 seconds)
2022-03-07 04:49:10 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)
2022-03-07 04:49:10 | INFO | train | epoch 422 | loss 2.132 | nll_loss 0.354 | ppl 1.28 | wps 22982.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 20535 | lr 0.000220675 | gnorm 0.432 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56795
2022-03-07 04:49:10 | INFO | fairseq.trainer | begin training epoch 423
2022-03-07 04:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:51:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:51:23 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 13.295 | nll_loss 12.677 | ppl 6547.64 | wps 41395.1 | wpb 510.9 | bsz 1 | num_updates 20584 | best_loss 8.937
2022-03-07 04:51:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 20584 updates
2022-03-07 04:51:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:51:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 423 @ 20584 updates, score 13.295) (writing took 2.3576963990926743 seconds)
2022-03-07 04:51:25 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)
2022-03-07 04:51:25 | INFO | train | epoch 423 | loss 2.131 | nll_loss 0.354 | ppl 1.28 | wps 23579.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20584 | lr 0.000220412 | gnorm 0.426 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 56930
2022-03-07 04:51:25 | INFO | fairseq.trainer | begin training epoch 424
2022-03-07 04:51:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:52:07 | INFO | train_inner | epoch 424:     16 / 49 loss=2.131, nll_loss=0.354, ppl=1.28, wps=23355.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=20600, lr=0.000220326, gnorm=0.427, loss_scale=32, train_wall=237, gb_free=8.8, wall=56972
2022-03-07 04:53:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:53:36 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 13.32 | nll_loss 12.7 | ppl 6652.23 | wps 43089.3 | wpb 510.9 | bsz 1 | num_updates 20633 | best_loss 8.937
2022-03-07 04:53:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 20633 updates
2022-03-07 04:53:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:53:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 424 @ 20633 updates, score 13.32) (writing took 2.2999250288121402 seconds)
2022-03-07 04:53:39 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)
2022-03-07 04:53:39 | INFO | train | epoch 424 | loss 2.13 | nll_loss 0.353 | ppl 1.28 | wps 23763.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20633 | lr 0.00022015 | gnorm 0.422 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 57063
2022-03-07 04:53:39 | INFO | fairseq.trainer | begin training epoch 425
2022-03-07 04:53:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:54:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 04:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:55:49 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 13.258 | nll_loss 12.634 | ppl 6354.46 | wps 44058.7 | wpb 510.9 | bsz 1 | num_updates 20681 | best_loss 8.937
2022-03-07 04:55:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 20681 updates
2022-03-07 04:55:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:55:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:55:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 425 @ 20681 updates, score 13.258) (writing took 2.318123992998153 seconds)
2022-03-07 04:55:51 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)
2022-03-07 04:55:51 | INFO | train | epoch 425 | loss 2.13 | nll_loss 0.353 | ppl 1.28 | wps 23513.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20681 | lr 0.000219894 | gnorm 0.424 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57196
2022-03-07 04:55:51 | INFO | fairseq.trainer | begin training epoch 426
2022-03-07 04:55:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 04:56:40 | INFO | train_inner | epoch 426:     19 / 49 loss=2.13, nll_loss=0.353, ppl=1.28, wps=23760.1, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=20700, lr=0.000219793, gnorm=0.424, loss_scale=32, train_wall=233, gb_free=8.8, wall=57245
2022-03-07 04:57:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 04:58:01 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 13.308 | nll_loss 12.688 | ppl 6599.66 | wps 43221 | wpb 510.9 | bsz 1 | num_updates 20730 | best_loss 8.937
2022-03-07 04:58:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 20730 updates
2022-03-07 04:58:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:58:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 04:58:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 426 @ 20730 updates, score 13.308) (writing took 2.3364652530290186 seconds)
2022-03-07 04:58:03 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)
2022-03-07 04:58:03 | INFO | train | epoch 426 | loss 2.131 | nll_loss 0.354 | ppl 1.28 | wps 24091.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20730 | lr 0.000219634 | gnorm 0.432 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 57328
2022-03-07 04:58:03 | INFO | fairseq.trainer | begin training epoch 427
2022-03-07 04:58:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:00:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:00:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:00:13 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 13.379 | nll_loss 12.769 | ppl 6980.48 | wps 43470.9 | wpb 510.9 | bsz 1 | num_updates 20778 | best_loss 8.937
2022-03-07 05:00:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 20778 updates
2022-03-07 05:00:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:00:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:00:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 427 @ 20778 updates, score 13.379) (writing took 2.3439329410903156 seconds)
2022-03-07 05:00:15 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)
2022-03-07 05:00:15 | INFO | train | epoch 427 | loss 2.129 | nll_loss 0.353 | ppl 1.28 | wps 23564.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20778 | lr 0.000219381 | gnorm 0.421 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 57460
2022-03-07 05:00:15 | INFO | fairseq.trainer | begin training epoch 428
2022-03-07 05:00:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:01:12 | INFO | train_inner | epoch 428:     22 / 49 loss=2.129, nll_loss=0.353, ppl=1.28, wps=23858.8, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=20800, lr=0.000219265, gnorm=0.426, loss_scale=32, train_wall=232, gb_free=8.8, wall=57517
2022-03-07 05:02:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:02:25 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 13.244 | nll_loss 12.622 | ppl 6301.73 | wps 43345.2 | wpb 510.9 | bsz 1 | num_updates 20827 | best_loss 8.937
2022-03-07 05:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 20827 updates
2022-03-07 05:02:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:02:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:02:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 428 @ 20827 updates, score 13.244) (writing took 2.367636729963124 seconds)
2022-03-07 05:02:28 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)
2022-03-07 05:02:28 | INFO | train | epoch 428 | loss 2.129 | nll_loss 0.352 | ppl 1.28 | wps 23981.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20827 | lr 0.000219122 | gnorm 0.432 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57592
2022-03-07 05:02:28 | INFO | fairseq.trainer | begin training epoch 429
2022-03-07 05:02:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:04:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:04:37 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 13.343 | nll_loss 12.726 | ppl 6774.24 | wps 43152 | wpb 510.9 | bsz 1 | num_updates 20876 | best_loss 8.937
2022-03-07 05:04:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 20876 updates
2022-03-07 05:04:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:04:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:04:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 429 @ 20876 updates, score 13.343) (writing took 2.389900431036949 seconds)
2022-03-07 05:04:40 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)
2022-03-07 05:04:40 | INFO | train | epoch 429 | loss 2.128 | nll_loss 0.352 | ppl 1.28 | wps 24038.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 20876 | lr 0.000218865 | gnorm 0.423 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 57725
2022-03-07 05:04:40 | INFO | fairseq.trainer | begin training epoch 430
2022-03-07 05:04:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:05:42 | INFO | train_inner | epoch 430:     24 / 49 loss=2.128, nll_loss=0.352, ppl=1.28, wps=24043.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=20900, lr=0.000218739, gnorm=0.427, loss_scale=32, train_wall=230, gb_free=8.8, wall=57786
2022-03-07 05:05:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:06:50 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 13.305 | nll_loss 12.688 | ppl 6597.55 | wps 42591 | wpb 510.9 | bsz 1 | num_updates 20924 | best_loss 8.937
2022-03-07 05:06:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 20924 updates
2022-03-07 05:06:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 430 @ 20924 updates, score 13.305) (writing took 2.463289160747081 seconds)
2022-03-07 05:06:52 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)
2022-03-07 05:06:52 | INFO | train | epoch 430 | loss 2.128 | nll_loss 0.351 | ppl 1.28 | wps 23462.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 20924 | lr 0.000218614 | gnorm 0.422 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 57857
2022-03-07 05:06:52 | INFO | fairseq.trainer | begin training epoch 431
2022-03-07 05:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:09:05 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 13.303 | nll_loss 12.681 | ppl 6566.29 | wps 40957.9 | wpb 510.9 | bsz 1 | num_updates 20973 | best_loss 8.937
2022-03-07 05:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 20973 updates
2022-03-07 05:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:09:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 431 @ 20973 updates, score 13.303) (writing took 2.5498285330832005 seconds)
2022-03-07 05:09:07 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)
2022-03-07 05:09:07 | INFO | train | epoch 431 | loss 2.127 | nll_loss 0.351 | ppl 1.28 | wps 23543.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 20973 | lr 0.000218358 | gnorm 0.428 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 57992
2022-03-07 05:09:07 | INFO | fairseq.trainer | begin training epoch 432
2022-03-07 05:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:10:18 | INFO | train_inner | epoch 432:     27 / 49 loss=2.127, nll_loss=0.351, ppl=1.28, wps=23445.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21000, lr=0.000218218, gnorm=0.428, loss_scale=32, train_wall=236, gb_free=8.8, wall=58063
2022-03-07 05:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:11:20 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 13.424 | nll_loss 12.811 | ppl 7183.81 | wps 41009.9 | wpb 510.9 | bsz 1 | num_updates 21022 | best_loss 8.937
2022-03-07 05:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 21022 updates
2022-03-07 05:11:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:11:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:11:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 432 @ 21022 updates, score 13.424) (writing took 2.433889382984489 seconds)
2022-03-07 05:11:23 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)
2022-03-07 05:11:23 | INFO | train | epoch 432 | loss 2.127 | nll_loss 0.351 | ppl 1.28 | wps 23520.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21022 | lr 0.000218104 | gnorm 0.429 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58127
2022-03-07 05:11:23 | INFO | fairseq.trainer | begin training epoch 433
2022-03-07 05:11:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:11:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:13:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:13:35 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 13.453 | nll_loss 12.847 | ppl 7365.81 | wps 41312.8 | wpb 510.9 | bsz 1 | num_updates 21070 | best_loss 8.937
2022-03-07 05:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 21070 updates
2022-03-07 05:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:13:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 433 @ 21070 updates, score 13.453) (writing took 2.4795927084051073 seconds)
2022-03-07 05:13:38 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)
2022-03-07 05:13:38 | INFO | train | epoch 433 | loss 2.126 | nll_loss 0.35 | ppl 1.27 | wps 23060.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21070 | lr 0.000217855 | gnorm 0.424 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58262
2022-03-07 05:13:38 | INFO | fairseq.trainer | begin training epoch 434
2022-03-07 05:13:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:14:56 | INFO | train_inner | epoch 434:     30 / 49 loss=2.126, nll_loss=0.35, ppl=1.27, wps=23340.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21100, lr=0.0002177, gnorm=0.423, loss_scale=32, train_wall=237, gb_free=8.8, wall=58341
2022-03-07 05:15:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:15:50 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 13.343 | nll_loss 12.729 | ppl 6789.7 | wps 42127.9 | wpb 510.9 | bsz 1 | num_updates 21119 | best_loss 8.937
2022-03-07 05:15:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 21119 updates
2022-03-07 05:15:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:15:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:15:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 434 @ 21119 updates, score 13.343) (writing took 2.352633820846677 seconds)
2022-03-07 05:15:52 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)
2022-03-07 05:15:52 | INFO | train | epoch 434 | loss 2.126 | nll_loss 0.35 | ppl 1.27 | wps 23584 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21119 | lr 0.000217602 | gnorm 0.42 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58397
2022-03-07 05:15:52 | INFO | fairseq.trainer | begin training epoch 435
2022-03-07 05:15:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:17:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:17:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:18:05 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 13.373 | nll_loss 12.762 | ppl 6948.02 | wps 41382.6 | wpb 510.9 | bsz 1 | num_updates 21167 | best_loss 8.937
2022-03-07 05:18:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 21167 updates
2022-03-07 05:18:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:18:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:18:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 435 @ 21167 updates, score 13.373) (writing took 2.4095778055489063 seconds)
2022-03-07 05:18:07 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)
2022-03-07 05:18:07 | INFO | train | epoch 435 | loss 2.125 | nll_loss 0.349 | ppl 1.27 | wps 23080 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21167 | lr 0.000217355 | gnorm 0.421 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58532
2022-03-07 05:18:07 | INFO | fairseq.trainer | begin training epoch 436
2022-03-07 05:18:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:19:34 | INFO | train_inner | epoch 436:     33 / 49 loss=2.125, nll_loss=0.349, ppl=1.27, wps=23382, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21200, lr=0.000217186, gnorm=0.423, loss_scale=32, train_wall=237, gb_free=8.8, wall=58618
2022-03-07 05:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:20:20 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 13.381 | nll_loss 12.766 | ppl 6963.54 | wps 41222 | wpb 510.9 | bsz 1 | num_updates 21216 | best_loss 8.937
2022-03-07 05:20:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 21216 updates
2022-03-07 05:20:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:20:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:20:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 436 @ 21216 updates, score 13.381) (writing took 2.447437833994627 seconds)
2022-03-07 05:20:22 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)
2022-03-07 05:20:22 | INFO | train | epoch 436 | loss 2.124 | nll_loss 0.349 | ppl 1.27 | wps 23530 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21216 | lr 0.000217104 | gnorm 0.427 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58667
2022-03-07 05:20:22 | INFO | fairseq.trainer | begin training epoch 437
2022-03-07 05:20:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:22:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:22:35 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 13.373 | nll_loss 12.763 | ppl 6951.88 | wps 41757.8 | wpb 510.9 | bsz 1 | num_updates 21265 | best_loss 8.937
2022-03-07 05:22:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 21265 updates
2022-03-07 05:22:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:22:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:22:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 437 @ 21265 updates, score 13.373) (writing took 2.507088913116604 seconds)
2022-03-07 05:22:37 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)
2022-03-07 05:22:37 | INFO | train | epoch 437 | loss 2.125 | nll_loss 0.349 | ppl 1.27 | wps 23548.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21265 | lr 0.000216854 | gnorm 0.422 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58802
2022-03-07 05:22:37 | INFO | fairseq.trainer | begin training epoch 438
2022-03-07 05:22:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:24:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:24:12 | INFO | train_inner | epoch 438:     36 / 49 loss=2.124, nll_loss=0.348, ppl=1.27, wps=23345.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21300, lr=0.000216676, gnorm=0.421, loss_scale=32, train_wall=237, gb_free=8.8, wall=58896
2022-03-07 05:24:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:24:50 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 13.362 | nll_loss 12.748 | ppl 6876.99 | wps 41346.5 | wpb 510.9 | bsz 1 | num_updates 21313 | best_loss 8.937
2022-03-07 05:24:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 21313 updates
2022-03-07 05:24:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:24:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:24:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 438 @ 21313 updates, score 13.362) (writing took 2.4151691971346736 seconds)
2022-03-07 05:24:52 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)
2022-03-07 05:24:52 | INFO | train | epoch 438 | loss 2.123 | nll_loss 0.348 | ppl 1.27 | wps 23078.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21313 | lr 0.00021661 | gnorm 0.419 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 58937
2022-03-07 05:24:52 | INFO | fairseq.trainer | begin training epoch 439
2022-03-07 05:24:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:27:04 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 13.355 | nll_loss 12.743 | ppl 6857.2 | wps 41850.2 | wpb 510.9 | bsz 1 | num_updates 21362 | best_loss 8.937
2022-03-07 05:27:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 21362 updates
2022-03-07 05:27:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:27:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:27:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 439 @ 21362 updates, score 13.355) (writing took 2.3873839606530964 seconds)
2022-03-07 05:27:07 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)
2022-03-07 05:27:07 | INFO | train | epoch 439 | loss 2.123 | nll_loss 0.348 | ppl 1.27 | wps 23594.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21362 | lr 0.000216361 | gnorm 0.423 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 59071
2022-03-07 05:27:07 | INFO | fairseq.trainer | begin training epoch 440
2022-03-07 05:27:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:28:46 | INFO | train_inner | epoch 440:     38 / 49 loss=2.123, nll_loss=0.348, ppl=1.27, wps=23603.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=21400, lr=0.000216169, gnorm=0.42, loss_scale=32, train_wall=234, gb_free=8.8, wall=59171
2022-03-07 05:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:29:19 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 13.304 | nll_loss 12.686 | ppl 6588.31 | wps 41496.1 | wpb 510.9 | bsz 1 | num_updates 21411 | best_loss 8.937
2022-03-07 05:29:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 21411 updates
2022-03-07 05:29:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:29:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:29:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 440 @ 21411 updates, score 13.304) (writing took 2.4270597477443516 seconds)
2022-03-07 05:29:21 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)
2022-03-07 05:29:21 | INFO | train | epoch 440 | loss 2.123 | nll_loss 0.348 | ppl 1.27 | wps 23591 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21411 | lr 0.000216113 | gnorm 0.418 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 59206
2022-03-07 05:29:21 | INFO | fairseq.trainer | begin training epoch 441
2022-03-07 05:29:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:30:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:31:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:31:32 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 13.446 | nll_loss 12.841 | ppl 7337.16 | wps 43437.4 | wpb 510.9 | bsz 1 | num_updates 21459 | best_loss 8.937
2022-03-07 05:31:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 21459 updates
2022-03-07 05:31:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:31:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 441 @ 21459 updates, score 13.446) (writing took 2.3655568258836865 seconds)
2022-03-07 05:31:35 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)
2022-03-07 05:31:35 | INFO | train | epoch 441 | loss 2.122 | nll_loss 0.347 | ppl 1.27 | wps 23358.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21459 | lr 0.000215871 | gnorm 0.423 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59339
2022-03-07 05:31:35 | INFO | fairseq.trainer | begin training epoch 442
2022-03-07 05:31:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:33:20 | INFO | train_inner | epoch 442:     41 / 49 loss=2.122, nll_loss=0.347, ppl=1.27, wps=23687.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21500, lr=0.000215666, gnorm=0.427, loss_scale=32, train_wall=233, gb_free=8.8, wall=59445
2022-03-07 05:33:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:33:45 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 13.413 | nll_loss 12.804 | ppl 7150.02 | wps 43466.2 | wpb 510.9 | bsz 1 | num_updates 21508 | best_loss 8.937
2022-03-07 05:33:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 21508 updates
2022-03-07 05:33:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:33:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:33:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 442 @ 21508 updates, score 13.413) (writing took 2.279694892000407 seconds)
2022-03-07 05:33:47 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)
2022-03-07 05:33:47 | INFO | train | epoch 442 | loss 2.122 | nll_loss 0.347 | ppl 1.27 | wps 24045.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21508 | lr 0.000215625 | gnorm 0.431 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59472
2022-03-07 05:33:47 | INFO | fairseq.trainer | begin training epoch 443
2022-03-07 05:33:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:35:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:35:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:35:57 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 13.303 | nll_loss 12.685 | ppl 6585.51 | wps 43588.2 | wpb 510.9 | bsz 1 | num_updates 21556 | best_loss 8.937
2022-03-07 05:35:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 21556 updates
2022-03-07 05:35:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:35:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:35:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 443 @ 21556 updates, score 13.303) (writing took 2.4430733709596097 seconds)
2022-03-07 05:35:59 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)
2022-03-07 05:35:59 | INFO | train | epoch 443 | loss 2.121 | nll_loss 0.346 | ppl 1.27 | wps 23532.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21556 | lr 0.000215385 | gnorm 0.416 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59604
2022-03-07 05:35:59 | INFO | fairseq.trainer | begin training epoch 444
2022-03-07 05:35:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:37:53 | INFO | train_inner | epoch 444:     44 / 49 loss=2.121, nll_loss=0.346, ppl=1.27, wps=23826.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21600, lr=0.000215166, gnorm=0.419, loss_scale=32, train_wall=232, gb_free=8.8, wall=59717
2022-03-07 05:38:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:38:09 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 13.425 | nll_loss 12.818 | ppl 7222.5 | wps 43786.6 | wpb 510.9 | bsz 1 | num_updates 21605 | best_loss 8.937
2022-03-07 05:38:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 21605 updates
2022-03-07 05:38:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:38:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:38:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 444 @ 21605 updates, score 13.425) (writing took 2.4201821866445243 seconds)
2022-03-07 05:38:11 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)
2022-03-07 05:38:11 | INFO | train | epoch 444 | loss 2.121 | nll_loss 0.346 | ppl 1.27 | wps 24009.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21605 | lr 0.000215141 | gnorm 0.419 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59736
2022-03-07 05:38:11 | INFO | fairseq.trainer | begin training epoch 445
2022-03-07 05:38:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:40:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:40:22 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 13.285 | nll_loss 12.672 | ppl 6524.22 | wps 42253.5 | wpb 510.9 | bsz 1 | num_updates 21654 | best_loss 8.937
2022-03-07 05:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 21654 updates
2022-03-07 05:40:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:40:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:40:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 445 @ 21654 updates, score 13.285) (writing took 2.4967158110812306 seconds)
2022-03-07 05:40:24 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)
2022-03-07 05:40:24 | INFO | train | epoch 445 | loss 2.121 | nll_loss 0.346 | ppl 1.27 | wps 23965.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21654 | lr 0.000214897 | gnorm 0.418 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 59869
2022-03-07 05:40:24 | INFO | fairseq.trainer | begin training epoch 446
2022-03-07 05:40:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:41:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:42:25 | INFO | train_inner | epoch 446:     47 / 49 loss=2.12, nll_loss=0.346, ppl=1.27, wps=23803.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=21700, lr=0.000214669, gnorm=0.417, loss_scale=32, train_wall=232, gb_free=8.8, wall=59990
2022-03-07 05:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:42:34 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 13.381 | nll_loss 12.771 | ppl 6989.96 | wps 42195.8 | wpb 510.9 | bsz 1 | num_updates 21702 | best_loss 8.937
2022-03-07 05:42:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 21702 updates
2022-03-07 05:42:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:42:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:42:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 446 @ 21702 updates, score 13.381) (writing took 2.4286066978238523 seconds)
2022-03-07 05:42:37 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)
2022-03-07 05:42:37 | INFO | train | epoch 446 | loss 2.12 | nll_loss 0.345 | ppl 1.27 | wps 23483.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21702 | lr 0.00021466 | gnorm 0.418 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 60001
2022-03-07 05:42:37 | INFO | fairseq.trainer | begin training epoch 447
2022-03-07 05:42:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:44:48 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 13.351 | nll_loss 12.737 | ppl 6828.31 | wps 41317.4 | wpb 510.9 | bsz 1 | num_updates 21751 | best_loss 8.937
2022-03-07 05:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 21751 updates
2022-03-07 05:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 447 @ 21751 updates, score 13.351) (writing took 2.4106450299732387 seconds)
2022-03-07 05:44:50 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)
2022-03-07 05:44:50 | INFO | train | epoch 447 | loss 2.12 | nll_loss 0.345 | ppl 1.27 | wps 23780.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 21751 | lr 0.000214418 | gnorm 0.42 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 60135
2022-03-07 05:44:50 | INFO | fairseq.trainer | begin training epoch 448
2022-03-07 05:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:46:57 | INFO | train_inner | epoch 448:     49 / 49 loss=2.119, nll_loss=0.345, ppl=1.27, wps=23691.7, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=21800, lr=0.000214176, gnorm=0.421, loss_scale=32, train_wall=232, gb_free=8.8, wall=60262
2022-03-07 05:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:47:03 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 13.275 | nll_loss 12.655 | ppl 6449.23 | wps 41046 | wpb 510.9 | bsz 1 | num_updates 21800 | best_loss 8.937
2022-03-07 05:47:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 21800 updates
2022-03-07 05:47:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 448 @ 21800 updates, score 13.275) (writing took 2.342598563991487 seconds)
2022-03-07 05:47:05 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)
2022-03-07 05:47:05 | INFO | train | epoch 448 | loss 2.119 | nll_loss 0.344 | ppl 1.27 | wps 23551.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21800 | lr 0.000214176 | gnorm 0.42 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60270
2022-03-07 05:47:05 | INFO | fairseq.trainer | begin training epoch 449
2022-03-07 05:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:47:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:49:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:49:18 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 13.29 | nll_loss 12.674 | ppl 6536.08 | wps 40970.1 | wpb 510.9 | bsz 1 | num_updates 21848 | best_loss 8.937
2022-03-07 05:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 21848 updates
2022-03-07 05:49:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:49:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:49:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 449 @ 21848 updates, score 13.29) (writing took 2.416279855184257 seconds)
2022-03-07 05:49:20 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)
2022-03-07 05:49:20 | INFO | train | epoch 449 | loss 2.119 | nll_loss 0.345 | ppl 1.27 | wps 23058.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21848 | lr 0.000213941 | gnorm 0.426 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60405
2022-03-07 05:49:20 | INFO | fairseq.trainer | begin training epoch 450
2022-03-07 05:49:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:51:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:51:33 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 13.34 | nll_loss 12.729 | ppl 6790.64 | wps 40844.6 | wpb 510.9 | bsz 1 | num_updates 21897 | best_loss 8.937
2022-03-07 05:51:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 21897 updates
2022-03-07 05:51:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:51:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:51:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 450 @ 21897 updates, score 13.34) (writing took 2.4469329393468797 seconds)
2022-03-07 05:51:35 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)
2022-03-07 05:51:35 | INFO | train | epoch 450 | loss 2.117 | nll_loss 0.343 | ppl 1.27 | wps 23490.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21897 | lr 0.000213702 | gnorm 0.416 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60540
2022-03-07 05:51:35 | INFO | fairseq.trainer | begin training epoch 451
2022-03-07 05:51:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:51:43 | INFO | train_inner | epoch 451:      3 / 49 loss=2.118, nll_loss=0.344, ppl=1.27, wps=22685.4, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=21900, lr=0.000213687, gnorm=0.421, loss_scale=32, train_wall=237, gb_free=8.8, wall=60548
2022-03-07 05:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:53:48 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 13.331 | nll_loss 12.72 | ppl 6745.6 | wps 41294.8 | wpb 510.9 | bsz 1 | num_updates 21946 | best_loss 8.937
2022-03-07 05:53:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 21946 updates
2022-03-07 05:53:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:53:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:53:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 451 @ 21946 updates, score 13.331) (writing took 2.457728016190231 seconds)
2022-03-07 05:53:50 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)
2022-03-07 05:53:50 | INFO | train | epoch 451 | loss 2.118 | nll_loss 0.344 | ppl 1.27 | wps 23550.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 21946 | lr 0.000213463 | gnorm 0.418 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 60675
2022-03-07 05:53:50 | INFO | fairseq.trainer | begin training epoch 452
2022-03-07 05:53:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:53:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 05:55:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:56:03 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 13.388 | nll_loss 12.782 | ppl 7042.8 | wps 41178.3 | wpb 510.9 | bsz 1 | num_updates 21994 | best_loss 8.937
2022-03-07 05:56:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 21994 updates
2022-03-07 05:56:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:56:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:56:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 452 @ 21994 updates, score 13.388) (writing took 2.324669854249805 seconds)
2022-03-07 05:56:05 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)
2022-03-07 05:56:05 | INFO | train | epoch 452 | loss 2.118 | nll_loss 0.344 | ppl 1.27 | wps 23078.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 21994 | lr 0.00021323 | gnorm 0.418 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60810
2022-03-07 05:56:05 | INFO | fairseq.trainer | begin training epoch 453
2022-03-07 05:56:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:56:21 | INFO | train_inner | epoch 453:      6 / 49 loss=2.117, nll_loss=0.344, ppl=1.27, wps=23362.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22000, lr=0.000213201, gnorm=0.418, loss_scale=32, train_wall=237, gb_free=8.8, wall=60826
2022-03-07 05:58:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 05:58:18 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 13.372 | nll_loss 12.762 | ppl 6946.63 | wps 41861 | wpb 510.9 | bsz 1 | num_updates 22043 | best_loss 8.937
2022-03-07 05:58:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 22043 updates
2022-03-07 05:58:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:58:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 05:58:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 453 @ 22043 updates, score 13.372) (writing took 2.3898508339188993 seconds)
2022-03-07 05:58:20 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)
2022-03-07 05:58:20 | INFO | train | epoch 453 | loss 2.117 | nll_loss 0.343 | ppl 1.27 | wps 23551.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22043 | lr 0.000212993 | gnorm 0.418 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 60945
2022-03-07 05:58:20 | INFO | fairseq.trainer | begin training epoch 454
2022-03-07 05:58:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 05:59:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:00:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:00:33 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 13.307 | nll_loss 12.688 | ppl 6599.73 | wps 41293.4 | wpb 510.9 | bsz 1 | num_updates 22091 | best_loss 8.937
2022-03-07 06:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 22091 updates
2022-03-07 06:00:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:00:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:00:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 454 @ 22091 updates, score 13.307) (writing took 2.45029063988477 seconds)
2022-03-07 06:00:35 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)
2022-03-07 06:00:35 | INFO | train | epoch 454 | loss 2.117 | nll_loss 0.343 | ppl 1.27 | wps 23043.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22091 | lr 0.000212761 | gnorm 0.42 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61080
2022-03-07 06:00:35 | INFO | fairseq.trainer | begin training epoch 455
2022-03-07 06:00:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:00:59 | INFO | train_inner | epoch 455:      9 / 49 loss=2.117, nll_loss=0.343, ppl=1.27, wps=23342.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22100, lr=0.000212718, gnorm=0.419, loss_scale=32, train_wall=237, gb_free=8.8, wall=61104
2022-03-07 06:02:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:02:48 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 13.312 | nll_loss 12.696 | ppl 6635.74 | wps 41016.6 | wpb 510.9 | bsz 1 | num_updates 22140 | best_loss 8.937
2022-03-07 06:02:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 22140 updates
2022-03-07 06:02:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:02:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 455 @ 22140 updates, score 13.312) (writing took 2.3983665220439434 seconds)
2022-03-07 06:02:50 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)
2022-03-07 06:02:50 | INFO | train | epoch 455 | loss 2.116 | nll_loss 0.343 | ppl 1.27 | wps 23520.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22140 | lr 0.000212526 | gnorm 0.422 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61215
2022-03-07 06:02:50 | INFO | fairseq.trainer | begin training epoch 456
2022-03-07 06:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:05:03 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 13.424 | nll_loss 12.818 | ppl 7221.83 | wps 41542.8 | wpb 510.9 | bsz 1 | num_updates 22189 | best_loss 8.937
2022-03-07 06:05:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 22189 updates
2022-03-07 06:05:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:05:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:05:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 456 @ 22189 updates, score 13.424) (writing took 2.382908685132861 seconds)
2022-03-07 06:05:05 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)
2022-03-07 06:05:05 | INFO | train | epoch 456 | loss 2.115 | nll_loss 0.342 | ppl 1.27 | wps 23586.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22189 | lr 0.000212291 | gnorm 0.412 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61350
2022-03-07 06:05:05 | INFO | fairseq.trainer | begin training epoch 457
2022-03-07 06:05:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:05:34 | INFO | train_inner | epoch 457:     11 / 49 loss=2.115, nll_loss=0.342, ppl=1.27, wps=23589.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22200, lr=0.000212238, gnorm=0.416, loss_scale=32, train_wall=234, gb_free=8.8, wall=61379
2022-03-07 06:05:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:07:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:07:18 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 13.339 | nll_loss 12.723 | ppl 6760.22 | wps 41225.7 | wpb 510.9 | bsz 1 | num_updates 22237 | best_loss 8.937
2022-03-07 06:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 22237 updates
2022-03-07 06:07:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:07:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 457 @ 22237 updates, score 13.339) (writing took 2.318185791838914 seconds)
2022-03-07 06:07:20 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)
2022-03-07 06:07:20 | INFO | train | epoch 457 | loss 2.115 | nll_loss 0.341 | ppl 1.27 | wps 23091.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22237 | lr 0.000212062 | gnorm 0.415 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61485
2022-03-07 06:07:20 | INFO | fairseq.trainer | begin training epoch 458
2022-03-07 06:07:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:09:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:09:30 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 13.308 | nll_loss 12.697 | ppl 6638.83 | wps 42372.9 | wpb 510.9 | bsz 1 | num_updates 22286 | best_loss 8.937
2022-03-07 06:09:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 22286 updates
2022-03-07 06:09:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:09:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:09:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 458 @ 22286 updates, score 13.308) (writing took 2.4723167051561177 seconds)
2022-03-07 06:09:32 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)
2022-03-07 06:09:32 | INFO | train | epoch 458 | loss 2.114 | nll_loss 0.341 | ppl 1.27 | wps 23991.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22286 | lr 0.000211828 | gnorm 0.417 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 61617
2022-03-07 06:09:32 | INFO | fairseq.trainer | begin training epoch 459
2022-03-07 06:09:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:10:09 | INFO | train_inner | epoch 459:     14 / 49 loss=2.114, nll_loss=0.341, ppl=1.27, wps=23576.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22300, lr=0.000211762, gnorm=0.416, loss_scale=32, train_wall=234, gb_free=8.8, wall=61654
2022-03-07 06:11:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:11:45 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 13.333 | nll_loss 12.722 | ppl 6755.58 | wps 39882.3 | wpb 510.9 | bsz 1 | num_updates 22335 | best_loss 8.937
2022-03-07 06:11:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 22335 updates
2022-03-07 06:11:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:11:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:11:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 459 @ 22335 updates, score 13.333) (writing took 2.5717398887500167 seconds)
2022-03-07 06:11:47 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)
2022-03-07 06:11:47 | INFO | train | epoch 459 | loss 2.114 | nll_loss 0.341 | ppl 1.27 | wps 23534.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22335 | lr 0.000211596 | gnorm 0.413 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 61752
2022-03-07 06:11:47 | INFO | fairseq.trainer | begin training epoch 460
2022-03-07 06:11:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:12:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:14:00 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 13.399 | nll_loss 12.795 | ppl 7108.02 | wps 41537.9 | wpb 510.9 | bsz 1 | num_updates 22383 | best_loss 8.937
2022-03-07 06:14:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 22383 updates
2022-03-07 06:14:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:14:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:14:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 460 @ 22383 updates, score 13.399) (writing took 2.481395768932998 seconds)
2022-03-07 06:14:02 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)
2022-03-07 06:14:02 | INFO | train | epoch 460 | loss 2.113 | nll_loss 0.34 | ppl 1.27 | wps 23090.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22383 | lr 0.000211369 | gnorm 0.413 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 61887
2022-03-07 06:14:02 | INFO | fairseq.trainer | begin training epoch 461
2022-03-07 06:14:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:14:47 | INFO | train_inner | epoch 461:     17 / 49 loss=2.113, nll_loss=0.341, ppl=1.27, wps=23375.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22400, lr=0.000211289, gnorm=0.415, loss_scale=32, train_wall=236, gb_free=8.8, wall=61931
2022-03-07 06:16:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:16:14 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 13.35 | nll_loss 12.741 | ppl 6844.43 | wps 41547.8 | wpb 510.9 | bsz 1 | num_updates 22432 | best_loss 8.937
2022-03-07 06:16:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 22432 updates
2022-03-07 06:16:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:16:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:16:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 461 @ 22432 updates, score 13.35) (writing took 2.4338552528060973 seconds)
2022-03-07 06:16:17 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)
2022-03-07 06:16:17 | INFO | train | epoch 461 | loss 2.112 | nll_loss 0.339 | ppl 1.27 | wps 23606.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22432 | lr 0.000211138 | gnorm 0.414 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62022
2022-03-07 06:16:17 | INFO | fairseq.trainer | begin training epoch 462
2022-03-07 06:16:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:18:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:18:29 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 13.423 | nll_loss 12.817 | ppl 7218.45 | wps 41447.4 | wpb 510.9 | bsz 1 | num_updates 22481 | best_loss 8.937
2022-03-07 06:18:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 22481 updates
2022-03-07 06:18:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:18:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:18:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 462 @ 22481 updates, score 13.423) (writing took 2.4974003699608147 seconds)
2022-03-07 06:18:32 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)
2022-03-07 06:18:32 | INFO | train | epoch 462 | loss 2.113 | nll_loss 0.34 | ppl 1.27 | wps 23539.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22481 | lr 0.000210908 | gnorm 0.418 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 62157
2022-03-07 06:18:32 | INFO | fairseq.trainer | begin training epoch 463
2022-03-07 06:18:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:18:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:19:24 | INFO | train_inner | epoch 463:     20 / 49 loss=2.113, nll_loss=0.34, ppl=1.27, wps=23371.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22500, lr=0.000210819, gnorm=0.415, loss_scale=32, train_wall=236, gb_free=8.8, wall=62209
2022-03-07 06:20:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:20:44 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 13.357 | nll_loss 12.746 | ppl 6867.51 | wps 42032.2 | wpb 510.9 | bsz 1 | num_updates 22529 | best_loss 8.937
2022-03-07 06:20:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 22529 updates
2022-03-07 06:20:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:20:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 463 @ 22529 updates, score 13.357) (writing took 2.3254073122516274 seconds)
2022-03-07 06:20:46 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)
2022-03-07 06:20:46 | INFO | train | epoch 463 | loss 2.112 | nll_loss 0.34 | ppl 1.27 | wps 23172.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22529 | lr 0.000210683 | gnorm 0.411 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 62291
2022-03-07 06:20:46 | INFO | fairseq.trainer | begin training epoch 464
2022-03-07 06:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:22:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:22:59 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 13.273 | nll_loss 12.656 | ppl 6454.54 | wps 41696.7 | wpb 510.9 | bsz 1 | num_updates 22578 | best_loss 8.937
2022-03-07 06:22:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 22578 updates
2022-03-07 06:22:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:23:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:23:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 464 @ 22578 updates, score 13.273) (writing took 2.4460963727906346 seconds)
2022-03-07 06:23:01 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)
2022-03-07 06:23:01 | INFO | train | epoch 464 | loss 2.112 | nll_loss 0.339 | ppl 1.27 | wps 23556.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22578 | lr 0.000210454 | gnorm 0.414 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62426
2022-03-07 06:23:01 | INFO | fairseq.trainer | begin training epoch 465
2022-03-07 06:23:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:23:59 | INFO | train_inner | epoch 465:     22 / 49 loss=2.112, nll_loss=0.339, ppl=1.27, wps=23636.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22600, lr=0.000210352, gnorm=0.412, loss_scale=32, train_wall=234, gb_free=8.8, wall=62483
2022-03-07 06:24:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:25:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:25:13 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 13.352 | nll_loss 12.741 | ppl 6843.42 | wps 41761.2 | wpb 510.9 | bsz 1 | num_updates 22626 | best_loss 8.937
2022-03-07 06:25:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 22626 updates
2022-03-07 06:25:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:25:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 465 @ 22626 updates, score 13.352) (writing took 2.4179505137726665 seconds)
2022-03-07 06:25:16 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)
2022-03-07 06:25:16 | INFO | train | epoch 465 | loss 2.111 | nll_loss 0.339 | ppl 1.26 | wps 23134.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22626 | lr 0.000210231 | gnorm 0.416 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62560
2022-03-07 06:25:16 | INFO | fairseq.trainer | begin training epoch 466
2022-03-07 06:25:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:27:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:27:28 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 13.326 | nll_loss 12.714 | ppl 6718.38 | wps 41337.1 | wpb 510.9 | bsz 1 | num_updates 22675 | best_loss 8.937
2022-03-07 06:27:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 22675 updates
2022-03-07 06:27:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:27:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 466 @ 22675 updates, score 13.326) (writing took 2.42513927584514 seconds)
2022-03-07 06:27:30 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)
2022-03-07 06:27:30 | INFO | train | epoch 466 | loss 2.112 | nll_loss 0.339 | ppl 1.27 | wps 23588.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22675 | lr 0.000210003 | gnorm 0.412 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62695
2022-03-07 06:27:30 | INFO | fairseq.trainer | begin training epoch 467
2022-03-07 06:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:28:36 | INFO | train_inner | epoch 467:     25 / 49 loss=2.111, nll_loss=0.339, ppl=1.26, wps=23404.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22700, lr=0.000209888, gnorm=0.412, loss_scale=32, train_wall=236, gb_free=8.8, wall=62761
2022-03-07 06:29:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:29:43 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 13.352 | nll_loss 12.74 | ppl 6841.28 | wps 42109.5 | wpb 510.9 | bsz 1 | num_updates 22724 | best_loss 8.937
2022-03-07 06:29:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 22724 updates
2022-03-07 06:29:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:29:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:29:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 467 @ 22724 updates, score 13.352) (writing took 2.4642111151479185 seconds)
2022-03-07 06:29:45 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)
2022-03-07 06:29:45 | INFO | train | epoch 467 | loss 2.11 | nll_loss 0.338 | ppl 1.26 | wps 23576.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22724 | lr 0.000209777 | gnorm 0.412 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 62830
2022-03-07 06:29:45 | INFO | fairseq.trainer | begin training epoch 468
2022-03-07 06:29:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:30:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:31:57 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 13.279 | nll_loss 12.657 | ppl 6457.33 | wps 41900.2 | wpb 510.9 | bsz 1 | num_updates 22772 | best_loss 8.937
2022-03-07 06:31:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 22772 updates
2022-03-07 06:31:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:31:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:32:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 468 @ 22772 updates, score 13.279) (writing took 2.482812105678022 seconds)
2022-03-07 06:32:00 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)
2022-03-07 06:32:00 | INFO | train | epoch 468 | loss 2.109 | nll_loss 0.338 | ppl 1.26 | wps 23173.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22772 | lr 0.000209556 | gnorm 0.413 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 62964
2022-03-07 06:32:00 | INFO | fairseq.trainer | begin training epoch 469
2022-03-07 06:32:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:33:13 | INFO | train_inner | epoch 469:     28 / 49 loss=2.11, nll_loss=0.338, ppl=1.26, wps=23415.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=22800, lr=0.000209427, gnorm=0.413, loss_scale=32, train_wall=236, gb_free=8.8, wall=63038
2022-03-07 06:34:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:34:12 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 13.287 | nll_loss 12.672 | ppl 6527.55 | wps 42664.8 | wpb 510.9 | bsz 1 | num_updates 22821 | best_loss 8.937
2022-03-07 06:34:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 22821 updates
2022-03-07 06:34:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:34:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:34:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 469 @ 22821 updates, score 13.287) (writing took 2.393005011137575 seconds)
2022-03-07 06:34:14 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)
2022-03-07 06:34:14 | INFO | train | epoch 469 | loss 2.109 | nll_loss 0.337 | ppl 1.26 | wps 23614.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 22821 | lr 0.000209331 | gnorm 0.406 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 63099
2022-03-07 06:34:14 | INFO | fairseq.trainer | begin training epoch 470
2022-03-07 06:34:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:36:24 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 13.413 | nll_loss 12.806 | ppl 7163.3 | wps 44110 | wpb 510.9 | bsz 1 | num_updates 22870 | best_loss 8.937
2022-03-07 06:36:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 22870 updates
2022-03-07 06:36:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:36:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:36:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 470 @ 22870 updates, score 13.413) (writing took 2.3908457248471677 seconds)
2022-03-07 06:36:26 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)
2022-03-07 06:36:26 | INFO | train | epoch 470 | loss 2.11 | nll_loss 0.338 | ppl 1.26 | wps 24076.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22870 | lr 0.000209106 | gnorm 0.415 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 63231
2022-03-07 06:36:26 | INFO | fairseq.trainer | begin training epoch 471
2022-03-07 06:36:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:36:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:37:46 | INFO | train_inner | epoch 471:     31 / 49 loss=2.109, nll_loss=0.337, ppl=1.26, wps=23770.6, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=22900, lr=0.000208969, gnorm=0.411, loss_scale=32, train_wall=233, gb_free=8.8, wall=63311
2022-03-07 06:38:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:38:36 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 13.266 | nll_loss 12.654 | ppl 6445.48 | wps 42634.8 | wpb 510.9 | bsz 1 | num_updates 22918 | best_loss 8.937
2022-03-07 06:38:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 22918 updates
2022-03-07 06:38:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:38:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:38:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 471 @ 22918 updates, score 13.266) (writing took 2.2812634566798806 seconds)
2022-03-07 06:38:38 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)
2022-03-07 06:38:38 | INFO | train | epoch 471 | loss 2.109 | nll_loss 0.337 | ppl 1.26 | wps 23532.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 22918 | lr 0.000208887 | gnorm 0.412 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 63363
2022-03-07 06:38:38 | INFO | fairseq.trainer | begin training epoch 472
2022-03-07 06:38:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:40:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:40:48 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 13.334 | nll_loss 12.726 | ppl 6776.6 | wps 44282.6 | wpb 510.9 | bsz 1 | num_updates 22967 | best_loss 8.937
2022-03-07 06:40:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 22967 updates
2022-03-07 06:40:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:40:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:40:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 472 @ 22967 updates, score 13.334) (writing took 2.3500348841771483 seconds)
2022-03-07 06:40:51 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)
2022-03-07 06:40:51 | INFO | train | epoch 472 | loss 2.107 | nll_loss 0.336 | ppl 1.26 | wps 24039.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 22967 | lr 0.000208664 | gnorm 0.409 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 63495
2022-03-07 06:40:51 | INFO | fairseq.trainer | begin training epoch 473
2022-03-07 06:40:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:42:16 | INFO | train_inner | epoch 473:     33 / 49 loss=2.108, nll_loss=0.337, ppl=1.26, wps=24055.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23000, lr=0.000208514, gnorm=0.411, loss_scale=32, train_wall=230, gb_free=8.8, wall=63580
2022-03-07 06:42:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:42:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:43:01 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 13.317 | nll_loss 12.707 | ppl 6687.21 | wps 41876.2 | wpb 510.9 | bsz 1 | num_updates 23015 | best_loss 8.937
2022-03-07 06:43:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 23015 updates
2022-03-07 06:43:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:43:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:43:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 473 @ 23015 updates, score 13.317) (writing took 2.539382480084896 seconds)
2022-03-07 06:43:03 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)
2022-03-07 06:43:03 | INFO | train | epoch 473 | loss 2.108 | nll_loss 0.337 | ppl 1.26 | wps 23466.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23015 | lr 0.000208446 | gnorm 0.411 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 63628
2022-03-07 06:43:03 | INFO | fairseq.trainer | begin training epoch 474
2022-03-07 06:43:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:45:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:45:13 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 13.272 | nll_loss 12.658 | ppl 6463.48 | wps 43061.3 | wpb 510.9 | bsz 1 | num_updates 23064 | best_loss 8.937
2022-03-07 06:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 23064 updates
2022-03-07 06:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:45:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:45:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 474 @ 23064 updates, score 13.272) (writing took 2.4001835719682276 seconds)
2022-03-07 06:45:15 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)
2022-03-07 06:45:15 | INFO | train | epoch 474 | loss 2.107 | nll_loss 0.336 | ppl 1.26 | wps 24026 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23064 | lr 0.000208225 | gnorm 0.401 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 63760
2022-03-07 06:45:15 | INFO | fairseq.trainer | begin training epoch 475
2022-03-07 06:45:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:46:49 | INFO | train_inner | epoch 475:     36 / 49 loss=2.107, nll_loss=0.336, ppl=1.26, wps=23688.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23100, lr=0.000208063, gnorm=0.405, loss_scale=32, train_wall=233, gb_free=8.8, wall=63854
2022-03-07 06:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:47:27 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 13.309 | nll_loss 12.7 | ppl 6655.73 | wps 41816.5 | wpb 510.9 | bsz 1 | num_updates 23113 | best_loss 8.937
2022-03-07 06:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 23113 updates
2022-03-07 06:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:47:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:47:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 475 @ 23113 updates, score 13.309) (writing took 2.498824254143983 seconds)
2022-03-07 06:47:30 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)
2022-03-07 06:47:30 | INFO | train | epoch 475 | loss 2.107 | nll_loss 0.336 | ppl 1.26 | wps 23646.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23113 | lr 0.000208004 | gnorm 0.412 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 63895
2022-03-07 06:47:30 | INFO | fairseq.trainer | begin training epoch 476
2022-03-07 06:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:48:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:49:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:49:42 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 13.344 | nll_loss 12.732 | ppl 6802.49 | wps 41758.8 | wpb 510.9 | bsz 1 | num_updates 23161 | best_loss 8.937
2022-03-07 06:49:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 23161 updates
2022-03-07 06:49:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:49:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 476 @ 23161 updates, score 13.344) (writing took 2.4218514850363135 seconds)
2022-03-07 06:49:45 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)
2022-03-07 06:49:45 | INFO | train | epoch 476 | loss 2.106 | nll_loss 0.335 | ppl 1.26 | wps 23094.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23161 | lr 0.000207788 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64029
2022-03-07 06:49:45 | INFO | fairseq.trainer | begin training epoch 477
2022-03-07 06:49:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:51:27 | INFO | train_inner | epoch 477:     39 / 49 loss=2.107, nll_loss=0.336, ppl=1.26, wps=23359, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23200, lr=0.000207614, gnorm=0.41, loss_scale=32, train_wall=237, gb_free=8.8, wall=64132
2022-03-07 06:51:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:51:57 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 13.387 | nll_loss 12.779 | ppl 7030.12 | wps 41678.8 | wpb 510.9 | bsz 1 | num_updates 23210 | best_loss 8.937
2022-03-07 06:51:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 23210 updates
2022-03-07 06:51:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:52:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:52:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 477 @ 23210 updates, score 13.387) (writing took 2.4436743878759444 seconds)
2022-03-07 06:52:00 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)
2022-03-07 06:52:00 | INFO | train | epoch 477 | loss 2.107 | nll_loss 0.336 | ppl 1.26 | wps 23539.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23210 | lr 0.000207569 | gnorm 0.415 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64164
2022-03-07 06:52:00 | INFO | fairseq.trainer | begin training epoch 478
2022-03-07 06:52:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:54:12 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 13.413 | nll_loss 12.812 | ppl 7189.42 | wps 41399.1 | wpb 510.9 | bsz 1 | num_updates 23259 | best_loss 8.937
2022-03-07 06:54:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 23259 updates
2022-03-07 06:54:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:54:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 478 @ 23259 updates, score 13.413) (writing took 2.466088240966201 seconds)
2022-03-07 06:54:15 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)
2022-03-07 06:54:15 | INFO | train | epoch 478 | loss 2.105 | nll_loss 0.334 | ppl 1.26 | wps 23519.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23259 | lr 0.00020735 | gnorm 0.404 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 64300
2022-03-07 06:54:15 | INFO | fairseq.trainer | begin training epoch 479
2022-03-07 06:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:54:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 06:56:05 | INFO | train_inner | epoch 479:     42 / 49 loss=2.105, nll_loss=0.335, ppl=1.26, wps=23354.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23300, lr=0.000207168, gnorm=0.407, loss_scale=32, train_wall=237, gb_free=8.8, wall=64410
2022-03-07 06:56:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:56:27 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 13.351 | nll_loss 12.74 | ppl 6840.03 | wps 41485.2 | wpb 510.9 | bsz 1 | num_updates 23307 | best_loss 8.937
2022-03-07 06:56:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 23307 updates
2022-03-07 06:56:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:56:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:56:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 479 @ 23307 updates, score 13.351) (writing took 2.4531050100922585 seconds)
2022-03-07 06:56:30 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)
2022-03-07 06:56:30 | INFO | train | epoch 479 | loss 2.106 | nll_loss 0.335 | ppl 1.26 | wps 23074.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23307 | lr 0.000207137 | gnorm 0.408 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64434
2022-03-07 06:56:30 | INFO | fairseq.trainer | begin training epoch 480
2022-03-07 06:56:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 06:58:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 06:58:42 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 13.383 | nll_loss 12.776 | ppl 7012.77 | wps 41921.5 | wpb 510.9 | bsz 1 | num_updates 23356 | best_loss 8.937
2022-03-07 06:58:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 23356 updates
2022-03-07 06:58:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:58:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 06:58:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 480 @ 23356 updates, score 13.383) (writing took 2.5258797467686236 seconds)
2022-03-07 06:58:45 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)
2022-03-07 06:58:45 | INFO | train | epoch 480 | loss 2.106 | nll_loss 0.335 | ppl 1.26 | wps 23541.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23356 | lr 0.000206919 | gnorm 0.415 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64569
2022-03-07 06:58:45 | INFO | fairseq.trainer | begin training epoch 481
2022-03-07 06:58:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:00:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:00:43 | INFO | train_inner | epoch 481:     45 / 49 loss=2.105, nll_loss=0.334, ppl=1.26, wps=23366.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=23400, lr=0.000206725, gnorm=0.413, loss_scale=32, train_wall=236, gb_free=8.8, wall=64687
2022-03-07 07:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:00:57 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 13.421 | nll_loss 12.818 | ppl 7222.21 | wps 42180.9 | wpb 510.9 | bsz 1 | num_updates 23404 | best_loss 8.937
2022-03-07 07:00:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 23404 updates
2022-03-07 07:00:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:00:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:00:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 481 @ 23404 updates, score 13.421) (writing took 2.417478912975639 seconds)
2022-03-07 07:00:59 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)
2022-03-07 07:00:59 | INFO | train | epoch 481 | loss 2.104 | nll_loss 0.334 | ppl 1.26 | wps 23110.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23404 | lr 0.000206707 | gnorm 0.41 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64704
2022-03-07 07:00:59 | INFO | fairseq.trainer | begin training epoch 482
2022-03-07 07:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:03:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:03:12 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 13.347 | nll_loss 12.743 | ppl 6856.15 | wps 41211.3 | wpb 510.9 | bsz 1 | num_updates 23453 | best_loss 8.937
2022-03-07 07:03:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 23453 updates
2022-03-07 07:03:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:03:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 482 @ 23453 updates, score 13.347) (writing took 2.363419079221785 seconds)
2022-03-07 07:03:14 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)
2022-03-07 07:03:14 | INFO | train | epoch 482 | loss 2.104 | nll_loss 0.333 | ppl 1.26 | wps 23552.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23453 | lr 0.000206491 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64839
2022-03-07 07:03:14 | INFO | fairseq.trainer | begin training epoch 483
2022-03-07 07:03:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:05:18 | INFO | train_inner | epoch 483:     47 / 49 loss=2.104, nll_loss=0.334, ppl=1.26, wps=23551.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=23500, lr=0.000206284, gnorm=0.409, loss_scale=32, train_wall=235, gb_free=8.8, wall=64963
2022-03-07 07:05:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:05:27 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 13.396 | nll_loss 12.793 | ppl 7098.21 | wps 41228.4 | wpb 510.9 | bsz 1 | num_updates 23502 | best_loss 8.937
2022-03-07 07:05:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 23502 updates
2022-03-07 07:05:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:05:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:05:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 483 @ 23502 updates, score 13.396) (writing took 2.3866844973526895 seconds)
2022-03-07 07:05:30 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)
2022-03-07 07:05:30 | INFO | train | epoch 483 | loss 2.104 | nll_loss 0.334 | ppl 1.26 | wps 23491.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23502 | lr 0.000206275 | gnorm 0.412 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 64974
2022-03-07 07:05:30 | INFO | fairseq.trainer | begin training epoch 484
2022-03-07 07:05:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:06:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:07:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:07:42 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 13.379 | nll_loss 12.776 | ppl 7013.95 | wps 41768.7 | wpb 510.9 | bsz 1 | num_updates 23550 | best_loss 8.937
2022-03-07 07:07:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 23550 updates
2022-03-07 07:07:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:07:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 484 @ 23550 updates, score 13.379) (writing took 2.3505067881196737 seconds)
2022-03-07 07:07:44 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)
2022-03-07 07:07:44 | INFO | train | epoch 484 | loss 2.103 | nll_loss 0.333 | ppl 1.26 | wps 23119.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23550 | lr 0.000206065 | gnorm 0.402 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 65109
2022-03-07 07:07:44 | INFO | fairseq.trainer | begin training epoch 485
2022-03-07 07:07:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:09:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:09:56 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 13.395 | nll_loss 12.791 | ppl 7088.15 | wps 42713.7 | wpb 510.9 | bsz 1 | num_updates 23599 | best_loss 8.937
2022-03-07 07:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 23599 updates
2022-03-07 07:09:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:09:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:09:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 485 @ 23599 updates, score 13.395) (writing took 2.4604540043510497 seconds)
2022-03-07 07:09:58 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)
2022-03-07 07:09:58 | INFO | train | epoch 485 | loss 2.102 | nll_loss 0.332 | ppl 1.26 | wps 23738.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23599 | lr 0.000205851 | gnorm 0.405 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 65243
2022-03-07 07:09:58 | INFO | fairseq.trainer | begin training epoch 486
2022-03-07 07:09:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:10:01 | INFO | train_inner | epoch 486:      1 / 49 loss=2.102, nll_loss=0.332, ppl=1.26, wps=22823.6, ups=0.35, wpb=64539.7, bsz=126.1, num_updates=23600, lr=0.000205847, gnorm=0.405, loss_scale=32, train_wall=234, gb_free=8.8, wall=65245
2022-03-07 07:12:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:12:08 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 13.422 | nll_loss 12.826 | ppl 7261.46 | wps 43256 | wpb 510.9 | bsz 1 | num_updates 23648 | best_loss 8.937
2022-03-07 07:12:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 23648 updates
2022-03-07 07:12:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:12:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 486 @ 23648 updates, score 13.422) (writing took 2.3620475050993264 seconds)
2022-03-07 07:12:10 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)
2022-03-07 07:12:10 | INFO | train | epoch 486 | loss 2.102 | nll_loss 0.332 | ppl 1.26 | wps 24016.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23648 | lr 0.000205638 | gnorm 0.404 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 65375
2022-03-07 07:12:10 | INFO | fairseq.trainer | begin training epoch 487
2022-03-07 07:12:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:12:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:14:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:14:21 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 13.346 | nll_loss 12.74 | ppl 6841.74 | wps 41400.1 | wpb 510.9 | bsz 1 | num_updates 23696 | best_loss 8.937
2022-03-07 07:14:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 23696 updates
2022-03-07 07:14:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:14:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:14:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 487 @ 23696 updates, score 13.346) (writing took 2.4455938450992107 seconds)
2022-03-07 07:14:23 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)
2022-03-07 07:14:23 | INFO | train | epoch 487 | loss 2.102 | nll_loss 0.332 | ppl 1.26 | wps 23474.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23696 | lr 0.000205429 | gnorm 0.404 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65508
2022-03-07 07:14:23 | INFO | fairseq.trainer | begin training epoch 488
2022-03-07 07:14:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:14:33 | INFO | train_inner | epoch 488:      4 / 49 loss=2.102, nll_loss=0.332, ppl=1.26, wps=23790.3, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23700, lr=0.000205412, gnorm=0.405, loss_scale=32, train_wall=232, gb_free=8.8, wall=65518
2022-03-07 07:16:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:16:33 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 13.408 | nll_loss 12.804 | ppl 7153.27 | wps 42486.4 | wpb 510.9 | bsz 1 | num_updates 23745 | best_loss 8.937
2022-03-07 07:16:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 23745 updates
2022-03-07 07:16:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:16:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:16:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 488 @ 23745 updates, score 13.408) (writing took 2.387719937134534 seconds)
2022-03-07 07:16:35 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)
2022-03-07 07:16:35 | INFO | train | epoch 488 | loss 2.102 | nll_loss 0.332 | ppl 1.26 | wps 23994.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23745 | lr 0.000205217 | gnorm 0.408 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65640
2022-03-07 07:16:35 | INFO | fairseq.trainer | begin training epoch 489
2022-03-07 07:16:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:18:45 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 13.356 | nll_loss 12.752 | ppl 6896.87 | wps 43497.9 | wpb 510.9 | bsz 1 | num_updates 23794 | best_loss 8.937
2022-03-07 07:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 23794 updates
2022-03-07 07:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:18:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:18:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 489 @ 23794 updates, score 13.356) (writing took 2.3312541469931602 seconds)
2022-03-07 07:18:48 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)
2022-03-07 07:18:48 | INFO | train | epoch 489 | loss 2.102 | nll_loss 0.332 | ppl 1.26 | wps 24006.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23794 | lr 0.000205006 | gnorm 0.409 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 65773
2022-03-07 07:18:48 | INFO | fairseq.trainer | begin training epoch 490
2022-03-07 07:18:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:18:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:19:06 | INFO | train_inner | epoch 490:      7 / 49 loss=2.102, nll_loss=0.332, ppl=1.26, wps=23809.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23800, lr=0.00020498, gnorm=0.409, loss_scale=32, train_wall=232, gb_free=8.8, wall=65791
2022-03-07 07:20:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:20:58 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 13.328 | nll_loss 12.72 | ppl 6744.83 | wps 43046.5 | wpb 510.9 | bsz 1 | num_updates 23842 | best_loss 8.937
2022-03-07 07:20:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 23842 updates
2022-03-07 07:20:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 490 @ 23842 updates, score 13.328) (writing took 2.4142855792306364 seconds)
2022-03-07 07:21:00 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)
2022-03-07 07:21:00 | INFO | train | epoch 490 | loss 2.101 | nll_loss 0.331 | ppl 1.26 | wps 23488.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 23842 | lr 0.000204799 | gnorm 0.416 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 65905
2022-03-07 07:21:00 | INFO | fairseq.trainer | begin training epoch 491
2022-03-07 07:21:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:23:11 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 13.32 | nll_loss 12.711 | ppl 6707.19 | wps 41872.4 | wpb 510.9 | bsz 1 | num_updates 23891 | best_loss 8.937
2022-03-07 07:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 23891 updates
2022-03-07 07:23:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:23:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:23:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 491 @ 23891 updates, score 13.32) (writing took 2.378809990826994 seconds)
2022-03-07 07:23:13 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)
2022-03-07 07:23:13 | INFO | train | epoch 491 | loss 2.101 | nll_loss 0.331 | ppl 1.26 | wps 23917 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 23891 | lr 0.000204589 | gnorm 0.408 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 66038
2022-03-07 07:23:13 | INFO | fairseq.trainer | begin training epoch 492
2022-03-07 07:23:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:23:37 | INFO | train_inner | epoch 492:      9 / 49 loss=2.1, nll_loss=0.331, ppl=1.26, wps=23912.6, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=23900, lr=0.000204551, gnorm=0.41, loss_scale=32, train_wall=231, gb_free=8.8, wall=66062
2022-03-07 07:24:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:25:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:25:26 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 13.354 | nll_loss 12.746 | ppl 6868.36 | wps 41263.3 | wpb 510.9 | bsz 1 | num_updates 23939 | best_loss 8.937
2022-03-07 07:25:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 23939 updates
2022-03-07 07:25:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:25:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:25:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 492 @ 23939 updates, score 13.354) (writing took 2.4134678319096565 seconds)
2022-03-07 07:25:28 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)
2022-03-07 07:25:28 | INFO | train | epoch 492 | loss 2.099 | nll_loss 0.33 | ppl 1.26 | wps 23014.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 23939 | lr 0.000204384 | gnorm 0.404 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66173
2022-03-07 07:25:28 | INFO | fairseq.trainer | begin training epoch 493
2022-03-07 07:25:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:27:41 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 13.328 | nll_loss 12.719 | ppl 6742.19 | wps 41173.9 | wpb 510.9 | bsz 1 | num_updates 23988 | best_loss 8.937
2022-03-07 07:27:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 23988 updates
2022-03-07 07:27:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:27:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:27:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 493 @ 23988 updates, score 13.328) (writing took 2.411224183626473 seconds)
2022-03-07 07:27:43 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)
2022-03-07 07:27:43 | INFO | train | epoch 493 | loss 2.1 | nll_loss 0.331 | ppl 1.26 | wps 23553.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 23988 | lr 0.000204175 | gnorm 0.407 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66308
2022-03-07 07:27:43 | INFO | fairseq.trainer | begin training epoch 494
2022-03-07 07:27:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:28:15 | INFO | train_inner | epoch 494:     12 / 49 loss=2.099, nll_loss=0.33, ppl=1.26, wps=23356.1, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=24000, lr=0.000204124, gnorm=0.405, loss_scale=32, train_wall=237, gb_free=8.8, wall=66340
2022-03-07 07:29:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:29:56 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 13.323 | nll_loss 12.712 | ppl 6709.15 | wps 41956.9 | wpb 510.9 | bsz 1 | num_updates 24037 | best_loss 8.937
2022-03-07 07:29:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 24037 updates
2022-03-07 07:29:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:29:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:29:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 494 @ 24037 updates, score 13.323) (writing took 2.375254639890045 seconds)
2022-03-07 07:29:58 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)
2022-03-07 07:29:58 | INFO | train | epoch 494 | loss 2.1 | nll_loss 0.33 | ppl 1.26 | wps 23561.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24037 | lr 0.000203967 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66443
2022-03-07 07:29:58 | INFO | fairseq.trainer | begin training epoch 495
2022-03-07 07:29:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:31:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:32:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:32:11 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 13.237 | nll_loss 12.62 | ppl 6294.31 | wps 41409 | wpb 510.9 | bsz 1 | num_updates 24085 | best_loss 8.937
2022-03-07 07:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 24085 updates
2022-03-07 07:32:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:32:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:32:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 495 @ 24085 updates, score 13.237) (writing took 2.575000397861004 seconds)
2022-03-07 07:32:13 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)
2022-03-07 07:32:13 | INFO | train | epoch 495 | loss 2.099 | nll_loss 0.33 | ppl 1.26 | wps 23058.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24085 | lr 0.000203764 | gnorm 0.409 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66578
2022-03-07 07:32:13 | INFO | fairseq.trainer | begin training epoch 496
2022-03-07 07:32:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:32:53 | INFO | train_inner | epoch 496:     15 / 49 loss=2.099, nll_loss=0.33, ppl=1.26, wps=23359.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=24100, lr=0.0002037, gnorm=0.407, loss_scale=32, train_wall=237, gb_free=8.8, wall=66617
2022-03-07 07:34:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:34:26 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 13.385 | nll_loss 12.776 | ppl 7014.89 | wps 41374.3 | wpb 510.9 | bsz 1 | num_updates 24134 | best_loss 8.937
2022-03-07 07:34:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 24134 updates
2022-03-07 07:34:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:34:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:34:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 496 @ 24134 updates, score 13.385) (writing took 2.3574066599830985 seconds)
2022-03-07 07:34:28 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)
2022-03-07 07:34:28 | INFO | train | epoch 496 | loss 2.099 | nll_loss 0.33 | ppl 1.26 | wps 23543.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24134 | lr 0.000203557 | gnorm 0.402 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66713
2022-03-07 07:34:28 | INFO | fairseq.trainer | begin training epoch 497
2022-03-07 07:34:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:36:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:36:41 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 13.3 | nll_loss 12.69 | ppl 6605.87 | wps 41411.3 | wpb 510.9 | bsz 1 | num_updates 24183 | best_loss 8.937
2022-03-07 07:36:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 24183 updates
2022-03-07 07:36:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:36:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:36:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 497 @ 24183 updates, score 13.3) (writing took 2.3801438910886645 seconds)
2022-03-07 07:36:43 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)
2022-03-07 07:36:43 | INFO | train | epoch 497 | loss 2.099 | nll_loss 0.33 | ppl 1.26 | wps 23543.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24183 | lr 0.00020335 | gnorm 0.408 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66848
2022-03-07 07:36:43 | INFO | fairseq.trainer | begin training epoch 498
2022-03-07 07:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:37:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:37:31 | INFO | train_inner | epoch 498:     18 / 49 loss=2.099, nll_loss=0.33, ppl=1.26, wps=23342.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=24200, lr=0.000203279, gnorm=0.406, loss_scale=32, train_wall=237, gb_free=8.8, wall=66895
2022-03-07 07:38:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:38:56 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 13.357 | nll_loss 12.758 | ppl 6927.29 | wps 40985.2 | wpb 510.9 | bsz 1 | num_updates 24231 | best_loss 8.937
2022-03-07 07:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 24231 updates
2022-03-07 07:38:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:38:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:38:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 498 @ 24231 updates, score 13.357) (writing took 2.4189596762880683 seconds)
2022-03-07 07:38:58 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)
2022-03-07 07:38:58 | INFO | train | epoch 498 | loss 2.098 | nll_loss 0.328 | ppl 1.26 | wps 23030.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24231 | lr 0.000203149 | gnorm 0.403 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 66983
2022-03-07 07:38:58 | INFO | fairseq.trainer | begin training epoch 499
2022-03-07 07:38:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:41:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:41:11 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 13.246 | nll_loss 12.627 | ppl 6326.81 | wps 41214.2 | wpb 510.9 | bsz 1 | num_updates 24280 | best_loss 8.937
2022-03-07 07:41:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 24280 updates
2022-03-07 07:41:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:41:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:41:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 499 @ 24280 updates, score 13.246) (writing took 2.414855540264398 seconds)
2022-03-07 07:41:14 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)
2022-03-07 07:41:14 | INFO | train | epoch 499 | loss 2.097 | nll_loss 0.329 | ppl 1.26 | wps 23469 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24280 | lr 0.000202944 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 67119
2022-03-07 07:41:14 | INFO | fairseq.trainer | begin training epoch 500
2022-03-07 07:41:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:42:06 | INFO | train_inner | epoch 500:     20 / 49 loss=2.097, nll_loss=0.328, ppl=1.26, wps=23519.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=24300, lr=0.00020286, gnorm=0.404, loss_scale=32, train_wall=235, gb_free=8.8, wall=67171
2022-03-07 07:43:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:43:26 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 13.354 | nll_loss 12.748 | ppl 6880.19 | wps 41522.6 | wpb 510.9 | bsz 1 | num_updates 24328 | best_loss 8.937
2022-03-07 07:43:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 24328 updates
2022-03-07 07:43:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:43:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:43:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 500 @ 24328 updates, score 13.354) (writing took 2.3237575702369213 seconds)
2022-03-07 07:43:28 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)
2022-03-07 07:43:28 | INFO | train | epoch 500 | loss 2.097 | nll_loss 0.328 | ppl 1.26 | wps 23129.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24328 | lr 0.000202743 | gnorm 0.401 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 67253
2022-03-07 07:43:28 | INFO | fairseq.trainer | begin training epoch 501
2022-03-07 07:43:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:45:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:45:41 | INFO | valid | epoch 501 | valid on 'valid' subset | loss 13.265 | nll_loss 12.655 | ppl 6448.05 | wps 39902.5 | wpb 510.9 | bsz 1 | num_updates 24377 | best_loss 8.937
2022-03-07 07:45:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 24377 updates
2022-03-07 07:45:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:45:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:45:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 501 @ 24377 updates, score 13.265) (writing took 2.462851834949106 seconds)
2022-03-07 07:45:43 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)
2022-03-07 07:45:43 | INFO | train | epoch 501 | loss 2.096 | nll_loss 0.328 | ppl 1.26 | wps 23541.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24377 | lr 0.00020254 | gnorm 0.401 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 67388
2022-03-07 07:45:43 | INFO | fairseq.trainer | begin training epoch 502
2022-03-07 07:45:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:46:43 | INFO | train_inner | epoch 502:     23 / 49 loss=2.097, nll_loss=0.328, ppl=1.26, wps=23478.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=24400, lr=0.000202444, gnorm=0.401, loss_scale=32, train_wall=235, gb_free=8.8, wall=67447
2022-03-07 07:47:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:47:54 | INFO | valid | epoch 502 | valid on 'valid' subset | loss 13.331 | nll_loss 12.722 | ppl 6754.62 | wps 43078.4 | wpb 510.9 | bsz 1 | num_updates 24426 | best_loss 8.937
2022-03-07 07:47:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 24426 updates
2022-03-07 07:47:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:47:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:47:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 502 @ 24426 updates, score 13.331) (writing took 2.3745194277726114 seconds)
2022-03-07 07:47:56 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)
2022-03-07 07:47:56 | INFO | train | epoch 502 | loss 2.096 | nll_loss 0.328 | ppl 1.26 | wps 23970.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24426 | lr 0.000202336 | gnorm 0.403 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 67521
2022-03-07 07:47:56 | INFO | fairseq.trainer | begin training epoch 503
2022-03-07 07:47:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:49:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:50:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:50:06 | INFO | valid | epoch 503 | valid on 'valid' subset | loss 13.394 | nll_loss 12.789 | ppl 7076.84 | wps 43030.8 | wpb 510.9 | bsz 1 | num_updates 24474 | best_loss 8.937
2022-03-07 07:50:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 24474 updates
2022-03-07 07:50:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:50:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:50:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 503 @ 24474 updates, score 13.394) (writing took 2.4777110926806927 seconds)
2022-03-07 07:50:08 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)
2022-03-07 07:50:08 | INFO | train | epoch 503 | loss 2.095 | nll_loss 0.327 | ppl 1.25 | wps 23550.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24474 | lr 0.000202138 | gnorm 0.401 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 67653
2022-03-07 07:50:08 | INFO | fairseq.trainer | begin training epoch 504
2022-03-07 07:50:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:51:15 | INFO | train_inner | epoch 504:     26 / 49 loss=2.096, nll_loss=0.327, ppl=1.25, wps=23809.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=24500, lr=0.000202031, gnorm=0.403, loss_scale=32, train_wall=232, gb_free=8.8, wall=67720
2022-03-07 07:52:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:52:18 | INFO | valid | epoch 504 | valid on 'valid' subset | loss 13.432 | nll_loss 12.835 | ppl 7305.01 | wps 43764.7 | wpb 510.9 | bsz 1 | num_updates 24523 | best_loss 8.937
2022-03-07 07:52:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 24523 updates
2022-03-07 07:52:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:52:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 504 @ 24523 updates, score 13.432) (writing took 2.454969620332122 seconds)
2022-03-07 07:52:20 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)
2022-03-07 07:52:20 | INFO | train | epoch 504 | loss 2.096 | nll_loss 0.328 | ppl 1.26 | wps 24013.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24523 | lr 0.000201936 | gnorm 0.407 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 67785
2022-03-07 07:52:20 | INFO | fairseq.trainer | begin training epoch 505
2022-03-07 07:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:54:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:54:30 | INFO | valid | epoch 505 | valid on 'valid' subset | loss 13.331 | nll_loss 12.723 | ppl 6759.59 | wps 43838.5 | wpb 510.9 | bsz 1 | num_updates 24572 | best_loss 8.937
2022-03-07 07:54:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 24572 updates
2022-03-07 07:54:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:54:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 505 @ 24572 updates, score 13.331) (writing took 2.3350098519586027 seconds)
2022-03-07 07:54:33 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)
2022-03-07 07:54:33 | INFO | train | epoch 505 | loss 2.095 | nll_loss 0.327 | ppl 1.25 | wps 24015.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24572 | lr 0.000201734 | gnorm 0.406 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 67918
2022-03-07 07:54:33 | INFO | fairseq.trainer | begin training epoch 506
2022-03-07 07:54:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:55:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 07:55:48 | INFO | train_inner | epoch 506:     29 / 49 loss=2.095, nll_loss=0.327, ppl=1.25, wps=23808, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=24600, lr=0.000201619, gnorm=0.404, loss_scale=32, train_wall=232, gb_free=8.8, wall=67992
2022-03-07 07:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:56:43 | INFO | valid | epoch 506 | valid on 'valid' subset | loss 13.359 | nll_loss 12.75 | ppl 6890.8 | wps 43414.4 | wpb 510.9 | bsz 1 | num_updates 24620 | best_loss 8.937
2022-03-07 07:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 24620 updates
2022-03-07 07:56:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:56:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:56:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 506 @ 24620 updates, score 13.359) (writing took 2.54941068822518 seconds)
2022-03-07 07:56:45 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)
2022-03-07 07:56:45 | INFO | train | epoch 506 | loss 2.094 | nll_loss 0.326 | ppl 1.25 | wps 23464 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24620 | lr 0.000201538 | gnorm 0.397 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 68050
2022-03-07 07:56:45 | INFO | fairseq.trainer | begin training epoch 507
2022-03-07 07:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 07:58:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 07:58:55 | INFO | valid | epoch 507 | valid on 'valid' subset | loss 13.297 | nll_loss 12.685 | ppl 6585.63 | wps 43519.7 | wpb 510.9 | bsz 1 | num_updates 24669 | best_loss 8.937
2022-03-07 07:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 24669 updates
2022-03-07 07:58:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:58:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 07:58:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 507 @ 24669 updates, score 13.297) (writing took 2.4121345938183367 seconds)
2022-03-07 07:58:58 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)
2022-03-07 07:58:58 | INFO | train | epoch 507 | loss 2.095 | nll_loss 0.327 | ppl 1.25 | wps 24044.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 24669 | lr 0.000201337 | gnorm 0.399 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 68182
2022-03-07 07:58:58 | INFO | fairseq.trainer | begin training epoch 508
2022-03-07 07:58:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:00:19 | INFO | train_inner | epoch 508:     31 / 49 loss=2.095, nll_loss=0.327, ppl=1.25, wps=23946.3, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=24700, lr=0.000201211, gnorm=0.4, loss_scale=32, train_wall=231, gb_free=8.8, wall=68263
2022-03-07 08:01:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:01:10 | INFO | valid | epoch 508 | valid on 'valid' subset | loss 13.374 | nll_loss 12.767 | ppl 6972.02 | wps 41465.4 | wpb 510.9 | bsz 1 | num_updates 24718 | best_loss 8.937
2022-03-07 08:01:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 24718 updates
2022-03-07 08:01:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:01:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:01:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 508 @ 24718 updates, score 13.374) (writing took 2.3670122949406505 seconds)
2022-03-07 08:01:12 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)
2022-03-07 08:01:12 | INFO | train | epoch 508 | loss 2.094 | nll_loss 0.326 | ppl 1.25 | wps 23637 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24718 | lr 0.000201138 | gnorm 0.403 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 68317
2022-03-07 08:01:12 | INFO | fairseq.trainer | begin training epoch 509
2022-03-07 08:01:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:03:25 | INFO | valid | epoch 509 | valid on 'valid' subset | loss 13.301 | nll_loss 12.688 | ppl 6597.23 | wps 42182 | wpb 510.9 | bsz 1 | num_updates 24766 | best_loss 8.937
2022-03-07 08:03:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 24766 updates
2022-03-07 08:03:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:03:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 509 @ 24766 updates, score 13.301) (writing took 2.5028724181465805 seconds)
2022-03-07 08:03:27 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)
2022-03-07 08:03:27 | INFO | train | epoch 509 | loss 2.094 | nll_loss 0.326 | ppl 1.25 | wps 23040.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 24766 | lr 0.000200943 | gnorm 0.404 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68452
2022-03-07 08:03:27 | INFO | fairseq.trainer | begin training epoch 510
2022-03-07 08:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:04:57 | INFO | train_inner | epoch 510:     34 / 49 loss=2.094, nll_loss=0.326, ppl=1.25, wps=23330.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=24800, lr=0.000200805, gnorm=0.404, loss_scale=32, train_wall=237, gb_free=8.8, wall=68541
2022-03-07 08:05:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:05:40 | INFO | valid | epoch 510 | valid on 'valid' subset | loss 13.403 | nll_loss 12.807 | ppl 7168.29 | wps 41134.8 | wpb 510.9 | bsz 1 | num_updates 24815 | best_loss 8.937
2022-03-07 08:05:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 24815 updates
2022-03-07 08:05:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:05:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:05:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 510 @ 24815 updates, score 13.403) (writing took 2.4006874370388687 seconds)
2022-03-07 08:05:42 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)
2022-03-07 08:05:42 | INFO | train | epoch 510 | loss 2.093 | nll_loss 0.326 | ppl 1.25 | wps 23536.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24815 | lr 0.000200744 | gnorm 0.405 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68587
2022-03-07 08:05:42 | INFO | fairseq.trainer | begin training epoch 511
2022-03-07 08:05:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:07:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:07:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:07:55 | INFO | valid | epoch 511 | valid on 'valid' subset | loss 13.371 | nll_loss 12.769 | ppl 6981.98 | wps 41433.8 | wpb 510.9 | bsz 1 | num_updates 24863 | best_loss 8.937
2022-03-07 08:07:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 24863 updates
2022-03-07 08:07:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:07:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:07:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 511 @ 24863 updates, score 13.371) (writing took 2.4642292908392847 seconds)
2022-03-07 08:07:57 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)
2022-03-07 08:07:57 | INFO | train | epoch 511 | loss 2.093 | nll_loss 0.326 | ppl 1.25 | wps 23013.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 24863 | lr 0.00020055 | gnorm 0.4 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68722
2022-03-07 08:07:57 | INFO | fairseq.trainer | begin training epoch 512
2022-03-07 08:07:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:09:35 | INFO | train_inner | epoch 512:     37 / 49 loss=2.093, nll_loss=0.325, ppl=1.25, wps=23332.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=24900, lr=0.000200401, gnorm=0.402, loss_scale=32, train_wall=237, gb_free=8.8, wall=68819
2022-03-07 08:10:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:10:10 | INFO | valid | epoch 512 | valid on 'valid' subset | loss 13.331 | nll_loss 12.726 | ppl 6772.64 | wps 41486.6 | wpb 510.9 | bsz 1 | num_updates 24912 | best_loss 8.937
2022-03-07 08:10:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 24912 updates
2022-03-07 08:10:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:10:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:10:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 512 @ 24912 updates, score 13.331) (writing took 2.4430827130563557 seconds)
2022-03-07 08:10:12 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)
2022-03-07 08:10:12 | INFO | train | epoch 512 | loss 2.092 | nll_loss 0.325 | ppl 1.25 | wps 23535.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24912 | lr 0.000200353 | gnorm 0.402 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68857
2022-03-07 08:10:12 | INFO | fairseq.trainer | begin training epoch 513
2022-03-07 08:10:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:12:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:12:25 | INFO | valid | epoch 513 | valid on 'valid' subset | loss 13.36 | nll_loss 12.751 | ppl 6895.1 | wps 41511.1 | wpb 510.9 | bsz 1 | num_updates 24961 | best_loss 8.937
2022-03-07 08:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 24961 updates
2022-03-07 08:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:12:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 513 @ 24961 updates, score 13.36) (writing took 2.2728199320845306 seconds)
2022-03-07 08:12:27 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)
2022-03-07 08:12:27 | INFO | train | epoch 513 | loss 2.092 | nll_loss 0.325 | ppl 1.25 | wps 23562.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 24961 | lr 0.000200156 | gnorm 0.402 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 68992
2022-03-07 08:12:27 | INFO | fairseq.trainer | begin training epoch 514
2022-03-07 08:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:13:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:14:12 | INFO | train_inner | epoch 514:     40 / 49 loss=2.092, nll_loss=0.325, ppl=1.25, wps=23364.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25000, lr=0.0002, gnorm=0.401, loss_scale=32, train_wall=237, gb_free=8.8, wall=69097
2022-03-07 08:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:14:40 | INFO | valid | epoch 514 | valid on 'valid' subset | loss 13.308 | nll_loss 12.701 | ppl 6659.1 | wps 42189.2 | wpb 510.9 | bsz 1 | num_updates 25009 | best_loss 8.937
2022-03-07 08:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 25009 updates
2022-03-07 08:14:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:14:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 514 @ 25009 updates, score 13.308) (writing took 2.4134750249795616 seconds)
2022-03-07 08:14:42 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)
2022-03-07 08:14:42 | INFO | train | epoch 514 | loss 2.092 | nll_loss 0.325 | ppl 1.25 | wps 23069.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25009 | lr 0.000199964 | gnorm 0.401 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69127
2022-03-07 08:14:42 | INFO | fairseq.trainer | begin training epoch 515
2022-03-07 08:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:16:55 | INFO | valid | epoch 515 | valid on 'valid' subset | loss 13.353 | nll_loss 12.749 | ppl 6881.61 | wps 39738.1 | wpb 510.9 | bsz 1 | num_updates 25058 | best_loss 8.937
2022-03-07 08:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 25058 updates
2022-03-07 08:16:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:16:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:16:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 515 @ 25058 updates, score 13.353) (writing took 2.5817505451850593 seconds)
2022-03-07 08:16:57 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)
2022-03-07 08:16:57 | INFO | train | epoch 515 | loss 2.092 | nll_loss 0.325 | ppl 1.25 | wps 23497.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25058 | lr 0.000199768 | gnorm 0.399 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69262
2022-03-07 08:16:58 | INFO | fairseq.trainer | begin training epoch 516
2022-03-07 08:16:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:18:48 | INFO | train_inner | epoch 516:     42 / 49 loss=2.092, nll_loss=0.325, ppl=1.25, wps=23554.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25100, lr=0.000199601, gnorm=0.397, loss_scale=32, train_wall=234, gb_free=8.8, wall=69372
2022-03-07 08:19:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:19:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:19:10 | INFO | valid | epoch 516 | valid on 'valid' subset | loss 13.391 | nll_loss 12.788 | ppl 7073.19 | wps 41377.9 | wpb 510.9 | bsz 1 | num_updates 25106 | best_loss 8.937
2022-03-07 08:19:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 25106 updates
2022-03-07 08:19:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:19:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:19:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 516 @ 25106 updates, score 13.391) (writing took 2.4439546829089522 seconds)
2022-03-07 08:19:12 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)
2022-03-07 08:19:12 | INFO | train | epoch 516 | loss 2.091 | nll_loss 0.324 | ppl 1.25 | wps 23066.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25106 | lr 0.000199577 | gnorm 0.398 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69397
2022-03-07 08:19:12 | INFO | fairseq.trainer | begin training epoch 517
2022-03-07 08:19:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:21:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:21:25 | INFO | valid | epoch 517 | valid on 'valid' subset | loss 13.298 | nll_loss 12.689 | ppl 6603.27 | wps 41755 | wpb 510.9 | bsz 1 | num_updates 25155 | best_loss 8.937
2022-03-07 08:21:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 25155 updates
2022-03-07 08:21:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:21:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:21:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 517 @ 25155 updates, score 13.298) (writing took 2.556631274987012 seconds)
2022-03-07 08:21:27 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)
2022-03-07 08:21:27 | INFO | train | epoch 517 | loss 2.091 | nll_loss 0.324 | ppl 1.25 | wps 23539.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25155 | lr 0.000199383 | gnorm 0.4 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69532
2022-03-07 08:21:27 | INFO | fairseq.trainer | begin training epoch 518
2022-03-07 08:21:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:23:25 | INFO | train_inner | epoch 518:     45 / 49 loss=2.091, nll_loss=0.324, ppl=1.25, wps=23415.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25200, lr=0.000199205, gnorm=0.399, loss_scale=32, train_wall=236, gb_free=8.8, wall=69649
2022-03-07 08:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:23:39 | INFO | valid | epoch 518 | valid on 'valid' subset | loss 13.411 | nll_loss 12.814 | ppl 7200.16 | wps 43495.1 | wpb 510.9 | bsz 1 | num_updates 25204 | best_loss 8.937
2022-03-07 08:23:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 25204 updates
2022-03-07 08:23:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:23:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:23:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 518 @ 25204 updates, score 13.411) (writing took 2.427992637269199 seconds)
2022-03-07 08:23:41 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)
2022-03-07 08:23:41 | INFO | train | epoch 518 | loss 2.091 | nll_loss 0.324 | ppl 1.25 | wps 23743.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25204 | lr 0.000199189 | gnorm 0.398 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 69666
2022-03-07 08:23:41 | INFO | fairseq.trainer | begin training epoch 519
2022-03-07 08:23:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:25:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:25:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:25:52 | INFO | valid | epoch 519 | valid on 'valid' subset | loss 13.409 | nll_loss 12.809 | ppl 7177.76 | wps 41934.3 | wpb 510.9 | bsz 1 | num_updates 25252 | best_loss 8.937
2022-03-07 08:25:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 25252 updates
2022-03-07 08:25:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:25:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:25:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 519 @ 25252 updates, score 13.409) (writing took 2.4814681820571423 seconds)
2022-03-07 08:25:54 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)
2022-03-07 08:25:54 | INFO | train | epoch 519 | loss 2.09 | nll_loss 0.324 | ppl 1.25 | wps 23431.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25252 | lr 0.000199 | gnorm 0.401 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 69799
2022-03-07 08:25:54 | INFO | fairseq.trainer | begin training epoch 520
2022-03-07 08:25:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:28:00 | INFO | train_inner | epoch 520:     48 / 49 loss=2.09, nll_loss=0.323, ppl=1.25, wps=23563.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25300, lr=0.000198811, gnorm=0.4, loss_scale=32, train_wall=234, gb_free=8.8, wall=69925
2022-03-07 08:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:28:07 | INFO | valid | epoch 520 | valid on 'valid' subset | loss 13.354 | nll_loss 12.749 | ppl 6882.71 | wps 41528.3 | wpb 510.9 | bsz 1 | num_updates 25301 | best_loss 8.937
2022-03-07 08:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 25301 updates
2022-03-07 08:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:28:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 520 @ 25301 updates, score 13.354) (writing took 2.466822342015803 seconds)
2022-03-07 08:28:09 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)
2022-03-07 08:28:09 | INFO | train | epoch 520 | loss 2.09 | nll_loss 0.323 | ppl 1.25 | wps 23546 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25301 | lr 0.000198807 | gnorm 0.399 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 69934
2022-03-07 08:28:09 | INFO | fairseq.trainer | begin training epoch 521
2022-03-07 08:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:30:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:30:22 | INFO | valid | epoch 521 | valid on 'valid' subset | loss 13.336 | nll_loss 12.725 | ppl 6769.46 | wps 41967.2 | wpb 510.9 | bsz 1 | num_updates 25350 | best_loss 8.937
2022-03-07 08:30:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 25350 updates
2022-03-07 08:30:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:30:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:30:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 521 @ 25350 updates, score 13.336) (writing took 2.434883945155889 seconds)
2022-03-07 08:30:24 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)
2022-03-07 08:30:24 | INFO | train | epoch 521 | loss 2.089 | nll_loss 0.323 | ppl 1.25 | wps 23567.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25350 | lr 0.000198615 | gnorm 0.399 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70069
2022-03-07 08:30:24 | INFO | fairseq.trainer | begin training epoch 522
2022-03-07 08:30:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:31:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:32:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:32:36 | INFO | valid | epoch 522 | valid on 'valid' subset | loss 13.35 | nll_loss 12.748 | ppl 6876.85 | wps 41988.8 | wpb 510.9 | bsz 1 | num_updates 25398 | best_loss 8.937
2022-03-07 08:32:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 25398 updates
2022-03-07 08:32:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:32:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:32:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 522 @ 25398 updates, score 13.35) (writing took 2.612725225277245 seconds)
2022-03-07 08:32:39 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)
2022-03-07 08:32:39 | INFO | train | epoch 522 | loss 2.089 | nll_loss 0.323 | ppl 1.25 | wps 23055.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25398 | lr 0.000198427 | gnorm 0.399 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 70204
2022-03-07 08:32:39 | INFO | fairseq.trainer | begin training epoch 523
2022-03-07 08:32:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:32:44 | INFO | train_inner | epoch 523:      2 / 49 loss=2.089, nll_loss=0.322, ppl=1.25, wps=22703.8, ups=0.35, wpb=64544.1, bsz=126.1, num_updates=25400, lr=0.000198419, gnorm=0.4, loss_scale=32, train_wall=235, gb_free=8.8, wall=70209
2022-03-07 08:34:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:34:51 | INFO | valid | epoch 523 | valid on 'valid' subset | loss 13.388 | nll_loss 12.783 | ppl 7047.97 | wps 42368.9 | wpb 510.9 | bsz 1 | num_updates 25447 | best_loss 8.937
2022-03-07 08:34:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 25447 updates
2022-03-07 08:34:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:34:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:34:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 523 @ 25447 updates, score 13.388) (writing took 2.4300225349143147 seconds)
2022-03-07 08:34:53 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)
2022-03-07 08:34:53 | INFO | train | epoch 523 | loss 2.089 | nll_loss 0.323 | ppl 1.25 | wps 23639.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25447 | lr 0.000198236 | gnorm 0.404 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 70338
2022-03-07 08:34:53 | INFO | fairseq.trainer | begin training epoch 524
2022-03-07 08:34:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:37:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:37:06 | INFO | valid | epoch 524 | valid on 'valid' subset | loss 13.417 | nll_loss 12.82 | ppl 7230.53 | wps 41137.8 | wpb 510.9 | bsz 1 | num_updates 25496 | best_loss 8.937
2022-03-07 08:37:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 25496 updates
2022-03-07 08:37:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:37:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:37:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 524 @ 25496 updates, score 13.417) (writing took 2.4057226171717048 seconds)
2022-03-07 08:37:08 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)
2022-03-07 08:37:08 | INFO | train | epoch 524 | loss 2.088 | nll_loss 0.321 | ppl 1.25 | wps 23590.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25496 | lr 0.000198045 | gnorm 0.394 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 70473
2022-03-07 08:37:08 | INFO | fairseq.trainer | begin training epoch 525
2022-03-07 08:37:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:37:19 | INFO | train_inner | epoch 525:      4 / 49 loss=2.088, nll_loss=0.322, ppl=1.25, wps=23638, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=25500, lr=0.00019803, gnorm=0.4, loss_scale=64, train_wall=234, gb_free=8.8, wall=70483
2022-03-07 08:37:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:39:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:39:20 | INFO | valid | epoch 525 | valid on 'valid' subset | loss 13.34 | nll_loss 12.738 | ppl 6829.3 | wps 41587.3 | wpb 510.9 | bsz 1 | num_updates 25544 | best_loss 8.937
2022-03-07 08:39:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 25544 updates
2022-03-07 08:39:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:39:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:39:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 525 @ 25544 updates, score 13.34) (writing took 2.3642945610918105 seconds)
2022-03-07 08:39:22 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)
2022-03-07 08:39:22 | INFO | train | epoch 525 | loss 2.088 | nll_loss 0.322 | ppl 1.25 | wps 23160.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25544 | lr 0.000197859 | gnorm 0.396 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 70607
2022-03-07 08:39:23 | INFO | fairseq.trainer | begin training epoch 526
2022-03-07 08:39:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:41:34 | INFO | valid | epoch 526 | valid on 'valid' subset | loss 13.408 | nll_loss 12.806 | ppl 7162.93 | wps 41509.8 | wpb 510.9 | bsz 1 | num_updates 25593 | best_loss 8.937
2022-03-07 08:41:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 25593 updates
2022-03-07 08:41:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:41:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:41:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 526 @ 25593 updates, score 13.408) (writing took 2.3955118828453124 seconds)
2022-03-07 08:41:37 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)
2022-03-07 08:41:37 | INFO | train | epoch 526 | loss 2.088 | nll_loss 0.322 | ppl 1.25 | wps 23663.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25593 | lr 0.000197669 | gnorm 0.394 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 70742
2022-03-07 08:41:37 | INFO | fairseq.trainer | begin training epoch 527
2022-03-07 08:41:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:41:55 | INFO | train_inner | epoch 527:      7 / 49 loss=2.088, nll_loss=0.322, ppl=1.25, wps=23470.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=25600, lr=0.000197642, gnorm=0.395, loss_scale=32, train_wall=235, gb_free=8.8, wall=70760
2022-03-07 08:43:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:43:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:43:49 | INFO | valid | epoch 527 | valid on 'valid' subset | loss 13.395 | nll_loss 12.798 | ppl 7120.41 | wps 42008.8 | wpb 510.9 | bsz 1 | num_updates 25641 | best_loss 8.937
2022-03-07 08:43:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 25641 updates
2022-03-07 08:43:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:43:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:43:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 527 @ 25641 updates, score 13.395) (writing took 2.4428758258000016 seconds)
2022-03-07 08:43:51 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)
2022-03-07 08:43:51 | INFO | train | epoch 527 | loss 2.088 | nll_loss 0.322 | ppl 1.25 | wps 23195.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25641 | lr 0.000197484 | gnorm 0.401 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 70876
2022-03-07 08:43:51 | INFO | fairseq.trainer | begin training epoch 528
2022-03-07 08:43:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:45:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:46:03 | INFO | valid | epoch 528 | valid on 'valid' subset | loss 13.421 | nll_loss 12.822 | ppl 7241.02 | wps 41518.3 | wpb 510.9 | bsz 1 | num_updates 25690 | best_loss 8.937
2022-03-07 08:46:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 25690 updates
2022-03-07 08:46:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:46:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:46:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 528 @ 25690 updates, score 13.421) (writing took 2.3174231578595936 seconds)
2022-03-07 08:46:05 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)
2022-03-07 08:46:05 | INFO | train | epoch 528 | loss 2.087 | nll_loss 0.321 | ppl 1.25 | wps 23652.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25690 | lr 0.000197296 | gnorm 0.402 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 71010
2022-03-07 08:46:05 | INFO | fairseq.trainer | begin training epoch 529
2022-03-07 08:46:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:46:32 | INFO | train_inner | epoch 529:     10 / 49 loss=2.087, nll_loss=0.321, ppl=1.25, wps=23451.4, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=25700, lr=0.000197257, gnorm=0.401, loss_scale=32, train_wall=236, gb_free=8.8, wall=71036
2022-03-07 08:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:48:18 | INFO | valid | epoch 529 | valid on 'valid' subset | loss 13.296 | nll_loss 12.689 | ppl 6605.06 | wps 40121.8 | wpb 510.9 | bsz 1 | num_updates 25739 | best_loss 8.937
2022-03-07 08:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 25739 updates
2022-03-07 08:48:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:48:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:48:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 529 @ 25739 updates, score 13.296) (writing took 2.5649183252826333 seconds)
2022-03-07 08:48:20 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)
2022-03-07 08:48:20 | INFO | train | epoch 529 | loss 2.086 | nll_loss 0.32 | ppl 1.25 | wps 23587.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 25739 | lr 0.000197108 | gnorm 0.398 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 71145
2022-03-07 08:48:20 | INFO | fairseq.trainer | begin training epoch 530
2022-03-07 08:48:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:49:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:50:32 | INFO | valid | epoch 530 | valid on 'valid' subset | loss 13.373 | nll_loss 12.77 | ppl 6982.7 | wps 41072.7 | wpb 510.9 | bsz 1 | num_updates 25787 | best_loss 8.937
2022-03-07 08:50:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 25787 updates
2022-03-07 08:50:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:50:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:50:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 530 @ 25787 updates, score 13.373) (writing took 2.4779639183543622 seconds)
2022-03-07 08:50:34 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)
2022-03-07 08:50:34 | INFO | train | epoch 530 | loss 2.086 | nll_loss 0.32 | ppl 1.25 | wps 23234.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25787 | lr 0.000196924 | gnorm 0.394 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 71279
2022-03-07 08:50:34 | INFO | fairseq.trainer | begin training epoch 531
2022-03-07 08:50:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:51:08 | INFO | train_inner | epoch 531:     13 / 49 loss=2.086, nll_loss=0.32, ppl=1.25, wps=23470, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=25800, lr=0.000196875, gnorm=0.395, loss_scale=32, train_wall=235, gb_free=8.8, wall=71313
2022-03-07 08:52:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:52:45 | INFO | valid | epoch 531 | valid on 'valid' subset | loss 13.346 | nll_loss 12.743 | ppl 6857.08 | wps 42912.6 | wpb 510.9 | bsz 1 | num_updates 25836 | best_loss 8.937
2022-03-07 08:52:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 25836 updates
2022-03-07 08:52:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:52:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 531 @ 25836 updates, score 13.346) (writing took 2.3322386350482702 seconds)
2022-03-07 08:52:47 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)
2022-03-07 08:52:47 | INFO | train | epoch 531 | loss 2.085 | nll_loss 0.319 | ppl 1.25 | wps 23838.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25836 | lr 0.000196738 | gnorm 0.392 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 71412
2022-03-07 08:52:47 | INFO | fairseq.trainer | begin training epoch 532
2022-03-07 08:52:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:54:57 | INFO | valid | epoch 532 | valid on 'valid' subset | loss 13.398 | nll_loss 12.795 | ppl 7106.88 | wps 43029 | wpb 510.9 | bsz 1 | num_updates 25885 | best_loss 8.937
2022-03-07 08:54:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 25885 updates
2022-03-07 08:54:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:54:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:54:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 532 @ 25885 updates, score 13.398) (writing took 2.320984970778227 seconds)
2022-03-07 08:54:59 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)
2022-03-07 08:54:59 | INFO | train | epoch 532 | loss 2.086 | nll_loss 0.32 | ppl 1.25 | wps 24109.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25885 | lr 0.000196551 | gnorm 0.398 | loss_scale 64 | train_wall 112 | gb_free 8.8 | wall 71544
2022-03-07 08:54:59 | INFO | fairseq.trainer | begin training epoch 533
2022-03-07 08:54:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:55:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 08:55:41 | INFO | train_inner | epoch 533:     16 / 49 loss=2.086, nll_loss=0.32, ppl=1.25, wps=23816.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=25900, lr=0.000196494, gnorm=0.397, loss_scale=32, train_wall=232, gb_free=8.8, wall=71585
2022-03-07 08:57:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:57:09 | INFO | valid | epoch 533 | valid on 'valid' subset | loss 13.344 | nll_loss 12.738 | ppl 6833.78 | wps 43277.7 | wpb 510.9 | bsz 1 | num_updates 25933 | best_loss 8.937
2022-03-07 08:57:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 25933 updates
2022-03-07 08:57:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 533 @ 25933 updates, score 13.344) (writing took 2.3134523136541247 seconds)
2022-03-07 08:57:11 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)
2022-03-07 08:57:11 | INFO | train | epoch 533 | loss 2.086 | nll_loss 0.32 | ppl 1.25 | wps 23545.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 25933 | lr 0.000196369 | gnorm 0.399 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71676
2022-03-07 08:57:11 | INFO | fairseq.trainer | begin training epoch 534
2022-03-07 08:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 08:59:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 08:59:21 | INFO | valid | epoch 534 | valid on 'valid' subset | loss 13.3 | nll_loss 12.695 | ppl 6629.61 | wps 42643.8 | wpb 510.9 | bsz 1 | num_updates 25982 | best_loss 8.937
2022-03-07 08:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 25982 updates
2022-03-07 08:59:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:59:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 08:59:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 534 @ 25982 updates, score 13.3) (writing took 2.3903788961470127 seconds)
2022-03-07 08:59:24 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)
2022-03-07 08:59:24 | INFO | train | epoch 534 | loss 2.085 | nll_loss 0.319 | ppl 1.25 | wps 23988 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 25982 | lr 0.000196184 | gnorm 0.399 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71809
2022-03-07 08:59:24 | INFO | fairseq.trainer | begin training epoch 535
2022-03-07 08:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:00:10 | INFO | train_inner | epoch 535:     18 / 49 loss=2.085, nll_loss=0.319, ppl=1.25, wps=24052, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26000, lr=0.000196116, gnorm=0.396, loss_scale=32, train_wall=230, gb_free=8.8, wall=71855
2022-03-07 09:01:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:01:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:01:35 | INFO | valid | epoch 535 | valid on 'valid' subset | loss 13.342 | nll_loss 12.738 | ppl 6833.22 | wps 42470.3 | wpb 510.9 | bsz 1 | num_updates 26030 | best_loss 8.937
2022-03-07 09:01:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 26030 updates
2022-03-07 09:01:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:01:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:01:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 535 @ 26030 updates, score 13.342) (writing took 2.3655459680594504 seconds)
2022-03-07 09:01:37 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)
2022-03-07 09:01:37 | INFO | train | epoch 535 | loss 2.084 | nll_loss 0.319 | ppl 1.25 | wps 23356.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26030 | lr 0.000196003 | gnorm 0.392 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 71942
2022-03-07 09:01:37 | INFO | fairseq.trainer | begin training epoch 536
2022-03-07 09:01:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:03:49 | INFO | valid | epoch 536 | valid on 'valid' subset | loss 13.36 | nll_loss 12.758 | ppl 6928.67 | wps 41482.4 | wpb 510.9 | bsz 1 | num_updates 26079 | best_loss 8.937
2022-03-07 09:03:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 26079 updates
2022-03-07 09:03:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:03:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:03:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 536 @ 26079 updates, score 13.36) (writing took 2.5114466911181808 seconds)
2022-03-07 09:03:52 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)
2022-03-07 09:03:52 | INFO | train | epoch 536 | loss 2.084 | nll_loss 0.319 | ppl 1.25 | wps 23633.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26079 | lr 0.000195819 | gnorm 0.398 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 72076
2022-03-07 09:03:52 | INFO | fairseq.trainer | begin training epoch 537
2022-03-07 09:03:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:04:47 | INFO | train_inner | epoch 537:     21 / 49 loss=2.084, nll_loss=0.319, ppl=1.25, wps=23439.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26100, lr=0.00019574, gnorm=0.396, loss_scale=32, train_wall=236, gb_free=8.8, wall=72132
2022-03-07 09:05:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:06:05 | INFO | valid | epoch 537 | valid on 'valid' subset | loss 13.377 | nll_loss 12.779 | ppl 7026.16 | wps 41571.7 | wpb 510.9 | bsz 1 | num_updates 26128 | best_loss 8.937
2022-03-07 09:06:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 26128 updates
2022-03-07 09:06:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:06:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:06:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 537 @ 26128 updates, score 13.377) (writing took 2.412575746886432 seconds)
2022-03-07 09:06:07 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)
2022-03-07 09:06:07 | INFO | train | epoch 537 | loss 2.084 | nll_loss 0.318 | ppl 1.25 | wps 23463.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26128 | lr 0.000195635 | gnorm 0.394 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 72212
2022-03-07 09:06:07 | INFO | fairseq.trainer | begin training epoch 538
2022-03-07 09:06:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:07:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:08:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:08:20 | INFO | valid | epoch 538 | valid on 'valid' subset | loss 13.411 | nll_loss 12.814 | ppl 7201.15 | wps 39920.6 | wpb 510.9 | bsz 1 | num_updates 26176 | best_loss 8.937
2022-03-07 09:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 26176 updates
2022-03-07 09:08:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:08:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:08:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 538 @ 26176 updates, score 13.411) (writing took 2.4982251874171197 seconds)
2022-03-07 09:08:23 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)
2022-03-07 09:08:23 | INFO | train | epoch 538 | loss 2.083 | nll_loss 0.318 | ppl 1.25 | wps 22916.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26176 | lr 0.000195456 | gnorm 0.392 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 72348
2022-03-07 09:08:23 | INFO | fairseq.trainer | begin training epoch 539
2022-03-07 09:08:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:09:26 | INFO | train_inner | epoch 539:     24 / 49 loss=2.084, nll_loss=0.318, ppl=1.25, wps=23238.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26200, lr=0.000195366, gnorm=0.394, loss_scale=32, train_wall=238, gb_free=8.8, wall=72411
2022-03-07 09:10:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:10:36 | INFO | valid | epoch 539 | valid on 'valid' subset | loss 13.36 | nll_loss 12.757 | ppl 6920.04 | wps 41327.7 | wpb 510.9 | bsz 1 | num_updates 26225 | best_loss 8.937
2022-03-07 09:10:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 26225 updates
2022-03-07 09:10:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:10:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:10:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 539 @ 26225 updates, score 13.36) (writing took 2.471005282830447 seconds)
2022-03-07 09:10:38 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)
2022-03-07 09:10:38 | INFO | train | epoch 539 | loss 2.083 | nll_loss 0.319 | ppl 1.25 | wps 23453.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26225 | lr 0.000195273 | gnorm 0.401 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 72483
2022-03-07 09:10:38 | INFO | fairseq.trainer | begin training epoch 540
2022-03-07 09:10:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:12:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:12:51 | INFO | valid | epoch 540 | valid on 'valid' subset | loss 13.418 | nll_loss 12.823 | ppl 7248.67 | wps 41670.9 | wpb 510.9 | bsz 1 | num_updates 26274 | best_loss 8.937
2022-03-07 09:12:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 26274 updates
2022-03-07 09:12:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:12:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:12:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 540 @ 26274 updates, score 13.418) (writing took 2.5307596470229328 seconds)
2022-03-07 09:12:54 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)
2022-03-07 09:12:54 | INFO | train | epoch 540 | loss 2.083 | nll_loss 0.319 | ppl 1.25 | wps 23446 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26274 | lr 0.000195091 | gnorm 0.396 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 72619
2022-03-07 09:12:54 | INFO | fairseq.trainer | begin training epoch 541
2022-03-07 09:12:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:13:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:14:05 | INFO | train_inner | epoch 541:     27 / 49 loss=2.083, nll_loss=0.319, ppl=1.25, wps=23267, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26300, lr=0.000194994, gnorm=0.398, loss_scale=32, train_wall=238, gb_free=8.8, wall=72690
2022-03-07 09:15:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:15:07 | INFO | valid | epoch 541 | valid on 'valid' subset | loss 13.366 | nll_loss 12.768 | ppl 6976.55 | wps 40740.6 | wpb 510.9 | bsz 1 | num_updates 26322 | best_loss 8.937
2022-03-07 09:15:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 26322 updates
2022-03-07 09:15:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:15:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 541 @ 26322 updates, score 13.366) (writing took 2.389066376723349 seconds)
2022-03-07 09:15:09 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)
2022-03-07 09:15:09 | INFO | train | epoch 541 | loss 2.083 | nll_loss 0.318 | ppl 1.25 | wps 22987 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26322 | lr 0.000194913 | gnorm 0.397 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 72754
2022-03-07 09:15:09 | INFO | fairseq.trainer | begin training epoch 542
2022-03-07 09:15:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:17:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:17:22 | INFO | valid | epoch 542 | valid on 'valid' subset | loss 13.358 | nll_loss 12.757 | ppl 6922.15 | wps 40959.8 | wpb 510.9 | bsz 1 | num_updates 26371 | best_loss 8.937
2022-03-07 09:17:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 26371 updates
2022-03-07 09:17:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:17:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:17:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 542 @ 26371 updates, score 13.358) (writing took 2.4214582932181656 seconds)
2022-03-07 09:17:25 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)
2022-03-07 09:17:25 | INFO | train | epoch 542 | loss 2.082 | nll_loss 0.317 | ppl 1.25 | wps 23449.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26371 | lr 0.000194732 | gnorm 0.385 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 72890
2022-03-07 09:17:25 | INFO | fairseq.trainer | begin training epoch 543
2022-03-07 09:17:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:18:41 | INFO | train_inner | epoch 543:     29 / 49 loss=2.082, nll_loss=0.317, ppl=1.25, wps=23473, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26400, lr=0.000194625, gnorm=0.39, loss_scale=32, train_wall=235, gb_free=8.8, wall=72966
2022-03-07 09:19:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:19:38 | INFO | valid | epoch 543 | valid on 'valid' subset | loss 13.421 | nll_loss 12.821 | ppl 7234.49 | wps 40161.2 | wpb 510.9 | bsz 1 | num_updates 26420 | best_loss 8.937
2022-03-07 09:19:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 26420 updates
2022-03-07 09:19:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:19:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:19:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 543 @ 26420 updates, score 13.421) (writing took 2.52617198927328 seconds)
2022-03-07 09:19:41 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)
2022-03-07 09:19:41 | INFO | train | epoch 543 | loss 2.082 | nll_loss 0.317 | ppl 1.25 | wps 23411.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26420 | lr 0.000194551 | gnorm 0.396 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 73025
2022-03-07 09:19:41 | INFO | fairseq.trainer | begin training epoch 544
2022-03-07 09:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:20:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:21:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:21:54 | INFO | valid | epoch 544 | valid on 'valid' subset | loss 13.366 | nll_loss 12.768 | ppl 6975.88 | wps 41372.5 | wpb 510.9 | bsz 1 | num_updates 26468 | best_loss 8.937
2022-03-07 09:21:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 26468 updates
2022-03-07 09:21:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:21:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:21:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 544 @ 26468 updates, score 13.366) (writing took 2.4826109977439046 seconds)
2022-03-07 09:21:56 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)
2022-03-07 09:21:56 | INFO | train | epoch 544 | loss 2.083 | nll_loss 0.318 | ppl 1.25 | wps 22973.1 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 26468 | lr 0.000194375 | gnorm 0.397 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 73161
2022-03-07 09:21:56 | INFO | fairseq.trainer | begin training epoch 545
2022-03-07 09:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:23:20 | INFO | train_inner | epoch 545:     32 / 49 loss=2.082, nll_loss=0.318, ppl=1.25, wps=23259.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26500, lr=0.000194257, gnorm=0.394, loss_scale=32, train_wall=237, gb_free=8.8, wall=73245
2022-03-07 09:24:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:24:09 | INFO | valid | epoch 545 | valid on 'valid' subset | loss 13.368 | nll_loss 12.763 | ppl 6952.42 | wps 42196.3 | wpb 510.9 | bsz 1 | num_updates 26517 | best_loss 8.937
2022-03-07 09:24:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 26517 updates
2022-03-07 09:24:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 545 @ 26517 updates, score 13.368) (writing took 2.5090333251282573 seconds)
2022-03-07 09:24:11 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)
2022-03-07 09:24:11 | INFO | train | epoch 545 | loss 2.081 | nll_loss 0.317 | ppl 1.25 | wps 23504.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26517 | lr 0.000194195 | gnorm 0.388 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 73296
2022-03-07 09:24:11 | INFO | fairseq.trainer | begin training epoch 546
2022-03-07 09:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:26:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:26:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:26:23 | INFO | valid | epoch 546 | valid on 'valid' subset | loss 13.415 | nll_loss 12.816 | ppl 7210.74 | wps 42855.6 | wpb 510.9 | bsz 1 | num_updates 26565 | best_loss 8.937
2022-03-07 09:26:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 26565 updates
2022-03-07 09:26:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:26:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:26:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 546 @ 26565 updates, score 13.415) (writing took 2.364596419967711 seconds)
2022-03-07 09:26:26 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)
2022-03-07 09:26:26 | INFO | train | epoch 546 | loss 2.081 | nll_loss 0.316 | ppl 1.25 | wps 23128.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26565 | lr 0.000194019 | gnorm 0.389 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 73431
2022-03-07 09:26:26 | INFO | fairseq.trainer | begin training epoch 547
2022-03-07 09:26:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:27:56 | INFO | train_inner | epoch 547:     35 / 49 loss=2.081, nll_loss=0.316, ppl=1.25, wps=23498.5, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=26600, lr=0.000193892, gnorm=0.389, loss_scale=32, train_wall=235, gb_free=8.8, wall=73521
2022-03-07 09:28:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:28:36 | INFO | valid | epoch 547 | valid on 'valid' subset | loss 13.373 | nll_loss 12.774 | ppl 7004.64 | wps 42724.8 | wpb 510.9 | bsz 1 | num_updates 26614 | best_loss 8.937
2022-03-07 09:28:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 26614 updates
2022-03-07 09:28:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:28:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:28:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 547 @ 26614 updates, score 13.373) (writing took 2.4503501811996102 seconds)
2022-03-07 09:28:39 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)
2022-03-07 09:28:39 | INFO | train | epoch 547 | loss 2.08 | nll_loss 0.316 | ppl 1.24 | wps 23927.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26614 | lr 0.000193841 | gnorm 0.389 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73563
2022-03-07 09:28:39 | INFO | fairseq.trainer | begin training epoch 548
2022-03-07 09:28:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:30:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:30:49 | INFO | valid | epoch 548 | valid on 'valid' subset | loss 13.325 | nll_loss 12.718 | ppl 6738.19 | wps 43072.6 | wpb 510.9 | bsz 1 | num_updates 26663 | best_loss 8.937
2022-03-07 09:30:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 26663 updates
2022-03-07 09:30:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:30:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 548 @ 26663 updates, score 13.325) (writing took 2.510625110939145 seconds)
2022-03-07 09:30:52 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)
2022-03-07 09:30:52 | INFO | train | epoch 548 | loss 2.08 | nll_loss 0.316 | ppl 1.24 | wps 23885.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26663 | lr 0.000193662 | gnorm 0.388 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73696
2022-03-07 09:30:52 | INFO | fairseq.trainer | begin training epoch 549
2022-03-07 09:30:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:31:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:32:30 | INFO | train_inner | epoch 549:     38 / 49 loss=2.08, nll_loss=0.316, ppl=1.24, wps=23726.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=26700, lr=0.000193528, gnorm=0.39, loss_scale=32, train_wall=233, gb_free=8.8, wall=73794
2022-03-07 09:32:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:33:02 | INFO | valid | epoch 549 | valid on 'valid' subset | loss 13.343 | nll_loss 12.741 | ppl 6844.82 | wps 43046.3 | wpb 510.9 | bsz 1 | num_updates 26711 | best_loss 8.937
2022-03-07 09:33:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 26711 updates
2022-03-07 09:33:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 549 @ 26711 updates, score 13.343) (writing took 2.502350872848183 seconds)
2022-03-07 09:33:04 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)
2022-03-07 09:33:04 | INFO | train | epoch 549 | loss 2.08 | nll_loss 0.316 | ppl 1.24 | wps 23457.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26711 | lr 0.000193488 | gnorm 0.393 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73829
2022-03-07 09:33:04 | INFO | fairseq.trainer | begin training epoch 550
2022-03-07 09:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:35:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:35:15 | INFO | valid | epoch 550 | valid on 'valid' subset | loss 13.33 | nll_loss 12.726 | ppl 6774.08 | wps 42928.3 | wpb 510.9 | bsz 1 | num_updates 26760 | best_loss 8.937
2022-03-07 09:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 26760 updates
2022-03-07 09:35:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:35:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:35:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 550 @ 26760 updates, score 13.33) (writing took 2.2943472689948976 seconds)
2022-03-07 09:35:17 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)
2022-03-07 09:35:17 | INFO | train | epoch 550 | loss 2.08 | nll_loss 0.316 | ppl 1.24 | wps 23955.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26760 | lr 0.000193311 | gnorm 0.392 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 73962
2022-03-07 09:35:17 | INFO | fairseq.trainer | begin training epoch 551
2022-03-07 09:35:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:37:00 | INFO | train_inner | epoch 551:     40 / 49 loss=2.079, nll_loss=0.316, ppl=1.24, wps=23973.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=26800, lr=0.000193167, gnorm=0.39, loss_scale=32, train_wall=231, gb_free=8.8, wall=74065
2022-03-07 09:37:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:37:27 | INFO | valid | epoch 551 | valid on 'valid' subset | loss 13.293 | nll_loss 12.69 | ppl 6609.62 | wps 43002.6 | wpb 510.9 | bsz 1 | num_updates 26809 | best_loss 8.937
2022-03-07 09:37:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 26809 updates
2022-03-07 09:37:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:37:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:37:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 551 @ 26809 updates, score 13.293) (writing took 2.440056513994932 seconds)
2022-03-07 09:37:30 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)
2022-03-07 09:37:30 | INFO | train | epoch 551 | loss 2.079 | nll_loss 0.315 | ppl 1.24 | wps 23933.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 26809 | lr 0.000193134 | gnorm 0.389 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 74095
2022-03-07 09:37:30 | INFO | fairseq.trainer | begin training epoch 552
2022-03-07 09:37:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:38:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:39:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:39:41 | INFO | valid | epoch 552 | valid on 'valid' subset | loss 13.334 | nll_loss 12.732 | ppl 6803.97 | wps 41030.5 | wpb 510.9 | bsz 1 | num_updates 26857 | best_loss 8.937
2022-03-07 09:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 26857 updates
2022-03-07 09:39:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:39:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:39:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 552 @ 26857 updates, score 13.334) (writing took 2.31883965106681 seconds)
2022-03-07 09:39:43 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)
2022-03-07 09:39:43 | INFO | train | epoch 552 | loss 2.079 | nll_loss 0.316 | ppl 1.24 | wps 23407.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 26857 | lr 0.000192962 | gnorm 0.388 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 74228
2022-03-07 09:39:43 | INFO | fairseq.trainer | begin training epoch 553
2022-03-07 09:39:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:41:36 | INFO | train_inner | epoch 553:     43 / 49 loss=2.079, nll_loss=0.315, ppl=1.24, wps=23520.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=26900, lr=0.000192807, gnorm=0.388, loss_scale=32, train_wall=235, gb_free=8.8, wall=74341
2022-03-07 09:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:41:56 | INFO | valid | epoch 553 | valid on 'valid' subset | loss 13.298 | nll_loss 12.69 | ppl 6607.54 | wps 41745.4 | wpb 510.9 | bsz 1 | num_updates 26906 | best_loss 8.937
2022-03-07 09:41:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 26906 updates
2022-03-07 09:41:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:41:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:41:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 553 @ 26906 updates, score 13.298) (writing took 2.5303901229053736 seconds)
2022-03-07 09:41:58 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)
2022-03-07 09:41:58 | INFO | train | epoch 553 | loss 2.079 | nll_loss 0.315 | ppl 1.24 | wps 23438.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26906 | lr 0.000192786 | gnorm 0.388 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 74363
2022-03-07 09:41:58 | INFO | fairseq.trainer | begin training epoch 554
2022-03-07 09:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:44:11 | INFO | valid | epoch 554 | valid on 'valid' subset | loss 13.364 | nll_loss 12.76 | ppl 6936.76 | wps 41821.4 | wpb 510.9 | bsz 1 | num_updates 26955 | best_loss 8.937
2022-03-07 09:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 26955 updates
2022-03-07 09:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 554 @ 26955 updates, score 13.364) (writing took 2.455768255982548 seconds)
2022-03-07 09:44:14 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)
2022-03-07 09:44:14 | INFO | train | epoch 554 | loss 2.079 | nll_loss 0.315 | ppl 1.24 | wps 23498.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 26955 | lr 0.000192611 | gnorm 0.391 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 74498
2022-03-07 09:44:14 | INFO | fairseq.trainer | begin training epoch 555
2022-03-07 09:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:44:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:46:15 | INFO | train_inner | epoch 555:     46 / 49 loss=2.079, nll_loss=0.315, ppl=1.24, wps=23281.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27000, lr=0.00019245, gnorm=0.391, loss_scale=32, train_wall=237, gb_free=8.8, wall=74620
2022-03-07 09:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:46:27 | INFO | valid | epoch 555 | valid on 'valid' subset | loss 13.392 | nll_loss 12.797 | ppl 7114.79 | wps 41021.2 | wpb 510.9 | bsz 1 | num_updates 27003 | best_loss 8.937
2022-03-07 09:46:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 27003 updates
2022-03-07 09:46:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:46:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 555 @ 27003 updates, score 13.392) (writing took 2.4181987452320755 seconds)
2022-03-07 09:46:29 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)
2022-03-07 09:46:29 | INFO | train | epoch 555 | loss 2.079 | nll_loss 0.315 | ppl 1.24 | wps 22966.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 27003 | lr 0.000192439 | gnorm 0.39 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 74634
2022-03-07 09:46:29 | INFO | fairseq.trainer | begin training epoch 556
2022-03-07 09:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:48:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:48:42 | INFO | valid | epoch 556 | valid on 'valid' subset | loss 13.475 | nll_loss 12.885 | ppl 7565.59 | wps 41301.6 | wpb 510.9 | bsz 1 | num_updates 27052 | best_loss 8.937
2022-03-07 09:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 27052 updates
2022-03-07 09:48:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:48:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:48:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 556 @ 27052 updates, score 13.475) (writing took 2.4063196619972587 seconds)
2022-03-07 09:48:45 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)
2022-03-07 09:48:45 | INFO | train | epoch 556 | loss 2.078 | nll_loss 0.314 | ppl 1.24 | wps 23482.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27052 | lr 0.000192265 | gnorm 0.389 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 74769
2022-03-07 09:48:45 | INFO | fairseq.trainer | begin training epoch 557
2022-03-07 09:48:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:50:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:50:52 | INFO | train_inner | epoch 557:     49 / 49 loss=2.078, nll_loss=0.314, ppl=1.24, wps=23266.8, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=27100, lr=0.000192095, gnorm=0.39, loss_scale=32, train_wall=236, gb_free=8.8, wall=74897
2022-03-07 09:50:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:50:58 | INFO | valid | epoch 557 | valid on 'valid' subset | loss 13.357 | nll_loss 12.758 | ppl 6925.1 | wps 40721.3 | wpb 510.9 | bsz 1 | num_updates 27100 | best_loss 8.937
2022-03-07 09:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 27100 updates
2022-03-07 09:50:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:51:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:51:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 557 @ 27100 updates, score 13.357) (writing took 2.466081609018147 seconds)
2022-03-07 09:51:00 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)
2022-03-07 09:51:00 | INFO | train | epoch 557 | loss 2.077 | nll_loss 0.314 | ppl 1.24 | wps 22962 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 27100 | lr 0.000192095 | gnorm 0.388 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 74905
2022-03-07 09:51:00 | INFO | fairseq.trainer | begin training epoch 558
2022-03-07 09:51:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:53:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:53:13 | INFO | valid | epoch 558 | valid on 'valid' subset | loss 13.417 | nll_loss 12.818 | ppl 7222.27 | wps 41004.4 | wpb 510.9 | bsz 1 | num_updates 27149 | best_loss 8.937
2022-03-07 09:53:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 27149 updates
2022-03-07 09:53:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:53:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:53:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 558 @ 27149 updates, score 13.417) (writing took 2.518791250884533 seconds)
2022-03-07 09:53:16 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)
2022-03-07 09:53:16 | INFO | train | epoch 558 | loss 2.077 | nll_loss 0.314 | ppl 1.24 | wps 23454.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27149 | lr 0.000191921 | gnorm 0.391 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75040
2022-03-07 09:53:16 | INFO | fairseq.trainer | begin training epoch 559
2022-03-07 09:53:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:55:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:55:28 | INFO | valid | epoch 559 | valid on 'valid' subset | loss 13.401 | nll_loss 12.803 | ppl 7146.08 | wps 41313.7 | wpb 510.9 | bsz 1 | num_updates 27198 | best_loss 8.937
2022-03-07 09:55:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 27198 updates
2022-03-07 09:55:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:55:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:55:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 559 @ 27198 updates, score 13.401) (writing took 2.401415579020977 seconds)
2022-03-07 09:55:31 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)
2022-03-07 09:55:31 | INFO | train | epoch 559 | loss 2.077 | nll_loss 0.314 | ppl 1.24 | wps 23490.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27198 | lr 0.000191748 | gnorm 0.388 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75176
2022-03-07 09:55:31 | INFO | fairseq.trainer | begin training epoch 560
2022-03-07 09:55:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:55:36 | INFO | train_inner | epoch 560:      2 / 49 loss=2.077, nll_loss=0.314, ppl=1.24, wps=22836.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=27200, lr=0.000191741, gnorm=0.389, loss_scale=32, train_wall=235, gb_free=8.8, wall=75181
2022-03-07 09:56:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 09:57:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:57:44 | INFO | valid | epoch 560 | valid on 'valid' subset | loss 13.42 | nll_loss 12.82 | ppl 7229.79 | wps 41531.4 | wpb 510.9 | bsz 1 | num_updates 27246 | best_loss 8.937
2022-03-07 09:57:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 27246 updates
2022-03-07 09:57:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:57:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 09:57:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 560 @ 27246 updates, score 13.42) (writing took 2.3862269511446357 seconds)
2022-03-07 09:57:46 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)
2022-03-07 09:57:46 | INFO | train | epoch 560 | loss 2.076 | nll_loss 0.313 | ppl 1.24 | wps 23001.4 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 27246 | lr 0.000191579 | gnorm 0.391 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75311
2022-03-07 09:57:46 | INFO | fairseq.trainer | begin training epoch 561
2022-03-07 09:57:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 09:59:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 09:59:59 | INFO | valid | epoch 561 | valid on 'valid' subset | loss 13.356 | nll_loss 12.756 | ppl 6918.02 | wps 41572.3 | wpb 510.9 | bsz 1 | num_updates 27295 | best_loss 8.937
2022-03-07 09:59:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 27295 updates
2022-03-07 09:59:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:00:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:00:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 561 @ 27295 updates, score 13.356) (writing took 2.314877673983574 seconds)
2022-03-07 10:00:01 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)
2022-03-07 10:00:01 | INFO | train | epoch 561 | loss 2.077 | nll_loss 0.314 | ppl 1.24 | wps 23562.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27295 | lr 0.000191407 | gnorm 0.392 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75446
2022-03-07 10:00:01 | INFO | fairseq.trainer | begin training epoch 562
2022-03-07 10:00:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:00:15 | INFO | train_inner | epoch 562:      5 / 49 loss=2.077, nll_loss=0.314, ppl=1.24, wps=23315.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27300, lr=0.00019139, gnorm=0.392, loss_scale=32, train_wall=237, gb_free=8.8, wall=75459
2022-03-07 10:02:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:02:14 | INFO | valid | epoch 562 | valid on 'valid' subset | loss 13.313 | nll_loss 12.709 | ppl 6696.86 | wps 42462.1 | wpb 510.9 | bsz 1 | num_updates 27344 | best_loss 8.937
2022-03-07 10:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 27344 updates
2022-03-07 10:02:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:02:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 562 @ 27344 updates, score 13.313) (writing took 2.4511386738158762 seconds)
2022-03-07 10:02:16 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)
2022-03-07 10:02:16 | INFO | train | epoch 562 | loss 2.076 | nll_loss 0.313 | ppl 1.24 | wps 23470.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27344 | lr 0.000191236 | gnorm 0.391 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 75581
2022-03-07 10:02:16 | INFO | fairseq.trainer | begin training epoch 563
2022-03-07 10:02:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:02:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:04:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:04:28 | INFO | valid | epoch 563 | valid on 'valid' subset | loss 13.399 | nll_loss 12.799 | ppl 7127.83 | wps 43016.6 | wpb 510.9 | bsz 1 | num_updates 27392 | best_loss 8.937
2022-03-07 10:04:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 27392 updates
2022-03-07 10:04:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:04:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:04:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 563 @ 27392 updates, score 13.399) (writing took 2.3477425980381668 seconds)
2022-03-07 10:04:30 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)
2022-03-07 10:04:30 | INFO | train | epoch 563 | loss 2.076 | nll_loss 0.313 | ppl 1.24 | wps 23284.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27392 | lr 0.000191068 | gnorm 0.396 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 75715
2022-03-07 10:04:30 | INFO | fairseq.trainer | begin training epoch 564
2022-03-07 10:04:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:04:51 | INFO | train_inner | epoch 564:      8 / 49 loss=2.076, nll_loss=0.313, ppl=1.24, wps=23480.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27400, lr=0.00019104, gnorm=0.393, loss_scale=32, train_wall=236, gb_free=8.8, wall=75736
2022-03-07 10:06:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:06:40 | INFO | valid | epoch 564 | valid on 'valid' subset | loss 13.491 | nll_loss 12.903 | ppl 7661.01 | wps 42412.3 | wpb 510.9 | bsz 1 | num_updates 27441 | best_loss 8.937
2022-03-07 10:06:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 27441 updates
2022-03-07 10:06:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:06:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:06:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 564 @ 27441 updates, score 13.491) (writing took 2.3811853183433414 seconds)
2022-03-07 10:06:43 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)
2022-03-07 10:06:43 | INFO | train | epoch 564 | loss 2.075 | nll_loss 0.312 | ppl 1.24 | wps 23947.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27441 | lr 0.000190897 | gnorm 0.386 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 75848
2022-03-07 10:06:43 | INFO | fairseq.trainer | begin training epoch 565
2022-03-07 10:06:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:08:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:08:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:08:53 | INFO | valid | epoch 565 | valid on 'valid' subset | loss 13.34 | nll_loss 12.737 | ppl 6825.77 | wps 43218.1 | wpb 510.9 | bsz 1 | num_updates 27489 | best_loss 8.937
2022-03-07 10:08:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 27489 updates
2022-03-07 10:08:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:08:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:08:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 565 @ 27489 updates, score 13.34) (writing took 2.276620627846569 seconds)
2022-03-07 10:08:55 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)
2022-03-07 10:08:55 | INFO | train | epoch 565 | loss 2.075 | nll_loss 0.312 | ppl 1.24 | wps 23508.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27489 | lr 0.000190731 | gnorm 0.387 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 75980
2022-03-07 10:08:55 | INFO | fairseq.trainer | begin training epoch 566
2022-03-07 10:08:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:09:24 | INFO | train_inner | epoch 566:     11 / 49 loss=2.075, nll_loss=0.312, ppl=1.24, wps=23756.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=27500, lr=0.000190693, gnorm=0.386, loss_scale=32, train_wall=233, gb_free=8.8, wall=76009
2022-03-07 10:11:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:11:06 | INFO | valid | epoch 566 | valid on 'valid' subset | loss 13.493 | nll_loss 12.903 | ppl 7659.53 | wps 41656.4 | wpb 510.9 | bsz 1 | num_updates 27538 | best_loss 8.937
2022-03-07 10:11:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 27538 updates
2022-03-07 10:11:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:11:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:11:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 566 @ 27538 updates, score 13.493) (writing took 2.3408636529929936 seconds)
2022-03-07 10:11:08 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)
2022-03-07 10:11:08 | INFO | train | epoch 566 | loss 2.075 | nll_loss 0.312 | ppl 1.24 | wps 23892 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27538 | lr 0.000190561 | gnorm 0.381 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 76113
2022-03-07 10:11:08 | INFO | fairseq.trainer | begin training epoch 567
2022-03-07 10:11:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:13:19 | INFO | valid | epoch 567 | valid on 'valid' subset | loss 13.415 | nll_loss 12.823 | ppl 7245.92 | wps 42492.7 | wpb 510.9 | bsz 1 | num_updates 27587 | best_loss 8.937
2022-03-07 10:13:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 27587 updates
2022-03-07 10:13:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:13:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:13:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 567 @ 27587 updates, score 13.415) (writing took 2.3918803087435663 seconds)
2022-03-07 10:13:21 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)
2022-03-07 10:13:21 | INFO | train | epoch 567 | loss 2.075 | nll_loss 0.312 | ppl 1.24 | wps 23893.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27587 | lr 0.000190392 | gnorm 0.393 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 76246
2022-03-07 10:13:21 | INFO | fairseq.trainer | begin training epoch 568
2022-03-07 10:13:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:13:55 | INFO | train_inner | epoch 568:     13 / 49 loss=2.075, nll_loss=0.312, ppl=1.24, wps=23936.8, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=27600, lr=0.000190347, gnorm=0.387, loss_scale=32, train_wall=231, gb_free=8.8, wall=76280
2022-03-07 10:14:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:15:32 | INFO | valid | epoch 568 | valid on 'valid' subset | loss 13.333 | nll_loss 12.729 | ppl 6787.3 | wps 41963 | wpb 510.9 | bsz 1 | num_updates 27635 | best_loss 8.937
2022-03-07 10:15:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 27635 updates
2022-03-07 10:15:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 568 @ 27635 updates, score 13.333) (writing took 2.3910456760786474 seconds)
2022-03-07 10:15:34 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)
2022-03-07 10:15:34 | INFO | train | epoch 568 | loss 2.074 | nll_loss 0.311 | ppl 1.24 | wps 23445.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27635 | lr 0.000190226 | gnorm 0.383 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 76379
2022-03-07 10:15:34 | INFO | fairseq.trainer | begin training epoch 569
2022-03-07 10:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:17:46 | INFO | valid | epoch 569 | valid on 'valid' subset | loss 13.346 | nll_loss 12.75 | ppl 6889.55 | wps 41276.7 | wpb 510.9 | bsz 1 | num_updates 27684 | best_loss 8.937
2022-03-07 10:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 27684 updates
2022-03-07 10:17:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:17:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:17:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 569 @ 27684 updates, score 13.346) (writing took 2.3546197381801903 seconds)
2022-03-07 10:17:48 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)
2022-03-07 10:17:48 | INFO | train | epoch 569 | loss 2.075 | nll_loss 0.312 | ppl 1.24 | wps 23747.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 27684 | lr 0.000190058 | gnorm 0.388 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 76513
2022-03-07 10:17:48 | INFO | fairseq.trainer | begin training epoch 570
2022-03-07 10:17:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:18:30 | INFO | train_inner | epoch 570:     16 / 49 loss=2.074, nll_loss=0.312, ppl=1.24, wps=23566.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=27700, lr=0.000190003, gnorm=0.385, loss_scale=32, train_wall=234, gb_free=8.8, wall=76555
2022-03-07 10:19:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:20:01 | INFO | valid | epoch 570 | valid on 'valid' subset | loss 13.405 | nll_loss 12.811 | ppl 7184.53 | wps 41518.2 | wpb 510.9 | bsz 1 | num_updates 27733 | best_loss 8.937
2022-03-07 10:20:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 27733 updates
2022-03-07 10:20:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:20:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:20:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 570 @ 27733 updates, score 13.405) (writing took 2.338000150863081 seconds)
2022-03-07 10:20:03 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)
2022-03-07 10:20:03 | INFO | train | epoch 570 | loss 2.073 | nll_loss 0.311 | ppl 1.24 | wps 23509.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27733 | lr 0.00018989 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 76648
2022-03-07 10:20:03 | INFO | fairseq.trainer | begin training epoch 571
2022-03-07 10:20:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:20:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:22:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:22:16 | INFO | valid | epoch 571 | valid on 'valid' subset | loss 13.432 | nll_loss 12.833 | ppl 7298.9 | wps 40480.5 | wpb 510.9 | bsz 1 | num_updates 27781 | best_loss 8.937
2022-03-07 10:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 27781 updates
2022-03-07 10:22:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:22:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:22:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 571 @ 27781 updates, score 13.432) (writing took 2.4715461200103164 seconds)
2022-03-07 10:22:18 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)
2022-03-07 10:22:18 | INFO | train | epoch 571 | loss 2.074 | nll_loss 0.312 | ppl 1.24 | wps 22984.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 27781 | lr 0.000189726 | gnorm 0.387 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 76783
2022-03-07 10:22:18 | INFO | fairseq.trainer | begin training epoch 572
2022-03-07 10:22:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:23:08 | INFO | train_inner | epoch 572:     19 / 49 loss=2.074, nll_loss=0.311, ppl=1.24, wps=23320, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=27800, lr=0.000189661, gnorm=0.385, loss_scale=32, train_wall=237, gb_free=8.8, wall=76833
2022-03-07 10:24:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:24:31 | INFO | valid | epoch 572 | valid on 'valid' subset | loss 13.409 | nll_loss 12.811 | ppl 7186.94 | wps 40670.9 | wpb 510.9 | bsz 1 | num_updates 27830 | best_loss 8.937
2022-03-07 10:24:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 27830 updates
2022-03-07 10:24:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:24:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 572 @ 27830 updates, score 13.409) (writing took 2.451420283410698 seconds)
2022-03-07 10:24:34 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)
2022-03-07 10:24:34 | INFO | train | epoch 572 | loss 2.074 | nll_loss 0.311 | ppl 1.24 | wps 23481.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27830 | lr 0.000189559 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 76919
2022-03-07 10:24:34 | INFO | fairseq.trainer | begin training epoch 573
2022-03-07 10:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:26:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:26:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:26:47 | INFO | valid | epoch 573 | valid on 'valid' subset | loss 13.45 | nll_loss 12.857 | ppl 7416.56 | wps 41275.6 | wpb 510.9 | bsz 1 | num_updates 27878 | best_loss 8.937
2022-03-07 10:26:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 27878 updates
2022-03-07 10:26:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:26:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:26:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 573 @ 27878 updates, score 13.45) (writing took 2.4273859160020947 seconds)
2022-03-07 10:26:49 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)
2022-03-07 10:26:49 | INFO | train | epoch 573 | loss 2.073 | nll_loss 0.311 | ppl 1.24 | wps 23030.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 27878 | lr 0.000189395 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77054
2022-03-07 10:26:49 | INFO | fairseq.trainer | begin training epoch 574
2022-03-07 10:26:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:27:47 | INFO | train_inner | epoch 574:     22 / 49 loss=2.073, nll_loss=0.311, ppl=1.24, wps=23281.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=27900, lr=0.000189321, gnorm=0.385, loss_scale=32, train_wall=237, gb_free=8.8, wall=77112
2022-03-07 10:28:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:29:02 | INFO | valid | epoch 574 | valid on 'valid' subset | loss 13.43 | nll_loss 12.835 | ppl 7307.14 | wps 41465.3 | wpb 510.9 | bsz 1 | num_updates 27927 | best_loss 8.937
2022-03-07 10:29:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 27927 updates
2022-03-07 10:29:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:29:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 574 @ 27927 updates, score 13.43) (writing took 2.3826898229308426 seconds)
2022-03-07 10:29:04 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)
2022-03-07 10:29:04 | INFO | train | epoch 574 | loss 2.072 | nll_loss 0.31 | ppl 1.24 | wps 23507.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27927 | lr 0.000189229 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77189
2022-03-07 10:29:04 | INFO | fairseq.trainer | begin training epoch 575
2022-03-07 10:29:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:31:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:31:17 | INFO | valid | epoch 575 | valid on 'valid' subset | loss 13.335 | nll_loss 12.737 | ppl 6829.19 | wps 42013.9 | wpb 510.9 | bsz 1 | num_updates 27976 | best_loss 8.937
2022-03-07 10:31:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 27976 updates
2022-03-07 10:31:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:31:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:31:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 575 @ 27976 updates, score 13.335) (writing took 2.5438431911170483 seconds)
2022-03-07 10:31:19 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)
2022-03-07 10:31:19 | INFO | train | epoch 575 | loss 2.072 | nll_loss 0.311 | ppl 1.24 | wps 23492.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 27976 | lr 0.000189063 | gnorm 0.382 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77324
2022-03-07 10:31:19 | INFO | fairseq.trainer | begin training epoch 576
2022-03-07 10:31:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:32:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:32:25 | INFO | train_inner | epoch 576:     25 / 49 loss=2.072, nll_loss=0.31, ppl=1.24, wps=23306.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28000, lr=0.000188982, gnorm=0.383, loss_scale=32, train_wall=237, gb_free=8.8, wall=77390
2022-03-07 10:33:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:33:32 | INFO | valid | epoch 576 | valid on 'valid' subset | loss 13.402 | nll_loss 12.805 | ppl 7158.18 | wps 41257.6 | wpb 510.9 | bsz 1 | num_updates 28024 | best_loss 8.937
2022-03-07 10:33:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 28024 updates
2022-03-07 10:33:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:33:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:33:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 576 @ 28024 updates, score 13.402) (writing took 2.494649402331561 seconds)
2022-03-07 10:33:35 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)
2022-03-07 10:33:35 | INFO | train | epoch 576 | loss 2.072 | nll_loss 0.31 | ppl 1.24 | wps 22974.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 28024 | lr 0.000188901 | gnorm 0.389 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77460
2022-03-07 10:33:35 | INFO | fairseq.trainer | begin training epoch 577
2022-03-07 10:33:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:35:48 | INFO | valid | epoch 577 | valid on 'valid' subset | loss 13.476 | nll_loss 12.887 | ppl 7574.38 | wps 41426.6 | wpb 510.9 | bsz 1 | num_updates 28073 | best_loss 8.937
2022-03-07 10:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 28073 updates
2022-03-07 10:35:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 577 @ 28073 updates, score 13.476) (writing took 2.4121874920092523 seconds)
2022-03-07 10:35:50 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)
2022-03-07 10:35:50 | INFO | train | epoch 577 | loss 2.072 | nll_loss 0.31 | ppl 1.24 | wps 23487 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28073 | lr 0.000188736 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77595
2022-03-07 10:35:50 | INFO | fairseq.trainer | begin training epoch 578
2022-03-07 10:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:37:01 | INFO | train_inner | epoch 578:     27 / 49 loss=2.072, nll_loss=0.31, ppl=1.24, wps=23510.7, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=28100, lr=0.000188646, gnorm=0.388, loss_scale=32, train_wall=235, gb_free=8.8, wall=77666
2022-03-07 10:37:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:38:03 | INFO | valid | epoch 578 | valid on 'valid' subset | loss 13.314 | nll_loss 12.711 | ppl 6703.66 | wps 40729 | wpb 510.9 | bsz 1 | num_updates 28122 | best_loss 8.937
2022-03-07 10:38:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 28122 updates
2022-03-07 10:38:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:38:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:38:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 578 @ 28122 updates, score 13.314) (writing took 2.3370918789878488 seconds)
2022-03-07 10:38:05 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)
2022-03-07 10:38:05 | INFO | train | epoch 578 | loss 2.072 | nll_loss 0.31 | ppl 1.24 | wps 23502.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28122 | lr 0.000188572 | gnorm 0.388 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77730
2022-03-07 10:38:05 | INFO | fairseq.trainer | begin training epoch 579
2022-03-07 10:38:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:38:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:40:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:40:18 | INFO | valid | epoch 579 | valid on 'valid' subset | loss 13.408 | nll_loss 12.816 | ppl 7212.06 | wps 41298.9 | wpb 510.9 | bsz 1 | num_updates 28170 | best_loss 8.937
2022-03-07 10:40:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 28170 updates
2022-03-07 10:40:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:40:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:40:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 579 @ 28170 updates, score 13.408) (writing took 2.6763760643079877 seconds)
2022-03-07 10:40:21 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)
2022-03-07 10:40:21 | INFO | train | epoch 579 | loss 2.072 | nll_loss 0.31 | ppl 1.24 | wps 22998.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 28170 | lr 0.000188411 | gnorm 0.39 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 77866
2022-03-07 10:40:21 | INFO | fairseq.trainer | begin training epoch 580
2022-03-07 10:40:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:41:39 | INFO | train_inner | epoch 580:     30 / 49 loss=2.071, nll_loss=0.31, ppl=1.24, wps=23365, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=28200, lr=0.000188311, gnorm=0.388, loss_scale=32, train_wall=236, gb_free=8.8, wall=77944
2022-03-07 10:42:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:42:32 | INFO | valid | epoch 580 | valid on 'valid' subset | loss 13.476 | nll_loss 12.888 | ppl 7581.36 | wps 42534.9 | wpb 510.9 | bsz 1 | num_updates 28219 | best_loss 8.937
2022-03-07 10:42:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 28219 updates
2022-03-07 10:42:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:42:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:42:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 580 @ 28219 updates, score 13.476) (writing took 2.51370047358796 seconds)
2022-03-07 10:42:34 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)
2022-03-07 10:42:34 | INFO | train | epoch 580 | loss 2.071 | nll_loss 0.309 | ppl 1.24 | wps 23827.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28219 | lr 0.000188247 | gnorm 0.38 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 77999
2022-03-07 10:42:34 | INFO | fairseq.trainer | begin training epoch 581
2022-03-07 10:42:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:44:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:44:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:44:46 | INFO | valid | epoch 581 | valid on 'valid' subset | loss 13.446 | nll_loss 12.85 | ppl 7380.49 | wps 40880.3 | wpb 510.9 | bsz 1 | num_updates 28267 | best_loss 8.937
2022-03-07 10:44:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 28267 updates
2022-03-07 10:44:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:44:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:44:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 581 @ 28267 updates, score 13.446) (writing took 2.4830756820738316 seconds)
2022-03-07 10:44:48 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)
2022-03-07 10:44:48 | INFO | train | epoch 581 | loss 2.071 | nll_loss 0.309 | ppl 1.24 | wps 23256.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28267 | lr 0.000188088 | gnorm 0.389 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 78133
2022-03-07 10:44:48 | INFO | fairseq.trainer | begin training epoch 582
2022-03-07 10:44:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:46:15 | INFO | train_inner | epoch 582:     33 / 49 loss=2.071, nll_loss=0.309, ppl=1.24, wps=23532, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28300, lr=0.000187978, gnorm=0.386, loss_scale=32, train_wall=235, gb_free=8.8, wall=78219
2022-03-07 10:46:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:47:01 | INFO | valid | epoch 582 | valid on 'valid' subset | loss 13.346 | nll_loss 12.749 | ppl 6881.87 | wps 41954.3 | wpb 510.9 | bsz 1 | num_updates 28316 | best_loss 8.937
2022-03-07 10:47:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 28316 updates
2022-03-07 10:47:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:47:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:47:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 582 @ 28316 updates, score 13.346) (writing took 2.556128269061446 seconds)
2022-03-07 10:47:03 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)
2022-03-07 10:47:03 | INFO | train | epoch 582 | loss 2.07 | nll_loss 0.309 | ppl 1.24 | wps 23523.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28316 | lr 0.000187925 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78268
2022-03-07 10:47:03 | INFO | fairseq.trainer | begin training epoch 583
2022-03-07 10:47:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:49:16 | INFO | valid | epoch 583 | valid on 'valid' subset | loss 13.356 | nll_loss 12.759 | ppl 6930.08 | wps 41513.9 | wpb 510.9 | bsz 1 | num_updates 28365 | best_loss 8.937
2022-03-07 10:49:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 28365 updates
2022-03-07 10:49:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:49:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 583 @ 28365 updates, score 13.356) (writing took 2.332127940375358 seconds)
2022-03-07 10:49:18 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)
2022-03-07 10:49:18 | INFO | train | epoch 583 | loss 2.07 | nll_loss 0.309 | ppl 1.24 | wps 23573.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28365 | lr 0.000187762 | gnorm 0.39 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78403
2022-03-07 10:49:18 | INFO | fairseq.trainer | begin training epoch 584
2022-03-07 10:49:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:50:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:50:52 | INFO | train_inner | epoch 584:     36 / 49 loss=2.07, nll_loss=0.309, ppl=1.24, wps=23355, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=28400, lr=0.000187647, gnorm=0.39, loss_scale=32, train_wall=237, gb_free=8.8, wall=78497
2022-03-07 10:51:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:51:30 | INFO | valid | epoch 584 | valid on 'valid' subset | loss 13.415 | nll_loss 12.822 | ppl 7242.21 | wps 41516 | wpb 510.9 | bsz 1 | num_updates 28413 | best_loss 8.937
2022-03-07 10:51:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 28413 updates
2022-03-07 10:51:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:51:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:51:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 584 @ 28413 updates, score 13.415) (writing took 2.49794437084347 seconds)
2022-03-07 10:51:33 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)
2022-03-07 10:51:33 | INFO | train | epoch 584 | loss 2.07 | nll_loss 0.309 | ppl 1.24 | wps 23058.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28413 | lr 0.000187604 | gnorm 0.39 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78538
2022-03-07 10:51:33 | INFO | fairseq.trainer | begin training epoch 585
2022-03-07 10:51:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:53:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:53:46 | INFO | valid | epoch 585 | valid on 'valid' subset | loss 13.459 | nll_loss 12.866 | ppl 7464.89 | wps 40705.2 | wpb 510.9 | bsz 1 | num_updates 28462 | best_loss 8.937
2022-03-07 10:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 28462 updates
2022-03-07 10:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 585 @ 28462 updates, score 13.459) (writing took 2.621994097251445 seconds)
2022-03-07 10:53:48 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)
2022-03-07 10:53:48 | INFO | train | epoch 585 | loss 2.07 | nll_loss 0.309 | ppl 1.24 | wps 23441.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28462 | lr 0.000187442 | gnorm 0.384 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78673
2022-03-07 10:53:48 | INFO | fairseq.trainer | begin training epoch 586
2022-03-07 10:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:55:28 | INFO | train_inner | epoch 586:     38 / 49 loss=2.069, nll_loss=0.308, ppl=1.24, wps=23533.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=28500, lr=0.000187317, gnorm=0.382, loss_scale=32, train_wall=235, gb_free=8.8, wall=78773
2022-03-07 10:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:56:01 | INFO | valid | epoch 586 | valid on 'valid' subset | loss 13.418 | nll_loss 12.825 | ppl 7253.77 | wps 41109.2 | wpb 510.9 | bsz 1 | num_updates 28511 | best_loss 8.937
2022-03-07 10:56:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 28511 updates
2022-03-07 10:56:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:56:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:56:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 586 @ 28511 updates, score 13.418) (writing took 2.389488069806248 seconds)
2022-03-07 10:56:03 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)
2022-03-07 10:56:03 | INFO | train | epoch 586 | loss 2.069 | nll_loss 0.308 | ppl 1.24 | wps 23546.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28511 | lr 0.000187281 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78808
2022-03-07 10:56:03 | INFO | fairseq.trainer | begin training epoch 587
2022-03-07 10:56:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 10:57:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 10:58:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 10:58:16 | INFO | valid | epoch 587 | valid on 'valid' subset | loss 13.452 | nll_loss 12.857 | ppl 7419.45 | wps 41148 | wpb 510.9 | bsz 1 | num_updates 28559 | best_loss 8.937
2022-03-07 10:58:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 28559 updates
2022-03-07 10:58:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:58:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 10:58:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 587 @ 28559 updates, score 13.452) (writing took 2.509663171134889 seconds)
2022-03-07 10:58:18 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)
2022-03-07 10:58:18 | INFO | train | epoch 587 | loss 2.07 | nll_loss 0.309 | ppl 1.24 | wps 23059.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28559 | lr 0.000187124 | gnorm 0.386 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 78943
2022-03-07 10:58:18 | INFO | fairseq.trainer | begin training epoch 588
2022-03-07 10:58:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:00:06 | INFO | train_inner | epoch 588:     41 / 49 loss=2.069, nll_loss=0.308, ppl=1.24, wps=23320.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28600, lr=0.000186989, gnorm=0.383, loss_scale=32, train_wall=237, gb_free=8.8, wall=79051
2022-03-07 11:00:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:00:31 | INFO | valid | epoch 588 | valid on 'valid' subset | loss 13.474 | nll_loss 12.888 | ppl 7579.16 | wps 41256.9 | wpb 510.9 | bsz 1 | num_updates 28608 | best_loss 8.937
2022-03-07 11:00:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 28608 updates
2022-03-07 11:00:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:00:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:00:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 588 @ 28608 updates, score 13.474) (writing took 2.4901925227604806 seconds)
2022-03-07 11:00:34 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)
2022-03-07 11:00:34 | INFO | train | epoch 588 | loss 2.068 | nll_loss 0.307 | ppl 1.24 | wps 23493.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28608 | lr 0.000186963 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 79078
2022-03-07 11:00:34 | INFO | fairseq.trainer | begin training epoch 589
2022-03-07 11:00:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:02:46 | INFO | valid | epoch 589 | valid on 'valid' subset | loss 13.414 | nll_loss 12.821 | ppl 7234.03 | wps 41561.2 | wpb 510.9 | bsz 1 | num_updates 28657 | best_loss 8.937
2022-03-07 11:02:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 28657 updates
2022-03-07 11:02:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:02:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:02:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 589 @ 28657 updates, score 13.414) (writing took 2.3320719618350267 seconds)
2022-03-07 11:02:49 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)
2022-03-07 11:02:49 | INFO | train | epoch 589 | loss 2.068 | nll_loss 0.307 | ppl 1.24 | wps 23552.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28657 | lr 0.000186803 | gnorm 0.385 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 79213
2022-03-07 11:02:49 | INFO | fairseq.trainer | begin training epoch 590
2022-03-07 11:02:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:03:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:04:44 | INFO | train_inner | epoch 590:     44 / 49 loss=2.068, nll_loss=0.307, ppl=1.24, wps=23358.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=28700, lr=0.000186663, gnorm=0.382, loss_scale=32, train_wall=237, gb_free=8.8, wall=79329
2022-03-07 11:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:05:01 | INFO | valid | epoch 590 | valid on 'valid' subset | loss 13.406 | nll_loss 12.811 | ppl 7183.69 | wps 41601.8 | wpb 510.9 | bsz 1 | num_updates 28705 | best_loss 8.937
2022-03-07 11:05:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 28705 updates
2022-03-07 11:05:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 590 @ 28705 updates, score 13.406) (writing took 2.414664153009653 seconds)
2022-03-07 11:05:03 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)
2022-03-07 11:05:03 | INFO | train | epoch 590 | loss 2.068 | nll_loss 0.307 | ppl 1.24 | wps 23086.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28705 | lr 0.000186647 | gnorm 0.381 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 79348
2022-03-07 11:05:03 | INFO | fairseq.trainer | begin training epoch 591
2022-03-07 11:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:07:15 | INFO | valid | epoch 591 | valid on 'valid' subset | loss 13.386 | nll_loss 12.791 | ppl 7087.54 | wps 43198.8 | wpb 510.9 | bsz 1 | num_updates 28754 | best_loss 8.937
2022-03-07 11:07:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 28754 updates
2022-03-07 11:07:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:07:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:07:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 591 @ 28754 updates, score 13.386) (writing took 2.5544814472086728 seconds)
2022-03-07 11:07:18 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)
2022-03-07 11:07:18 | INFO | train | epoch 591 | loss 2.068 | nll_loss 0.307 | ppl 1.24 | wps 23635.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 28754 | lr 0.000186488 | gnorm 0.379 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 79483
2022-03-07 11:07:18 | INFO | fairseq.trainer | begin training epoch 592
2022-03-07 11:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:09:18 | INFO | train_inner | epoch 592:     46 / 49 loss=2.068, nll_loss=0.307, ppl=1.24, wps=23700.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=28800, lr=0.000186339, gnorm=0.383, loss_scale=64, train_wall=233, gb_free=8.8, wall=79602
2022-03-07 11:09:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:09:29 | INFO | valid | epoch 592 | valid on 'valid' subset | loss 13.395 | nll_loss 12.8 | ppl 7132.1 | wps 42767.2 | wpb 510.9 | bsz 1 | num_updates 28803 | best_loss 8.937
2022-03-07 11:09:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 28803 updates
2022-03-07 11:09:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:09:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:09:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 592 @ 28803 updates, score 13.395) (writing took 2.304824756924063 seconds)
2022-03-07 11:09:31 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)
2022-03-07 11:09:31 | INFO | train | epoch 592 | loss 2.068 | nll_loss 0.307 | ppl 1.24 | wps 23793.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28803 | lr 0.000186329 | gnorm 0.387 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 79616
2022-03-07 11:09:31 | INFO | fairseq.trainer | begin training epoch 593
2022-03-07 11:09:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:09:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:11:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:11:41 | INFO | valid | epoch 593 | valid on 'valid' subset | loss 13.414 | nll_loss 12.822 | ppl 7242.44 | wps 43600.5 | wpb 510.9 | bsz 1 | num_updates 28851 | best_loss 8.937
2022-03-07 11:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 28851 updates
2022-03-07 11:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:11:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:11:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 593 @ 28851 updates, score 13.414) (writing took 2.466080970596522 seconds)
2022-03-07 11:11:44 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)
2022-03-07 11:11:44 | INFO | train | epoch 593 | loss 2.067 | nll_loss 0.306 | ppl 1.24 | wps 23504.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28851 | lr 0.000186174 | gnorm 0.377 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 79749
2022-03-07 11:11:44 | INFO | fairseq.trainer | begin training epoch 594
2022-03-07 11:11:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:13:49 | INFO | train_inner | epoch 594:     49 / 49 loss=2.067, nll_loss=0.307, ppl=1.24, wps=23800, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=28900, lr=0.000186016, gnorm=0.382, loss_scale=32, train_wall=231, gb_free=8.8, wall=79874
2022-03-07 11:13:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:13:54 | INFO | valid | epoch 594 | valid on 'valid' subset | loss 13.48 | nll_loss 12.89 | ppl 7589.77 | wps 43033.9 | wpb 510.9 | bsz 1 | num_updates 28900 | best_loss 8.937
2022-03-07 11:13:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 28900 updates
2022-03-07 11:13:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:13:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:13:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 594 @ 28900 updates, score 13.48) (writing took 2.417445870116353 seconds)
2022-03-07 11:13:56 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)
2022-03-07 11:13:56 | INFO | train | epoch 594 | loss 2.067 | nll_loss 0.307 | ppl 1.24 | wps 23996.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28900 | lr 0.000186016 | gnorm 0.383 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 79881
2022-03-07 11:13:56 | INFO | fairseq.trainer | begin training epoch 595
2022-03-07 11:13:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:15:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:16:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:16:07 | INFO | valid | epoch 595 | valid on 'valid' subset | loss 13.356 | nll_loss 12.763 | ppl 6949.21 | wps 43448.5 | wpb 510.9 | bsz 1 | num_updates 28948 | best_loss 8.937
2022-03-07 11:16:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 28948 updates
2022-03-07 11:16:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:16:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:16:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 595 @ 28948 updates, score 13.356) (writing took 2.3864679588004947 seconds)
2022-03-07 11:16:09 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)
2022-03-07 11:16:09 | INFO | train | epoch 595 | loss 2.067 | nll_loss 0.307 | ppl 1.24 | wps 23476.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 28948 | lr 0.000185862 | gnorm 0.384 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 80014
2022-03-07 11:16:09 | INFO | fairseq.trainer | begin training epoch 596
2022-03-07 11:16:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:18:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:18:19 | INFO | valid | epoch 596 | valid on 'valid' subset | loss 13.348 | nll_loss 12.751 | ppl 6893.29 | wps 42816.5 | wpb 510.9 | bsz 1 | num_updates 28997 | best_loss 8.937
2022-03-07 11:18:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 28997 updates
2022-03-07 11:18:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:18:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:18:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 596 @ 28997 updates, score 13.348) (writing took 2.4455216298811138 seconds)
2022-03-07 11:18:21 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)
2022-03-07 11:18:21 | INFO | train | epoch 596 | loss 2.066 | nll_loss 0.306 | ppl 1.24 | wps 23977.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 28997 | lr 0.000185705 | gnorm 0.383 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 80146
2022-03-07 11:18:21 | INFO | fairseq.trainer | begin training epoch 597
2022-03-07 11:18:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:18:29 | INFO | train_inner | epoch 597:      3 / 49 loss=2.067, nll_loss=0.306, ppl=1.24, wps=23126.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29000, lr=0.000185695, gnorm=0.383, loss_scale=32, train_wall=233, gb_free=8.8, wall=80154
2022-03-07 11:20:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:20:33 | INFO | valid | epoch 597 | valid on 'valid' subset | loss 13.368 | nll_loss 12.768 | ppl 6977.3 | wps 41239.6 | wpb 510.9 | bsz 1 | num_updates 29046 | best_loss 8.937
2022-03-07 11:20:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 29046 updates
2022-03-07 11:20:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:20:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:20:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 597 @ 29046 updates, score 13.368) (writing took 2.4124240619130433 seconds)
2022-03-07 11:20:35 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)
2022-03-07 11:20:35 | INFO | train | epoch 597 | loss 2.066 | nll_loss 0.306 | ppl 1.24 | wps 23743.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29046 | lr 0.000185548 | gnorm 0.378 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 80280
2022-03-07 11:20:35 | INFO | fairseq.trainer | begin training epoch 598
2022-03-07 11:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:21:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:22:48 | INFO | valid | epoch 598 | valid on 'valid' subset | loss 13.274 | nll_loss 12.672 | ppl 6525.09 | wps 41751 | wpb 510.9 | bsz 1 | num_updates 29094 | best_loss 8.937
2022-03-07 11:22:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 29094 updates
2022-03-07 11:22:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:22:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:22:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 598 @ 29094 updates, score 13.274) (writing took 2.410533011890948 seconds)
2022-03-07 11:22:50 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)
2022-03-07 11:22:50 | INFO | train | epoch 598 | loss 2.066 | nll_loss 0.305 | ppl 1.24 | wps 23076.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29094 | lr 0.000185395 | gnorm 0.382 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80415
2022-03-07 11:22:50 | INFO | fairseq.trainer | begin training epoch 599
2022-03-07 11:22:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:23:06 | INFO | train_inner | epoch 599:      6 / 49 loss=2.066, nll_loss=0.306, ppl=1.24, wps=23443, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29100, lr=0.000185376, gnorm=0.38, loss_scale=32, train_wall=236, gb_free=8.8, wall=80431
2022-03-07 11:24:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:25:03 | INFO | valid | epoch 599 | valid on 'valid' subset | loss 13.425 | nll_loss 12.833 | ppl 7296.22 | wps 40116.1 | wpb 510.9 | bsz 1 | num_updates 29143 | best_loss 8.937
2022-03-07 11:25:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 29143 updates
2022-03-07 11:25:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:25:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:25:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 599 @ 29143 updates, score 13.425) (writing took 2.519023286178708 seconds)
2022-03-07 11:25:05 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)
2022-03-07 11:25:05 | INFO | train | epoch 599 | loss 2.065 | nll_loss 0.305 | ppl 1.24 | wps 23521.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29143 | lr 0.000185239 | gnorm 0.384 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80550
2022-03-07 11:25:05 | INFO | fairseq.trainer | begin training epoch 600
2022-03-07 11:25:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:27:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:27:18 | INFO | valid | epoch 600 | valid on 'valid' subset | loss 13.406 | nll_loss 12.809 | ppl 7174.22 | wps 42099.3 | wpb 510.9 | bsz 1 | num_updates 29192 | best_loss 8.937
2022-03-07 11:27:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 29192 updates
2022-03-07 11:27:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:27:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:27:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 600 @ 29192 updates, score 13.406) (writing took 2.5118037913925946 seconds)
2022-03-07 11:27:20 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)
2022-03-07 11:27:20 | INFO | train | epoch 600 | loss 2.066 | nll_loss 0.306 | ppl 1.24 | wps 23540.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29192 | lr 0.000185084 | gnorm 0.382 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80685
2022-03-07 11:27:20 | INFO | fairseq.trainer | begin training epoch 601
2022-03-07 11:27:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:27:41 | INFO | train_inner | epoch 601:      8 / 49 loss=2.066, nll_loss=0.306, ppl=1.24, wps=23564.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=29200, lr=0.000185058, gnorm=0.383, loss_scale=64, train_wall=234, gb_free=8.8, wall=80706
2022-03-07 11:29:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:29:33 | INFO | valid | epoch 601 | valid on 'valid' subset | loss 13.305 | nll_loss 12.702 | ppl 6664.43 | wps 43103 | wpb 510.9 | bsz 1 | num_updates 29240 | best_loss 8.937
2022-03-07 11:29:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 29240 updates
2022-03-07 11:29:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:29:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 601 @ 29240 updates, score 13.305) (writing took 2.3442618511617184 seconds)
2022-03-07 11:29:35 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)
2022-03-07 11:29:35 | INFO | train | epoch 601 | loss 2.065 | nll_loss 0.305 | ppl 1.24 | wps 23133.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29240 | lr 0.000184932 | gnorm 0.378 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80820
2022-03-07 11:29:35 | INFO | fairseq.trainer | begin training epoch 602
2022-03-07 11:29:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:31:47 | INFO | valid | epoch 602 | valid on 'valid' subset | loss 13.408 | nll_loss 12.811 | ppl 7186.75 | wps 41896.7 | wpb 510.9 | bsz 1 | num_updates 29289 | best_loss 8.937
2022-03-07 11:31:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 29289 updates
2022-03-07 11:31:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:31:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:31:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 602 @ 29289 updates, score 13.408) (writing took 2.451705066021532 seconds)
2022-03-07 11:31:50 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)
2022-03-07 11:31:50 | INFO | train | epoch 602 | loss 2.065 | nll_loss 0.306 | ppl 1.24 | wps 23530 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29289 | lr 0.000184777 | gnorm 0.382 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 80955
2022-03-07 11:31:50 | INFO | fairseq.trainer | begin training epoch 603
2022-03-07 11:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:32:19 | INFO | train_inner | epoch 603:     11 / 49 loss=2.064, nll_loss=0.305, ppl=1.24, wps=23375.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=29300, lr=0.000184742, gnorm=0.379, loss_scale=32, train_wall=237, gb_free=8.8, wall=80984
2022-03-07 11:33:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:34:03 | INFO | valid | epoch 603 | valid on 'valid' subset | loss 13.428 | nll_loss 12.835 | ppl 7307.06 | wps 41824.7 | wpb 510.9 | bsz 1 | num_updates 29338 | best_loss 8.937
2022-03-07 11:34:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 29338 updates
2022-03-07 11:34:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:34:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 603 @ 29338 updates, score 13.428) (writing took 2.4197987522929907 seconds)
2022-03-07 11:34:05 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)
2022-03-07 11:34:05 | INFO | train | epoch 603 | loss 2.065 | nll_loss 0.305 | ppl 1.24 | wps 23529.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29338 | lr 0.000184623 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81090
2022-03-07 11:34:05 | INFO | fairseq.trainer | begin training epoch 604
2022-03-07 11:34:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:35:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:36:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:36:18 | INFO | valid | epoch 604 | valid on 'valid' subset | loss 13.448 | nll_loss 12.86 | ppl 7434.91 | wps 41505 | wpb 510.9 | bsz 1 | num_updates 29386 | best_loss 8.937
2022-03-07 11:36:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 29386 updates
2022-03-07 11:36:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:36:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:36:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 604 @ 29386 updates, score 13.448) (writing took 2.549536442384124 seconds)
2022-03-07 11:36:20 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)
2022-03-07 11:36:20 | INFO | train | epoch 604 | loss 2.064 | nll_loss 0.304 | ppl 1.23 | wps 23018.9 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 29386 | lr 0.000184472 | gnorm 0.374 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81225
2022-03-07 11:36:20 | INFO | fairseq.trainer | begin training epoch 605
2022-03-07 11:36:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:36:57 | INFO | train_inner | epoch 605:     14 / 49 loss=2.064, nll_loss=0.305, ppl=1.24, wps=23323.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29400, lr=0.000184428, gnorm=0.376, loss_scale=32, train_wall=237, gb_free=8.8, wall=81262
2022-03-07 11:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:38:33 | INFO | valid | epoch 605 | valid on 'valid' subset | loss 13.333 | nll_loss 12.734 | ppl 6810.49 | wps 41104.4 | wpb 510.9 | bsz 1 | num_updates 29435 | best_loss 8.937
2022-03-07 11:38:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 29435 updates
2022-03-07 11:38:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:38:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 605 @ 29435 updates, score 13.333) (writing took 2.4648139718919992 seconds)
2022-03-07 11:38:35 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)
2022-03-07 11:38:35 | INFO | train | epoch 605 | loss 2.064 | nll_loss 0.304 | ppl 1.23 | wps 23558 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29435 | lr 0.000184318 | gnorm 0.381 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81360
2022-03-07 11:38:35 | INFO | fairseq.trainer | begin training epoch 606
2022-03-07 11:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:40:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:40:47 | INFO | valid | epoch 606 | valid on 'valid' subset | loss 13.479 | nll_loss 12.893 | ppl 7603.8 | wps 41264.5 | wpb 510.9 | bsz 1 | num_updates 29484 | best_loss 8.937
2022-03-07 11:40:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 29484 updates
2022-03-07 11:40:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:40:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:40:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 606 @ 29484 updates, score 13.479) (writing took 2.4022173527628183 seconds)
2022-03-07 11:40:50 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)
2022-03-07 11:40:50 | INFO | train | epoch 606 | loss 2.064 | nll_loss 0.304 | ppl 1.23 | wps 23596.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29484 | lr 0.000184165 | gnorm 0.381 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 81495
2022-03-07 11:40:50 | INFO | fairseq.trainer | begin training epoch 607
2022-03-07 11:40:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:41:32 | INFO | train_inner | epoch 607:     16 / 49 loss=2.064, nll_loss=0.304, ppl=1.23, wps=23608.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=29500, lr=0.000184115, gnorm=0.381, loss_scale=64, train_wall=234, gb_free=8.8, wall=81536
2022-03-07 11:41:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:42:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:43:02 | INFO | valid | epoch 607 | valid on 'valid' subset | loss 13.405 | nll_loss 12.808 | ppl 7173.15 | wps 41906.5 | wpb 510.9 | bsz 1 | num_updates 29532 | best_loss 8.937
2022-03-07 11:43:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 29532 updates
2022-03-07 11:43:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:43:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:43:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 607 @ 29532 updates, score 13.405) (writing took 2.385381819680333 seconds)
2022-03-07 11:43:05 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)
2022-03-07 11:43:05 | INFO | train | epoch 607 | loss 2.064 | nll_loss 0.304 | ppl 1.23 | wps 23081.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29532 | lr 0.000184015 | gnorm 0.383 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 81629
2022-03-07 11:43:05 | INFO | fairseq.trainer | begin training epoch 608
2022-03-07 11:43:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:45:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:45:15 | INFO | valid | epoch 608 | valid on 'valid' subset | loss 13.414 | nll_loss 12.822 | ppl 7239.56 | wps 43459.6 | wpb 510.9 | bsz 1 | num_updates 29581 | best_loss 8.937
2022-03-07 11:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 29581 updates
2022-03-07 11:45:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:45:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 608 @ 29581 updates, score 13.414) (writing took 2.5605014679022133 seconds)
2022-03-07 11:45:17 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)
2022-03-07 11:45:17 | INFO | train | epoch 608 | loss 2.063 | nll_loss 0.304 | ppl 1.23 | wps 23960.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29581 | lr 0.000183863 | gnorm 0.385 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 81762
2022-03-07 11:45:17 | INFO | fairseq.trainer | begin training epoch 609
2022-03-07 11:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:46:06 | INFO | train_inner | epoch 609:     19 / 49 loss=2.064, nll_loss=0.304, ppl=1.23, wps=23628.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=29600, lr=0.000183804, gnorm=0.384, loss_scale=32, train_wall=234, gb_free=8.8, wall=81811
2022-03-07 11:47:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:47:27 | INFO | valid | epoch 609 | valid on 'valid' subset | loss 13.444 | nll_loss 12.857 | ppl 7418.49 | wps 42634.2 | wpb 510.9 | bsz 1 | num_updates 29630 | best_loss 8.937
2022-03-07 11:47:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 29630 updates
2022-03-07 11:47:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:47:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:47:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 609 @ 29630 updates, score 13.444) (writing took 2.3770048329606652 seconds)
2022-03-07 11:47:30 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)
2022-03-07 11:47:30 | INFO | train | epoch 609 | loss 2.064 | nll_loss 0.305 | ppl 1.24 | wps 23998.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29630 | lr 0.000183711 | gnorm 0.379 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 81894
2022-03-07 11:47:30 | INFO | fairseq.trainer | begin training epoch 610
2022-03-07 11:47:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:48:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:49:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:49:40 | INFO | valid | epoch 610 | valid on 'valid' subset | loss 13.403 | nll_loss 12.81 | ppl 7180.96 | wps 43556 | wpb 510.9 | bsz 1 | num_updates 29678 | best_loss 8.937
2022-03-07 11:49:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 29678 updates
2022-03-07 11:49:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:49:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:49:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 610 @ 29678 updates, score 13.403) (writing took 2.462244752328843 seconds)
2022-03-07 11:49:42 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)
2022-03-07 11:49:42 | INFO | train | epoch 610 | loss 2.063 | nll_loss 0.304 | ppl 1.23 | wps 23526 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29678 | lr 0.000183562 | gnorm 0.38 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 82027
2022-03-07 11:49:42 | INFO | fairseq.trainer | begin training epoch 611
2022-03-07 11:49:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:50:38 | INFO | train_inner | epoch 611:     22 / 49 loss=2.063, nll_loss=0.304, ppl=1.23, wps=23837.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=29700, lr=0.000183494, gnorm=0.378, loss_scale=32, train_wall=232, gb_free=8.8, wall=82083
2022-03-07 11:51:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:51:52 | INFO | valid | epoch 611 | valid on 'valid' subset | loss 13.404 | nll_loss 12.815 | ppl 7206.9 | wps 42989.9 | wpb 510.9 | bsz 1 | num_updates 29727 | best_loss 8.937
2022-03-07 11:51:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 29727 updates
2022-03-07 11:51:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:51:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:51:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 611 @ 29727 updates, score 13.404) (writing took 2.374054383020848 seconds)
2022-03-07 11:51:54 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)
2022-03-07 11:51:54 | INFO | train | epoch 611 | loss 2.063 | nll_loss 0.303 | ppl 1.23 | wps 24054 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29727 | lr 0.000183411 | gnorm 0.376 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 82159
2022-03-07 11:51:54 | INFO | fairseq.trainer | begin training epoch 612
2022-03-07 11:51:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:53:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 11:53:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:54:04 | INFO | valid | epoch 612 | valid on 'valid' subset | loss 13.421 | nll_loss 12.827 | ppl 7265.98 | wps 43015.3 | wpb 510.9 | bsz 1 | num_updates 29775 | best_loss 8.937
2022-03-07 11:54:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 29775 updates
2022-03-07 11:54:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:54:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 612 @ 29775 updates, score 13.421) (writing took 2.3483919324353337 seconds)
2022-03-07 11:54:06 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)
2022-03-07 11:54:06 | INFO | train | epoch 612 | loss 2.062 | nll_loss 0.304 | ppl 1.23 | wps 23545.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 29775 | lr 0.000183263 | gnorm 0.379 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 82291
2022-03-07 11:54:06 | INFO | fairseq.trainer | begin training epoch 613
2022-03-07 11:54:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:55:11 | INFO | train_inner | epoch 613:     25 / 49 loss=2.062, nll_loss=0.303, ppl=1.23, wps=23820, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=29800, lr=0.000183186, gnorm=0.378, loss_scale=32, train_wall=232, gb_free=8.8, wall=82356
2022-03-07 11:56:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:56:16 | INFO | valid | epoch 613 | valid on 'valid' subset | loss 13.327 | nll_loss 12.73 | ppl 6793.22 | wps 42231.8 | wpb 510.9 | bsz 1 | num_updates 29824 | best_loss 8.937
2022-03-07 11:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 29824 updates
2022-03-07 11:56:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:56:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 613 @ 29824 updates, score 13.327) (writing took 2.5615754569880664 seconds)
2022-03-07 11:56:19 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)
2022-03-07 11:56:19 | INFO | train | epoch 613 | loss 2.062 | nll_loss 0.303 | ppl 1.23 | wps 23972.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 29824 | lr 0.000183112 | gnorm 0.377 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 82424
2022-03-07 11:56:19 | INFO | fairseq.trainer | begin training epoch 614
2022-03-07 11:56:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 11:58:31 | INFO | valid | epoch 614 | valid on 'valid' subset | loss 13.358 | nll_loss 12.762 | ppl 6946.14 | wps 41274.9 | wpb 510.9 | bsz 1 | num_updates 29873 | best_loss 8.937
2022-03-07 11:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 29873 updates
2022-03-07 11:58:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:58:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 11:58:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 614 @ 29873 updates, score 13.358) (writing took 2.4377542259171605 seconds)
2022-03-07 11:58:34 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)
2022-03-07 11:58:34 | INFO | train | epoch 614 | loss 2.062 | nll_loss 0.303 | ppl 1.23 | wps 23588.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29873 | lr 0.000182962 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 82558
2022-03-07 11:58:34 | INFO | fairseq.trainer | begin training epoch 615
2022-03-07 11:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 11:59:45 | INFO | train_inner | epoch 615:     27 / 49 loss=2.062, nll_loss=0.303, ppl=1.23, wps=23647.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=29900, lr=0.000182879, gnorm=0.38, loss_scale=32, train_wall=233, gb_free=8.8, wall=82630
2022-03-07 12:00:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:00:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:00:48 | INFO | valid | epoch 615 | valid on 'valid' subset | loss 13.533 | nll_loss 12.95 | ppl 7910.61 | wps 40364.3 | wpb 510.9 | bsz 1 | num_updates 29921 | best_loss 8.937
2022-03-07 12:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 29921 updates
2022-03-07 12:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:00:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:00:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 615 @ 29921 updates, score 13.533) (writing took 2.324197109322995 seconds)
2022-03-07 12:00:50 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)
2022-03-07 12:00:50 | INFO | train | epoch 615 | loss 2.061 | nll_loss 0.302 | ppl 1.23 | wps 22795.5 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 29921 | lr 0.000182815 | gnorm 0.384 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 82695
2022-03-07 12:00:50 | INFO | fairseq.trainer | begin training epoch 616
2022-03-07 12:00:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:03:04 | INFO | valid | epoch 616 | valid on 'valid' subset | loss 13.379 | nll_loss 12.786 | ppl 7063.22 | wps 40708.9 | wpb 510.9 | bsz 1 | num_updates 29970 | best_loss 8.937
2022-03-07 12:03:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 29970 updates
2022-03-07 12:03:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:03:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:03:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 616 @ 29970 updates, score 13.379) (writing took 2.3196195159107447 seconds)
2022-03-07 12:03:06 | INFO | fairseq_cli.train | end of epoch 616 (average epoch stats below)
2022-03-07 12:03:06 | INFO | train | epoch 616 | loss 2.061 | nll_loss 0.302 | ppl 1.23 | wps 23316 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 29970 | lr 0.000182666 | gnorm 0.375 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 82831
2022-03-07 12:03:06 | INFO | fairseq.trainer | begin training epoch 617
2022-03-07 12:03:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:04:26 | INFO | train_inner | epoch 617:     30 / 49 loss=2.061, nll_loss=0.302, ppl=1.23, wps=23097.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30000, lr=0.000182574, gnorm=0.375, loss_scale=32, train_wall=239, gb_free=8.8, wall=82911
2022-03-07 12:05:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:05:20 | INFO | valid | epoch 617 | valid on 'valid' subset | loss 13.343 | nll_loss 12.743 | ppl 6855.38 | wps 41381.1 | wpb 510.9 | bsz 1 | num_updates 30019 | best_loss 8.937
2022-03-07 12:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 617 @ 30019 updates
2022-03-07 12:05:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:05:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 617 @ 30019 updates, score 13.343) (writing took 2.512356096878648 seconds)
2022-03-07 12:05:23 | INFO | fairseq_cli.train | end of epoch 617 (average epoch stats below)
2022-03-07 12:05:23 | INFO | train | epoch 617 | loss 2.061 | nll_loss 0.302 | ppl 1.23 | wps 23307.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30019 | lr 0.000182516 | gnorm 0.373 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 82968
2022-03-07 12:05:23 | INFO | fairseq.trainer | begin training epoch 618
2022-03-07 12:05:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:07:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:07:37 | INFO | valid | epoch 618 | valid on 'valid' subset | loss 13.391 | nll_loss 12.797 | ppl 7115.54 | wps 39535.8 | wpb 510.9 | bsz 1 | num_updates 30067 | best_loss 8.937
2022-03-07 12:07:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 618 @ 30067 updates
2022-03-07 12:07:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:07:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 618 @ 30067 updates, score 13.391) (writing took 2.58335466356948 seconds)
2022-03-07 12:07:39 | INFO | fairseq_cli.train | end of epoch 618 (average epoch stats below)
2022-03-07 12:07:39 | INFO | train | epoch 618 | loss 2.061 | nll_loss 0.302 | ppl 1.23 | wps 22785.6 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30067 | lr 0.000182371 | gnorm 0.375 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83104
2022-03-07 12:07:39 | INFO | fairseq.trainer | begin training epoch 619
2022-03-07 12:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:09:07 | INFO | train_inner | epoch 619:     33 / 49 loss=2.061, nll_loss=0.302, ppl=1.23, wps=23103.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30100, lr=0.000182271, gnorm=0.375, loss_scale=32, train_wall=239, gb_free=8.8, wall=83191
2022-03-07 12:09:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:09:54 | INFO | valid | epoch 619 | valid on 'valid' subset | loss 13.355 | nll_loss 12.763 | ppl 6949.78 | wps 39968.7 | wpb 510.9 | bsz 1 | num_updates 30116 | best_loss 8.937
2022-03-07 12:09:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 619 @ 30116 updates
2022-03-07 12:09:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:09:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:09:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 619 @ 30116 updates, score 13.355) (writing took 2.4308902621269226 seconds)
2022-03-07 12:09:56 | INFO | fairseq_cli.train | end of epoch 619 (average epoch stats below)
2022-03-07 12:09:56 | INFO | train | epoch 619 | loss 2.061 | nll_loss 0.302 | ppl 1.23 | wps 23240.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30116 | lr 0.000182222 | gnorm 0.377 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83241
2022-03-07 12:09:56 | INFO | fairseq.trainer | begin training epoch 620
2022-03-07 12:09:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:12:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:12:10 | INFO | valid | epoch 620 | valid on 'valid' subset | loss 13.437 | nll_loss 12.845 | ppl 7355.51 | wps 40301.8 | wpb 510.9 | bsz 1 | num_updates 30165 | best_loss 8.937
2022-03-07 12:12:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 620 @ 30165 updates
2022-03-07 12:12:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:12:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:12:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 620 @ 30165 updates, score 13.437) (writing took 2.5559274861589074 seconds)
2022-03-07 12:12:13 | INFO | fairseq_cli.train | end of epoch 620 (average epoch stats below)
2022-03-07 12:12:13 | INFO | train | epoch 620 | loss 2.06 | nll_loss 0.301 | ppl 1.23 | wps 23235.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30165 | lr 0.000182074 | gnorm 0.377 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83378
2022-03-07 12:12:13 | INFO | fairseq.trainer | begin training epoch 621
2022-03-07 12:12:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:13:49 | INFO | train_inner | epoch 621:     36 / 49 loss=2.06, nll_loss=0.301, ppl=1.23, wps=23020.6, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=30200, lr=0.000181969, gnorm=0.376, loss_scale=32, train_wall=240, gb_free=8.8, wall=83473
2022-03-07 12:14:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:14:27 | INFO | valid | epoch 621 | valid on 'valid' subset | loss 13.392 | nll_loss 12.802 | ppl 7141.76 | wps 40508.2 | wpb 510.9 | bsz 1 | num_updates 30213 | best_loss 8.937
2022-03-07 12:14:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 621 @ 30213 updates
2022-03-07 12:14:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:14:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:14:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 621 @ 30213 updates, score 13.392) (writing took 2.5034114979207516 seconds)
2022-03-07 12:14:30 | INFO | fairseq_cli.train | end of epoch 621 (average epoch stats below)
2022-03-07 12:14:30 | INFO | train | epoch 621 | loss 2.059 | nll_loss 0.301 | ppl 1.23 | wps 22749.7 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30213 | lr 0.000181929 | gnorm 0.371 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83514
2022-03-07 12:14:30 | INFO | fairseq.trainer | begin training epoch 622
2022-03-07 12:14:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:16:44 | INFO | valid | epoch 622 | valid on 'valid' subset | loss 13.402 | nll_loss 12.81 | ppl 7182.63 | wps 40807.6 | wpb 510.9 | bsz 1 | num_updates 30262 | best_loss 8.937
2022-03-07 12:16:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 622 @ 30262 updates
2022-03-07 12:16:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:16:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:16:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 622 @ 30262 updates, score 13.402) (writing took 2.442933695856482 seconds)
2022-03-07 12:16:46 | INFO | fairseq_cli.train | end of epoch 622 (average epoch stats below)
2022-03-07 12:16:46 | INFO | train | epoch 622 | loss 2.06 | nll_loss 0.302 | ppl 1.23 | wps 23269.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30262 | lr 0.000181782 | gnorm 0.382 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 83651
2022-03-07 12:16:46 | INFO | fairseq.trainer | begin training epoch 623
2022-03-07 12:16:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:18:27 | INFO | train_inner | epoch 623:     38 / 49 loss=2.06, nll_loss=0.302, ppl=1.23, wps=23280.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30300, lr=0.000181668, gnorm=0.38, loss_scale=32, train_wall=237, gb_free=8.8, wall=83752
2022-03-07 12:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:19:01 | INFO | valid | epoch 623 | valid on 'valid' subset | loss 13.325 | nll_loss 12.731 | ppl 6796.47 | wps 40414.5 | wpb 510.9 | bsz 1 | num_updates 30311 | best_loss 8.937
2022-03-07 12:19:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 623 @ 30311 updates
2022-03-07 12:19:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:19:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:19:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 623 @ 30311 updates, score 13.325) (writing took 2.45419969689101 seconds)
2022-03-07 12:19:03 | INFO | fairseq_cli.train | end of epoch 623 (average epoch stats below)
2022-03-07 12:19:03 | INFO | train | epoch 623 | loss 2.06 | nll_loss 0.302 | ppl 1.23 | wps 23249.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30311 | lr 0.000181635 | gnorm 0.378 | loss_scale 64 | train_wall 116 | gb_free 8.8 | wall 83788
2022-03-07 12:19:03 | INFO | fairseq.trainer | begin training epoch 624
2022-03-07 12:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:19:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:21:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:21:15 | INFO | valid | epoch 624 | valid on 'valid' subset | loss 13.464 | nll_loss 12.878 | ppl 7526.57 | wps 41498.7 | wpb 510.9 | bsz 1 | num_updates 30359 | best_loss 8.937
2022-03-07 12:21:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 624 @ 30359 updates
2022-03-07 12:21:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:21:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:21:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 624 @ 30359 updates, score 13.464) (writing took 2.42267773905769 seconds)
2022-03-07 12:21:18 | INFO | fairseq_cli.train | end of epoch 624 (average epoch stats below)
2022-03-07 12:21:18 | INFO | train | epoch 624 | loss 2.059 | nll_loss 0.301 | ppl 1.23 | wps 23088.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 30359 | lr 0.000181491 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 83923
2022-03-07 12:21:18 | INFO | fairseq.trainer | begin training epoch 625
2022-03-07 12:21:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:23:05 | INFO | train_inner | epoch 625:     41 / 49 loss=2.059, nll_loss=0.301, ppl=1.23, wps=23390.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30400, lr=0.000181369, gnorm=0.376, loss_scale=32, train_wall=236, gb_free=8.8, wall=84029
2022-03-07 12:23:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:23:29 | INFO | valid | epoch 625 | valid on 'valid' subset | loss 13.344 | nll_loss 12.748 | ppl 6879.85 | wps 41652.8 | wpb 510.9 | bsz 1 | num_updates 30408 | best_loss 8.937
2022-03-07 12:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 625 @ 30408 updates
2022-03-07 12:23:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:23:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:23:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 625 @ 30408 updates, score 13.344) (writing took 2.4107526103034616 seconds)
2022-03-07 12:23:32 | INFO | fairseq_cli.train | end of epoch 625 (average epoch stats below)
2022-03-07 12:23:32 | INFO | train | epoch 625 | loss 2.059 | nll_loss 0.301 | ppl 1.23 | wps 23722.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 30408 | lr 0.000181345 | gnorm 0.373 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84057
2022-03-07 12:23:32 | INFO | fairseq.trainer | begin training epoch 626
2022-03-07 12:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:25:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:25:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:25:43 | INFO | valid | epoch 626 | valid on 'valid' subset | loss 13.43 | nll_loss 12.839 | ppl 7328.45 | wps 42337.5 | wpb 510.9 | bsz 1 | num_updates 30456 | best_loss 8.937
2022-03-07 12:25:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 626 @ 30456 updates
2022-03-07 12:25:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:25:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:25:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 626 @ 30456 updates, score 13.43) (writing took 2.460590075701475 seconds)
2022-03-07 12:25:46 | INFO | fairseq_cli.train | end of epoch 626 (average epoch stats below)
2022-03-07 12:25:46 | INFO | train | epoch 626 | loss 2.059 | nll_loss 0.301 | ppl 1.23 | wps 23239.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 30456 | lr 0.000181202 | gnorm 0.382 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84190
2022-03-07 12:25:46 | INFO | fairseq.trainer | begin training epoch 627
2022-03-07 12:25:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:27:40 | INFO | train_inner | epoch 627:     44 / 49 loss=2.059, nll_loss=0.301, ppl=1.23, wps=23549.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30500, lr=0.000181071, gnorm=0.38, loss_scale=32, train_wall=235, gb_free=8.8, wall=84305
2022-03-07 12:27:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:27:57 | INFO | valid | epoch 627 | valid on 'valid' subset | loss 13.383 | nll_loss 12.788 | ppl 7070.59 | wps 41585.5 | wpb 510.9 | bsz 1 | num_updates 30505 | best_loss 8.937
2022-03-07 12:27:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 627 @ 30505 updates
2022-03-07 12:27:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:28:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:28:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 627 @ 30505 updates, score 13.383) (writing took 2.5276487939991057 seconds)
2022-03-07 12:28:00 | INFO | fairseq_cli.train | end of epoch 627 (average epoch stats below)
2022-03-07 12:28:00 | INFO | train | epoch 627 | loss 2.059 | nll_loss 0.3 | ppl 1.23 | wps 23712.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 30505 | lr 0.000181057 | gnorm 0.377 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84325
2022-03-07 12:28:00 | INFO | fairseq.trainer | begin training epoch 628
2022-03-07 12:28:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:30:11 | INFO | valid | epoch 628 | valid on 'valid' subset | loss 13.364 | nll_loss 12.767 | ppl 6971.68 | wps 41697.1 | wpb 510.9 | bsz 1 | num_updates 30554 | best_loss 8.937
2022-03-07 12:30:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 628 @ 30554 updates
2022-03-07 12:30:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:30:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 628 @ 30554 updates, score 13.364) (writing took 2.392796366941184 seconds)
2022-03-07 12:30:14 | INFO | fairseq_cli.train | end of epoch 628 (average epoch stats below)
2022-03-07 12:30:14 | INFO | train | epoch 628 | loss 2.058 | nll_loss 0.3 | ppl 1.23 | wps 23751.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 30554 | lr 0.000180911 | gnorm 0.372 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84458
2022-03-07 12:30:14 | INFO | fairseq.trainer | begin training epoch 629
2022-03-07 12:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:31:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:32:16 | INFO | train_inner | epoch 629:     47 / 49 loss=2.058, nll_loss=0.3, ppl=1.23, wps=23519.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30600, lr=0.000180775, gnorm=0.375, loss_scale=32, train_wall=235, gb_free=8.8, wall=84581
2022-03-07 12:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:32:25 | INFO | valid | epoch 629 | valid on 'valid' subset | loss 13.462 | nll_loss 12.876 | ppl 7518.86 | wps 42449.5 | wpb 510.9 | bsz 1 | num_updates 30602 | best_loss 8.937
2022-03-07 12:32:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 629 @ 30602 updates
2022-03-07 12:32:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 629 @ 30602 updates, score 13.462) (writing took 2.495502312667668 seconds)
2022-03-07 12:32:27 | INFO | fairseq_cli.train | end of epoch 629 (average epoch stats below)
2022-03-07 12:32:27 | INFO | train | epoch 629 | loss 2.058 | nll_loss 0.3 | ppl 1.23 | wps 23256.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 30602 | lr 0.000180769 | gnorm 0.378 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 84592
2022-03-07 12:32:27 | INFO | fairseq.trainer | begin training epoch 630
2022-03-07 12:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:34:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:34:40 | INFO | valid | epoch 630 | valid on 'valid' subset | loss 13.489 | nll_loss 12.905 | ppl 7671.46 | wps 40667.9 | wpb 510.9 | bsz 1 | num_updates 30651 | best_loss 8.937
2022-03-07 12:34:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 630 @ 30651 updates
2022-03-07 12:34:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:34:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:34:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 630 @ 30651 updates, score 13.489) (writing took 2.4036530572921038 seconds)
2022-03-07 12:34:42 | INFO | fairseq_cli.train | end of epoch 630 (average epoch stats below)
2022-03-07 12:34:42 | INFO | train | epoch 630 | loss 2.058 | nll_loss 0.3 | ppl 1.23 | wps 23568.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30651 | lr 0.000180625 | gnorm 0.381 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 84727
2022-03-07 12:34:42 | INFO | fairseq.trainer | begin training epoch 631
2022-03-07 12:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:36:51 | INFO | train_inner | epoch 631:     49 / 49 loss=2.058, nll_loss=0.3, ppl=1.23, wps=23460.8, ups=0.36, wpb=64544.1, bsz=126.1, num_updates=30700, lr=0.000180481, gnorm=0.378, loss_scale=32, train_wall=234, gb_free=8.8, wall=84856
2022-03-07 12:36:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:36:56 | INFO | valid | epoch 631 | valid on 'valid' subset | loss 13.412 | nll_loss 12.818 | ppl 7219.61 | wps 39974.4 | wpb 510.9 | bsz 1 | num_updates 30700 | best_loss 8.937
2022-03-07 12:36:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 631 @ 30700 updates
2022-03-07 12:36:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:36:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:36:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 631 @ 30700 updates, score 13.412) (writing took 2.490391190163791 seconds)
2022-03-07 12:36:59 | INFO | fairseq_cli.train | end of epoch 631 (average epoch stats below)
2022-03-07 12:36:59 | INFO | train | epoch 631 | loss 2.057 | nll_loss 0.3 | ppl 1.23 | wps 23244.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30700 | lr 0.000180481 | gnorm 0.373 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 84864
2022-03-07 12:36:59 | INFO | fairseq.trainer | begin training epoch 632
2022-03-07 12:36:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:37:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:39:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:39:13 | INFO | valid | epoch 632 | valid on 'valid' subset | loss 13.434 | nll_loss 12.844 | ppl 7349.87 | wps 40350.3 | wpb 510.9 | bsz 1 | num_updates 30748 | best_loss 8.937
2022-03-07 12:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 632 @ 30748 updates
2022-03-07 12:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:39:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:39:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 632 @ 30748 updates, score 13.434) (writing took 2.491828480735421 seconds)
2022-03-07 12:39:16 | INFO | fairseq_cli.train | end of epoch 632 (average epoch stats below)
2022-03-07 12:39:16 | INFO | train | epoch 632 | loss 2.057 | nll_loss 0.299 | ppl 1.23 | wps 22722.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30748 | lr 0.00018034 | gnorm 0.373 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 85001
2022-03-07 12:39:16 | INFO | fairseq.trainer | begin training epoch 633
2022-03-07 12:39:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:41:30 | INFO | valid | epoch 633 | valid on 'valid' subset | loss 13.422 | nll_loss 12.834 | ppl 7300.55 | wps 41240 | wpb 510.9 | bsz 1 | num_updates 30797 | best_loss 8.937
2022-03-07 12:41:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 633 @ 30797 updates
2022-03-07 12:41:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:41:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:41:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 633 @ 30797 updates, score 13.422) (writing took 2.4821127681061625 seconds)
2022-03-07 12:41:33 | INFO | fairseq_cli.train | end of epoch 633 (average epoch stats below)
2022-03-07 12:41:33 | INFO | train | epoch 633 | loss 2.057 | nll_loss 0.3 | ppl 1.23 | wps 23261.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30797 | lr 0.000180196 | gnorm 0.376 | loss_scale 32 | train_wall 116 | gb_free 8.8 | wall 85137
2022-03-07 12:41:33 | INFO | fairseq.trainer | begin training epoch 634
2022-03-07 12:41:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:41:41 | INFO | train_inner | epoch 634:      3 / 49 loss=2.057, nll_loss=0.299, ppl=1.23, wps=22400.1, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=30800, lr=0.000180187, gnorm=0.374, loss_scale=32, train_wall=240, gb_free=8.8, wall=85145
2022-03-07 12:43:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:43:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:43:45 | INFO | valid | epoch 634 | valid on 'valid' subset | loss 13.421 | nll_loss 12.833 | ppl 7295.12 | wps 41399.5 | wpb 510.9 | bsz 1 | num_updates 30845 | best_loss 8.937
2022-03-07 12:43:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 634 @ 30845 updates
2022-03-07 12:43:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:43:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:43:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 634 @ 30845 updates, score 13.421) (writing took 2.411412295419723 seconds)
2022-03-07 12:43:48 | INFO | fairseq_cli.train | end of epoch 634 (average epoch stats below)
2022-03-07 12:43:48 | INFO | train | epoch 634 | loss 2.057 | nll_loss 0.299 | ppl 1.23 | wps 23058.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 30845 | lr 0.000180056 | gnorm 0.372 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85272
2022-03-07 12:43:48 | INFO | fairseq.trainer | begin training epoch 635
2022-03-07 12:43:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:45:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:46:00 | INFO | valid | epoch 635 | valid on 'valid' subset | loss 13.409 | nll_loss 12.819 | ppl 7228.53 | wps 41350.7 | wpb 510.9 | bsz 1 | num_updates 30894 | best_loss 8.937
2022-03-07 12:46:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 635 @ 30894 updates
2022-03-07 12:46:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:46:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:46:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 635 @ 30894 updates, score 13.409) (writing took 2.4464833829551935 seconds)
2022-03-07 12:46:03 | INFO | fairseq_cli.train | end of epoch 635 (average epoch stats below)
2022-03-07 12:46:03 | INFO | train | epoch 635 | loss 2.056 | nll_loss 0.299 | ppl 1.23 | wps 23546.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30894 | lr 0.000179913 | gnorm 0.377 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85407
2022-03-07 12:46:03 | INFO | fairseq.trainer | begin training epoch 636
2022-03-07 12:46:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:46:18 | INFO | train_inner | epoch 636:      6 / 49 loss=2.057, nll_loss=0.299, ppl=1.23, wps=23348.8, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=30900, lr=0.000179896, gnorm=0.375, loss_scale=32, train_wall=237, gb_free=8.8, wall=85423
2022-03-07 12:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:48:15 | INFO | valid | epoch 636 | valid on 'valid' subset | loss 13.431 | nll_loss 12.845 | ppl 7356.57 | wps 40058.7 | wpb 510.9 | bsz 1 | num_updates 30943 | best_loss 8.937
2022-03-07 12:48:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 636 @ 30943 updates
2022-03-07 12:48:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:48:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:48:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 636 @ 30943 updates, score 13.431) (writing took 2.637418385129422 seconds)
2022-03-07 12:48:18 | INFO | fairseq_cli.train | end of epoch 636 (average epoch stats below)
2022-03-07 12:48:18 | INFO | train | epoch 636 | loss 2.056 | nll_loss 0.299 | ppl 1.23 | wps 23444 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 30943 | lr 0.000179771 | gnorm 0.373 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85543
2022-03-07 12:48:18 | INFO | fairseq.trainer | begin training epoch 637
2022-03-07 12:48:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:49:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:50:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:50:31 | INFO | valid | epoch 637 | valid on 'valid' subset | loss 13.347 | nll_loss 12.754 | ppl 6909.29 | wps 41376.8 | wpb 510.9 | bsz 1 | num_updates 30991 | best_loss 8.937
2022-03-07 12:50:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 637 @ 30991 updates
2022-03-07 12:50:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:50:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 637 @ 30991 updates, score 13.347) (writing took 2.457731978967786 seconds)
2022-03-07 12:50:33 | INFO | fairseq_cli.train | end of epoch 637 (average epoch stats below)
2022-03-07 12:50:33 | INFO | train | epoch 637 | loss 2.056 | nll_loss 0.299 | ppl 1.23 | wps 23016.8 | ups 0.35 | wpb 64844.1 | bsz 126.7 | num_updates 30991 | lr 0.000179631 | gnorm 0.38 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85678
2022-03-07 12:50:33 | INFO | fairseq.trainer | begin training epoch 638
2022-03-07 12:50:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:50:57 | INFO | train_inner | epoch 638:      9 / 49 loss=2.056, nll_loss=0.299, ppl=1.23, wps=23282.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=31000, lr=0.000179605, gnorm=0.376, loss_scale=32, train_wall=237, gb_free=8.8, wall=85702
2022-03-07 12:52:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:52:46 | INFO | valid | epoch 638 | valid on 'valid' subset | loss 13.435 | nll_loss 12.845 | ppl 7358.07 | wps 41378.9 | wpb 510.9 | bsz 1 | num_updates 31040 | best_loss 8.937
2022-03-07 12:52:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 638 @ 31040 updates
2022-03-07 12:52:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:52:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:52:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 638 @ 31040 updates, score 13.435) (writing took 2.4039104469120502 seconds)
2022-03-07 12:52:49 | INFO | fairseq_cli.train | end of epoch 638 (average epoch stats below)
2022-03-07 12:52:49 | INFO | train | epoch 638 | loss 2.056 | nll_loss 0.299 | ppl 1.23 | wps 23490.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31040 | lr 0.00017949 | gnorm 0.372 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85813
2022-03-07 12:52:49 | INFO | fairseq.trainer | begin training epoch 639
2022-03-07 12:52:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:54:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:55:01 | INFO | valid | epoch 639 | valid on 'valid' subset | loss 13.459 | nll_loss 12.873 | ppl 7500.02 | wps 41695.7 | wpb 510.9 | bsz 1 | num_updates 31089 | best_loss 8.937
2022-03-07 12:55:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 639 @ 31089 updates
2022-03-07 12:55:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:55:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:55:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 639 @ 31089 updates, score 13.459) (writing took 2.3319694879464805 seconds)
2022-03-07 12:55:03 | INFO | fairseq_cli.train | end of epoch 639 (average epoch stats below)
2022-03-07 12:55:03 | INFO | train | epoch 639 | loss 2.055 | nll_loss 0.298 | ppl 1.23 | wps 23600.2 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31089 | lr 0.000179348 | gnorm 0.372 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 85948
2022-03-07 12:55:03 | INFO | fairseq.trainer | begin training epoch 640
2022-03-07 12:55:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:55:32 | INFO | train_inner | epoch 640:     11 / 49 loss=2.056, nll_loss=0.298, ppl=1.23, wps=23583.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=31100, lr=0.000179316, gnorm=0.372, loss_scale=64, train_wall=234, gb_free=8.8, wall=85977
2022-03-07 12:55:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 12:57:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:57:15 | INFO | valid | epoch 640 | valid on 'valid' subset | loss 13.443 | nll_loss 12.854 | ppl 7404.28 | wps 41803.7 | wpb 510.9 | bsz 1 | num_updates 31137 | best_loss 8.937
2022-03-07 12:57:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 640 @ 31137 updates
2022-03-07 12:57:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:57:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:57:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 640 @ 31137 updates, score 13.443) (writing took 2.380813712719828 seconds)
2022-03-07 12:57:18 | INFO | fairseq_cli.train | end of epoch 640 (average epoch stats below)
2022-03-07 12:57:18 | INFO | train | epoch 640 | loss 2.055 | nll_loss 0.298 | ppl 1.23 | wps 23123.1 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31137 | lr 0.00017921 | gnorm 0.376 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86083
2022-03-07 12:57:18 | INFO | fairseq.trainer | begin training epoch 641
2022-03-07 12:57:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 12:59:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 12:59:28 | INFO | valid | epoch 641 | valid on 'valid' subset | loss 13.403 | nll_loss 12.811 | ppl 7186.22 | wps 43180.2 | wpb 510.9 | bsz 1 | num_updates 31186 | best_loss 8.937
2022-03-07 12:59:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 641 @ 31186 updates
2022-03-07 12:59:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:59:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 12:59:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 641 @ 31186 updates, score 13.403) (writing took 2.5174815631471574 seconds)
2022-03-07 12:59:31 | INFO | fairseq_cli.train | end of epoch 641 (average epoch stats below)
2022-03-07 12:59:31 | INFO | train | epoch 641 | loss 2.055 | nll_loss 0.298 | ppl 1.23 | wps 23937.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31186 | lr 0.000179069 | gnorm 0.374 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 86215
2022-03-07 12:59:31 | INFO | fairseq.trainer | begin training epoch 642
2022-03-07 12:59:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:00:07 | INFO | train_inner | epoch 642:     14 / 49 loss=2.055, nll_loss=0.298, ppl=1.23, wps=23627.7, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=31200, lr=0.000179029, gnorm=0.375, loss_scale=32, train_wall=234, gb_free=8.8, wall=86251
2022-03-07 13:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:01:42 | INFO | valid | epoch 642 | valid on 'valid' subset | loss 13.438 | nll_loss 12.849 | ppl 7375.56 | wps 41747 | wpb 510.9 | bsz 1 | num_updates 31235 | best_loss 8.937
2022-03-07 13:01:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 642 @ 31235 updates
2022-03-07 13:01:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:01:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 642 @ 31235 updates, score 13.438) (writing took 2.3996030436828732 seconds)
2022-03-07 13:01:44 | INFO | fairseq_cli.train | end of epoch 642 (average epoch stats below)
2022-03-07 13:01:44 | INFO | train | epoch 642 | loss 2.055 | nll_loss 0.298 | ppl 1.23 | wps 23802.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31235 | lr 0.000178928 | gnorm 0.371 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 86349
2022-03-07 13:01:44 | INFO | fairseq.trainer | begin training epoch 643
2022-03-07 13:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:02:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:03:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:03:56 | INFO | valid | epoch 643 | valid on 'valid' subset | loss 13.351 | nll_loss 12.755 | ppl 6912.95 | wps 41524 | wpb 510.9 | bsz 1 | num_updates 31283 | best_loss 8.937
2022-03-07 13:03:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 643 @ 31283 updates
2022-03-07 13:03:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:03:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:03:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 643 @ 31283 updates, score 13.351) (writing took 2.663962595164776 seconds)
2022-03-07 13:03:59 | INFO | fairseq_cli.train | end of epoch 643 (average epoch stats below)
2022-03-07 13:03:59 | INFO | train | epoch 643 | loss 2.055 | nll_loss 0.298 | ppl 1.23 | wps 23057.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31283 | lr 0.000178791 | gnorm 0.372 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86484
2022-03-07 13:03:59 | INFO | fairseq.trainer | begin training epoch 644
2022-03-07 13:03:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:04:44 | INFO | train_inner | epoch 644:     17 / 49 loss=2.054, nll_loss=0.298, ppl=1.23, wps=23409.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31300, lr=0.000178743, gnorm=0.37, loss_scale=32, train_wall=236, gb_free=8.8, wall=86528
2022-03-07 13:06:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:06:11 | INFO | valid | epoch 644 | valid on 'valid' subset | loss 13.449 | nll_loss 12.86 | ppl 7432.23 | wps 41583.4 | wpb 510.9 | bsz 1 | num_updates 31332 | best_loss 8.937
2022-03-07 13:06:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 644 @ 31332 updates
2022-03-07 13:06:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:06:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:06:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 644 @ 31332 updates, score 13.449) (writing took 2.3069244669750333 seconds)
2022-03-07 13:06:14 | INFO | fairseq_cli.train | end of epoch 644 (average epoch stats below)
2022-03-07 13:06:14 | INFO | train | epoch 644 | loss 2.054 | nll_loss 0.298 | ppl 1.23 | wps 23605.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31332 | lr 0.000178651 | gnorm 0.369 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86619
2022-03-07 13:06:14 | INFO | fairseq.trainer | begin training epoch 645
2022-03-07 13:06:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:08:26 | INFO | valid | epoch 645 | valid on 'valid' subset | loss 13.382 | nll_loss 12.791 | ppl 7086.2 | wps 40957.1 | wpb 510.9 | bsz 1 | num_updates 31381 | best_loss 8.937
2022-03-07 13:08:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 645 @ 31381 updates
2022-03-07 13:08:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:08:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:08:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 645 @ 31381 updates, score 13.382) (writing took 2.592175906058401 seconds)
2022-03-07 13:08:29 | INFO | fairseq_cli.train | end of epoch 645 (average epoch stats below)
2022-03-07 13:08:29 | INFO | train | epoch 645 | loss 2.054 | nll_loss 0.298 | ppl 1.23 | wps 23550.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31381 | lr 0.000178512 | gnorm 0.373 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 86753
2022-03-07 13:08:29 | INFO | fairseq.trainer | begin training epoch 646
2022-03-07 13:08:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:09:21 | INFO | train_inner | epoch 646:     20 / 49 loss=2.054, nll_loss=0.298, ppl=1.23, wps=23385.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31400, lr=0.000178458, gnorm=0.371, loss_scale=32, train_wall=236, gb_free=8.8, wall=86806
2022-03-07 13:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:10:41 | INFO | valid | epoch 646 | valid on 'valid' subset | loss 13.45 | nll_loss 12.86 | ppl 7436.36 | wps 41612.4 | wpb 510.9 | bsz 1 | num_updates 31429 | best_loss 8.937
2022-03-07 13:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 646 @ 31429 updates
2022-03-07 13:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:10:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:10:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 646 @ 31429 updates, score 13.45) (writing took 2.522713858168572 seconds)
2022-03-07 13:10:44 | INFO | fairseq_cli.train | end of epoch 646 (average epoch stats below)
2022-03-07 13:10:44 | INFO | train | epoch 646 | loss 2.054 | nll_loss 0.297 | ppl 1.23 | wps 23070.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31429 | lr 0.000178375 | gnorm 0.37 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 86888
2022-03-07 13:10:44 | INFO | fairseq.trainer | begin training epoch 647
2022-03-07 13:10:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:12:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:12:56 | INFO | valid | epoch 647 | valid on 'valid' subset | loss 13.474 | nll_loss 12.886 | ppl 7571.57 | wps 41471.3 | wpb 510.9 | bsz 1 | num_updates 31478 | best_loss 8.937
2022-03-07 13:12:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 647 @ 31478 updates
2022-03-07 13:12:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:12:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:12:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 647 @ 31478 updates, score 13.474) (writing took 2.495131972245872 seconds)
2022-03-07 13:12:58 | INFO | fairseq_cli.train | end of epoch 647 (average epoch stats below)
2022-03-07 13:12:58 | INFO | train | epoch 647 | loss 2.054 | nll_loss 0.297 | ppl 1.23 | wps 23622.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31478 | lr 0.000178236 | gnorm 0.369 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 87023
2022-03-07 13:12:58 | INFO | fairseq.trainer | begin training epoch 648
2022-03-07 13:12:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:13:56 | INFO | train_inner | epoch 648:     22 / 49 loss=2.053, nll_loss=0.297, ppl=1.23, wps=23629.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31500, lr=0.000178174, gnorm=0.37, loss_scale=32, train_wall=234, gb_free=8.8, wall=87080
2022-03-07 13:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:15:10 | INFO | valid | epoch 648 | valid on 'valid' subset | loss 13.411 | nll_loss 12.818 | ppl 7222.86 | wps 40491.9 | wpb 510.9 | bsz 1 | num_updates 31527 | best_loss 8.937
2022-03-07 13:15:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 648 @ 31527 updates
2022-03-07 13:15:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:15:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:15:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 648 @ 31527 updates, score 13.411) (writing took 2.3551415358670056 seconds)
2022-03-07 13:15:13 | INFO | fairseq_cli.train | end of epoch 648 (average epoch stats below)
2022-03-07 13:15:13 | INFO | train | epoch 648 | loss 2.053 | nll_loss 0.297 | ppl 1.23 | wps 23606.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31527 | lr 0.000178098 | gnorm 0.368 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 87158
2022-03-07 13:15:13 | INFO | fairseq.trainer | begin training epoch 649
2022-03-07 13:15:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:15:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:17:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:17:25 | INFO | valid | epoch 649 | valid on 'valid' subset | loss 13.515 | nll_loss 12.935 | ppl 7832.47 | wps 41155.1 | wpb 510.9 | bsz 1 | num_updates 31575 | best_loss 8.937
2022-03-07 13:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 649 @ 31575 updates
2022-03-07 13:17:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 649 @ 31575 updates, score 13.515) (writing took 2.3605948351323605 seconds)
2022-03-07 13:17:27 | INFO | fairseq_cli.train | end of epoch 649 (average epoch stats below)
2022-03-07 13:17:27 | INFO | train | epoch 649 | loss 2.053 | nll_loss 0.296 | ppl 1.23 | wps 23126 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31575 | lr 0.000177962 | gnorm 0.375 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 87292
2022-03-07 13:17:27 | INFO | fairseq.trainer | begin training epoch 650
2022-03-07 13:17:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:18:33 | INFO | train_inner | epoch 650:     25 / 49 loss=2.053, nll_loss=0.297, ppl=1.23, wps=23403.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=31600, lr=0.000177892, gnorm=0.371, loss_scale=32, train_wall=236, gb_free=8.8, wall=87358
2022-03-07 13:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:19:40 | INFO | valid | epoch 650 | valid on 'valid' subset | loss 13.503 | nll_loss 12.923 | ppl 7768.8 | wps 39893.9 | wpb 510.9 | bsz 1 | num_updates 31624 | best_loss 8.937
2022-03-07 13:19:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 650 @ 31624 updates
2022-03-07 13:19:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:19:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:19:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 650 @ 31624 updates, score 13.503) (writing took 2.3869393719360232 seconds)
2022-03-07 13:19:42 | INFO | fairseq_cli.train | end of epoch 650 (average epoch stats below)
2022-03-07 13:19:42 | INFO | train | epoch 650 | loss 2.052 | nll_loss 0.296 | ppl 1.23 | wps 23596.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31624 | lr 0.000177825 | gnorm 0.369 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 87427
2022-03-07 13:19:42 | INFO | fairseq.trainer | begin training epoch 651
2022-03-07 13:19:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:21:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:21:54 | INFO | valid | epoch 651 | valid on 'valid' subset | loss 13.323 | nll_loss 12.723 | ppl 6760.17 | wps 41358 | wpb 510.9 | bsz 1 | num_updates 31673 | best_loss 8.937
2022-03-07 13:21:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 651 @ 31673 updates
2022-03-07 13:21:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:21:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 651 @ 31673 updates, score 13.323) (writing took 2.6813356252387166 seconds)
2022-03-07 13:21:57 | INFO | fairseq_cli.train | end of epoch 651 (average epoch stats below)
2022-03-07 13:21:57 | INFO | train | epoch 651 | loss 2.053 | nll_loss 0.296 | ppl 1.23 | wps 23571.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 31673 | lr 0.000177687 | gnorm 0.371 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 87562
2022-03-07 13:21:57 | INFO | fairseq.trainer | begin training epoch 652
2022-03-07 13:21:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:22:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:23:10 | INFO | train_inner | epoch 652:     28 / 49 loss=2.052, nll_loss=0.296, ppl=1.23, wps=23413.2, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=31700, lr=0.000177611, gnorm=0.371, loss_scale=32, train_wall=236, gb_free=8.8, wall=87635
2022-03-07 13:24:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:24:09 | INFO | valid | epoch 652 | valid on 'valid' subset | loss 13.401 | nll_loss 12.81 | ppl 7183.34 | wps 41234.6 | wpb 510.9 | bsz 1 | num_updates 31721 | best_loss 8.937
2022-03-07 13:24:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 652 @ 31721 updates
2022-03-07 13:24:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:24:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:24:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 652 @ 31721 updates, score 13.401) (writing took 2.3550263373181224 seconds)
2022-03-07 13:24:11 | INFO | fairseq_cli.train | end of epoch 652 (average epoch stats below)
2022-03-07 13:24:11 | INFO | train | epoch 652 | loss 2.053 | nll_loss 0.297 | ppl 1.23 | wps 23189.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31721 | lr 0.000177552 | gnorm 0.378 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 87696
2022-03-07 13:24:11 | INFO | fairseq.trainer | begin training epoch 653
2022-03-07 13:24:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:26:22 | INFO | valid | epoch 653 | valid on 'valid' subset | loss 13.476 | nll_loss 12.894 | ppl 7609.96 | wps 42645.8 | wpb 510.9 | bsz 1 | num_updates 31770 | best_loss 8.937
2022-03-07 13:26:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 653 @ 31770 updates
2022-03-07 13:26:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:26:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:26:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 653 @ 31770 updates, score 13.476) (writing took 2.3230193750932813 seconds)
2022-03-07 13:26:25 | INFO | fairseq_cli.train | end of epoch 653 (average epoch stats below)
2022-03-07 13:26:25 | INFO | train | epoch 653 | loss 2.052 | nll_loss 0.296 | ppl 1.23 | wps 23793.2 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31770 | lr 0.000177415 | gnorm 0.372 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 87829
2022-03-07 13:26:25 | INFO | fairseq.trainer | begin training epoch 654
2022-03-07 13:26:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:27:42 | INFO | train_inner | epoch 654:     30 / 49 loss=2.052, nll_loss=0.296, ppl=1.23, wps=23843.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=31800, lr=0.000177332, gnorm=0.375, loss_scale=32, train_wall=232, gb_free=8.8, wall=87907
2022-03-07 13:28:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:28:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:28:35 | INFO | valid | epoch 654 | valid on 'valid' subset | loss 13.508 | nll_loss 12.926 | ppl 7784.25 | wps 42679.5 | wpb 510.9 | bsz 1 | num_updates 31818 | best_loss 8.937
2022-03-07 13:28:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 654 @ 31818 updates
2022-03-07 13:28:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:28:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:28:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 654 @ 31818 updates, score 13.508) (writing took 2.3258010242134333 seconds)
2022-03-07 13:28:37 | INFO | fairseq_cli.train | end of epoch 654 (average epoch stats below)
2022-03-07 13:28:37 | INFO | train | epoch 654 | loss 2.052 | nll_loss 0.296 | ppl 1.23 | wps 23519.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 31818 | lr 0.000177282 | gnorm 0.374 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 87962
2022-03-07 13:28:37 | INFO | fairseq.trainer | begin training epoch 655
2022-03-07 13:28:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:30:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:30:47 | INFO | valid | epoch 655 | valid on 'valid' subset | loss 13.414 | nll_loss 12.822 | ppl 7240.09 | wps 41658.3 | wpb 510.9 | bsz 1 | num_updates 31867 | best_loss 8.937
2022-03-07 13:30:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 655 @ 31867 updates
2022-03-07 13:30:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:30:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:30:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 655 @ 31867 updates, score 13.414) (writing took 2.4178272541612387 seconds)
2022-03-07 13:30:50 | INFO | fairseq_cli.train | end of epoch 655 (average epoch stats below)
2022-03-07 13:30:50 | INFO | train | epoch 655 | loss 2.052 | nll_loss 0.296 | ppl 1.23 | wps 23984.3 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31867 | lr 0.000177145 | gnorm 0.378 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 88094
2022-03-07 13:30:50 | INFO | fairseq.trainer | begin training epoch 656
2022-03-07 13:30:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:32:14 | INFO | train_inner | epoch 656:     33 / 49 loss=2.052, nll_loss=0.296, ppl=1.23, wps=23827.4, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=31900, lr=0.000177054, gnorm=0.375, loss_scale=32, train_wall=232, gb_free=8.8, wall=88179
2022-03-07 13:32:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:32:59 | INFO | valid | epoch 656 | valid on 'valid' subset | loss 13.472 | nll_loss 12.887 | ppl 7575.19 | wps 42648.8 | wpb 510.9 | bsz 1 | num_updates 31916 | best_loss 8.937
2022-03-07 13:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 656 @ 31916 updates
2022-03-07 13:32:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:33:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:33:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 656 @ 31916 updates, score 13.472) (writing took 2.4270780929364264 seconds)
2022-03-07 13:33:02 | INFO | fairseq_cli.train | end of epoch 656 (average epoch stats below)
2022-03-07 13:33:02 | INFO | train | epoch 656 | loss 2.052 | nll_loss 0.296 | ppl 1.23 | wps 24015.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31916 | lr 0.000177009 | gnorm 0.37 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 88227
2022-03-07 13:33:02 | INFO | fairseq.trainer | begin training epoch 657
2022-03-07 13:33:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:35:12 | INFO | valid | epoch 657 | valid on 'valid' subset | loss 13.5 | nll_loss 12.913 | ppl 7710.26 | wps 42629.4 | wpb 510.9 | bsz 1 | num_updates 31965 | best_loss 8.937
2022-03-07 13:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 657 @ 31965 updates
2022-03-07 13:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 657 @ 31965 updates, score 13.5) (writing took 2.301000020932406 seconds)
2022-03-07 13:35:14 | INFO | fairseq_cli.train | end of epoch 657 (average epoch stats below)
2022-03-07 13:35:14 | INFO | train | epoch 657 | loss 2.052 | nll_loss 0.296 | ppl 1.23 | wps 24007.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 31965 | lr 0.000176873 | gnorm 0.372 | loss_scale 64 | train_wall 113 | gb_free 8.8 | wall 88359
2022-03-07 13:35:14 | INFO | fairseq.trainer | begin training epoch 658
2022-03-07 13:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:35:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:36:48 | INFO | train_inner | epoch 658:     36 / 49 loss=2.052, nll_loss=0.296, ppl=1.23, wps=23699.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=32000, lr=0.000176777, gnorm=0.372, loss_scale=32, train_wall=233, gb_free=8.8, wall=88453
2022-03-07 13:37:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:37:26 | INFO | valid | epoch 658 | valid on 'valid' subset | loss 13.502 | nll_loss 12.917 | ppl 7731.73 | wps 41589.9 | wpb 510.9 | bsz 1 | num_updates 32013 | best_loss 8.937
2022-03-07 13:37:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 658 @ 32013 updates
2022-03-07 13:37:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:37:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 658 @ 32013 updates, score 13.502) (writing took 2.446825962048024 seconds)
2022-03-07 13:37:29 | INFO | fairseq_cli.train | end of epoch 658 (average epoch stats below)
2022-03-07 13:37:29 | INFO | train | epoch 658 | loss 2.051 | nll_loss 0.295 | ppl 1.23 | wps 23179.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32013 | lr 0.000176741 | gnorm 0.371 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 88493
2022-03-07 13:37:29 | INFO | fairseq.trainer | begin training epoch 659
2022-03-07 13:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:39:41 | INFO | valid | epoch 659 | valid on 'valid' subset | loss 13.397 | nll_loss 12.805 | ppl 7154.63 | wps 41181.7 | wpb 510.9 | bsz 1 | num_updates 32062 | best_loss 8.937
2022-03-07 13:39:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 659 @ 32062 updates
2022-03-07 13:39:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:39:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:39:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 659 @ 32062 updates, score 13.397) (writing took 2.5398726142011583 seconds)
2022-03-07 13:39:44 | INFO | fairseq_cli.train | end of epoch 659 (average epoch stats below)
2022-03-07 13:39:44 | INFO | train | epoch 659 | loss 2.051 | nll_loss 0.295 | ppl 1.23 | wps 23500.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32062 | lr 0.000176606 | gnorm 0.371 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 88628
2022-03-07 13:39:44 | INFO | fairseq.trainer | begin training epoch 660
2022-03-07 13:39:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:41:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:41:26 | INFO | train_inner | epoch 660:     39 / 49 loss=2.051, nll_loss=0.295, ppl=1.23, wps=23339.9, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32100, lr=0.000176501, gnorm=0.369, loss_scale=32, train_wall=237, gb_free=8.8, wall=88731
2022-03-07 13:41:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:41:56 | INFO | valid | epoch 660 | valid on 'valid' subset | loss 13.483 | nll_loss 12.898 | ppl 7635.4 | wps 41135.1 | wpb 510.9 | bsz 1 | num_updates 32110 | best_loss 8.937
2022-03-07 13:41:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 660 @ 32110 updates
2022-03-07 13:41:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:41:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:41:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 660 @ 32110 updates, score 13.483) (writing took 2.485159510280937 seconds)
2022-03-07 13:41:59 | INFO | fairseq_cli.train | end of epoch 660 (average epoch stats below)
2022-03-07 13:41:59 | INFO | train | epoch 660 | loss 2.051 | nll_loss 0.295 | ppl 1.23 | wps 23034 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32110 | lr 0.000176474 | gnorm 0.367 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 88764
2022-03-07 13:41:59 | INFO | fairseq.trainer | begin training epoch 661
2022-03-07 13:41:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:44:11 | INFO | valid | epoch 661 | valid on 'valid' subset | loss 13.464 | nll_loss 12.88 | ppl 7537.57 | wps 41785 | wpb 510.9 | bsz 1 | num_updates 32159 | best_loss 8.937
2022-03-07 13:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 661 @ 32159 updates
2022-03-07 13:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:44:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:44:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 661 @ 32159 updates, score 13.464) (writing took 2.5271762190386653 seconds)
2022-03-07 13:44:14 | INFO | fairseq_cli.train | end of epoch 661 (average epoch stats below)
2022-03-07 13:44:14 | INFO | train | epoch 661 | loss 2.051 | nll_loss 0.295 | ppl 1.23 | wps 23569.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32159 | lr 0.000176339 | gnorm 0.371 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 88898
2022-03-07 13:44:14 | INFO | fairseq.trainer | begin training epoch 662
2022-03-07 13:44:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:46:01 | INFO | train_inner | epoch 662:     41 / 49 loss=2.051, nll_loss=0.295, ppl=1.23, wps=23582.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32200, lr=0.000176227, gnorm=0.372, loss_scale=32, train_wall=234, gb_free=8.8, wall=89006
2022-03-07 13:46:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:46:26 | INFO | valid | epoch 662 | valid on 'valid' subset | loss 13.442 | nll_loss 12.853 | ppl 7397.35 | wps 41785.3 | wpb 510.9 | bsz 1 | num_updates 32208 | best_loss 8.937
2022-03-07 13:46:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 662 @ 32208 updates
2022-03-07 13:46:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:46:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:46:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 662 @ 32208 updates, score 13.442) (writing took 2.5130713880062103 seconds)
2022-03-07 13:46:29 | INFO | fairseq_cli.train | end of epoch 662 (average epoch stats below)
2022-03-07 13:46:29 | INFO | train | epoch 662 | loss 2.051 | nll_loss 0.295 | ppl 1.23 | wps 23573.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32208 | lr 0.000176205 | gnorm 0.374 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89033
2022-03-07 13:46:29 | INFO | fairseq.trainer | begin training epoch 663
2022-03-07 13:46:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:47:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:48:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:48:41 | INFO | valid | epoch 663 | valid on 'valid' subset | loss 13.438 | nll_loss 12.856 | ppl 7414.98 | wps 41831.7 | wpb 510.9 | bsz 1 | num_updates 32256 | best_loss 8.937
2022-03-07 13:48:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 663 @ 32256 updates
2022-03-07 13:48:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:48:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:48:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 663 @ 32256 updates, score 13.438) (writing took 2.438213286921382 seconds)
2022-03-07 13:48:43 | INFO | fairseq_cli.train | end of epoch 663 (average epoch stats below)
2022-03-07 13:48:43 | INFO | train | epoch 663 | loss 2.05 | nll_loss 0.294 | ppl 1.23 | wps 23082.8 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32256 | lr 0.000176074 | gnorm 0.363 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89168
2022-03-07 13:48:43 | INFO | fairseq.trainer | begin training epoch 664
2022-03-07 13:48:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:50:39 | INFO | train_inner | epoch 664:     44 / 49 loss=2.05, nll_loss=0.295, ppl=1.23, wps=23350.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32300, lr=0.000175954, gnorm=0.367, loss_scale=32, train_wall=237, gb_free=8.8, wall=89284
2022-03-07 13:50:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:50:56 | INFO | valid | epoch 664 | valid on 'valid' subset | loss 13.483 | nll_loss 12.897 | ppl 7628.11 | wps 40120.7 | wpb 510.9 | bsz 1 | num_updates 32305 | best_loss 8.937
2022-03-07 13:50:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 664 @ 32305 updates
2022-03-07 13:50:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:50:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 664 @ 32305 updates, score 13.483) (writing took 2.4292813120409846 seconds)
2022-03-07 13:50:59 | INFO | fairseq_cli.train | end of epoch 664 (average epoch stats below)
2022-03-07 13:50:59 | INFO | train | epoch 664 | loss 2.05 | nll_loss 0.295 | ppl 1.23 | wps 23508.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32305 | lr 0.00017594 | gnorm 0.371 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89303
2022-03-07 13:50:59 | INFO | fairseq.trainer | begin training epoch 665
2022-03-07 13:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:53:11 | INFO | valid | epoch 665 | valid on 'valid' subset | loss 13.475 | nll_loss 12.889 | ppl 7583.02 | wps 41649.5 | wpb 510.9 | bsz 1 | num_updates 32354 | best_loss 8.937
2022-03-07 13:53:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 665 @ 32354 updates
2022-03-07 13:53:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:53:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:53:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 665 @ 32354 updates, score 13.475) (writing took 2.5118682361207902 seconds)
2022-03-07 13:53:14 | INFO | fairseq_cli.train | end of epoch 665 (average epoch stats below)
2022-03-07 13:53:14 | INFO | train | epoch 665 | loss 2.05 | nll_loss 0.294 | ppl 1.23 | wps 23549.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32354 | lr 0.000175807 | gnorm 0.37 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89438
2022-03-07 13:53:14 | INFO | fairseq.trainer | begin training epoch 666
2022-03-07 13:53:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:54:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 13:55:17 | INFO | train_inner | epoch 666:     47 / 49 loss=2.05, nll_loss=0.294, ppl=1.23, wps=23357.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32400, lr=0.000175682, gnorm=0.37, loss_scale=32, train_wall=236, gb_free=8.8, wall=89561
2022-03-07 13:55:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:55:26 | INFO | valid | epoch 666 | valid on 'valid' subset | loss 13.417 | nll_loss 12.828 | ppl 7269.62 | wps 41667.7 | wpb 510.9 | bsz 1 | num_updates 32402 | best_loss 8.937
2022-03-07 13:55:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 666 @ 32402 updates
2022-03-07 13:55:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:55:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 666 @ 32402 updates, score 13.417) (writing took 2.328475845977664 seconds)
2022-03-07 13:55:28 | INFO | fairseq_cli.train | end of epoch 666 (average epoch stats below)
2022-03-07 13:55:28 | INFO | train | epoch 666 | loss 2.05 | nll_loss 0.294 | ppl 1.23 | wps 23122.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32402 | lr 0.000175677 | gnorm 0.369 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89573
2022-03-07 13:55:28 | INFO | fairseq.trainer | begin training epoch 667
2022-03-07 13:55:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:57:40 | INFO | valid | epoch 667 | valid on 'valid' subset | loss 13.381 | nll_loss 12.793 | ppl 7098.65 | wps 41987.6 | wpb 510.9 | bsz 1 | num_updates 32451 | best_loss 8.937
2022-03-07 13:57:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 667 @ 32451 updates
2022-03-07 13:57:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:57:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:57:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 667 @ 32451 updates, score 13.381) (writing took 2.42812812095508 seconds)
2022-03-07 13:57:43 | INFO | fairseq_cli.train | end of epoch 667 (average epoch stats below)
2022-03-07 13:57:43 | INFO | train | epoch 667 | loss 2.049 | nll_loss 0.294 | ppl 1.23 | wps 23580 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32451 | lr 0.000175544 | gnorm 0.371 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 89708
2022-03-07 13:57:43 | INFO | fairseq.trainer | begin training epoch 668
2022-03-07 13:57:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 13:59:49 | INFO | train_inner | epoch 668:     49 / 49 loss=2.049, nll_loss=0.294, ppl=1.23, wps=23670.2, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=32500, lr=0.000175412, gnorm=0.371, loss_scale=64, train_wall=232, gb_free=8.8, wall=89834
2022-03-07 13:59:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 13:59:54 | INFO | valid | epoch 668 | valid on 'valid' subset | loss 13.517 | nll_loss 12.937 | ppl 7840.59 | wps 43509.9 | wpb 510.9 | bsz 1 | num_updates 32500 | best_loss 8.937
2022-03-07 13:59:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 668 @ 32500 updates
2022-03-07 13:59:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:59:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 13:59:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 668 @ 32500 updates, score 13.517) (writing took 2.29767831787467 seconds)
2022-03-07 13:59:57 | INFO | fairseq_cli.train | end of epoch 668 (average epoch stats below)
2022-03-07 13:59:57 | INFO | train | epoch 668 | loss 2.048 | nll_loss 0.293 | ppl 1.23 | wps 23759.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 32500 | lr 0.000175412 | gnorm 0.37 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 89841
2022-03-07 13:59:57 | INFO | fairseq.trainer | begin training epoch 669
2022-03-07 13:59:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:00:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:02:07 | INFO | valid | epoch 669 | valid on 'valid' subset | loss 13.506 | nll_loss 12.921 | ppl 7755.01 | wps 42247.5 | wpb 510.9 | bsz 1 | num_updates 32548 | best_loss 8.937
2022-03-07 14:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 669 @ 32548 updates
2022-03-07 14:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:02:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:02:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 669 @ 32548 updates, score 13.506) (writing took 2.3840772230178118 seconds)
2022-03-07 14:02:09 | INFO | fairseq_cli.train | end of epoch 669 (average epoch stats below)
2022-03-07 14:02:09 | INFO | train | epoch 669 | loss 2.049 | nll_loss 0.294 | ppl 1.23 | wps 23483.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32548 | lr 0.000175282 | gnorm 0.365 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 89974
2022-03-07 14:02:09 | INFO | fairseq.trainer | begin training epoch 670
2022-03-07 14:02:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:04:19 | INFO | valid | epoch 670 | valid on 'valid' subset | loss 13.447 | nll_loss 12.862 | ppl 7447.02 | wps 42210.9 | wpb 510.9 | bsz 1 | num_updates 32597 | best_loss 8.937
2022-03-07 14:04:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 670 @ 32597 updates
2022-03-07 14:04:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:04:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 670 @ 32597 updates, score 13.447) (writing took 2.379046014044434 seconds)
2022-03-07 14:04:22 | INFO | fairseq_cli.train | end of epoch 670 (average epoch stats below)
2022-03-07 14:04:22 | INFO | train | epoch 670 | loss 2.049 | nll_loss 0.294 | ppl 1.23 | wps 24010.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 32597 | lr 0.00017515 | gnorm 0.371 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90106
2022-03-07 14:04:22 | INFO | fairseq.trainer | begin training epoch 671
2022-03-07 14:04:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:04:29 | INFO | train_inner | epoch 671:      3 / 49 loss=2.049, nll_loss=0.294, ppl=1.23, wps=23154.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=32600, lr=0.000175142, gnorm=0.368, loss_scale=32, train_wall=232, gb_free=8.8, wall=90114
2022-03-07 14:05:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:06:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:06:31 | INFO | valid | epoch 671 | valid on 'valid' subset | loss 13.449 | nll_loss 12.866 | ppl 7464.81 | wps 42785.8 | wpb 510.9 | bsz 1 | num_updates 32645 | best_loss 8.937
2022-03-07 14:06:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 671 @ 32645 updates
2022-03-07 14:06:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 671 @ 32645 updates, score 13.449) (writing took 2.3462442997843027 seconds)
2022-03-07 14:06:34 | INFO | fairseq_cli.train | end of epoch 671 (average epoch stats below)
2022-03-07 14:06:34 | INFO | train | epoch 671 | loss 2.049 | nll_loss 0.293 | ppl 1.23 | wps 23531.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32645 | lr 0.000175022 | gnorm 0.376 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90239
2022-03-07 14:06:34 | INFO | fairseq.trainer | begin training epoch 672
2022-03-07 14:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:08:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:08:43 | INFO | valid | epoch 672 | valid on 'valid' subset | loss 13.509 | nll_loss 12.93 | ppl 7802.12 | wps 43698.2 | wpb 510.9 | bsz 1 | num_updates 32694 | best_loss 8.937
2022-03-07 14:08:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 672 @ 32694 updates
2022-03-07 14:08:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:08:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:08:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 672 @ 32694 updates, score 13.509) (writing took 2.3101883893832564 seconds)
2022-03-07 14:08:46 | INFO | fairseq_cli.train | end of epoch 672 (average epoch stats below)
2022-03-07 14:08:46 | INFO | train | epoch 672 | loss 2.048 | nll_loss 0.293 | ppl 1.23 | wps 24097.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 32694 | lr 0.00017489 | gnorm 0.368 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 90370
2022-03-07 14:08:46 | INFO | fairseq.trainer | begin training epoch 673
2022-03-07 14:08:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:09:01 | INFO | train_inner | epoch 673:      6 / 49 loss=2.048, nll_loss=0.293, ppl=1.23, wps=23864.8, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=32700, lr=0.000174874, gnorm=0.372, loss_scale=32, train_wall=232, gb_free=8.8, wall=90386
2022-03-07 14:10:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:10:56 | INFO | valid | epoch 673 | valid on 'valid' subset | loss 13.429 | nll_loss 12.843 | ppl 7345.14 | wps 43105.3 | wpb 510.9 | bsz 1 | num_updates 32743 | best_loss 8.937
2022-03-07 14:10:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 673 @ 32743 updates
2022-03-07 14:10:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:10:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 673 @ 32743 updates, score 13.429) (writing took 2.4107548999600112 seconds)
2022-03-07 14:10:58 | INFO | fairseq_cli.train | end of epoch 673 (average epoch stats below)
2022-03-07 14:10:58 | INFO | train | epoch 673 | loss 2.048 | nll_loss 0.293 | ppl 1.23 | wps 24000.8 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 32743 | lr 0.000174759 | gnorm 0.368 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90503
2022-03-07 14:10:58 | INFO | fairseq.trainer | begin training epoch 674
2022-03-07 14:10:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:12:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:13:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:13:08 | INFO | valid | epoch 674 | valid on 'valid' subset | loss 13.374 | nll_loss 12.784 | ppl 7055 | wps 41629.3 | wpb 510.9 | bsz 1 | num_updates 32791 | best_loss 8.937
2022-03-07 14:13:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 674 @ 32791 updates
2022-03-07 14:13:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:13:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:13:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 674 @ 32791 updates, score 13.374) (writing took 2.383742058649659 seconds)
2022-03-07 14:13:11 | INFO | fairseq_cli.train | end of epoch 674 (average epoch stats below)
2022-03-07 14:13:11 | INFO | train | epoch 674 | loss 2.047 | nll_loss 0.293 | ppl 1.22 | wps 23486 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32791 | lr 0.000174632 | gnorm 0.366 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 90635
2022-03-07 14:13:11 | INFO | fairseq.trainer | begin training epoch 675
2022-03-07 14:13:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:13:34 | INFO | train_inner | epoch 675:      9 / 49 loss=2.047, nll_loss=0.293, ppl=1.22, wps=23751.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=32800, lr=0.000174608, gnorm=0.366, loss_scale=32, train_wall=233, gb_free=8.8, wall=90659
2022-03-07 14:15:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:15:23 | INFO | valid | epoch 675 | valid on 'valid' subset | loss 13.473 | nll_loss 12.89 | ppl 7588.9 | wps 41434.5 | wpb 510.9 | bsz 1 | num_updates 32840 | best_loss 8.937
2022-03-07 14:15:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 675 @ 32840 updates
2022-03-07 14:15:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:15:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:15:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 675 @ 32840 updates, score 13.473) (writing took 2.5197052620351315 seconds)
2022-03-07 14:15:26 | INFO | fairseq_cli.train | end of epoch 675 (average epoch stats below)
2022-03-07 14:15:26 | INFO | train | epoch 675 | loss 2.048 | nll_loss 0.293 | ppl 1.23 | wps 23533.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32840 | lr 0.000174501 | gnorm 0.37 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 90770
2022-03-07 14:15:26 | INFO | fairseq.trainer | begin training epoch 676
2022-03-07 14:15:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:17:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:17:38 | INFO | valid | epoch 676 | valid on 'valid' subset | loss 13.445 | nll_loss 12.855 | ppl 7409.55 | wps 41677.4 | wpb 510.9 | bsz 1 | num_updates 32889 | best_loss 8.937
2022-03-07 14:17:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 676 @ 32889 updates
2022-03-07 14:17:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:17:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 676 @ 32889 updates, score 13.445) (writing took 2.441444932948798 seconds)
2022-03-07 14:17:40 | INFO | fairseq_cli.train | end of epoch 676 (average epoch stats below)
2022-03-07 14:17:40 | INFO | train | epoch 676 | loss 2.048 | nll_loss 0.293 | ppl 1.23 | wps 23582.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32889 | lr 0.000174371 | gnorm 0.369 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 90905
2022-03-07 14:17:40 | INFO | fairseq.trainer | begin training epoch 677
2022-03-07 14:17:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:18:09 | INFO | train_inner | epoch 677:     11 / 49 loss=2.048, nll_loss=0.293, ppl=1.23, wps=23598.3, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=32900, lr=0.000174342, gnorm=0.369, loss_scale=64, train_wall=234, gb_free=8.8, wall=90934
2022-03-07 14:18:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:19:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:19:53 | INFO | valid | epoch 677 | valid on 'valid' subset | loss 13.437 | nll_loss 12.851 | ppl 7389.33 | wps 41717.7 | wpb 510.9 | bsz 1 | num_updates 32937 | best_loss 8.937
2022-03-07 14:19:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 677 @ 32937 updates
2022-03-07 14:19:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:19:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 677 @ 32937 updates, score 13.437) (writing took 2.570028693880886 seconds)
2022-03-07 14:19:55 | INFO | fairseq_cli.train | end of epoch 677 (average epoch stats below)
2022-03-07 14:19:55 | INFO | train | epoch 677 | loss 2.047 | nll_loss 0.292 | ppl 1.22 | wps 23114.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 32937 | lr 0.000174244 | gnorm 0.367 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 91040
2022-03-07 14:19:55 | INFO | fairseq.trainer | begin training epoch 678
2022-03-07 14:19:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:22:08 | INFO | valid | epoch 678 | valid on 'valid' subset | loss 13.445 | nll_loss 12.856 | ppl 7413.71 | wps 40237.5 | wpb 510.9 | bsz 1 | num_updates 32986 | best_loss 8.937
2022-03-07 14:22:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 678 @ 32986 updates
2022-03-07 14:22:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:22:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:22:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 678 @ 32986 updates, score 13.445) (writing took 2.5133028379641473 seconds)
2022-03-07 14:22:10 | INFO | fairseq_cli.train | end of epoch 678 (average epoch stats below)
2022-03-07 14:22:10 | INFO | train | epoch 678 | loss 2.046 | nll_loss 0.292 | ppl 1.22 | wps 23525 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 32986 | lr 0.000174115 | gnorm 0.365 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91175
2022-03-07 14:22:10 | INFO | fairseq.trainer | begin training epoch 679
2022-03-07 14:22:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:22:47 | INFO | train_inner | epoch 679:     14 / 49 loss=2.046, nll_loss=0.292, ppl=1.22, wps=23368.6, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=33000, lr=0.000174078, gnorm=0.365, loss_scale=32, train_wall=236, gb_free=8.8, wall=91212
2022-03-07 14:24:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:24:23 | INFO | valid | epoch 679 | valid on 'valid' subset | loss 13.442 | nll_loss 12.854 | ppl 7404.7 | wps 41126.4 | wpb 510.9 | bsz 1 | num_updates 33035 | best_loss 8.937
2022-03-07 14:24:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 679 @ 33035 updates
2022-03-07 14:24:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:24:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:24:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 679 @ 33035 updates, score 13.442) (writing took 2.446014037821442 seconds)
2022-03-07 14:24:25 | INFO | fairseq_cli.train | end of epoch 679 (average epoch stats below)
2022-03-07 14:24:25 | INFO | train | epoch 679 | loss 2.047 | nll_loss 0.292 | ppl 1.22 | wps 23573.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33035 | lr 0.000173985 | gnorm 0.365 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91310
2022-03-07 14:24:25 | INFO | fairseq.trainer | begin training epoch 680
2022-03-07 14:24:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:24:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:26:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:26:38 | INFO | valid | epoch 680 | valid on 'valid' subset | loss 13.498 | nll_loss 12.916 | ppl 7730.53 | wps 41633.4 | wpb 510.9 | bsz 1 | num_updates 33083 | best_loss 8.937
2022-03-07 14:26:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 680 @ 33083 updates
2022-03-07 14:26:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:26:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:26:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 680 @ 33083 updates, score 13.498) (writing took 2.3910537688061595 seconds)
2022-03-07 14:26:40 | INFO | fairseq_cli.train | end of epoch 680 (average epoch stats below)
2022-03-07 14:26:40 | INFO | train | epoch 680 | loss 2.046 | nll_loss 0.292 | ppl 1.22 | wps 23065 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33083 | lr 0.000173859 | gnorm 0.363 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91445
2022-03-07 14:26:40 | INFO | fairseq.trainer | begin training epoch 681
2022-03-07 14:26:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:27:24 | INFO | train_inner | epoch 681:     17 / 49 loss=2.046, nll_loss=0.292, ppl=1.22, wps=23373.5, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=33100, lr=0.000173814, gnorm=0.364, loss_scale=32, train_wall=236, gb_free=8.8, wall=91489
2022-03-07 14:28:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:28:52 | INFO | valid | epoch 681 | valid on 'valid' subset | loss 13.438 | nll_loss 12.853 | ppl 7397.27 | wps 42000.5 | wpb 510.9 | bsz 1 | num_updates 33132 | best_loss 8.937
2022-03-07 14:28:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 681 @ 33132 updates
2022-03-07 14:28:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:28:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:28:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 681 @ 33132 updates, score 13.438) (writing took 2.4800893990322948 seconds)
2022-03-07 14:28:55 | INFO | fairseq_cli.train | end of epoch 681 (average epoch stats below)
2022-03-07 14:28:55 | INFO | train | epoch 681 | loss 2.046 | nll_loss 0.292 | ppl 1.22 | wps 23563.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33132 | lr 0.000173731 | gnorm 0.365 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91580
2022-03-07 14:28:55 | INFO | fairseq.trainer | begin training epoch 682
2022-03-07 14:28:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:30:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:31:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:31:07 | INFO | valid | epoch 682 | valid on 'valid' subset | loss 13.484 | nll_loss 12.9 | ppl 7644.43 | wps 41460.4 | wpb 510.9 | bsz 1 | num_updates 33180 | best_loss 8.937
2022-03-07 14:31:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 682 @ 33180 updates
2022-03-07 14:31:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:31:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:31:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 682 @ 33180 updates, score 13.484) (writing took 2.40468881605193 seconds)
2022-03-07 14:31:10 | INFO | fairseq_cli.train | end of epoch 682 (average epoch stats below)
2022-03-07 14:31:10 | INFO | train | epoch 682 | loss 2.047 | nll_loss 0.293 | ppl 1.22 | wps 23078.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33180 | lr 0.000173605 | gnorm 0.369 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91714
2022-03-07 14:31:10 | INFO | fairseq.trainer | begin training epoch 683
2022-03-07 14:31:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:32:02 | INFO | train_inner | epoch 683:     20 / 49 loss=2.046, nll_loss=0.292, ppl=1.22, wps=23337.2, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=33200, lr=0.000173553, gnorm=0.367, loss_scale=32, train_wall=237, gb_free=8.8, wall=91767
2022-03-07 14:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:33:22 | INFO | valid | epoch 683 | valid on 'valid' subset | loss 13.413 | nll_loss 12.823 | ppl 7247.99 | wps 41260.1 | wpb 510.9 | bsz 1 | num_updates 33229 | best_loss 8.937
2022-03-07 14:33:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 683 @ 33229 updates
2022-03-07 14:33:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:33:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:33:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 683 @ 33229 updates, score 13.413) (writing took 2.5405582459643483 seconds)
2022-03-07 14:33:25 | INFO | fairseq_cli.train | end of epoch 683 (average epoch stats below)
2022-03-07 14:33:25 | INFO | train | epoch 683 | loss 2.046 | nll_loss 0.292 | ppl 1.22 | wps 23512.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33229 | lr 0.000173477 | gnorm 0.368 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91850
2022-03-07 14:33:25 | INFO | fairseq.trainer | begin training epoch 684
2022-03-07 14:33:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:35:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:35:37 | INFO | valid | epoch 684 | valid on 'valid' subset | loss 13.474 | nll_loss 12.895 | ppl 7616.6 | wps 42000.8 | wpb 510.9 | bsz 1 | num_updates 33278 | best_loss 8.937
2022-03-07 14:35:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 684 @ 33278 updates
2022-03-07 14:35:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:35:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 684 @ 33278 updates, score 13.474) (writing took 2.4891859809868038 seconds)
2022-03-07 14:35:40 | INFO | fairseq_cli.train | end of epoch 684 (average epoch stats below)
2022-03-07 14:35:40 | INFO | train | epoch 684 | loss 2.045 | nll_loss 0.291 | ppl 1.22 | wps 23568.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33278 | lr 0.000173349 | gnorm 0.367 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 91984
2022-03-07 14:35:40 | INFO | fairseq.trainer | begin training epoch 685
2022-03-07 14:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:36:37 | INFO | train_inner | epoch 685:     22 / 49 loss=2.046, nll_loss=0.292, ppl=1.22, wps=23636.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=33300, lr=0.000173292, gnorm=0.369, loss_scale=32, train_wall=234, gb_free=8.8, wall=92042
2022-03-07 14:36:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:37:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:37:50 | INFO | valid | epoch 685 | valid on 'valid' subset | loss 13.444 | nll_loss 12.861 | ppl 7437.34 | wps 43029.2 | wpb 510.9 | bsz 1 | num_updates 33326 | best_loss 8.937
2022-03-07 14:37:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 685 @ 33326 updates
2022-03-07 14:37:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 685 @ 33326 updates, score 13.444) (writing took 2.3612486380152404 seconds)
2022-03-07 14:37:53 | INFO | fairseq_cli.train | end of epoch 685 (average epoch stats below)
2022-03-07 14:37:53 | INFO | train | epoch 685 | loss 2.045 | nll_loss 0.291 | ppl 1.22 | wps 23410.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33326 | lr 0.000173224 | gnorm 0.368 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92117
2022-03-07 14:37:53 | INFO | fairseq.trainer | begin training epoch 686
2022-03-07 14:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:39:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:40:03 | INFO | valid | epoch 686 | valid on 'valid' subset | loss 13.489 | nll_loss 12.907 | ppl 7682.91 | wps 43289.8 | wpb 510.9 | bsz 1 | num_updates 33375 | best_loss 8.937
2022-03-07 14:40:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 686 @ 33375 updates
2022-03-07 14:40:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:40:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:40:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 686 @ 33375 updates, score 13.489) (writing took 2.3637384911999106 seconds)
2022-03-07 14:40:05 | INFO | fairseq_cli.train | end of epoch 686 (average epoch stats below)
2022-03-07 14:40:05 | INFO | train | epoch 686 | loss 2.045 | nll_loss 0.291 | ppl 1.22 | wps 24026.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33375 | lr 0.000173097 | gnorm 0.367 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92250
2022-03-07 14:40:05 | INFO | fairseq.trainer | begin training epoch 687
2022-03-07 14:40:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:41:10 | INFO | train_inner | epoch 687:     25 / 49 loss=2.045, nll_loss=0.291, ppl=1.22, wps=23790.9, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=33400, lr=0.000173032, gnorm=0.366, loss_scale=32, train_wall=232, gb_free=8.8, wall=92314
2022-03-07 14:42:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:42:15 | INFO | valid | epoch 687 | valid on 'valid' subset | loss 13.432 | nll_loss 12.846 | ppl 7364.5 | wps 43476.6 | wpb 510.9 | bsz 1 | num_updates 33424 | best_loss 8.937
2022-03-07 14:42:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 687 @ 33424 updates
2022-03-07 14:42:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:42:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:42:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 687 @ 33424 updates, score 13.432) (writing took 2.325177335180342 seconds)
2022-03-07 14:42:17 | INFO | fairseq_cli.train | end of epoch 687 (average epoch stats below)
2022-03-07 14:42:17 | INFO | train | epoch 687 | loss 2.045 | nll_loss 0.291 | ppl 1.22 | wps 24038.9 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33424 | lr 0.00017297 | gnorm 0.366 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92382
2022-03-07 14:42:17 | INFO | fairseq.trainer | begin training epoch 688
2022-03-07 14:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:43:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:44:27 | INFO | valid | epoch 688 | valid on 'valid' subset | loss 13.57 | nll_loss 12.999 | ppl 8187.96 | wps 42980.1 | wpb 510.9 | bsz 1 | num_updates 33472 | best_loss 8.937
2022-03-07 14:44:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 688 @ 33472 updates
2022-03-07 14:44:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:44:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:44:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 688 @ 33472 updates, score 13.57) (writing took 2.3853207072243094 seconds)
2022-03-07 14:44:30 | INFO | fairseq_cli.train | end of epoch 688 (average epoch stats below)
2022-03-07 14:44:30 | INFO | train | epoch 688 | loss 2.044 | nll_loss 0.29 | ppl 1.22 | wps 23494.2 | ups 0.36 | wpb 64853.3 | bsz 126.7 | num_updates 33472 | lr 0.000172846 | gnorm 0.363 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92514
2022-03-07 14:44:30 | INFO | fairseq.trainer | begin training epoch 689
2022-03-07 14:44:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:45:42 | INFO | train_inner | epoch 689:     28 / 49 loss=2.045, nll_loss=0.291, ppl=1.22, wps=23839.2, ups=0.37, wpb=64880.6, bsz=126.7, num_updates=33500, lr=0.000172774, gnorm=0.367, loss_scale=32, train_wall=232, gb_free=8.8, wall=92586
2022-03-07 14:46:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:46:40 | INFO | valid | epoch 689 | valid on 'valid' subset | loss 13.481 | nll_loss 12.9 | ppl 7641.89 | wps 42828 | wpb 510.9 | bsz 1 | num_updates 33521 | best_loss 8.937
2022-03-07 14:46:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 689 @ 33521 updates
2022-03-07 14:46:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:46:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:46:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 689 @ 33521 updates, score 13.481) (writing took 2.330152740702033 seconds)
2022-03-07 14:46:42 | INFO | fairseq_cli.train | end of epoch 689 (average epoch stats below)
2022-03-07 14:46:42 | INFO | train | epoch 689 | loss 2.045 | nll_loss 0.292 | ppl 1.22 | wps 24026.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33521 | lr 0.00017272 | gnorm 0.373 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 92647
2022-03-07 14:46:42 | INFO | fairseq.trainer | begin training epoch 690
2022-03-07 14:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:48:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:48:52 | INFO | valid | epoch 690 | valid on 'valid' subset | loss 13.506 | nll_loss 12.922 | ppl 7762.03 | wps 42807 | wpb 510.9 | bsz 1 | num_updates 33570 | best_loss 8.937
2022-03-07 14:48:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 690 @ 33570 updates
2022-03-07 14:48:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:48:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 690 @ 33570 updates, score 13.506) (writing took 2.3043055748566985 seconds)
2022-03-07 14:48:54 | INFO | fairseq_cli.train | end of epoch 690 (average epoch stats below)
2022-03-07 14:48:54 | INFO | train | epoch 690 | loss 2.044 | nll_loss 0.291 | ppl 1.22 | wps 24005.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 33570 | lr 0.000172593 | gnorm 0.365 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 92779
2022-03-07 14:48:54 | INFO | fairseq.trainer | begin training epoch 691
2022-03-07 14:48:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:49:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:50:15 | INFO | train_inner | epoch 691:     31 / 49 loss=2.044, nll_loss=0.29, ppl=1.22, wps=23778.1, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=33600, lr=0.000172516, gnorm=0.366, loss_scale=32, train_wall=233, gb_free=8.8, wall=92859
2022-03-07 14:51:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:51:06 | INFO | valid | epoch 691 | valid on 'valid' subset | loss 13.473 | nll_loss 12.89 | ppl 7589.03 | wps 41859 | wpb 510.9 | bsz 1 | num_updates 33618 | best_loss 8.937
2022-03-07 14:51:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 691 @ 33618 updates
2022-03-07 14:51:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:51:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:51:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 691 @ 33618 updates, score 13.473) (writing took 2.4431038140319288 seconds)
2022-03-07 14:51:08 | INFO | fairseq_cli.train | end of epoch 691 (average epoch stats below)
2022-03-07 14:51:08 | INFO | train | epoch 691 | loss 2.044 | nll_loss 0.29 | ppl 1.22 | wps 23264.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33618 | lr 0.00017247 | gnorm 0.369 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 92913
2022-03-07 14:51:08 | INFO | fairseq.trainer | begin training epoch 692
2022-03-07 14:51:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:53:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:53:21 | INFO | valid | epoch 692 | valid on 'valid' subset | loss 13.406 | nll_loss 12.815 | ppl 7208.28 | wps 39648.3 | wpb 510.9 | bsz 1 | num_updates 33667 | best_loss 8.937
2022-03-07 14:53:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 692 @ 33667 updates
2022-03-07 14:53:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:53:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:53:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 692 @ 33667 updates, score 13.406) (writing took 2.5152446418069303 seconds)
2022-03-07 14:53:23 | INFO | fairseq_cli.train | end of epoch 692 (average epoch stats below)
2022-03-07 14:53:23 | INFO | train | epoch 692 | loss 2.044 | nll_loss 0.29 | ppl 1.22 | wps 23515.6 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33667 | lr 0.000172345 | gnorm 0.361 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93048
2022-03-07 14:53:23 | INFO | fairseq.trainer | begin training epoch 693
2022-03-07 14:53:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:54:50 | INFO | train_inner | epoch 693:     33 / 49 loss=2.044, nll_loss=0.291, ppl=1.22, wps=23564.9, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=33700, lr=0.00017226, gnorm=0.364, loss_scale=32, train_wall=234, gb_free=8.8, wall=93135
2022-03-07 14:55:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:55:36 | INFO | valid | epoch 693 | valid on 'valid' subset | loss 13.451 | nll_loss 12.869 | ppl 7480.94 | wps 41514.7 | wpb 510.9 | bsz 1 | num_updates 33716 | best_loss 8.937
2022-03-07 14:55:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 693 @ 33716 updates
2022-03-07 14:55:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:55:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:55:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 693 @ 33716 updates, score 13.451) (writing took 2.3689902988262475 seconds)
2022-03-07 14:55:38 | INFO | fairseq_cli.train | end of epoch 693 (average epoch stats below)
2022-03-07 14:55:38 | INFO | train | epoch 693 | loss 2.044 | nll_loss 0.29 | ppl 1.22 | wps 23563.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33716 | lr 0.000172219 | gnorm 0.365 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93183
2022-03-07 14:55:38 | INFO | fairseq.trainer | begin training epoch 694
2022-03-07 14:55:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:55:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 14:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 14:57:51 | INFO | valid | epoch 694 | valid on 'valid' subset | loss 13.45 | nll_loss 12.864 | ppl 7452.53 | wps 41212.1 | wpb 510.9 | bsz 1 | num_updates 33764 | best_loss 8.937
2022-03-07 14:57:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 694 @ 33764 updates
2022-03-07 14:57:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:57:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 14:57:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 694 @ 33764 updates, score 13.45) (writing took 2.459101499989629 seconds)
2022-03-07 14:57:53 | INFO | fairseq_cli.train | end of epoch 694 (average epoch stats below)
2022-03-07 14:57:53 | INFO | train | epoch 694 | loss 2.044 | nll_loss 0.29 | ppl 1.22 | wps 23041.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33764 | lr 0.000172097 | gnorm 0.368 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93318
2022-03-07 14:57:53 | INFO | fairseq.trainer | begin training epoch 695
2022-03-07 14:57:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 14:59:28 | INFO | train_inner | epoch 695:     36 / 49 loss=2.043, nll_loss=0.29, ppl=1.22, wps=23358.1, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=33800, lr=0.000172005, gnorm=0.364, loss_scale=32, train_wall=237, gb_free=8.8, wall=93412
2022-03-07 15:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:00:05 | INFO | valid | epoch 695 | valid on 'valid' subset | loss 13.444 | nll_loss 12.86 | ppl 7436.73 | wps 44013.3 | wpb 510.9 | bsz 1 | num_updates 33813 | best_loss 8.937
2022-03-07 15:00:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 695 @ 33813 updates
2022-03-07 15:00:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:00:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:00:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 695 @ 33813 updates, score 13.444) (writing took 2.4532526112161577 seconds)
2022-03-07 15:00:07 | INFO | fairseq_cli.train | end of epoch 695 (average epoch stats below)
2022-03-07 15:00:07 | INFO | train | epoch 695 | loss 2.043 | nll_loss 0.289 | ppl 1.22 | wps 23671.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33813 | lr 0.000171972 | gnorm 0.36 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 93452
2022-03-07 15:00:07 | INFO | fairseq.trainer | begin training epoch 696
2022-03-07 15:00:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:01:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:02:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:02:20 | INFO | valid | epoch 696 | valid on 'valid' subset | loss 13.45 | nll_loss 12.863 | ppl 7449.07 | wps 41387.6 | wpb 510.9 | bsz 1 | num_updates 33861 | best_loss 8.937
2022-03-07 15:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 696 @ 33861 updates
2022-03-07 15:02:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:02:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 696 @ 33861 updates, score 13.45) (writing took 2.3393887178972363 seconds)
2022-03-07 15:02:22 | INFO | fairseq_cli.train | end of epoch 696 (average epoch stats below)
2022-03-07 15:02:22 | INFO | train | epoch 696 | loss 2.043 | nll_loss 0.29 | ppl 1.22 | wps 23130.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 33861 | lr 0.00017185 | gnorm 0.365 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 93587
2022-03-07 15:02:22 | INFO | fairseq.trainer | begin training epoch 697
2022-03-07 15:02:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:04:04 | INFO | train_inner | epoch 697:     39 / 49 loss=2.043, nll_loss=0.29, ppl=1.22, wps=23449.5, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=33900, lr=0.000171751, gnorm=0.364, loss_scale=32, train_wall=236, gb_free=8.8, wall=93689
2022-03-07 15:04:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:04:34 | INFO | valid | epoch 697 | valid on 'valid' subset | loss 13.487 | nll_loss 12.907 | ppl 7679.94 | wps 41642.1 | wpb 510.9 | bsz 1 | num_updates 33910 | best_loss 8.937
2022-03-07 15:04:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 697 @ 33910 updates
2022-03-07 15:04:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 697 @ 33910 updates, score 13.487) (writing took 2.53232332598418 seconds)
2022-03-07 15:04:37 | INFO | fairseq_cli.train | end of epoch 697 (average epoch stats below)
2022-03-07 15:04:37 | INFO | train | epoch 697 | loss 2.043 | nll_loss 0.29 | ppl 1.22 | wps 23547.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33910 | lr 0.000171726 | gnorm 0.366 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93722
2022-03-07 15:04:37 | INFO | fairseq.trainer | begin training epoch 698
2022-03-07 15:04:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:06:49 | INFO | valid | epoch 698 | valid on 'valid' subset | loss 13.466 | nll_loss 12.882 | ppl 7550.29 | wps 41209.6 | wpb 510.9 | bsz 1 | num_updates 33959 | best_loss 8.937
2022-03-07 15:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 698 @ 33959 updates
2022-03-07 15:06:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:06:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 698 @ 33959 updates, score 13.466) (writing took 2.3750201859511435 seconds)
2022-03-07 15:06:52 | INFO | fairseq_cli.train | end of epoch 698 (average epoch stats below)
2022-03-07 15:06:52 | INFO | train | epoch 698 | loss 2.043 | nll_loss 0.29 | ppl 1.22 | wps 23586.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 33959 | lr 0.000171602 | gnorm 0.366 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93856
2022-03-07 15:06:52 | INFO | fairseq.trainer | begin training epoch 699
2022-03-07 15:06:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:07:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:08:42 | INFO | train_inner | epoch 699:     42 / 49 loss=2.043, nll_loss=0.29, ppl=1.22, wps=23362.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34000, lr=0.000171499, gnorm=0.364, loss_scale=32, train_wall=237, gb_free=8.8, wall=93967
2022-03-07 15:08:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:09:04 | INFO | valid | epoch 699 | valid on 'valid' subset | loss 13.382 | nll_loss 12.794 | ppl 7103.02 | wps 41932.2 | wpb 510.9 | bsz 1 | num_updates 34007 | best_loss 8.937
2022-03-07 15:09:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 699 @ 34007 updates
2022-03-07 15:09:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:09:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:09:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 699 @ 34007 updates, score 13.382) (writing took 2.4102452658116817 seconds)
2022-03-07 15:09:06 | INFO | fairseq_cli.train | end of epoch 699 (average epoch stats below)
2022-03-07 15:09:06 | INFO | train | epoch 699 | loss 2.042 | nll_loss 0.289 | ppl 1.22 | wps 23094.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34007 | lr 0.000171481 | gnorm 0.361 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 93991
2022-03-07 15:09:07 | INFO | fairseq.trainer | begin training epoch 700
2022-03-07 15:09:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:11:19 | INFO | valid | epoch 700 | valid on 'valid' subset | loss 13.521 | nll_loss 12.943 | ppl 7876.03 | wps 42613.1 | wpb 510.9 | bsz 1 | num_updates 34056 | best_loss 8.937
2022-03-07 15:11:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 700 @ 34056 updates
2022-03-07 15:11:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:11:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:11:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 700 @ 34056 updates, score 13.521) (writing took 2.453614806756377 seconds)
2022-03-07 15:11:21 | INFO | fairseq_cli.train | end of epoch 700 (average epoch stats below)
2022-03-07 15:11:21 | INFO | train | epoch 700 | loss 2.043 | nll_loss 0.29 | ppl 1.22 | wps 23602 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34056 | lr 0.000171358 | gnorm 0.364 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 94126
2022-03-07 15:11:21 | INFO | fairseq.trainer | begin training epoch 701
2022-03-07 15:11:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:13:16 | INFO | train_inner | epoch 701:     44 / 49 loss=2.042, nll_loss=0.289, ppl=1.22, wps=23644.3, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34100, lr=0.000171247, gnorm=0.364, loss_scale=32, train_wall=234, gb_free=8.8, wall=94241
2022-03-07 15:13:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:13:33 | INFO | valid | epoch 701 | valid on 'valid' subset | loss 13.45 | nll_loss 12.867 | ppl 7469.68 | wps 41350.7 | wpb 510.9 | bsz 1 | num_updates 34105 | best_loss 8.937
2022-03-07 15:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 701 @ 34105 updates
2022-03-07 15:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 701 @ 34105 updates, score 13.45) (writing took 2.435473944991827 seconds)
2022-03-07 15:13:36 | INFO | fairseq_cli.train | end of epoch 701 (average epoch stats below)
2022-03-07 15:13:36 | INFO | train | epoch 701 | loss 2.042 | nll_loss 0.289 | ppl 1.22 | wps 23611.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34105 | lr 0.000171234 | gnorm 0.362 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 94260
2022-03-07 15:13:36 | INFO | fairseq.trainer | begin training epoch 702
2022-03-07 15:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:13:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:15:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:15:46 | INFO | valid | epoch 702 | valid on 'valid' subset | loss 13.475 | nll_loss 12.891 | ppl 7596.46 | wps 42665 | wpb 510.9 | bsz 1 | num_updates 34153 | best_loss 8.937
2022-03-07 15:15:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 702 @ 34153 updates
2022-03-07 15:15:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:15:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:15:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 702 @ 34153 updates, score 13.475) (writing took 2.3871979410760105 seconds)
2022-03-07 15:15:48 | INFO | fairseq_cli.train | end of epoch 702 (average epoch stats below)
2022-03-07 15:15:48 | INFO | train | epoch 702 | loss 2.042 | nll_loss 0.289 | ppl 1.22 | wps 23535.4 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34153 | lr 0.000171114 | gnorm 0.363 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 94393
2022-03-07 15:15:48 | INFO | fairseq.trainer | begin training epoch 703
2022-03-07 15:15:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:17:49 | INFO | train_inner | epoch 703:     47 / 49 loss=2.042, nll_loss=0.289, ppl=1.22, wps=23743.2, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=34200, lr=0.000170996, gnorm=0.363, loss_scale=32, train_wall=233, gb_free=8.8, wall=94514
2022-03-07 15:17:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:17:59 | INFO | valid | epoch 703 | valid on 'valid' subset | loss 13.456 | nll_loss 12.871 | ppl 7491.81 | wps 41472.7 | wpb 510.9 | bsz 1 | num_updates 34202 | best_loss 8.937
2022-03-07 15:17:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 703 @ 34202 updates
2022-03-07 15:17:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:18:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 703 @ 34202 updates, score 13.456) (writing took 2.3772715004161 seconds)
2022-03-07 15:18:01 | INFO | fairseq_cli.train | end of epoch 703 (average epoch stats below)
2022-03-07 15:18:01 | INFO | train | epoch 703 | loss 2.042 | nll_loss 0.289 | ppl 1.22 | wps 23888 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34202 | lr 0.000170991 | gnorm 0.364 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 94526
2022-03-07 15:18:01 | INFO | fairseq.trainer | begin training epoch 704
2022-03-07 15:18:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:20:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:20:13 | INFO | valid | epoch 704 | valid on 'valid' subset | loss 13.421 | nll_loss 12.836 | ppl 7310.95 | wps 41040.7 | wpb 510.9 | bsz 1 | num_updates 34251 | best_loss 8.937
2022-03-07 15:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 704 @ 34251 updates
2022-03-07 15:20:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:20:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:20:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 704 @ 34251 updates, score 13.421) (writing took 2.3688547550700605 seconds)
2022-03-07 15:20:16 | INFO | fairseq_cli.train | end of epoch 704 (average epoch stats below)
2022-03-07 15:20:16 | INFO | train | epoch 704 | loss 2.041 | nll_loss 0.288 | ppl 1.22 | wps 23610 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34251 | lr 0.000170869 | gnorm 0.359 | loss_scale 64 | train_wall 114 | gb_free 8.8 | wall 94660
2022-03-07 15:20:16 | INFO | fairseq.trainer | begin training epoch 705
2022-03-07 15:20:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:22:23 | INFO | train_inner | epoch 705:     49 / 49 loss=2.041, nll_loss=0.288, ppl=1.22, wps=23630.5, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=34300, lr=0.000170747, gnorm=0.363, loss_scale=64, train_wall=233, gb_free=8.8, wall=94787
2022-03-07 15:22:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:22:28 | INFO | valid | epoch 705 | valid on 'valid' subset | loss 13.473 | nll_loss 12.891 | ppl 7594.29 | wps 41696.1 | wpb 510.9 | bsz 1 | num_updates 34300 | best_loss 8.937
2022-03-07 15:22:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 705 @ 34300 updates
2022-03-07 15:22:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:22:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:22:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 705 @ 34300 updates, score 13.473) (writing took 2.3422460150904953 seconds)
2022-03-07 15:22:30 | INFO | fairseq_cli.train | end of epoch 705 (average epoch stats below)
2022-03-07 15:22:30 | INFO | train | epoch 705 | loss 2.041 | nll_loss 0.288 | ppl 1.22 | wps 23612.5 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34300 | lr 0.000170747 | gnorm 0.364 | loss_scale 64 | train_wall 115 | gb_free 8.8 | wall 94795
2022-03-07 15:22:30 | INFO | fairseq.trainer | begin training epoch 706
2022-03-07 15:22:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:22:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:24:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:24:42 | INFO | valid | epoch 706 | valid on 'valid' subset | loss 13.458 | nll_loss 12.872 | ppl 7497.61 | wps 40290 | wpb 510.9 | bsz 1 | num_updates 34348 | best_loss 8.937
2022-03-07 15:24:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 706 @ 34348 updates
2022-03-07 15:24:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:24:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:24:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 706 @ 34348 updates, score 13.458) (writing took 2.4654965568333864 seconds)
2022-03-07 15:24:45 | INFO | fairseq_cli.train | end of epoch 706 (average epoch stats below)
2022-03-07 15:24:45 | INFO | train | epoch 706 | loss 2.041 | nll_loss 0.288 | ppl 1.22 | wps 23107.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34348 | lr 0.000170628 | gnorm 0.368 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 94930
2022-03-07 15:24:45 | INFO | fairseq.trainer | begin training epoch 707
2022-03-07 15:24:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:26:57 | INFO | valid | epoch 707 | valid on 'valid' subset | loss 13.403 | nll_loss 12.817 | ppl 7216.67 | wps 41489.3 | wpb 510.9 | bsz 1 | num_updates 34397 | best_loss 8.937
2022-03-07 15:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 707 @ 34397 updates
2022-03-07 15:26:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:27:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:27:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 707 @ 34397 updates, score 13.403) (writing took 2.502997543197125 seconds)
2022-03-07 15:27:00 | INFO | fairseq_cli.train | end of epoch 707 (average epoch stats below)
2022-03-07 15:27:00 | INFO | train | epoch 707 | loss 2.041 | nll_loss 0.288 | ppl 1.22 | wps 23587.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34397 | lr 0.000170506 | gnorm 0.359 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95064
2022-03-07 15:27:00 | INFO | fairseq.trainer | begin training epoch 708
2022-03-07 15:27:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:27:08 | INFO | train_inner | epoch 708:      3 / 49 loss=2.041, nll_loss=0.288, ppl=1.22, wps=22761.8, ups=0.35, wpb=64871.8, bsz=126.7, num_updates=34400, lr=0.000170499, gnorm=0.363, loss_scale=32, train_wall=236, gb_free=8.8, wall=95072
2022-03-07 15:28:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:29:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:29:12 | INFO | valid | epoch 708 | valid on 'valid' subset | loss 13.517 | nll_loss 12.937 | ppl 7844.17 | wps 42237.3 | wpb 510.9 | bsz 1 | num_updates 34445 | best_loss 8.937
2022-03-07 15:29:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 708 @ 34445 updates
2022-03-07 15:29:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:29:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:29:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 708 @ 34445 updates, score 13.517) (writing took 2.495164154097438 seconds)
2022-03-07 15:29:14 | INFO | fairseq_cli.train | end of epoch 708 (average epoch stats below)
2022-03-07 15:29:14 | INFO | train | epoch 708 | loss 2.041 | nll_loss 0.288 | ppl 1.22 | wps 23153.3 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34445 | lr 0.000170387 | gnorm 0.363 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 95199
2022-03-07 15:29:14 | INFO | fairseq.trainer | begin training epoch 709
2022-03-07 15:29:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:31:26 | INFO | valid | epoch 709 | valid on 'valid' subset | loss 13.423 | nll_loss 12.837 | ppl 7314.6 | wps 42013.5 | wpb 510.9 | bsz 1 | num_updates 34494 | best_loss 8.937
2022-03-07 15:31:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 709 @ 34494 updates
2022-03-07 15:31:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:31:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:31:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 709 @ 34494 updates, score 13.423) (writing took 2.4626630302518606 seconds)
2022-03-07 15:31:29 | INFO | fairseq_cli.train | end of epoch 709 (average epoch stats below)
2022-03-07 15:31:29 | INFO | train | epoch 709 | loss 2.04 | nll_loss 0.288 | ppl 1.22 | wps 23614.9 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34494 | lr 0.000170266 | gnorm 0.363 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95333
2022-03-07 15:31:29 | INFO | fairseq.trainer | begin training epoch 710
2022-03-07 15:31:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:31:44 | INFO | train_inner | epoch 710:      6 / 49 loss=2.041, nll_loss=0.288, ppl=1.22, wps=23435.6, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34500, lr=0.000170251, gnorm=0.363, loss_scale=32, train_wall=236, gb_free=8.8, wall=95349
2022-03-07 15:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:33:41 | INFO | valid | epoch 710 | valid on 'valid' subset | loss 13.43 | nll_loss 12.846 | ppl 7362.22 | wps 41888.6 | wpb 510.9 | bsz 1 | num_updates 34543 | best_loss 8.937
2022-03-07 15:33:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 710 @ 34543 updates
2022-03-07 15:33:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:33:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:33:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 710 @ 34543 updates, score 13.43) (writing took 2.3453919999301434 seconds)
2022-03-07 15:33:43 | INFO | fairseq_cli.train | end of epoch 710 (average epoch stats below)
2022-03-07 15:33:43 | INFO | train | epoch 710 | loss 2.041 | nll_loss 0.288 | ppl 1.22 | wps 23667.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34543 | lr 0.000170145 | gnorm 0.362 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 95468
2022-03-07 15:33:43 | INFO | fairseq.trainer | begin training epoch 711
2022-03-07 15:33:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:35:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:35:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:35:55 | INFO | valid | epoch 711 | valid on 'valid' subset | loss 13.427 | nll_loss 12.843 | ppl 7349.3 | wps 41705.4 | wpb 510.9 | bsz 1 | num_updates 34591 | best_loss 8.937
2022-03-07 15:35:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 711 @ 34591 updates
2022-03-07 15:35:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:35:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 711 @ 34591 updates, score 13.427) (writing took 2.5601374469697475 seconds)
2022-03-07 15:35:58 | INFO | fairseq_cli.train | end of epoch 711 (average epoch stats below)
2022-03-07 15:35:58 | INFO | train | epoch 711 | loss 2.041 | nll_loss 0.288 | ppl 1.22 | wps 23101.9 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34591 | lr 0.000170027 | gnorm 0.361 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 95602
2022-03-07 15:35:58 | INFO | fairseq.trainer | begin training epoch 712
2022-03-07 15:35:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:36:21 | INFO | train_inner | epoch 712:      9 / 49 loss=2.04, nll_loss=0.288, ppl=1.22, wps=23434.1, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34600, lr=0.000170005, gnorm=0.361, loss_scale=32, train_wall=236, gb_free=8.8, wall=95626
2022-03-07 15:38:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:38:10 | INFO | valid | epoch 712 | valid on 'valid' subset | loss 13.485 | nll_loss 12.905 | ppl 7669.55 | wps 42691.7 | wpb 510.9 | bsz 1 | num_updates 34640 | best_loss 8.937
2022-03-07 15:38:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 712 @ 34640 updates
2022-03-07 15:38:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:38:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:38:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 712 @ 34640 updates, score 13.485) (writing took 2.4889460122212768 seconds)
2022-03-07 15:38:12 | INFO | fairseq_cli.train | end of epoch 712 (average epoch stats below)
2022-03-07 15:38:12 | INFO | train | epoch 712 | loss 2.04 | nll_loss 0.288 | ppl 1.22 | wps 23638.8 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34640 | lr 0.000169907 | gnorm 0.36 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 95737
2022-03-07 15:38:12 | INFO | fairseq.trainer | begin training epoch 713
2022-03-07 15:38:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:40:24 | INFO | valid | epoch 713 | valid on 'valid' subset | loss 13.48 | nll_loss 12.894 | ppl 7610.79 | wps 41715.1 | wpb 510.9 | bsz 1 | num_updates 34689 | best_loss 8.937
2022-03-07 15:40:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 713 @ 34689 updates
2022-03-07 15:40:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:40:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 713 @ 34689 updates, score 13.48) (writing took 2.3938955599442124 seconds)
2022-03-07 15:40:27 | INFO | fairseq_cli.train | end of epoch 713 (average epoch stats below)
2022-03-07 15:40:27 | INFO | train | epoch 713 | loss 2.04 | nll_loss 0.288 | ppl 1.22 | wps 23646.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 34689 | lr 0.000169787 | gnorm 0.365 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 95871
2022-03-07 15:40:27 | INFO | fairseq.trainer | begin training epoch 714
2022-03-07 15:40:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:40:55 | INFO | train_inner | epoch 714:     11 / 49 loss=2.04, nll_loss=0.288, ppl=1.22, wps=23668.4, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=34700, lr=0.00016976, gnorm=0.363, loss_scale=32, train_wall=234, gb_free=8.8, wall=95900
2022-03-07 15:41:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:42:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:42:38 | INFO | valid | epoch 714 | valid on 'valid' subset | loss 13.501 | nll_loss 12.916 | ppl 7728.55 | wps 43990.1 | wpb 510.9 | bsz 1 | num_updates 34737 | best_loss 8.937
2022-03-07 15:42:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 714 @ 34737 updates
2022-03-07 15:42:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:42:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:42:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 714 @ 34737 updates, score 13.501) (writing took 2.3320377906784415 seconds)
2022-03-07 15:42:40 | INFO | fairseq_cli.train | end of epoch 714 (average epoch stats below)
2022-03-07 15:42:40 | INFO | train | epoch 714 | loss 2.04 | nll_loss 0.288 | ppl 1.22 | wps 23289.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34737 | lr 0.00016967 | gnorm 0.363 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 96005
2022-03-07 15:42:40 | INFO | fairseq.trainer | begin training epoch 715
2022-03-07 15:42:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:44:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:44:50 | INFO | valid | epoch 715 | valid on 'valid' subset | loss 13.519 | nll_loss 12.942 | ppl 7869.84 | wps 43461.1 | wpb 510.9 | bsz 1 | num_updates 34786 | best_loss 8.937
2022-03-07 15:44:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 715 @ 34786 updates
2022-03-07 15:44:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:44:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:44:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 715 @ 34786 updates, score 13.519) (writing took 2.4146067332476377 seconds)
2022-03-07 15:44:52 | INFO | fairseq_cli.train | end of epoch 715 (average epoch stats below)
2022-03-07 15:44:52 | INFO | train | epoch 715 | loss 2.04 | nll_loss 0.288 | ppl 1.22 | wps 24030.7 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34786 | lr 0.00016955 | gnorm 0.368 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 96137
2022-03-07 15:44:52 | INFO | fairseq.trainer | begin training epoch 716
2022-03-07 15:44:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:45:29 | INFO | train_inner | epoch 716:     14 / 49 loss=2.04, nll_loss=0.288, ppl=1.22, wps=23734.4, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=34800, lr=0.000169516, gnorm=0.366, loss_scale=32, train_wall=233, gb_free=8.8, wall=96173
2022-03-07 15:46:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:47:02 | INFO | valid | epoch 716 | valid on 'valid' subset | loss 13.485 | nll_loss 12.909 | ppl 7689.9 | wps 42821 | wpb 510.9 | bsz 1 | num_updates 34835 | best_loss 8.937
2022-03-07 15:47:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 716 @ 34835 updates
2022-03-07 15:47:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:47:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:47:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 716 @ 34835 updates, score 13.485) (writing took 2.427102972753346 seconds)
2022-03-07 15:47:05 | INFO | fairseq_cli.train | end of epoch 716 (average epoch stats below)
2022-03-07 15:47:05 | INFO | train | epoch 716 | loss 2.039 | nll_loss 0.287 | ppl 1.22 | wps 24006.4 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34835 | lr 0.000169431 | gnorm 0.364 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 96270
2022-03-07 15:47:05 | INFO | fairseq.trainer | begin training epoch 717
2022-03-07 15:47:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:48:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:49:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:49:15 | INFO | valid | epoch 717 | valid on 'valid' subset | loss 13.405 | nll_loss 12.819 | ppl 7223.92 | wps 43100.1 | wpb 510.9 | bsz 1 | num_updates 34883 | best_loss 8.937
2022-03-07 15:49:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 717 @ 34883 updates
2022-03-07 15:49:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:49:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:49:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 717 @ 34883 updates, score 13.405) (writing took 2.4655531789176166 seconds)
2022-03-07 15:49:17 | INFO | fairseq_cli.train | end of epoch 717 (average epoch stats below)
2022-03-07 15:49:17 | INFO | train | epoch 717 | loss 2.039 | nll_loss 0.287 | ppl 1.22 | wps 23515.5 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 34883 | lr 0.000169314 | gnorm 0.363 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 96402
2022-03-07 15:49:17 | INFO | fairseq.trainer | begin training epoch 718
2022-03-07 15:49:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:50:01 | INFO | train_inner | epoch 718:     17 / 49 loss=2.039, nll_loss=0.287, ppl=1.22, wps=23817.1, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=34900, lr=0.000169273, gnorm=0.362, loss_scale=32, train_wall=232, gb_free=8.8, wall=96446
2022-03-07 15:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:51:27 | INFO | valid | epoch 718 | valid on 'valid' subset | loss 13.436 | nll_loss 12.849 | ppl 7378.39 | wps 42974.1 | wpb 510.9 | bsz 1 | num_updates 34932 | best_loss 8.937
2022-03-07 15:51:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 718 @ 34932 updates
2022-03-07 15:51:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:51:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 718 @ 34932 updates, score 13.436) (writing took 2.393421556800604 seconds)
2022-03-07 15:51:29 | INFO | fairseq_cli.train | end of epoch 718 (average epoch stats below)
2022-03-07 15:51:29 | INFO | train | epoch 718 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 24042.5 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34932 | lr 0.000169195 | gnorm 0.356 | loss_scale 32 | train_wall 112 | gb_free 8.8 | wall 96534
2022-03-07 15:51:29 | INFO | fairseq.trainer | begin training epoch 719
2022-03-07 15:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:53:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:53:41 | INFO | valid | epoch 719 | valid on 'valid' subset | loss 13.49 | nll_loss 12.907 | ppl 7678.74 | wps 41668.1 | wpb 510.9 | bsz 1 | num_updates 34981 | best_loss 8.937
2022-03-07 15:53:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 719 @ 34981 updates
2022-03-07 15:53:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:53:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:53:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 719 @ 34981 updates, score 13.49) (writing took 2.460030316375196 seconds)
2022-03-07 15:53:43 | INFO | fairseq_cli.train | end of epoch 719 (average epoch stats below)
2022-03-07 15:53:43 | INFO | train | epoch 719 | loss 2.039 | nll_loss 0.287 | ppl 1.22 | wps 23723 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 34981 | lr 0.000169077 | gnorm 0.372 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 96668
2022-03-07 15:53:43 | INFO | fairseq.trainer | begin training epoch 720
2022-03-07 15:53:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:54:33 | INFO | train_inner | epoch 720:     19 / 49 loss=2.039, nll_loss=0.287, ppl=1.22, wps=23817.9, ups=0.37, wpb=64876.2, bsz=126.7, num_updates=35000, lr=0.000169031, gnorm=0.366, loss_scale=64, train_wall=232, gb_free=8.8, wall=96718
2022-03-07 15:54:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 15:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:55:56 | INFO | valid | epoch 720 | valid on 'valid' subset | loss 13.541 | nll_loss 12.965 | ppl 7996.35 | wps 40154.8 | wpb 510.9 | bsz 1 | num_updates 35029 | best_loss 8.937
2022-03-07 15:55:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 720 @ 35029 updates
2022-03-07 15:55:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:55:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 720 @ 35029 updates, score 13.541) (writing took 2.4801731039769948 seconds)
2022-03-07 15:55:58 | INFO | fairseq_cli.train | end of epoch 720 (average epoch stats below)
2022-03-07 15:55:58 | INFO | train | epoch 720 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 23027.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35029 | lr 0.000168961 | gnorm 0.364 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 96803
2022-03-07 15:55:58 | INFO | fairseq.trainer | begin training epoch 721
2022-03-07 15:55:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 15:58:11 | INFO | valid | epoch 721 | valid on 'valid' subset | loss 13.463 | nll_loss 12.877 | ppl 7520.49 | wps 41136.8 | wpb 510.9 | bsz 1 | num_updates 35078 | best_loss 8.937
2022-03-07 15:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 721 @ 35078 updates
2022-03-07 15:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 15:58:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 721 @ 35078 updates, score 13.463) (writing took 2.3783544758334756 seconds)
2022-03-07 15:58:13 | INFO | fairseq_cli.train | end of epoch 721 (average epoch stats below)
2022-03-07 15:58:13 | INFO | train | epoch 721 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 23556.3 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35078 | lr 0.000168843 | gnorm 0.358 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 96938
2022-03-07 15:58:13 | INFO | fairseq.trainer | begin training epoch 722
2022-03-07 15:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 15:59:11 | INFO | train_inner | epoch 722:     22 / 49 loss=2.038, nll_loss=0.286, ppl=1.22, wps=23343.2, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=35100, lr=0.00016879, gnorm=0.359, loss_scale=32, train_wall=237, gb_free=8.8, wall=96996
2022-03-07 16:00:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:00:26 | INFO | valid | epoch 722 | valid on 'valid' subset | loss 13.441 | nll_loss 12.859 | ppl 7428.71 | wps 41244.7 | wpb 510.9 | bsz 1 | num_updates 35127 | best_loss 8.937
2022-03-07 16:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 722 @ 35127 updates
2022-03-07 16:00:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:00:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:00:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 722 @ 35127 updates, score 13.441) (writing took 2.3862358019687235 seconds)
2022-03-07 16:00:28 | INFO | fairseq_cli.train | end of epoch 722 (average epoch stats below)
2022-03-07 16:00:28 | INFO | train | epoch 722 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 23526 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35127 | lr 0.000168725 | gnorm 0.359 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97073
2022-03-07 16:00:28 | INFO | fairseq.trainer | begin training epoch 723
2022-03-07 16:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:01:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:02:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:02:41 | INFO | valid | epoch 723 | valid on 'valid' subset | loss 13.481 | nll_loss 12.898 | ppl 7631.8 | wps 42121.5 | wpb 510.9 | bsz 1 | num_updates 35175 | best_loss 8.937
2022-03-07 16:02:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 723 @ 35175 updates
2022-03-07 16:02:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:02:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:02:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 723 @ 35175 updates, score 13.481) (writing took 2.345793799031526 seconds)
2022-03-07 16:02:43 | INFO | fairseq_cli.train | end of epoch 723 (average epoch stats below)
2022-03-07 16:02:43 | INFO | train | epoch 723 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 23112.7 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35175 | lr 0.00016861 | gnorm 0.362 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97208
2022-03-07 16:02:43 | INFO | fairseq.trainer | begin training epoch 724
2022-03-07 16:02:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:03:49 | INFO | train_inner | epoch 724:     25 / 49 loss=2.038, nll_loss=0.286, ppl=1.22, wps=23367.3, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=35200, lr=0.00016855, gnorm=0.362, loss_scale=32, train_wall=237, gb_free=8.8, wall=97274
2022-03-07 16:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:04:56 | INFO | valid | epoch 724 | valid on 'valid' subset | loss 13.471 | nll_loss 12.891 | ppl 7595.65 | wps 41987.7 | wpb 510.9 | bsz 1 | num_updates 35224 | best_loss 8.937
2022-03-07 16:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 724 @ 35224 updates
2022-03-07 16:04:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:04:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 724 @ 35224 updates, score 13.471) (writing took 2.384370224084705 seconds)
2022-03-07 16:04:58 | INFO | fairseq_cli.train | end of epoch 724 (average epoch stats below)
2022-03-07 16:04:58 | INFO | train | epoch 724 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 23531.4 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35224 | lr 0.000168493 | gnorm 0.363 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97343
2022-03-07 16:04:58 | INFO | fairseq.trainer | begin training epoch 725
2022-03-07 16:04:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:07:11 | INFO | valid | epoch 725 | valid on 'valid' subset | loss 13.493 | nll_loss 12.911 | ppl 7704.25 | wps 40829.7 | wpb 510.9 | bsz 1 | num_updates 35273 | best_loss 8.937
2022-03-07 16:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 725 @ 35273 updates
2022-03-07 16:07:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:07:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:07:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 725 @ 35273 updates, score 13.493) (writing took 2.4879343770444393 seconds)
2022-03-07 16:07:13 | INFO | fairseq_cli.train | end of epoch 725 (average epoch stats below)
2022-03-07 16:07:13 | INFO | train | epoch 725 | loss 2.037 | nll_loss 0.286 | ppl 1.22 | wps 23528.1 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35273 | lr 0.000168375 | gnorm 0.358 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97478
2022-03-07 16:07:13 | INFO | fairseq.trainer | begin training epoch 726
2022-03-07 16:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:07:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:08:27 | INFO | train_inner | epoch 726:     28 / 49 loss=2.038, nll_loss=0.286, ppl=1.22, wps=23370.7, ups=0.36, wpb=64871.8, bsz=126.7, num_updates=35300, lr=0.000168311, gnorm=0.361, loss_scale=32, train_wall=236, gb_free=8.8, wall=97551
2022-03-07 16:09:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:09:26 | INFO | valid | epoch 726 | valid on 'valid' subset | loss 13.443 | nll_loss 12.863 | ppl 7451.94 | wps 41132.7 | wpb 510.9 | bsz 1 | num_updates 35321 | best_loss 8.937
2022-03-07 16:09:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 726 @ 35321 updates
2022-03-07 16:09:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:09:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 726 @ 35321 updates, score 13.443) (writing took 2.4440767862834036 seconds)
2022-03-07 16:09:28 | INFO | fairseq_cli.train | end of epoch 726 (average epoch stats below)
2022-03-07 16:09:28 | INFO | train | epoch 726 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 23077.6 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35321 | lr 0.000168261 | gnorm 0.361 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97613
2022-03-07 16:09:28 | INFO | fairseq.trainer | begin training epoch 727
2022-03-07 16:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:11:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:11:41 | INFO | valid | epoch 727 | valid on 'valid' subset | loss 13.465 | nll_loss 12.88 | ppl 7537.72 | wps 41143 | wpb 510.9 | bsz 1 | num_updates 35370 | best_loss 8.937
2022-03-07 16:11:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 727 @ 35370 updates
2022-03-07 16:11:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:11:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:11:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 727 @ 35370 updates, score 13.465) (writing took 2.431670479942113 seconds)
2022-03-07 16:11:43 | INFO | fairseq_cli.train | end of epoch 727 (average epoch stats below)
2022-03-07 16:11:43 | INFO | train | epoch 727 | loss 2.038 | nll_loss 0.286 | ppl 1.22 | wps 23537.7 | ups 0.36 | wpb 64858.2 | bsz 126.7 | num_updates 35370 | lr 0.000168144 | gnorm 0.36 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97748
2022-03-07 16:11:43 | INFO | fairseq.trainer | begin training epoch 728
2022-03-07 16:11:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:13:02 | INFO | train_inner | epoch 728:     30 / 49 loss=2.037, nll_loss=0.285, ppl=1.22, wps=23566, ups=0.36, wpb=64867.4, bsz=126.7, num_updates=35400, lr=0.000168073, gnorm=0.358, loss_scale=32, train_wall=234, gb_free=8.8, wall=97827
2022-03-07 16:13:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:13:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:13:55 | INFO | valid | epoch 728 | valid on 'valid' subset | loss 13.414 | nll_loss 12.829 | ppl 7276.94 | wps 42184.4 | wpb 510.9 | bsz 1 | num_updates 35418 | best_loss 8.937
2022-03-07 16:13:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 728 @ 35418 updates
2022-03-07 16:13:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:13:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:13:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 728 @ 35418 updates, score 13.414) (writing took 2.50691699096933 seconds)
2022-03-07 16:13:58 | INFO | fairseq_cli.train | end of epoch 728 (average epoch stats below)
2022-03-07 16:13:58 | INFO | train | epoch 728 | loss 2.036 | nll_loss 0.285 | ppl 1.22 | wps 23079.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35418 | lr 0.00016803 | gnorm 0.355 | loss_scale 32 | train_wall 115 | gb_free 8.8 | wall 97883
2022-03-07 16:13:58 | INFO | fairseq.trainer | begin training epoch 729
2022-03-07 16:13:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:16:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:16:10 | INFO | valid | epoch 729 | valid on 'valid' subset | loss 13.429 | nll_loss 12.846 | ppl 7363.91 | wps 43329.2 | wpb 510.9 | bsz 1 | num_updates 35467 | best_loss 8.937
2022-03-07 16:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 729 @ 35467 updates
2022-03-07 16:16:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:16:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:16:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 729 @ 35467 updates, score 13.429) (writing took 2.370353430043906 seconds)
2022-03-07 16:16:12 | INFO | fairseq_cli.train | end of epoch 729 (average epoch stats below)
2022-03-07 16:16:12 | INFO | train | epoch 729 | loss 2.036 | nll_loss 0.285 | ppl 1.22 | wps 23704.6 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35467 | lr 0.000167914 | gnorm 0.359 | loss_scale 32 | train_wall 114 | gb_free 8.8 | wall 98017
2022-03-07 16:16:12 | INFO | fairseq.trainer | begin training epoch 730
2022-03-07 16:16:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:17:37 | INFO | train_inner | epoch 730:     33 / 49 loss=2.037, nll_loss=0.285, ppl=1.22, wps=23554, ups=0.36, wpb=64876.2, bsz=126.7, num_updates=35500, lr=0.000167836, gnorm=0.359, loss_scale=32, train_wall=235, gb_free=8.8, wall=98102
2022-03-07 16:18:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:18:22 | INFO | valid | epoch 730 | valid on 'valid' subset | loss 13.414 | nll_loss 12.83 | ppl 7280.35 | wps 42328.2 | wpb 510.9 | bsz 1 | num_updates 35516 | best_loss 8.937
2022-03-07 16:18:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 730 @ 35516 updates
2022-03-07 16:18:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:18:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:18:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 730 @ 35516 updates, score 13.414) (writing took 2.452133949380368 seconds)
2022-03-07 16:18:25 | INFO | fairseq_cli.train | end of epoch 730 (average epoch stats below)
2022-03-07 16:18:25 | INFO | train | epoch 730 | loss 2.037 | nll_loss 0.286 | ppl 1.22 | wps 23943.1 | ups 0.37 | wpb 64858.2 | bsz 126.7 | num_updates 35516 | lr 0.000167798 | gnorm 0.36 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 98150
2022-03-07 16:18:25 | INFO | fairseq.trainer | begin training epoch 731
2022-03-07 16:18:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:19:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:20:35 | INFO | valid | epoch 731 | valid on 'valid' subset | loss 13.449 | nll_loss 12.865 | ppl 7460 | wps 43537.5 | wpb 510.9 | bsz 1 | num_updates 35564 | best_loss 8.937
2022-03-07 16:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 731 @ 35564 updates
2022-03-07 16:20:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 731 @ 35564 updates, score 13.449) (writing took 2.539177775848657 seconds)
2022-03-07 16:20:37 | INFO | fairseq_cli.train | end of epoch 731 (average epoch stats below)
2022-03-07 16:20:37 | INFO | train | epoch 731 | loss 2.036 | nll_loss 0.285 | ppl 1.22 | wps 23496.2 | ups 0.36 | wpb 64844.1 | bsz 126.7 | num_updates 35564 | lr 0.000167685 | gnorm 0.36 | loss_scale 32 | train_wall 113 | gb_free 8.8 | wall 98282
2022-03-07 16:20:37 | INFO | fairseq.trainer | begin training epoch 732
2022-03-07 16:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:22:06 | INFO | train_inner | epoch 732:     36 / 49 loss=2.036, nll_loss=0.285, ppl=1.22, wps=24162.5, ups=0.37, wpb=64867.4, bsz=126.7, num_updates=35600, lr=0.0001676, gnorm=0.358, loss_scale=32, train_wall=228, gb_free=8.8, wall=98371
2022-03-07 16:22:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:22:41 | INFO | valid | epoch 732 | valid on 'valid' subset | loss 13.441 | nll_loss 12.859 | ppl 7429.29 | wps 47943.9 | wpb 510.9 | bsz 1 | num_updates 35613 | best_loss 8.937
2022-03-07 16:22:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 732 @ 35613 updates
2022-03-07 16:22:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:22:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:22:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 732 @ 35613 updates, score 13.441) (writing took 2.232933976687491 seconds)
2022-03-07 16:22:43 | INFO | fairseq_cli.train | end of epoch 732 (average epoch stats below)
2022-03-07 16:22:43 | INFO | train | epoch 732 | loss 2.036 | nll_loss 0.285 | ppl 1.22 | wps 25280.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35613 | lr 0.00016757 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98408
2022-03-07 16:22:43 | INFO | fairseq.trainer | begin training epoch 733
2022-03-07 16:22:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:24:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:24:46 | INFO | valid | epoch 733 | valid on 'valid' subset | loss 13.521 | nll_loss 12.946 | ppl 7893.2 | wps 48472 | wpb 510.9 | bsz 1 | num_updates 35662 | best_loss 8.937
2022-03-07 16:24:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 733 @ 35662 updates
2022-03-07 16:24:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:24:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 733 @ 35662 updates, score 13.521) (writing took 2.259642221033573 seconds)
2022-03-07 16:24:48 | INFO | fairseq_cli.train | end of epoch 733 (average epoch stats below)
2022-03-07 16:24:48 | INFO | train | epoch 733 | loss 2.036 | nll_loss 0.285 | ppl 1.22 | wps 25394.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35662 | lr 0.000167455 | gnorm 0.37 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 98533
2022-03-07 16:24:48 | INFO | fairseq.trainer | begin training epoch 734
2022-03-07 16:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:25:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:26:23 | INFO | train_inner | epoch 734:     39 / 49 loss=2.036, nll_loss=0.285, ppl=1.22, wps=25175.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35700, lr=0.000167365, gnorm=0.365, loss_scale=32, train_wall=220, gb_free=8.8, wall=98628
2022-03-07 16:26:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:26:51 | INFO | valid | epoch 734 | valid on 'valid' subset | loss 13.492 | nll_loss 12.913 | ppl 7714.93 | wps 47886.5 | wpb 510.9 | bsz 1 | num_updates 35710 | best_loss 8.937
2022-03-07 16:26:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 734 @ 35710 updates
2022-03-07 16:26:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:26:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:26:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 734 @ 35710 updates, score 13.492) (writing took 2.447935023345053 seconds)
2022-03-07 16:26:54 | INFO | fairseq_cli.train | end of epoch 734 (average epoch stats below)
2022-03-07 16:26:54 | INFO | train | epoch 734 | loss 2.036 | nll_loss 0.285 | ppl 1.22 | wps 24789.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35710 | lr 0.000167342 | gnorm 0.363 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 98658
2022-03-07 16:26:54 | INFO | fairseq.trainer | begin training epoch 735
2022-03-07 16:26:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:28:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:28:56 | INFO | valid | epoch 735 | valid on 'valid' subset | loss 13.527 | nll_loss 12.953 | ppl 7928.92 | wps 48245.2 | wpb 510.9 | bsz 1 | num_updates 35759 | best_loss 8.937
2022-03-07 16:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 735 @ 35759 updates
2022-03-07 16:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:28:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:28:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 735 @ 35759 updates, score 13.527) (writing took 2.3243763190694153 seconds)
2022-03-07 16:28:59 | INFO | fairseq_cli.train | end of epoch 735 (average epoch stats below)
2022-03-07 16:28:59 | INFO | train | epoch 735 | loss 2.035 | nll_loss 0.285 | ppl 1.22 | wps 25407.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35759 | lr 0.000167227 | gnorm 0.357 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 98784
2022-03-07 16:28:59 | INFO | fairseq.trainer | begin training epoch 736
2022-03-07 16:28:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:30:39 | INFO | train_inner | epoch 736:     41 / 49 loss=2.036, nll_loss=0.285, ppl=1.22, wps=25394.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35800, lr=0.000167132, gnorm=0.359, loss_scale=32, train_wall=217, gb_free=8.8, wall=98884
2022-03-07 16:30:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:31:02 | INFO | valid | epoch 736 | valid on 'valid' subset | loss 13.531 | nll_loss 12.953 | ppl 7932.13 | wps 48220.3 | wpb 510.9 | bsz 1 | num_updates 35808 | best_loss 8.937
2022-03-07 16:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 736 @ 35808 updates
2022-03-07 16:31:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:31:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 736 @ 35808 updates, score 13.531) (writing took 2.2987214545719326 seconds)
2022-03-07 16:31:04 | INFO | fairseq_cli.train | end of epoch 736 (average epoch stats below)
2022-03-07 16:31:04 | INFO | train | epoch 736 | loss 2.036 | nll_loss 0.285 | ppl 1.22 | wps 25382.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35808 | lr 0.000167113 | gnorm 0.359 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 98909
2022-03-07 16:31:04 | INFO | fairseq.trainer | begin training epoch 737
2022-03-07 16:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:31:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:33:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:33:07 | INFO | valid | epoch 737 | valid on 'valid' subset | loss 13.398 | nll_loss 12.814 | ppl 7199.05 | wps 48157 | wpb 510.9 | bsz 1 | num_updates 35856 | best_loss 8.937
2022-03-07 16:33:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 737 @ 35856 updates
2022-03-07 16:33:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:33:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:33:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 737 @ 35856 updates, score 13.398) (writing took 2.274475562851876 seconds)
2022-03-07 16:33:09 | INFO | fairseq_cli.train | end of epoch 737 (average epoch stats below)
2022-03-07 16:33:09 | INFO | train | epoch 737 | loss 2.035 | nll_loss 0.284 | ppl 1.22 | wps 24890 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 35856 | lr 0.000167001 | gnorm 0.358 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 99034
2022-03-07 16:33:09 | INFO | fairseq.trainer | begin training epoch 738
2022-03-07 16:33:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:34:56 | INFO | train_inner | epoch 738:     44 / 49 loss=2.035, nll_loss=0.284, ppl=1.22, wps=25198, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=35900, lr=0.000166899, gnorm=0.358, loss_scale=32, train_wall=219, gb_free=8.8, wall=99141
2022-03-07 16:35:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:35:12 | INFO | valid | epoch 738 | valid on 'valid' subset | loss 13.405 | nll_loss 12.822 | ppl 7241.6 | wps 47511.7 | wpb 510.9 | bsz 1 | num_updates 35905 | best_loss 8.937
2022-03-07 16:35:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 738 @ 35905 updates
2022-03-07 16:35:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:35:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:35:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 738 @ 35905 updates, score 13.405) (writing took 2.4482544036582112 seconds)
2022-03-07 16:35:14 | INFO | fairseq_cli.train | end of epoch 738 (average epoch stats below)
2022-03-07 16:35:14 | INFO | train | epoch 738 | loss 2.035 | nll_loss 0.284 | ppl 1.22 | wps 25340.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35905 | lr 0.000166887 | gnorm 0.359 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 99159
2022-03-07 16:35:14 | INFO | fairseq.trainer | begin training epoch 739
2022-03-07 16:35:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:37:18 | INFO | valid | epoch 739 | valid on 'valid' subset | loss 13.444 | nll_loss 12.863 | ppl 7450.61 | wps 47753.4 | wpb 510.9 | bsz 1 | num_updates 35954 | best_loss 8.937
2022-03-07 16:37:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 739 @ 35954 updates
2022-03-07 16:37:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:37:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 739 @ 35954 updates, score 13.444) (writing took 2.3384068543091416 seconds)
2022-03-07 16:37:20 | INFO | fairseq_cli.train | end of epoch 739 (average epoch stats below)
2022-03-07 16:37:20 | INFO | train | epoch 739 | loss 2.035 | nll_loss 0.284 | ppl 1.22 | wps 25343.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 35954 | lr 0.000166773 | gnorm 0.358 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 99285
2022-03-07 16:37:20 | INFO | fairseq.trainer | begin training epoch 740
2022-03-07 16:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:37:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:39:15 | INFO | train_inner | epoch 740:     47 / 49 loss=2.035, nll_loss=0.284, ppl=1.22, wps=25126.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36000, lr=0.000166667, gnorm=0.359, loss_scale=32, train_wall=220, gb_free=8.8, wall=99399
2022-03-07 16:39:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:39:23 | INFO | valid | epoch 740 | valid on 'valid' subset | loss 13.527 | nll_loss 12.947 | ppl 7898.02 | wps 48137.7 | wpb 510.9 | bsz 1 | num_updates 36002 | best_loss 8.937
2022-03-07 16:39:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 740 @ 36002 updates
2022-03-07 16:39:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:39:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:39:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 740 @ 36002 updates, score 13.527) (writing took 2.3421697109006345 seconds)
2022-03-07 16:39:25 | INFO | fairseq_cli.train | end of epoch 740 (average epoch stats below)
2022-03-07 16:39:25 | INFO | train | epoch 740 | loss 2.034 | nll_loss 0.284 | ppl 1.22 | wps 24850.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36002 | lr 0.000166662 | gnorm 0.36 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 99410
2022-03-07 16:39:25 | INFO | fairseq.trainer | begin training epoch 741
2022-03-07 16:39:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:41:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:41:28 | INFO | valid | epoch 741 | valid on 'valid' subset | loss 13.512 | nll_loss 12.93 | ppl 7805.14 | wps 48400.9 | wpb 510.9 | bsz 1 | num_updates 36051 | best_loss 8.937
2022-03-07 16:41:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 741 @ 36051 updates
2022-03-07 16:41:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:41:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:41:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 741 @ 36051 updates, score 13.512) (writing took 2.2692449470050633 seconds)
2022-03-07 16:41:30 | INFO | fairseq_cli.train | end of epoch 741 (average epoch stats below)
2022-03-07 16:41:30 | INFO | train | epoch 741 | loss 2.034 | nll_loss 0.284 | ppl 1.22 | wps 25359.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36051 | lr 0.000166549 | gnorm 0.361 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99535
2022-03-07 16:41:30 | INFO | fairseq.trainer | begin training epoch 742
2022-03-07 16:41:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:43:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:43:34 | INFO | valid | epoch 742 | valid on 'valid' subset | loss 13.513 | nll_loss 12.935 | ppl 7828.48 | wps 46079.1 | wpb 510.9 | bsz 1 | num_updates 36099 | best_loss 8.937
2022-03-07 16:43:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 742 @ 36099 updates
2022-03-07 16:43:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:43:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:43:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 742 @ 36099 updates, score 13.513) (writing took 2.4833595589734614 seconds)
2022-03-07 16:43:36 | INFO | fairseq_cli.train | end of epoch 742 (average epoch stats below)
2022-03-07 16:43:36 | INFO | train | epoch 742 | loss 2.034 | nll_loss 0.284 | ppl 1.22 | wps 24762.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36099 | lr 0.000166438 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99661
2022-03-07 16:43:36 | INFO | fairseq.trainer | begin training epoch 743
2022-03-07 16:43:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:43:39 | INFO | train_inner | epoch 743:      1 / 49 loss=2.034, nll_loss=0.284, ppl=1.22, wps=24431.4, ups=0.38, wpb=64544.1, bsz=126.1, num_updates=36100, lr=0.000166436, gnorm=0.361, loss_scale=32, train_wall=219, gb_free=8.8, wall=99663
2022-03-07 16:45:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:45:39 | INFO | valid | epoch 743 | valid on 'valid' subset | loss 13.537 | nll_loss 12.962 | ppl 7978.14 | wps 47505.3 | wpb 510.9 | bsz 1 | num_updates 36148 | best_loss 8.937
2022-03-07 16:45:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 743 @ 36148 updates
2022-03-07 16:45:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:45:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:45:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 743 @ 36148 updates, score 13.537) (writing took 2.3755606850609183 seconds)
2022-03-07 16:45:42 | INFO | fairseq_cli.train | end of epoch 743 (average epoch stats below)
2022-03-07 16:45:42 | INFO | train | epoch 743 | loss 2.034 | nll_loss 0.284 | ppl 1.22 | wps 25352 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36148 | lr 0.000166325 | gnorm 0.359 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 99786
2022-03-07 16:45:42 | INFO | fairseq.trainer | begin training epoch 744
2022-03-07 16:45:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:47:44 | INFO | valid | epoch 744 | valid on 'valid' subset | loss 13.472 | nll_loss 12.891 | ppl 7598.14 | wps 48244.9 | wpb 510.9 | bsz 1 | num_updates 36197 | best_loss 8.937
2022-03-07 16:47:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 744 @ 36197 updates
2022-03-07 16:47:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:47:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:47:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 744 @ 36197 updates, score 13.472) (writing took 2.307240054011345 seconds)
2022-03-07 16:47:47 | INFO | fairseq_cli.train | end of epoch 744 (average epoch stats below)
2022-03-07 16:47:47 | INFO | train | epoch 744 | loss 2.034 | nll_loss 0.283 | ppl 1.22 | wps 25372.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36197 | lr 0.000166213 | gnorm 0.36 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 99912
2022-03-07 16:47:47 | INFO | fairseq.trainer | begin training epoch 745
2022-03-07 16:47:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:47:54 | INFO | train_inner | epoch 745:      3 / 49 loss=2.034, nll_loss=0.284, ppl=1.22, wps=25395, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36200, lr=0.000166206, gnorm=0.359, loss_scale=32, train_wall=217, gb_free=8.8, wall=99919
2022-03-07 16:49:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:49:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:49:50 | INFO | valid | epoch 745 | valid on 'valid' subset | loss 13.413 | nll_loss 12.826 | ppl 7262.63 | wps 48440.2 | wpb 510.9 | bsz 1 | num_updates 36245 | best_loss 8.937
2022-03-07 16:49:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 745 @ 36245 updates
2022-03-07 16:49:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:49:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:49:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 745 @ 36245 updates, score 13.413) (writing took 2.2607857841067016 seconds)
2022-03-07 16:49:52 | INFO | fairseq_cli.train | end of epoch 745 (average epoch stats below)
2022-03-07 16:49:52 | INFO | train | epoch 745 | loss 2.034 | nll_loss 0.284 | ppl 1.22 | wps 24862.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36245 | lr 0.000166102 | gnorm 0.361 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 100037
2022-03-07 16:49:52 | INFO | fairseq.trainer | begin training epoch 746
2022-03-07 16:49:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:51:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:51:55 | INFO | valid | epoch 746 | valid on 'valid' subset | loss 13.433 | nll_loss 12.848 | ppl 7372.41 | wps 45826.3 | wpb 510.9 | bsz 1 | num_updates 36294 | best_loss 8.937
2022-03-07 16:51:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 746 @ 36294 updates
2022-03-07 16:51:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:51:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:51:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 746 @ 36294 updates, score 13.433) (writing took 2.377505459357053 seconds)
2022-03-07 16:51:58 | INFO | fairseq_cli.train | end of epoch 746 (average epoch stats below)
2022-03-07 16:51:58 | INFO | train | epoch 746 | loss 2.033 | nll_loss 0.283 | ppl 1.22 | wps 25309.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36294 | lr 0.00016599 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100162
2022-03-07 16:51:58 | INFO | fairseq.trainer | begin training epoch 747
2022-03-07 16:51:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:52:12 | INFO | train_inner | epoch 747:      6 / 49 loss=2.033, nll_loss=0.283, ppl=1.22, wps=25135.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36300, lr=0.000165977, gnorm=0.357, loss_scale=32, train_wall=220, gb_free=8.8, wall=100177
2022-03-07 16:53:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:54:00 | INFO | valid | epoch 747 | valid on 'valid' subset | loss 13.561 | nll_loss 12.987 | ppl 8117.32 | wps 48183 | wpb 510.9 | bsz 1 | num_updates 36343 | best_loss 8.937
2022-03-07 16:54:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 747 @ 36343 updates
2022-03-07 16:54:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:54:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:54:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 747 @ 36343 updates, score 13.561) (writing took 2.359802320599556 seconds)
2022-03-07 16:54:03 | INFO | fairseq_cli.train | end of epoch 747 (average epoch stats below)
2022-03-07 16:54:03 | INFO | train | epoch 747 | loss 2.034 | nll_loss 0.283 | ppl 1.22 | wps 25373.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36343 | lr 0.000165878 | gnorm 0.361 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 100288
2022-03-07 16:54:03 | INFO | fairseq.trainer | begin training epoch 748
2022-03-07 16:54:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:54:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 16:56:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:56:06 | INFO | valid | epoch 748 | valid on 'valid' subset | loss 13.526 | nll_loss 12.95 | ppl 7910.64 | wps 48217.4 | wpb 510.9 | bsz 1 | num_updates 36391 | best_loss 8.937
2022-03-07 16:56:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 748 @ 36391 updates
2022-03-07 16:56:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:56:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:56:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 748 @ 36391 updates, score 13.526) (writing took 2.294953074771911 seconds)
2022-03-07 16:56:08 | INFO | fairseq_cli.train | end of epoch 748 (average epoch stats below)
2022-03-07 16:56:08 | INFO | train | epoch 748 | loss 2.034 | nll_loss 0.283 | ppl 1.22 | wps 24859 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36391 | lr 0.000165769 | gnorm 0.359 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100413
2022-03-07 16:56:08 | INFO | fairseq.trainer | begin training epoch 749
2022-03-07 16:56:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 16:56:30 | INFO | train_inner | epoch 749:      9 / 49 loss=2.034, nll_loss=0.283, ppl=1.22, wps=25164, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36400, lr=0.000165748, gnorm=0.36, loss_scale=32, train_wall=220, gb_free=8.8, wall=100435
2022-03-07 16:58:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 16:58:11 | INFO | valid | epoch 749 | valid on 'valid' subset | loss 13.485 | nll_loss 12.903 | ppl 7660.08 | wps 48412.7 | wpb 510.9 | bsz 1 | num_updates 36440 | best_loss 8.937
2022-03-07 16:58:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 749 @ 36440 updates
2022-03-07 16:58:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:58:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 16:58:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 749 @ 36440 updates, score 13.485) (writing took 2.247365090996027 seconds)
2022-03-07 16:58:13 | INFO | fairseq_cli.train | end of epoch 749 (average epoch stats below)
2022-03-07 16:58:13 | INFO | train | epoch 749 | loss 2.033 | nll_loss 0.283 | ppl 1.22 | wps 25413.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36440 | lr 0.000165657 | gnorm 0.358 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 100538
2022-03-07 16:58:13 | INFO | fairseq.trainer | begin training epoch 750
2022-03-07 16:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:00:16 | INFO | valid | epoch 750 | valid on 'valid' subset | loss 13.476 | nll_loss 12.897 | ppl 7625.31 | wps 45247.1 | wpb 510.9 | bsz 1 | num_updates 36489 | best_loss 8.937
2022-03-07 17:00:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 750 @ 36489 updates
2022-03-07 17:00:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:00:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:00:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 750 @ 36489 updates, score 13.476) (writing took 2.291746899019927 seconds)
2022-03-07 17:00:19 | INFO | fairseq_cli.train | end of epoch 750 (average epoch stats below)
2022-03-07 17:00:19 | INFO | train | epoch 750 | loss 2.033 | nll_loss 0.283 | ppl 1.22 | wps 25325 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36489 | lr 0.000165546 | gnorm 0.361 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 100663
2022-03-07 17:00:19 | INFO | fairseq.trainer | begin training epoch 751
2022-03-07 17:00:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:00:45 | INFO | train_inner | epoch 751:     11 / 49 loss=2.033, nll_loss=0.283, ppl=1.22, wps=25393, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=36500, lr=0.000165521, gnorm=0.358, loss_scale=64, train_wall=217, gb_free=8.8, wall=100690
2022-03-07 17:01:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:02:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:02:22 | INFO | valid | epoch 751 | valid on 'valid' subset | loss 13.511 | nll_loss 12.932 | ppl 7814.02 | wps 47633.3 | wpb 510.9 | bsz 1 | num_updates 36537 | best_loss 8.937
2022-03-07 17:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 751 @ 36537 updates
2022-03-07 17:02:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:02:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:02:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 751 @ 36537 updates, score 13.511) (writing took 2.3524781120941043 seconds)
2022-03-07 17:02:24 | INFO | fairseq_cli.train | end of epoch 751 (average epoch stats below)
2022-03-07 17:02:24 | INFO | train | epoch 751 | loss 2.032 | nll_loss 0.282 | ppl 1.22 | wps 24813.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36537 | lr 0.000165437 | gnorm 0.353 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100789
2022-03-07 17:02:24 | INFO | fairseq.trainer | begin training epoch 752
2022-03-07 17:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:04:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:04:27 | INFO | valid | epoch 752 | valid on 'valid' subset | loss 13.459 | nll_loss 12.874 | ppl 7505.36 | wps 48154.6 | wpb 510.9 | bsz 1 | num_updates 36586 | best_loss 8.937
2022-03-07 17:04:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 752 @ 36586 updates
2022-03-07 17:04:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:04:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:04:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 752 @ 36586 updates, score 13.459) (writing took 2.273687758948654 seconds)
2022-03-07 17:04:29 | INFO | fairseq_cli.train | end of epoch 752 (average epoch stats below)
2022-03-07 17:04:29 | INFO | train | epoch 752 | loss 2.033 | nll_loss 0.283 | ppl 1.22 | wps 25376.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36586 | lr 0.000165327 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 100914
2022-03-07 17:04:29 | INFO | fairseq.trainer | begin training epoch 753
2022-03-07 17:04:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:05:03 | INFO | train_inner | epoch 753:     14 / 49 loss=2.033, nll_loss=0.283, ppl=1.22, wps=25167.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=36600, lr=0.000165295, gnorm=0.356, loss_scale=32, train_wall=220, gb_free=8.8, wall=100948
2022-03-07 17:06:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:06:32 | INFO | valid | epoch 753 | valid on 'valid' subset | loss 13.477 | nll_loss 12.901 | ppl 7646.64 | wps 48033.4 | wpb 510.9 | bsz 1 | num_updates 36635 | best_loss 8.937
2022-03-07 17:06:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 753 @ 36635 updates
2022-03-07 17:06:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:06:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:06:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 753 @ 36635 updates, score 13.477) (writing took 2.268811461981386 seconds)
2022-03-07 17:06:34 | INFO | fairseq_cli.train | end of epoch 753 (average epoch stats below)
2022-03-07 17:06:34 | INFO | train | epoch 753 | loss 2.033 | nll_loss 0.283 | ppl 1.22 | wps 25402.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36635 | lr 0.000165216 | gnorm 0.36 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101039
2022-03-07 17:06:34 | INFO | fairseq.trainer | begin training epoch 754
2022-03-07 17:06:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:07:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:08:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:08:37 | INFO | valid | epoch 754 | valid on 'valid' subset | loss 13.438 | nll_loss 12.852 | ppl 7392.8 | wps 46325.5 | wpb 510.9 | bsz 1 | num_updates 36683 | best_loss 8.937
2022-03-07 17:08:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 754 @ 36683 updates
2022-03-07 17:08:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:08:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:08:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 754 @ 36683 updates, score 13.438) (writing took 2.3268369962461293 seconds)
2022-03-07 17:08:40 | INFO | fairseq_cli.train | end of epoch 754 (average epoch stats below)
2022-03-07 17:08:40 | INFO | train | epoch 754 | loss 2.032 | nll_loss 0.282 | ppl 1.22 | wps 24857.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36683 | lr 0.000165108 | gnorm 0.357 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101164
2022-03-07 17:08:40 | INFO | fairseq.trainer | begin training epoch 755
2022-03-07 17:08:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:09:21 | INFO | train_inner | epoch 755:     17 / 49 loss=2.033, nll_loss=0.283, ppl=1.22, wps=25170.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=36700, lr=0.00016507, gnorm=0.357, loss_scale=32, train_wall=219, gb_free=8.8, wall=101206
2022-03-07 17:10:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:10:42 | INFO | valid | epoch 755 | valid on 'valid' subset | loss 13.635 | nll_loss 13.067 | ppl 8580.79 | wps 48092.6 | wpb 510.9 | bsz 1 | num_updates 36732 | best_loss 8.937
2022-03-07 17:10:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 755 @ 36732 updates
2022-03-07 17:10:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:10:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 755 @ 36732 updates, score 13.635) (writing took 2.350453902967274 seconds)
2022-03-07 17:10:45 | INFO | fairseq_cli.train | end of epoch 755 (average epoch stats below)
2022-03-07 17:10:45 | INFO | train | epoch 755 | loss 2.032 | nll_loss 0.282 | ppl 1.22 | wps 25370.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36732 | lr 0.000164998 | gnorm 0.358 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101290
2022-03-07 17:10:45 | INFO | fairseq.trainer | begin training epoch 756
2022-03-07 17:10:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:12:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:12:48 | INFO | valid | epoch 756 | valid on 'valid' subset | loss 13.475 | nll_loss 12.896 | ppl 7621.66 | wps 48121.3 | wpb 510.9 | bsz 1 | num_updates 36781 | best_loss 8.937
2022-03-07 17:12:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 756 @ 36781 updates
2022-03-07 17:12:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:12:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:12:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 756 @ 36781 updates, score 13.475) (writing took 2.2779868678189814 seconds)
2022-03-07 17:12:50 | INFO | fairseq_cli.train | end of epoch 756 (average epoch stats below)
2022-03-07 17:12:50 | INFO | train | epoch 756 | loss 2.032 | nll_loss 0.282 | ppl 1.22 | wps 25388.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36781 | lr 0.000164888 | gnorm 0.359 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101415
2022-03-07 17:12:50 | INFO | fairseq.trainer | begin training epoch 757
2022-03-07 17:12:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:13:36 | INFO | train_inner | epoch 757:     19 / 49 loss=2.032, nll_loss=0.282, ppl=1.22, wps=25409.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=36800, lr=0.000164845, gnorm=0.358, loss_scale=64, train_wall=217, gb_free=8.8, wall=101461
2022-03-07 17:13:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:14:53 | INFO | valid | epoch 757 | valid on 'valid' subset | loss 13.443 | nll_loss 12.857 | ppl 7419.66 | wps 48276.3 | wpb 510.9 | bsz 1 | num_updates 36829 | best_loss 8.937
2022-03-07 17:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 757 @ 36829 updates
2022-03-07 17:14:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:14:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:14:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 757 @ 36829 updates, score 13.443) (writing took 2.2688890392892063 seconds)
2022-03-07 17:14:55 | INFO | fairseq_cli.train | end of epoch 757 (average epoch stats below)
2022-03-07 17:14:55 | INFO | train | epoch 757 | loss 2.031 | nll_loss 0.281 | ppl 1.22 | wps 24889.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36829 | lr 0.00016478 | gnorm 0.354 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101540
2022-03-07 17:14:55 | INFO | fairseq.trainer | begin training epoch 758
2022-03-07 17:14:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:16:58 | INFO | valid | epoch 758 | valid on 'valid' subset | loss 13.484 | nll_loss 12.905 | ppl 7670.2 | wps 47396.1 | wpb 510.9 | bsz 1 | num_updates 36878 | best_loss 8.937
2022-03-07 17:16:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 758 @ 36878 updates
2022-03-07 17:16:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:17:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:17:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 758 @ 36878 updates, score 13.484) (writing took 2.2990656099282205 seconds)
2022-03-07 17:17:00 | INFO | fairseq_cli.train | end of epoch 758 (average epoch stats below)
2022-03-07 17:17:00 | INFO | train | epoch 758 | loss 2.032 | nll_loss 0.282 | ppl 1.22 | wps 25396.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36878 | lr 0.000164671 | gnorm 0.359 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101665
2022-03-07 17:17:00 | INFO | fairseq.trainer | begin training epoch 759
2022-03-07 17:17:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:17:54 | INFO | train_inner | epoch 759:     22 / 49 loss=2.031, nll_loss=0.282, ppl=1.22, wps=25189.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=36900, lr=0.000164622, gnorm=0.357, loss_scale=32, train_wall=219, gb_free=8.8, wall=101719
2022-03-07 17:18:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:19:03 | INFO | valid | epoch 759 | valid on 'valid' subset | loss 13.545 | nll_loss 12.973 | ppl 8042.03 | wps 48208.5 | wpb 510.9 | bsz 1 | num_updates 36927 | best_loss 8.937
2022-03-07 17:19:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 759 @ 36927 updates
2022-03-07 17:19:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:19:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:19:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 759 @ 36927 updates, score 13.545) (writing took 2.33085989812389 seconds)
2022-03-07 17:19:05 | INFO | fairseq_cli.train | end of epoch 759 (average epoch stats below)
2022-03-07 17:19:05 | INFO | train | epoch 759 | loss 2.032 | nll_loss 0.282 | ppl 1.22 | wps 25387.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 36927 | lr 0.000164561 | gnorm 0.358 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101790
2022-03-07 17:19:05 | INFO | fairseq.trainer | begin training epoch 760
2022-03-07 17:19:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:19:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:21:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:21:08 | INFO | valid | epoch 760 | valid on 'valid' subset | loss 13.421 | nll_loss 12.841 | ppl 7335.48 | wps 48219.5 | wpb 510.9 | bsz 1 | num_updates 36975 | best_loss 8.937
2022-03-07 17:21:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 760 @ 36975 updates
2022-03-07 17:21:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:21:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:21:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 760 @ 36975 updates, score 13.421) (writing took 2.3084135591052473 seconds)
2022-03-07 17:21:10 | INFO | fairseq_cli.train | end of epoch 760 (average epoch stats below)
2022-03-07 17:21:10 | INFO | train | epoch 760 | loss 2.031 | nll_loss 0.281 | ppl 1.22 | wps 24884.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 36975 | lr 0.000164455 | gnorm 0.357 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 101915
2022-03-07 17:21:10 | INFO | fairseq.trainer | begin training epoch 761
2022-03-07 17:21:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:22:12 | INFO | train_inner | epoch 761:     25 / 49 loss=2.031, nll_loss=0.281, ppl=1.22, wps=25175.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=37000, lr=0.000164399, gnorm=0.357, loss_scale=32, train_wall=219, gb_free=8.8, wall=101976
2022-03-07 17:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:23:13 | INFO | valid | epoch 761 | valid on 'valid' subset | loss 13.508 | nll_loss 12.93 | ppl 7803.68 | wps 48302.9 | wpb 510.9 | bsz 1 | num_updates 37024 | best_loss 8.937
2022-03-07 17:23:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 761 @ 37024 updates
2022-03-07 17:23:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:23:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:23:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 761 @ 37024 updates, score 13.508) (writing took 2.301906744018197 seconds)
2022-03-07 17:23:16 | INFO | fairseq_cli.train | end of epoch 761 (average epoch stats below)
2022-03-07 17:23:16 | INFO | train | epoch 761 | loss 2.031 | nll_loss 0.281 | ppl 1.22 | wps 25392.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37024 | lr 0.000164346 | gnorm 0.355 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 102040
2022-03-07 17:23:16 | INFO | fairseq.trainer | begin training epoch 762
2022-03-07 17:23:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:25:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:25:19 | INFO | valid | epoch 762 | valid on 'valid' subset | loss 13.428 | nll_loss 12.85 | ppl 7384.15 | wps 45544.2 | wpb 510.9 | bsz 1 | num_updates 37073 | best_loss 8.937
2022-03-07 17:25:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 762 @ 37073 updates
2022-03-07 17:25:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:25:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:25:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 762 @ 37073 updates, score 13.428) (writing took 2.3168108728714287 seconds)
2022-03-07 17:25:21 | INFO | fairseq_cli.train | end of epoch 762 (average epoch stats below)
2022-03-07 17:25:21 | INFO | train | epoch 762 | loss 2.031 | nll_loss 0.282 | ppl 1.22 | wps 25319.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37073 | lr 0.000164237 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102166
2022-03-07 17:25:21 | INFO | fairseq.trainer | begin training epoch 763
2022-03-07 17:25:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:25:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:26:30 | INFO | train_inner | epoch 763:     28 / 49 loss=2.031, nll_loss=0.282, ppl=1.22, wps=25113.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=37100, lr=0.000164177, gnorm=0.356, loss_scale=32, train_wall=220, gb_free=8.8, wall=102235
2022-03-07 17:27:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:27:25 | INFO | valid | epoch 763 | valid on 'valid' subset | loss 13.55 | nll_loss 12.978 | ppl 8070.16 | wps 47776 | wpb 510.9 | bsz 1 | num_updates 37121 | best_loss 8.937
2022-03-07 17:27:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 763 @ 37121 updates
2022-03-07 17:27:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:27:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:27:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 763 @ 37121 updates, score 13.55) (writing took 2.385966560803354 seconds)
2022-03-07 17:27:27 | INFO | fairseq_cli.train | end of epoch 763 (average epoch stats below)
2022-03-07 17:27:27 | INFO | train | epoch 763 | loss 2.031 | nll_loss 0.281 | ppl 1.21 | wps 24702.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37121 | lr 0.000164131 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 102292
2022-03-07 17:27:27 | INFO | fairseq.trainer | begin training epoch 764
2022-03-07 17:27:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:29:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:29:30 | INFO | valid | epoch 764 | valid on 'valid' subset | loss 13.463 | nll_loss 12.88 | ppl 7540.6 | wps 48108.6 | wpb 510.9 | bsz 1 | num_updates 37170 | best_loss 8.937
2022-03-07 17:29:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 764 @ 37170 updates
2022-03-07 17:29:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:29:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:29:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 764 @ 37170 updates, score 13.463) (writing took 2.285170986317098 seconds)
2022-03-07 17:29:32 | INFO | fairseq_cli.train | end of epoch 764 (average epoch stats below)
2022-03-07 17:29:32 | INFO | train | epoch 764 | loss 2.03 | nll_loss 0.281 | ppl 1.21 | wps 25419.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37170 | lr 0.000164023 | gnorm 0.358 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 102417
2022-03-07 17:29:32 | INFO | fairseq.trainer | begin training epoch 765
2022-03-07 17:29:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:30:45 | INFO | train_inner | epoch 765:     30 / 49 loss=2.03, nll_loss=0.281, ppl=1.21, wps=25387.8, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=37200, lr=0.000163956, gnorm=0.355, loss_scale=32, train_wall=217, gb_free=8.8, wall=102490
2022-03-07 17:31:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:31:35 | INFO | valid | epoch 765 | valid on 'valid' subset | loss 13.484 | nll_loss 12.907 | ppl 7683.23 | wps 48151 | wpb 510.9 | bsz 1 | num_updates 37219 | best_loss 8.937
2022-03-07 17:31:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 765 @ 37219 updates
2022-03-07 17:31:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:31:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:31:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 765 @ 37219 updates, score 13.484) (writing took 2.2647059559822083 seconds)
2022-03-07 17:31:37 | INFO | fairseq_cli.train | end of epoch 765 (average epoch stats below)
2022-03-07 17:31:37 | INFO | train | epoch 765 | loss 2.03 | nll_loss 0.281 | ppl 1.21 | wps 25412.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37219 | lr 0.000163915 | gnorm 0.356 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 102542
2022-03-07 17:31:37 | INFO | fairseq.trainer | begin training epoch 766
2022-03-07 17:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:31:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:33:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:33:40 | INFO | valid | epoch 766 | valid on 'valid' subset | loss 13.399 | nll_loss 12.815 | ppl 7204.14 | wps 46129.2 | wpb 510.9 | bsz 1 | num_updates 37267 | best_loss 8.937
2022-03-07 17:33:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 766 @ 37267 updates
2022-03-07 17:33:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:33:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:33:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 766 @ 37267 updates, score 13.399) (writing took 2.327242171857506 seconds)
2022-03-07 17:33:43 | INFO | fairseq_cli.train | end of epoch 766 (average epoch stats below)
2022-03-07 17:33:43 | INFO | train | epoch 766 | loss 2.031 | nll_loss 0.281 | ppl 1.22 | wps 24813 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37267 | lr 0.000163809 | gnorm 0.36 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 102667
2022-03-07 17:33:43 | INFO | fairseq.trainer | begin training epoch 767
2022-03-07 17:33:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:35:03 | INFO | train_inner | epoch 767:     33 / 49 loss=2.031, nll_loss=0.281, ppl=1.22, wps=25179.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37300, lr=0.000163737, gnorm=0.358, loss_scale=32, train_wall=219, gb_free=8.8, wall=102748
2022-03-07 17:35:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:35:45 | INFO | valid | epoch 767 | valid on 'valid' subset | loss 13.413 | nll_loss 12.828 | ppl 7273.48 | wps 48224.1 | wpb 510.9 | bsz 1 | num_updates 37316 | best_loss 8.937
2022-03-07 17:35:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 767 @ 37316 updates
2022-03-07 17:35:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:35:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:35:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 767 @ 37316 updates, score 13.413) (writing took 2.3381129009649158 seconds)
2022-03-07 17:35:48 | INFO | fairseq_cli.train | end of epoch 767 (average epoch stats below)
2022-03-07 17:35:48 | INFO | train | epoch 767 | loss 2.031 | nll_loss 0.282 | ppl 1.22 | wps 25394.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37316 | lr 0.000163701 | gnorm 0.355 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 102793
2022-03-07 17:35:48 | INFO | fairseq.trainer | begin training epoch 768
2022-03-07 17:35:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:37:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:37:51 | INFO | valid | epoch 768 | valid on 'valid' subset | loss 13.556 | nll_loss 12.983 | ppl 8093.43 | wps 48447.4 | wpb 510.9 | bsz 1 | num_updates 37365 | best_loss 8.937
2022-03-07 17:37:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 768 @ 37365 updates
2022-03-07 17:37:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:37:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:37:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 768 @ 37365 updates, score 13.556) (writing took 2.3052452667616308 seconds)
2022-03-07 17:37:53 | INFO | fairseq_cli.train | end of epoch 768 (average epoch stats below)
2022-03-07 17:37:53 | INFO | train | epoch 768 | loss 2.03 | nll_loss 0.281 | ppl 1.21 | wps 25398.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37365 | lr 0.000163594 | gnorm 0.356 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 102918
2022-03-07 17:37:53 | INFO | fairseq.trainer | begin training epoch 769
2022-03-07 17:37:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:38:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:39:21 | INFO | train_inner | epoch 769:     36 / 49 loss=2.03, nll_loss=0.281, ppl=1.21, wps=25174.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37400, lr=0.000163517, gnorm=0.357, loss_scale=32, train_wall=219, gb_free=8.8, wall=103005
2022-03-07 17:39:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:39:56 | INFO | valid | epoch 769 | valid on 'valid' subset | loss 13.41 | nll_loss 12.826 | ppl 7263.5 | wps 48071 | wpb 510.9 | bsz 1 | num_updates 37413 | best_loss 8.937
2022-03-07 17:39:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 769 @ 37413 updates
2022-03-07 17:39:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:39:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:39:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 769 @ 37413 updates, score 13.41) (writing took 2.2695612027309835 seconds)
2022-03-07 17:39:58 | INFO | fairseq_cli.train | end of epoch 769 (average epoch stats below)
2022-03-07 17:39:58 | INFO | train | epoch 769 | loss 2.03 | nll_loss 0.28 | ppl 1.21 | wps 24884.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37413 | lr 0.000163489 | gnorm 0.361 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 103043
2022-03-07 17:39:58 | INFO | fairseq.trainer | begin training epoch 770
2022-03-07 17:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:41:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:42:01 | INFO | valid | epoch 770 | valid on 'valid' subset | loss 13.463 | nll_loss 12.88 | ppl 7539.03 | wps 46854.7 | wpb 510.9 | bsz 1 | num_updates 37462 | best_loss 8.937
2022-03-07 17:42:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 770 @ 37462 updates
2022-03-07 17:42:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:42:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:42:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 770 @ 37462 updates, score 13.463) (writing took 2.359661031048745 seconds)
2022-03-07 17:42:03 | INFO | fairseq_cli.train | end of epoch 770 (average epoch stats below)
2022-03-07 17:42:03 | INFO | train | epoch 770 | loss 2.03 | nll_loss 0.28 | ppl 1.21 | wps 25369.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37462 | lr 0.000163382 | gnorm 0.356 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 103168
2022-03-07 17:42:03 | INFO | fairseq.trainer | begin training epoch 771
2022-03-07 17:42:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:43:36 | INFO | train_inner | epoch 771:     38 / 49 loss=2.03, nll_loss=0.28, ppl=1.21, wps=25412.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37500, lr=0.000163299, gnorm=0.356, loss_scale=64, train_wall=217, gb_free=8.8, wall=103261
2022-03-07 17:43:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:44:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:44:06 | INFO | valid | epoch 771 | valid on 'valid' subset | loss 13.454 | nll_loss 12.872 | ppl 7499.07 | wps 48276.9 | wpb 510.9 | bsz 1 | num_updates 37510 | best_loss 8.937
2022-03-07 17:44:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 771 @ 37510 updates
2022-03-07 17:44:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:44:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:44:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 771 @ 37510 updates, score 13.454) (writing took 2.3490719897672534 seconds)
2022-03-07 17:44:09 | INFO | fairseq_cli.train | end of epoch 771 (average epoch stats below)
2022-03-07 17:44:09 | INFO | train | epoch 771 | loss 2.029 | nll_loss 0.28 | ppl 1.21 | wps 24817.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37510 | lr 0.000163278 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 103293
2022-03-07 17:44:09 | INFO | fairseq.trainer | begin training epoch 772
2022-03-07 17:44:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:46:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:46:11 | INFO | valid | epoch 772 | valid on 'valid' subset | loss 13.517 | nll_loss 12.942 | ppl 7868.02 | wps 48138.2 | wpb 510.9 | bsz 1 | num_updates 37559 | best_loss 8.937
2022-03-07 17:46:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 772 @ 37559 updates
2022-03-07 17:46:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:46:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:46:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 772 @ 37559 updates, score 13.517) (writing took 2.2959226393140852 seconds)
2022-03-07 17:46:14 | INFO | fairseq_cli.train | end of epoch 772 (average epoch stats below)
2022-03-07 17:46:14 | INFO | train | epoch 772 | loss 2.03 | nll_loss 0.28 | ppl 1.21 | wps 25398.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37559 | lr 0.000163171 | gnorm 0.356 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 103419
2022-03-07 17:46:14 | INFO | fairseq.trainer | begin training epoch 773
2022-03-07 17:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:47:54 | INFO | train_inner | epoch 773:     41 / 49 loss=2.029, nll_loss=0.28, ppl=1.21, wps=25138.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37600, lr=0.000163082, gnorm=0.355, loss_scale=32, train_wall=220, gb_free=8.8, wall=103519
2022-03-07 17:48:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:48:17 | INFO | valid | epoch 773 | valid on 'valid' subset | loss 13.459 | nll_loss 12.882 | ppl 7547.21 | wps 47899.2 | wpb 510.9 | bsz 1 | num_updates 37608 | best_loss 8.937
2022-03-07 17:48:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 773 @ 37608 updates
2022-03-07 17:48:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:48:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:48:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 773 @ 37608 updates, score 13.459) (writing took 2.296243625227362 seconds)
2022-03-07 17:48:19 | INFO | fairseq_cli.train | end of epoch 773 (average epoch stats below)
2022-03-07 17:48:19 | INFO | train | epoch 773 | loss 2.029 | nll_loss 0.28 | ppl 1.21 | wps 25344.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37608 | lr 0.000163065 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 103544
2022-03-07 17:48:19 | INFO | fairseq.trainer | begin training epoch 774
2022-03-07 17:48:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:50:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:50:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:50:22 | INFO | valid | epoch 774 | valid on 'valid' subset | loss 13.34 | nll_loss 12.751 | ppl 6894.66 | wps 47428 | wpb 510.9 | bsz 1 | num_updates 37656 | best_loss 8.937
2022-03-07 17:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 774 @ 37656 updates
2022-03-07 17:50:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:50:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 774 @ 37656 updates, score 13.34) (writing took 2.3486917060799897 seconds)
2022-03-07 17:50:24 | INFO | fairseq_cli.train | end of epoch 774 (average epoch stats below)
2022-03-07 17:50:24 | INFO | train | epoch 774 | loss 2.029 | nll_loss 0.28 | ppl 1.21 | wps 24847.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37656 | lr 0.000162961 | gnorm 0.351 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 103669
2022-03-07 17:50:24 | INFO | fairseq.trainer | begin training epoch 775
2022-03-07 17:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:52:13 | INFO | train_inner | epoch 775:     44 / 49 loss=2.029, nll_loss=0.28, ppl=1.21, wps=25021.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=37700, lr=0.000162866, gnorm=0.352, loss_scale=32, train_wall=221, gb_free=8.8, wall=103778
2022-03-07 17:52:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:52:29 | INFO | valid | epoch 775 | valid on 'valid' subset | loss 13.562 | nll_loss 12.988 | ppl 8126.91 | wps 46540.2 | wpb 510.9 | bsz 1 | num_updates 37705 | best_loss 8.937
2022-03-07 17:52:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 775 @ 37705 updates
2022-03-07 17:52:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:52:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:52:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 775 @ 37705 updates, score 13.562) (writing took 3.367663220036775 seconds)
2022-03-07 17:52:33 | INFO | fairseq_cli.train | end of epoch 775 (average epoch stats below)
2022-03-07 17:52:33 | INFO | train | epoch 775 | loss 2.029 | nll_loss 0.28 | ppl 1.21 | wps 24803.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 37705 | lr 0.000162855 | gnorm 0.354 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103797
2022-03-07 17:52:33 | INFO | fairseq.trainer | begin training epoch 776
2022-03-07 17:52:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:54:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:54:37 | INFO | valid | epoch 776 | valid on 'valid' subset | loss 13.461 | nll_loss 12.88 | ppl 7539.05 | wps 46618.7 | wpb 510.9 | bsz 1 | num_updates 37754 | best_loss 8.937
2022-03-07 17:54:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 776 @ 37754 updates
2022-03-07 17:54:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:54:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:54:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 776 @ 37754 updates, score 13.461) (writing took 2.3485752739943564 seconds)
2022-03-07 17:54:40 | INFO | fairseq_cli.train | end of epoch 776 (average epoch stats below)
2022-03-07 17:54:40 | INFO | train | epoch 776 | loss 2.028 | nll_loss 0.279 | ppl 1.21 | wps 25015.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37754 | lr 0.000162749 | gnorm 0.356 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 103924
2022-03-07 17:54:40 | INFO | fairseq.trainer | begin training epoch 777
2022-03-07 17:54:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:56:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 17:56:35 | INFO | train_inner | epoch 777:     47 / 49 loss=2.029, nll_loss=0.28, ppl=1.21, wps=24812.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=37800, lr=0.00016265, gnorm=0.357, loss_scale=32, train_wall=222, gb_free=8.8, wall=104039
2022-03-07 17:56:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:56:43 | INFO | valid | epoch 777 | valid on 'valid' subset | loss 13.407 | nll_loss 12.823 | ppl 7245.08 | wps 48231.3 | wpb 510.9 | bsz 1 | num_updates 37802 | best_loss 8.937
2022-03-07 17:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 777 @ 37802 updates
2022-03-07 17:56:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:56:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:56:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 777 @ 37802 updates, score 13.407) (writing took 2.269653012044728 seconds)
2022-03-07 17:56:45 | INFO | fairseq_cli.train | end of epoch 777 (average epoch stats below)
2022-03-07 17:56:45 | INFO | train | epoch 777 | loss 2.028 | nll_loss 0.28 | ppl 1.21 | wps 24781.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37802 | lr 0.000162646 | gnorm 0.358 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104050
2022-03-07 17:56:45 | INFO | fairseq.trainer | begin training epoch 778
2022-03-07 17:56:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 17:58:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 17:58:48 | INFO | valid | epoch 778 | valid on 'valid' subset | loss 13.518 | nll_loss 12.946 | ppl 7890.36 | wps 48024.9 | wpb 510.9 | bsz 1 | num_updates 37851 | best_loss 8.937
2022-03-07 17:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 778 @ 37851 updates
2022-03-07 17:58:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:58:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 17:58:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 778 @ 37851 updates, score 13.518) (writing took 2.285484371241182 seconds)
2022-03-07 17:58:50 | INFO | fairseq_cli.train | end of epoch 778 (average epoch stats below)
2022-03-07 17:58:50 | INFO | train | epoch 778 | loss 2.028 | nll_loss 0.28 | ppl 1.21 | wps 25396.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37851 | lr 0.00016254 | gnorm 0.355 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 104175
2022-03-07 17:58:50 | INFO | fairseq.trainer | begin training epoch 779
2022-03-07 17:58:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:00:49 | INFO | train_inner | epoch 779:     49 / 49 loss=2.028, nll_loss=0.28, ppl=1.21, wps=25381, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=37900, lr=0.000162435, gnorm=0.356, loss_scale=32, train_wall=216, gb_free=8.8, wall=104294
2022-03-07 18:00:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:00:54 | INFO | valid | epoch 779 | valid on 'valid' subset | loss 13.388 | nll_loss 12.803 | ppl 7146.2 | wps 48292.1 | wpb 510.9 | bsz 1 | num_updates 37900 | best_loss 8.937
2022-03-07 18:00:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 779 @ 37900 updates
2022-03-07 18:00:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:00:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:00:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 779 @ 37900 updates, score 13.388) (writing took 2.3351778029464185 seconds)
2022-03-07 18:00:56 | INFO | fairseq_cli.train | end of epoch 779 (average epoch stats below)
2022-03-07 18:00:56 | INFO | train | epoch 779 | loss 2.028 | nll_loss 0.28 | ppl 1.21 | wps 25304.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37900 | lr 0.000162435 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104301
2022-03-07 18:00:56 | INFO | fairseq.trainer | begin training epoch 780
2022-03-07 18:00:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:02:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:02:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:02:59 | INFO | valid | epoch 780 | valid on 'valid' subset | loss 13.538 | nll_loss 12.961 | ppl 7974.44 | wps 48219.7 | wpb 510.9 | bsz 1 | num_updates 37948 | best_loss 8.937
2022-03-07 18:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 780 @ 37948 updates
2022-03-07 18:02:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:03:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 780 @ 37948 updates, score 13.538) (writing took 2.274303400889039 seconds)
2022-03-07 18:03:01 | INFO | fairseq_cli.train | end of epoch 780 (average epoch stats below)
2022-03-07 18:03:01 | INFO | train | epoch 780 | loss 2.028 | nll_loss 0.279 | ppl 1.21 | wps 24878.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 37948 | lr 0.000162333 | gnorm 0.352 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 104426
2022-03-07 18:03:01 | INFO | fairseq.trainer | begin training epoch 781
2022-03-07 18:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:04:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:05:04 | INFO | valid | epoch 781 | valid on 'valid' subset | loss 13.513 | nll_loss 12.938 | ppl 7845.82 | wps 48247.6 | wpb 510.9 | bsz 1 | num_updates 37997 | best_loss 8.937
2022-03-07 18:05:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 781 @ 37997 updates
2022-03-07 18:05:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:05:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:05:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 781 @ 37997 updates, score 13.513) (writing took 2.2378850406967103 seconds)
2022-03-07 18:05:06 | INFO | fairseq_cli.train | end of epoch 781 (average epoch stats below)
2022-03-07 18:05:06 | INFO | train | epoch 781 | loss 2.028 | nll_loss 0.279 | ppl 1.21 | wps 25370.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 37997 | lr 0.000162228 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104551
2022-03-07 18:05:06 | INFO | fairseq.trainer | begin training epoch 782
2022-03-07 18:05:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:05:14 | INFO | train_inner | epoch 782:      3 / 49 loss=2.028, nll_loss=0.279, ppl=1.21, wps=24508.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=38000, lr=0.000162221, gnorm=0.352, loss_scale=32, train_wall=220, gb_free=8.8, wall=104558
2022-03-07 18:07:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:07:09 | INFO | valid | epoch 782 | valid on 'valid' subset | loss 13.526 | nll_loss 12.949 | ppl 7908.17 | wps 48525.2 | wpb 510.9 | bsz 1 | num_updates 38046 | best_loss 8.937
2022-03-07 18:07:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 782 @ 38046 updates
2022-03-07 18:07:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:07:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:07:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 782 @ 38046 updates, score 13.526) (writing took 2.289062339812517 seconds)
2022-03-07 18:07:11 | INFO | fairseq_cli.train | end of epoch 782 (average epoch stats below)
2022-03-07 18:07:11 | INFO | train | epoch 782 | loss 2.028 | nll_loss 0.279 | ppl 1.21 | wps 25416.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38046 | lr 0.000162123 | gnorm 0.353 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 104676
2022-03-07 18:07:11 | INFO | fairseq.trainer | begin training epoch 783
2022-03-07 18:07:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:07:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:09:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:09:14 | INFO | valid | epoch 783 | valid on 'valid' subset | loss 13.518 | nll_loss 12.944 | ppl 7877.57 | wps 48106.1 | wpb 510.9 | bsz 1 | num_updates 38094 | best_loss 8.937
2022-03-07 18:09:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 783 @ 38094 updates
2022-03-07 18:09:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 783 @ 38094 updates, score 13.518) (writing took 2.345645182300359 seconds)
2022-03-07 18:09:17 | INFO | fairseq_cli.train | end of epoch 783 (average epoch stats below)
2022-03-07 18:09:17 | INFO | train | epoch 783 | loss 2.027 | nll_loss 0.279 | ppl 1.21 | wps 24826.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38094 | lr 0.000162021 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104801
2022-03-07 18:09:17 | INFO | fairseq.trainer | begin training epoch 784
2022-03-07 18:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:09:32 | INFO | train_inner | epoch 784:      6 / 49 loss=2.027, nll_loss=0.279, ppl=1.21, wps=25160.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38100, lr=0.000162008, gnorm=0.35, loss_scale=32, train_wall=220, gb_free=8.8, wall=104816
2022-03-07 18:11:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:11:20 | INFO | valid | epoch 784 | valid on 'valid' subset | loss 13.471 | nll_loss 12.89 | ppl 7588.25 | wps 47850.2 | wpb 510.9 | bsz 1 | num_updates 38143 | best_loss 8.937
2022-03-07 18:11:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 784 @ 38143 updates
2022-03-07 18:11:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:11:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:11:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 784 @ 38143 updates, score 13.471) (writing took 2.282796734943986 seconds)
2022-03-07 18:11:22 | INFO | fairseq_cli.train | end of epoch 784 (average epoch stats below)
2022-03-07 18:11:22 | INFO | train | epoch 784 | loss 2.028 | nll_loss 0.28 | ppl 1.21 | wps 25348 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38143 | lr 0.000161917 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 104927
2022-03-07 18:11:22 | INFO | fairseq.trainer | begin training epoch 785
2022-03-07 18:11:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:13:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:13:26 | INFO | valid | epoch 785 | valid on 'valid' subset | loss 13.464 | nll_loss 12.888 | ppl 7580.94 | wps 46658.8 | wpb 510.9 | bsz 1 | num_updates 38192 | best_loss 8.937
2022-03-07 18:13:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 785 @ 38192 updates
2022-03-07 18:13:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:13:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:13:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 785 @ 38192 updates, score 13.464) (writing took 2.2568427808582783 seconds)
2022-03-07 18:13:28 | INFO | fairseq_cli.train | end of epoch 785 (average epoch stats below)
2022-03-07 18:13:28 | INFO | train | epoch 785 | loss 2.028 | nll_loss 0.279 | ppl 1.21 | wps 25277.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38192 | lr 0.000161813 | gnorm 0.352 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 105053
2022-03-07 18:13:28 | INFO | fairseq.trainer | begin training epoch 786
2022-03-07 18:13:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:13:47 | INFO | train_inner | epoch 786:      8 / 49 loss=2.027, nll_loss=0.279, ppl=1.21, wps=25354.5, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=38200, lr=0.000161796, gnorm=0.354, loss_scale=64, train_wall=218, gb_free=8.8, wall=105072
2022-03-07 18:14:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:15:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:15:31 | INFO | valid | epoch 786 | valid on 'valid' subset | loss 13.516 | nll_loss 12.94 | ppl 7857.34 | wps 48065.5 | wpb 510.9 | bsz 1 | num_updates 38240 | best_loss 8.937
2022-03-07 18:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 786 @ 38240 updates
2022-03-07 18:15:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:15:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:15:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 786 @ 38240 updates, score 13.516) (writing took 2.3131422149017453 seconds)
2022-03-07 18:15:33 | INFO | fairseq_cli.train | end of epoch 786 (average epoch stats below)
2022-03-07 18:15:33 | INFO | train | epoch 786 | loss 2.027 | nll_loss 0.278 | ppl 1.21 | wps 24840.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38240 | lr 0.000161712 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105178
2022-03-07 18:15:33 | INFO | fairseq.trainer | begin training epoch 787
2022-03-07 18:15:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:17:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:17:36 | INFO | valid | epoch 787 | valid on 'valid' subset | loss 13.49 | nll_loss 12.911 | ppl 7702.11 | wps 47712 | wpb 510.9 | bsz 1 | num_updates 38289 | best_loss 8.937
2022-03-07 18:17:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 787 @ 38289 updates
2022-03-07 18:17:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:17:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:17:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 787 @ 38289 updates, score 13.49) (writing took 2.366616584826261 seconds)
2022-03-07 18:17:38 | INFO | fairseq_cli.train | end of epoch 787 (average epoch stats below)
2022-03-07 18:17:38 | INFO | train | epoch 787 | loss 2.027 | nll_loss 0.279 | ppl 1.21 | wps 25351.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38289 | lr 0.000161608 | gnorm 0.357 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105303
2022-03-07 18:17:39 | INFO | fairseq.trainer | begin training epoch 788
2022-03-07 18:17:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:18:05 | INFO | train_inner | epoch 788:     11 / 49 loss=2.027, nll_loss=0.279, ppl=1.21, wps=25153.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=38300, lr=0.000161585, gnorm=0.354, loss_scale=32, train_wall=220, gb_free=8.8, wall=105330
2022-03-07 18:19:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:19:42 | INFO | valid | epoch 788 | valid on 'valid' subset | loss 13.477 | nll_loss 12.899 | ppl 7639.2 | wps 45474.7 | wpb 510.9 | bsz 1 | num_updates 38338 | best_loss 8.937
2022-03-07 18:19:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 788 @ 38338 updates
2022-03-07 18:19:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:19:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:19:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 788 @ 38338 updates, score 13.477) (writing took 2.3220323068089783 seconds)
2022-03-07 18:19:45 | INFO | fairseq_cli.train | end of epoch 788 (average epoch stats below)
2022-03-07 18:19:45 | INFO | train | epoch 788 | loss 2.026 | nll_loss 0.278 | ppl 1.21 | wps 25157.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38338 | lr 0.000161505 | gnorm 0.353 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 105430
2022-03-07 18:19:45 | INFO | fairseq.trainer | begin training epoch 789
2022-03-07 18:19:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:20:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:21:50 | INFO | valid | epoch 789 | valid on 'valid' subset | loss 13.511 | nll_loss 12.936 | ppl 7837.36 | wps 46766.7 | wpb 510.9 | bsz 1 | num_updates 38386 | best_loss 8.937
2022-03-07 18:21:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 789 @ 38386 updates
2022-03-07 18:21:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:21:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:21:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 789 @ 38386 updates, score 13.511) (writing took 2.2673346800729632 seconds)
2022-03-07 18:21:52 | INFO | fairseq_cli.train | end of epoch 789 (average epoch stats below)
2022-03-07 18:21:52 | INFO | train | epoch 789 | loss 2.026 | nll_loss 0.278 | ppl 1.21 | wps 24447.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38386 | lr 0.000161404 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 105557
2022-03-07 18:21:52 | INFO | fairseq.trainer | begin training epoch 790
2022-03-07 18:21:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:22:27 | INFO | train_inner | epoch 790:     14 / 49 loss=2.026, nll_loss=0.278, ppl=1.21, wps=24802, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=38400, lr=0.000161374, gnorm=0.352, loss_scale=32, train_wall=223, gb_free=8.8, wall=105592
2022-03-07 18:23:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:23:56 | INFO | valid | epoch 790 | valid on 'valid' subset | loss 13.39 | nll_loss 12.807 | ppl 7165.28 | wps 48397 | wpb 510.9 | bsz 1 | num_updates 38435 | best_loss 8.937
2022-03-07 18:23:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 790 @ 38435 updates
2022-03-07 18:23:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:23:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:23:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 790 @ 38435 updates, score 13.39) (writing took 2.271738873794675 seconds)
2022-03-07 18:23:58 | INFO | fairseq_cli.train | end of epoch 790 (average epoch stats below)
2022-03-07 18:23:58 | INFO | train | epoch 790 | loss 2.026 | nll_loss 0.278 | ppl 1.21 | wps 25261.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38435 | lr 0.000161301 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105683
2022-03-07 18:23:58 | INFO | fairseq.trainer | begin training epoch 791
2022-03-07 18:23:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:25:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:25:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:26:01 | INFO | valid | epoch 791 | valid on 'valid' subset | loss 13.406 | nll_loss 12.826 | ppl 7260.57 | wps 47882.9 | wpb 510.9 | bsz 1 | num_updates 38483 | best_loss 8.937
2022-03-07 18:26:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 791 @ 38483 updates
2022-03-07 18:26:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:26:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:26:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 791 @ 38483 updates, score 13.406) (writing took 2.3275929177179933 seconds)
2022-03-07 18:26:03 | INFO | fairseq_cli.train | end of epoch 791 (average epoch stats below)
2022-03-07 18:26:03 | INFO | train | epoch 791 | loss 2.026 | nll_loss 0.278 | ppl 1.21 | wps 24825 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38483 | lr 0.0001612 | gnorm 0.356 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105808
2022-03-07 18:26:03 | INFO | fairseq.trainer | begin training epoch 792
2022-03-07 18:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:26:45 | INFO | train_inner | epoch 792:     17 / 49 loss=2.026, nll_loss=0.278, ppl=1.21, wps=25136.8, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=38500, lr=0.000161165, gnorm=0.354, loss_scale=32, train_wall=220, gb_free=8.8, wall=105850
2022-03-07 18:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:28:06 | INFO | valid | epoch 792 | valid on 'valid' subset | loss 13.469 | nll_loss 12.888 | ppl 7578.96 | wps 48603.9 | wpb 510.9 | bsz 1 | num_updates 38532 | best_loss 8.937
2022-03-07 18:28:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 792 @ 38532 updates
2022-03-07 18:28:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:28:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 792 @ 38532 updates, score 13.469) (writing took 2.310108260717243 seconds)
2022-03-07 18:28:09 | INFO | fairseq_cli.train | end of epoch 792 (average epoch stats below)
2022-03-07 18:28:09 | INFO | train | epoch 792 | loss 2.026 | nll_loss 0.279 | ppl 1.21 | wps 25381 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38532 | lr 0.000161098 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 105933
2022-03-07 18:28:09 | INFO | fairseq.trainer | begin training epoch 793
2022-03-07 18:28:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:30:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:30:12 | INFO | valid | epoch 793 | valid on 'valid' subset | loss 13.459 | nll_loss 12.883 | ppl 7551.45 | wps 48166.2 | wpb 510.9 | bsz 1 | num_updates 38581 | best_loss 8.937
2022-03-07 18:30:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 793 @ 38581 updates
2022-03-07 18:30:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:30:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:30:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 793 @ 38581 updates, score 13.459) (writing took 2.281060331966728 seconds)
2022-03-07 18:30:14 | INFO | fairseq_cli.train | end of epoch 793 (average epoch stats below)
2022-03-07 18:30:14 | INFO | train | epoch 793 | loss 2.026 | nll_loss 0.278 | ppl 1.21 | wps 25363.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38581 | lr 0.000160995 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106059
2022-03-07 18:30:14 | INFO | fairseq.trainer | begin training epoch 794
2022-03-07 18:30:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:31:00 | INFO | train_inner | epoch 794:     19 / 49 loss=2.026, nll_loss=0.278, ppl=1.21, wps=25402.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=38600, lr=0.000160956, gnorm=0.353, loss_scale=32, train_wall=217, gb_free=8.8, wall=106105
2022-03-07 18:32:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:32:17 | INFO | valid | epoch 794 | valid on 'valid' subset | loss 13.485 | nll_loss 12.907 | ppl 7679.95 | wps 48293.9 | wpb 510.9 | bsz 1 | num_updates 38630 | best_loss 8.937
2022-03-07 18:32:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 794 @ 38630 updates
2022-03-07 18:32:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:32:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:32:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 794 @ 38630 updates, score 13.485) (writing took 2.2631265339441597 seconds)
2022-03-07 18:32:19 | INFO | fairseq_cli.train | end of epoch 794 (average epoch stats below)
2022-03-07 18:32:19 | INFO | train | epoch 794 | loss 2.026 | nll_loss 0.278 | ppl 1.21 | wps 25407.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38630 | lr 0.000160893 | gnorm 0.353 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 106184
2022-03-07 18:32:19 | INFO | fairseq.trainer | begin training epoch 795
2022-03-07 18:32:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:32:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:34:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:34:22 | INFO | valid | epoch 795 | valid on 'valid' subset | loss 13.418 | nll_loss 12.835 | ppl 7308.64 | wps 47922.2 | wpb 510.9 | bsz 1 | num_updates 38678 | best_loss 8.937
2022-03-07 18:34:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 795 @ 38678 updates
2022-03-07 18:34:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:34:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:34:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 795 @ 38678 updates, score 13.418) (writing took 2.368966655805707 seconds)
2022-03-07 18:34:24 | INFO | fairseq_cli.train | end of epoch 795 (average epoch stats below)
2022-03-07 18:34:24 | INFO | train | epoch 795 | loss 2.026 | nll_loss 0.278 | ppl 1.21 | wps 24842.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38678 | lr 0.000160793 | gnorm 0.353 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 106309
2022-03-07 18:34:24 | INFO | fairseq.trainer | begin training epoch 796
2022-03-07 18:34:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:35:18 | INFO | train_inner | epoch 796:     22 / 49 loss=2.025, nll_loss=0.278, ppl=1.21, wps=25195.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38700, lr=0.000160748, gnorm=0.353, loss_scale=32, train_wall=219, gb_free=8.8, wall=106363
2022-03-07 18:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:36:27 | INFO | valid | epoch 796 | valid on 'valid' subset | loss 13.446 | nll_loss 12.865 | ppl 7461.3 | wps 48194.8 | wpb 510.9 | bsz 1 | num_updates 38727 | best_loss 8.937
2022-03-07 18:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 796 @ 38727 updates
2022-03-07 18:36:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 796 @ 38727 updates, score 13.446) (writing took 2.2782394220121205 seconds)
2022-03-07 18:36:29 | INFO | fairseq_cli.train | end of epoch 796 (average epoch stats below)
2022-03-07 18:36:29 | INFO | train | epoch 796 | loss 2.025 | nll_loss 0.278 | ppl 1.21 | wps 25398.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38727 | lr 0.000160692 | gnorm 0.357 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 106434
2022-03-07 18:36:29 | INFO | fairseq.trainer | begin training epoch 797
2022-03-07 18:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:38:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:38:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:38:32 | INFO | valid | epoch 797 | valid on 'valid' subset | loss 13.425 | nll_loss 12.842 | ppl 7341.28 | wps 47989 | wpb 510.9 | bsz 1 | num_updates 38775 | best_loss 8.937
2022-03-07 18:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 797 @ 38775 updates
2022-03-07 18:38:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 797 @ 38775 updates, score 13.425) (writing took 2.2900104047730565 seconds)
2022-03-07 18:38:35 | INFO | fairseq_cli.train | end of epoch 797 (average epoch stats below)
2022-03-07 18:38:35 | INFO | train | epoch 797 | loss 2.025 | nll_loss 0.277 | ppl 1.21 | wps 24856.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38775 | lr 0.000160592 | gnorm 0.357 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 106559
2022-03-07 18:38:35 | INFO | fairseq.trainer | begin training epoch 798
2022-03-07 18:38:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:39:36 | INFO | train_inner | epoch 798:     25 / 49 loss=2.025, nll_loss=0.277, ppl=1.21, wps=25148.2, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=38800, lr=0.00016054, gnorm=0.354, loss_scale=32, train_wall=220, gb_free=8.8, wall=106620
2022-03-07 18:40:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:40:37 | INFO | valid | epoch 798 | valid on 'valid' subset | loss 13.515 | nll_loss 12.936 | ppl 7838.77 | wps 48319.5 | wpb 510.9 | bsz 1 | num_updates 38824 | best_loss 8.937
2022-03-07 18:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 798 @ 38824 updates
2022-03-07 18:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:40:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:40:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 798 @ 38824 updates, score 13.515) (writing took 2.2765266858041286 seconds)
2022-03-07 18:40:40 | INFO | fairseq_cli.train | end of epoch 798 (average epoch stats below)
2022-03-07 18:40:40 | INFO | train | epoch 798 | loss 2.025 | nll_loss 0.277 | ppl 1.21 | wps 25396.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38824 | lr 0.000160491 | gnorm 0.347 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 106684
2022-03-07 18:40:40 | INFO | fairseq.trainer | begin training epoch 799
2022-03-07 18:40:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:42:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:42:43 | INFO | valid | epoch 799 | valid on 'valid' subset | loss 13.507 | nll_loss 12.932 | ppl 7813.16 | wps 48154.9 | wpb 510.9 | bsz 1 | num_updates 38873 | best_loss 8.937
2022-03-07 18:42:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 799 @ 38873 updates
2022-03-07 18:42:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:42:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:42:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 799 @ 38873 updates, score 13.507) (writing took 2.326795090921223 seconds)
2022-03-07 18:42:45 | INFO | fairseq_cli.train | end of epoch 799 (average epoch stats below)
2022-03-07 18:42:45 | INFO | train | epoch 799 | loss 2.025 | nll_loss 0.278 | ppl 1.21 | wps 25363.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38873 | lr 0.00016039 | gnorm 0.354 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 106810
2022-03-07 18:42:45 | INFO | fairseq.trainer | begin training epoch 800
2022-03-07 18:42:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:43:51 | INFO | train_inner | epoch 800:     27 / 49 loss=2.025, nll_loss=0.277, ppl=1.21, wps=25447.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=38900, lr=0.000160334, gnorm=0.352, loss_scale=64, train_wall=217, gb_free=8.8, wall=106875
2022-03-07 18:44:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:44:48 | INFO | valid | epoch 800 | valid on 'valid' subset | loss 13.506 | nll_loss 12.929 | ppl 7798.06 | wps 48197.9 | wpb 510.9 | bsz 1 | num_updates 38921 | best_loss 8.937
2022-03-07 18:44:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 800 @ 38921 updates
2022-03-07 18:44:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 800 @ 38921 updates, score 13.506) (writing took 2.3025720710866153 seconds)
2022-03-07 18:44:50 | INFO | fairseq_cli.train | end of epoch 800 (average epoch stats below)
2022-03-07 18:44:50 | INFO | train | epoch 800 | loss 2.025 | nll_loss 0.277 | ppl 1.21 | wps 24888.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 38921 | lr 0.000160291 | gnorm 0.349 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 106935
2022-03-07 18:44:50 | INFO | fairseq.trainer | begin training epoch 801
2022-03-07 18:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:46:53 | INFO | valid | epoch 801 | valid on 'valid' subset | loss 13.451 | nll_loss 12.873 | ppl 7501.84 | wps 48359.2 | wpb 510.9 | bsz 1 | num_updates 38970 | best_loss 8.937
2022-03-07 18:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 801 @ 38970 updates
2022-03-07 18:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 801 @ 38970 updates, score 13.451) (writing took 2.2990133790299296 seconds)
2022-03-07 18:46:55 | INFO | fairseq_cli.train | end of epoch 801 (average epoch stats below)
2022-03-07 18:46:55 | INFO | train | epoch 801 | loss 2.025 | nll_loss 0.278 | ppl 1.21 | wps 25407.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 38970 | lr 0.00016019 | gnorm 0.356 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 107060
2022-03-07 18:46:55 | INFO | fairseq.trainer | begin training epoch 802
2022-03-07 18:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:48:08 | INFO | train_inner | epoch 802:     30 / 49 loss=2.025, nll_loss=0.277, ppl=1.21, wps=25169, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=39000, lr=0.000160128, gnorm=0.353, loss_scale=32, train_wall=220, gb_free=8.8, wall=107133
2022-03-07 18:48:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:48:58 | INFO | valid | epoch 802 | valid on 'valid' subset | loss 13.511 | nll_loss 12.938 | ppl 7849.73 | wps 48511.3 | wpb 510.9 | bsz 1 | num_updates 39019 | best_loss 8.937
2022-03-07 18:48:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 802 @ 39019 updates
2022-03-07 18:48:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:49:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:49:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 802 @ 39019 updates, score 13.511) (writing took 2.3027212689630687 seconds)
2022-03-07 18:49:00 | INFO | fairseq_cli.train | end of epoch 802 (average epoch stats below)
2022-03-07 18:49:00 | INFO | train | epoch 802 | loss 2.024 | nll_loss 0.276 | ppl 1.21 | wps 25395.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39019 | lr 0.000160089 | gnorm 0.349 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 107185
2022-03-07 18:49:00 | INFO | fairseq.trainer | begin training epoch 803
2022-03-07 18:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:49:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:50:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:51:03 | INFO | valid | epoch 803 | valid on 'valid' subset | loss 13.394 | nll_loss 12.815 | ppl 7203.77 | wps 48316.5 | wpb 510.9 | bsz 1 | num_updates 39067 | best_loss 8.937
2022-03-07 18:51:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 803 @ 39067 updates
2022-03-07 18:51:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:51:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:51:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 803 @ 39067 updates, score 13.394) (writing took 2.345179975964129 seconds)
2022-03-07 18:51:06 | INFO | fairseq_cli.train | end of epoch 803 (average epoch stats below)
2022-03-07 18:51:06 | INFO | train | epoch 803 | loss 2.024 | nll_loss 0.276 | ppl 1.21 | wps 24849.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39067 | lr 0.000159991 | gnorm 0.351 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 107310
2022-03-07 18:51:06 | INFO | fairseq.trainer | begin training epoch 804
2022-03-07 18:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:52:26 | INFO | train_inner | epoch 804:     33 / 49 loss=2.024, nll_loss=0.277, ppl=1.21, wps=25178, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=39100, lr=0.000159923, gnorm=0.351, loss_scale=32, train_wall=219, gb_free=8.8, wall=107391
2022-03-07 18:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:53:08 | INFO | valid | epoch 804 | valid on 'valid' subset | loss 13.587 | nll_loss 13.018 | ppl 8292.83 | wps 48198.3 | wpb 510.9 | bsz 1 | num_updates 39116 | best_loss 8.937
2022-03-07 18:53:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 804 @ 39116 updates
2022-03-07 18:53:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 804 @ 39116 updates, score 13.587) (writing took 2.266183896921575 seconds)
2022-03-07 18:53:11 | INFO | fairseq_cli.train | end of epoch 804 (average epoch stats below)
2022-03-07 18:53:11 | INFO | train | epoch 804 | loss 2.024 | nll_loss 0.277 | ppl 1.21 | wps 25387.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39116 | lr 0.000159891 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107435
2022-03-07 18:53:11 | INFO | fairseq.trainer | begin training epoch 805
2022-03-07 18:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:55:14 | INFO | valid | epoch 805 | valid on 'valid' subset | loss 13.467 | nll_loss 12.89 | ppl 7591.78 | wps 48325.3 | wpb 510.9 | bsz 1 | num_updates 39165 | best_loss 8.937
2022-03-07 18:55:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 805 @ 39165 updates
2022-03-07 18:55:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 805 @ 39165 updates, score 13.467) (writing took 2.273078912869096 seconds)
2022-03-07 18:55:16 | INFO | fairseq_cli.train | end of epoch 805 (average epoch stats below)
2022-03-07 18:55:16 | INFO | train | epoch 805 | loss 2.023 | nll_loss 0.276 | ppl 1.21 | wps 25407.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39165 | lr 0.00015979 | gnorm 0.353 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 107561
2022-03-07 18:55:16 | INFO | fairseq.trainer | begin training epoch 806
2022-03-07 18:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:55:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 18:56:44 | INFO | train_inner | epoch 806:     36 / 49 loss=2.024, nll_loss=0.276, ppl=1.21, wps=25176.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=39200, lr=0.000159719, gnorm=0.354, loss_scale=32, train_wall=220, gb_free=8.8, wall=107648
2022-03-07 18:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:57:19 | INFO | valid | epoch 806 | valid on 'valid' subset | loss 13.51 | nll_loss 12.938 | ppl 7845.93 | wps 48074.8 | wpb 510.9 | bsz 1 | num_updates 39213 | best_loss 8.937
2022-03-07 18:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 806 @ 39213 updates
2022-03-07 18:57:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 806 @ 39213 updates, score 13.51) (writing took 2.2949304240755737 seconds)
2022-03-07 18:57:21 | INFO | fairseq_cli.train | end of epoch 806 (average epoch stats below)
2022-03-07 18:57:21 | INFO | train | epoch 806 | loss 2.024 | nll_loss 0.277 | ppl 1.21 | wps 24872 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39213 | lr 0.000159693 | gnorm 0.355 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 107686
2022-03-07 18:57:21 | INFO | fairseq.trainer | begin training epoch 807
2022-03-07 18:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 18:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 18:59:24 | INFO | valid | epoch 807 | valid on 'valid' subset | loss 13.459 | nll_loss 12.879 | ppl 7534.67 | wps 46956.9 | wpb 510.9 | bsz 1 | num_updates 39262 | best_loss 8.937
2022-03-07 18:59:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 807 @ 39262 updates
2022-03-07 18:59:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:59:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 18:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 807 @ 39262 updates, score 13.459) (writing took 2.3809832371771336 seconds)
2022-03-07 18:59:27 | INFO | fairseq_cli.train | end of epoch 807 (average epoch stats below)
2022-03-07 18:59:27 | INFO | train | epoch 807 | loss 2.024 | nll_loss 0.276 | ppl 1.21 | wps 25290.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39262 | lr 0.000159593 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107811
2022-03-07 18:59:27 | INFO | fairseq.trainer | begin training epoch 808
2022-03-07 18:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:01:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:01:03 | INFO | train_inner | epoch 808:     39 / 49 loss=2.023, nll_loss=0.276, ppl=1.21, wps=25048.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=39300, lr=0.000159516, gnorm=0.35, loss_scale=32, train_wall=220, gb_free=8.8, wall=107907
2022-03-07 19:01:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:01:31 | INFO | valid | epoch 808 | valid on 'valid' subset | loss 13.534 | nll_loss 12.965 | ppl 7993.43 | wps 45851.6 | wpb 510.9 | bsz 1 | num_updates 39310 | best_loss 8.937
2022-03-07 19:01:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 808 @ 39310 updates
2022-03-07 19:01:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:01:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:01:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 808 @ 39310 updates, score 13.534) (writing took 2.3068951149471104 seconds)
2022-03-07 19:01:33 | INFO | fairseq_cli.train | end of epoch 808 (average epoch stats below)
2022-03-07 19:01:33 | INFO | train | epoch 808 | loss 2.023 | nll_loss 0.276 | ppl 1.21 | wps 24580.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39310 | lr 0.000159496 | gnorm 0.352 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 107938
2022-03-07 19:01:33 | INFO | fairseq.trainer | begin training epoch 809
2022-03-07 19:01:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:03:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:03:38 | INFO | valid | epoch 809 | valid on 'valid' subset | loss 13.509 | nll_loss 12.936 | ppl 7838.23 | wps 46968.4 | wpb 510.9 | bsz 1 | num_updates 39359 | best_loss 8.937
2022-03-07 19:03:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 809 @ 39359 updates
2022-03-07 19:03:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:03:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:03:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 809 @ 39359 updates, score 13.509) (writing took 2.28682624688372 seconds)
2022-03-07 19:03:40 | INFO | fairseq_cli.train | end of epoch 809 (average epoch stats below)
2022-03-07 19:03:40 | INFO | train | epoch 809 | loss 2.024 | nll_loss 0.277 | ppl 1.21 | wps 24989.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39359 | lr 0.000159396 | gnorm 0.353 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108065
2022-03-07 19:03:40 | INFO | fairseq.trainer | begin training epoch 810
2022-03-07 19:03:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:05:22 | INFO | train_inner | epoch 810:     41 / 49 loss=2.024, nll_loss=0.276, ppl=1.21, wps=25036.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=39400, lr=0.000159313, gnorm=0.351, loss_scale=32, train_wall=221, gb_free=8.8, wall=108167
2022-03-07 19:05:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:05:45 | INFO | valid | epoch 810 | valid on 'valid' subset | loss 13.456 | nll_loss 12.879 | ppl 7533.73 | wps 46983.5 | wpb 510.9 | bsz 1 | num_updates 39408 | best_loss 8.937
2022-03-07 19:05:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 810 @ 39408 updates
2022-03-07 19:05:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:05:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:05:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 810 @ 39408 updates, score 13.456) (writing took 2.3118584929034114 seconds)
2022-03-07 19:05:47 | INFO | fairseq_cli.train | end of epoch 810 (average epoch stats below)
2022-03-07 19:05:47 | INFO | train | epoch 810 | loss 2.023 | nll_loss 0.276 | ppl 1.21 | wps 25034.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39408 | lr 0.000159297 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108192
2022-03-07 19:05:47 | INFO | fairseq.trainer | begin training epoch 811
2022-03-07 19:05:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:07:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:07:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:07:52 | INFO | valid | epoch 811 | valid on 'valid' subset | loss 13.497 | nll_loss 12.918 | ppl 7739.67 | wps 46161.5 | wpb 510.9 | bsz 1 | num_updates 39456 | best_loss 8.937
2022-03-07 19:07:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 811 @ 39456 updates
2022-03-07 19:07:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:07:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:07:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 811 @ 39456 updates, score 13.497) (writing took 2.377167232800275 seconds)
2022-03-07 19:07:55 | INFO | fairseq_cli.train | end of epoch 811 (average epoch stats below)
2022-03-07 19:07:55 | INFO | train | epoch 811 | loss 2.023 | nll_loss 0.276 | ppl 1.21 | wps 24456.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39456 | lr 0.0001592 | gnorm 0.354 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108319
2022-03-07 19:07:55 | INFO | fairseq.trainer | begin training epoch 812
2022-03-07 19:07:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:09:44 | INFO | train_inner | epoch 812:     44 / 49 loss=2.023, nll_loss=0.276, ppl=1.21, wps=24788.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=39500, lr=0.000159111, gnorm=0.352, loss_scale=32, train_wall=223, gb_free=8.8, wall=108428
2022-03-07 19:09:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:09:59 | INFO | valid | epoch 812 | valid on 'valid' subset | loss 13.578 | nll_loss 13.009 | ppl 8244.09 | wps 46469.4 | wpb 510.9 | bsz 1 | num_updates 39505 | best_loss 8.937
2022-03-07 19:09:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 812 @ 39505 updates
2022-03-07 19:09:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:10:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 812 @ 39505 updates, score 13.578) (writing took 2.30160041898489 seconds)
2022-03-07 19:10:02 | INFO | fairseq_cli.train | end of epoch 812 (average epoch stats below)
2022-03-07 19:10:02 | INFO | train | epoch 812 | loss 2.023 | nll_loss 0.276 | ppl 1.21 | wps 25009.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39505 | lr 0.000159101 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108446
2022-03-07 19:10:02 | INFO | fairseq.trainer | begin training epoch 813
2022-03-07 19:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:12:06 | INFO | valid | epoch 813 | valid on 'valid' subset | loss 13.435 | nll_loss 12.856 | ppl 7412.11 | wps 46833.7 | wpb 510.9 | bsz 1 | num_updates 39554 | best_loss 8.937
2022-03-07 19:12:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 813 @ 39554 updates
2022-03-07 19:12:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:12:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:12:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 813 @ 39554 updates, score 13.435) (writing took 2.2617372437380254 seconds)
2022-03-07 19:12:08 | INFO | fairseq_cli.train | end of epoch 813 (average epoch stats below)
2022-03-07 19:12:08 | INFO | train | epoch 813 | loss 2.023 | nll_loss 0.276 | ppl 1.21 | wps 25063.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39554 | lr 0.000159003 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108573
2022-03-07 19:12:09 | INFO | fairseq.trainer | begin training epoch 814
2022-03-07 19:12:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:13:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:14:05 | INFO | train_inner | epoch 814:     47 / 49 loss=2.023, nll_loss=0.276, ppl=1.21, wps=24813.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39600, lr=0.00015891, gnorm=0.351, loss_scale=32, train_wall=223, gb_free=8.8, wall=108690
2022-03-07 19:14:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:14:13 | INFO | valid | epoch 814 | valid on 'valid' subset | loss 13.544 | nll_loss 12.975 | ppl 8053.23 | wps 46942.2 | wpb 510.9 | bsz 1 | num_updates 39602 | best_loss 8.937
2022-03-07 19:14:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 814 @ 39602 updates
2022-03-07 19:14:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:14:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:14:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 814 @ 39602 updates, score 13.544) (writing took 2.274181235115975 seconds)
2022-03-07 19:14:16 | INFO | fairseq_cli.train | end of epoch 814 (average epoch stats below)
2022-03-07 19:14:16 | INFO | train | epoch 814 | loss 2.023 | nll_loss 0.276 | ppl 1.21 | wps 24477.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39602 | lr 0.000158906 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108700
2022-03-07 19:14:16 | INFO | fairseq.trainer | begin training epoch 815
2022-03-07 19:14:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:16:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:16:20 | INFO | valid | epoch 815 | valid on 'valid' subset | loss 13.467 | nll_loss 12.89 | ppl 7588.97 | wps 46321.3 | wpb 510.9 | bsz 1 | num_updates 39651 | best_loss 8.937
2022-03-07 19:16:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 815 @ 39651 updates
2022-03-07 19:16:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:16:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:16:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 815 @ 39651 updates, score 13.467) (writing took 2.423135334160179 seconds)
2022-03-07 19:16:23 | INFO | fairseq_cli.train | end of epoch 815 (average epoch stats below)
2022-03-07 19:16:23 | INFO | train | epoch 815 | loss 2.022 | nll_loss 0.275 | ppl 1.21 | wps 24973.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39651 | lr 0.000158808 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108828
2022-03-07 19:16:23 | INFO | fairseq.trainer | begin training epoch 816
2022-03-07 19:16:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:18:23 | INFO | train_inner | epoch 816:     49 / 49 loss=2.022, nll_loss=0.275, ppl=1.21, wps=25018.3, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=39700, lr=0.00015871, gnorm=0.349, loss_scale=32, train_wall=219, gb_free=8.8, wall=108948
2022-03-07 19:18:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:18:28 | INFO | valid | epoch 816 | valid on 'valid' subset | loss 13.533 | nll_loss 12.962 | ppl 7981.5 | wps 46527.3 | wpb 510.9 | bsz 1 | num_updates 39700 | best_loss 8.937
2022-03-07 19:18:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 816 @ 39700 updates
2022-03-07 19:18:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:18:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 816 @ 39700 updates, score 13.533) (writing took 2.301449988037348 seconds)
2022-03-07 19:18:30 | INFO | fairseq_cli.train | end of epoch 816 (average epoch stats below)
2022-03-07 19:18:30 | INFO | train | epoch 816 | loss 2.022 | nll_loss 0.275 | ppl 1.21 | wps 25002.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39700 | lr 0.00015871 | gnorm 0.35 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 108955
2022-03-07 19:18:30 | INFO | fairseq.trainer | begin training epoch 817
2022-03-07 19:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:19:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:20:35 | INFO | valid | epoch 817 | valid on 'valid' subset | loss 13.472 | nll_loss 12.896 | ppl 7620.98 | wps 46344.2 | wpb 510.9 | bsz 1 | num_updates 39748 | best_loss 8.937
2022-03-07 19:20:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 817 @ 39748 updates
2022-03-07 19:20:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:20:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:20:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 817 @ 39748 updates, score 13.472) (writing took 2.269463190343231 seconds)
2022-03-07 19:20:37 | INFO | fairseq_cli.train | end of epoch 817 (average epoch stats below)
2022-03-07 19:20:37 | INFO | train | epoch 817 | loss 2.022 | nll_loss 0.275 | ppl 1.21 | wps 24483.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39748 | lr 0.000158614 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109082
2022-03-07 19:20:37 | INFO | fairseq.trainer | begin training epoch 818
2022-03-07 19:20:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:22:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:22:42 | INFO | valid | epoch 818 | valid on 'valid' subset | loss 13.531 | nll_loss 12.961 | ppl 7974.66 | wps 47114.9 | wpb 510.9 | bsz 1 | num_updates 39797 | best_loss 8.937
2022-03-07 19:22:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 818 @ 39797 updates
2022-03-07 19:22:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:22:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:22:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 818 @ 39797 updates, score 13.531) (writing took 2.3091869661584496 seconds)
2022-03-07 19:22:44 | INFO | fairseq_cli.train | end of epoch 818 (average epoch stats below)
2022-03-07 19:22:44 | INFO | train | epoch 818 | loss 2.022 | nll_loss 0.275 | ppl 1.21 | wps 24963.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39797 | lr 0.000158517 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109209
2022-03-07 19:22:44 | INFO | fairseq.trainer | begin training epoch 819
2022-03-07 19:22:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:22:52 | INFO | train_inner | epoch 819:      3 / 49 loss=2.022, nll_loss=0.275, ppl=1.21, wps=24116.7, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=39800, lr=0.000158511, gnorm=0.35, loss_scale=32, train_wall=223, gb_free=8.8, wall=109217
2022-03-07 19:24:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:24:49 | INFO | valid | epoch 819 | valid on 'valid' subset | loss 13.499 | nll_loss 12.923 | ppl 7766.61 | wps 45595.4 | wpb 510.9 | bsz 1 | num_updates 39846 | best_loss 8.937
2022-03-07 19:24:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 819 @ 39846 updates
2022-03-07 19:24:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:24:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:24:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 819 @ 39846 updates, score 13.499) (writing took 2.5041226521134377 seconds)
2022-03-07 19:24:52 | INFO | fairseq_cli.train | end of epoch 819 (average epoch stats below)
2022-03-07 19:24:52 | INFO | train | epoch 819 | loss 2.022 | nll_loss 0.275 | ppl 1.21 | wps 24933.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 39846 | lr 0.000158419 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109337
2022-03-07 19:24:52 | INFO | fairseq.trainer | begin training epoch 820
2022-03-07 19:24:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:25:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:26:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:26:57 | INFO | valid | epoch 820 | valid on 'valid' subset | loss 13.473 | nll_loss 12.894 | ppl 7612.53 | wps 46469.3 | wpb 510.9 | bsz 1 | num_updates 39894 | best_loss 8.937
2022-03-07 19:26:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 820 @ 39894 updates
2022-03-07 19:26:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:26:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:26:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 820 @ 39894 updates, score 13.473) (writing took 2.342288702726364 seconds)
2022-03-07 19:26:59 | INFO | fairseq_cli.train | end of epoch 820 (average epoch stats below)
2022-03-07 19:26:59 | INFO | train | epoch 820 | loss 2.021 | nll_loss 0.275 | ppl 1.21 | wps 24500.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 39894 | lr 0.000158324 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109464
2022-03-07 19:26:59 | INFO | fairseq.trainer | begin training epoch 821
2022-03-07 19:26:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:27:14 | INFO | train_inner | epoch 821:      6 / 49 loss=2.022, nll_loss=0.275, ppl=1.21, wps=24769, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=39900, lr=0.000158312, gnorm=0.349, loss_scale=32, train_wall=223, gb_free=8.8, wall=109479
2022-03-07 19:28:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:29:04 | INFO | valid | epoch 821 | valid on 'valid' subset | loss 13.533 | nll_loss 12.96 | ppl 7970.68 | wps 46535.4 | wpb 510.9 | bsz 1 | num_updates 39943 | best_loss 8.937
2022-03-07 19:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 821 @ 39943 updates
2022-03-07 19:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 821 @ 39943 updates, score 13.533) (writing took 2.289666718803346 seconds)
2022-03-07 19:29:06 | INFO | fairseq_cli.train | end of epoch 821 (average epoch stats below)
2022-03-07 19:29:06 | INFO | train | epoch 821 | loss 2.022 | nll_loss 0.275 | ppl 1.21 | wps 25027.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39943 | lr 0.000158227 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109591
2022-03-07 19:29:06 | INFO | fairseq.trainer | begin training epoch 822
2022-03-07 19:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:31:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:31:11 | INFO | valid | epoch 822 | valid on 'valid' subset | loss 13.556 | nll_loss 12.982 | ppl 8090.97 | wps 47014.2 | wpb 510.9 | bsz 1 | num_updates 39992 | best_loss 8.937
2022-03-07 19:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 822 @ 39992 updates
2022-03-07 19:31:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:31:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:31:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 822 @ 39992 updates, score 13.556) (writing took 2.312729478813708 seconds)
2022-03-07 19:31:13 | INFO | fairseq_cli.train | end of epoch 822 (average epoch stats below)
2022-03-07 19:31:13 | INFO | train | epoch 822 | loss 2.021 | nll_loss 0.275 | ppl 1.21 | wps 25000.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 39992 | lr 0.00015813 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109718
2022-03-07 19:31:13 | INFO | fairseq.trainer | begin training epoch 823
2022-03-07 19:31:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:31:33 | INFO | train_inner | epoch 823:      8 / 49 loss=2.021, nll_loss=0.275, ppl=1.21, wps=25037.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40000, lr=0.000158114, gnorm=0.349, loss_scale=64, train_wall=221, gb_free=8.8, wall=109738
2022-03-07 19:31:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:33:18 | INFO | valid | epoch 823 | valid on 'valid' subset | loss 13.503 | nll_loss 12.933 | ppl 7818.83 | wps 44502 | wpb 510.9 | bsz 1 | num_updates 40040 | best_loss 8.937
2022-03-07 19:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 823 @ 40040 updates
2022-03-07 19:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:33:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:33:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 823 @ 40040 updates, score 13.503) (writing took 2.479116030037403 seconds)
2022-03-07 19:33:20 | INFO | fairseq_cli.train | end of epoch 823 (average epoch stats below)
2022-03-07 19:33:20 | INFO | train | epoch 823 | loss 2.021 | nll_loss 0.275 | ppl 1.21 | wps 24446.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40040 | lr 0.000158035 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109845
2022-03-07 19:33:20 | INFO | fairseq.trainer | begin training epoch 824
2022-03-07 19:33:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:35:25 | INFO | valid | epoch 824 | valid on 'valid' subset | loss 13.514 | nll_loss 12.943 | ppl 7872.65 | wps 46453 | wpb 510.9 | bsz 1 | num_updates 40089 | best_loss 8.937
2022-03-07 19:35:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 824 @ 40089 updates
2022-03-07 19:35:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:35:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 824 @ 40089 updates, score 13.514) (writing took 2.383867233991623 seconds)
2022-03-07 19:35:28 | INFO | fairseq_cli.train | end of epoch 824 (average epoch stats below)
2022-03-07 19:35:28 | INFO | train | epoch 824 | loss 2.021 | nll_loss 0.275 | ppl 1.21 | wps 24986 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40089 | lr 0.000157938 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 109972
2022-03-07 19:35:28 | INFO | fairseq.trainer | begin training epoch 825
2022-03-07 19:35:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:35:55 | INFO | train_inner | epoch 825:     11 / 49 loss=2.021, nll_loss=0.275, ppl=1.21, wps=24769.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40100, lr=0.000157917, gnorm=0.347, loss_scale=32, train_wall=223, gb_free=8.8, wall=110000
2022-03-07 19:37:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:37:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:37:32 | INFO | valid | epoch 825 | valid on 'valid' subset | loss 13.513 | nll_loss 12.935 | ppl 7833.43 | wps 47321.6 | wpb 510.9 | bsz 1 | num_updates 40137 | best_loss 8.937
2022-03-07 19:37:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 825 @ 40137 updates
2022-03-07 19:37:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:37:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 825 @ 40137 updates, score 13.513) (writing took 2.3006177470088005 seconds)
2022-03-07 19:37:35 | INFO | fairseq_cli.train | end of epoch 825 (average epoch stats below)
2022-03-07 19:37:35 | INFO | train | epoch 825 | loss 2.021 | nll_loss 0.275 | ppl 1.21 | wps 24507.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40137 | lr 0.000157844 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110099
2022-03-07 19:37:35 | INFO | fairseq.trainer | begin training epoch 826
2022-03-07 19:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:39:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:39:39 | INFO | valid | epoch 826 | valid on 'valid' subset | loss 13.49 | nll_loss 12.914 | ppl 7716.67 | wps 46661.4 | wpb 510.9 | bsz 1 | num_updates 40186 | best_loss 8.937
2022-03-07 19:39:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 826 @ 40186 updates
2022-03-07 19:39:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:39:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:39:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 826 @ 40186 updates, score 13.49) (writing took 2.269202542025596 seconds)
2022-03-07 19:39:41 | INFO | fairseq_cli.train | end of epoch 826 (average epoch stats below)
2022-03-07 19:39:41 | INFO | train | epoch 826 | loss 2.021 | nll_loss 0.274 | ppl 1.21 | wps 25045.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40186 | lr 0.000157748 | gnorm 0.352 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110226
2022-03-07 19:39:41 | INFO | fairseq.trainer | begin training epoch 827
2022-03-07 19:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:40:16 | INFO | train_inner | epoch 827:     14 / 49 loss=2.021, nll_loss=0.275, ppl=1.21, wps=24813.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40200, lr=0.00015772, gnorm=0.35, loss_scale=32, train_wall=223, gb_free=8.8, wall=110261
2022-03-07 19:41:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:41:46 | INFO | valid | epoch 827 | valid on 'valid' subset | loss 13.58 | nll_loss 13.014 | ppl 8271.38 | wps 46160 | wpb 510.9 | bsz 1 | num_updates 40235 | best_loss 8.937
2022-03-07 19:41:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 827 @ 40235 updates
2022-03-07 19:41:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:41:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:41:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 827 @ 40235 updates, score 13.58) (writing took 2.395502282772213 seconds)
2022-03-07 19:41:49 | INFO | fairseq_cli.train | end of epoch 827 (average epoch stats below)
2022-03-07 19:41:49 | INFO | train | epoch 827 | loss 2.021 | nll_loss 0.275 | ppl 1.21 | wps 24943.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40235 | lr 0.000157651 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110354
2022-03-07 19:41:49 | INFO | fairseq.trainer | begin training epoch 828
2022-03-07 19:41:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:43:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:43:52 | INFO | valid | epoch 828 | valid on 'valid' subset | loss 13.511 | nll_loss 12.934 | ppl 7827.77 | wps 48270.4 | wpb 510.9 | bsz 1 | num_updates 40283 | best_loss 8.937
2022-03-07 19:43:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 828 @ 40283 updates
2022-03-07 19:43:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:43:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 828 @ 40283 updates, score 13.511) (writing took 2.3615135666914284 seconds)
2022-03-07 19:43:54 | INFO | fairseq_cli.train | end of epoch 828 (average epoch stats below)
2022-03-07 19:43:54 | INFO | train | epoch 828 | loss 2.02 | nll_loss 0.274 | ppl 1.21 | wps 24857.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40283 | lr 0.000157558 | gnorm 0.35 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 110479
2022-03-07 19:43:54 | INFO | fairseq.trainer | begin training epoch 829
2022-03-07 19:43:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:44:36 | INFO | train_inner | epoch 829:     17 / 49 loss=2.02, nll_loss=0.274, ppl=1.21, wps=25023.6, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=40300, lr=0.000157524, gnorm=0.35, loss_scale=32, train_wall=221, gb_free=8.8, wall=110520
2022-03-07 19:45:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:45:57 | INFO | valid | epoch 829 | valid on 'valid' subset | loss 13.578 | nll_loss 13.01 | ppl 8249.06 | wps 47746.8 | wpb 510.9 | bsz 1 | num_updates 40332 | best_loss 8.937
2022-03-07 19:45:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 829 @ 40332 updates
2022-03-07 19:45:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:45:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 829 @ 40332 updates, score 13.578) (writing took 2.2782110371626914 seconds)
2022-03-07 19:45:59 | INFO | fairseq_cli.train | end of epoch 829 (average epoch stats below)
2022-03-07 19:45:59 | INFO | train | epoch 829 | loss 2.02 | nll_loss 0.274 | ppl 1.21 | wps 25393 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40332 | lr 0.000157462 | gnorm 0.346 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 110604
2022-03-07 19:45:59 | INFO | fairseq.trainer | begin training epoch 830
2022-03-07 19:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:47:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:48:03 | INFO | valid | epoch 830 | valid on 'valid' subset | loss 13.546 | nll_loss 12.976 | ppl 8057.4 | wps 46952 | wpb 510.9 | bsz 1 | num_updates 40381 | best_loss 8.937
2022-03-07 19:48:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 830 @ 40381 updates
2022-03-07 19:48:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:48:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 830 @ 40381 updates, score 13.546) (writing took 2.3078788123093545 seconds)
2022-03-07 19:48:06 | INFO | fairseq_cli.train | end of epoch 830 (average epoch stats below)
2022-03-07 19:48:06 | INFO | train | epoch 830 | loss 2.02 | nll_loss 0.274 | ppl 1.21 | wps 25142.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40381 | lr 0.000157366 | gnorm 0.349 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 110730
2022-03-07 19:48:06 | INFO | fairseq.trainer | begin training epoch 831
2022-03-07 19:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:48:53 | INFO | train_inner | epoch 831:     19 / 49 loss=2.02, nll_loss=0.274, ppl=1.21, wps=25218.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40400, lr=0.000157329, gnorm=0.348, loss_scale=32, train_wall=219, gb_free=8.8, wall=110777
2022-03-07 19:49:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:50:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:50:10 | INFO | valid | epoch 831 | valid on 'valid' subset | loss 13.569 | nll_loss 13 | ppl 8191.95 | wps 45313.4 | wpb 510.9 | bsz 1 | num_updates 40429 | best_loss 8.937
2022-03-07 19:50:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 831 @ 40429 updates
2022-03-07 19:50:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:50:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:50:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 831 @ 40429 updates, score 13.569) (writing took 2.3407051800750196 seconds)
2022-03-07 19:50:13 | INFO | fairseq_cli.train | end of epoch 831 (average epoch stats below)
2022-03-07 19:50:13 | INFO | train | epoch 831 | loss 2.02 | nll_loss 0.274 | ppl 1.21 | wps 24479.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40429 | lr 0.000157273 | gnorm 0.353 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110858
2022-03-07 19:50:13 | INFO | fairseq.trainer | begin training epoch 832
2022-03-07 19:50:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:52:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:52:18 | INFO | valid | epoch 832 | valid on 'valid' subset | loss 13.504 | nll_loss 12.927 | ppl 7788.42 | wps 46672.9 | wpb 510.9 | bsz 1 | num_updates 40478 | best_loss 8.937
2022-03-07 19:52:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 832 @ 40478 updates
2022-03-07 19:52:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:52:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 832 @ 40478 updates, score 13.504) (writing took 2.3794987821020186 seconds)
2022-03-07 19:52:20 | INFO | fairseq_cli.train | end of epoch 832 (average epoch stats below)
2022-03-07 19:52:20 | INFO | train | epoch 832 | loss 2.02 | nll_loss 0.274 | ppl 1.21 | wps 24973.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40478 | lr 0.000157178 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 110985
2022-03-07 19:52:20 | INFO | fairseq.trainer | begin training epoch 833
2022-03-07 19:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:53:14 | INFO | train_inner | epoch 833:     22 / 49 loss=2.02, nll_loss=0.274, ppl=1.21, wps=24797.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40500, lr=0.000157135, gnorm=0.35, loss_scale=32, train_wall=223, gb_free=8.8, wall=111039
2022-03-07 19:54:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:54:25 | INFO | valid | epoch 833 | valid on 'valid' subset | loss 13.446 | nll_loss 12.867 | ppl 7472.37 | wps 46746.4 | wpb 510.9 | bsz 1 | num_updates 40527 | best_loss 8.937
2022-03-07 19:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 833 @ 40527 updates
2022-03-07 19:54:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:54:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:54:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 833 @ 40527 updates, score 13.446) (writing took 2.2963503301143646 seconds)
2022-03-07 19:54:27 | INFO | fairseq_cli.train | end of epoch 833 (average epoch stats below)
2022-03-07 19:54:27 | INFO | train | epoch 833 | loss 2.019 | nll_loss 0.273 | ppl 1.21 | wps 25020.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40527 | lr 0.000157082 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111112
2022-03-07 19:54:27 | INFO | fairseq.trainer | begin training epoch 834
2022-03-07 19:54:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:55:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 19:56:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:56:32 | INFO | valid | epoch 834 | valid on 'valid' subset | loss 13.458 | nll_loss 12.883 | ppl 7554.18 | wps 47035.3 | wpb 510.9 | bsz 1 | num_updates 40575 | best_loss 8.937
2022-03-07 19:56:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 834 @ 40575 updates
2022-03-07 19:56:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:56:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:56:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 834 @ 40575 updates, score 13.458) (writing took 2.23095657909289 seconds)
2022-03-07 19:56:34 | INFO | fairseq_cli.train | end of epoch 834 (average epoch stats below)
2022-03-07 19:56:34 | INFO | train | epoch 834 | loss 2.019 | nll_loss 0.273 | ppl 1.21 | wps 24529.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40575 | lr 0.00015699 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111239
2022-03-07 19:56:34 | INFO | fairseq.trainer | begin training epoch 835
2022-03-07 19:56:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 19:57:36 | INFO | train_inner | epoch 835:     25 / 49 loss=2.019, nll_loss=0.274, ppl=1.21, wps=24803.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=40600, lr=0.000156941, gnorm=0.351, loss_scale=32, train_wall=223, gb_free=8.8, wall=111301
2022-03-07 19:58:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 19:58:39 | INFO | valid | epoch 835 | valid on 'valid' subset | loss 13.453 | nll_loss 12.874 | ppl 7506.72 | wps 46915 | wpb 510.9 | bsz 1 | num_updates 40624 | best_loss 8.937
2022-03-07 19:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 835 @ 40624 updates
2022-03-07 19:58:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:58:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 19:58:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 835 @ 40624 updates, score 13.453) (writing took 2.3326022191904485 seconds)
2022-03-07 19:58:41 | INFO | fairseq_cli.train | end of epoch 835 (average epoch stats below)
2022-03-07 19:58:41 | INFO | train | epoch 835 | loss 2.02 | nll_loss 0.274 | ppl 1.21 | wps 25018.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40624 | lr 0.000156895 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111366
2022-03-07 19:58:41 | INFO | fairseq.trainer | begin training epoch 836
2022-03-07 19:58:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:00:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:00:46 | INFO | valid | epoch 836 | valid on 'valid' subset | loss 13.503 | nll_loss 12.927 | ppl 7788.24 | wps 46506.4 | wpb 510.9 | bsz 1 | num_updates 40673 | best_loss 8.937
2022-03-07 20:00:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 836 @ 40673 updates
2022-03-07 20:00:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:00:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:00:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 836 @ 40673 updates, score 13.503) (writing took 2.3822323381900787 seconds)
2022-03-07 20:00:48 | INFO | fairseq_cli.train | end of epoch 836 (average epoch stats below)
2022-03-07 20:00:48 | INFO | train | epoch 836 | loss 2.02 | nll_loss 0.274 | ppl 1.21 | wps 24961.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40673 | lr 0.0001568 | gnorm 0.347 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 111493
2022-03-07 20:00:48 | INFO | fairseq.trainer | begin training epoch 837
2022-03-07 20:00:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:01:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:01:58 | INFO | train_inner | epoch 837:     28 / 49 loss=2.019, nll_loss=0.274, ppl=1.21, wps=24790.4, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=40700, lr=0.000156748, gnorm=0.347, loss_scale=32, train_wall=223, gb_free=8.8, wall=111562
2022-03-07 20:02:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:02:53 | INFO | valid | epoch 837 | valid on 'valid' subset | loss 13.517 | nll_loss 12.942 | ppl 7867.19 | wps 46768.1 | wpb 510.9 | bsz 1 | num_updates 40721 | best_loss 8.937
2022-03-07 20:02:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 837 @ 40721 updates
2022-03-07 20:02:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:02:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 837 @ 40721 updates, score 13.517) (writing took 2.356897218618542 seconds)
2022-03-07 20:02:55 | INFO | fairseq_cli.train | end of epoch 837 (average epoch stats below)
2022-03-07 20:02:55 | INFO | train | epoch 837 | loss 2.019 | nll_loss 0.274 | ppl 1.21 | wps 24475.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40721 | lr 0.000156708 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111620
2022-03-07 20:02:55 | INFO | fairseq.trainer | begin training epoch 838
2022-03-07 20:02:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:04:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:05:00 | INFO | valid | epoch 838 | valid on 'valid' subset | loss 13.505 | nll_loss 12.933 | ppl 7819.77 | wps 46687.3 | wpb 510.9 | bsz 1 | num_updates 40770 | best_loss 8.937
2022-03-07 20:05:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 838 @ 40770 updates
2022-03-07 20:05:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 838 @ 40770 updates, score 13.505) (writing took 2.25916680181399 seconds)
2022-03-07 20:05:03 | INFO | fairseq_cli.train | end of epoch 838 (average epoch stats below)
2022-03-07 20:05:03 | INFO | train | epoch 838 | loss 2.019 | nll_loss 0.273 | ppl 1.21 | wps 25004.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 40770 | lr 0.000156614 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111747
2022-03-07 20:05:03 | INFO | fairseq.trainer | begin training epoch 839
2022-03-07 20:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:06:17 | INFO | train_inner | epoch 839:     30 / 49 loss=2.019, nll_loss=0.273, ppl=1.21, wps=25021.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=40800, lr=0.000156556, gnorm=0.349, loss_scale=32, train_wall=221, gb_free=8.8, wall=111822
2022-03-07 20:06:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:07:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:07:07 | INFO | valid | epoch 839 | valid on 'valid' subset | loss 13.5 | nll_loss 12.926 | ppl 7782.52 | wps 47157.5 | wpb 510.9 | bsz 1 | num_updates 40818 | best_loss 8.937
2022-03-07 20:07:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 839 @ 40818 updates
2022-03-07 20:07:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:07:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:07:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 839 @ 40818 updates, score 13.5) (writing took 2.332964546047151 seconds)
2022-03-07 20:07:10 | INFO | fairseq_cli.train | end of epoch 839 (average epoch stats below)
2022-03-07 20:07:10 | INFO | train | epoch 839 | loss 2.019 | nll_loss 0.273 | ppl 1.21 | wps 24518.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40818 | lr 0.000156522 | gnorm 0.345 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 111874
2022-03-07 20:07:10 | INFO | fairseq.trainer | begin training epoch 840
2022-03-07 20:07:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:09:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:09:14 | INFO | valid | epoch 840 | valid on 'valid' subset | loss 13.502 | nll_loss 12.924 | ppl 7773.75 | wps 46372.1 | wpb 510.9 | bsz 1 | num_updates 40867 | best_loss 8.937
2022-03-07 20:09:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 840 @ 40867 updates
2022-03-07 20:09:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 840 @ 40867 updates, score 13.502) (writing took 2.3707678262144327 seconds)
2022-03-07 20:09:17 | INFO | fairseq_cli.train | end of epoch 840 (average epoch stats below)
2022-03-07 20:09:17 | INFO | train | epoch 840 | loss 2.018 | nll_loss 0.273 | ppl 1.21 | wps 24964.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40867 | lr 0.000156428 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112002
2022-03-07 20:09:17 | INFO | fairseq.trainer | begin training epoch 841
2022-03-07 20:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:10:39 | INFO | train_inner | epoch 841:     33 / 49 loss=2.018, nll_loss=0.273, ppl=1.21, wps=24788.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=40900, lr=0.000156365, gnorm=0.344, loss_scale=32, train_wall=223, gb_free=8.8, wall=112083
2022-03-07 20:11:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:11:22 | INFO | valid | epoch 841 | valid on 'valid' subset | loss 13.507 | nll_loss 12.937 | ppl 7841.09 | wps 46170 | wpb 510.9 | bsz 1 | num_updates 40916 | best_loss 8.937
2022-03-07 20:11:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 841 @ 40916 updates
2022-03-07 20:11:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:11:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 841 @ 40916 updates, score 13.507) (writing took 2.318807716947049 seconds)
2022-03-07 20:11:24 | INFO | fairseq_cli.train | end of epoch 841 (average epoch stats below)
2022-03-07 20:11:24 | INFO | train | epoch 841 | loss 2.018 | nll_loss 0.272 | ppl 1.21 | wps 24969.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 40916 | lr 0.000156334 | gnorm 0.344 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112129
2022-03-07 20:11:24 | INFO | fairseq.trainer | begin training epoch 842
2022-03-07 20:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:12:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:13:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:13:29 | INFO | valid | epoch 842 | valid on 'valid' subset | loss 13.495 | nll_loss 12.924 | ppl 7769.22 | wps 46856.4 | wpb 510.9 | bsz 1 | num_updates 40964 | best_loss 8.937
2022-03-07 20:13:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 842 @ 40964 updates
2022-03-07 20:13:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 842 @ 40964 updates, score 13.495) (writing took 2.264003255404532 seconds)
2022-03-07 20:13:31 | INFO | fairseq_cli.train | end of epoch 842 (average epoch stats below)
2022-03-07 20:13:31 | INFO | train | epoch 842 | loss 2.019 | nll_loss 0.273 | ppl 1.21 | wps 24523.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 40964 | lr 0.000156242 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112256
2022-03-07 20:13:31 | INFO | fairseq.trainer | begin training epoch 843
2022-03-07 20:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:15:00 | INFO | train_inner | epoch 843:     36 / 49 loss=2.019, nll_loss=0.273, ppl=1.21, wps=24790.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41000, lr=0.000156174, gnorm=0.348, loss_scale=32, train_wall=223, gb_free=8.8, wall=112345
2022-03-07 20:15:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:15:36 | INFO | valid | epoch 843 | valid on 'valid' subset | loss 13.495 | nll_loss 12.921 | ppl 7757.8 | wps 46723.3 | wpb 510.9 | bsz 1 | num_updates 41013 | best_loss 8.937
2022-03-07 20:15:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 843 @ 41013 updates
2022-03-07 20:15:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:15:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:15:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 843 @ 41013 updates, score 13.495) (writing took 2.3487194972112775 seconds)
2022-03-07 20:15:38 | INFO | fairseq_cli.train | end of epoch 843 (average epoch stats below)
2022-03-07 20:15:38 | INFO | train | epoch 843 | loss 2.018 | nll_loss 0.273 | ppl 1.21 | wps 24967.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41013 | lr 0.000156149 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112383
2022-03-07 20:15:38 | INFO | fairseq.trainer | begin training epoch 844
2022-03-07 20:15:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:17:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:17:43 | INFO | valid | epoch 844 | valid on 'valid' subset | loss 13.516 | nll_loss 12.944 | ppl 7877.71 | wps 45996 | wpb 510.9 | bsz 1 | num_updates 41062 | best_loss 8.937
2022-03-07 20:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 844 @ 41062 updates
2022-03-07 20:17:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:17:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:17:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 844 @ 41062 updates, score 13.516) (writing took 2.3714825161732733 seconds)
2022-03-07 20:17:46 | INFO | fairseq_cli.train | end of epoch 844 (average epoch stats below)
2022-03-07 20:17:46 | INFO | train | epoch 844 | loss 2.018 | nll_loss 0.273 | ppl 1.21 | wps 24960.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41062 | lr 0.000156056 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112510
2022-03-07 20:17:46 | INFO | fairseq.trainer | begin training epoch 845
2022-03-07 20:17:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:19:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:19:22 | INFO | train_inner | epoch 845:     39 / 49 loss=2.018, nll_loss=0.273, ppl=1.21, wps=24775.6, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=41100, lr=0.000155984, gnorm=0.347, loss_scale=32, train_wall=223, gb_free=8.8, wall=112607
2022-03-07 20:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:19:50 | INFO | valid | epoch 845 | valid on 'valid' subset | loss 13.454 | nll_loss 12.878 | ppl 7527.29 | wps 46708.5 | wpb 510.9 | bsz 1 | num_updates 41110 | best_loss 8.937
2022-03-07 20:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 845 @ 41110 updates
2022-03-07 20:19:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:19:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:19:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 845 @ 41110 updates, score 13.454) (writing took 2.3283814298920333 seconds)
2022-03-07 20:19:53 | INFO | fairseq_cli.train | end of epoch 845 (average epoch stats below)
2022-03-07 20:19:53 | INFO | train | epoch 845 | loss 2.018 | nll_loss 0.273 | ppl 1.21 | wps 24505 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41110 | lr 0.000155965 | gnorm 0.344 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112637
2022-03-07 20:19:53 | INFO | fairseq.trainer | begin training epoch 846
2022-03-07 20:19:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:21:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:21:58 | INFO | valid | epoch 846 | valid on 'valid' subset | loss 13.524 | nll_loss 12.951 | ppl 7918.5 | wps 46127.5 | wpb 510.9 | bsz 1 | num_updates 41159 | best_loss 8.937
2022-03-07 20:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 846 @ 41159 updates
2022-03-07 20:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:22:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:22:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 846 @ 41159 updates, score 13.524) (writing took 2.2817646469920874 seconds)
2022-03-07 20:22:00 | INFO | fairseq_cli.train | end of epoch 846 (average epoch stats below)
2022-03-07 20:22:00 | INFO | train | epoch 846 | loss 2.018 | nll_loss 0.273 | ppl 1.21 | wps 24989 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41159 | lr 0.000155872 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 112765
2022-03-07 20:22:00 | INFO | fairseq.trainer | begin training epoch 847
2022-03-07 20:22:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:23:40 | INFO | train_inner | epoch 847:     41 / 49 loss=2.018, nll_loss=0.272, ppl=1.21, wps=25132, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41200, lr=0.000155794, gnorm=0.347, loss_scale=32, train_wall=220, gb_free=8.8, wall=112865
2022-03-07 20:23:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:24:03 | INFO | valid | epoch 847 | valid on 'valid' subset | loss 13.452 | nll_loss 12.876 | ppl 7518.17 | wps 46790 | wpb 510.9 | bsz 1 | num_updates 41208 | best_loss 8.937
2022-03-07 20:24:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 847 @ 41208 updates
2022-03-07 20:24:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:24:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:24:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 847 @ 41208 updates, score 13.452) (writing took 2.2850060127675533 seconds)
2022-03-07 20:24:06 | INFO | fairseq_cli.train | end of epoch 847 (average epoch stats below)
2022-03-07 20:24:06 | INFO | train | epoch 847 | loss 2.017 | nll_loss 0.272 | ppl 1.21 | wps 25276.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41208 | lr 0.000155779 | gnorm 0.345 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 112890
2022-03-07 20:24:06 | INFO | fairseq.trainer | begin training epoch 848
2022-03-07 20:24:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:24:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:26:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:26:09 | INFO | valid | epoch 848 | valid on 'valid' subset | loss 13.472 | nll_loss 12.896 | ppl 7622.42 | wps 47719.2 | wpb 510.9 | bsz 1 | num_updates 41256 | best_loss 8.937
2022-03-07 20:26:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 848 @ 41256 updates
2022-03-07 20:26:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:26:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:26:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 848 @ 41256 updates, score 13.472) (writing took 2.424099228810519 seconds)
2022-03-07 20:26:11 | INFO | fairseq_cli.train | end of epoch 848 (average epoch stats below)
2022-03-07 20:26:11 | INFO | train | epoch 848 | loss 2.018 | nll_loss 0.273 | ppl 1.21 | wps 24811 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41256 | lr 0.000155688 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113016
2022-03-07 20:26:11 | INFO | fairseq.trainer | begin training epoch 849
2022-03-07 20:26:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:27:58 | INFO | train_inner | epoch 849:     44 / 49 loss=2.018, nll_loss=0.273, ppl=1.21, wps=25139.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41300, lr=0.000155606, gnorm=0.35, loss_scale=32, train_wall=220, gb_free=8.8, wall=113123
2022-03-07 20:28:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:28:14 | INFO | valid | epoch 849 | valid on 'valid' subset | loss 13.449 | nll_loss 12.87 | ppl 7484.07 | wps 48224.9 | wpb 510.9 | bsz 1 | num_updates 41305 | best_loss 8.937
2022-03-07 20:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 849 @ 41305 updates
2022-03-07 20:28:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:28:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 849 @ 41305 updates, score 13.449) (writing took 2.264489713124931 seconds)
2022-03-07 20:28:16 | INFO | fairseq_cli.train | end of epoch 849 (average epoch stats below)
2022-03-07 20:28:16 | INFO | train | epoch 849 | loss 2.018 | nll_loss 0.273 | ppl 1.21 | wps 25411.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41305 | lr 0.000155596 | gnorm 0.352 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 113141
2022-03-07 20:28:16 | INFO | fairseq.trainer | begin training epoch 850
2022-03-07 20:28:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:30:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:30:19 | INFO | valid | epoch 850 | valid on 'valid' subset | loss 13.534 | nll_loss 12.962 | ppl 7981.55 | wps 46981 | wpb 510.9 | bsz 1 | num_updates 41354 | best_loss 8.937
2022-03-07 20:30:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 850 @ 41354 updates
2022-03-07 20:30:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:30:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:30:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 850 @ 41354 updates, score 13.534) (writing took 2.3005332821048796 seconds)
2022-03-07 20:30:21 | INFO | fairseq_cli.train | end of epoch 850 (average epoch stats below)
2022-03-07 20:30:21 | INFO | train | epoch 850 | loss 2.017 | nll_loss 0.272 | ppl 1.21 | wps 25367.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41354 | lr 0.000155504 | gnorm 0.346 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 113266
2022-03-07 20:30:21 | INFO | fairseq.trainer | begin training epoch 851
2022-03-07 20:30:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:30:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:32:16 | INFO | train_inner | epoch 851:     47 / 49 loss=2.017, nll_loss=0.272, ppl=1.21, wps=25121.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41400, lr=0.000155417, gnorm=0.346, loss_scale=32, train_wall=220, gb_free=8.8, wall=113381
2022-03-07 20:32:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:32:25 | INFO | valid | epoch 851 | valid on 'valid' subset | loss 13.525 | nll_loss 12.953 | ppl 7930.42 | wps 46809.1 | wpb 510.9 | bsz 1 | num_updates 41402 | best_loss 8.937
2022-03-07 20:32:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 851 @ 41402 updates
2022-03-07 20:32:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:32:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 851 @ 41402 updates, score 13.525) (writing took 2.28829483082518 seconds)
2022-03-07 20:32:27 | INFO | fairseq_cli.train | end of epoch 851 (average epoch stats below)
2022-03-07 20:32:27 | INFO | train | epoch 851 | loss 2.017 | nll_loss 0.271 | ppl 1.21 | wps 24730.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41402 | lr 0.000155414 | gnorm 0.346 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113392
2022-03-07 20:32:27 | INFO | fairseq.trainer | begin training epoch 852
2022-03-07 20:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:34:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:34:32 | INFO | valid | epoch 852 | valid on 'valid' subset | loss 13.513 | nll_loss 12.938 | ppl 7850.09 | wps 45182.3 | wpb 510.9 | bsz 1 | num_updates 41451 | best_loss 8.937
2022-03-07 20:34:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 852 @ 41451 updates
2022-03-07 20:34:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:34:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:34:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 852 @ 41451 updates, score 13.513) (writing took 2.463731739204377 seconds)
2022-03-07 20:34:35 | INFO | fairseq_cli.train | end of epoch 852 (average epoch stats below)
2022-03-07 20:34:35 | INFO | train | epoch 852 | loss 2.017 | nll_loss 0.272 | ppl 1.21 | wps 24926 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41451 | lr 0.000155322 | gnorm 0.35 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113519
2022-03-07 20:34:35 | INFO | fairseq.trainer | begin training epoch 853
2022-03-07 20:34:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:36:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:36:39 | INFO | valid | epoch 853 | valid on 'valid' subset | loss 13.425 | nll_loss 12.84 | ppl 7330.63 | wps 48380.1 | wpb 510.9 | bsz 1 | num_updates 41499 | best_loss 8.937
2022-03-07 20:36:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 853 @ 41499 updates
2022-03-07 20:36:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:36:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:36:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 853 @ 41499 updates, score 13.425) (writing took 2.311462459154427 seconds)
2022-03-07 20:36:41 | INFO | fairseq_cli.train | end of epoch 853 (average epoch stats below)
2022-03-07 20:36:41 | INFO | train | epoch 853 | loss 2.017 | nll_loss 0.272 | ppl 1.21 | wps 24571.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41499 | lr 0.000155232 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 113646
2022-03-07 20:36:41 | INFO | fairseq.trainer | begin training epoch 854
2022-03-07 20:36:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:36:44 | INFO | train_inner | epoch 854:      1 / 49 loss=2.017, nll_loss=0.272, ppl=1.21, wps=24134.7, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=41500, lr=0.00015523, gnorm=0.35, loss_scale=32, train_wall=221, gb_free=8.8, wall=113649
2022-03-07 20:38:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:38:44 | INFO | valid | epoch 854 | valid on 'valid' subset | loss 13.538 | nll_loss 12.966 | ppl 8001.94 | wps 48104 | wpb 510.9 | bsz 1 | num_updates 41548 | best_loss 8.937
2022-03-07 20:38:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 854 @ 41548 updates
2022-03-07 20:38:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:38:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:38:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 854 @ 41548 updates, score 13.538) (writing took 2.2713335836306214 seconds)
2022-03-07 20:38:46 | INFO | fairseq_cli.train | end of epoch 854 (average epoch stats below)
2022-03-07 20:38:46 | INFO | train | epoch 854 | loss 2.017 | nll_loss 0.272 | ppl 1.21 | wps 25409.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41548 | lr 0.00015514 | gnorm 0.347 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 113771
2022-03-07 20:38:46 | INFO | fairseq.trainer | begin training epoch 855
2022-03-07 20:38:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:40:49 | INFO | valid | epoch 855 | valid on 'valid' subset | loss 13.5 | nll_loss 12.923 | ppl 7767.73 | wps 48625 | wpb 510.9 | bsz 1 | num_updates 41597 | best_loss 8.937
2022-03-07 20:40:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 855 @ 41597 updates
2022-03-07 20:40:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:40:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:40:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 855 @ 41597 updates, score 13.5) (writing took 2.272730273194611 seconds)
2022-03-07 20:40:52 | INFO | fairseq_cli.train | end of epoch 855 (average epoch stats below)
2022-03-07 20:40:52 | INFO | train | epoch 855 | loss 2.017 | nll_loss 0.272 | ppl 1.21 | wps 25386.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41597 | lr 0.000155049 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 113896
2022-03-07 20:40:52 | INFO | fairseq.trainer | begin training epoch 856
2022-03-07 20:40:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:40:59 | INFO | train_inner | epoch 856:      3 / 49 loss=2.017, nll_loss=0.272, ppl=1.21, wps=25431.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41600, lr=0.000155043, gnorm=0.347, loss_scale=32, train_wall=217, gb_free=8.8, wall=113904
2022-03-07 20:42:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:42:55 | INFO | valid | epoch 856 | valid on 'valid' subset | loss 13.494 | nll_loss 12.918 | ppl 7738.84 | wps 45876.9 | wpb 510.9 | bsz 1 | num_updates 41646 | best_loss 8.937
2022-03-07 20:42:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 856 @ 41646 updates
2022-03-07 20:42:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:42:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:42:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 856 @ 41646 updates, score 13.494) (writing took 2.505906615871936 seconds)
2022-03-07 20:42:57 | INFO | fairseq_cli.train | end of epoch 856 (average epoch stats below)
2022-03-07 20:42:57 | INFO | train | epoch 856 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 25296.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41646 | lr 0.000154958 | gnorm 0.343 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 114022
2022-03-07 20:42:57 | INFO | fairseq.trainer | begin training epoch 857
2022-03-07 20:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:43:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:45:01 | INFO | valid | epoch 857 | valid on 'valid' subset | loss 13.516 | nll_loss 12.941 | ppl 7865.37 | wps 48103.6 | wpb 510.9 | bsz 1 | num_updates 41694 | best_loss 8.937
2022-03-07 20:45:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 857 @ 41694 updates
2022-03-07 20:45:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:45:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:45:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 857 @ 41694 updates, score 13.516) (writing took 2.330569901969284 seconds)
2022-03-07 20:45:03 | INFO | fairseq_cli.train | end of epoch 857 (average epoch stats below)
2022-03-07 20:45:03 | INFO | train | epoch 857 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 24768.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41694 | lr 0.000154869 | gnorm 0.351 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 114148
2022-03-07 20:45:03 | INFO | fairseq.trainer | begin training epoch 858
2022-03-07 20:45:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:45:18 | INFO | train_inner | epoch 858:      6 / 49 loss=2.016, nll_loss=0.271, ppl=1.21, wps=25082.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41700, lr=0.000154857, gnorm=0.347, loss_scale=32, train_wall=220, gb_free=8.8, wall=114162
2022-03-07 20:47:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:47:06 | INFO | valid | epoch 858 | valid on 'valid' subset | loss 13.519 | nll_loss 12.946 | ppl 7889.6 | wps 48772 | wpb 510.9 | bsz 1 | num_updates 41743 | best_loss 8.937
2022-03-07 20:47:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 858 @ 41743 updates
2022-03-07 20:47:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:47:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:47:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 858 @ 41743 updates, score 13.519) (writing took 2.2814905429258943 seconds)
2022-03-07 20:47:08 | INFO | fairseq_cli.train | end of epoch 858 (average epoch stats below)
2022-03-07 20:47:08 | INFO | train | epoch 858 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 25434.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41743 | lr 0.000154778 | gnorm 0.345 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 114273
2022-03-07 20:47:08 | INFO | fairseq.trainer | begin training epoch 859
2022-03-07 20:47:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:48:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:49:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:49:11 | INFO | valid | epoch 859 | valid on 'valid' subset | loss 13.454 | nll_loss 12.876 | ppl 7517.87 | wps 48260.3 | wpb 510.9 | bsz 1 | num_updates 41791 | best_loss 8.937
2022-03-07 20:49:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 859 @ 41791 updates
2022-03-07 20:49:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:49:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:49:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 859 @ 41791 updates, score 13.454) (writing took 2.2794346008449793 seconds)
2022-03-07 20:49:13 | INFO | fairseq_cli.train | end of epoch 859 (average epoch stats below)
2022-03-07 20:49:13 | INFO | train | epoch 859 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 24849.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41791 | lr 0.000154689 | gnorm 0.35 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 114398
2022-03-07 20:49:13 | INFO | fairseq.trainer | begin training epoch 860
2022-03-07 20:49:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:49:35 | INFO | train_inner | epoch 860:      9 / 49 loss=2.016, nll_loss=0.271, ppl=1.21, wps=25169.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41800, lr=0.000154672, gnorm=0.348, loss_scale=32, train_wall=220, gb_free=8.8, wall=114420
2022-03-07 20:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:51:18 | INFO | valid | epoch 860 | valid on 'valid' subset | loss 13.442 | nll_loss 12.868 | ppl 7476.69 | wps 42957.2 | wpb 510.9 | bsz 1 | num_updates 41840 | best_loss 8.937
2022-03-07 20:51:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 860 @ 41840 updates
2022-03-07 20:51:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:51:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:51:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 860 @ 41840 updates, score 13.442) (writing took 2.367026778869331 seconds)
2022-03-07 20:51:21 | INFO | fairseq_cli.train | end of epoch 860 (average epoch stats below)
2022-03-07 20:51:21 | INFO | train | epoch 860 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 24910.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 41840 | lr 0.000154598 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114525
2022-03-07 20:51:21 | INFO | fairseq.trainer | begin training epoch 861
2022-03-07 20:51:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:53:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:53:25 | INFO | valid | epoch 861 | valid on 'valid' subset | loss 13.501 | nll_loss 12.927 | ppl 7787.37 | wps 46121.1 | wpb 510.9 | bsz 1 | num_updates 41889 | best_loss 8.937
2022-03-07 20:53:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 861 @ 41889 updates
2022-03-07 20:53:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:53:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:53:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 861 @ 41889 updates, score 13.501) (writing took 2.409816682804376 seconds)
2022-03-07 20:53:28 | INFO | fairseq_cli.train | end of epoch 861 (average epoch stats below)
2022-03-07 20:53:28 | INFO | train | epoch 861 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 24996.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41889 | lr 0.000154508 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114653
2022-03-07 20:53:28 | INFO | fairseq.trainer | begin training epoch 862
2022-03-07 20:53:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:53:55 | INFO | train_inner | epoch 862:     11 / 49 loss=2.016, nll_loss=0.271, ppl=1.21, wps=24977.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=41900, lr=0.000154487, gnorm=0.346, loss_scale=32, train_wall=221, gb_free=8.8, wall=114680
2022-03-07 20:54:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 20:55:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:55:32 | INFO | valid | epoch 862 | valid on 'valid' subset | loss 13.636 | nll_loss 13.075 | ppl 8629.58 | wps 46975 | wpb 510.9 | bsz 1 | num_updates 41937 | best_loss 8.937
2022-03-07 20:55:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 862 @ 41937 updates
2022-03-07 20:55:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:55:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:55:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 862 @ 41937 updates, score 13.636) (writing took 2.290328244213015 seconds)
2022-03-07 20:55:35 | INFO | fairseq_cli.train | end of epoch 862 (average epoch stats below)
2022-03-07 20:55:35 | INFO | train | epoch 862 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 24530 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 41937 | lr 0.000154419 | gnorm 0.349 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114779
2022-03-07 20:55:35 | INFO | fairseq.trainer | begin training epoch 863
2022-03-07 20:55:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:57:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:57:39 | INFO | valid | epoch 863 | valid on 'valid' subset | loss 13.465 | nll_loss 12.888 | ppl 7577.9 | wps 46744.7 | wpb 510.9 | bsz 1 | num_updates 41986 | best_loss 8.937
2022-03-07 20:57:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 863 @ 41986 updates
2022-03-07 20:57:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:57:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:57:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 863 @ 41986 updates, score 13.465) (writing took 2.309050905983895 seconds)
2022-03-07 20:57:42 | INFO | fairseq_cli.train | end of epoch 863 (average epoch stats below)
2022-03-07 20:57:42 | INFO | train | epoch 863 | loss 2.016 | nll_loss 0.271 | ppl 1.21 | wps 25014.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 41986 | lr 0.000154329 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 114907
2022-03-07 20:57:42 | INFO | fairseq.trainer | begin training epoch 864
2022-03-07 20:57:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 20:58:17 | INFO | train_inner | epoch 864:     14 / 49 loss=2.016, nll_loss=0.271, ppl=1.21, wps=24813, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42000, lr=0.000154303, gnorm=0.346, loss_scale=32, train_wall=223, gb_free=8.8, wall=114941
2022-03-07 20:59:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 20:59:47 | INFO | valid | epoch 864 | valid on 'valid' subset | loss 13.45 | nll_loss 12.871 | ppl 7489.55 | wps 45796.4 | wpb 510.9 | bsz 1 | num_updates 42035 | best_loss 8.937
2022-03-07 20:59:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 864 @ 42035 updates
2022-03-07 20:59:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:59:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 20:59:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 864 @ 42035 updates, score 13.45) (writing took 2.2924316050484776 seconds)
2022-03-07 20:59:49 | INFO | fairseq_cli.train | end of epoch 864 (average epoch stats below)
2022-03-07 20:59:49 | INFO | train | epoch 864 | loss 2.015 | nll_loss 0.271 | ppl 1.21 | wps 25012 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42035 | lr 0.000154239 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115034
2022-03-07 20:59:49 | INFO | fairseq.trainer | begin training epoch 865
2022-03-07 20:59:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:00:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:01:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:01:54 | INFO | valid | epoch 865 | valid on 'valid' subset | loss 13.582 | nll_loss 13.016 | ppl 8286.19 | wps 46942.6 | wpb 510.9 | bsz 1 | num_updates 42083 | best_loss 8.937
2022-03-07 21:01:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 865 @ 42083 updates
2022-03-07 21:01:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:01:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 865 @ 42083 updates, score 13.582) (writing took 2.387344356160611 seconds)
2022-03-07 21:01:56 | INFO | fairseq_cli.train | end of epoch 865 (average epoch stats below)
2022-03-07 21:01:56 | INFO | train | epoch 865 | loss 2.015 | nll_loss 0.27 | ppl 1.21 | wps 24479.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42083 | lr 0.000154151 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115161
2022-03-07 21:01:56 | INFO | fairseq.trainer | begin training epoch 866
2022-03-07 21:01:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:02:38 | INFO | train_inner | epoch 866:     17 / 49 loss=2.015, nll_loss=0.271, ppl=1.21, wps=24802.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42100, lr=0.00015412, gnorm=0.344, loss_scale=32, train_wall=223, gb_free=8.8, wall=115203
2022-03-07 21:03:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:04:01 | INFO | valid | epoch 866 | valid on 'valid' subset | loss 13.463 | nll_loss 12.886 | ppl 7569.43 | wps 46702.2 | wpb 510.9 | bsz 1 | num_updates 42132 | best_loss 8.937
2022-03-07 21:04:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 866 @ 42132 updates
2022-03-07 21:04:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:04:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:04:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 866 @ 42132 updates, score 13.463) (writing took 2.312177506275475 seconds)
2022-03-07 21:04:03 | INFO | fairseq_cli.train | end of epoch 866 (average epoch stats below)
2022-03-07 21:04:03 | INFO | train | epoch 866 | loss 2.014 | nll_loss 0.27 | ppl 1.21 | wps 24995.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42132 | lr 0.000154061 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115288
2022-03-07 21:04:03 | INFO | fairseq.trainer | begin training epoch 867
2022-03-07 21:04:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:06:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:06:08 | INFO | valid | epoch 867 | valid on 'valid' subset | loss 13.528 | nll_loss 12.956 | ppl 7948.25 | wps 46875.8 | wpb 510.9 | bsz 1 | num_updates 42181 | best_loss 8.937
2022-03-07 21:06:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 867 @ 42181 updates
2022-03-07 21:06:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:06:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:06:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 867 @ 42181 updates, score 13.528) (writing took 2.282606156077236 seconds)
2022-03-07 21:06:10 | INFO | fairseq_cli.train | end of epoch 867 (average epoch stats below)
2022-03-07 21:06:10 | INFO | train | epoch 867 | loss 2.015 | nll_loss 0.27 | ppl 1.21 | wps 25027.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42181 | lr 0.000153972 | gnorm 0.341 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 115415
2022-03-07 21:06:10 | INFO | fairseq.trainer | begin training epoch 868
2022-03-07 21:06:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:06:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:07:00 | INFO | train_inner | epoch 868:     20 / 49 loss=2.015, nll_loss=0.27, ppl=1.21, wps=24796.7, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42200, lr=0.000153937, gnorm=0.342, loss_scale=32, train_wall=223, gb_free=8.8, wall=115464
2022-03-07 21:08:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:08:15 | INFO | valid | epoch 868 | valid on 'valid' subset | loss 13.591 | nll_loss 13.024 | ppl 8330.34 | wps 46990.1 | wpb 510.9 | bsz 1 | num_updates 42229 | best_loss 8.937
2022-03-07 21:08:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 868 @ 42229 updates
2022-03-07 21:08:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:08:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:08:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 868 @ 42229 updates, score 13.591) (writing took 2.3146086470223963 seconds)
2022-03-07 21:08:17 | INFO | fairseq_cli.train | end of epoch 868 (average epoch stats below)
2022-03-07 21:08:17 | INFO | train | epoch 868 | loss 2.015 | nll_loss 0.271 | ppl 1.21 | wps 24526.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42229 | lr 0.000153884 | gnorm 0.345 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115542
2022-03-07 21:08:17 | INFO | fairseq.trainer | begin training epoch 869
2022-03-07 21:08:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:10:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:10:21 | INFO | valid | epoch 869 | valid on 'valid' subset | loss 13.45 | nll_loss 12.875 | ppl 7513.18 | wps 47824.1 | wpb 510.9 | bsz 1 | num_updates 42278 | best_loss 8.937
2022-03-07 21:10:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 869 @ 42278 updates
2022-03-07 21:10:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:10:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:10:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 869 @ 42278 updates, score 13.45) (writing took 2.40214976714924 seconds)
2022-03-07 21:10:24 | INFO | fairseq_cli.train | end of epoch 869 (average epoch stats below)
2022-03-07 21:10:24 | INFO | train | epoch 869 | loss 2.015 | nll_loss 0.271 | ppl 1.21 | wps 25055.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42278 | lr 0.000153795 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115669
2022-03-07 21:10:24 | INFO | fairseq.trainer | begin training epoch 870
2022-03-07 21:10:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:11:18 | INFO | train_inner | epoch 870:     22 / 49 loss=2.015, nll_loss=0.27, ppl=1.21, wps=25120.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=42300, lr=0.000153755, gnorm=0.347, loss_scale=32, train_wall=220, gb_free=8.8, wall=115723
2022-03-07 21:12:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:12:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:12:28 | INFO | valid | epoch 870 | valid on 'valid' subset | loss 13.512 | nll_loss 12.94 | ppl 7857.93 | wps 46142.9 | wpb 510.9 | bsz 1 | num_updates 42326 | best_loss 8.937
2022-03-07 21:12:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 870 @ 42326 updates
2022-03-07 21:12:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:12:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:12:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 870 @ 42326 updates, score 13.512) (writing took 2.3271204298362136 seconds)
2022-03-07 21:12:31 | INFO | fairseq_cli.train | end of epoch 870 (average epoch stats below)
2022-03-07 21:12:31 | INFO | train | epoch 870 | loss 2.014 | nll_loss 0.27 | ppl 1.21 | wps 24555.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42326 | lr 0.000153708 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115795
2022-03-07 21:12:31 | INFO | fairseq.trainer | begin training epoch 871
2022-03-07 21:12:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:14:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:14:35 | INFO | valid | epoch 871 | valid on 'valid' subset | loss 13.546 | nll_loss 12.973 | ppl 8039.49 | wps 46203.5 | wpb 510.9 | bsz 1 | num_updates 42375 | best_loss 8.937
2022-03-07 21:14:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 871 @ 42375 updates
2022-03-07 21:14:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:14:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:14:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 871 @ 42375 updates, score 13.546) (writing took 2.2992513701319695 seconds)
2022-03-07 21:14:38 | INFO | fairseq_cli.train | end of epoch 871 (average epoch stats below)
2022-03-07 21:14:38 | INFO | train | epoch 871 | loss 2.014 | nll_loss 0.27 | ppl 1.21 | wps 25010.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42375 | lr 0.000153619 | gnorm 0.344 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 115922
2022-03-07 21:14:38 | INFO | fairseq.trainer | begin training epoch 872
2022-03-07 21:14:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:15:40 | INFO | train_inner | epoch 872:     25 / 49 loss=2.014, nll_loss=0.27, ppl=1.21, wps=24782.1, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=42400, lr=0.000153574, gnorm=0.345, loss_scale=32, train_wall=223, gb_free=8.8, wall=115984
2022-03-07 21:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:16:42 | INFO | valid | epoch 872 | valid on 'valid' subset | loss 13.464 | nll_loss 12.885 | ppl 7566.49 | wps 47779.9 | wpb 510.9 | bsz 1 | num_updates 42424 | best_loss 8.937
2022-03-07 21:16:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 872 @ 42424 updates
2022-03-07 21:16:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 872 @ 42424 updates, score 13.464) (writing took 2.2672231728211045 seconds)
2022-03-07 21:16:45 | INFO | fairseq_cli.train | end of epoch 872 (average epoch stats below)
2022-03-07 21:16:45 | INFO | train | epoch 872 | loss 2.014 | nll_loss 0.27 | ppl 1.21 | wps 25049.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42424 | lr 0.00015353 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116049
2022-03-07 21:16:45 | INFO | fairseq.trainer | begin training epoch 873
2022-03-07 21:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:18:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:18:50 | INFO | valid | epoch 873 | valid on 'valid' subset | loss 13.526 | nll_loss 12.953 | ppl 7930.28 | wps 44855.9 | wpb 510.9 | bsz 1 | num_updates 42473 | best_loss 8.937
2022-03-07 21:18:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 873 @ 42473 updates
2022-03-07 21:18:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:18:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:18:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 873 @ 42473 updates, score 13.526) (writing took 2.4204943939112127 seconds)
2022-03-07 21:18:52 | INFO | fairseq_cli.train | end of epoch 873 (average epoch stats below)
2022-03-07 21:18:52 | INFO | train | epoch 873 | loss 2.014 | nll_loss 0.27 | ppl 1.21 | wps 24914.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 42473 | lr 0.000153442 | gnorm 0.347 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 116177
2022-03-07 21:18:52 | INFO | fairseq.trainer | begin training epoch 874
2022-03-07 21:18:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:19:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:20:01 | INFO | train_inner | epoch 874:     28 / 49 loss=2.014, nll_loss=0.27, ppl=1.21, wps=24808.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42500, lr=0.000153393, gnorm=0.347, loss_scale=32, train_wall=223, gb_free=8.8, wall=116246
2022-03-07 21:20:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:20:57 | INFO | valid | epoch 874 | valid on 'valid' subset | loss 13.508 | nll_loss 12.936 | ppl 7836.95 | wps 45872.1 | wpb 510.9 | bsz 1 | num_updates 42521 | best_loss 8.937
2022-03-07 21:20:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 874 @ 42521 updates
2022-03-07 21:20:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:20:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:20:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 874 @ 42521 updates, score 13.508) (writing took 2.344064198900014 seconds)
2022-03-07 21:20:59 | INFO | fairseq_cli.train | end of epoch 874 (average epoch stats below)
2022-03-07 21:20:59 | INFO | train | epoch 874 | loss 2.014 | nll_loss 0.269 | ppl 1.21 | wps 24515.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42521 | lr 0.000153355 | gnorm 0.346 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116304
2022-03-07 21:20:59 | INFO | fairseq.trainer | begin training epoch 875
2022-03-07 21:20:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:22:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:23:04 | INFO | valid | epoch 875 | valid on 'valid' subset | loss 13.624 | nll_loss 13.058 | ppl 8527.53 | wps 46196.9 | wpb 510.9 | bsz 1 | num_updates 42570 | best_loss 8.937
2022-03-07 21:23:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 875 @ 42570 updates
2022-03-07 21:23:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:23:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:23:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 875 @ 42570 updates, score 13.624) (writing took 2.3130092518404126 seconds)
2022-03-07 21:23:06 | INFO | fairseq_cli.train | end of epoch 875 (average epoch stats below)
2022-03-07 21:23:06 | INFO | train | epoch 875 | loss 2.013 | nll_loss 0.27 | ppl 1.21 | wps 25046.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42570 | lr 0.000153267 | gnorm 0.338 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116431
2022-03-07 21:23:06 | INFO | fairseq.trainer | begin training epoch 876
2022-03-07 21:23:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:24:20 | INFO | train_inner | epoch 876:     30 / 49 loss=2.013, nll_loss=0.269, ppl=1.21, wps=25068.9, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=42600, lr=0.000153213, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=116505
2022-03-07 21:24:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:25:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:25:10 | INFO | valid | epoch 876 | valid on 'valid' subset | loss 13.485 | nll_loss 12.912 | ppl 7709.23 | wps 47781.2 | wpb 510.9 | bsz 1 | num_updates 42618 | best_loss 8.937
2022-03-07 21:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 876 @ 42618 updates
2022-03-07 21:25:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:25:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 876 @ 42618 updates, score 13.485) (writing took 2.2505258140154183 seconds)
2022-03-07 21:25:12 | INFO | fairseq_cli.train | end of epoch 876 (average epoch stats below)
2022-03-07 21:25:12 | INFO | train | epoch 876 | loss 2.013 | nll_loss 0.269 | ppl 1.21 | wps 24705.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42618 | lr 0.00015318 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116557
2022-03-07 21:25:12 | INFO | fairseq.trainer | begin training epoch 877
2022-03-07 21:25:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:27:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:27:16 | INFO | valid | epoch 877 | valid on 'valid' subset | loss 13.527 | nll_loss 12.953 | ppl 7930.04 | wps 46164.9 | wpb 510.9 | bsz 1 | num_updates 42667 | best_loss 8.937
2022-03-07 21:27:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 877 @ 42667 updates
2022-03-07 21:27:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:27:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:27:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 877 @ 42667 updates, score 13.527) (writing took 2.359063913114369 seconds)
2022-03-07 21:27:19 | INFO | fairseq_cli.train | end of epoch 877 (average epoch stats below)
2022-03-07 21:27:19 | INFO | train | epoch 877 | loss 2.014 | nll_loss 0.27 | ppl 1.21 | wps 25103.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42667 | lr 0.000153093 | gnorm 0.351 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 116683
2022-03-07 21:27:19 | INFO | fairseq.trainer | begin training epoch 878
2022-03-07 21:27:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:28:40 | INFO | train_inner | epoch 878:     33 / 49 loss=2.014, nll_loss=0.27, ppl=1.21, wps=24975, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=42700, lr=0.000153033, gnorm=0.346, loss_scale=32, train_wall=221, gb_free=8.8, wall=116764
2022-03-07 21:29:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:29:23 | INFO | valid | epoch 878 | valid on 'valid' subset | loss 13.581 | nll_loss 13.015 | ppl 8277.98 | wps 46662.5 | wpb 510.9 | bsz 1 | num_updates 42716 | best_loss 8.937
2022-03-07 21:29:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 878 @ 42716 updates
2022-03-07 21:29:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:29:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:29:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 878 @ 42716 updates, score 13.581) (writing took 2.348926685284823 seconds)
2022-03-07 21:29:25 | INFO | fairseq_cli.train | end of epoch 878 (average epoch stats below)
2022-03-07 21:29:25 | INFO | train | epoch 878 | loss 2.013 | nll_loss 0.27 | ppl 1.21 | wps 25116.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42716 | lr 0.000153005 | gnorm 0.341 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116810
2022-03-07 21:29:25 | INFO | fairseq.trainer | begin training epoch 879
2022-03-07 21:29:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:31:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:31:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:31:29 | INFO | valid | epoch 879 | valid on 'valid' subset | loss 13.498 | nll_loss 12.924 | ppl 7770.55 | wps 46826.7 | wpb 510.9 | bsz 1 | num_updates 42764 | best_loss 8.937
2022-03-07 21:31:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 879 @ 42764 updates
2022-03-07 21:31:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:31:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:31:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 879 @ 42764 updates, score 13.498) (writing took 2.3040177361108363 seconds)
2022-03-07 21:31:32 | INFO | fairseq_cli.train | end of epoch 879 (average epoch stats below)
2022-03-07 21:31:32 | INFO | train | epoch 879 | loss 2.013 | nll_loss 0.269 | ppl 1.21 | wps 24611.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42764 | lr 0.000152919 | gnorm 0.348 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 116936
2022-03-07 21:31:32 | INFO | fairseq.trainer | begin training epoch 880
2022-03-07 21:31:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:33:00 | INFO | train_inner | epoch 880:     36 / 49 loss=2.013, nll_loss=0.269, ppl=1.21, wps=24899, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=42800, lr=0.000152854, gnorm=0.344, loss_scale=32, train_wall=222, gb_free=8.8, wall=117025
2022-03-07 21:33:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:33:36 | INFO | valid | epoch 880 | valid on 'valid' subset | loss 13.596 | nll_loss 13.028 | ppl 8352.61 | wps 46617.4 | wpb 510.9 | bsz 1 | num_updates 42813 | best_loss 8.937
2022-03-07 21:33:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 880 @ 42813 updates
2022-03-07 21:33:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:33:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:33:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 880 @ 42813 updates, score 13.596) (writing took 2.3038097196258605 seconds)
2022-03-07 21:33:38 | INFO | fairseq_cli.train | end of epoch 880 (average epoch stats below)
2022-03-07 21:33:38 | INFO | train | epoch 880 | loss 2.013 | nll_loss 0.27 | ppl 1.21 | wps 25137.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42813 | lr 0.000152831 | gnorm 0.344 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 117063
2022-03-07 21:33:38 | INFO | fairseq.trainer | begin training epoch 881
2022-03-07 21:33:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:35:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:35:42 | INFO | valid | epoch 881 | valid on 'valid' subset | loss 13.52 | nll_loss 12.952 | ppl 7922.11 | wps 46746.3 | wpb 510.9 | bsz 1 | num_updates 42862 | best_loss 8.937
2022-03-07 21:35:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 881 @ 42862 updates
2022-03-07 21:35:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:35:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:35:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 881 @ 42862 updates, score 13.52) (writing took 2.397991850040853 seconds)
2022-03-07 21:35:45 | INFO | fairseq_cli.train | end of epoch 881 (average epoch stats below)
2022-03-07 21:35:45 | INFO | train | epoch 881 | loss 2.013 | nll_loss 0.269 | ppl 1.21 | wps 25080.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42862 | lr 0.000152744 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117189
2022-03-07 21:35:45 | INFO | fairseq.trainer | begin training epoch 882
2022-03-07 21:35:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:37:18 | INFO | train_inner | epoch 882:     38 / 49 loss=2.013, nll_loss=0.269, ppl=1.21, wps=25130.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=42900, lr=0.000152676, gnorm=0.346, loss_scale=64, train_wall=220, gb_free=8.8, wall=117283
2022-03-07 21:37:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:37:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:37:49 | INFO | valid | epoch 882 | valid on 'valid' subset | loss 13.516 | nll_loss 12.943 | ppl 7875.72 | wps 46594.2 | wpb 510.9 | bsz 1 | num_updates 42910 | best_loss 8.937
2022-03-07 21:37:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 882 @ 42910 updates
2022-03-07 21:37:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:37:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:37:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 882 @ 42910 updates, score 13.516) (writing took 2.3451731051318347 seconds)
2022-03-07 21:37:51 | INFO | fairseq_cli.train | end of epoch 882 (average epoch stats below)
2022-03-07 21:37:51 | INFO | train | epoch 882 | loss 2.013 | nll_loss 0.269 | ppl 1.21 | wps 24578.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 42910 | lr 0.000152658 | gnorm 0.343 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 117316
2022-03-07 21:37:51 | INFO | fairseq.trainer | begin training epoch 883
2022-03-07 21:37:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:39:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:39:54 | INFO | valid | epoch 883 | valid on 'valid' subset | loss 13.482 | nll_loss 12.907 | ppl 7682.84 | wps 48318.3 | wpb 510.9 | bsz 1 | num_updates 42959 | best_loss 8.937
2022-03-07 21:39:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 883 @ 42959 updates
2022-03-07 21:39:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:39:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:39:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 883 @ 42959 updates, score 13.482) (writing took 2.3302227980457246 seconds)
2022-03-07 21:39:57 | INFO | fairseq_cli.train | end of epoch 883 (average epoch stats below)
2022-03-07 21:39:57 | INFO | train | epoch 883 | loss 2.013 | nll_loss 0.269 | ppl 1.21 | wps 25376.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 42959 | lr 0.000152571 | gnorm 0.344 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 117441
2022-03-07 21:39:57 | INFO | fairseq.trainer | begin training epoch 884
2022-03-07 21:39:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:41:37 | INFO | train_inner | epoch 884:     41 / 49 loss=2.013, nll_loss=0.269, ppl=1.2, wps=25130.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43000, lr=0.000152499, gnorm=0.344, loss_scale=32, train_wall=220, gb_free=8.8, wall=117541
2022-03-07 21:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:41:59 | INFO | valid | epoch 884 | valid on 'valid' subset | loss 13.549 | nll_loss 12.976 | ppl 8056.42 | wps 48303.9 | wpb 510.9 | bsz 1 | num_updates 43008 | best_loss 8.937
2022-03-07 21:41:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 884 @ 43008 updates
2022-03-07 21:41:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:42:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 884 @ 43008 updates, score 13.549) (writing took 2.3125962112098932 seconds)
2022-03-07 21:42:02 | INFO | fairseq_cli.train | end of epoch 884 (average epoch stats below)
2022-03-07 21:42:02 | INFO | train | epoch 884 | loss 2.013 | nll_loss 0.269 | ppl 1.2 | wps 25402 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43008 | lr 0.000152484 | gnorm 0.345 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 117566
2022-03-07 21:42:02 | INFO | fairseq.trainer | begin training epoch 885
2022-03-07 21:42:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:44:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:44:05 | INFO | valid | epoch 885 | valid on 'valid' subset | loss 13.557 | nll_loss 12.987 | ppl 8116.89 | wps 47900.2 | wpb 510.9 | bsz 1 | num_updates 43057 | best_loss 8.937
2022-03-07 21:44:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 885 @ 43057 updates
2022-03-07 21:44:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:44:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:44:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 885 @ 43057 updates, score 13.557) (writing took 2.385840986855328 seconds)
2022-03-07 21:44:07 | INFO | fairseq_cli.train | end of epoch 885 (average epoch stats below)
2022-03-07 21:44:07 | INFO | train | epoch 885 | loss 2.013 | nll_loss 0.27 | ppl 1.21 | wps 25328.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43057 | lr 0.000152398 | gnorm 0.346 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 117692
2022-03-07 21:44:07 | INFO | fairseq.trainer | begin training epoch 886
2022-03-07 21:44:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:44:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:45:54 | INFO | train_inner | epoch 886:     44 / 49 loss=2.013, nll_loss=0.269, ppl=1.21, wps=25160.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43100, lr=0.000152322, gnorm=0.345, loss_scale=32, train_wall=220, gb_free=8.8, wall=117799
2022-03-07 21:46:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:46:10 | INFO | valid | epoch 886 | valid on 'valid' subset | loss 13.52 | nll_loss 12.945 | ppl 7884.36 | wps 48279.2 | wpb 510.9 | bsz 1 | num_updates 43105 | best_loss 8.937
2022-03-07 21:46:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 886 @ 43105 updates
2022-03-07 21:46:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:46:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 886 @ 43105 updates, score 13.52) (writing took 2.3127382467500865 seconds)
2022-03-07 21:46:12 | INFO | fairseq_cli.train | end of epoch 886 (average epoch stats below)
2022-03-07 21:46:12 | INFO | train | epoch 886 | loss 2.012 | nll_loss 0.269 | ppl 1.2 | wps 24890.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43105 | lr 0.000152313 | gnorm 0.342 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 117817
2022-03-07 21:46:12 | INFO | fairseq.trainer | begin training epoch 887
2022-03-07 21:46:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:48:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:48:15 | INFO | valid | epoch 887 | valid on 'valid' subset | loss 13.498 | nll_loss 12.925 | ppl 7776.83 | wps 48199.6 | wpb 510.9 | bsz 1 | num_updates 43154 | best_loss 8.937
2022-03-07 21:48:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 887 @ 43154 updates
2022-03-07 21:48:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:48:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:48:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 887 @ 43154 updates, score 13.498) (writing took 2.282611162401736 seconds)
2022-03-07 21:48:17 | INFO | fairseq_cli.train | end of epoch 887 (average epoch stats below)
2022-03-07 21:48:17 | INFO | train | epoch 887 | loss 2.012 | nll_loss 0.268 | ppl 1.2 | wps 25439.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43154 | lr 0.000152226 | gnorm 0.342 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 117942
2022-03-07 21:48:17 | INFO | fairseq.trainer | begin training epoch 888
2022-03-07 21:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:49:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:50:12 | INFO | train_inner | epoch 888:     47 / 49 loss=2.012, nll_loss=0.268, ppl=1.2, wps=25198.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43200, lr=0.000152145, gnorm=0.34, loss_scale=32, train_wall=219, gb_free=8.8, wall=118057
2022-03-07 21:50:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:50:20 | INFO | valid | epoch 888 | valid on 'valid' subset | loss 13.579 | nll_loss 13.012 | ppl 8261.6 | wps 47816.9 | wpb 510.9 | bsz 1 | num_updates 43202 | best_loss 8.937
2022-03-07 21:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 888 @ 43202 updates
2022-03-07 21:50:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:50:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:50:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 888 @ 43202 updates, score 13.579) (writing took 2.2828018590807915 seconds)
2022-03-07 21:50:22 | INFO | fairseq_cli.train | end of epoch 888 (average epoch stats below)
2022-03-07 21:50:22 | INFO | train | epoch 888 | loss 2.012 | nll_loss 0.268 | ppl 1.2 | wps 24845.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43202 | lr 0.000152142 | gnorm 0.338 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 118067
2022-03-07 21:50:22 | INFO | fairseq.trainer | begin training epoch 889
2022-03-07 21:50:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:52:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:52:25 | INFO | valid | epoch 889 | valid on 'valid' subset | loss 13.585 | nll_loss 13.018 | ppl 8297.38 | wps 47849.2 | wpb 510.9 | bsz 1 | num_updates 43251 | best_loss 8.937
2022-03-07 21:52:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 889 @ 43251 updates
2022-03-07 21:52:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:52:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 889 @ 43251 updates, score 13.585) (writing took 2.4039345709607005 seconds)
2022-03-07 21:52:28 | INFO | fairseq_cli.train | end of epoch 889 (average epoch stats below)
2022-03-07 21:52:28 | INFO | train | epoch 889 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 25344.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43251 | lr 0.000152055 | gnorm 0.34 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 118193
2022-03-07 21:52:28 | INFO | fairseq.trainer | begin training epoch 890
2022-03-07 21:52:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:54:28 | INFO | train_inner | epoch 890:     49 / 49 loss=2.012, nll_loss=0.269, ppl=1.2, wps=25226.9, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=43300, lr=0.000151969, gnorm=0.345, loss_scale=32, train_wall=218, gb_free=8.8, wall=118312
2022-03-07 21:54:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:54:32 | INFO | valid | epoch 890 | valid on 'valid' subset | loss 13.44 | nll_loss 12.863 | ppl 7450.55 | wps 46167.1 | wpb 510.9 | bsz 1 | num_updates 43300 | best_loss 8.937
2022-03-07 21:54:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 890 @ 43300 updates
2022-03-07 21:54:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:54:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:54:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 890 @ 43300 updates, score 13.44) (writing took 2.2913964968174696 seconds)
2022-03-07 21:54:35 | INFO | fairseq_cli.train | end of epoch 890 (average epoch stats below)
2022-03-07 21:54:35 | INFO | train | epoch 890 | loss 2.013 | nll_loss 0.269 | ppl 1.21 | wps 25027.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43300 | lr 0.000151969 | gnorm 0.348 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118320
2022-03-07 21:54:35 | INFO | fairseq.trainer | begin training epoch 891
2022-03-07 21:54:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:55:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 21:56:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:56:40 | INFO | valid | epoch 891 | valid on 'valid' subset | loss 13.656 | nll_loss 13.094 | ppl 8742.15 | wps 46502.1 | wpb 510.9 | bsz 1 | num_updates 43348 | best_loss 8.937
2022-03-07 21:56:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 891 @ 43348 updates
2022-03-07 21:56:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:56:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:56:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 891 @ 43348 updates, score 13.656) (writing took 2.2645970578305423 seconds)
2022-03-07 21:56:42 | INFO | fairseq_cli.train | end of epoch 891 (average epoch stats below)
2022-03-07 21:56:42 | INFO | train | epoch 891 | loss 2.012 | nll_loss 0.269 | ppl 1.2 | wps 24492.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43348 | lr 0.000151885 | gnorm 0.347 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 118447
2022-03-07 21:56:42 | INFO | fairseq.trainer | begin training epoch 892
2022-03-07 21:56:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 21:58:45 | INFO | valid | epoch 892 | valid on 'valid' subset | loss 13.558 | nll_loss 12.988 | ppl 8125.95 | wps 48287.2 | wpb 510.9 | bsz 1 | num_updates 43397 | best_loss 8.937
2022-03-07 21:58:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 892 @ 43397 updates
2022-03-07 21:58:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:58:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 21:58:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 892 @ 43397 updates, score 13.558) (writing took 2.261426290962845 seconds)
2022-03-07 21:58:47 | INFO | fairseq_cli.train | end of epoch 892 (average epoch stats below)
2022-03-07 21:58:47 | INFO | train | epoch 892 | loss 2.012 | nll_loss 0.269 | ppl 1.2 | wps 25321.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43397 | lr 0.000151799 | gnorm 0.346 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118572
2022-03-07 21:58:47 | INFO | fairseq.trainer | begin training epoch 893
2022-03-07 21:58:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 21:58:55 | INFO | train_inner | epoch 893:      3 / 49 loss=2.012, nll_loss=0.269, ppl=1.2, wps=24286.5, ups=0.37, wpb=64871.8, bsz=126.7, num_updates=43400, lr=0.000151794, gnorm=0.347, loss_scale=32, train_wall=221, gb_free=8.8, wall=118580
2022-03-07 22:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:00:51 | INFO | valid | epoch 893 | valid on 'valid' subset | loss 13.505 | nll_loss 12.933 | ppl 7818.72 | wps 47637.3 | wpb 510.9 | bsz 1 | num_updates 43446 | best_loss 8.937
2022-03-07 22:00:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 893 @ 43446 updates
2022-03-07 22:00:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:00:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:00:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 893 @ 43446 updates, score 13.505) (writing took 2.414277782663703 seconds)
2022-03-07 22:00:53 | INFO | fairseq_cli.train | end of epoch 893 (average epoch stats below)
2022-03-07 22:00:53 | INFO | train | epoch 893 | loss 2.012 | nll_loss 0.268 | ppl 1.2 | wps 25294.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43446 | lr 0.000151714 | gnorm 0.345 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118698
2022-03-07 22:00:53 | INFO | fairseq.trainer | begin training epoch 894
2022-03-07 22:00:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:01:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:02:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:02:56 | INFO | valid | epoch 894 | valid on 'valid' subset | loss 13.544 | nll_loss 12.977 | ppl 8064.66 | wps 48377.4 | wpb 510.9 | bsz 1 | num_updates 43494 | best_loss 8.937
2022-03-07 22:02:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 894 @ 43494 updates
2022-03-07 22:02:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:02:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:02:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 894 @ 43494 updates, score 13.544) (writing took 2.310758614912629 seconds)
2022-03-07 22:02:58 | INFO | fairseq_cli.train | end of epoch 894 (average epoch stats below)
2022-03-07 22:02:58 | INFO | train | epoch 894 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 24824.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43494 | lr 0.00015163 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118823
2022-03-07 22:02:58 | INFO | fairseq.trainer | begin training epoch 895
2022-03-07 22:02:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:03:13 | INFO | train_inner | epoch 895:      6 / 49 loss=2.011, nll_loss=0.268, ppl=1.2, wps=25109, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43500, lr=0.00015162, gnorm=0.342, loss_scale=32, train_wall=220, gb_free=8.8, wall=118838
2022-03-07 22:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:05:02 | INFO | valid | epoch 895 | valid on 'valid' subset | loss 13.646 | nll_loss 13.089 | ppl 8712.43 | wps 48059.5 | wpb 510.9 | bsz 1 | num_updates 43543 | best_loss 8.937
2022-03-07 22:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 895 @ 43543 updates
2022-03-07 22:05:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:05:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 895 @ 43543 updates, score 13.646) (writing took 2.2689370908774436 seconds)
2022-03-07 22:05:04 | INFO | fairseq_cli.train | end of epoch 895 (average epoch stats below)
2022-03-07 22:05:04 | INFO | train | epoch 895 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 25335.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43543 | lr 0.000151545 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 118949
2022-03-07 22:05:04 | INFO | fairseq.trainer | begin training epoch 896
2022-03-07 22:05:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:07:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:07:07 | INFO | valid | epoch 896 | valid on 'valid' subset | loss 13.585 | nll_loss 13.018 | ppl 8295.21 | wps 48214.4 | wpb 510.9 | bsz 1 | num_updates 43592 | best_loss 8.937
2022-03-07 22:07:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 896 @ 43592 updates
2022-03-07 22:07:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:07:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:07:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 896 @ 43592 updates, score 13.585) (writing took 2.2681278670206666 seconds)
2022-03-07 22:07:09 | INFO | fairseq_cli.train | end of epoch 896 (average epoch stats below)
2022-03-07 22:07:09 | INFO | train | epoch 896 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 25370.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43592 | lr 0.00015146 | gnorm 0.338 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 119074
2022-03-07 22:07:09 | INFO | fairseq.trainer | begin training epoch 897
2022-03-07 22:07:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:07:29 | INFO | train_inner | epoch 897:      8 / 49 loss=2.011, nll_loss=0.268, ppl=1.2, wps=25372.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43600, lr=0.000151446, gnorm=0.34, loss_scale=64, train_wall=218, gb_free=8.8, wall=119094
2022-03-07 22:07:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:09:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:09:14 | INFO | valid | epoch 897 | valid on 'valid' subset | loss 13.644 | nll_loss 13.087 | ppl 8699.08 | wps 46098.3 | wpb 510.9 | bsz 1 | num_updates 43640 | best_loss 8.937
2022-03-07 22:09:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 897 @ 43640 updates
2022-03-07 22:09:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:09:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:09:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 897 @ 43640 updates, score 13.644) (writing took 2.47322349390015 seconds)
2022-03-07 22:09:16 | INFO | fairseq_cli.train | end of epoch 897 (average epoch stats below)
2022-03-07 22:09:16 | INFO | train | epoch 897 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 24521.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43640 | lr 0.000151376 | gnorm 0.341 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 119201
2022-03-07 22:09:16 | INFO | fairseq.trainer | begin training epoch 898
2022-03-07 22:09:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:11:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:11:21 | INFO | valid | epoch 898 | valid on 'valid' subset | loss 13.494 | nll_loss 12.918 | ppl 7738.45 | wps 46662 | wpb 510.9 | bsz 1 | num_updates 43689 | best_loss 8.937
2022-03-07 22:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 898 @ 43689 updates
2022-03-07 22:11:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:11:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:11:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 898 @ 43689 updates, score 13.494) (writing took 3.141092746052891 seconds)
2022-03-07 22:11:24 | INFO | fairseq_cli.train | end of epoch 898 (average epoch stats below)
2022-03-07 22:11:24 | INFO | train | epoch 898 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 24847.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 43689 | lr 0.000151291 | gnorm 0.344 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 119329
2022-03-07 22:11:24 | INFO | fairseq.trainer | begin training epoch 899
2022-03-07 22:11:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:11:51 | INFO | train_inner | epoch 899:     11 / 49 loss=2.011, nll_loss=0.267, ppl=1.2, wps=24719.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=43700, lr=0.000151272, gnorm=0.342, loss_scale=32, train_wall=223, gb_free=8.8, wall=119356
2022-03-07 22:13:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:13:28 | INFO | valid | epoch 899 | valid on 'valid' subset | loss 13.58 | nll_loss 13.012 | ppl 8262.66 | wps 47675.2 | wpb 510.9 | bsz 1 | num_updates 43738 | best_loss 8.937
2022-03-07 22:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 899 @ 43738 updates
2022-03-07 22:13:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:13:30 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:13:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 899 @ 43738 updates, score 13.58) (writing took 2.3092764518223703 seconds)
2022-03-07 22:13:30 | INFO | fairseq_cli.train | end of epoch 899 (average epoch stats below)
2022-03-07 22:13:30 | INFO | train | epoch 899 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 25169.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43738 | lr 0.000151207 | gnorm 0.344 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 119455
2022-03-07 22:13:30 | INFO | fairseq.trainer | begin training epoch 900
2022-03-07 22:13:30 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:13:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:15:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:15:33 | INFO | valid | epoch 900 | valid on 'valid' subset | loss 13.487 | nll_loss 12.913 | ppl 7712.65 | wps 48038.4 | wpb 510.9 | bsz 1 | num_updates 43786 | best_loss 8.937
2022-03-07 22:15:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 900 @ 43786 updates
2022-03-07 22:15:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 900 @ 43786 updates, score 13.487) (writing took 2.281880878843367 seconds)
2022-03-07 22:15:35 | INFO | fairseq_cli.train | end of epoch 900 (average epoch stats below)
2022-03-07 22:15:35 | INFO | train | epoch 900 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 24864 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43786 | lr 0.000151124 | gnorm 0.341 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119580
2022-03-07 22:15:35 | INFO | fairseq.trainer | begin training epoch 901
2022-03-07 22:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:16:10 | INFO | train_inner | epoch 901:     14 / 49 loss=2.011, nll_loss=0.268, ppl=1.2, wps=25095.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=43800, lr=0.000151099, gnorm=0.342, loss_scale=32, train_wall=220, gb_free=8.8, wall=119614
2022-03-07 22:17:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:17:39 | INFO | valid | epoch 901 | valid on 'valid' subset | loss 13.518 | nll_loss 12.948 | ppl 7900.89 | wps 46834.3 | wpb 510.9 | bsz 1 | num_updates 43835 | best_loss 8.937
2022-03-07 22:17:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 901 @ 43835 updates
2022-03-07 22:17:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:17:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:17:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 901 @ 43835 updates, score 13.518) (writing took 2.395025060977787 seconds)
2022-03-07 22:17:41 | INFO | fairseq_cli.train | end of epoch 901 (average epoch stats below)
2022-03-07 22:17:41 | INFO | train | epoch 901 | loss 2.011 | nll_loss 0.268 | ppl 1.2 | wps 25274.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43835 | lr 0.000151039 | gnorm 0.344 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119706
2022-03-07 22:17:41 | INFO | fairseq.trainer | begin training epoch 902
2022-03-07 22:17:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:19:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:19:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:19:44 | INFO | valid | epoch 902 | valid on 'valid' subset | loss 13.546 | nll_loss 12.977 | ppl 8064.56 | wps 48090.2 | wpb 510.9 | bsz 1 | num_updates 43883 | best_loss 8.937
2022-03-07 22:19:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 902 @ 43883 updates
2022-03-07 22:19:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:19:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:19:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 902 @ 43883 updates, score 13.546) (writing took 2.279907986987382 seconds)
2022-03-07 22:19:46 | INFO | fairseq_cli.train | end of epoch 902 (average epoch stats below)
2022-03-07 22:19:46 | INFO | train | epoch 902 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 24890.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 43883 | lr 0.000150957 | gnorm 0.341 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 119831
2022-03-07 22:19:46 | INFO | fairseq.trainer | begin training epoch 903
2022-03-07 22:19:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:20:28 | INFO | train_inner | epoch 903:     17 / 49 loss=2.01, nll_loss=0.268, ppl=1.2, wps=25159, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=43900, lr=0.000150927, gnorm=0.343, loss_scale=32, train_wall=219, gb_free=8.8, wall=119872
2022-03-07 22:21:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:21:49 | INFO | valid | epoch 903 | valid on 'valid' subset | loss 13.537 | nll_loss 12.966 | ppl 7999.01 | wps 48338.7 | wpb 510.9 | bsz 1 | num_updates 43932 | best_loss 8.937
2022-03-07 22:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 903 @ 43932 updates
2022-03-07 22:21:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:21:51 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:21:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 903 @ 43932 updates, score 13.537) (writing took 2.290876355022192 seconds)
2022-03-07 22:21:51 | INFO | fairseq_cli.train | end of epoch 903 (average epoch stats below)
2022-03-07 22:21:51 | INFO | train | epoch 903 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 25378.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43932 | lr 0.000150872 | gnorm 0.345 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 119956
2022-03-07 22:21:51 | INFO | fairseq.trainer | begin training epoch 904
2022-03-07 22:21:51 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:23:54 | INFO | valid | epoch 904 | valid on 'valid' subset | loss 13.572 | nll_loss 13.002 | ppl 8202.48 | wps 48499.8 | wpb 510.9 | bsz 1 | num_updates 43981 | best_loss 8.937
2022-03-07 22:23:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 904 @ 43981 updates
2022-03-07 22:23:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:23:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:23:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 904 @ 43981 updates, score 13.572) (writing took 2.2526505081914365 seconds)
2022-03-07 22:23:56 | INFO | fairseq_cli.train | end of epoch 904 (average epoch stats below)
2022-03-07 22:23:56 | INFO | train | epoch 904 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 25432.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 43981 | lr 0.000150788 | gnorm 0.344 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 120081
2022-03-07 22:23:56 | INFO | fairseq.trainer | begin training epoch 905
2022-03-07 22:23:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:24:43 | INFO | train_inner | epoch 905:     19 / 49 loss=2.01, nll_loss=0.267, ppl=1.2, wps=25390.4, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=44000, lr=0.000150756, gnorm=0.344, loss_scale=32, train_wall=218, gb_free=8.8, wall=120128
2022-03-07 22:25:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:25:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:26:00 | INFO | valid | epoch 905 | valid on 'valid' subset | loss 13.506 | nll_loss 12.933 | ppl 7819.91 | wps 47808.4 | wpb 510.9 | bsz 1 | num_updates 44029 | best_loss 8.937
2022-03-07 22:26:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 905 @ 44029 updates
2022-03-07 22:26:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:26:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:26:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 905 @ 44029 updates, score 13.506) (writing took 2.370636814273894 seconds)
2022-03-07 22:26:02 | INFO | fairseq_cli.train | end of epoch 905 (average epoch stats below)
2022-03-07 22:26:02 | INFO | train | epoch 905 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 24732.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44029 | lr 0.000150706 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120207
2022-03-07 22:26:02 | INFO | fairseq.trainer | begin training epoch 906
2022-03-07 22:26:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:28:05 | INFO | valid | epoch 906 | valid on 'valid' subset | loss 13.605 | nll_loss 13.042 | ppl 8434.17 | wps 48254.8 | wpb 510.9 | bsz 1 | num_updates 44078 | best_loss 8.937
2022-03-07 22:28:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 906 @ 44078 updates
2022-03-07 22:28:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:28:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:28:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 906 @ 44078 updates, score 13.605) (writing took 2.2917073844000697 seconds)
2022-03-07 22:28:07 | INFO | fairseq_cli.train | end of epoch 906 (average epoch stats below)
2022-03-07 22:28:07 | INFO | train | epoch 906 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 25381.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44078 | lr 0.000150622 | gnorm 0.34 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 120332
2022-03-07 22:28:07 | INFO | fairseq.trainer | begin training epoch 907
2022-03-07 22:28:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:29:01 | INFO | train_inner | epoch 907:     22 / 49 loss=2.01, nll_loss=0.267, ppl=1.2, wps=25147.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44100, lr=0.000150585, gnorm=0.339, loss_scale=32, train_wall=220, gb_free=8.8, wall=120386
2022-03-07 22:30:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:30:10 | INFO | valid | epoch 907 | valid on 'valid' subset | loss 13.505 | nll_loss 12.932 | ppl 7816.54 | wps 48084.9 | wpb 510.9 | bsz 1 | num_updates 44127 | best_loss 8.937
2022-03-07 22:30:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 907 @ 44127 updates
2022-03-07 22:30:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:30:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:30:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 907 @ 44127 updates, score 13.505) (writing took 2.2538175731897354 seconds)
2022-03-07 22:30:13 | INFO | fairseq_cli.train | end of epoch 907 (average epoch stats below)
2022-03-07 22:30:13 | INFO | train | epoch 907 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 25398.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44127 | lr 0.000150539 | gnorm 0.337 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 120457
2022-03-07 22:30:13 | INFO | fairseq.trainer | begin training epoch 908
2022-03-07 22:30:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:30:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:32:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:32:15 | INFO | valid | epoch 908 | valid on 'valid' subset | loss 13.518 | nll_loss 12.947 | ppl 7898.97 | wps 48225.1 | wpb 510.9 | bsz 1 | num_updates 44175 | best_loss 8.937
2022-03-07 22:32:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 908 @ 44175 updates
2022-03-07 22:32:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:32:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:32:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 908 @ 44175 updates, score 13.518) (writing took 2.25040267361328 seconds)
2022-03-07 22:32:18 | INFO | fairseq_cli.train | end of epoch 908 (average epoch stats below)
2022-03-07 22:32:18 | INFO | train | epoch 908 | loss 2.009 | nll_loss 0.267 | ppl 1.2 | wps 24857.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44175 | lr 0.000150457 | gnorm 0.34 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120582
2022-03-07 22:32:18 | INFO | fairseq.trainer | begin training epoch 909
2022-03-07 22:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:33:19 | INFO | train_inner | epoch 909:     25 / 49 loss=2.01, nll_loss=0.267, ppl=1.2, wps=25167.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44200, lr=0.000150414, gnorm=0.34, loss_scale=32, train_wall=220, gb_free=8.8, wall=120644
2022-03-07 22:34:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:34:21 | INFO | valid | epoch 909 | valid on 'valid' subset | loss 13.566 | nll_loss 12.996 | ppl 8168.06 | wps 48162.3 | wpb 510.9 | bsz 1 | num_updates 44224 | best_loss 8.937
2022-03-07 22:34:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 909 @ 44224 updates
2022-03-07 22:34:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:34:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:34:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 909 @ 44224 updates, score 13.566) (writing took 2.3511858731508255 seconds)
2022-03-07 22:34:23 | INFO | fairseq_cli.train | end of epoch 909 (average epoch stats below)
2022-03-07 22:34:23 | INFO | train | epoch 909 | loss 2.01 | nll_loss 0.267 | ppl 1.2 | wps 25335.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44224 | lr 0.000150373 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 120708
2022-03-07 22:34:23 | INFO | fairseq.trainer | begin training epoch 910
2022-03-07 22:34:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:36:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:36:26 | INFO | valid | epoch 910 | valid on 'valid' subset | loss 13.569 | nll_loss 13.004 | ppl 8215.53 | wps 48061.4 | wpb 510.9 | bsz 1 | num_updates 44273 | best_loss 8.937
2022-03-07 22:36:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 910 @ 44273 updates
2022-03-07 22:36:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:36:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 910 @ 44273 updates, score 13.569) (writing took 2.3056077328510582 seconds)
2022-03-07 22:36:29 | INFO | fairseq_cli.train | end of epoch 910 (average epoch stats below)
2022-03-07 22:36:29 | INFO | train | epoch 910 | loss 2.009 | nll_loss 0.266 | ppl 1.2 | wps 25338.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44273 | lr 0.00015029 | gnorm 0.342 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 120833
2022-03-07 22:36:29 | INFO | fairseq.trainer | begin training epoch 911
2022-03-07 22:36:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:37:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:37:37 | INFO | train_inner | epoch 911:     28 / 49 loss=2.009, nll_loss=0.266, ppl=1.2, wps=25122.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=44300, lr=0.000150244, gnorm=0.34, loss_scale=32, train_wall=220, gb_free=8.8, wall=120902
2022-03-07 22:38:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:38:32 | INFO | valid | epoch 911 | valid on 'valid' subset | loss 13.537 | nll_loss 12.969 | ppl 8019.54 | wps 48353.3 | wpb 510.9 | bsz 1 | num_updates 44321 | best_loss 8.937
2022-03-07 22:38:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 911 @ 44321 updates
2022-03-07 22:38:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:38:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:38:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 911 @ 44321 updates, score 13.537) (writing took 2.2848636796697974 seconds)
2022-03-07 22:38:34 | INFO | fairseq_cli.train | end of epoch 911 (average epoch stats below)
2022-03-07 22:38:34 | INFO | train | epoch 911 | loss 2.009 | nll_loss 0.266 | ppl 1.2 | wps 24860.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44321 | lr 0.000150209 | gnorm 0.342 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 120959
2022-03-07 22:38:34 | INFO | fairseq.trainer | begin training epoch 912
2022-03-07 22:38:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:40:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:40:37 | INFO | valid | epoch 912 | valid on 'valid' subset | loss 13.586 | nll_loss 13.018 | ppl 8294.89 | wps 48264.6 | wpb 510.9 | bsz 1 | num_updates 44370 | best_loss 8.937
2022-03-07 22:40:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 912 @ 44370 updates
2022-03-07 22:40:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:40:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 912 @ 44370 updates, score 13.586) (writing took 2.275065829977393 seconds)
2022-03-07 22:40:39 | INFO | fairseq_cli.train | end of epoch 912 (average epoch stats below)
2022-03-07 22:40:39 | INFO | train | epoch 912 | loss 2.009 | nll_loss 0.267 | ppl 1.2 | wps 25415 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44370 | lr 0.000150126 | gnorm 0.339 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 121084
2022-03-07 22:40:39 | INFO | fairseq.trainer | begin training epoch 913
2022-03-07 22:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:41:52 | INFO | train_inner | epoch 913:     30 / 49 loss=2.009, nll_loss=0.267, ppl=1.2, wps=25434.4, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44400, lr=0.000150075, gnorm=0.34, loss_scale=32, train_wall=217, gb_free=8.8, wall=121157
2022-03-07 22:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:42:42 | INFO | valid | epoch 913 | valid on 'valid' subset | loss 13.612 | nll_loss 13.052 | ppl 8492.75 | wps 47374.3 | wpb 510.9 | bsz 1 | num_updates 44419 | best_loss 8.937
2022-03-07 22:42:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 913 @ 44419 updates
2022-03-07 22:42:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:42:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 913 @ 44419 updates, score 13.612) (writing took 2.3654789929278195 seconds)
2022-03-07 22:42:44 | INFO | fairseq_cli.train | end of epoch 913 (average epoch stats below)
2022-03-07 22:42:44 | INFO | train | epoch 913 | loss 2.009 | nll_loss 0.267 | ppl 1.2 | wps 25323.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44419 | lr 0.000150043 | gnorm 0.338 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 121209
2022-03-07 22:42:44 | INFO | fairseq.trainer | begin training epoch 914
2022-03-07 22:42:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:43:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:44:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:44:47 | INFO | valid | epoch 914 | valid on 'valid' subset | loss 13.578 | nll_loss 13.014 | ppl 8273.13 | wps 48439.9 | wpb 510.9 | bsz 1 | num_updates 44467 | best_loss 8.937
2022-03-07 22:44:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 914 @ 44467 updates
2022-03-07 22:44:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:44:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:44:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 914 @ 44467 updates, score 13.578) (writing took 2.297667818143964 seconds)
2022-03-07 22:44:50 | INFO | fairseq_cli.train | end of epoch 914 (average epoch stats below)
2022-03-07 22:44:50 | INFO | train | epoch 914 | loss 2.009 | nll_loss 0.267 | ppl 1.2 | wps 24843.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44467 | lr 0.000149962 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121334
2022-03-07 22:44:50 | INFO | fairseq.trainer | begin training epoch 915
2022-03-07 22:44:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:46:10 | INFO | train_inner | epoch 915:     33 / 49 loss=2.009, nll_loss=0.267, ppl=1.2, wps=25124.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44500, lr=0.000149906, gnorm=0.339, loss_scale=32, train_wall=220, gb_free=8.8, wall=121415
2022-03-07 22:46:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:46:53 | INFO | valid | epoch 915 | valid on 'valid' subset | loss 13.463 | nll_loss 12.887 | ppl 7575.74 | wps 48127.6 | wpb 510.9 | bsz 1 | num_updates 44516 | best_loss 8.937
2022-03-07 22:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 915 @ 44516 updates
2022-03-07 22:46:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:46:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:46:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 915 @ 44516 updates, score 13.463) (writing took 2.282624057959765 seconds)
2022-03-07 22:46:55 | INFO | fairseq_cli.train | end of epoch 915 (average epoch stats below)
2022-03-07 22:46:55 | INFO | train | epoch 915 | loss 2.009 | nll_loss 0.266 | ppl 1.2 | wps 25352.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44516 | lr 0.000149879 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121460
2022-03-07 22:46:55 | INFO | fairseq.trainer | begin training epoch 916
2022-03-07 22:46:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:48:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:48:58 | INFO | valid | epoch 916 | valid on 'valid' subset | loss 13.562 | nll_loss 12.994 | ppl 8160.57 | wps 48362.6 | wpb 510.9 | bsz 1 | num_updates 44565 | best_loss 8.937
2022-03-07 22:48:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 916 @ 44565 updates
2022-03-07 22:48:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:49:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:49:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 916 @ 44565 updates, score 13.562) (writing took 2.2748059849254787 seconds)
2022-03-07 22:49:00 | INFO | fairseq_cli.train | end of epoch 916 (average epoch stats below)
2022-03-07 22:49:00 | INFO | train | epoch 916 | loss 2.008 | nll_loss 0.266 | ppl 1.2 | wps 25373.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44565 | lr 0.000149797 | gnorm 0.338 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 121585
2022-03-07 22:49:00 | INFO | fairseq.trainer | begin training epoch 917
2022-03-07 22:49:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:50:26 | INFO | train_inner | epoch 917:     35 / 49 loss=2.008, nll_loss=0.266, ppl=1.2, wps=25390, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44600, lr=0.000149738, gnorm=0.339, loss_scale=64, train_wall=218, gb_free=8.8, wall=121671
2022-03-07 22:50:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:50:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:51:03 | INFO | valid | epoch 917 | valid on 'valid' subset | loss 13.513 | nll_loss 12.94 | ppl 7857.87 | wps 47875.2 | wpb 510.9 | bsz 1 | num_updates 44613 | best_loss 8.937
2022-03-07 22:51:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 917 @ 44613 updates
2022-03-07 22:51:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:51:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:51:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 917 @ 44613 updates, score 13.513) (writing took 2.354339860379696 seconds)
2022-03-07 22:51:06 | INFO | fairseq_cli.train | end of epoch 917 (average epoch stats below)
2022-03-07 22:51:06 | INFO | train | epoch 917 | loss 2.008 | nll_loss 0.266 | ppl 1.2 | wps 24805.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44613 | lr 0.000149716 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 121710
2022-03-07 22:51:06 | INFO | fairseq.trainer | begin training epoch 918
2022-03-07 22:51:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:53:09 | INFO | valid | epoch 918 | valid on 'valid' subset | loss 13.54 | nll_loss 12.974 | ppl 8044.34 | wps 47955.3 | wpb 510.9 | bsz 1 | num_updates 44662 | best_loss 8.937
2022-03-07 22:53:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 918 @ 44662 updates
2022-03-07 22:53:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:53:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 918 @ 44662 updates, score 13.54) (writing took 2.2636654218658805 seconds)
2022-03-07 22:53:11 | INFO | fairseq_cli.train | end of epoch 918 (average epoch stats below)
2022-03-07 22:53:11 | INFO | train | epoch 918 | loss 2.008 | nll_loss 0.266 | ppl 1.2 | wps 25387.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44662 | lr 0.000149634 | gnorm 0.341 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 121836
2022-03-07 22:53:11 | INFO | fairseq.trainer | begin training epoch 919
2022-03-07 22:53:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:54:44 | INFO | train_inner | epoch 919:     38 / 49 loss=2.009, nll_loss=0.266, ppl=1.2, wps=25165.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44700, lr=0.000149571, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=121928
2022-03-07 22:55:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:55:14 | INFO | valid | epoch 919 | valid on 'valid' subset | loss 13.544 | nll_loss 12.976 | ppl 8055.78 | wps 48642.8 | wpb 510.9 | bsz 1 | num_updates 44711 | best_loss 8.937
2022-03-07 22:55:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 919 @ 44711 updates
2022-03-07 22:55:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:55:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:55:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 919 @ 44711 updates, score 13.544) (writing took 2.265524205751717 seconds)
2022-03-07 22:55:16 | INFO | fairseq_cli.train | end of epoch 919 (average epoch stats below)
2022-03-07 22:55:16 | INFO | train | epoch 919 | loss 2.008 | nll_loss 0.266 | ppl 1.2 | wps 25403.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44711 | lr 0.000149552 | gnorm 0.341 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 121961
2022-03-07 22:55:16 | INFO | fairseq.trainer | begin training epoch 920
2022-03-07 22:55:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:56:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 22:57:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:57:19 | INFO | valid | epoch 920 | valid on 'valid' subset | loss 13.54 | nll_loss 12.971 | ppl 8026.75 | wps 46872.5 | wpb 510.9 | bsz 1 | num_updates 44759 | best_loss 8.937
2022-03-07 22:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 920 @ 44759 updates
2022-03-07 22:57:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:57:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:57:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 920 @ 44759 updates, score 13.54) (writing took 2.281972021330148 seconds)
2022-03-07 22:57:21 | INFO | fairseq_cli.train | end of epoch 920 (average epoch stats below)
2022-03-07 22:57:21 | INFO | train | epoch 920 | loss 2.008 | nll_loss 0.266 | ppl 1.2 | wps 24807 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44759 | lr 0.000149472 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122086
2022-03-07 22:57:21 | INFO | fairseq.trainer | begin training epoch 921
2022-03-07 22:57:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 22:59:02 | INFO | train_inner | epoch 921:     41 / 49 loss=2.008, nll_loss=0.266, ppl=1.2, wps=25135.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=44800, lr=0.000149404, gnorm=0.342, loss_scale=32, train_wall=220, gb_free=8.8, wall=122186
2022-03-07 22:59:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 22:59:25 | INFO | valid | epoch 921 | valid on 'valid' subset | loss 13.54 | nll_loss 12.973 | ppl 8037.52 | wps 47557.9 | wpb 510.9 | bsz 1 | num_updates 44808 | best_loss 8.937
2022-03-07 22:59:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 921 @ 44808 updates
2022-03-07 22:59:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:59:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 22:59:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 921 @ 44808 updates, score 13.54) (writing took 2.3694688170216978 seconds)
2022-03-07 22:59:27 | INFO | fairseq_cli.train | end of epoch 921 (average epoch stats below)
2022-03-07 22:59:27 | INFO | train | epoch 921 | loss 2.009 | nll_loss 0.267 | ppl 1.2 | wps 25285.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44808 | lr 0.00014939 | gnorm 0.346 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122212
2022-03-07 22:59:27 | INFO | fairseq.trainer | begin training epoch 922
2022-03-07 22:59:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:01:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:01:30 | INFO | valid | epoch 922 | valid on 'valid' subset | loss 13.574 | nll_loss 13.006 | ppl 8227.66 | wps 47791.2 | wpb 510.9 | bsz 1 | num_updates 44857 | best_loss 8.937
2022-03-07 23:01:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 922 @ 44857 updates
2022-03-07 23:01:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:01:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:01:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 922 @ 44857 updates, score 13.574) (writing took 2.2679231227375567 seconds)
2022-03-07 23:01:32 | INFO | fairseq_cli.train | end of epoch 922 (average epoch stats below)
2022-03-07 23:01:32 | INFO | train | epoch 922 | loss 2.008 | nll_loss 0.266 | ppl 1.2 | wps 25388.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44857 | lr 0.000149309 | gnorm 0.343 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 122337
2022-03-07 23:01:32 | INFO | fairseq.trainer | begin training epoch 923
2022-03-07 23:01:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:02:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:03:20 | INFO | train_inner | epoch 923:     44 / 49 loss=2.008, nll_loss=0.266, ppl=1.2, wps=25131.5, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=44900, lr=0.000149237, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=122445
2022-03-07 23:03:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:03:36 | INFO | valid | epoch 923 | valid on 'valid' subset | loss 13.597 | nll_loss 13.033 | ppl 8381.2 | wps 47224.7 | wpb 510.9 | bsz 1 | num_updates 44905 | best_loss 8.937
2022-03-07 23:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 923 @ 44905 updates
2022-03-07 23:03:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:03:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 923 @ 44905 updates, score 13.597) (writing took 2.274599348194897 seconds)
2022-03-07 23:03:38 | INFO | fairseq_cli.train | end of epoch 923 (average epoch stats below)
2022-03-07 23:03:38 | INFO | train | epoch 923 | loss 2.008 | nll_loss 0.265 | ppl 1.2 | wps 24806.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 44905 | lr 0.000149229 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122463
2022-03-07 23:03:38 | INFO | fairseq.trainer | begin training epoch 924
2022-03-07 23:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:05:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:05:41 | INFO | valid | epoch 924 | valid on 'valid' subset | loss 13.618 | nll_loss 13.055 | ppl 8507.69 | wps 48264.3 | wpb 510.9 | bsz 1 | num_updates 44954 | best_loss 8.937
2022-03-07 23:05:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 924 @ 44954 updates
2022-03-07 23:05:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:05:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 924 @ 44954 updates, score 13.618) (writing took 2.239766472019255 seconds)
2022-03-07 23:05:43 | INFO | fairseq_cli.train | end of epoch 924 (average epoch stats below)
2022-03-07 23:05:43 | INFO | train | epoch 924 | loss 2.008 | nll_loss 0.266 | ppl 1.2 | wps 25353.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 44954 | lr 0.000149147 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122588
2022-03-07 23:05:43 | INFO | fairseq.trainer | begin training epoch 925
2022-03-07 23:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:07:36 | INFO | train_inner | epoch 925:     46 / 49 loss=2.008, nll_loss=0.266, ppl=1.2, wps=25363.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=45000, lr=0.000149071, gnorm=0.34, loss_scale=32, train_wall=218, gb_free=8.8, wall=122700
2022-03-07 23:07:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:07:46 | INFO | valid | epoch 925 | valid on 'valid' subset | loss 13.548 | nll_loss 12.979 | ppl 8073.32 | wps 47864.6 | wpb 510.9 | bsz 1 | num_updates 45003 | best_loss 8.937
2022-03-07 23:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 925 @ 45003 updates
2022-03-07 23:07:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:07:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 925 @ 45003 updates, score 13.548) (writing took 2.377291742246598 seconds)
2022-03-07 23:07:49 | INFO | fairseq_cli.train | end of epoch 925 (average epoch stats below)
2022-03-07 23:07:49 | INFO | train | epoch 925 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 25318 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45003 | lr 0.000149066 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122713
2022-03-07 23:07:49 | INFO | fairseq.trainer | begin training epoch 926
2022-03-07 23:07:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:08:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:09:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:09:52 | INFO | valid | epoch 926 | valid on 'valid' subset | loss 13.576 | nll_loss 13.012 | ppl 8261.1 | wps 48112.8 | wpb 510.9 | bsz 1 | num_updates 45051 | best_loss 8.937
2022-03-07 23:09:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 926 @ 45051 updates
2022-03-07 23:09:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:09:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:09:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 926 @ 45051 updates, score 13.576) (writing took 2.2957701389677823 seconds)
2022-03-07 23:09:54 | INFO | fairseq_cli.train | end of epoch 926 (average epoch stats below)
2022-03-07 23:09:54 | INFO | train | epoch 926 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 24871 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 45051 | lr 0.000148987 | gnorm 0.342 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 122839
2022-03-07 23:09:54 | INFO | fairseq.trainer | begin training epoch 927
2022-03-07 23:09:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:11:52 | INFO | train_inner | epoch 927:     49 / 49 loss=2.007, nll_loss=0.265, ppl=1.2, wps=25133.5, ups=0.39, wpb=64548.5, bsz=126.1, num_updates=45100, lr=0.000148906, gnorm=0.343, loss_scale=32, train_wall=219, gb_free=8.8, wall=122957
2022-03-07 23:11:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:11:57 | INFO | valid | epoch 927 | valid on 'valid' subset | loss 13.591 | nll_loss 13.027 | ppl 8347.53 | wps 48335.8 | wpb 510.9 | bsz 1 | num_updates 45100 | best_loss 8.937
2022-03-07 23:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 927 @ 45100 updates
2022-03-07 23:11:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:11:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:11:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 927 @ 45100 updates, score 13.591) (writing took 2.304075038060546 seconds)
2022-03-07 23:11:59 | INFO | fairseq_cli.train | end of epoch 927 (average epoch stats below)
2022-03-07 23:11:59 | INFO | train | epoch 927 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 25334.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45100 | lr 0.000148906 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 122964
2022-03-07 23:11:59 | INFO | fairseq.trainer | begin training epoch 928
2022-03-07 23:11:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:13:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:13:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:14:02 | INFO | valid | epoch 928 | valid on 'valid' subset | loss 13.508 | nll_loss 12.938 | ppl 7849.01 | wps 48323.7 | wpb 510.9 | bsz 1 | num_updates 45148 | best_loss 8.937
2022-03-07 23:14:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 928 @ 45148 updates
2022-03-07 23:14:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:14:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 928 @ 45148 updates, score 13.508) (writing took 2.2913279342465103 seconds)
2022-03-07 23:14:05 | INFO | fairseq_cli.train | end of epoch 928 (average epoch stats below)
2022-03-07 23:14:05 | INFO | train | epoch 928 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 24825.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45148 | lr 0.000148827 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123089
2022-03-07 23:14:05 | INFO | fairseq.trainer | begin training epoch 929
2022-03-07 23:14:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:16:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:16:08 | INFO | valid | epoch 929 | valid on 'valid' subset | loss 13.538 | nll_loss 12.97 | ppl 8024.47 | wps 47470.1 | wpb 510.9 | bsz 1 | num_updates 45197 | best_loss 8.937
2022-03-07 23:16:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 929 @ 45197 updates
2022-03-07 23:16:08 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:16:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:16:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 929 @ 45197 updates, score 13.538) (writing took 2.3724004197865725 seconds)
2022-03-07 23:16:10 | INFO | fairseq_cli.train | end of epoch 929 (average epoch stats below)
2022-03-07 23:16:10 | INFO | train | epoch 929 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 25350.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45197 | lr 0.000148746 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123215
2022-03-07 23:16:10 | INFO | fairseq.trainer | begin training epoch 930
2022-03-07 23:16:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:16:17 | INFO | train_inner | epoch 930:      3 / 49 loss=2.007, nll_loss=0.265, ppl=1.2, wps=24471.4, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=45200, lr=0.000148741, gnorm=0.337, loss_scale=32, train_wall=220, gb_free=8.8, wall=123222
2022-03-07 23:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:18:13 | INFO | valid | epoch 930 | valid on 'valid' subset | loss 13.621 | nll_loss 13.061 | ppl 8542.93 | wps 48469.8 | wpb 510.9 | bsz 1 | num_updates 45246 | best_loss 8.937
2022-03-07 23:18:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 930 @ 45246 updates
2022-03-07 23:18:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:18:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:18:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 930 @ 45246 updates, score 13.621) (writing took 2.3062433255836368 seconds)
2022-03-07 23:18:15 | INFO | fairseq_cli.train | end of epoch 930 (average epoch stats below)
2022-03-07 23:18:15 | INFO | train | epoch 930 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 25374.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45246 | lr 0.000148665 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123340
2022-03-07 23:18:15 | INFO | fairseq.trainer | begin training epoch 931
2022-03-07 23:18:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:19:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:20:18 | INFO | valid | epoch 931 | valid on 'valid' subset | loss 13.565 | nll_loss 13.001 | ppl 8196.35 | wps 48354.4 | wpb 510.9 | bsz 1 | num_updates 45294 | best_loss 8.937
2022-03-07 23:20:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 931 @ 45294 updates
2022-03-07 23:20:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:20:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:20:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 931 @ 45294 updates, score 13.565) (writing took 2.24703720305115 seconds)
2022-03-07 23:20:20 | INFO | fairseq_cli.train | end of epoch 931 (average epoch stats below)
2022-03-07 23:20:20 | INFO | train | epoch 931 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 24861.2 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 45294 | lr 0.000148587 | gnorm 0.343 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123465
2022-03-07 23:20:21 | INFO | fairseq.trainer | begin training epoch 932
2022-03-07 23:20:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:20:35 | INFO | train_inner | epoch 932:      6 / 49 loss=2.007, nll_loss=0.265, ppl=1.2, wps=25170, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45300, lr=0.000148577, gnorm=0.34, loss_scale=32, train_wall=220, gb_free=8.8, wall=123480
2022-03-07 23:22:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:22:24 | INFO | valid | epoch 932 | valid on 'valid' subset | loss 13.61 | nll_loss 13.046 | ppl 8459.09 | wps 48323.3 | wpb 510.9 | bsz 1 | num_updates 45343 | best_loss 8.937
2022-03-07 23:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 932 @ 45343 updates
2022-03-07 23:22:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:22:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 932 @ 45343 updates, score 13.61) (writing took 2.2835624990984797 seconds)
2022-03-07 23:22:26 | INFO | fairseq_cli.train | end of epoch 932 (average epoch stats below)
2022-03-07 23:22:26 | INFO | train | epoch 932 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 25362.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45343 | lr 0.000148506 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123591
2022-03-07 23:22:26 | INFO | fairseq.trainer | begin training epoch 933
2022-03-07 23:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:24:29 | INFO | valid | epoch 933 | valid on 'valid' subset | loss 13.565 | nll_loss 13.001 | ppl 8195.98 | wps 47512.3 | wpb 510.9 | bsz 1 | num_updates 45392 | best_loss 8.937
2022-03-07 23:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 933 @ 45392 updates
2022-03-07 23:24:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:24:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 933 @ 45392 updates, score 13.565) (writing took 2.3923728610388935 seconds)
2022-03-07 23:24:31 | INFO | fairseq_cli.train | end of epoch 933 (average epoch stats below)
2022-03-07 23:24:31 | INFO | train | epoch 933 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 25333.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45392 | lr 0.000148426 | gnorm 0.339 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 123716
2022-03-07 23:24:31 | INFO | fairseq.trainer | begin training epoch 934
2022-03-07 23:24:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:24:51 | INFO | train_inner | epoch 934:      8 / 49 loss=2.007, nll_loss=0.265, ppl=1.2, wps=25387.7, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=45400, lr=0.000148413, gnorm=0.339, loss_scale=32, train_wall=217, gb_free=8.8, wall=123736
2022-03-07 23:25:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:26:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:26:34 | INFO | valid | epoch 934 | valid on 'valid' subset | loss 13.528 | nll_loss 12.958 | ppl 7955.05 | wps 48312.8 | wpb 510.9 | bsz 1 | num_updates 45440 | best_loss 8.937
2022-03-07 23:26:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 934 @ 45440 updates
2022-03-07 23:26:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:26:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:26:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 934 @ 45440 updates, score 13.528) (writing took 2.2776816338300705 seconds)
2022-03-07 23:26:36 | INFO | fairseq_cli.train | end of epoch 934 (average epoch stats below)
2022-03-07 23:26:36 | INFO | train | epoch 934 | loss 2.007 | nll_loss 0.265 | ppl 1.2 | wps 24857.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45440 | lr 0.000148348 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123841
2022-03-07 23:26:36 | INFO | fairseq.trainer | begin training epoch 935
2022-03-07 23:26:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:28:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:28:39 | INFO | valid | epoch 935 | valid on 'valid' subset | loss 13.514 | nll_loss 12.945 | ppl 7883.34 | wps 48257.2 | wpb 510.9 | bsz 1 | num_updates 45489 | best_loss 8.937
2022-03-07 23:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 935 @ 45489 updates
2022-03-07 23:28:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:28:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:28:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 935 @ 45489 updates, score 13.514) (writing took 2.2668827730230987 seconds)
2022-03-07 23:28:42 | INFO | fairseq_cli.train | end of epoch 935 (average epoch stats below)
2022-03-07 23:28:42 | INFO | train | epoch 935 | loss 2.006 | nll_loss 0.265 | ppl 1.2 | wps 25380.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45489 | lr 0.000148268 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 123966
2022-03-07 23:28:42 | INFO | fairseq.trainer | begin training epoch 936
2022-03-07 23:28:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:29:08 | INFO | train_inner | epoch 936:     11 / 49 loss=2.007, nll_loss=0.265, ppl=1.2, wps=25172.3, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45500, lr=0.00014825, gnorm=0.339, loss_scale=32, train_wall=220, gb_free=8.8, wall=123993
2022-03-07 23:30:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:30:45 | INFO | valid | epoch 936 | valid on 'valid' subset | loss 13.56 | nll_loss 12.995 | ppl 8166.46 | wps 48203.5 | wpb 510.9 | bsz 1 | num_updates 45538 | best_loss 8.937
2022-03-07 23:30:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 936 @ 45538 updates
2022-03-07 23:30:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:30:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:30:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 936 @ 45538 updates, score 13.56) (writing took 2.2716048788279295 seconds)
2022-03-07 23:30:47 | INFO | fairseq_cli.train | end of epoch 936 (average epoch stats below)
2022-03-07 23:30:47 | INFO | train | epoch 936 | loss 2.006 | nll_loss 0.265 | ppl 1.2 | wps 25393.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45538 | lr 0.000148188 | gnorm 0.336 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124092
2022-03-07 23:30:47 | INFO | fairseq.trainer | begin training epoch 937
2022-03-07 23:30:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:31:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:32:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:32:50 | INFO | valid | epoch 937 | valid on 'valid' subset | loss 13.579 | nll_loss 13.016 | ppl 8284.92 | wps 48211.7 | wpb 510.9 | bsz 1 | num_updates 45586 | best_loss 8.937
2022-03-07 23:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 937 @ 45586 updates
2022-03-07 23:32:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:32:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 937 @ 45586 updates, score 13.579) (writing took 2.3649485828354955 seconds)
2022-03-07 23:32:52 | INFO | fairseq_cli.train | end of epoch 937 (average epoch stats below)
2022-03-07 23:32:52 | INFO | train | epoch 937 | loss 2.006 | nll_loss 0.265 | ppl 1.2 | wps 24835.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45586 | lr 0.00014811 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124217
2022-03-07 23:32:52 | INFO | fairseq.trainer | begin training epoch 938
2022-03-07 23:32:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:33:26 | INFO | train_inner | epoch 938:     14 / 49 loss=2.006, nll_loss=0.264, ppl=1.2, wps=25154.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45600, lr=0.000148087, gnorm=0.337, loss_scale=32, train_wall=220, gb_free=8.8, wall=124251
2022-03-07 23:34:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:34:55 | INFO | valid | epoch 938 | valid on 'valid' subset | loss 13.579 | nll_loss 13.016 | ppl 8281.35 | wps 48145.8 | wpb 510.9 | bsz 1 | num_updates 45635 | best_loss 8.937
2022-03-07 23:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 938 @ 45635 updates
2022-03-07 23:34:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:34:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 938 @ 45635 updates, score 13.579) (writing took 2.266153850592673 seconds)
2022-03-07 23:34:57 | INFO | fairseq_cli.train | end of epoch 938 (average epoch stats below)
2022-03-07 23:34:57 | INFO | train | epoch 938 | loss 2.006 | nll_loss 0.264 | ppl 1.2 | wps 25390.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45635 | lr 0.00014803 | gnorm 0.337 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 124342
2022-03-07 23:34:57 | INFO | fairseq.trainer | begin training epoch 939
2022-03-07 23:34:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:37:00 | INFO | valid | epoch 939 | valid on 'valid' subset | loss 13.574 | nll_loss 13.01 | ppl 8250.67 | wps 48753.8 | wpb 510.9 | bsz 1 | num_updates 45684 | best_loss 8.937
2022-03-07 23:37:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 939 @ 45684 updates
2022-03-07 23:37:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:37:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:37:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 939 @ 45684 updates, score 13.574) (writing took 3.955245849210769 seconds)
2022-03-07 23:37:04 | INFO | fairseq_cli.train | end of epoch 939 (average epoch stats below)
2022-03-07 23:37:04 | INFO | train | epoch 939 | loss 2.006 | nll_loss 0.264 | ppl 1.2 | wps 25075.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45684 | lr 0.000147951 | gnorm 0.338 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 124469
2022-03-07 23:37:04 | INFO | fairseq.trainer | begin training epoch 940
2022-03-07 23:37:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:37:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:37:46 | INFO | train_inner | epoch 940:     17 / 49 loss=2.005, nll_loss=0.264, ppl=1.2, wps=25004.2, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=45700, lr=0.000147925, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=124511
2022-03-07 23:39:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:39:07 | INFO | valid | epoch 940 | valid on 'valid' subset | loss 13.56 | nll_loss 12.997 | ppl 8172.43 | wps 48770.5 | wpb 510.9 | bsz 1 | num_updates 45732 | best_loss 8.937
2022-03-07 23:39:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 940 @ 45732 updates
2022-03-07 23:39:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:39:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:39:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 940 @ 45732 updates, score 13.56) (writing took 2.3174260850064456 seconds)
2022-03-07 23:39:09 | INFO | fairseq_cli.train | end of epoch 940 (average epoch stats below)
2022-03-07 23:39:09 | INFO | train | epoch 940 | loss 2.006 | nll_loss 0.264 | ppl 1.2 | wps 24841.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45732 | lr 0.000147873 | gnorm 0.34 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124594
2022-03-07 23:39:09 | INFO | fairseq.trainer | begin training epoch 941
2022-03-07 23:39:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:41:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:41:12 | INFO | valid | epoch 941 | valid on 'valid' subset | loss 13.62 | nll_loss 13.059 | ppl 8534.21 | wps 48172.9 | wpb 510.9 | bsz 1 | num_updates 45781 | best_loss 8.937
2022-03-07 23:41:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 941 @ 45781 updates
2022-03-07 23:41:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:41:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:41:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 941 @ 45781 updates, score 13.62) (writing took 2.371140165720135 seconds)
2022-03-07 23:41:15 | INFO | fairseq_cli.train | end of epoch 941 (average epoch stats below)
2022-03-07 23:41:15 | INFO | train | epoch 941 | loss 2.006 | nll_loss 0.264 | ppl 1.2 | wps 25320.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45781 | lr 0.000147794 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 124720
2022-03-07 23:41:15 | INFO | fairseq.trainer | begin training epoch 942
2022-03-07 23:41:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:42:01 | INFO | train_inner | epoch 942:     19 / 49 loss=2.006, nll_loss=0.264, ppl=1.2, wps=25401.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45800, lr=0.000147764, gnorm=0.342, loss_scale=32, train_wall=217, gb_free=8.8, wall=124766
2022-03-07 23:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:43:18 | INFO | valid | epoch 942 | valid on 'valid' subset | loss 13.519 | nll_loss 12.951 | ppl 7916 | wps 46288.5 | wpb 510.9 | bsz 1 | num_updates 45830 | best_loss 8.937
2022-03-07 23:43:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 942 @ 45830 updates
2022-03-07 23:43:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:43:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:43:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 942 @ 45830 updates, score 13.519) (writing took 2.3129936829209328 seconds)
2022-03-07 23:43:21 | INFO | fairseq_cli.train | end of epoch 942 (average epoch stats below)
2022-03-07 23:43:21 | INFO | train | epoch 942 | loss 2.006 | nll_loss 0.264 | ppl 1.2 | wps 25288 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45830 | lr 0.000147715 | gnorm 0.338 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 124845
2022-03-07 23:43:21 | INFO | fairseq.trainer | begin training epoch 943
2022-03-07 23:43:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:44:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:45:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:45:25 | INFO | valid | epoch 943 | valid on 'valid' subset | loss 13.605 | nll_loss 13.044 | ppl 8447.37 | wps 48169.2 | wpb 510.9 | bsz 1 | num_updates 45878 | best_loss 8.937
2022-03-07 23:45:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 943 @ 45878 updates
2022-03-07 23:45:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:45:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:45:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 943 @ 45878 updates, score 13.605) (writing took 2.3313983902335167 seconds)
2022-03-07 23:45:27 | INFO | fairseq_cli.train | end of epoch 943 (average epoch stats below)
2022-03-07 23:45:27 | INFO | train | epoch 943 | loss 2.005 | nll_loss 0.264 | ppl 1.2 | wps 24612.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 45878 | lr 0.000147638 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 124972
2022-03-07 23:45:27 | INFO | fairseq.trainer | begin training epoch 944
2022-03-07 23:45:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:46:21 | INFO | train_inner | epoch 944:     22 / 49 loss=2.005, nll_loss=0.264, ppl=1.2, wps=24979.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=45900, lr=0.000147602, gnorm=0.337, loss_scale=32, train_wall=221, gb_free=8.8, wall=125026
2022-03-07 23:47:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:47:30 | INFO | valid | epoch 944 | valid on 'valid' subset | loss 13.571 | nll_loss 13.004 | ppl 8215.62 | wps 48014.4 | wpb 510.9 | bsz 1 | num_updates 45927 | best_loss 8.937
2022-03-07 23:47:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 944 @ 45927 updates
2022-03-07 23:47:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:47:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:47:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 944 @ 45927 updates, score 13.571) (writing took 2.266157432924956 seconds)
2022-03-07 23:47:32 | INFO | fairseq_cli.train | end of epoch 944 (average epoch stats below)
2022-03-07 23:47:32 | INFO | train | epoch 944 | loss 2.005 | nll_loss 0.264 | ppl 1.2 | wps 25378.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45927 | lr 0.000147559 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125097
2022-03-07 23:47:32 | INFO | fairseq.trainer | begin training epoch 945
2022-03-07 23:47:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:49:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:49:35 | INFO | valid | epoch 945 | valid on 'valid' subset | loss 13.534 | nll_loss 12.965 | ppl 7997.61 | wps 47086.5 | wpb 510.9 | bsz 1 | num_updates 45976 | best_loss 8.937
2022-03-07 23:49:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 945 @ 45976 updates
2022-03-07 23:49:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:49:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:49:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 945 @ 45976 updates, score 13.534) (writing took 2.3966777767054737 seconds)
2022-03-07 23:49:38 | INFO | fairseq_cli.train | end of epoch 945 (average epoch stats below)
2022-03-07 23:49:38 | INFO | train | epoch 945 | loss 2.006 | nll_loss 0.264 | ppl 1.2 | wps 25311.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 45976 | lr 0.00014748 | gnorm 0.343 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125223
2022-03-07 23:49:38 | INFO | fairseq.trainer | begin training epoch 946
2022-03-07 23:49:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:50:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:50:39 | INFO | train_inner | epoch 946:     25 / 49 loss=2.005, nll_loss=0.264, ppl=1.2, wps=25153.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46000, lr=0.000147442, gnorm=0.34, loss_scale=32, train_wall=220, gb_free=8.8, wall=125284
2022-03-07 23:51:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:51:41 | INFO | valid | epoch 946 | valid on 'valid' subset | loss 13.545 | nll_loss 12.98 | ppl 8077.25 | wps 48478.6 | wpb 510.9 | bsz 1 | num_updates 46024 | best_loss 8.937
2022-03-07 23:51:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 946 @ 46024 updates
2022-03-07 23:51:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:51:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:51:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 946 @ 46024 updates, score 13.545) (writing took 2.316043057013303 seconds)
2022-03-07 23:51:43 | INFO | fairseq_cli.train | end of epoch 946 (average epoch stats below)
2022-03-07 23:51:43 | INFO | train | epoch 946 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 24846.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46024 | lr 0.000147404 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125348
2022-03-07 23:51:43 | INFO | fairseq.trainer | begin training epoch 947
2022-03-07 23:51:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:53:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:53:46 | INFO | valid | epoch 947 | valid on 'valid' subset | loss 13.57 | nll_loss 13.003 | ppl 8211.12 | wps 48124 | wpb 510.9 | bsz 1 | num_updates 46073 | best_loss 8.937
2022-03-07 23:53:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 947 @ 46073 updates
2022-03-07 23:53:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:53:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:53:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 947 @ 46073 updates, score 13.57) (writing took 2.3045471720397472 seconds)
2022-03-07 23:53:48 | INFO | fairseq_cli.train | end of epoch 947 (average epoch stats below)
2022-03-07 23:53:48 | INFO | train | epoch 947 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 25404.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46073 | lr 0.000147325 | gnorm 0.336 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 125473
2022-03-07 23:53:48 | INFO | fairseq.trainer | begin training epoch 948
2022-03-07 23:53:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:54:54 | INFO | train_inner | epoch 948:     27 / 49 loss=2.004, nll_loss=0.263, ppl=1.2, wps=25404.1, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=46100, lr=0.000147282, gnorm=0.336, loss_scale=32, train_wall=217, gb_free=8.8, wall=125539
2022-03-07 23:55:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-07 23:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:55:51 | INFO | valid | epoch 948 | valid on 'valid' subset | loss 13.561 | nll_loss 12.997 | ppl 8173.06 | wps 48250.3 | wpb 510.9 | bsz 1 | num_updates 46121 | best_loss 8.937
2022-03-07 23:55:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 948 @ 46121 updates
2022-03-07 23:55:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:55:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:55:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 948 @ 46121 updates, score 13.561) (writing took 2.2440716540440917 seconds)
2022-03-07 23:55:53 | INFO | fairseq_cli.train | end of epoch 948 (average epoch stats below)
2022-03-07 23:55:53 | INFO | train | epoch 948 | loss 2.005 | nll_loss 0.264 | ppl 1.2 | wps 24846.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46121 | lr 0.000147248 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125598
2022-03-07 23:55:53 | INFO | fairseq.trainer | begin training epoch 949
2022-03-07 23:55:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-07 23:57:56 | INFO | valid | epoch 949 | valid on 'valid' subset | loss 13.483 | nll_loss 12.916 | ppl 7728.7 | wps 47396.8 | wpb 510.9 | bsz 1 | num_updates 46170 | best_loss 8.937
2022-03-07 23:57:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 949 @ 46170 updates
2022-03-07 23:57:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-07 23:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 949 @ 46170 updates, score 13.483) (writing took 2.433327459730208 seconds)
2022-03-07 23:57:59 | INFO | fairseq_cli.train | end of epoch 949 (average epoch stats below)
2022-03-07 23:57:59 | INFO | train | epoch 949 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 25322.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46170 | lr 0.00014717 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125724
2022-03-07 23:57:59 | INFO | fairseq.trainer | begin training epoch 950
2022-03-07 23:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-07 23:59:12 | INFO | train_inner | epoch 950:     30 / 49 loss=2.005, nll_loss=0.264, ppl=1.2, wps=25154.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46200, lr=0.000147122, gnorm=0.34, loss_scale=32, train_wall=220, gb_free=8.8, wall=125797
2022-03-07 23:59:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:00:02 | INFO | valid | epoch 950 | valid on 'valid' subset | loss 13.577 | nll_loss 13.013 | ppl 8268.07 | wps 47868.4 | wpb 510.9 | bsz 1 | num_updates 46219 | best_loss 8.937
2022-03-08 00:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 950 @ 46219 updates
2022-03-08 00:00:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:00:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:00:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 950 @ 46219 updates, score 13.577) (writing took 2.331009632907808 seconds)
2022-03-08 00:00:04 | INFO | fairseq_cli.train | end of epoch 950 (average epoch stats below)
2022-03-08 00:00:04 | INFO | train | epoch 950 | loss 2.005 | nll_loss 0.264 | ppl 1.2 | wps 25368.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46219 | lr 0.000147092 | gnorm 0.338 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 125849
2022-03-08 00:00:04 | INFO | fairseq.trainer | begin training epoch 951
2022-03-08 00:00:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:01:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:02:07 | INFO | valid | epoch 951 | valid on 'valid' subset | loss 13.572 | nll_loss 13.008 | ppl 8238.02 | wps 47967.8 | wpb 510.9 | bsz 1 | num_updates 46267 | best_loss 8.937
2022-03-08 00:02:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 951 @ 46267 updates
2022-03-08 00:02:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 951 @ 46267 updates, score 13.572) (writing took 2.2441670349799097 seconds)
2022-03-08 00:02:10 | INFO | fairseq_cli.train | end of epoch 951 (average epoch stats below)
2022-03-08 00:02:10 | INFO | train | epoch 951 | loss 2.004 | nll_loss 0.264 | ppl 1.2 | wps 24819.3 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46267 | lr 0.000147016 | gnorm 0.34 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 125974
2022-03-08 00:02:10 | INFO | fairseq.trainer | begin training epoch 952
2022-03-08 00:02:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:03:30 | INFO | train_inner | epoch 952:     33 / 49 loss=2.004, nll_loss=0.263, ppl=1.2, wps=25117.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=46300, lr=0.000146964, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=126055
2022-03-08 00:04:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:04:13 | INFO | valid | epoch 952 | valid on 'valid' subset | loss 13.502 | nll_loss 12.932 | ppl 7813.41 | wps 48733.4 | wpb 510.9 | bsz 1 | num_updates 46316 | best_loss 8.937
2022-03-08 00:04:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 952 @ 46316 updates
2022-03-08 00:04:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:04:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:04:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 952 @ 46316 updates, score 13.502) (writing took 2.281313352752477 seconds)
2022-03-08 00:04:15 | INFO | fairseq_cli.train | end of epoch 952 (average epoch stats below)
2022-03-08 00:04:15 | INFO | train | epoch 952 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 25388.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46316 | lr 0.000146938 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126100
2022-03-08 00:04:15 | INFO | fairseq.trainer | begin training epoch 953
2022-03-08 00:04:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:06:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:06:18 | INFO | valid | epoch 953 | valid on 'valid' subset | loss 13.577 | nll_loss 13.01 | ppl 8247.99 | wps 46844.3 | wpb 510.9 | bsz 1 | num_updates 46365 | best_loss 8.937
2022-03-08 00:06:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 953 @ 46365 updates
2022-03-08 00:06:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:06:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:06:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 953 @ 46365 updates, score 13.577) (writing took 2.4314560717903078 seconds)
2022-03-08 00:06:21 | INFO | fairseq_cli.train | end of epoch 953 (average epoch stats below)
2022-03-08 00:06:21 | INFO | train | epoch 953 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 25265.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46365 | lr 0.00014686 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126225
2022-03-08 00:06:21 | INFO | fairseq.trainer | begin training epoch 954
2022-03-08 00:06:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:06:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:07:49 | INFO | train_inner | epoch 954:     36 / 49 loss=2.004, nll_loss=0.263, ppl=1.2, wps=25122.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46400, lr=0.000146805, gnorm=0.337, loss_scale=32, train_wall=220, gb_free=8.8, wall=126313
2022-03-08 00:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:08:24 | INFO | valid | epoch 954 | valid on 'valid' subset | loss 13.613 | nll_loss 13.052 | ppl 8491.44 | wps 48113 | wpb 510.9 | bsz 1 | num_updates 46413 | best_loss 8.937
2022-03-08 00:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 954 @ 46413 updates
2022-03-08 00:08:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:08:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:08:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 954 @ 46413 updates, score 13.613) (writing took 2.291505475062877 seconds)
2022-03-08 00:08:26 | INFO | fairseq_cli.train | end of epoch 954 (average epoch stats below)
2022-03-08 00:08:26 | INFO | train | epoch 954 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 24814.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46413 | lr 0.000146784 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126351
2022-03-08 00:08:26 | INFO | fairseq.trainer | begin training epoch 955
2022-03-08 00:08:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:10:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:10:29 | INFO | valid | epoch 955 | valid on 'valid' subset | loss 13.625 | nll_loss 13.064 | ppl 8566.52 | wps 47818.2 | wpb 510.9 | bsz 1 | num_updates 46462 | best_loss 8.937
2022-03-08 00:10:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 955 @ 46462 updates
2022-03-08 00:10:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:10:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:10:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 955 @ 46462 updates, score 13.625) (writing took 2.3100888417102396 seconds)
2022-03-08 00:10:31 | INFO | fairseq_cli.train | end of epoch 955 (average epoch stats below)
2022-03-08 00:10:31 | INFO | train | epoch 955 | loss 2.005 | nll_loss 0.264 | ppl 1.2 | wps 25390.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46462 | lr 0.000146707 | gnorm 0.341 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 126476
2022-03-08 00:10:31 | INFO | fairseq.trainer | begin training epoch 956
2022-03-08 00:10:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:12:04 | INFO | train_inner | epoch 956:     38 / 49 loss=2.004, nll_loss=0.263, ppl=1.2, wps=25399.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46500, lr=0.000146647, gnorm=0.337, loss_scale=32, train_wall=217, gb_free=8.8, wall=126569
2022-03-08 00:12:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:12:34 | INFO | valid | epoch 956 | valid on 'valid' subset | loss 13.593 | nll_loss 13.027 | ppl 8346.64 | wps 47945.2 | wpb 510.9 | bsz 1 | num_updates 46511 | best_loss 8.937
2022-03-08 00:12:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 956 @ 46511 updates
2022-03-08 00:12:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:12:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 956 @ 46511 updates, score 13.593) (writing took 2.260656202211976 seconds)
2022-03-08 00:12:36 | INFO | fairseq_cli.train | end of epoch 956 (average epoch stats below)
2022-03-08 00:12:36 | INFO | train | epoch 956 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 25393.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46511 | lr 0.00014663 | gnorm 0.336 | loss_scale 64 | train_wall 106 | gb_free 8.8 | wall 126601
2022-03-08 00:12:36 | INFO | fairseq.trainer | begin training epoch 957
2022-03-08 00:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:13:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:14:40 | INFO | valid | epoch 957 | valid on 'valid' subset | loss 13.604 | nll_loss 13.042 | ppl 8435.42 | wps 47557.3 | wpb 510.9 | bsz 1 | num_updates 46559 | best_loss 8.937
2022-03-08 00:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 957 @ 46559 updates
2022-03-08 00:14:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:14:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:14:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 957 @ 46559 updates, score 13.604) (writing took 2.4356408729217947 seconds)
2022-03-08 00:14:42 | INFO | fairseq_cli.train | end of epoch 957 (average epoch stats below)
2022-03-08 00:14:42 | INFO | train | epoch 957 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 24766.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46559 | lr 0.000146554 | gnorm 0.341 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126727
2022-03-08 00:14:42 | INFO | fairseq.trainer | begin training epoch 958
2022-03-08 00:14:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:16:22 | INFO | train_inner | epoch 958:     41 / 49 loss=2.004, nll_loss=0.264, ppl=1.2, wps=25122.8, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46600, lr=0.00014649, gnorm=0.341, loss_scale=32, train_wall=220, gb_free=8.8, wall=126827
2022-03-08 00:16:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:16:45 | INFO | valid | epoch 958 | valid on 'valid' subset | loss 13.502 | nll_loss 12.93 | ppl 7805.54 | wps 48162.2 | wpb 510.9 | bsz 1 | num_updates 46608 | best_loss 8.937
2022-03-08 00:16:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 958 @ 46608 updates
2022-03-08 00:16:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:16:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 958 @ 46608 updates, score 13.502) (writing took 2.3356288322247565 seconds)
2022-03-08 00:16:47 | INFO | fairseq_cli.train | end of epoch 958 (average epoch stats below)
2022-03-08 00:16:47 | INFO | train | epoch 958 | loss 2.004 | nll_loss 0.264 | ppl 1.2 | wps 25342.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46608 | lr 0.000146477 | gnorm 0.342 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 126852
2022-03-08 00:16:47 | INFO | fairseq.trainer | begin training epoch 959
2022-03-08 00:16:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:18:51 | INFO | valid | epoch 959 | valid on 'valid' subset | loss 13.596 | nll_loss 13.034 | ppl 8389.95 | wps 47759 | wpb 510.9 | bsz 1 | num_updates 46657 | best_loss 8.937
2022-03-08 00:18:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 959 @ 46657 updates
2022-03-08 00:18:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:18:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:18:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 959 @ 46657 updates, score 13.596) (writing took 2.262015489395708 seconds)
2022-03-08 00:18:53 | INFO | fairseq_cli.train | end of epoch 959 (average epoch stats below)
2022-03-08 00:18:53 | INFO | train | epoch 959 | loss 2.003 | nll_loss 0.263 | ppl 1.2 | wps 25330 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46657 | lr 0.0001464 | gnorm 0.338 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 126978
2022-03-08 00:18:53 | INFO | fairseq.trainer | begin training epoch 960
2022-03-08 00:18:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:19:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:20:40 | INFO | train_inner | epoch 960:     44 / 49 loss=2.004, nll_loss=0.263, ppl=1.2, wps=25117.2, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46700, lr=0.000146333, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=127085
2022-03-08 00:20:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:20:56 | INFO | valid | epoch 960 | valid on 'valid' subset | loss 13.572 | nll_loss 13.004 | ppl 8217.42 | wps 48294.9 | wpb 510.9 | bsz 1 | num_updates 46705 | best_loss 8.937
2022-03-08 00:20:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 960 @ 46705 updates
2022-03-08 00:20:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:20:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:20:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 960 @ 46705 updates, score 13.572) (writing took 2.2557553900405765 seconds)
2022-03-08 00:20:58 | INFO | fairseq_cli.train | end of epoch 960 (average epoch stats below)
2022-03-08 00:20:58 | INFO | train | epoch 960 | loss 2.004 | nll_loss 0.263 | ppl 1.2 | wps 24832.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46705 | lr 0.000146325 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127103
2022-03-08 00:20:58 | INFO | fairseq.trainer | begin training epoch 961
2022-03-08 00:20:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:22:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:23:01 | INFO | valid | epoch 961 | valid on 'valid' subset | loss 13.578 | nll_loss 13.014 | ppl 8271 | wps 47464.8 | wpb 510.9 | bsz 1 | num_updates 46754 | best_loss 8.937
2022-03-08 00:23:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 961 @ 46754 updates
2022-03-08 00:23:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:23:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:23:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 961 @ 46754 updates, score 13.578) (writing took 2.418107529170811 seconds)
2022-03-08 00:23:04 | INFO | fairseq_cli.train | end of epoch 961 (average epoch stats below)
2022-03-08 00:23:04 | INFO | train | epoch 961 | loss 2.003 | nll_loss 0.263 | ppl 1.2 | wps 25313.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46754 | lr 0.000146248 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127229
2022-03-08 00:23:04 | INFO | fairseq.trainer | begin training epoch 962
2022-03-08 00:23:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:24:56 | INFO | train_inner | epoch 962:     46 / 49 loss=2.003, nll_loss=0.263, ppl=1.2, wps=25371.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=46800, lr=0.000146176, gnorm=0.338, loss_scale=32, train_wall=218, gb_free=8.8, wall=127341
2022-03-08 00:25:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:25:07 | INFO | valid | epoch 962 | valid on 'valid' subset | loss 13.572 | nll_loss 13.007 | ppl 8234.62 | wps 48657.6 | wpb 510.9 | bsz 1 | num_updates 46803 | best_loss 8.937
2022-03-08 00:25:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 962 @ 46803 updates
2022-03-08 00:25:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:25:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:25:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 962 @ 46803 updates, score 13.572) (writing took 2.3101481730118394 seconds)
2022-03-08 00:25:09 | INFO | fairseq_cli.train | end of epoch 962 (average epoch stats below)
2022-03-08 00:25:09 | INFO | train | epoch 962 | loss 2.003 | nll_loss 0.263 | ppl 1.2 | wps 25359 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46803 | lr 0.000146172 | gnorm 0.339 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 127354
2022-03-08 00:25:09 | INFO | fairseq.trainer | begin training epoch 963
2022-03-08 00:25:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:25:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:27:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:27:12 | INFO | valid | epoch 963 | valid on 'valid' subset | loss 13.602 | nll_loss 13.039 | ppl 8417.15 | wps 47805.4 | wpb 510.9 | bsz 1 | num_updates 46851 | best_loss 8.937
2022-03-08 00:27:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 963 @ 46851 updates
2022-03-08 00:27:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:27:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:27:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 963 @ 46851 updates, score 13.602) (writing took 2.2885812828317285 seconds)
2022-03-08 00:27:15 | INFO | fairseq_cli.train | end of epoch 963 (average epoch stats below)
2022-03-08 00:27:15 | INFO | train | epoch 963 | loss 2.003 | nll_loss 0.262 | ppl 1.2 | wps 24781 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46851 | lr 0.000146097 | gnorm 0.335 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127479
2022-03-08 00:27:15 | INFO | fairseq.trainer | begin training epoch 964
2022-03-08 00:27:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:29:13 | INFO | train_inner | epoch 964:     49 / 49 loss=2.003, nll_loss=0.262, ppl=1.2, wps=25125.8, ups=0.39, wpb=64544.1, bsz=126.1, num_updates=46900, lr=0.00014602, gnorm=0.337, loss_scale=32, train_wall=219, gb_free=8.8, wall=127598
2022-03-08 00:29:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:29:18 | INFO | valid | epoch 964 | valid on 'valid' subset | loss 13.541 | nll_loss 12.976 | ppl 8056.2 | wps 47935.5 | wpb 510.9 | bsz 1 | num_updates 46900 | best_loss 8.937
2022-03-08 00:29:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 964 @ 46900 updates
2022-03-08 00:29:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:29:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:29:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 964 @ 46900 updates, score 13.541) (writing took 2.2690688520669937 seconds)
2022-03-08 00:29:20 | INFO | fairseq_cli.train | end of epoch 964 (average epoch stats below)
2022-03-08 00:29:20 | INFO | train | epoch 964 | loss 2.003 | nll_loss 0.263 | ppl 1.2 | wps 25379.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46900 | lr 0.00014602 | gnorm 0.336 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 127605
2022-03-08 00:29:20 | INFO | fairseq.trainer | begin training epoch 965
2022-03-08 00:29:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:31:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:31:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:31:23 | INFO | valid | epoch 965 | valid on 'valid' subset | loss 13.5 | nll_loss 12.929 | ppl 7796.89 | wps 47076.6 | wpb 510.9 | bsz 1 | num_updates 46948 | best_loss 8.937
2022-03-08 00:31:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 965 @ 46948 updates
2022-03-08 00:31:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:31:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 965 @ 46948 updates, score 13.5) (writing took 2.4266475248150527 seconds)
2022-03-08 00:31:25 | INFO | fairseq_cli.train | end of epoch 965 (average epoch stats below)
2022-03-08 00:31:25 | INFO | train | epoch 965 | loss 2.003 | nll_loss 0.263 | ppl 1.2 | wps 24789 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 46948 | lr 0.000145946 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127730
2022-03-08 00:31:25 | INFO | fairseq.trainer | begin training epoch 966
2022-03-08 00:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:33:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:33:28 | INFO | valid | epoch 966 | valid on 'valid' subset | loss 13.571 | nll_loss 13.006 | ppl 8223.37 | wps 48184 | wpb 510.9 | bsz 1 | num_updates 46997 | best_loss 8.937
2022-03-08 00:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 966 @ 46997 updates
2022-03-08 00:33:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:33:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:33:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 966 @ 46997 updates, score 13.571) (writing took 2.2979838820174336 seconds)
2022-03-08 00:33:31 | INFO | fairseq_cli.train | end of epoch 966 (average epoch stats below)
2022-03-08 00:33:31 | INFO | train | epoch 966 | loss 2.003 | nll_loss 0.263 | ppl 1.2 | wps 25359.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 46997 | lr 0.00014587 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127856
2022-03-08 00:33:31 | INFO | fairseq.trainer | begin training epoch 967
2022-03-08 00:33:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:33:38 | INFO | train_inner | epoch 967:      3 / 49 loss=2.003, nll_loss=0.263, ppl=1.2, wps=24464.2, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47000, lr=0.000145865, gnorm=0.337, loss_scale=32, train_wall=220, gb_free=8.8, wall=127863
2022-03-08 00:35:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:35:34 | INFO | valid | epoch 967 | valid on 'valid' subset | loss 13.575 | nll_loss 13.009 | ppl 8243.99 | wps 47704.5 | wpb 510.9 | bsz 1 | num_updates 47046 | best_loss 8.937
2022-03-08 00:35:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 967 @ 47046 updates
2022-03-08 00:35:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:35:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 967 @ 47046 updates, score 13.575) (writing took 2.3499577692709863 seconds)
2022-03-08 00:35:36 | INFO | fairseq_cli.train | end of epoch 967 (average epoch stats below)
2022-03-08 00:35:36 | INFO | train | epoch 967 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25324.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47046 | lr 0.000145794 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 127981
2022-03-08 00:35:36 | INFO | fairseq.trainer | begin training epoch 968
2022-03-08 00:35:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:36:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:37:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:37:39 | INFO | valid | epoch 968 | valid on 'valid' subset | loss 13.553 | nll_loss 12.986 | ppl 8115.31 | wps 48287 | wpb 510.9 | bsz 1 | num_updates 47094 | best_loss 8.937
2022-03-08 00:37:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 968 @ 47094 updates
2022-03-08 00:37:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:37:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:37:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 968 @ 47094 updates, score 13.553) (writing took 2.265395130030811 seconds)
2022-03-08 00:37:41 | INFO | fairseq_cli.train | end of epoch 968 (average epoch stats below)
2022-03-08 00:37:41 | INFO | train | epoch 968 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 24863.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47094 | lr 0.000145719 | gnorm 0.341 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 128106
2022-03-08 00:37:41 | INFO | fairseq.trainer | begin training epoch 969
2022-03-08 00:37:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:37:56 | INFO | train_inner | epoch 969:      6 / 49 loss=2.002, nll_loss=0.262, ppl=1.2, wps=25146.9, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=47100, lr=0.00014571, gnorm=0.338, loss_scale=32, train_wall=220, gb_free=8.8, wall=128121
2022-03-08 00:39:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:39:45 | INFO | valid | epoch 969 | valid on 'valid' subset | loss 13.538 | nll_loss 12.974 | ppl 8047.34 | wps 46036.4 | wpb 510.9 | bsz 1 | num_updates 47143 | best_loss 8.937
2022-03-08 00:39:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 969 @ 47143 updates
2022-03-08 00:39:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:39:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:39:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 969 @ 47143 updates, score 13.538) (writing took 2.467908435035497 seconds)
2022-03-08 00:39:48 | INFO | fairseq_cli.train | end of epoch 969 (average epoch stats below)
2022-03-08 00:39:48 | INFO | train | epoch 969 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25185.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47143 | lr 0.000145644 | gnorm 0.333 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128232
2022-03-08 00:39:48 | INFO | fairseq.trainer | begin training epoch 970
2022-03-08 00:39:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:41:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:41:51 | INFO | valid | epoch 970 | valid on 'valid' subset | loss 13.589 | nll_loss 13.025 | ppl 8333.7 | wps 48076.2 | wpb 510.9 | bsz 1 | num_updates 47192 | best_loss 8.937
2022-03-08 00:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 970 @ 47192 updates
2022-03-08 00:41:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:41:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:41:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 970 @ 47192 updates, score 13.589) (writing took 2.325333360116929 seconds)
2022-03-08 00:41:53 | INFO | fairseq_cli.train | end of epoch 970 (average epoch stats below)
2022-03-08 00:41:53 | INFO | train | epoch 970 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25356.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47192 | lr 0.000145568 | gnorm 0.334 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128358
2022-03-08 00:41:53 | INFO | fairseq.trainer | begin training epoch 971
2022-03-08 00:41:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:42:13 | INFO | train_inner | epoch 971:      8 / 49 loss=2.002, nll_loss=0.262, ppl=1.2, wps=25297.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=47200, lr=0.000145556, gnorm=0.333, loss_scale=32, train_wall=218, gb_free=8.8, wall=128377
2022-03-08 00:42:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:43:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:43:57 | INFO | valid | epoch 971 | valid on 'valid' subset | loss 13.54 | nll_loss 12.97 | ppl 8026.17 | wps 44514.8 | wpb 510.9 | bsz 1 | num_updates 47240 | best_loss 8.937
2022-03-08 00:43:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 971 @ 47240 updates
2022-03-08 00:43:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:43:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:43:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 971 @ 47240 updates, score 13.54) (writing took 2.3470750488340855 seconds)
2022-03-08 00:43:59 | INFO | fairseq_cli.train | end of epoch 971 (average epoch stats below)
2022-03-08 00:43:59 | INFO | train | epoch 971 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 24616.9 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47240 | lr 0.000145494 | gnorm 0.335 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128484
2022-03-08 00:43:59 | INFO | fairseq.trainer | begin training epoch 972
2022-03-08 00:43:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:45:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:46:04 | INFO | valid | epoch 972 | valid on 'valid' subset | loss 13.546 | nll_loss 12.98 | ppl 8076.83 | wps 48312.9 | wpb 510.9 | bsz 1 | num_updates 47289 | best_loss 8.937
2022-03-08 00:46:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 972 @ 47289 updates
2022-03-08 00:46:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:46:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:46:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 972 @ 47289 updates, score 13.546) (writing took 2.278001152444631 seconds)
2022-03-08 00:46:06 | INFO | fairseq_cli.train | end of epoch 972 (average epoch stats below)
2022-03-08 00:46:06 | INFO | train | epoch 972 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25082.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47289 | lr 0.000145419 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128611
2022-03-08 00:46:06 | INFO | fairseq.trainer | begin training epoch 973
2022-03-08 00:46:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:46:33 | INFO | train_inner | epoch 973:     11 / 49 loss=2.002, nll_loss=0.262, ppl=1.2, wps=24897.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=47300, lr=0.000145402, gnorm=0.336, loss_scale=32, train_wall=222, gb_free=8.8, wall=128638
2022-03-08 00:48:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:48:09 | INFO | valid | epoch 973 | valid on 'valid' subset | loss 13.629 | nll_loss 13.067 | ppl 8579.48 | wps 45422.4 | wpb 510.9 | bsz 1 | num_updates 47338 | best_loss 8.937
2022-03-08 00:48:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 973 @ 47338 updates
2022-03-08 00:48:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:48:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:48:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 973 @ 47338 updates, score 13.629) (writing took 2.4500570418313146 seconds)
2022-03-08 00:48:12 | INFO | fairseq_cli.train | end of epoch 973 (average epoch stats below)
2022-03-08 00:48:12 | INFO | train | epoch 973 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25276.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47338 | lr 0.000145343 | gnorm 0.34 | loss_scale 64 | train_wall 107 | gb_free 8.8 | wall 128737
2022-03-08 00:48:12 | INFO | fairseq.trainer | begin training epoch 974
2022-03-08 00:48:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:48:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:50:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:50:16 | INFO | valid | epoch 974 | valid on 'valid' subset | loss 13.653 | nll_loss 13.093 | ppl 8736.42 | wps 47747.6 | wpb 510.9 | bsz 1 | num_updates 47386 | best_loss 8.937
2022-03-08 00:50:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 974 @ 47386 updates
2022-03-08 00:50:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:50:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 974 @ 47386 updates, score 13.653) (writing took 2.365798839367926 seconds)
2022-03-08 00:50:19 | INFO | fairseq_cli.train | end of epoch 974 (average epoch stats below)
2022-03-08 00:50:19 | INFO | train | epoch 974 | loss 2.003 | nll_loss 0.262 | ppl 1.2 | wps 24521.5 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 47386 | lr 0.00014527 | gnorm 0.34 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 128864
2022-03-08 00:50:19 | INFO | fairseq.trainer | begin training epoch 975
2022-03-08 00:50:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:50:53 | INFO | train_inner | epoch 975:     14 / 49 loss=2.002, nll_loss=0.262, ppl=1.2, wps=24969, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=47400, lr=0.000145248, gnorm=0.34, loss_scale=32, train_wall=221, gb_free=8.8, wall=128898
2022-03-08 00:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:52:23 | INFO | valid | epoch 975 | valid on 'valid' subset | loss 13.53 | nll_loss 12.961 | ppl 7971 | wps 47112.1 | wpb 510.9 | bsz 1 | num_updates 47435 | best_loss 8.937
2022-03-08 00:52:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 975 @ 47435 updates
2022-03-08 00:52:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:52:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:52:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 975 @ 47435 updates, score 13.53) (writing took 2.320754867978394 seconds)
2022-03-08 00:52:25 | INFO | fairseq_cli.train | end of epoch 975 (average epoch stats below)
2022-03-08 00:52:25 | INFO | train | epoch 975 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25200 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47435 | lr 0.000145195 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 128990
2022-03-08 00:52:25 | INFO | fairseq.trainer | begin training epoch 976
2022-03-08 00:52:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:53:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 00:54:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:54:28 | INFO | valid | epoch 976 | valid on 'valid' subset | loss 13.537 | nll_loss 12.973 | ppl 8037.48 | wps 47602.5 | wpb 510.9 | bsz 1 | num_updates 47483 | best_loss 8.937
2022-03-08 00:54:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 976 @ 47483 updates
2022-03-08 00:54:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:54:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 976 @ 47483 updates, score 13.537) (writing took 2.2753700162284076 seconds)
2022-03-08 00:54:31 | INFO | fairseq_cli.train | end of epoch 976 (average epoch stats below)
2022-03-08 00:54:31 | INFO | train | epoch 976 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 24736.9 | ups 0.38 | wpb 64853.3 | bsz 126.7 | num_updates 47483 | lr 0.000145121 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129116
2022-03-08 00:54:31 | INFO | fairseq.trainer | begin training epoch 977
2022-03-08 00:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:55:12 | INFO | train_inner | epoch 977:     17 / 49 loss=2.002, nll_loss=0.262, ppl=1.2, wps=25013.3, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=47500, lr=0.000145095, gnorm=0.34, loss_scale=32, train_wall=221, gb_free=8.8, wall=129157
2022-03-08 00:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:56:34 | INFO | valid | epoch 977 | valid on 'valid' subset | loss 13.553 | nll_loss 12.987 | ppl 8116.62 | wps 45662.1 | wpb 510.9 | bsz 1 | num_updates 47532 | best_loss 8.937
2022-03-08 00:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 977 @ 47532 updates
2022-03-08 00:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:56:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:56:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 977 @ 47532 updates, score 13.553) (writing took 2.3420110386796296 seconds)
2022-03-08 00:56:36 | INFO | fairseq_cli.train | end of epoch 977 (average epoch stats below)
2022-03-08 00:56:36 | INFO | train | epoch 977 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25315.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47532 | lr 0.000145046 | gnorm 0.342 | loss_scale 32 | train_wall 106 | gb_free 8.8 | wall 129241
2022-03-08 00:56:36 | INFO | fairseq.trainer | begin training epoch 978
2022-03-08 00:56:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:58:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 00:58:39 | INFO | valid | epoch 978 | valid on 'valid' subset | loss 13.554 | nll_loss 12.985 | ppl 8104.63 | wps 47917.7 | wpb 510.9 | bsz 1 | num_updates 47581 | best_loss 8.937
2022-03-08 00:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 978 @ 47581 updates
2022-03-08 00:58:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:58:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 00:58:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 978 @ 47581 updates, score 13.554) (writing took 2.3701800289563835 seconds)
2022-03-08 00:58:42 | INFO | fairseq_cli.train | end of epoch 978 (average epoch stats below)
2022-03-08 00:58:42 | INFO | train | epoch 978 | loss 2.002 | nll_loss 0.262 | ppl 1.2 | wps 25313.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47581 | lr 0.000144972 | gnorm 0.338 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129367
2022-03-08 00:58:42 | INFO | fairseq.trainer | begin training epoch 979
2022-03-08 00:58:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 00:59:28 | INFO | train_inner | epoch 979:     19 / 49 loss=2.002, nll_loss=0.262, ppl=1.2, wps=25351.1, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=47600, lr=0.000144943, gnorm=0.339, loss_scale=64, train_wall=218, gb_free=8.8, wall=129413
2022-03-08 00:59:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:00:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:00:45 | INFO | valid | epoch 979 | valid on 'valid' subset | loss 13.552 | nll_loss 12.983 | ppl 8097.63 | wps 48112.5 | wpb 510.9 | bsz 1 | num_updates 47629 | best_loss 8.937
2022-03-08 01:00:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 979 @ 47629 updates
2022-03-08 01:00:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:00:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:00:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 979 @ 47629 updates, score 13.552) (writing took 2.260286681354046 seconds)
2022-03-08 01:00:47 | INFO | fairseq_cli.train | end of epoch 979 (average epoch stats below)
2022-03-08 01:00:47 | INFO | train | epoch 979 | loss 2.001 | nll_loss 0.262 | ppl 1.2 | wps 24819.2 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47629 | lr 0.000144899 | gnorm 0.339 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129492
2022-03-08 01:00:47 | INFO | fairseq.trainer | begin training epoch 980
2022-03-08 01:00:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:02:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:02:50 | INFO | valid | epoch 980 | valid on 'valid' subset | loss 13.574 | nll_loss 13.01 | ppl 8247.65 | wps 48291.3 | wpb 510.9 | bsz 1 | num_updates 47678 | best_loss 8.937
2022-03-08 01:02:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 980 @ 47678 updates
2022-03-08 01:02:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:02:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:02:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 980 @ 47678 updates, score 13.574) (writing took 2.290666650980711 seconds)
2022-03-08 01:02:53 | INFO | fairseq_cli.train | end of epoch 980 (average epoch stats below)
2022-03-08 01:02:53 | INFO | train | epoch 980 | loss 2.001 | nll_loss 0.262 | ppl 1.2 | wps 25345.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47678 | lr 0.000144824 | gnorm 0.337 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129617
2022-03-08 01:02:53 | INFO | fairseq.trainer | begin training epoch 981
2022-03-08 01:02:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:03:46 | INFO | train_inner | epoch 981:     22 / 49 loss=2.001, nll_loss=0.261, ppl=1.2, wps=25118.1, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=47700, lr=0.000144791, gnorm=0.335, loss_scale=32, train_wall=220, gb_free=8.8, wall=129671
2022-03-08 01:04:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:04:56 | INFO | valid | epoch 981 | valid on 'valid' subset | loss 13.696 | nll_loss 13.143 | ppl 9042.65 | wps 46478.4 | wpb 510.9 | bsz 1 | num_updates 47727 | best_loss 8.937
2022-03-08 01:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 981 @ 47727 updates
2022-03-08 01:04:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:04:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:04:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 981 @ 47727 updates, score 13.696) (writing took 2.3474431121721864 seconds)
2022-03-08 01:04:58 | INFO | fairseq_cli.train | end of epoch 981 (average epoch stats below)
2022-03-08 01:04:58 | INFO | train | epoch 981 | loss 2.001 | nll_loss 0.261 | ppl 1.2 | wps 25291 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47727 | lr 0.00014475 | gnorm 0.332 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129743
2022-03-08 01:04:58 | INFO | fairseq.trainer | begin training epoch 982
2022-03-08 01:04:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:06:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:07:02 | INFO | valid | epoch 982 | valid on 'valid' subset | loss 13.625 | nll_loss 13.067 | ppl 8583.94 | wps 48260.1 | wpb 510.9 | bsz 1 | num_updates 47775 | best_loss 8.937
2022-03-08 01:07:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 982 @ 47775 updates
2022-03-08 01:07:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:07:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:07:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 982 @ 47775 updates, score 13.625) (writing took 2.350256246048957 seconds)
2022-03-08 01:07:04 | INFO | fairseq_cli.train | end of epoch 982 (average epoch stats below)
2022-03-08 01:07:04 | INFO | train | epoch 982 | loss 2.001 | nll_loss 0.261 | ppl 1.2 | wps 24772.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47775 | lr 0.000144677 | gnorm 0.333 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129869
2022-03-08 01:07:04 | INFO | fairseq.trainer | begin training epoch 983
2022-03-08 01:07:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:08:05 | INFO | train_inner | epoch 983:     25 / 49 loss=2.001, nll_loss=0.261, ppl=1.2, wps=25094.6, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=47800, lr=0.000144639, gnorm=0.332, loss_scale=32, train_wall=220, gb_free=8.8, wall=129930
2022-03-08 01:09:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:09:07 | INFO | valid | epoch 983 | valid on 'valid' subset | loss 13.642 | nll_loss 13.084 | ppl 8684.45 | wps 48174.6 | wpb 510.9 | bsz 1 | num_updates 47824 | best_loss 8.937
2022-03-08 01:09:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 983 @ 47824 updates
2022-03-08 01:09:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:09:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 983 @ 47824 updates, score 13.642) (writing took 2.257087705191225 seconds)
2022-03-08 01:09:09 | INFO | fairseq_cli.train | end of epoch 983 (average epoch stats below)
2022-03-08 01:09:09 | INFO | train | epoch 983 | loss 2.001 | nll_loss 0.261 | ppl 1.2 | wps 25365.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47824 | lr 0.000144603 | gnorm 0.336 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 129994
2022-03-08 01:09:09 | INFO | fairseq.trainer | begin training epoch 984
2022-03-08 01:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:11:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:11:13 | INFO | valid | epoch 984 | valid on 'valid' subset | loss 13.582 | nll_loss 13.017 | ppl 8290.28 | wps 48231.6 | wpb 510.9 | bsz 1 | num_updates 47873 | best_loss 8.937
2022-03-08 01:11:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 984 @ 47873 updates
2022-03-08 01:11:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:11:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:11:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 984 @ 47873 updates, score 13.582) (writing took 2.2749689538031816 seconds)
2022-03-08 01:11:15 | INFO | fairseq_cli.train | end of epoch 984 (average epoch stats below)
2022-03-08 01:11:15 | INFO | train | epoch 984 | loss 2.001 | nll_loss 0.261 | ppl 1.2 | wps 25308.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47873 | lr 0.000144529 | gnorm 0.335 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 130120
2022-03-08 01:11:15 | INFO | fairseq.trainer | begin training epoch 985
2022-03-08 01:11:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:12:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:12:23 | INFO | train_inner | epoch 985:     28 / 49 loss=2.001, nll_loss=0.261, ppl=1.2, wps=25106.4, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=47900, lr=0.000144488, gnorm=0.337, loss_scale=32, train_wall=220, gb_free=8.8, wall=130188
2022-03-08 01:13:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:13:18 | INFO | valid | epoch 985 | valid on 'valid' subset | loss 13.613 | nll_loss 13.053 | ppl 8499.79 | wps 46572 | wpb 510.9 | bsz 1 | num_updates 47921 | best_loss 8.937
2022-03-08 01:13:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 985 @ 47921 updates
2022-03-08 01:13:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:13:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 985 @ 47921 updates, score 13.613) (writing took 2.29498501541093 seconds)
2022-03-08 01:13:20 | INFO | fairseq_cli.train | end of epoch 985 (average epoch stats below)
2022-03-08 01:13:20 | INFO | train | epoch 985 | loss 2.001 | nll_loss 0.261 | ppl 1.2 | wps 24780.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 47921 | lr 0.000144456 | gnorm 0.334 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 130245
2022-03-08 01:13:20 | INFO | fairseq.trainer | begin training epoch 986
2022-03-08 01:13:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:15:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:15:24 | INFO | valid | epoch 986 | valid on 'valid' subset | loss 13.621 | nll_loss 13.06 | ppl 8540.23 | wps 46644.2 | wpb 510.9 | bsz 1 | num_updates 47970 | best_loss 8.937
2022-03-08 01:15:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 986 @ 47970 updates
2022-03-08 01:15:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:15:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:15:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 986 @ 47970 updates, score 13.621) (writing took 2.400120321661234 seconds)
2022-03-08 01:15:27 | INFO | fairseq_cli.train | end of epoch 986 (average epoch stats below)
2022-03-08 01:15:27 | INFO | train | epoch 986 | loss 2 | nll_loss 0.261 | ppl 1.2 | wps 25182 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 47970 | lr 0.000144383 | gnorm 0.333 | loss_scale 32 | train_wall 107 | gb_free 8.8 | wall 130371
2022-03-08 01:15:27 | INFO | fairseq.trainer | begin training epoch 987
2022-03-08 01:15:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:16:41 | INFO | train_inner | epoch 987:     30 / 49 loss=2, nll_loss=0.261, ppl=1.2, wps=25195, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48000, lr=0.000144338, gnorm=0.335, loss_scale=32, train_wall=219, gb_free=8.8, wall=130446
2022-03-08 01:17:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:17:31 | INFO | valid | epoch 987 | valid on 'valid' subset | loss 13.564 | nll_loss 12.999 | ppl 8183.54 | wps 46137.2 | wpb 510.9 | bsz 1 | num_updates 48019 | best_loss 8.937
2022-03-08 01:17:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 987 @ 48019 updates
2022-03-08 01:17:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:17:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:17:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 987 @ 48019 updates, score 13.564) (writing took 2.3187727769836783 seconds)
2022-03-08 01:17:34 | INFO | fairseq_cli.train | end of epoch 987 (average epoch stats below)
2022-03-08 01:17:34 | INFO | train | epoch 987 | loss 2 | nll_loss 0.26 | ppl 1.2 | wps 24990.9 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48019 | lr 0.000144309 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 130499
2022-03-08 01:17:34 | INFO | fairseq.trainer | begin training epoch 988
2022-03-08 01:17:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:19:39 | INFO | valid | epoch 988 | valid on 'valid' subset | loss 13.544 | nll_loss 12.977 | ppl 8059.85 | wps 46724.7 | wpb 510.9 | bsz 1 | num_updates 48068 | best_loss 8.937
2022-03-08 01:19:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 988 @ 48068 updates
2022-03-08 01:19:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:19:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:19:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 988 @ 48068 updates, score 13.544) (writing took 2.2469373107887805 seconds)
2022-03-08 01:19:41 | INFO | fairseq_cli.train | end of epoch 988 (average epoch stats below)
2022-03-08 01:19:41 | INFO | train | epoch 988 | loss 2 | nll_loss 0.261 | ppl 1.2 | wps 24985 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48068 | lr 0.000144235 | gnorm 0.335 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 130626
2022-03-08 01:19:41 | INFO | fairseq.trainer | begin training epoch 989
2022-03-08 01:19:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:19:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:21:03 | INFO | train_inner | epoch 989:     33 / 49 loss=2, nll_loss=0.26, ppl=1.2, wps=24766.4, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=48100, lr=0.000144187, gnorm=0.335, loss_scale=32, train_wall=223, gb_free=8.8, wall=130708
2022-03-08 01:21:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:21:46 | INFO | valid | epoch 989 | valid on 'valid' subset | loss 13.644 | nll_loss 13.088 | ppl 8706.1 | wps 46497.2 | wpb 510.9 | bsz 1 | num_updates 48116 | best_loss 8.937
2022-03-08 01:21:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 989 @ 48116 updates
2022-03-08 01:21:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:21:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:21:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 989 @ 48116 updates, score 13.644) (writing took 2.288732938002795 seconds)
2022-03-08 01:21:48 | INFO | fairseq_cli.train | end of epoch 989 (average epoch stats below)
2022-03-08 01:21:48 | INFO | train | epoch 989 | loss 2 | nll_loss 0.26 | ppl 1.2 | wps 24483.1 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48116 | lr 0.000144163 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 130753
2022-03-08 01:21:48 | INFO | fairseq.trainer | begin training epoch 990
2022-03-08 01:21:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:23:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:23:53 | INFO | valid | epoch 990 | valid on 'valid' subset | loss 13.55 | nll_loss 12.984 | ppl 8100.61 | wps 46524.2 | wpb 510.9 | bsz 1 | num_updates 48165 | best_loss 8.937
2022-03-08 01:23:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 990 @ 48165 updates
2022-03-08 01:23:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:23:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:23:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 990 @ 48165 updates, score 13.55) (writing took 2.3878852101042867 seconds)
2022-03-08 01:23:56 | INFO | fairseq_cli.train | end of epoch 990 (average epoch stats below)
2022-03-08 01:23:56 | INFO | train | epoch 990 | loss 2 | nll_loss 0.261 | ppl 1.2 | wps 24947.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48165 | lr 0.00014409 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 130880
2022-03-08 01:23:56 | INFO | fairseq.trainer | begin training epoch 991
2022-03-08 01:23:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:25:22 | INFO | train_inner | epoch 991:     35 / 49 loss=2, nll_loss=0.261, ppl=1.2, wps=24994.7, ups=0.39, wpb=64867.4, bsz=126.7, num_updates=48200, lr=0.000144038, gnorm=0.332, loss_scale=64, train_wall=221, gb_free=8.8, wall=130967
2022-03-08 01:25:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:25:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:26:00 | INFO | valid | epoch 991 | valid on 'valid' subset | loss 13.556 | nll_loss 12.991 | ppl 8143.77 | wps 47185.4 | wpb 510.9 | bsz 1 | num_updates 48213 | best_loss 8.937
2022-03-08 01:26:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 991 @ 48213 updates
2022-03-08 01:26:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:26:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:26:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 991 @ 48213 updates, score 13.556) (writing took 2.2959808837622404 seconds)
2022-03-08 01:26:03 | INFO | fairseq_cli.train | end of epoch 991 (average epoch stats below)
2022-03-08 01:26:03 | INFO | train | epoch 991 | loss 2 | nll_loss 0.26 | ppl 1.2 | wps 24468.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48213 | lr 0.000144018 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131007
2022-03-08 01:26:03 | INFO | fairseq.trainer | begin training epoch 992
2022-03-08 01:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:28:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:28:07 | INFO | valid | epoch 992 | valid on 'valid' subset | loss 13.537 | nll_loss 12.971 | ppl 8026.26 | wps 47449.9 | wpb 510.9 | bsz 1 | num_updates 48262 | best_loss 8.937
2022-03-08 01:28:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 992 @ 48262 updates
2022-03-08 01:28:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:28:09 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:28:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 992 @ 48262 updates, score 13.537) (writing took 2.2396137551404536 seconds)
2022-03-08 01:28:09 | INFO | fairseq_cli.train | end of epoch 992 (average epoch stats below)
2022-03-08 01:28:09 | INFO | train | epoch 992 | loss 2 | nll_loss 0.26 | ppl 1.2 | wps 25066.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48262 | lr 0.000143945 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131134
2022-03-08 01:28:10 | INFO | fairseq.trainer | begin training epoch 993
2022-03-08 01:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:29:43 | INFO | train_inner | epoch 993:     38 / 49 loss=2, nll_loss=0.261, ppl=1.2, wps=24844.8, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=48300, lr=0.000143889, gnorm=0.334, loss_scale=32, train_wall=222, gb_free=8.8, wall=131228
2022-03-08 01:30:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:30:14 | INFO | valid | epoch 993 | valid on 'valid' subset | loss 13.545 | nll_loss 12.976 | ppl 8056.61 | wps 46370 | wpb 510.9 | bsz 1 | num_updates 48311 | best_loss 8.937
2022-03-08 01:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 993 @ 48311 updates
2022-03-08 01:30:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 993 @ 48311 updates, score 13.545) (writing took 2.3166901930235326 seconds)
2022-03-08 01:30:16 | INFO | fairseq_cli.train | end of epoch 993 (average epoch stats below)
2022-03-08 01:30:16 | INFO | train | epoch 993 | loss 2 | nll_loss 0.261 | ppl 1.2 | wps 25029.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48311 | lr 0.000143872 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131261
2022-03-08 01:30:16 | INFO | fairseq.trainer | begin training epoch 994
2022-03-08 01:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:31:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:32:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:32:22 | INFO | valid | epoch 994 | valid on 'valid' subset | loss 13.485 | nll_loss 12.913 | ppl 7712.49 | wps 46324.8 | wpb 510.9 | bsz 1 | num_updates 48359 | best_loss 8.937
2022-03-08 01:32:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 994 @ 48359 updates
2022-03-08 01:32:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:32:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 994 @ 48359 updates, score 13.485) (writing took 2.4503944823518395 seconds)
2022-03-08 01:32:24 | INFO | fairseq_cli.train | end of epoch 994 (average epoch stats below)
2022-03-08 01:32:24 | INFO | train | epoch 994 | loss 2 | nll_loss 0.26 | ppl 1.2 | wps 24406.5 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48359 | lr 0.000143801 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131389
2022-03-08 01:32:24 | INFO | fairseq.trainer | begin training epoch 995
2022-03-08 01:32:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:34:06 | INFO | train_inner | epoch 995:     41 / 49 loss=2, nll_loss=0.261, ppl=1.2, wps=24747.6, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48400, lr=0.00014374, gnorm=0.334, loss_scale=32, train_wall=223, gb_free=8.8, wall=131490
2022-03-08 01:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:34:29 | INFO | valid | epoch 995 | valid on 'valid' subset | loss 13.557 | nll_loss 12.993 | ppl 8152.22 | wps 46364.1 | wpb 510.9 | bsz 1 | num_updates 48408 | best_loss 8.937
2022-03-08 01:34:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 995 @ 48408 updates
2022-03-08 01:34:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 995 @ 48408 updates, score 13.557) (writing took 2.3455819417722523 seconds)
2022-03-08 01:34:31 | INFO | fairseq_cli.train | end of epoch 995 (average epoch stats below)
2022-03-08 01:34:31 | INFO | train | epoch 995 | loss 2 | nll_loss 0.261 | ppl 1.2 | wps 24969.6 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48408 | lr 0.000143728 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131516
2022-03-08 01:34:31 | INFO | fairseq.trainer | begin training epoch 996
2022-03-08 01:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:36:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:36:36 | INFO | valid | epoch 996 | valid on 'valid' subset | loss 13.551 | nll_loss 12.989 | ppl 8127.65 | wps 46866.6 | wpb 510.9 | bsz 1 | num_updates 48457 | best_loss 8.937
2022-03-08 01:36:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 996 @ 48457 updates
2022-03-08 01:36:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:36:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:36:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 996 @ 48457 updates, score 13.551) (writing took 2.3079985370859504 seconds)
2022-03-08 01:36:38 | INFO | fairseq_cli.train | end of epoch 996 (average epoch stats below)
2022-03-08 01:36:38 | INFO | train | epoch 996 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 25020.4 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48457 | lr 0.000143655 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131643
2022-03-08 01:36:38 | INFO | fairseq.trainer | begin training epoch 997
2022-03-08 01:36:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:37:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:38:27 | INFO | train_inner | epoch 997:     44 / 49 loss=1.999, nll_loss=0.26, ppl=1.2, wps=24803.1, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=48500, lr=0.000143592, gnorm=0.331, loss_scale=32, train_wall=223, gb_free=8.8, wall=131752
2022-03-08 01:38:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:38:43 | INFO | valid | epoch 997 | valid on 'valid' subset | loss 13.521 | nll_loss 12.955 | ppl 7941.38 | wps 46990.4 | wpb 510.9 | bsz 1 | num_updates 48505 | best_loss 8.937
2022-03-08 01:38:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 997 @ 48505 updates
2022-03-08 01:38:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:38:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:38:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 997 @ 48505 updates, score 13.521) (writing took 2.3100480032153428 seconds)
2022-03-08 01:38:45 | INFO | fairseq_cli.train | end of epoch 997 (average epoch stats below)
2022-03-08 01:38:45 | INFO | train | epoch 997 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 24516.7 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48505 | lr 0.000143584 | gnorm 0.33 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131770
2022-03-08 01:38:45 | INFO | fairseq.trainer | begin training epoch 998
2022-03-08 01:38:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:40:50 | INFO | valid | epoch 998 | valid on 'valid' subset | loss 13.648 | nll_loss 13.086 | ppl 8697.18 | wps 46359.8 | wpb 510.9 | bsz 1 | num_updates 48554 | best_loss 8.937
2022-03-08 01:40:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 998 @ 48554 updates
2022-03-08 01:40:50 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:40:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:40:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 998 @ 48554 updates, score 13.648) (writing took 2.3875037720426917 seconds)
2022-03-08 01:40:53 | INFO | fairseq_cli.train | end of epoch 998 (average epoch stats below)
2022-03-08 01:40:53 | INFO | train | epoch 998 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 24955 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48554 | lr 0.000143512 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 131897
2022-03-08 01:40:53 | INFO | fairseq.trainer | begin training epoch 999
2022-03-08 01:40:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:42:46 | INFO | train_inner | epoch 999:     46 / 49 loss=1.999, nll_loss=0.26, ppl=1.2, wps=25023.6, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48600, lr=0.000143444, gnorm=0.335, loss_scale=32, train_wall=221, gb_free=8.8, wall=132011
2022-03-08 01:42:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:42:57 | INFO | valid | epoch 999 | valid on 'valid' subset | loss 13.563 | nll_loss 12.992 | ppl 8146.91 | wps 46738.9 | wpb 510.9 | bsz 1 | num_updates 48603 | best_loss 8.937
2022-03-08 01:42:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 999 @ 48603 updates
2022-03-08 01:42:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:43:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:43:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 999 @ 48603 updates, score 13.563) (writing took 2.3233850789256394 seconds)
2022-03-08 01:43:00 | INFO | fairseq_cli.train | end of epoch 999 (average epoch stats below)
2022-03-08 01:43:00 | INFO | train | epoch 999 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 25024.6 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48603 | lr 0.000143439 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 132024
2022-03-08 01:43:00 | INFO | fairseq.trainer | begin training epoch 1000
2022-03-08 01:43:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:45:04 | INFO | valid | epoch 1000 | valid on 'valid' subset | loss 13.537 | nll_loss 12.97 | ppl 8024.47 | wps 46762.8 | wpb 510.9 | bsz 1 | num_updates 48652 | best_loss 8.937
2022-03-08 01:45:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1000 @ 48652 updates
2022-03-08 01:45:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:45:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:45:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1000 @ 48652 updates, score 13.537) (writing took 2.221234835218638 seconds)
2022-03-08 01:45:06 | INFO | fairseq_cli.train | end of epoch 1000 (average epoch stats below)
2022-03-08 01:45:06 | INFO | train | epoch 1000 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 25050.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48652 | lr 0.000143367 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 132151
2022-03-08 01:45:06 | INFO | fairseq.trainer | begin training epoch 1001
2022-03-08 01:45:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:05 | INFO | train_inner | epoch 1001:     48 / 49 loss=1.999, nll_loss=0.26, ppl=1.2, wps=25044.7, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=48700, lr=0.000143296, gnorm=0.332, loss_scale=64, train_wall=220, gb_free=8.8, wall=132270
2022-03-08 01:47:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:47:11 | INFO | valid | epoch 1001 | valid on 'valid' subset | loss 13.577 | nll_loss 13.011 | ppl 8253.86 | wps 46643 | wpb 510.9 | bsz 1 | num_updates 48701 | best_loss 8.937
2022-03-08 01:47:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1001 @ 48701 updates
2022-03-08 01:47:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:47:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1001 @ 48701 updates, score 13.577) (writing took 2.27495100395754 seconds)
2022-03-08 01:47:14 | INFO | fairseq_cli.train | end of epoch 1001 (average epoch stats below)
2022-03-08 01:47:14 | INFO | train | epoch 1001 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 24987 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48701 | lr 0.000143295 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 132278
2022-03-08 01:47:14 | INFO | fairseq.trainer | begin training epoch 1002
2022-03-08 01:47:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:47:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:49:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:49:19 | INFO | valid | epoch 1002 | valid on 'valid' subset | loss 13.656 | nll_loss 13.099 | ppl 8776.84 | wps 45447.5 | wpb 510.9 | bsz 1 | num_updates 48749 | best_loss 8.937
2022-03-08 01:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1002 @ 48749 updates
2022-03-08 01:49:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1002 @ 48749 updates, score 13.656) (writing took 2.376635469030589 seconds)
2022-03-08 01:49:21 | INFO | fairseq_cli.train | end of epoch 1002 (average epoch stats below)
2022-03-08 01:49:21 | INFO | train | epoch 1002 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 24349.6 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48749 | lr 0.000143224 | gnorm 0.337 | loss_scale 32 | train_wall 109 | gb_free 8.8 | wall 132406
2022-03-08 01:49:21 | INFO | fairseq.trainer | begin training epoch 1003
2022-03-08 01:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:51:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:51:26 | INFO | valid | epoch 1003 | valid on 'valid' subset | loss 13.664 | nll_loss 13.105 | ppl 8810.91 | wps 46574.1 | wpb 510.9 | bsz 1 | num_updates 48798 | best_loss 8.937
2022-03-08 01:51:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1003 @ 48798 updates
2022-03-08 01:51:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:51:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:51:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1003 @ 48798 updates, score 13.664) (writing took 2.3132362626492977 seconds)
2022-03-08 01:51:29 | INFO | fairseq_cli.train | end of epoch 1003 (average epoch stats below)
2022-03-08 01:51:29 | INFO | train | epoch 1003 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 24988.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48798 | lr 0.000143153 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 132533
2022-03-08 01:51:29 | INFO | fairseq.trainer | begin training epoch 1004
2022-03-08 01:51:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:51:34 | INFO | train_inner | epoch 1004:      2 / 49 loss=1.999, nll_loss=0.26, ppl=1.2, wps=24056.3, ups=0.37, wpb=64544.1, bsz=126.1, num_updates=48800, lr=0.00014315, gnorm=0.337, loss_scale=32, train_wall=222, gb_free=8.8, wall=132538
2022-03-08 01:53:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:53:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:53:33 | INFO | valid | epoch 1004 | valid on 'valid' subset | loss 13.576 | nll_loss 13.013 | ppl 8267.69 | wps 46970 | wpb 510.9 | bsz 1 | num_updates 48846 | best_loss 8.937
2022-03-08 01:53:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1004 @ 48846 updates
2022-03-08 01:53:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:53:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:53:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1004 @ 48846 updates, score 13.576) (writing took 2.2962453570216894 seconds)
2022-03-08 01:53:36 | INFO | fairseq_cli.train | end of epoch 1004 (average epoch stats below)
2022-03-08 01:53:36 | INFO | train | epoch 1004 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24489.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48846 | lr 0.000143082 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 132661
2022-03-08 01:53:36 | INFO | fairseq.trainer | begin training epoch 1005
2022-03-08 01:53:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:55:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:55:41 | INFO | valid | epoch 1005 | valid on 'valid' subset | loss 13.581 | nll_loss 13.018 | ppl 8297.06 | wps 46956.2 | wpb 510.9 | bsz 1 | num_updates 48895 | best_loss 8.937
2022-03-08 01:55:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1005 @ 48895 updates
2022-03-08 01:55:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:55:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:55:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1005 @ 48895 updates, score 13.581) (writing took 2.3688862808048725 seconds)
2022-03-08 01:55:43 | INFO | fairseq_cli.train | end of epoch 1005 (average epoch stats below)
2022-03-08 01:55:43 | INFO | train | epoch 1005 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 25000.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 48895 | lr 0.00014301 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 132788
2022-03-08 01:55:43 | INFO | fairseq.trainer | begin training epoch 1006
2022-03-08 01:55:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:55:55 | INFO | train_inner | epoch 1006:      5 / 49 loss=1.998, nll_loss=0.259, ppl=1.2, wps=24781.9, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=48900, lr=0.000143003, gnorm=0.332, loss_scale=32, train_wall=223, gb_free=8.8, wall=132800
2022-03-08 01:57:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:57:48 | INFO | valid | epoch 1006 | valid on 'valid' subset | loss 13.517 | nll_loss 12.949 | ppl 7905.81 | wps 46247.8 | wpb 510.9 | bsz 1 | num_updates 48944 | best_loss 8.937
2022-03-08 01:57:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1006 @ 48944 updates
2022-03-08 01:57:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:57:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:57:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1006 @ 48944 updates, score 13.517) (writing took 2.3869240609928966 seconds)
2022-03-08 01:57:50 | INFO | fairseq_cli.train | end of epoch 1006 (average epoch stats below)
2022-03-08 01:57:50 | INFO | train | epoch 1006 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24920.4 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 48944 | lr 0.000142939 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 132915
2022-03-08 01:57:50 | INFO | fairseq.trainer | begin training epoch 1007
2022-03-08 01:57:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 01:59:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 01:59:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 01:59:55 | INFO | valid | epoch 1007 | valid on 'valid' subset | loss 13.572 | nll_loss 13.005 | ppl 8222.71 | wps 46533 | wpb 510.9 | bsz 1 | num_updates 48992 | best_loss 8.937
2022-03-08 01:59:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1007 @ 48992 updates
2022-03-08 01:59:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:59:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 01:59:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1007 @ 48992 updates, score 13.572) (writing took 2.3065719790756702 seconds)
2022-03-08 01:59:58 | INFO | fairseq_cli.train | end of epoch 1007 (average epoch stats below)
2022-03-08 01:59:58 | INFO | train | epoch 1007 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 24441.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 48992 | lr 0.000142869 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133042
2022-03-08 01:59:58 | INFO | fairseq.trainer | begin training epoch 1008
2022-03-08 01:59:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:00:17 | INFO | train_inner | epoch 1008:      8 / 49 loss=1.998, nll_loss=0.259, ppl=1.2, wps=24764.7, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49000, lr=0.000142857, gnorm=0.333, loss_scale=32, train_wall=223, gb_free=8.8, wall=133062
2022-03-08 02:01:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:02:02 | INFO | valid | epoch 1008 | valid on 'valid' subset | loss 13.637 | nll_loss 13.079 | ppl 8650.85 | wps 46113.7 | wpb 510.9 | bsz 1 | num_updates 49041 | best_loss 8.937
2022-03-08 02:02:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1008 @ 49041 updates
2022-03-08 02:02:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:02:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:02:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1008 @ 49041 updates, score 13.637) (writing took 2.268102797213942 seconds)
2022-03-08 02:02:05 | INFO | fairseq_cli.train | end of epoch 1008 (average epoch stats below)
2022-03-08 02:02:05 | INFO | train | epoch 1008 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 25053.3 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49041 | lr 0.000142797 | gnorm 0.335 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133169
2022-03-08 02:02:05 | INFO | fairseq.trainer | begin training epoch 1009
2022-03-08 02:02:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:04:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:04:09 | INFO | valid | epoch 1009 | valid on 'valid' subset | loss 13.522 | nll_loss 12.951 | ppl 7920.95 | wps 47165.8 | wpb 510.9 | bsz 1 | num_updates 49090 | best_loss 8.937
2022-03-08 02:04:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1009 @ 49090 updates
2022-03-08 02:04:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:04:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:04:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1009 @ 49090 updates, score 13.522) (writing took 2.2901230482384562 seconds)
2022-03-08 02:04:12 | INFO | fairseq_cli.train | end of epoch 1009 (average epoch stats below)
2022-03-08 02:04:12 | INFO | train | epoch 1009 | loss 1.999 | nll_loss 0.26 | ppl 1.2 | wps 25016.7 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49090 | lr 0.000142726 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133296
2022-03-08 02:04:12 | INFO | fairseq.trainer | begin training epoch 1010
2022-03-08 02:04:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:04:37 | INFO | train_inner | epoch 1010:     10 / 49 loss=1.998, nll_loss=0.26, ppl=1.2, wps=25029.8, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=49100, lr=0.000142712, gnorm=0.333, loss_scale=32, train_wall=221, gb_free=8.8, wall=133321
2022-03-08 02:06:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:06:17 | INFO | valid | epoch 1010 | valid on 'valid' subset | loss 13.561 | nll_loss 12.995 | ppl 8163.79 | wps 46203.2 | wpb 510.9 | bsz 1 | num_updates 49139 | best_loss 8.937
2022-03-08 02:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1010 @ 49139 updates
2022-03-08 02:06:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:06:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:06:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1010 @ 49139 updates, score 13.561) (writing took 2.4219628339633346 seconds)
2022-03-08 02:06:19 | INFO | fairseq_cli.train | end of epoch 1010 (average epoch stats below)
2022-03-08 02:06:19 | INFO | train | epoch 1010 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24949.1 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49139 | lr 0.000142655 | gnorm 0.333 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 133424
2022-03-08 02:06:19 | INFO | fairseq.trainer | begin training epoch 1011
2022-03-08 02:06:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:07:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:08:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:08:24 | INFO | valid | epoch 1011 | valid on 'valid' subset | loss 13.493 | nll_loss 12.924 | ppl 7769.72 | wps 46439.7 | wpb 510.9 | bsz 1 | num_updates 49187 | best_loss 8.937
2022-03-08 02:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1011 @ 49187 updates
2022-03-08 02:08:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:08:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:08:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1011 @ 49187 updates, score 13.493) (writing took 2.291403466835618 seconds)
2022-03-08 02:08:26 | INFO | fairseq_cli.train | end of epoch 1011 (average epoch stats below)
2022-03-08 02:08:26 | INFO | train | epoch 1011 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24485.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49187 | lr 0.000142585 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133551
2022-03-08 02:08:26 | INFO | fairseq.trainer | begin training epoch 1012
2022-03-08 02:08:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:08:58 | INFO | train_inner | epoch 1012:     13 / 49 loss=1.998, nll_loss=0.259, ppl=1.2, wps=24784.8, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49200, lr=0.000142566, gnorm=0.334, loss_scale=32, train_wall=223, gb_free=8.8, wall=133583
2022-03-08 02:10:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:10:31 | INFO | valid | epoch 1012 | valid on 'valid' subset | loss 13.605 | nll_loss 13.047 | ppl 8461.51 | wps 45897.6 | wpb 510.9 | bsz 1 | num_updates 49236 | best_loss 8.937
2022-03-08 02:10:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1012 @ 49236 updates
2022-03-08 02:10:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:10:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1012 @ 49236 updates, score 13.605) (writing took 2.2614555512554944 seconds)
2022-03-08 02:10:33 | INFO | fairseq_cli.train | end of epoch 1012 (average epoch stats below)
2022-03-08 02:10:33 | INFO | train | epoch 1012 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24997.2 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49236 | lr 0.000142514 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133678
2022-03-08 02:10:33 | INFO | fairseq.trainer | begin training epoch 1013
2022-03-08 02:10:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:12:38 | INFO | valid | epoch 1013 | valid on 'valid' subset | loss 13.603 | nll_loss 13.041 | ppl 8428.37 | wps 47046.6 | wpb 510.9 | bsz 1 | num_updates 49285 | best_loss 8.937
2022-03-08 02:12:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1013 @ 49285 updates
2022-03-08 02:12:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:12:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:12:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1013 @ 49285 updates, score 13.603) (writing took 2.3002474419772625 seconds)
2022-03-08 02:12:41 | INFO | fairseq_cli.train | end of epoch 1013 (average epoch stats below)
2022-03-08 02:12:41 | INFO | train | epoch 1013 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24980.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49285 | lr 0.000142443 | gnorm 0.333 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 133805
2022-03-08 02:12:41 | INFO | fairseq.trainer | begin training epoch 1014
2022-03-08 02:12:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:13:18 | INFO | train_inner | epoch 1014:     15 / 49 loss=1.998, nll_loss=0.259, ppl=1.2, wps=25003.5, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49300, lr=0.000142422, gnorm=0.333, loss_scale=32, train_wall=221, gb_free=8.8, wall=133843
2022-03-08 02:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:14:46 | INFO | valid | epoch 1014 | valid on 'valid' subset | loss 13.547 | nll_loss 12.982 | ppl 8089.89 | wps 45731.4 | wpb 510.9 | bsz 1 | num_updates 49334 | best_loss 8.937
2022-03-08 02:14:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1014 @ 49334 updates
2022-03-08 02:14:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:14:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1014 @ 49334 updates, score 13.547) (writing took 2.3765665628015995 seconds)
2022-03-08 02:14:48 | INFO | fairseq_cli.train | end of epoch 1014 (average epoch stats below)
2022-03-08 02:14:48 | INFO | train | epoch 1014 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24941.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49334 | lr 0.000142373 | gnorm 0.333 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 133933
2022-03-08 02:14:48 | INFO | fairseq.trainer | begin training epoch 1015
2022-03-08 02:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:16:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:16:53 | INFO | valid | epoch 1015 | valid on 'valid' subset | loss 13.618 | nll_loss 13.054 | ppl 8501.86 | wps 46556.1 | wpb 510.9 | bsz 1 | num_updates 49383 | best_loss 8.937
2022-03-08 02:16:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1015 @ 49383 updates
2022-03-08 02:16:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:16:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:16:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1015 @ 49383 updates, score 13.618) (writing took 2.303805814124644 seconds)
2022-03-08 02:16:55 | INFO | fairseq_cli.train | end of epoch 1015 (average epoch stats below)
2022-03-08 02:16:55 | INFO | train | epoch 1015 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24946.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49383 | lr 0.000142302 | gnorm 0.331 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 134060
2022-03-08 02:16:55 | INFO | fairseq.trainer | begin training epoch 1016
2022-03-08 02:16:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:17:37 | INFO | train_inner | epoch 1016:     17 / 49 loss=1.998, nll_loss=0.259, ppl=1.2, wps=24994, ups=0.39, wpb=64876.2, bsz=126.7, num_updates=49400, lr=0.000142278, gnorm=0.333, loss_scale=64, train_wall=221, gb_free=8.8, wall=134102
2022-03-08 02:17:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:19:00 | INFO | valid | epoch 1016 | valid on 'valid' subset | loss 13.548 | nll_loss 12.983 | ppl 8096.36 | wps 46162.1 | wpb 510.9 | bsz 1 | num_updates 49431 | best_loss 8.937
2022-03-08 02:19:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1016 @ 49431 updates
2022-03-08 02:19:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:19:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:19:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1016 @ 49431 updates, score 13.548) (writing took 2.2960900138132274 seconds)
2022-03-08 02:19:02 | INFO | fairseq_cli.train | end of epoch 1016 (average epoch stats below)
2022-03-08 02:19:02 | INFO | train | epoch 1016 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24472.8 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49431 | lr 0.000142233 | gnorm 0.337 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134187
2022-03-08 02:19:03 | INFO | fairseq.trainer | begin training epoch 1017
2022-03-08 02:19:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:21:07 | INFO | valid | epoch 1017 | valid on 'valid' subset | loss 13.565 | nll_loss 12.999 | ppl 8186.53 | wps 46993 | wpb 510.9 | bsz 1 | num_updates 49480 | best_loss 8.937
2022-03-08 02:21:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1017 @ 49480 updates
2022-03-08 02:21:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:21:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:21:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1017 @ 49480 updates, score 13.565) (writing took 2.3169894330203533 seconds)
2022-03-08 02:21:10 | INFO | fairseq_cli.train | end of epoch 1017 (average epoch stats below)
2022-03-08 02:21:10 | INFO | train | epoch 1017 | loss 1.998 | nll_loss 0.259 | ppl 1.2 | wps 24975.8 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49480 | lr 0.000142163 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134314
2022-03-08 02:21:10 | INFO | fairseq.trainer | begin training epoch 1018
2022-03-08 02:21:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:21:59 | INFO | train_inner | epoch 1018:     20 / 49 loss=1.998, nll_loss=0.259, ppl=1.2, wps=24755.5, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49500, lr=0.000142134, gnorm=0.335, loss_scale=32, train_wall=223, gb_free=8.8, wall=134364
2022-03-08 02:23:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:23:15 | INFO | valid | epoch 1018 | valid on 'valid' subset | loss 13.616 | nll_loss 13.057 | ppl 8524.19 | wps 46141 | wpb 510.9 | bsz 1 | num_updates 49529 | best_loss 8.937
2022-03-08 02:23:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1018 @ 49529 updates
2022-03-08 02:23:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:23:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:23:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1018 @ 49529 updates, score 13.616) (writing took 2.3985391068272293 seconds)
2022-03-08 02:23:17 | INFO | fairseq_cli.train | end of epoch 1018 (average epoch stats below)
2022-03-08 02:23:17 | INFO | train | epoch 1018 | loss 1.997 | nll_loss 0.259 | ppl 1.2 | wps 24930.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49529 | lr 0.000142092 | gnorm 0.334 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 134442
2022-03-08 02:23:17 | INFO | fairseq.trainer | begin training epoch 1019
2022-03-08 02:23:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:23:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:25:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:25:22 | INFO | valid | epoch 1019 | valid on 'valid' subset | loss 13.658 | nll_loss 13.104 | ppl 8801.69 | wps 46327 | wpb 510.9 | bsz 1 | num_updates 49577 | best_loss 8.937
2022-03-08 02:25:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1019 @ 49577 updates
2022-03-08 02:25:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:25:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1019 @ 49577 updates, score 13.658) (writing took 2.356944592203945 seconds)
2022-03-08 02:25:24 | INFO | fairseq_cli.train | end of epoch 1019 (average epoch stats below)
2022-03-08 02:25:24 | INFO | train | epoch 1019 | loss 1.997 | nll_loss 0.258 | ppl 1.2 | wps 24504.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49577 | lr 0.000142023 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134569
2022-03-08 02:25:24 | INFO | fairseq.trainer | begin training epoch 1020
2022-03-08 02:25:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:26:21 | INFO | train_inner | epoch 1020:     23 / 49 loss=1.997, nll_loss=0.258, ppl=1.2, wps=24783, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=49600, lr=0.00014199, gnorm=0.333, loss_scale=32, train_wall=223, gb_free=8.8, wall=134626
2022-03-08 02:27:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:27:29 | INFO | valid | epoch 1020 | valid on 'valid' subset | loss 13.656 | nll_loss 13.1 | ppl 8777.12 | wps 45146.5 | wpb 510.9 | bsz 1 | num_updates 49626 | best_loss 8.937
2022-03-08 02:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1020 @ 49626 updates
2022-03-08 02:27:29 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:27:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1020 @ 49626 updates, score 13.656) (writing took 2.250464358832687 seconds)
2022-03-08 02:27:32 | INFO | fairseq_cli.train | end of epoch 1020 (average epoch stats below)
2022-03-08 02:27:32 | INFO | train | epoch 1020 | loss 1.997 | nll_loss 0.258 | ppl 1.2 | wps 24961.7 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49626 | lr 0.000141953 | gnorm 0.336 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134696
2022-03-08 02:27:32 | INFO | fairseq.trainer | begin training epoch 1021
2022-03-08 02:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:29:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:29:36 | INFO | valid | epoch 1021 | valid on 'valid' subset | loss 13.638 | nll_loss 13.073 | ppl 8619.25 | wps 46459.2 | wpb 510.9 | bsz 1 | num_updates 49674 | best_loss 8.937
2022-03-08 02:29:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1021 @ 49674 updates
2022-03-08 02:29:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:29:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:29:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1021 @ 49674 updates, score 13.638) (writing took 2.2822310579940677 seconds)
2022-03-08 02:29:38 | INFO | fairseq_cli.train | end of epoch 1021 (average epoch stats below)
2022-03-08 02:29:38 | INFO | train | epoch 1021 | loss 1.997 | nll_loss 0.259 | ppl 1.2 | wps 24531.4 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49674 | lr 0.000141885 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134823
2022-03-08 02:29:38 | INFO | fairseq.trainer | begin training epoch 1022
2022-03-08 02:29:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:30:43 | INFO | train_inner | epoch 1022:     26 / 49 loss=1.997, nll_loss=0.259, ppl=1.2, wps=24772.3, ups=0.38, wpb=64867.4, bsz=126.7, num_updates=49700, lr=0.000141848, gnorm=0.333, loss_scale=32, train_wall=223, gb_free=8.8, wall=134888
2022-03-08 02:31:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:31:44 | INFO | valid | epoch 1022 | valid on 'valid' subset | loss 13.647 | nll_loss 13.088 | ppl 8707.63 | wps 45272 | wpb 510.9 | bsz 1 | num_updates 49723 | best_loss 8.937
2022-03-08 02:31:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1022 @ 49723 updates
2022-03-08 02:31:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:31:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:31:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1022 @ 49723 updates, score 13.647) (writing took 2.412296023685485 seconds)
2022-03-08 02:31:46 | INFO | fairseq_cli.train | end of epoch 1022 (average epoch stats below)
2022-03-08 02:31:46 | INFO | train | epoch 1022 | loss 1.997 | nll_loss 0.259 | ppl 1.2 | wps 24918.5 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49723 | lr 0.000141815 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 134951
2022-03-08 02:31:46 | INFO | fairseq.trainer | begin training epoch 1023
2022-03-08 02:31:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:33:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:33:51 | INFO | valid | epoch 1023 | valid on 'valid' subset | loss 13.579 | nll_loss 13.012 | ppl 8260.29 | wps 46764 | wpb 510.9 | bsz 1 | num_updates 49772 | best_loss 8.937
2022-03-08 02:33:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1023 @ 49772 updates
2022-03-08 02:33:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:33:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:33:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1023 @ 49772 updates, score 13.579) (writing took 2.344062875956297 seconds)
2022-03-08 02:33:53 | INFO | fairseq_cli.train | end of epoch 1023 (average epoch stats below)
2022-03-08 02:33:53 | INFO | train | epoch 1023 | loss 1.996 | nll_loss 0.258 | ppl 1.2 | wps 25005.5 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49772 | lr 0.000141745 | gnorm 0.331 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135078
2022-03-08 02:33:53 | INFO | fairseq.trainer | begin training epoch 1024
2022-03-08 02:33:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:35:02 | INFO | train_inner | epoch 1024:     28 / 49 loss=1.997, nll_loss=0.258, ppl=1.2, wps=25005, ups=0.39, wpb=64871.8, bsz=126.7, num_updates=49800, lr=0.000141705, gnorm=0.332, loss_scale=64, train_wall=221, gb_free=8.8, wall=135147
2022-03-08 02:35:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:35:58 | INFO | valid | epoch 1024 | valid on 'valid' subset | loss 13.575 | nll_loss 13.012 | ppl 8260.71 | wps 45722.3 | wpb 510.9 | bsz 1 | num_updates 49821 | best_loss 8.937
2022-03-08 02:35:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1024 @ 49821 updates
2022-03-08 02:35:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:36:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:36:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1024 @ 49821 updates, score 13.575) (writing took 2.2513719969429076 seconds)
2022-03-08 02:36:00 | INFO | fairseq_cli.train | end of epoch 1024 (average epoch stats below)
2022-03-08 02:36:00 | INFO | train | epoch 1024 | loss 1.996 | nll_loss 0.258 | ppl 1.2 | wps 24966.9 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49821 | lr 0.000141675 | gnorm 0.332 | loss_scale 64 | train_wall 108 | gb_free 8.8 | wall 135205
2022-03-08 02:36:00 | INFO | fairseq.trainer | begin training epoch 1025
2022-03-08 02:36:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:36:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:38:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:38:06 | INFO | valid | epoch 1025 | valid on 'valid' subset | loss 13.6 | nll_loss 13.039 | ppl 8417.02 | wps 46768 | wpb 510.9 | bsz 1 | num_updates 49869 | best_loss 8.937
2022-03-08 02:38:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1025 @ 49869 updates
2022-03-08 02:38:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:38:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:38:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1025 @ 49869 updates, score 13.6) (writing took 2.350180040113628 seconds)
2022-03-08 02:38:08 | INFO | fairseq_cli.train | end of epoch 1025 (average epoch stats below)
2022-03-08 02:38:08 | INFO | train | epoch 1025 | loss 1.996 | nll_loss 0.258 | ppl 1.2 | wps 24409 | ups 0.38 | wpb 64844.1 | bsz 126.7 | num_updates 49869 | lr 0.000141607 | gnorm 0.329 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135333
2022-03-08 02:38:08 | INFO | fairseq.trainer | begin training epoch 1026
2022-03-08 02:38:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:39:25 | INFO | train_inner | epoch 1026:     31 / 49 loss=1.996, nll_loss=0.258, ppl=1.2, wps=24710.9, ups=0.38, wpb=64871.8, bsz=126.7, num_updates=49900, lr=0.000141563, gnorm=0.33, loss_scale=32, train_wall=224, gb_free=8.8, wall=135410
2022-03-08 02:40:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:40:13 | INFO | valid | epoch 1026 | valid on 'valid' subset | loss 13.617 | nll_loss 13.059 | ppl 8531.32 | wps 44151.9 | wpb 510.9 | bsz 1 | num_updates 49918 | best_loss 8.937
2022-03-08 02:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1026 @ 49918 updates
2022-03-08 02:40:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:40:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:40:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1026 @ 49918 updates, score 13.617) (writing took 2.4508285969495773 seconds)
2022-03-08 02:40:16 | INFO | fairseq_cli.train | end of epoch 1026 (average epoch stats below)
2022-03-08 02:40:16 | INFO | train | epoch 1026 | loss 1.996 | nll_loss 0.258 | ppl 1.2 | wps 24853.8 | ups 0.38 | wpb 64858.2 | bsz 126.7 | num_updates 49918 | lr 0.000141537 | gnorm 0.332 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135460
2022-03-08 02:40:16 | INFO | fairseq.trainer | begin training epoch 1027
2022-03-08 02:40:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:42:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:42:21 | INFO | valid | epoch 1027 | valid on 'valid' subset | loss 13.629 | nll_loss 13.067 | ppl 8582.6 | wps 46688.9 | wpb 510.9 | bsz 1 | num_updates 49967 | best_loss 8.937
2022-03-08 02:42:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1027 @ 49967 updates
2022-03-08 02:42:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:42:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1027 @ 49967 updates, score 13.629) (writing took 2.3391310460865498 seconds)
2022-03-08 02:42:23 | INFO | fairseq_cli.train | end of epoch 1027 (average epoch stats below)
2022-03-08 02:42:23 | INFO | train | epoch 1027 | loss 1.997 | nll_loss 0.259 | ppl 1.2 | wps 24995.1 | ups 0.39 | wpb 64858.2 | bsz 126.7 | num_updates 49967 | lr 0.000141468 | gnorm 0.334 | loss_scale 32 | train_wall 108 | gb_free 8.8 | wall 135588
2022-03-08 02:42:23 | INFO | fairseq.trainer | begin training epoch 1028
2022-03-08 02:42:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-08 02:42:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-08 02:43:47 | INFO | train_inner | epoch 1028:     34 / 49 loss=1.997, nll_loss=0.258, ppl=1.2, wps=24732.7, ups=0.38, wpb=64876.2, bsz=126.7, num_updates=50000, lr=0.000141421, gnorm=0.334, loss_scale=32, train_wall=223, gb_free=8.8, wall=135672
2022-03-08 02:43:47 | INFO | fairseq_cli.train | Stopping training due to num_updates: 50000 >= max_update: 50000
2022-03-08 02:43:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-08 02:43:52 | INFO | valid | epoch 1028 | valid on 'valid' subset | loss 13.637 | nll_loss 13.079 | ppl 8650.1 | wps 46889.1 | wpb 510.9 | bsz 1 | num_updates 50000 | best_loss 8.937
2022-03-08 02:43:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1028 @ 50000 updates
2022-03-08 02:43:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:43:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt
2022-03-08 02:43:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/w103_size_0.03125_fp16-label_smoothing_0.08_#2/checkpoint_last.pt (epoch 1028 @ 50000 updates, score 13.637) (writing took 2.4089858001098037 seconds)
2022-03-08 02:43:54 | INFO | fairseq_cli.train | end of epoch 1028 (average epoch stats below)
2022-03-08 02:43:54 | INFO | train | epoch 1028 | loss 1.996 | nll_loss 0.258 | ppl 1.2 | wps 23627.2 | ups 0.36 | wpb 65536 | bsz 128 | num_updates 50000 | lr 0.000141421 | gnorm 0.33 | loss_scale 32 | train_wall 76 | gb_free 8.8 | wall 135679
2022-03-08 02:43:54 | INFO | fairseq_cli.train | done training in 135679.0 seconds
