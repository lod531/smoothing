Sender: LSF System <lsfadmin@eu-g3-065>
Subject: Job 210652973: <iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1> was submitted from host <eu-login-27> by user <andriusb> in cluster <euler> at Wed Mar 23 18:54:57 2022
Job was executed on host(s) <eu-g3-065>, in queue <gpuhe.24h>, as user <andriusb> in cluster <euler> at Wed Mar 23 18:55:08 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 18:55:08 2022
Terminated at Wed Mar 23 23:49:44 2022
Results reported at Wed Mar 23 23:49:44 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion kneser_ney_smoothing --kneser-d 0.32 --kneser-n 2 --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17654.62 sec.
    Max Memory :                                 4932 MB
    Average Memory :                             4306.78 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15068.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   17676 sec.
    Turnaround time :                            17687 sec.

The output (if any) follows:

2022-03-23 18:55:16 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='kneser_ney_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, kneser_d=0.32, kneser_n=2, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'kneser_ney_smoothing', 'kneser_d': 0.32, 'kneser_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 18:55:16 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 18:55:16 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 18:55:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:55:16 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:55:16 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1190/160239 [00:00<00:13, 11876.90it/s]  2%|▏         | 2569/160239 [00:00<00:12, 12991.93it/s]  2%|▏         | 3990/160239 [00:00<00:11, 13541.96it/s]  3%|▎         | 5345/160239 [00:00<00:11, 13257.40it/s]  4%|▍         | 6720/160239 [00:00<00:11, 13432.20it/s]  5%|▌         | 8065/160239 [00:00<00:11, 13021.00it/s]  6%|▌         | 9370/160239 [00:00<00:11, 12968.55it/s]  7%|▋         | 10754/160239 [00:00<00:11, 13239.67it/s]  8%|▊         | 12080/160239 [00:00<00:11, 13111.56it/s]  8%|▊         | 13398/160239 [00:01<00:11, 13126.57it/s]  9%|▉         | 14712/160239 [00:01<00:11, 13077.48it/s] 10%|▉         | 16021/160239 [00:01<00:11, 12936.74it/s] 11%|█         | 17316/160239 [00:01<00:11, 12609.79it/s] 12%|█▏        | 18599/160239 [00:01<00:11, 12671.10it/s] 13%|█▎        | 20034/160239 [00:01<00:10, 13163.45it/s] 13%|█▎        | 21353/160239 [00:01<00:10, 13068.30it/s] 14%|█▍        | 22662/160239 [00:01<00:10, 12858.16it/s] 15%|█▍        | 23950/160239 [00:01<00:10, 12849.01it/s] 16%|█▌        | 25236/160239 [00:01<00:10, 12837.24it/s] 17%|█▋        | 26521/160239 [00:02<00:10, 12719.34it/s] 17%|█▋        | 27856/160239 [00:02<00:10, 12905.39it/s] 18%|█▊        | 29171/160239 [00:02<00:10, 12976.16it/s] 19%|█▉        | 30470/160239 [00:02<00:10, 12687.08it/s] 20%|█▉        | 31883/160239 [00:02<00:09, 13108.52it/s] 21%|██        | 33196/160239 [00:02<00:09, 12812.99it/s] 22%|██▏       | 34480/160239 [00:02<00:09, 12735.87it/s] 22%|██▏       | 35756/160239 [00:02<00:09, 12513.47it/s] 23%|██▎       | 37068/160239 [00:02<00:09, 12688.79it/s] 24%|██▍       | 38380/160239 [00:02<00:09, 12815.18it/s] 25%|██▍       | 39663/160239 [00:03<00:09, 12731.27it/s] 26%|██▌       | 41024/160239 [00:03<00:09, 12988.65it/s] 26%|██▋       | 42324/160239 [00:03<00:09, 12675.11it/s] 27%|██▋       | 43594/160239 [00:03<00:09, 12596.30it/s] 28%|██▊       | 44856/160239 [00:03<00:09, 12438.38it/s] 29%|██▉       | 46233/160239 [00:03<00:08, 12824.16it/s] 30%|██▉       | 47582/160239 [00:03<00:08, 13018.39it/s] 31%|███       | 48886/160239 [00:03<00:08, 12819.98it/s] 31%|███▏      | 50171/160239 [00:03<00:08, 12827.92it/s] 32%|███▏      | 51534/160239 [00:03<00:08, 13062.14it/s] 33%|███▎      | 52850/160239 [00:04<00:08, 13089.71it/s] 34%|███▍      | 54160/160239 [00:04<00:08, 12954.29it/s] 35%|███▍      | 55457/160239 [00:04<00:08, 12821.26it/s] 35%|███▌      | 56751/160239 [00:04<00:08, 12851.53it/s] 36%|███▋      | 58136/160239 [00:04<00:07, 13144.19it/s] 37%|███▋      | 59467/160239 [00:04<00:07, 13193.24it/s] 38%|███▊      | 60787/160239 [00:04<00:07, 13153.19it/s] 39%|███▉      | 62103/160239 [00:04<00:07, 12977.91it/s] 40%|███▉      | 63484/160239 [00:04<00:07, 13220.59it/s] 41%|████      | 64967/160239 [00:05<00:06, 13697.15it/s] 41%|████▏     | 66338/160239 [00:05<00:06, 13678.11it/s] 42%|████▏     | 67707/160239 [00:05<00:06, 13223.24it/s] 43%|████▎     | 69033/160239 [00:05<00:07, 12951.06it/s] 44%|████▍     | 70378/160239 [00:05<00:06, 13095.04it/s] 45%|████▍     | 71691/160239 [00:05<00:06, 13040.77it/s] 46%|████▌     | 72997/160239 [00:05<00:06, 12868.77it/s] 46%|████▋     | 74286/160239 [00:05<00:06, 12835.83it/s] 47%|████▋     | 75571/160239 [00:05<00:06, 12761.40it/s] 48%|████▊     | 76908/160239 [00:05<00:06, 12937.74it/s] 49%|████▉     | 78292/160239 [00:06<00:06, 13203.19it/s] 50%|████▉     | 79640/160239 [00:06<00:06, 13285.31it/s] 51%|█████     | 81085/160239 [00:06<00:05, 13629.88it/s] 51%|█████▏    | 82449/160239 [00:06<00:05, 13512.03it/s] 52%|█████▏    | 83801/160239 [00:06<00:05, 13410.87it/s] 53%|█████▎    | 85143/160239 [00:06<00:05, 13197.68it/s] 54%|█████▍    | 86601/160239 [00:06<00:05, 13600.30it/s] 55%|█████▍    | 87963/160239 [00:06<00:05, 13579.78it/s] 56%|█████▌    | 89322/160239 [00:06<00:05, 13445.23it/s] 57%|█████▋    | 90678/160239 [00:06<00:05, 13478.61it/s] 57%|█████▋    | 92027/160239 [00:07<00:05, 13212.57it/s] 58%|█████▊    | 93365/160239 [00:07<00:05, 13261.09it/s] 59%|█████▉    | 94693/160239 [00:07<00:05, 12979.73it/s] 60%|█████▉    | 96042/160239 [00:07<00:04, 13127.64it/s] 61%|██████    | 97357/160239 [00:07<00:04, 13080.09it/s] 62%|██████▏   | 98667/160239 [00:07<00:04, 12889.67it/s] 62%|██████▏   | 100040/160239 [00:07<00:04, 13135.35it/s] 63%|██████▎   | 101390/160239 [00:07<00:04, 13241.11it/s] 64%|██████▍   | 102716/160239 [00:07<00:04, 13062.20it/s] 65%|██████▍   | 104024/160239 [00:07<00:04, 12971.29it/s] 66%|██████▌   | 105422/160239 [00:08<00:04, 13266.70it/s] 67%|██████▋   | 106750/160239 [00:08<00:04, 13175.25it/s] 67%|██████▋   | 108069/160239 [00:08<00:04, 12797.65it/s] 68%|██████▊   | 109352/160239 [00:08<00:04, 12667.16it/s] 69%|██████▉   | 110669/160239 [00:08<00:03, 12811.38it/s] 70%|██████▉   | 112033/160239 [00:08<00:03, 13054.47it/s] 71%|███████   | 113341/160239 [00:08<00:03, 12990.92it/s] 72%|███████▏  | 114672/160239 [00:08<00:03, 13085.03it/s] 72%|███████▏  | 115982/160239 [00:08<00:03, 13085.01it/s] 73%|███████▎  | 117292/160239 [00:09<00:03, 12902.71it/s] 74%|███████▍  | 118621/160239 [00:09<00:03, 13011.56it/s] 75%|███████▍  | 119983/160239 [00:09<00:03, 13187.28it/s] 76%|███████▌  | 121303/160239 [00:09<00:02, 13182.85it/s] 77%|███████▋  | 122704/160239 [00:09<00:02, 13427.92it/s] 77%|███████▋  | 124048/160239 [00:09<00:02, 13282.54it/s] 78%|███████▊  | 125377/160239 [00:09<00:02, 12942.20it/s] 79%|███████▉  | 126708/160239 [00:09<00:02, 13047.45it/s] 80%|███████▉  | 128067/160239 [00:09<00:02, 13205.37it/s] 81%|████████  | 129390/160239 [00:09<00:02, 13116.34it/s] 82%|████████▏ | 130703/160239 [00:10<00:02, 12730.91it/s] 82%|████████▏ | 131992/160239 [00:10<00:02, 12775.06it/s] 83%|████████▎ | 133272/160239 [00:10<00:02, 12725.51it/s] 84%|████████▍ | 134546/160239 [00:10<00:02, 12639.29it/s] 85%|████████▍ | 135864/160239 [00:10<00:01, 12796.98it/s] 86%|████████▌ | 137203/160239 [00:10<00:01, 12968.13it/s] 86%|████████▋ | 138553/160239 [00:10<00:01, 13124.61it/s] 87%|████████▋ | 139917/160239 [00:10<00:01, 13271.48it/s] 88%|████████▊ | 141291/160239 [00:10<00:01, 13410.05it/s] 89%|████████▉ | 142633/160239 [00:10<00:01, 13044.12it/s] 90%|████████▉ | 143940/160239 [00:11<00:01, 13041.64it/s] 91%|█████████ | 145246/160239 [00:11<00:01, 13021.47it/s] 91%|█████████▏| 146550/160239 [00:11<00:01, 12792.39it/s] 92%|█████████▏| 147831/160239 [00:11<00:00, 12750.93it/s] 93%|█████████▎| 149108/160239 [00:11<00:00, 12469.76it/s] 94%|█████████▍| 150436/160239 [00:11<00:00, 12701.10it/s] 95%|█████████▍| 151763/160239 [00:11<00:00, 12867.50it/s] 96%|█████████▌| 153052/160239 [00:11<00:00, 12863.42it/s] 96%|█████████▋| 154367/160239 [00:11<00:00, 12947.46it/s] 97%|█████████▋| 155701/160239 [00:11<00:00, 13060.85it/s] 98%|█████████▊| 157041/160239 [00:12<00:00, 13158.02it/s] 99%|█████████▉| 158358/160239 [00:12<00:00, 12858.59it/s]100%|█████████▉| 159746/160239 [00:12<00:00, 13158.13it/s]100%|██████████| 160239/160239 [00:12<00:00, 13020.60it/s]
  0%|          | 0/6629 [00:00<?, ?it/s]  0%|          | 29/6629 [00:00<00:23, 286.17it/s]  1%|          | 59/6629 [00:00<00:22, 289.71it/s]  1%|▏         | 90/6629 [00:00<00:22, 294.40it/s]  2%|▏         | 120/6629 [00:00<00:22, 291.82it/s]  2%|▏         | 150/6629 [00:00<00:22, 287.39it/s]  3%|▎         | 179/6629 [00:00<00:22, 285.29it/s]  3%|▎         | 208/6629 [00:00<00:22, 283.00it/s]  4%|▎         | 237/6629 [00:00<00:22, 283.34it/s]  4%|▍         | 266/6629 [00:00<00:22, 280.32it/s]  4%|▍         | 295/6629 [00:01<00:22, 279.46it/s]  5%|▍         | 323/6629 [00:01<00:22, 278.18it/s]  5%|▌         | 351/6629 [00:01<00:22, 276.86it/s]  6%|▌         | 379/6629 [00:01<00:22, 276.46it/s]  6%|▌         | 408/6629 [00:01<00:22, 279.89it/s]  7%|▋         | 437/6629 [00:01<00:22, 281.26it/s]  7%|▋         | 466/6629 [00:01<00:22, 279.90it/s]  7%|▋         | 494/6629 [00:01<00:21, 278.88it/s]  8%|▊         | 522/6629 [00:01<00:21, 277.87it/s]  8%|▊         | 550/6629 [00:01<00:21, 277.52it/s]  9%|▊         | 578/6629 [00:02<00:21, 277.94it/s]  9%|▉         | 606/6629 [00:02<00:21, 277.27it/s] 10%|▉         | 634/6629 [00:02<00:21, 275.88it/s] 10%|▉         | 662/6629 [00:02<00:21, 275.12it/s] 10%|█         | 690/6629 [00:02<00:21, 275.86it/s] 11%|█         | 718/6629 [00:02<00:21, 276.27it/s] 11%|█▏        | 746/6629 [00:02<00:21, 276.12it/s] 12%|█▏        | 774/6629 [00:02<00:21, 276.06it/s] 12%|█▏        | 803/6629 [00:02<00:20, 277.99it/s] 13%|█▎        | 832/6629 [00:02<00:20, 279.53it/s] 13%|█▎        | 860/6629 [00:03<00:20, 278.94it/s] 13%|█▎        | 888/6629 [00:03<00:20, 278.74it/s] 14%|█▍        | 917/6629 [00:03<00:20, 280.60it/s] 14%|█▍        | 946/6629 [00:03<00:20, 280.67it/s] 15%|█▍        | 975/6629 [00:03<00:20, 279.53it/s] 15%|█▌        | 1003/6629 [00:03<00:20, 276.72it/s] 16%|█▌        | 1032/6629 [00:03<00:20, 278.83it/s] 16%|█▌        | 1062/6629 [00:03<00:19, 283.25it/s] 16%|█▋        | 1093/6629 [00:03<00:19, 288.69it/s] 17%|█▋        | 1123/6629 [00:03<00:18, 291.72it/s] 17%|█▋        | 1153/6629 [00:04<00:18, 292.81it/s] 18%|█▊        | 1183/6629 [00:04<00:18, 292.72it/s] 18%|█▊        | 1213/6629 [00:04<00:18, 293.68it/s] 19%|█▉        | 1243/6629 [00:04<00:18, 293.53it/s] 19%|█▉        | 1273/6629 [00:04<00:18, 294.81it/s] 20%|█▉        | 1303/6629 [00:04<00:18, 294.91it/s] 20%|██        | 1333/6629 [00:04<00:17, 295.45it/s] 21%|██        | 1363/6629 [00:04<00:17, 295.73it/s] 21%|██        | 1393/6629 [00:04<00:17, 295.53it/s] 21%|██▏       | 1423/6629 [00:05<00:17, 295.38it/s] 22%|██▏       | 1453/6629 [00:05<00:17, 295.76it/s] 22%|██▏       | 1483/6629 [00:05<00:17, 295.83it/s] 23%|██▎       | 1513/6629 [00:05<00:17, 296.90it/s] 23%|██▎       | 1543/6629 [00:05<00:17, 297.21it/s] 24%|██▎       | 1573/6629 [00:05<00:16, 297.45it/s] 24%|██▍       | 1603/6629 [00:05<00:16, 297.12it/s] 25%|██▍       | 1633/6629 [00:05<00:16, 296.92it/s] 25%|██▌       | 1663/6629 [00:05<00:16, 296.63it/s] 26%|██▌       | 1693/6629 [00:05<00:16, 296.64it/s] 26%|██▌       | 1723/6629 [00:06<00:16, 297.29it/s] 26%|██▋       | 1754/6629 [00:06<00:16, 299.76it/s] 27%|██▋       | 1785/6629 [00:06<00:16, 300.56it/s] 27%|██▋       | 1817/6629 [00:06<00:15, 304.72it/s] 28%|██▊       | 1848/6629 [00:06<00:15, 304.44it/s] 28%|██▊       | 1879/6629 [00:06<00:15, 302.05it/s] 29%|██▉       | 1910/6629 [00:06<00:15, 299.77it/s] 29%|██▉       | 1940/6629 [00:06<00:15, 299.01it/s] 30%|██▉       | 1970/6629 [00:06<00:15, 298.20it/s] 30%|███       | 2000/6629 [00:06<00:15, 295.26it/s] 31%|███       | 2030/6629 [00:07<00:15, 295.15it/s] 31%|███       | 2060/6629 [00:07<00:15, 293.92it/s] 32%|███▏      | 2090/6629 [00:07<00:15, 294.11it/s] 32%|███▏      | 2120/6629 [00:07<00:15, 294.61it/s] 32%|███▏      | 2150/6629 [00:07<00:15, 295.14it/s] 33%|███▎      | 2180/6629 [00:07<00:15, 296.24it/s] 33%|███▎      | 2210/6629 [00:07<00:14, 296.75it/s] 34%|███▍      | 2240/6629 [00:07<00:14, 296.14it/s] 34%|███▍      | 2270/6629 [00:07<00:14, 296.85it/s] 35%|███▍      | 2301/6629 [00:07<00:14, 297.89it/s] 35%|███▌      | 2332/6629 [00:08<00:14, 298.85it/s] 36%|███▌      | 2362/6629 [00:08<00:14, 298.45it/s] 36%|███▌      | 2392/6629 [00:08<00:14, 297.94it/s] 37%|███▋      | 2422/6629 [00:08<00:14, 297.65it/s] 37%|███▋      | 2452/6629 [00:08<00:14, 297.59it/s] 37%|███▋      | 2482/6629 [00:08<00:13, 297.28it/s] 38%|███▊      | 2512/6629 [00:08<00:13, 297.70it/s] 38%|███▊      | 2542/6629 [00:08<00:13, 297.02it/s] 39%|███▉      | 2572/6629 [00:08<00:13, 297.87it/s] 39%|███▉      | 2602/6629 [00:08<00:13, 297.74it/s] 40%|███▉      | 2633/6629 [00:09<00:13, 300.80it/s] 40%|████      | 2665/6629 [00:09<00:13, 304.18it/s] 41%|████      | 2697/6629 [00:09<00:12, 307.43it/s] 41%|████      | 2728/6629 [00:09<00:12, 306.48it/s] 42%|████▏     | 2759/6629 [00:09<00:12, 303.77it/s] 42%|████▏     | 2790/6629 [00:09<00:12, 301.79it/s] 43%|████▎     | 2821/6629 [00:09<00:12, 300.48it/s] 43%|████▎     | 2852/6629 [00:09<00:12, 298.81it/s] 43%|████▎     | 2882/6629 [00:09<00:12, 298.01it/s] 44%|████▍     | 2912/6629 [00:09<00:12, 296.35it/s] 44%|████▍     | 2942/6629 [00:10<00:12, 294.80it/s] 45%|████▍     | 2972/6629 [00:10<00:12, 295.45it/s] 45%|████▌     | 3003/6629 [00:10<00:12, 297.37it/s] 46%|████▌     | 3034/6629 [00:10<00:12, 298.37it/s] 46%|████▌     | 3065/6629 [00:10<00:11, 298.96it/s] 47%|████▋     | 3096/6629 [00:10<00:11, 299.49it/s] 47%|████▋     | 3126/6629 [00:10<00:11, 299.03it/s] 48%|████▊     | 3156/6629 [00:10<00:11, 298.53it/s] 48%|████▊     | 3186/6629 [00:10<00:11, 298.36it/s] 49%|████▊     | 3216/6629 [00:11<00:11, 298.73it/s] 49%|████▉     | 3246/6629 [00:11<00:11, 298.90it/s] 49%|████▉     | 3276/6629 [00:11<00:11, 298.54it/s] 50%|████▉     | 3306/6629 [00:11<00:11, 298.11it/s] 50%|█████     | 3337/6629 [00:11<00:10, 301.11it/s] 51%|█████     | 3368/6629 [00:11<00:10, 302.33it/s] 51%|█████▏    | 3399/6629 [00:11<00:10, 301.39it/s] 52%|█████▏    | 3430/6629 [00:11<00:10, 299.33it/s] 52%|█████▏    | 3462/6629 [00:11<00:10, 303.21it/s] 53%|█████▎    | 3493/6629 [00:11<00:10, 303.00it/s] 53%|█████▎    | 3524/6629 [00:12<00:10, 301.56it/s] 54%|█████▎    | 3555/6629 [00:12<00:10, 302.72it/s] 54%|█████▍    | 3586/6629 [00:12<00:10, 302.10it/s] 55%|█████▍    | 3617/6629 [00:12<00:10, 299.96it/s] 55%|█████▌    | 3648/6629 [00:12<00:09, 300.10it/s] 55%|█████▌    | 3679/6629 [00:12<00:09, 299.58it/s] 56%|█████▌    | 3709/6629 [00:12<00:09, 298.55it/s] 56%|█████▋    | 3739/6629 [00:12<00:09, 297.63it/s] 57%|█████▋    | 3769/6629 [00:12<00:09, 297.03it/s] 57%|█████▋    | 3799/6629 [00:12<00:09, 297.41it/s] 58%|█████▊    | 3829/6629 [00:13<00:09, 296.94it/s] 58%|█████▊    | 3859/6629 [00:13<00:09, 296.68it/s] 59%|█████▊    | 3890/6629 [00:13<00:09, 297.70it/s] 59%|█████▉    | 3920/6629 [00:13<00:09, 296.79it/s] 60%|█████▉    | 3950/6629 [00:13<00:09, 297.13it/s] 60%|██████    | 3980/6629 [00:13<00:08, 297.94it/s] 61%|██████    | 4011/6629 [00:13<00:08, 299.52it/s] 61%|██████    | 4042/6629 [00:13<00:08, 302.21it/s] 61%|██████▏   | 4073/6629 [00:13<00:08, 302.78it/s] 62%|██████▏   | 4104/6629 [00:13<00:08, 302.85it/s] 62%|██████▏   | 4135/6629 [00:14<00:08, 300.70it/s] 63%|██████▎   | 4166/6629 [00:14<00:08, 300.68it/s] 63%|██████▎   | 4197/6629 [00:14<00:08, 299.70it/s] 64%|██████▍   | 4227/6629 [00:14<00:08, 297.42it/s] 64%|██████▍   | 4257/6629 [00:14<00:07, 297.54it/s] 65%|██████▍   | 4287/6629 [00:14<00:07, 297.23it/s] 65%|██████▌   | 4318/6629 [00:14<00:07, 298.62it/s] 66%|██████▌   | 4348/6629 [00:14<00:07, 297.66it/s] 66%|██████▌   | 4378/6629 [00:14<00:07, 296.71it/s] 67%|██████▋   | 4409/6629 [00:15<00:07, 297.87it/s] 67%|██████▋   | 4440/6629 [00:15<00:07, 300.16it/s] 67%|██████▋   | 4471/6629 [00:15<00:07, 302.80it/s] 68%|██████▊   | 4502/6629 [00:15<00:07, 302.62it/s] 68%|██████▊   | 4533/6629 [00:15<00:06, 301.02it/s] 69%|██████▉   | 4564/6629 [00:15<00:06, 300.39it/s] 69%|██████▉   | 4595/6629 [00:15<00:06, 298.82it/s] 70%|██████▉   | 4626/6629 [00:15<00:06, 299.64it/s] 70%|███████   | 4656/6629 [00:15<00:06, 298.04it/s] 71%|███████   | 4687/6629 [00:15<00:06, 299.68it/s] 71%|███████   | 4718/6629 [00:16<00:06, 300.68it/s] 72%|███████▏  | 4749/6629 [00:16<00:06, 300.19it/s] 72%|███████▏  | 4780/6629 [00:16<00:06, 299.14it/s] 73%|███████▎  | 4810/6629 [00:16<00:06, 297.37it/s] 73%|███████▎  | 4840/6629 [00:16<00:06, 297.50it/s] 73%|███████▎  | 4870/6629 [00:16<00:05, 296.82it/s] 74%|███████▍  | 4901/6629 [00:16<00:05, 300.44it/s] 74%|███████▍  | 4932/6629 [00:16<00:05, 302.16it/s] 75%|███████▍  | 4963/6629 [00:16<00:05, 298.83it/s] 75%|███████▌  | 4994/6629 [00:16<00:05, 299.13it/s] 76%|███████▌  | 5024/6629 [00:17<00:05, 297.56it/s] 76%|███████▌  | 5054/6629 [00:17<00:05, 295.25it/s] 77%|███████▋  | 5084/6629 [00:17<00:05, 295.26it/s] 77%|███████▋  | 5114/6629 [00:17<00:05, 295.16it/s] 78%|███████▊  | 5144/6629 [00:17<00:05, 295.16it/s] 78%|███████▊  | 5174/6629 [00:17<00:04, 295.51it/s] 79%|███████▊  | 5204/6629 [00:17<00:04, 294.16it/s] 79%|███████▉  | 5235/6629 [00:17<00:04, 297.85it/s] 79%|███████▉  | 5266/6629 [00:17<00:04, 299.71it/s] 80%|███████▉  | 5296/6629 [00:17<00:04, 297.98it/s] 80%|████████  | 5327/6629 [00:18<00:04, 299.51it/s] 81%|████████  | 5357/6629 [00:18<00:04, 299.35it/s] 81%|████████▏ | 5388/6629 [00:18<00:04, 299.98it/s] 82%|████████▏ | 5418/6629 [00:18<00:04, 298.52it/s] 82%|████████▏ | 5448/6629 [00:18<00:03, 298.23it/s] 83%|████████▎ | 5478/6629 [00:18<00:03, 296.99it/s] 83%|████████▎ | 5508/6629 [00:18<00:03, 296.62it/s] 84%|████████▎ | 5538/6629 [00:18<00:03, 295.82it/s] 84%|████████▍ | 5568/6629 [00:18<00:03, 296.64it/s] 84%|████████▍ | 5598/6629 [00:18<00:03, 297.32it/s] 85%|████████▍ | 5628/6629 [00:19<00:03, 297.14it/s] 85%|████████▌ | 5658/6629 [00:19<00:03, 296.55it/s] 86%|████████▌ | 5689/6629 [00:19<00:03, 298.45it/s] 86%|████████▋ | 5720/6629 [00:19<00:03, 301.46it/s] 87%|████████▋ | 5751/6629 [00:19<00:02, 301.10it/s] 87%|████████▋ | 5782/6629 [00:19<00:02, 300.28it/s] 88%|████████▊ | 5813/6629 [00:19<00:02, 297.55it/s] 88%|████████▊ | 5844/6629 [00:19<00:02, 301.01it/s] 89%|████████▊ | 5875/6629 [00:19<00:02, 302.16it/s] 89%|████████▉ | 5906/6629 [00:20<00:02, 299.81it/s] 90%|████████▉ | 5936/6629 [00:20<00:02, 298.66it/s] 90%|████████▉ | 5966/6629 [00:20<00:02, 298.34it/s] 90%|█████████ | 5996/6629 [00:20<00:02, 298.59it/s] 91%|█████████ | 6026/6629 [00:20<00:02, 297.27it/s] 91%|█████████▏| 6056/6629 [00:20<00:01, 297.36it/s] 92%|█████████▏| 6086/6629 [00:20<00:01, 298.06it/s] 92%|█████████▏| 6117/6629 [00:20<00:01, 298.69it/s] 93%|█████████▎| 6147/6629 [00:20<00:01, 298.29it/s] 93%|█████████▎| 6178/6629 [00:20<00:01, 299.05it/s] 94%|█████████▎| 6208/6629 [00:21<00:01, 299.08it/s] 94%|█████████▍| 6238/6629 [00:21<00:01, 298.73it/s] 95%|█████████▍| 6269/6629 [00:21<00:01, 301.09it/s] 95%|█████████▌| 6300/6629 [00:21<00:01, 299.30it/s] 96%|█████████▌| 6331/6629 [00:21<00:00, 300.16it/s] 96%|█████████▌| 6362/6629 [00:21<00:00, 298.49it/s] 96%|█████████▋| 6392/6629 [00:21<00:00, 296.26it/s] 97%|█████████▋| 6422/6629 [00:21<00:00, 296.22it/s] 97%|█████████▋| 6452/6629 [00:21<00:00, 296.07it/s] 98%|█████████▊| 6482/6629 [00:21<00:00, 295.76it/s] 98%|█████████▊| 6512/6629 [00:22<00:00, 296.90it/s] 99%|█████████▊| 6543/6629 [00:22<00:00, 299.33it/s] 99%|█████████▉| 6575/6629 [00:22<00:00, 302.91it/s]100%|█████████▉| 6606/6629 [00:22<00:00, 301.45it/s]100%|██████████| 6629/6629 [00:22<00:00, 295.49it/s]AVERAGE DENSITY :0.0
2022-03-23 18:56:08 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 18:56:08 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 18:56:08 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 18:56:08 | INFO | fairseq_cli.train | criterion: KneserNeySmoothingCriterion
2022-03-23 18:56:08 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 18:56:08 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 18:56:08 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 18:56:08 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 18:56:08 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 18:56:08 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 18:56:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:56:08 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 18:56:08 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 18:56:08 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 18:56:08 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 18:56:08 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_last.pt
2022-03-23 18:56:08 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_last.pt
2022-03-23 18:56:08 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 18:56:08 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 18:56:08 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 18:56:08 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 18:56:09 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 18:56:09 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 18:56:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 18:56:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 18:56:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 18:56:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 19:00:58 | INFO | train_inner | epoch 001:    104 / 157 loss=11.411, ppl=2723.48, wps=9053.7, ups=0.36, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=3.605, loss_scale=8, train_wall=288, gb_free=13.5, wall=289
2022-03-23 19:01:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-23 19:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
/cluster/home/andriusb/fq/fairseq/fairseq/criterions/kneser_ney_smoothing.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  vals = torch.tensor(kl_stuff[hash("val")], device=torch.device("cuda"), dtype=torch.float16)
2022-03-23 19:03:25 | INFO | fairseq.tasks.translation | example hypothesis: .....
2022-03-23 19:03:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:03:30 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,.....
2022-03-23 19:03:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:03:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,
2022-03-23 19:03:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:03:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:03:47 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:03:55 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:03:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:04:02 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:04:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:04:10 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:04:10 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:04:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:04:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:04:21 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:04:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:04:21 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.669 | ppl 813.97 | bleu 0.01 | wps 2949.8 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-23 19:04:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-23 19:04:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:04:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:04:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.01) (writing took 0.7722084909910336 seconds)
2022-03-23 19:04:22 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 19:04:22 | INFO | train | epoch 001 | loss 10.957 | ppl 1988.39 | wps 7920 | ups 0.32 | wpb 25120.6 | bsz 980.6 | num_updates 152 | lr 1.9e-05 | gnorm 2.855 | loss_scale 4 | train_wall 431 | gb_free 22.4 | wall 493
2022-03-23 19:04:22 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 19:04:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:06:37 | INFO | train_inner | epoch 002:     48 / 157 loss=9.791, ppl=886.05, wps=7489.5, ups=0.29, wpb=25437.5, bsz=1087.6, num_updates=200, lr=2.5e-05, gnorm=1.42, loss_scale=4, train_wall=278, gb_free=13.7, wall=629
2022-03-23 19:11:09 | INFO | train_inner | epoch 002:    148 / 157 loss=9.078, ppl=540.55, wps=9176.5, ups=0.37, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.527, loss_scale=4, train_wall=272, gb_free=20, wall=901
2022-03-23 19:11:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:11:37 | INFO | fairseq.tasks.translation | example hypothesis: we we we we we we.
2022-03-23 19:11:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:11:42 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:11:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:11:49 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:11:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:11:56 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:11:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:12:03 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:12:03 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:12:11 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:12:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:12:18 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:12:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:12:26 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:12:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:12:35 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "" "" "" ""
2022-03-23 19:12:35 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:12:37 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 19:12:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:12:37 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.675 | ppl 408.67 | bleu 0.01 | wps 2683.5 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.01
2022-03-23 19:12:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-23 19:12:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:12:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.01) (writing took 0.759867303975625 seconds)
2022-03-23 19:12:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 19:12:38 | INFO | train | epoch 002 | loss 9.187 | ppl 582.81 | wps 7951.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 1.486 | loss_scale 4 | train_wall 429 | gb_free 13.5 | wall 990
2022-03-23 19:12:39 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 19:12:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:16:47 | INFO | train_inner | epoch 003:     91 / 157 loss=8.713, ppl=419.76, wps=7345.1, ups=0.3, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=1.439, loss_scale=4, train_wall=270, gb_free=12.9, wall=1239
2022-03-23 19:19:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:19:53 | INFO | fairseq.tasks.translation | example hypothesis: we the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:19:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:19:59 | INFO | fairseq.tasks.translation | example hypothesis: is is the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:19:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:20:05 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 19:20:05 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:20:12 | INFO | fairseq.tasks.translation | example hypothesis: it's's a, and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and it
2022-03-23 19:20:12 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:20:19 | INFO | fairseq.tasks.translation | example hypothesis: we we that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that.
2022-03-23 19:20:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:20:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:20:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:20:34 | INFO | fairseq.tasks.translation | example hypothesis: 's the the the the the the the, and the the the the the the the, and and the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:20:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:20:42 | INFO | fairseq.tasks.translation | example hypothesis: we we we the the the, and the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and and and and and and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-23 19:20:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:20:51 | INFO | fairseq.tasks.translation | example hypothesis: 's's, "" "" "" "" "" "" "" ""
2022-03-23 19:20:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:20:54 | INFO | fairseq.tasks.translation | example hypothesis: we we we a a a a a a a a, and the the the the the the the the the the, and the the the the, and the the the the the the the the the, and the the the the the the the the the the the the the the the the the the the the, and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and and and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the, and that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that,
2022-03-23 19:20:54 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:20:54 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.447 | ppl 349.09 | bleu 0.04 | wps 2712.6 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.04
2022-03-23 19:20:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-23 19:20:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:20:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.04) (writing took 0.7906781269994099 seconds)
2022-03-23 19:20:54 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 19:20:54 | INFO | train | epoch 003 | loss 8.625 | ppl 394.93 | wps 7959.2 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.576 | loss_scale 4 | train_wall 429 | gb_free 13.2 | wall 1486
2022-03-23 19:20:55 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 19:20:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:22:30 | INFO | train_inner | epoch 004:     34 / 157 loss=8.465, ppl=353.37, wps=7431.3, ups=0.29, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=1.525, loss_scale=4, train_wall=276, gb_free=13, wall=1581
2022-03-23 19:27:04 | INFO | train_inner | epoch 004:    134 / 157 loss=8.219, ppl=297.89, wps=9198.4, ups=0.36, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=1.582, loss_scale=4, train_wall=274, gb_free=13.8, wall=1855
2022-03-23 19:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:28:09 | INFO | fairseq.tasks.translation | example hypothesis: we're the world in the world.
2022-03-23 19:28:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:28:14 | INFO | fairseq.tasks.translation | example hypothesis: the world is the world is the world.
2022-03-23 19:28:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:28:20 | INFO | fairseq.tasks.translation | example hypothesis: we're're the world of the world of the world.
2022-03-23 19:28:20 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:28:26 | INFO | fairseq.tasks.translation | example hypothesis: , it's a way, and it's a way, and it's a way.
2022-03-23 19:28:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:28:33 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not not not not not not not not not not not not not.
2022-03-23 19:28:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:28:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world, and the world is the world of the world, and the world, and the world, and the world of the world of the world.
2022-03-23 19:28:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:28:46 | INFO | fairseq.tasks.translation | example hypothesis: it's not not not not not not, but you can can can can can can can can can can can can can can can can can can can can can can can can can see to be be be be be be their their their their, but but but it.
2022-03-23 19:28:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:28:54 | INFO | fairseq.tasks.translation | example hypothesis: we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can see of the way, and the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can
2022-03-23 19:28:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:29:03 | INFO | fairseq.tasks.translation | example hypothesis: "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 19:29:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:29:05 | INFO | fairseq.tasks.translation | example hypothesis: , we have to have the world, which we have to can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be the world, which which which is the world, which which it's the world, which is the world, which we're the world of the world, which we're the world of the world, which we're the world of the world of the world of the world, and it's the world, which we're're're're be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be, which which which which we're the world.
2022-03-23 19:29:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:29:05 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.807 | ppl 223.97 | bleu 0.92 | wps 2899.7 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 0.92
2022-03-23 19:29:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-23 19:29:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:29:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:29:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 4 @ 623 updates, score 0.92) (writing took 0.776249484042637 seconds)
2022-03-23 19:29:06 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 19:29:06 | INFO | train | epoch 004 | loss 8.233 | ppl 300.78 | wps 8032 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 1.505 | loss_scale 4 | train_wall 428 | gb_free 13.4 | wall 1978
2022-03-23 19:29:06 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 19:29:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:32:34 | INFO | train_inner | epoch 005:     77 / 157 loss=7.933, ppl=244.31, wps=7418.7, ups=0.3, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=1.966, loss_scale=4, train_wall=267, gb_free=14.6, wall=2185
2022-03-23 19:36:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:36:23 | INFO | fairseq.tasks.translation | example hypothesis: we have in the world in the world in the world.
2022-03-23 19:36:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:36:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the world of the most of the world.
2022-03-23 19:36:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:36:37 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go to be a new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 19:36:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:36:44 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's a lot of the world, and it's a lot of the world, and it's a lot of the way, and it's a lot of the
2022-03-23 19:36:44 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:36:52 | INFO | fairseq.tasks.translation | example hypothesis: we don't know that we're not not not not not not not not going to do that we're going to do that we're going to do that we're going to do that we're not not not not not not not not not not
2022-03-23 19:36:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:37:00 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of the world of the world, and the world, and the world for the world, and the world for the world, and the world for the world for the world of the world of the world of the world, and the world, and the world, and the world
2022-03-23 19:37:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:37:08 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the lot of the lot of the way, and they're not not not not not going to be a lot of the lot of the lot of the lot of the way, and they're going to go to get the way of the way of the way, and they're going to go to get the same of the way of the
2022-03-23 19:37:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:37:16 | INFO | fairseq.tasks.translation | example hypothesis: we can see that we can see that we can see the world of the way of the way of the way that we can see that we can see that we can see that we can see that we can see that we can see the way of the way of the way of the way of the way of the way of the world of the way that we can see that we can see that we can see that we can see that we can see the way of the same
2022-03-23 19:37:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:37:25 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the way, and it's going to say, "it's a lot of the way, and it's a lot of the way," it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it's a lot of the way, "it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it's a lot of the way," it's a lot of the way, and it's a lot of the way, and it's a lot of the way, and it's a lot of the way of the way, "" ""
2022-03-23 19:37:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:37:28 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the way that we have to be a lot of the way that we can't have to go to be a lot of the way that that we have that that we have to be a lot of the way, and it's a lot of the way, and it, and it, and it's a lot of the way that we can't have to be a lot of the way that we can't have to be a lot of the way that we can't have to be that that that we have that we have a lot of the way that we have to be that we have to be a lot of the way that that we can't have to have to be a lot of the way that that that that we have to be that that that that we have to be a lot of the way of the way to be be be that that, and it's a lot of the way of the way of the way of the way of the way of the way of the way of the way, and it, and we can't have to
2022-03-23 19:37:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:37:28 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.406 | ppl 169.54 | bleu 1.09 | wps 2518.2 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 1.09
2022-03-23 19:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-23 19:37:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:37:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:37:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 5 @ 780 updates, score 1.09) (writing took 0.7710488460143097 seconds)
2022-03-23 19:37:28 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 19:37:28 | INFO | train | epoch 005 | loss 7.74 | ppl 213.83 | wps 7862.1 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 1.794 | loss_scale 4 | train_wall 430 | gb_free 13.6 | wall 2480
2022-03-23 19:37:29 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 19:37:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:38:22 | INFO | train_inner | epoch 006:     20 / 157 loss=7.623, ppl=197.18, wps=7307, ups=0.29, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=1.741, loss_scale=4, train_wall=276, gb_free=12.2, wall=2533
2022-03-23 19:42:58 | INFO | train_inner | epoch 006:    120 / 157 loss=7.346, ppl=162.66, wps=9162, ups=0.36, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.616, loss_scale=4, train_wall=276, gb_free=13.6, wall=2809
2022-03-23 19:44:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:44:44 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world.
2022-03-23 19:44:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:44:50 | INFO | fairseq.tasks.translation | example hypothesis: here's here here here's the most of the world.
2022-03-23 19:44:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:44:56 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a new new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 19:44:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:45:03 | INFO | fairseq.tasks.translation | example hypothesis: it's a lot of the world, and it's going to be a lot of the world, and it's going to be a lot of the world.
2022-03-23 19:45:03 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:45:11 | INFO | fairseq.tasks.translation | example hypothesis: we're going to do that we're not going to do that we're going to do that we're going to do it's not not not going to do that we're going to do it's going to do it's going to do it
2022-03-23 19:45:11 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:45:19 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of people who are in the world, for the world, for the world, and people are the people in the world, for the world, for the world, for the world, for the world, for the world, for the people is in the world, and people
2022-03-23 19:45:19 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:45:27 | INFO | fairseq.tasks.translation | example hypothesis: if you're not going to be a lot of the world, but they're not not not not going to be a lot of the way, but they're going to be a lot of the world, but they're going to be able to be not not going to be a lot of the world, but they're going to be able to be able to
2022-03-23 19:45:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:45:35 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see that we're going to see the world, and we can see that we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we're going to make the world, and we're going to be a lot of the world, and we're going to be a lot of the world, and we can see that we can
2022-03-23 19:45:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:45:45 | INFO | fairseq.tasks.translation | example hypothesis: i said, "" you know, "you know," "you're going to say," you know, "you're going to say," you know, "you know," you know, "it's going to say," you know, "it's going to say," you know, "it's going to say," it's going to say, "" you're going to say, "it's going to say," "" "" "it's a good," "" "you're going to say," it's a "you're going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," it's a "" "" "" "" "" ""
2022-03-23 19:45:45 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:45:47 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to be a lot of the world, which is a lot of the world, that we're going to be a lot of the world, which is that we're going to be a lot of the world, which is that we're going to be a lot of the way that we can be a lot of the world that we can't have that we're going to be a lot of the world, which is that we're going to be a lot of the way that we can't have a lot of the world that we're going to be a lot of the world that we're going to be able to be a lot of the world, which is that we're going to be a lot of the way that we're going to be a lot of the world, which is that we're going to be a lot of the world, which is that we can't have to be able to be a lot of the world, which is, which is that we're going to be a lot of the world, which is that we're going
2022-03-23 19:45:47 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:45:47 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.021 | ppl 129.84 | bleu 1.39 | wps 2582.6 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 1.39
2022-03-23 19:45:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-23 19:45:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:45:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:45:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 6 @ 937 updates, score 1.39) (writing took 0.7874430160154589 seconds)
2022-03-23 19:45:48 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 19:45:48 | INFO | train | epoch 006 | loss 7.337 | ppl 161.66 | wps 7903.7 | ups 0.31 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 1.674 | loss_scale 4 | train_wall 429 | gb_free 14.3 | wall 2980
2022-03-23 19:45:48 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 19:45:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:48:40 | INFO | train_inner | epoch 007:     63 / 157 loss=7.116, ppl=138.76, wps=7352.9, ups=0.29, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.511, loss_scale=4, train_wall=272, gb_free=14.4, wall=3152
2022-03-23 19:52:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 19:53:01 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see on this.
2022-03-23 19:53:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 19:53:07 | INFO | fairseq.tasks.translation | example hypothesis: here's the idea of the idea of the first thing.
2022-03-23 19:53:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 19:53:13 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be new new new new new new new new new new new new new new new new new new new new new new.
2022-03-23 19:53:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 19:53:20 | INFO | fairseq.tasks.translation | example hypothesis: it's going to be going to be going to be, and it's going to be going to be going to be going to be, and it.
2022-03-23 19:53:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 19:53:27 | INFO | fairseq.tasks.translation | example hypothesis: what we're going to do is that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do it.
2022-03-23 19:53:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 19:53:34 | INFO | fairseq.tasks.translation | example hypothesis: this is a lot of people in the people, and the most people who are a lot of the people in the people in the world, and the world, and the world, and the most people who are in the people in the people in the world.
2022-03-23 19:53:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 19:53:42 | INFO | fairseq.tasks.translation | example hypothesis: if you're going to get a lot of these things, but they're going to get a lot of these are going to get a lot of them, but they're going to be going to get a lot of them, but they're going to get a lot of the united states, but they're going to be going to be going to be able to
2022-03-23 19:53:42 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 19:53:50 | INFO | fairseq.tasks.translation | example hypothesis: we're going to get a lot of the world, and we're going to get a lot of the world, and we're going to be going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a lot of the world
2022-03-23 19:53:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 19:53:59 | INFO | fairseq.tasks.translation | example hypothesis: we said, "" "you're going to say," "you're going to say," you're going to say, "you're going to say," you're going to say, "" "you're going to say," you're going to say, "you're going to say," "" "" you're going to say, "you're going to say," "you're going to say," "" "" "" "" "" "" "" "" "you're going to say," you're going to say, "you're going to say," "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," "" "" "
2022-03-23 19:53:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 19:54:02 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to be a lot of the world that we're going to be a lot of the world that we're going to be going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be a lot of the world that we're going to be able to be able to be a lot of the first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first first, and then we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 19:54:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 19:54:02 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.751 | ppl 107.71 | bleu 1.75 | wps 2712.2 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 1.75
2022-03-23 19:54:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-23 19:54:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:54:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 19:54:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 1.75) (writing took 0.7784238819731399 seconds)
2022-03-23 19:54:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 19:54:02 | INFO | train | epoch 007 | loss 7.036 | ppl 131.22 | wps 7988.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.509 | loss_scale 4 | train_wall 427 | gb_free 14 | wall 3474
2022-03-23 19:54:03 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 19:54:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 19:54:18 | INFO | train_inner | epoch 008:      6 / 157 loss=6.973, ppl=125.6, wps=7401.5, ups=0.3, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.497, loss_scale=4, train_wall=271, gb_free=13.9, wall=3490
2022-03-23 19:58:52 | INFO | train_inner | epoch 008:    106 / 157 loss=6.739, ppl=106.85, wps=9225.8, ups=0.37, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.472, loss_scale=4, train_wall=273, gb_free=14.2, wall=3763
2022-03-23 20:01:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:01:17 | INFO | fairseq.tasks.translation | example hypothesis: we've got to see this.
2022-03-23 20:01:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:01:23 | INFO | fairseq.tasks.translation | example hypothesis: this is the most most most of the most most most of the most most of the most most most most of the most of the most most of the
2022-03-23 20:01:23 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:01:30 | INFO | fairseq.tasks.translation | example hypothesis: in new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 20:01:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:01:37 | INFO | fairseq.tasks.translation | example hypothesis: it's an example, where it's in the water, where it's a little bit, where it's where it's where it's in the country, and it's a little bit, where it's
2022-03-23 20:01:37 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:01:45 | INFO | fairseq.tasks.translation | example hypothesis: it's not what we're going to do is that we're going to do that we're not going to do that we're going to do that we're going to do that we're going to do that we're not going to do in
2022-03-23 20:01:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:01:52 | INFO | fairseq.tasks.translation | example hypothesis: in fact, the most people who are in the most people in the people who are in the people in the people in the people who are in the people in the people in the people who are in the people in the people in the people in the people who are in the people in the people
2022-03-23 20:01:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:02:00 | INFO | fairseq.tasks.translation | example hypothesis: if you get some of them, but it's a lot of the same time, but it's not a lot of the same way, but it's the same way, but it's a lot of the same way, but they can't get a lot of the same way, but they're not a lot of them, but they're so they're
2022-03-23 20:02:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:02:08 | INFO | fairseq.tasks.translation | example hypothesis: we can see that the way that we can see, and then we can see that we can see the brain, and then we can see the brain, and then we can see that we can see the brain, the brain, and the brain, the brain, and the brain, the brain, the brain is that we can see that we can see that we can see that we can see that we can see that we can see the way of the brain, that
2022-03-23 20:02:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:02:17 | INFO | fairseq.tasks.translation | example hypothesis: if you say, "you know, you know, you know," you know, you know, "it's a little little bit of the first first thing," you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, it's a little bit of the first first first first first first first first first first first first first first first first first of the first first first first first first first first first first first first first first first first first first first first first first first, "the first first first first first first first first first first first first first first first first first first first first first first first first first first thing," you know, "you know, and then, it's a little bit of the first first first first first first first first first first first first first first first thing,"
2022-03-23 20:02:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:02:20 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to get a little little bit of the way that we're going to see that we're going to get a little little bit of the same way that we're going to get a little little bit of the same time, and then we're going to get a little little little bit of the most of the same time that we're going to see that we're going to make a little little bit of the same way that we're going to see that we're going to see that we're going to make a little little bit of the same way that we're going to make a little little little bit of the same same time, which is a little little little bit of the same way that we're going to take a little little little bit of the same time, and then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then then get to get to get a little little little little bit of the same way to be a little little bit of the
2022-03-23 20:02:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:02:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.544 | ppl 93.3 | bleu 2.28 | wps 2611.7 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 2.28
2022-03-23 20:02:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-23 20:02:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:02:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 2.28) (writing took 0.7597793469903991 seconds)
2022-03-23 20:02:21 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 20:02:21 | INFO | train | epoch 008 | loss 6.806 | ppl 111.91 | wps 7927.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.459 | loss_scale 4 | train_wall 428 | gb_free 13.1 | wall 3972
2022-03-23 20:02:21 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 20:02:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:04:39 | INFO | train_inner | epoch 009:     49 / 157 loss=6.736, ppl=106.61, wps=7380, ups=0.29, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.353, loss_scale=4, train_wall=278, gb_free=14.5, wall=4111
2022-03-23 20:09:09 | INFO | train_inner | epoch 009:    149 / 157 loss=6.545, ppl=93.39, wps=9200.8, ups=0.37, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.429, loss_scale=4, train_wall=269, gb_free=13.9, wall=4381
2022-03-23 20:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:09:35 | INFO | fairseq.tasks.translation | example hypothesis: we did this in this room.
2022-03-23 20:09:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:09:41 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of the most most most most most of the most most most most most.
2022-03-23 20:09:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:09:48 | INFO | fairseq.tasks.translation | example hypothesis: this is new new new new new new new new new new new new new new new new new new new new are two two.
2022-03-23 20:09:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:09:54 | INFO | fairseq.tasks.translation | example hypothesis: there's an example of example, and there's a little bit, where you're going to be where it's going to be where it's going to be where you're going to go.
2022-03-23 20:09:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:10:01 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're not just just just just a little bit of what we're going to do that's going to do in his life.
2022-03-23 20:10:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:10:08 | INFO | fairseq.tasks.translation | example hypothesis: in fact, as people like people in the people who are in the people in the people, and it's a lot of people who's a lot of people in the united states, and it's a lot of people in the people in the people.
2022-03-23 20:10:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:10:16 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of some of some of some of these are not, but it's not, but it's not the same time, but it's not the same time, but it doesn't have to get it, but it's the same time, but it's also the same time, but it's the same time, but it doesn't
2022-03-23 20:10:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:10:24 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use the information that we're going to use the information that we can use the information that we can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:10:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:10:33 | INFO | fairseq.tasks.translation | example hypothesis: one of the world: "well," it's one of the world, "you know," well, "you know," well, "you know," well, "you're going to say," you're going to say, "well," well, "well," well, "well," well, "you're going to say," you're going to say, "you know," well, "you're going to say," well, "well," well, "well," well, "well," well, "well," well, "you know," "you know," you know, "you know," you're going to say, "you know," you know, "well," you know, "you know," you know, "you know," you know, "you know,"
2022-03-23 20:10:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:10:36 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's a lot of course, which is that we're going to do that we're going to have a lot of the world that we're going to do that we're going to do that we're going to be able to be able to be a lot of the world that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-23 20:10:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:10:36 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.171 | ppl 72.08 | bleu 3.52 | wps 2710.6 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 3.52
2022-03-23 20:10:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-23 20:10:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:10:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:10:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 3.52) (writing took 0.7439036380383186 seconds)
2022-03-23 20:10:37 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 20:10:37 | INFO | train | epoch 009 | loss 6.54 | ppl 93.02 | wps 7962.1 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.386 | loss_scale 4 | train_wall 428 | gb_free 14.2 | wall 4468
2022-03-23 20:10:37 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 20:10:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:14:50 | INFO | train_inner | epoch 010:     92 / 157 loss=6.304, ppl=79.02, wps=7367, ups=0.29, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.343, loss_scale=4, train_wall=273, gb_free=13.8, wall=4721
2022-03-23 20:17:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:17:51 | INFO | fairseq.tasks.translation | example hypothesis: we did this.
2022-03-23 20:17:51 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:17:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the name of the most most of the most most most most most of you know.
2022-03-23 20:17:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:18:02 | INFO | fairseq.tasks.translation | example hypothesis: these are new new new new new new new new new new new new new new cells.
2022-03-23 20:18:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:18:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's an food, where you're going to go.
2022-03-23 20:18:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:18:14 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're just just just just just a little bit of the brain, and what's going on.
2022-03-23 20:18:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:18:20 | INFO | fairseq.tasks.translation | example hypothesis: in the middle of people like people who are working for the people for the people, and that's a lot of people in the people.
2022-03-23 20:18:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:18:27 | INFO | fairseq.tasks.translation | example hypothesis: some of some of some of the brain, but if you're not able to use the energy, but if you don't get the energy, it's the energy, if you don't have the energy, it's the energy, if you don't have the energy, it's the energy, if you don't get the energy, it, it's
2022-03-23 20:18:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:18:34 | INFO | fairseq.tasks.translation | example hypothesis: if we're going to use the information that we can use this information, and we can use the information, and we can use it with a structure of the brain, and the brain, and the information that can be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the information with the brain
2022-03-23 20:18:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:18:43 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons, and it's interesting interesting, and it's going to talk about this, and then it's a long time for me, and then we're going to talk about the first time, and then you're going to talk about the first time, and then you're going to talk about the first time, and then you're going to talk about that's going to talk about that's going to talk about the first time, and then you know, and then, and then you know, and then you know, and then you're going to talk about this is that's going to do it's going to talk about that's going to talk about that's going to talk about the first time, and then you know, and then you're going to do it's going to talk about it's going to talk about the first time with a little bit of the first time with a
2022-03-23 20:18:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:18:45 | INFO | fairseq.tasks.translation | example hypothesis: it's always always always always always always been a few years, and when we're going to get a little bit of the world, and when we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-23 20:18:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:18:45 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.816 | ppl 56.33 | bleu 6.13 | wps 3017.7 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 6.13
2022-03-23 20:18:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-23 20:18:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:18:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:18:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 6.13) (writing took 0.7673222190351225 seconds)
2022-03-23 20:18:46 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 20:18:46 | INFO | train | epoch 010 | loss 6.222 | ppl 74.64 | wps 8068.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.396 | loss_scale 4 | train_wall 428 | gb_free 13.3 | wall 4957
2022-03-23 20:18:46 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 20:18:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:20:20 | INFO | train_inner | epoch 011:     35 / 157 loss=6.144, ppl=70.7, wps=7530, ups=0.3, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.492, loss_scale=4, train_wall=269, gb_free=13, wall=5051
2022-03-23 20:24:57 | INFO | train_inner | epoch 011:    135 / 157 loss=5.866, ppl=58.32, wps=9226.7, ups=0.36, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.411, loss_scale=4, train_wall=277, gb_free=12.9, wall=5328
2022-03-23 20:25:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:26:01 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the clinics.
2022-03-23 20:26:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:26:07 | INFO | fairseq.tasks.translation | example hypothesis: this is the name of ha, most most most most most most most most most most most most here.
2022-03-23 20:26:07 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:26:13 | INFO | fairseq.tasks.translation | example hypothesis: new new york are going to be two new new new new york.
2022-03-23 20:26:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:26:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a chinese chinese chinese, where they're going to go up with a pow, and they're going to be able to be able.
2022-03-23 20:26:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:26:25 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just just a few of his head, and what's going on.
2022-03-23 20:26:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:26:32 | INFO | fairseq.tasks.translation | example hypothesis: in fact, like the way that people have been working for for the number of years, and that's a few years, and that's a few years.
2022-03-23 20:26:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:26:38 | INFO | fairseq.tasks.translation | example hypothesis: some of you are some of the water, but if you don't need to use the energy, but if you need to use the energy, you need to use the energy, you need to use it.
2022-03-23 20:26:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:26:44 | INFO | fairseq.tasks.translation | example hypothesis: if we use information information information, we can use this information, we can take a structure of the structure, and we can use the structure of the structure of the structure, and the structure of the structure.
2022-03-23 20:26:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:26:50 | INFO | fairseq.tasks.translation | example hypothesis: one: one of the reasons, and it's interesting for me, "and then," if we have to say, "well," you know, "well," well, "you know," well, "well," well, "you know," well, "you know," well, "well," well, "well," well, "well," you know, "well," well, "well," well, "you know," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," well, "well," you know, "you know," well, "well," well, "well," well, "well," well, "well," well, "
2022-03-23 20:26:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:26:52 | INFO | fairseq.tasks.translation | example hypothesis: then, it's still still still the mother, and we've got a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:26:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:26:52 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.464 | ppl 44.13 | bleu 8.57 | wps 3195.4 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 8.57
2022-03-23 20:26:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-23 20:26:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:26:53 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:26:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 8.57) (writing took 0.7474023649701849 seconds)
2022-03-23 20:26:53 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 20:26:53 | INFO | train | epoch 011 | loss 5.937 | ppl 61.27 | wps 8104.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.436 | loss_scale 4 | train_wall 429 | gb_free 13.6 | wall 5445
2022-03-23 20:26:54 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 20:26:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:30:27 | INFO | train_inner | epoch 012:     78 / 157 loss=5.751, ppl=53.86, wps=7557.7, ups=0.3, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.41, loss_scale=4, train_wall=273, gb_free=13.5, wall=5659
2022-03-23 20:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:34:09 | INFO | fairseq.tasks.translation | example hypothesis: we got these clinics in the clinics.
2022-03-23 20:34:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:34:15 | INFO | fairseq.tasks.translation | example hypothesis: this is the bottom point of ha ha, most most of most most most most of you know.
2022-03-23 20:34:15 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:34:21 | INFO | fairseq.tasks.translation | example hypothesis: these are new states.
2022-03-23 20:34:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:34:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese chinese chinese chinese chinese chinese, where they're going to die with it.
2022-03-23 20:34:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:34:34 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just just a few of your head on his head, and what's going on.
2022-03-23 20:34:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:34:41 | INFO | fairseq.tasks.translation | example hypothesis: in fact, the mamamamamats of the responsibility for the number of animals, the number of animals, and this is a number of years.
2022-03-23 20:34:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:34:47 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're going to look at the microscope, but if you don't need to use the energy, if you need to use your energy, it doesn't need your energy, and you need to need the energy.
2022-03-23 20:34:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:34:54 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, we can use this information information, we can see it's going to be able to be able to take the structure of the structure, and all the structure of the structure, and all the information that are all the information that are all the information that are all the structure that are all the information that are all the information.
2022-03-23 20:34:54 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:35:00 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, it's interesting for me, and it's interesting for women for women, "okay," if we've got to say, "you know," and then we're going to say, "you know," you know, "if we've got to say," you're going to say, "you're going to say," you're going to say, "you know," you're going to say, "you know," you're going to say, "you know," you're going to go to say, "you know," you've got to go to go to go to go to be in this is that, "and then you're going to go to go to be in this is that the first time with this is that's a little bit of this is that's the first time," and then you're going to be a
2022-03-23 20:35:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:35:03 | INFO | fairseq.tasks.translation | example hypothesis: finally, it's still still the mother, and the great part of our work, and we had a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 20:35:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:35:03 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.106 | ppl 34.44 | bleu 9.88 | wps 3068.3 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 9.88
2022-03-23 20:35:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-23 20:35:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:35:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:35:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 12 @ 1879 updates, score 9.88) (writing took 0.7772792809992097 seconds)
2022-03-23 20:35:03 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 20:35:03 | INFO | train | epoch 012 | loss 5.6 | ppl 48.49 | wps 8054.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.411 | loss_scale 4 | train_wall 430 | gb_free 13.7 | wall 5935
2022-03-23 20:35:04 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 20:35:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:36:00 | INFO | train_inner | epoch 013:     21 / 157 loss=5.448, ppl=43.65, wps=7543.9, ups=0.3, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.469, loss_scale=4, train_wall=272, gb_free=13.4, wall=5992
2022-03-23 20:40:35 | INFO | train_inner | epoch 013:    121 / 157 loss=5.327, ppl=40.15, wps=9190.1, ups=0.36, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.337, loss_scale=4, train_wall=275, gb_free=13.1, wall=6267
2022-03-23 20:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:42:18 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppon the clinics.
2022-03-23 20:42:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:42:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skydoha doha, most most most of most.
2022-03-23 20:42:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:42:30 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be new york.
2022-03-23 20:42:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:42:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, where they're going to get ppppon.
2022-03-23 20:42:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:42:41 | INFO | fairseq.tasks.translation | example hypothesis: it's not just that we're not just just just a couple of electrodes on his head, and what's going on on.
2022-03-23 20:42:41 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:42:48 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamamamacy, the responsibility for the number of animals, and this is a number of years.
2022-03-23 20:42:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:42:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some of you're able to go through the magic, but i don't want to move the energy energy, if you don't need your energy energy, you need to get the energy.
2022-03-23 20:42:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:42:59 | INFO | fairseq.tasks.translation | example hypothesis: if we use information that information from this reflection, we can begin to look at a huge kind of design, and we can start with the structure of the structure of the structure of the structure and all the structure.
2022-03-23 20:42:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:43:05 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, it's interesting to do interesting, and for example, for example, for example, "oh," oh, "oh," if you've been working with the best revolution, "you've got to say," you know, "you've got a long time to say," if you've been working in this conference. "
2022-03-23 20:43:05 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:43:07 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, it's still still the mother invention of the invention, and a lot of work that we had to solve in our market, and if we had to use it into a system that was able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use it
2022-03-23 20:43:07 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:43:07 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.857 | ppl 28.99 | bleu 12.16 | wps 3342.3 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 12.16
2022-03-23 20:43:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-23 20:43:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:43:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:43:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 12.16) (writing took 0.7968669300316833 seconds)
2022-03-23 20:43:08 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 20:43:08 | INFO | train | epoch 013 | loss 5.29 | ppl 39.13 | wps 8146.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.342 | loss_scale 4 | train_wall 429 | gb_free 13 | wall 6420
2022-03-23 20:43:09 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 20:43:09 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:46:03 | INFO | train_inner | epoch 014:     64 / 157 loss=5.117, ppl=34.69, wps=7619.5, ups=0.31, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.307, loss_scale=4, train_wall=272, gb_free=13.6, wall=6595
2022-03-23 20:50:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:50:24 | INFO | fairseq.tasks.translation | example hypothesis: we made these pppills in the clinics.
2022-03-23 20:50:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:50:30 | INFO | fairseq.tasks.translation | example hypothesis: this is the new line of doha, ha, the most most most of the most of you know.
2022-03-23 20:50:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:50:36 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to create new dines that are going to make two new clients.
2022-03-23 20:50:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:50:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese chinese chinese food where the legs are going to get out and get rid of it.
2022-03-23 20:50:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:50:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just have a few electrodes on his head on his head, and what's going on on the mind.
2022-03-23 20:50:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:50:54 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamamace of people, like the responsibility came up to the number of animals, and this has become a lot of conservation.
2022-03-23 20:50:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:51:00 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the magnetic magnetic magnetic lines in the lines, but it doesn't have the energy of the energy, and if you need your energy.
2022-03-23 20:51:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:51:06 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the reflection of this reflection of reflection, we can start with a traditional traditional traditional design, and we can start through a whole structure of information and all the information.
2022-03-23 20:51:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:51:12 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons, the reasons it's interesting, and it's interesting to make me here for tedtedtedtalks about women, "oh," if we're talking to you're talking about this stage, "and then we're going to say," one of these two reasons. "
2022-03-23 20:51:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:51:13 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, the mother is still the mother of the invention, and a lot of design that we had to see that if we had to be able to use the electric electric system, and if it had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use a regenerate the electric electric speed.
2022-03-23 20:51:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:51:13 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.649 | ppl 25.09 | bleu 14.51 | wps 3330.1 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 14.51
2022-03-23 20:51:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-23 20:51:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:51:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 14.51) (writing took 0.8084862359683029 seconds)
2022-03-23 20:51:14 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 20:51:14 | INFO | train | epoch 014 | loss 4.953 | ppl 30.97 | wps 8134.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.277 | loss_scale 4 | train_wall 429 | gb_free 13.3 | wall 6905
2022-03-23 20:51:14 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 20:51:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 20:51:36 | INFO | train_inner | epoch 015:      7 / 157 loss=4.828, ppl=28.4, wps=7665.6, ups=0.3, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.204, loss_scale=4, train_wall=277, gb_free=13.4, wall=6928
2022-03-23 20:56:09 | INFO | train_inner | epoch 015:    107 / 157 loss=4.687, ppl=25.76, wps=9229.5, ups=0.37, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.327, loss_scale=4, train_wall=272, gb_free=13.5, wall=7200
2022-03-23 20:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 20:58:29 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinics.
2022-03-23 20:58:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 20:58:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-23 20:58:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 20:58:41 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to create new dindinburgh.
2022-03-23 20:58:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 20:58:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese chinese food, where the legs are so happy with legs and salt.
2022-03-23 20:58:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 20:58:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a couple of electrodes on his head, and what all of your mind are on your mind.
2022-03-23 20:58:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 20:59:00 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamamamace, like the responsibility of responsibility, grew up to the number of animals, and this is a number of conservation for conservation.
2022-03-23 20:59:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 20:59:06 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic magnetic magnetic magnetic lines in the field, but it doesn't like the alalalalalalalaly, if you're going to move your energy, and you need to move your energy.
2022-03-23 20:59:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 20:59:12 | INFO | fairseq.tasks.translation | example hypothesis: if we use information, the reflection of this reflection reflection, we can start with a traditional idea of traditional faces that are able to start with a big light, and there's a huge shape of the structure of the information that are all the structure of the structure of the structure.
2022-03-23 20:59:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 20:59:19 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting, and interesting for example, for example, for example, this is that women were talking to me -- yes, "oh, when the best time it was the best thing that she said," oh, "if we're going to ask you're going to say," if we've got a long time to ask you're going to ask you know, "oh," you're going to ask you know, "oh," if we've got a long time for a long time to ask you're going to do a long time to ask you're going to ask you're going to ask you know that's a long time to be a long time to ask you're going to ask you know, "oh," the first time for you're going to be a long time to ask you know, "oh," and then have a long time to
2022-03-23 20:59:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 20:59:21 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention of the invention, and a big design part of our work on our airplane, we had to see that if we had a unique effect of the aircraft, that it was a unique system, or if we had to use it to use a unique system, if it was a unique system, if we had to use it to use it to be a unique system, or a unique system, if we had to use of a unique, if we had to use the electric electric electric electric market, or a lot of a lot of energy system, or a lot of the power, if we had to use it's a lot of energy system, if we had to use it's a lot of the power, that it's a lot of the power, or a lot of the power, if it's a lot of the power, if we had to use it's a lot of the power, if we had to use it's a lot of the power, that it's a lot of the power,
2022-03-23 20:59:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 20:59:21 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.301 | ppl 19.71 | bleu 16.1 | wps 3172.6 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 16.1
2022-03-23 20:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-23 20:59:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:59:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 20:59:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 16.1) (writing took 0.8388632130227052 seconds)
2022-03-23 20:59:22 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 20:59:22 | INFO | train | epoch 015 | loss 4.717 | ppl 26.3 | wps 8089.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.297 | loss_scale 4 | train_wall 428 | gb_free 13.3 | wall 7393
2022-03-23 20:59:22 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 20:59:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:01:45 | INFO | train_inner | epoch 016:     50 / 157 loss=4.711, ppl=26.19, wps=7561.8, ups=0.3, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.248, loss_scale=4, train_wall=277, gb_free=13.8, wall=7536
2022-03-23 21:06:13 | INFO | train_inner | epoch 016:    150 / 157 loss=4.362, ppl=20.56, wps=9193.9, ups=0.37, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.119, loss_scale=4, train_wall=268, gb_free=14, wall=7805
2022-03-23 21:06:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:06:37 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinics.
2022-03-23 21:06:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:06:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-23 21:06:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:06:48 | INFO | fairseq.tasks.translation | example hypothesis: these are new stars going to create two new dines.
2022-03-23 21:06:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:06:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where happy legs are going to be.
2022-03-23 21:06:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:06:59 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head, and understand what all the thoughts are on your mind.
2022-03-23 21:06:59 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:07:05 | INFO | fairseq.tasks.translation | example hypothesis: in the mammals like the responsibility, grew up to the number of animals. and this is a foundation for conservation.
2022-03-23 21:07:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:07:11 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines in the field, but the conductor doesn't move if they need it, they don't need their energy, and they need their energy.
2022-03-23 21:07:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:07:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection, we can start with a traditional face, we can start able to start able to start able to start with a traditional face of the face of the face of the shape and reform.
2022-03-23 21:07:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:07:22 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that we have interesting and measure for tedtalks to be here, and then for tedtalks is that...
2022-03-23 21:07:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:07:23 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention and a part of the design that we had to solve on our airplane, the plane was that we had to solve was a unique result that we had to solve a unique result that we had to solve it.
2022-03-23 21:07:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:07:23 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.182 | ppl 18.15 | bleu 13.25 | wps 3584.1 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 16.1
2022-03-23 21:07:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-23 21:07:23 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 21:07:23 | INFO | train | epoch 016 | loss 4.44 | ppl 21.7 | wps 8207.9 | ups 0.33 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.184 | loss_scale 4 | train_wall 429 | gb_free 13.6 | wall 7875
2022-03-23 21:07:23 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 21:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:11:40 | INFO | train_inner | epoch 017:     93 / 157 loss=4.25, ppl=19.03, wps=7740.3, ups=0.31, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.178, loss_scale=4, train_wall=275, gb_free=14.5, wall=8132
2022-03-23 21:14:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:14:39 | INFO | fairseq.tasks.translation | example hypothesis: we did this pink in the clinic clinic clinics at the clinic clinic.
2022-03-23 21:14:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:14:46 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 21:14:46 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:14:52 | INFO | fairseq.tasks.translation | example hypothesis: these stars are going to create new golsticks that are going to create two new locks.
2022-03-23 21:14:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:14:58 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food food food, where frog legs and pie.
2022-03-23 21:14:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:15:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just have a few electrodes on his head and understand what all its thoughts are on the table.
2022-03-23 21:15:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:15:11 | INFO | fairseq.tasks.translation | example hypothesis: in the mamamac, like the responsibility for the wild, grew up to the number of animals, and this is a foundation for conservation.
2022-03-23 21:15:11 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:15:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some of them are a few of magnetic magnetic magnetic field, but the sususully of the superconductor, and so if you don't need their energy.
2022-03-23 21:15:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:15:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection reflection reflection, we can start with a traditional facial facial, and the basic shape of the interfaces, and the whole structure of the structure, and the whole structure of the structure, and the whole structure of the structure, the structure of the structure, the structure, the structure, the whole structure of the structure, the structure, the structure, the whole structure, the structure
2022-03-23 21:15:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:15:32 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting to be interesting for me to be here, and then, for me, "oh, when we've got the best part of you said," well, you know, "the best thing that we're going to support you're going to support you."
2022-03-23 21:15:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:15:34 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, interestingly, the mother's invention of invention, and a big part of the design that we've had to solve is that we had to solve a unique amount of problems that we had to solve it in the ground, and if you're all connected to the web, it's a very unique, or if you can actually be able to be able to see the web, you're able to see the engine, the engine, the engine, the engine, you're able to see that if you're able to be able to be able to see the engine, you're able to be able to see, you're able to see, you're able to see, you're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the engine, or a very specific, or a very specific, you're able to be able to be able to be able to be able to be able to see,
2022-03-23 21:15:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:15:34 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.995 | ppl 15.95 | bleu 17 | wps 2990.3 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 17
2022-03-23 21:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-23 21:15:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:15:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:15:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 17.0) (writing took 0.8066573279793374 seconds)
2022-03-23 21:15:35 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 21:15:35 | INFO | train | epoch 017 | loss 4.243 | ppl 18.94 | wps 8026.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.197 | loss_scale 4 | train_wall 430 | gb_free 13.2 | wall 8367
2022-03-23 21:15:35 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 21:15:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:17:17 | INFO | train_inner | epoch 018:     36 / 157 loss=4.175, ppl=18.06, wps=7490.8, ups=0.3, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.185, loss_scale=4, train_wall=275, gb_free=13.9, wall=8468
2022-03-23 21:21:46 | INFO | train_inner | epoch 018:    136 / 157 loss=3.992, ppl=15.92, wps=9217.4, ups=0.37, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.053, loss_scale=4, train_wall=269, gb_free=13.7, wall=8738
2022-03-23 21:22:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:22:50 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 21:22:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:22:56 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, which probably knows most of you.
2022-03-23 21:22:56 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:23:02 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golsticks that will create the two new pigs.
2022-03-23 21:23:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:23:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where frog legs are being served with salz and fat.
2022-03-23 21:23:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:23:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to put a few electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 21:23:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:23:20 | INFO | fairseq.tasks.translation | example hypothesis: in the maibia, like the people who grew up for the wild, grew up the number of animals, and that's a foundation for conservation protection.
2022-03-23 21:23:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:23:26 | INFO | fairseq.tasks.translation | example hypothesis: first, they're some blooding of magnetic fields in the inner lines, but the sususulant alarm doesn't like it, if they're moving your energy movements, they need their energy movements, and so they need the susulant.
2022-03-23 21:23:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:23:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial face, which can start with a traditional facial facial faces that can start with the big configuration of the face of the constructions and repeat and repeat and reform it through the form of information, and that's a whole structure.
2022-03-23 21:23:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:23:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's interesting for me to be here for tedwomen, and then we've started talking to them, "oh," oh, you know, "oh," oh, "oh, you know," the best thing that you're going to support you're going to help you're going to support a playful revolution, "and then we've started to be a playful revolution for a long time to support for example," oh, "you're going to help you're going to support you've started to be a playful time to be here for women,"
2022-03-23 21:23:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:23:42 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother is still the invention of invention, and a big part of the design that we're doing in our plane, was a result that we had to solve it was a unique result that we had to solve the same problems that we had to solve it in the ground -- it would be connected to the ground -- to a survevestock system, or an aircraft, which is that if you can actually use the air, it to use the air, it to use the air, it to use the air, you're all the air, or to use the air, it to use the air, you can't use the air, it to use the air, it to use the air, it to be a specific system, or to use the air, or the air, it's a very specific system that you can't use the air, you can't use the air, or to use the air, you can't use the air, you can't use the air, it to be a very much more expensive, it to be
2022-03-23 21:23:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:23:42 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.673 | ppl 12.75 | bleu 20.71 | wps 3196.9 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 20.71
2022-03-23 21:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-23 21:23:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:23:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 20.71) (writing took 0.8095107799745165 seconds)
2022-03-23 21:23:42 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 21:23:42 | INFO | train | epoch 018 | loss 3.999 | ppl 15.99 | wps 8103.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.026 | loss_scale 4 | train_wall 428 | gb_free 13.2 | wall 8854
2022-03-23 21:23:43 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 21:23:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:27:23 | INFO | train_inner | epoch 019:     79 / 157 loss=3.871, ppl=14.63, wps=7602.6, ups=0.3, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.987, loss_scale=4, train_wall=278, gb_free=13.5, wall=9075
2022-03-23 21:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:30:58 | INFO | fairseq.tasks.translation | example hypothesis: we made this sheep in the clinic.
2022-03-23 21:30:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:31:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows most of you here.
2022-03-23 21:31:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:31:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks of dindinburgh that will become two new pigs.
2022-03-23 21:31:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:31:15 | INFO | fairseq.tasks.translation | example hypothesis: for example, french food food food, where frog legs are served with salz and fat.
2022-03-23 21:31:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:31:21 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand exactly what all the thoughts on the road.
2022-03-23 21:31:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:31:27 | INFO | fairseq.tasks.translation | example hypothesis: in the mammals like the people's responsibility for wildlife, grew up the number of animals again, and that's a foundation for conservation in nambia.
2022-03-23 21:31:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:31:33 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloods of magnetic fields in the inner field, but the sulalalalalalalalarm doesn't like you move your energy movements and so forth.
2022-03-23 21:31:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:31:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face, which can begin with a traditional facial face of the face and the basic shape of the interactions and the interactions of the information that the entire structure of the structure, the whole structure, which is reflection of this reflection, and the entire portion of this reflection.
2022-03-23 21:31:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:31:46 | INFO | fairseq.tasks.translation | example hypothesis: keith: one of the reasons that it's interesting, and measure me here at tedwomen, for tedwomen, is that...
2022-03-23 21:31:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:31:48 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother's invention of invention, and a big part of the design work that we were using on our airplane was a result of that we had to resolution the unique problems to the ground -- everything connected to the ground -- and a large scale of the invention of the invention of the engine, and a large part of the engine, and a large part of the design of the design, which is the aircraft, which is that we're going to use of the aircraft, or the aircraft, or the aircraft, or the aircraft, or the aircraft, or the aircraft, or the aircraft, or the tratratrajegic, or the aircraft, which is that allows us to use of a tragic system, or the aircraft, or the aircraft, and then allows us to use of a fluids, and the aircraft, which is that we put it into a fluids, and then allows us to put it into a fluids, and the plane, and then allows us to use
2022-03-23 21:31:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:31:48 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.596 | ppl 12.09 | bleu 21.1 | wps 3250 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 21.1
2022-03-23 21:31:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-23 21:31:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:31:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:31:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 19 @ 2978 updates, score 21.1) (writing took 0.8275823459844105 seconds)
2022-03-23 21:31:49 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 21:31:49 | INFO | train | epoch 019 | loss 3.786 | ppl 13.79 | wps 8111.7 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.004 | loss_scale 4 | train_wall 429 | gb_free 13.4 | wall 9341
2022-03-23 21:31:50 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 21:31:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:32:51 | INFO | train_inner | epoch 020:     22 / 157 loss=3.687, ppl=12.88, wps=7567.5, ups=0.31, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=0.968, loss_scale=4, train_wall=270, gb_free=14.2, wall=9403
2022-03-23 21:37:31 | INFO | train_inner | epoch 020:    122 / 157 loss=3.6, ppl=12.13, wps=9223.5, ups=0.36, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.889, loss_scale=4, train_wall=280, gb_free=13.2, wall=9683
2022-03-23 21:38:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:39:05 | INFO | fairseq.tasks.translation | example hypothesis: we made these sheep in the clinic.
2022-03-23 21:39:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:39:11 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, which probably knows most of you here.
2022-03-23 21:39:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:39:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldidates of the two new pigments.
2022-03-23 21:39:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:39:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salz and plaser.
2022-03-23 21:39:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:39:29 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding what all his thoughts are on the track.
2022-03-23 21:39:29 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:39:35 | INFO | fairseq.tasks.translation | example hypothesis: so in the make-like people's responsibility for wildlife, the number of animals grew up again, and that's a foundation of conservation in the conservation of conservation.
2022-03-23 21:39:35 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:39:41 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnet lines in the inner lines, but the sulaloner doesn't like it if they're moving their energy, and so the susuicide disorder.
2022-03-23 21:39:41 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:39:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional facial that can start with a traditional facial of the face and the basic shape of the information, and through the information, which is the whole structure of the whole structure, and the whole structure of all the structure of these reflection.
2022-03-23 21:39:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:39:55 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's interesting to be interesting and measured for me to be here in tedwomen, that's that... yes, when somebody said, "if someone said to you about the best," and you say, "if you start to be able to be able to be able to be able to be able to give you a table revolution in a table, and then you know," the fact that you've already started to be here for tedtedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen who have been working with tedwomen, "'"' "'"' "'"' "is that says," '"'" '"'" '"'" '"'" '"is that says," and then we've already started to be here, "well,"
2022-03-23 21:39:55 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:39:57 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention of invention, and a big part of the design work that we're going to be able to solve in our airplane, a result of it was a unique problem that we had to solve the unique problems that were connected to the ground -- everything from a continuously variable, and it's a big part of the refrigergergergergergerator of the mechanism that allows us to be able to be able to be able to use a mechanism for a mechanism, or a mechanism, if it's a mechanism, or even if it's a mechanical mechanism, it's a mechanical mechanism, it's a mechanism, it's a mechanism, it's a mechanism, it's even though it's a mechanism that it's a constitable to be able to be able to be able to be able to be able to be able to be able to use anything else else else else else else else else else else else else else else else that is
2022-03-23 21:39:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:39:57 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.44 | ppl 10.85 | bleu 23.18 | wps 3136.2 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 23.18
2022-03-23 21:39:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-23 21:39:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:39:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:39:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 23.18) (writing took 0.8126416169689037 seconds)
2022-03-23 21:39:58 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 21:39:58 | INFO | train | epoch 020 | loss 3.585 | ppl 12 | wps 8079.7 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.933 | loss_scale 4 | train_wall 429 | gb_free 13.7 | wall 9829
2022-03-23 21:39:58 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 21:39:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:43:02 | INFO | train_inner | epoch 021:     65 / 157 loss=3.45, ppl=10.93, wps=7526.5, ups=0.3, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=0.97, loss_scale=4, train_wall=271, gb_free=13.4, wall=10014
2022-03-23 21:47:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:47:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 21:47:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:47:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 21:47:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:47:26 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to generate new goldicks.
2022-03-23 21:47:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:47:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food, where frog legs are served with salz.
2022-03-23 21:47:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:47:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:47:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:47:44 | INFO | fairseq.tasks.translation | example hypothesis: so, in the case of people, the number of wildlife, grew back again, and that's a foundation for the conservation in namibia.
2022-03-23 21:47:44 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:47:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bingle of magnetic fields in the internal lines, but the sulant eggs may not like you, if you move your movements, and you need the superconductor.
2022-03-23 21:47:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:47:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which can start with the big constructions of the face and the basic shape, and it gives you the information that the whole structure and fold.
2022-03-23 21:47:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:48:03 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's very interesting and measuring me here for tedwomen, is that... "
2022-03-23 21:48:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:48:06 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and a big part of the design work that we're going to be able to see in the plane, or we had to solve a result that we had to solve the unique problems that were connected to the ground -- everything from a refrigeration system that allows us to be able to be able to be able to be able to get a specific.
2022-03-23 21:48:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:48:06 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.31 | ppl 9.92 | bleu 23.75 | wps 3200.3 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 23.75
2022-03-23 21:48:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-23 21:48:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:48:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 21:48:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 23.75) (writing took 0.8471106499782763 seconds)
2022-03-23 21:48:07 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 21:48:07 | INFO | train | epoch 021 | loss 3.462 | ppl 11.02 | wps 8080.2 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.941 | loss_scale 4 | train_wall 430 | gb_free 14.3 | wall 10318
2022-03-23 21:48:07 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 21:48:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:48:30 | INFO | train_inner | epoch 022:      8 / 157 loss=3.502, ppl=11.33, wps=7541.6, ups=0.3, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.954, loss_scale=4, train_wall=270, gb_free=13.4, wall=10342
2022-03-23 21:52:58 | INFO | train_inner | epoch 022:    108 / 157 loss=3.393, ppl=10.51, wps=9195.5, ups=0.37, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=0.952, loss_scale=4, train_wall=268, gb_free=13.4, wall=10610
2022-03-23 21:55:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 21:55:22 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 21:55:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 21:55:27 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline line of doha, which probably knows most of you here.
2022-03-23 21:55:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 21:55:34 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to generate new goldicks.
2022-03-23 21:55:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 21:55:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where happy legs are served with salz.
2022-03-23 21:55:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 21:55:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are.
2022-03-23 21:55:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 21:55:51 | INFO | fairseq.tasks.translation | example hypothesis: in fact, people like the responsibility of wildlife, the number of wild animals have come back. and that's a foundation for conservation.
2022-03-23 21:55:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 21:55:57 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bloodding lines in the inner, but the sulaleiter doesn't like, if you move your movements.
2022-03-23 21:55:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 21:56:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big constructions of the face, and the basic shape of the face, and the basic shape, which gives it through the sound of the information, which is the whole information that creates the whole information of the sound of the face.
2022-03-23 21:56:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 21:56:08 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that it's very interesting and measured for me here at tedwomen is that... tj: yeah, when someone said, it was the best thing when someone said, "turn you to the men on the men."
2022-03-23 21:56:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 21:56:09 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the invention of invention, and a large part of the design work that we're in the aircraft.
2022-03-23 21:56:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 21:56:09 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.291 | ppl 9.79 | bleu 22.21 | wps 3439.6 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 23.75
2022-03-23 21:56:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-23 21:56:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 21:56:09 | INFO | train | epoch 022 | loss 3.35 | ppl 10.2 | wps 8181.5 | ups 0.33 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.899 | loss_scale 4 | train_wall 429 | gb_free 14 | wall 10801
2022-03-23 21:56:10 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 21:56:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 21:58:29 | INFO | train_inner | epoch 023:     51 / 157 loss=3.275, ppl=9.68, wps=7708.7, ups=0.3, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.777, loss_scale=4, train_wall=277, gb_free=13.3, wall=10941
2022-03-23 22:03:04 | INFO | train_inner | epoch 023:    151 / 157 loss=3.124, ppl=8.72, wps=9229, ups=0.36, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.839, loss_scale=4, train_wall=275, gb_free=13.3, wall=11216
2022-03-23 22:03:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:03:25 | INFO | fairseq.tasks.translation | example hypothesis: we made this sheet in the clinic.
2022-03-23 22:03:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:03:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-23 22:03:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:03:37 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that create two new pigs.
2022-03-23 22:03:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:03:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pbuffer.
2022-03-23 22:03:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:03:48 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just making some electrodes on his head and just understanding exactly what all its thoughts are on the track.
2022-03-23 22:03:48 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:03:54 | INFO | fairseq.tasks.translation | example hypothesis: in the make-like people's responsibility for wildlife, growing the number of wild animals again. and that's a foundation for conservation conservation in namibia.
2022-03-23 22:03:54 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:04:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of magnetic field lines are caught inside, but the superconductor doesn't like if you move, because your movements need your energy, and so the superconductor of the superconductor.
2022-03-23 22:04:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:04:07 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial can start with the big constructions of the face and the basic structure of the face and the network of the network, and put it through the network, which is the whole portion of portion, the whole portion of portion and all the fabric structure, and put it into a structure of this reflection.
2022-03-23 22:04:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:04:15 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons it's very interesting to be here at tedwomen, is that... tat dinner, when you got dinner dinner, when someone said, "well, when someone said," shut you to the men on a table and tell you, "if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to help you."
2022-03-23 22:04:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:04:17 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention and a big part of the design work that we're in the aircraft, was a result that we had to solve the unique problems that we've got to solve it on the ground -- everything from a continuous system of the invention of the invention and a large part of the design work, you know, everything from a continuous amount of design work, and a lot of refrigergeration of transportation system that allows us to use in the transportation, in the transportation system, in the transportation system, in the transportation system, in the transportation system, in the transportation system, if you know, you can use, you can use, you can use in the transportation system, you know, you know, you know, you know, you know, you know, there was also have to use in the transportation system, you have to use in the air conditioning the transportation system, you have to use, you know, you know, there was also got to do
2022-03-23 22:04:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:04:17 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.19 | ppl 9.13 | bleu 25.26 | wps 3168.2 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 25.26
2022-03-23 22:04:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-23 22:04:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:04:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:04:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 25.26) (writing took 0.8074381689657457 seconds)
2022-03-23 22:04:18 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 22:04:18 | INFO | train | epoch 023 | loss 3.177 | ppl 9.05 | wps 8085 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.82 | loss_scale 4 | train_wall 429 | gb_free 14.2 | wall 11289
2022-03-23 22:04:18 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 22:04:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:08:35 | INFO | train_inner | epoch 024:     94 / 157 loss=3.084, ppl=8.48, wps=7537.4, ups=0.3, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.785, loss_scale=4, train_wall=271, gb_free=13.3, wall=11547
2022-03-23 22:11:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:11:34 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 22:11:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:11:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 22:11:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:11:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks that are going to transcend two new pigs.
2022-03-23 22:11:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:11:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 22:11:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:11:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just taking some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 22:11:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:12:03 | INFO | fairseq.tasks.translation | example hypothesis: this is a basis of how people were taking responsibility for wildlife, growing the number of wildwildanimals again, and that's a foundation for conservation in namibia.
2022-03-23 22:12:03 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:12:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some legs of magnetic fields are caught in the inside, but the superconductor doesn't like you move, because your movements need their energy, and so the superconductor.
2022-03-23 22:12:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:12:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection, we can start with a traditional facial, which restores the big constructures of the face and the basic form, and through the theft of information which pulls all the ports and folds.
2022-03-23 22:12:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:12:21 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons that it was very interesting and measured to me here at tedwomen is that... tall, when someone said, "well," you know, "if the revolution starts to support you on your table and say," if the revolution starts to help you, "] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["
2022-03-23 22:12:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:12:23 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variable and cooling system that allows us to refrightening that if you're in the aircraft, or that you can either be able to be able to use the republicans.
2022-03-23 22:12:23 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:12:23 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.022 | ppl 8.12 | bleu 26.22 | wps 3356.5 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 26.22
2022-03-23 22:12:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-23 22:12:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:12:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:12:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 26.22) (writing took 0.8378287659725174 seconds)
2022-03-23 22:12:24 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 22:12:24 | INFO | train | epoch 024 | loss 3.066 | ppl 8.38 | wps 8126.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.776 | loss_scale 4 | train_wall 430 | gb_free 13.9 | wall 11775
2022-03-23 22:12:24 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 22:12:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:14:09 | INFO | train_inner | epoch 025:     37 / 157 loss=2.975, ppl=7.86, wps=7633.9, ups=0.3, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.75, loss_scale=4, train_wall=278, gb_free=13.5, wall=11881
2022-03-23 22:18:41 | INFO | train_inner | epoch 025:    137 / 157 loss=3.033, ppl=8.18, wps=9207.7, ups=0.37, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.819, loss_scale=4, train_wall=272, gb_free=13.4, wall=12152
2022-03-23 22:19:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:19:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 22:19:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:19:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably knows.
2022-03-23 22:19:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:19:51 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to run two new pigs.
2022-03-23 22:19:51 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:19:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where happy legs are served with salz and pbuffer.
2022-03-23 22:19:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:20:02 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 22:20:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:20:08 | INFO | fairseq.tasks.translation | example hypothesis: it's like people's responsibility for wildlife survival. and that's a basis for conservation protection in namibia.
2022-03-23 22:20:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:20:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are stuck inside, but the superconductor doesn't like you move because your movements need your energy, and the superconductor disorder.
2022-03-23 22:20:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:20:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, the big constructures of the face and the basic shape, and it restores it through the one information that pulls all the porter structure and fold.
2022-03-23 22:20:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:20:25 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and measured to me here at tedwomen, is that -- tja, when someone said, "well, when someone said," well, "turn on the men on your desk and tell you."
2022-03-23 22:20:25 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:20:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to it -- everything from a continuing system to the prophecy system that allows us to do in the air, or if we can't use the aircraft.
2022-03-23 22:20:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:20:26 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.116 | ppl 8.67 | bleu 23.52 | wps 3511.2 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 26.22
2022-03-23 22:20:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-23 22:20:26 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 22:20:26 | INFO | train | epoch 025 | loss 2.982 | ppl 7.9 | wps 8181.8 | ups 0.33 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.787 | loss_scale 4 | train_wall 430 | gb_free 14.2 | wall 12258
2022-03-23 22:20:27 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 22:20:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:24:11 | INFO | train_inner | epoch 026:     80 / 157 loss=2.88, ppl=7.36, wps=7704.7, ups=0.3, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.73, loss_scale=4, train_wall=277, gb_free=13.5, wall=12483
2022-03-23 22:27:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:27:43 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 22:27:43 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:27:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 22:27:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:27:54 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will be exposed to two new pigs.
2022-03-23 22:27:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:28:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pbuffer.
2022-03-23 22:28:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:28:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all its thoughts are on the track.
2022-03-23 22:28:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:28:12 | INFO | fairseq.tasks.translation | example hypothesis: it's like people's responsibility for wildlife, growing up the number of wildlife animals, and that's a basis for conservation in namibia.
2022-03-23 22:28:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:28:18 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are caught in the inside, but the suprouconductor doesn't like it when they move, because their movements need their movements, and so the superconductor disorder.
2022-03-23 22:28:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:28:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restores the big contextures of the face and the basic shape, and through the theft of information that makes all the portural structure and all the fits.
2022-03-23 22:28:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:28:30 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that's interesting and measuring it up to me here at tedwomen, is that... tyes, when someone said, "turning you to the men on your table and say," if the revolution starts to support you. "
2022-03-23 22:28:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:28:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're at the stack of our airplane was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable system and cooling with a refrigerator, that allows us to use a refrigeration machine to be a particular vehicle, to be a constructive, to the most specific deal with a mechanism, if we could be able to see the most commodity of a commodity of prophector, if we can be connected to a concrete, or the most commodity of prophector.
2022-03-23 22:28:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:28:33 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.85 | ppl 7.21 | bleu 28.29 | wps 3273.4 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 28.29
2022-03-23 22:28:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-23 22:28:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:28:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:28:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 28.29) (writing took 0.8468814110383391 seconds)
2022-03-23 22:28:34 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 22:28:34 | INFO | train | epoch 026 | loss 2.87 | ppl 7.31 | wps 8104.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.735 | loss_scale 4 | train_wall 430 | gb_free 13.8 | wall 12745
2022-03-23 22:28:34 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 22:28:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:29:41 | INFO | train_inner | epoch 027:     23 / 157 loss=2.803, ppl=6.98, wps=7575.3, ups=0.3, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.741, loss_scale=4, train_wall=272, gb_free=14.3, wall=12812
2022-03-23 22:34:15 | INFO | train_inner | epoch 027:    123 / 157 loss=2.818, ppl=7.05, wps=9137.2, ups=0.36, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.718, loss_scale=4, train_wall=274, gb_free=13.1, wall=13086
2022-03-23 22:35:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:35:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepters in the clinic.
2022-03-23 22:35:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:35:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, who probably knows most of you here.
2022-03-23 22:35:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:36:03 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to boost two new pigs.
2022-03-23 22:36:03 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:36:09 | INFO | fairseq.tasks.translation | example hypothesis: for example, french chinese food, where frog legs are served with salz and pitcase.
2022-03-23 22:36:09 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:36:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:36:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:36:20 | INFO | fairseq.tasks.translation | example hypothesis: in this case, as people were taking responsibility for wildlife, the number of wildwildlife grew again, and that's a basis for conservation in namibia.
2022-03-23 22:36:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:36:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are captured inside, but the supraleiters don't like to move, because their movements need their energy, and so the supralo disorder.
2022-03-23 22:36:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:36:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big contextures of the face and the basic shape, and through the diethful information that pulls the whole portion structure and all the fits.
2022-03-23 22:36:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:36:37 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that it's highly interesting and measured to me here at tedwomen, is that -- tja, when the most strictly dinner was summarized when somebody said, "turn you to men in your table and say," if the revolution begins to you. "
2022-03-23 22:36:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:36:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at at our aircraft was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous, refrigerator and refrigeration system that allows us to use aircraft, or to use a particular vehicle.
2022-03-23 22:36:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:36:39 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.797 | ppl 6.95 | bleu 27.9 | wps 3497.5 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 28.29
2022-03-23 22:36:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-23 22:36:39 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 22:36:39 | INFO | train | epoch 027 | loss 2.77 | ppl 6.82 | wps 8145.5 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.702 | loss_scale 4 | train_wall 431 | gb_free 13.5 | wall 13230
2022-03-23 22:36:39 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 22:36:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:39:39 | INFO | train_inner | epoch 028:     66 / 157 loss=2.703, ppl=6.51, wps=7664.2, ups=0.31, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.693, loss_scale=4, train_wall=272, gb_free=14.2, wall=13411
2022-03-23 22:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:43:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 22:43:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:44:01 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 22:44:01 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:44:07 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to write two new pigs.
2022-03-23 22:44:07 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:44:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salz and pffer.
2022-03-23 22:44:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:44:19 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all its thoughts are on the track.
2022-03-23 22:44:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:44:25 | INFO | fairseq.tasks.translation | example hypothesis: in the case, as people took responsibility for wildlife, the number of wildwildlife grew again, and this is a foundation for conservation in namibia.
2022-03-23 22:44:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:44:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside, but the superconductor doesn't like moving, because your movements need energy, and so the superconductor disorder.
2022-03-23 22:44:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:44:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restores the big configurations of the face and the basic shape, and through the dieting of information that contains all the porter structure and all the fits.
2022-03-23 22:44:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:44:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and measured to me here at tedwomen, is that -- tja, when you've already been supported, it's been the best thing when someone said, "turn you to men on your table and say," if the revolution starts to you. "
2022-03-23 22:44:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:44:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane crust was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and a cooling system that allows us to use in the air until you can use a fluid device, and you can use it in the air.
2022-03-23 22:44:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:44:44 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.744 | ppl 6.7 | bleu 29.1 | wps 3347.2 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 29.1
2022-03-23 22:44:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-23 22:44:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:44:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 22:44:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 29.1) (writing took 0.8707705219858326 seconds)
2022-03-23 22:44:45 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 22:44:45 | INFO | train | epoch 028 | loss 2.695 | ppl 6.48 | wps 8111.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.71 | loss_scale 4 | train_wall 431 | gb_free 13.3 | wall 13717
2022-03-23 22:44:46 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 22:44:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:45:11 | INFO | train_inner | epoch 029:      9 / 157 loss=2.723, ppl=6.6, wps=7591.8, ups=0.3, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.743, loss_scale=4, train_wall=276, gb_free=13.2, wall=13743
2022-03-23 22:49:45 | INFO | train_inner | epoch 029:    109 / 157 loss=2.613, ppl=6.12, wps=9188.5, ups=0.37, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.668, loss_scale=4, train_wall=273, gb_free=13.1, wall=14016
2022-03-23 22:51:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 22:52:02 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 22:52:02 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 22:52:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 22:52:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 22:52:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will transcend two new pigs.
2022-03-23 22:52:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 22:52:20 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pbuffer.
2022-03-23 22:52:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 22:52:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just taking some electrodes on its head and understanding exactly what all its thoughts are on the track.
2022-03-23 22:52:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 22:52:32 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people were taking responsibility for wildlife, the number of wildwildwildwildwildwildwildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 22:52:32 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 22:52:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because their movements need, and so the supralty disorder.
2022-03-23 22:52:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 22:52:44 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which restores the big configurations of the face and the basic shape, and through the information that pulls all the portural structure and all a fold.
2022-03-23 22:52:44 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 22:52:50 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it high-interesting and appropriate to me here at tedwomen, is that... tja, when dinner was best summarized when someone said, "turn you to the men on your table and tell you," if the revolution starts to support you. "
2022-03-23 22:52:50 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 22:52:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane the stumest toes was a result that we had to solve unique problems that were connected to operating on the ground -- everything from a continuous variables and a system that allows us to use aircraft, or if you can use a mechanism, or if you can see the market market market market market market, or if you can use a mechanism, if you can use a mechanism, you can see the market market market market market market, if you can see the market market market market market market market market market market market market market market market, or if you can use, if you can use the market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market market, either, or if you can see the market market market market market market market market market market market market market market market market market market,
2022-03-23 22:52:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 22:52:52 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.727 | ppl 6.62 | bleu 29.07 | wps 3276.2 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 29.1
2022-03-23 22:52:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-23 22:52:52 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 22:52:52 | INFO | train | epoch 029 | loss 2.62 | ppl 6.15 | wps 8108 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.693 | loss_scale 4 | train_wall 431 | gb_free 12.9 | wall 14204
2022-03-23 22:52:53 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 22:52:53 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 22:55:15 | INFO | train_inner | epoch 030:     52 / 157 loss=2.607, ppl=6.09, wps=7582.9, ups=0.3, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.688, loss_scale=4, train_wall=274, gb_free=13.5, wall=14347
2022-03-23 22:59:51 | INFO | train_inner | epoch 030:    152 / 157 loss=2.508, ppl=5.69, wps=9192.5, ups=0.36, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.605, loss_scale=4, train_wall=275, gb_free=14.3, wall=14622
2022-03-23 23:00:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:00:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples on the clinic.
2022-03-23 23:00:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:00:16 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you here.
2022-03-23 23:00:16 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:00:21 | INFO | fairseq.tasks.translation | example hypothesis: stars are being created new goldilocks that are going to be transferred by two new pigs.
2022-03-23 23:00:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:00:27 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pp suitcase.
2022-03-23 23:00:27 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:00:33 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what's all his thoughts on the track.
2022-03-23 23:00:33 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:00:39 | INFO | fairseq.tasks.translation | example hypothesis: so in the case of people's responsibility for wildlife, the number of wild animals grew up again, and this is a foundation for conservation in namibia.
2022-03-23 23:00:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:00:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside, but the superconductor doesn't like it if they move, because their movements require their energy, and so the superconducting disorders.
2022-03-23 23:00:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:00:51 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restores the large constraints of the face and the basic shape, and then picking it through this information that pulls all the porter structure and all the ffits.
2022-03-23 23:00:51 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:00:56 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that's really interesting and measuring it to me here at tedwomen is that -- tja, dinner was summarized at the best when someone said, "turn you to men on your table and tell them," if the revolution starts to support you. "
2022-03-23 23:00:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:00:58 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our plane is a result that we had to solve the unique problems associated with doing it on the ground -- everything from a continuous variables and a system of refrigeration, which allows us to use aircraft and to use a particular device, until we get the propelled to a particular device.
2022-03-23 23:00:58 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:00:58 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.657 | ppl 6.31 | bleu 29.98 | wps 3422.2 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 29.98
2022-03-23 23:00:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-23 23:00:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 23:00:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 23:00:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 30 @ 4705 updates, score 29.98) (writing took 0.9078249149606563 seconds)
2022-03-23 23:00:59 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 23:00:59 | INFO | train | epoch 030 | loss 2.529 | ppl 5.77 | wps 8119.9 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.631 | loss_scale 4 | train_wall 431 | gb_free 12.9 | wall 14690
2022-03-23 23:00:59 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 23:00:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:05:26 | INFO | train_inner | epoch 031:     95 / 157 loss=2.486, ppl=5.6, wps=7631, ups=0.3, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.635, loss_scale=4, train_wall=280, gb_free=13.1, wall=14957
2022-03-23 23:08:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:08:16 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepples in the clinic.
2022-03-23 23:08:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:08:22 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline from doha, which probably most of you know here.
2022-03-23 23:08:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:08:28 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two new vibrations.
2022-03-23 23:08:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:08:33 | INFO | fairseq.tasks.translation | example hypothesis: there's french chinese food, for example, where frog legs are served with salz and pffer.
2022-03-23 23:08:33 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:08:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just taking some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 23:08:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:08:45 | INFO | fairseq.tasks.translation | example hypothesis: in the case of how people took responsibility for wildlife, the number of wildwildwildlife grew again, and that's become a basis for conservation in namibia.
2022-03-23 23:08:45 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:08:51 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are caught inside, but the superconductor doesn't like moving, because your movements need your energy, and so the superconductor.
2022-03-23 23:08:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:08:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restores the big constraints of the face and the basic shape, and pulls it through this information that pulls the whole porter structure and all the fffits.
2022-03-23 23:08:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:09:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to me here at tedwomen is that... tja, when he was given dinner, it was best summarized when someone said, "turn you to men on your table and say," if the revolution begins, then we support you. "the truth is that we've been supporting you for a long time."
2022-03-23 23:09:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:09:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still an invention, and a large part of the design work that we're on on our aircraft was a result that we had to solve the unique problems that were connected to it -- everything from a continuous variable driver and a system of refrigeration, that allows us to use aircraft in a machine, or if we had to be able to solve the solutions to a particular car car car car system, or if you can either drive it.
2022-03-23 23:09:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:09:05 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.63 | ppl 6.19 | bleu 30.03 | wps 3373.2 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.03
2022-03-23 23:09:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-23 23:09:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 23:09:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 23:09:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.03) (writing took 0.8965347009943798 seconds)
2022-03-23 23:09:06 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 23:09:06 | INFO | train | epoch 031 | loss 2.478 | ppl 5.57 | wps 8111.6 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.644 | loss_scale 4 | train_wall 431 | gb_free 12.9 | wall 15177
2022-03-23 23:09:06 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 23:09:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:10:52 | INFO | train_inner | epoch 032:     38 / 157 loss=2.411, ppl=5.32, wps=7623.5, ups=0.31, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.625, loss_scale=4, train_wall=271, gb_free=13.9, wall=15284
2022-03-23 23:15:28 | INFO | train_inner | epoch 032:    138 / 157 loss=2.438, ppl=5.42, wps=9170.1, ups=0.36, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.687, loss_scale=4, train_wall=275, gb_free=13.9, wall=15559
2022-03-23 23:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:16:23 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:16:23 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:16:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you here.
2022-03-23 23:16:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:16:34 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will transcend two new pigs.
2022-03-23 23:16:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:16:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pitcase.
2022-03-23 23:16:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:16:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all of its thoughts are on the track.
2022-03-23 23:16:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:16:52 | INFO | fairseq.tasks.translation | example hypothesis: and in the case, as people were responsible for wildlife, the number of wildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 23:16:52 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:16:58 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it, if they move, because their movements need their movements, and so the superconductor disorder.
2022-03-23 23:16:58 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:17:04 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that restores the large constraints of the face, and the basic shape, and it travels through the information that pulls the entire porn structure and all the ffits.
2022-03-23 23:17:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:17:10 | INFO | fairseq.tasks.translation | example hypothesis: it's one of the reasons that makes it interesting and measured to me here at tedwomen is that -- tja, when he stripped dinner was best summarized when someone said, "turn you to men in your desk and tell you, 'if the revolution begins, then we'll support you.' the truth is that we've already been supporting you for a long time for silly carbono."
2022-03-23 23:17:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:17:12 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention is still the mother of invention, and a large part of the design work that we are on our plane was a result that we had to solve the unique problems that were connected to it -- everything from a continuous version and cooling system that allows us to use in the aircraft until you go to a particular vehicle, or whatever you can see in the prophecy, it's allowed to do.
2022-03-23 23:17:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:17:12 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.605 | ppl 6.08 | bleu 29.88 | wps 3326.5 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.03
2022-03-23 23:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-23 23:17:12 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 23:17:12 | INFO | train | epoch 032 | loss 2.417 | ppl 5.34 | wps 8114.7 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.655 | loss_scale 4 | train_wall 431 | gb_free 14 | wall 15664
2022-03-23 23:17:13 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 23:17:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:20:57 | INFO | train_inner | epoch 033:     81 / 157 loss=2.311, ppl=4.96, wps=7621.5, ups=0.3, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.613, loss_scale=4, train_wall=273, gb_free=13.6, wall=15889
2022-03-23 23:24:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:24:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:24:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:24:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:24:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:24:42 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of newspapers that are going to create two new gay transscriptions.
2022-03-23 23:24:42 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:24:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and ppeffer.
2022-03-23 23:24:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:24:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 23:24:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:25:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the human responsibility for wildlife, the number of wild wildlife raised again, and that's become a basis for conservation in namibia.
2022-03-23 23:25:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:25:06 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some magnetic field lines are trapped inside, but the superconductor doesn't like moving because their movements use, and so the superconductor disorder.
2022-03-23 23:25:06 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:25:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection from this reflection, we can start with a traditional facial can, which refuse the large contextures of the face and the basic shape, and reconvicts it through the theft of information that pulls the whole porter structure and all the ffloods.
2022-03-23 23:25:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:25:18 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons it was very interesting and measured to me here at tedwomen is that... tja, when strictly dinner, it was best summarized when someone said, "turn you to men on your table and tell them," if the revolution starts to support you. '"the truth is that women love that we've already started supporting you for a long period of time."
2022-03-23 23:25:18 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:25:20 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on our aircraft was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continual variables, and a cooling system that allows us to use aircraft in the aircraft, or to go to a specialty, to a local transportation, to a specialty machine, to a specialty, if you can either drive the ground, to a mechanism, if you can see the propheheating machine in the air conditioner, or to the ground, you can be able, you can be able, you can be able, you can be able, you can be able, you would be able to do it would be able to do it, you can use it to do it to do it.
2022-03-23 23:25:20 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:25:20 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.563 | ppl 5.91 | bleu 31.39 | wps 3249.5 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.39
2022-03-23 23:25:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-23 23:25:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 23:25:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt
2022-03-23 23:25:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_kneser_n2_d0.32_#1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.39) (writing took 0.85271795198787 seconds)
2022-03-23 23:25:21 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 23:25:21 | INFO | train | epoch 033 | loss 2.36 | ppl 5.13 | wps 8077.4 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.629 | loss_scale 4 | train_wall 431 | gb_free 13.5 | wall 16153
2022-03-23 23:25:22 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 23:25:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:26:31 | INFO | train_inner | epoch 034:     24 / 157 loss=2.399, ppl=5.27, wps=7539.1, ups=0.3, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.64, loss_scale=4, train_wall=276, gb_free=13.4, wall=16222
2022-03-23 23:31:03 | INFO | train_inner | epoch 034:    124 / 157 loss=2.279, ppl=4.85, wps=9214.2, ups=0.37, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.625, loss_scale=4, train_wall=272, gb_free=13.2, wall=16495
2022-03-23 23:32:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:32:38 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepples in the clinic.
2022-03-23 23:32:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:32:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:32:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:32:49 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks of dinments that will transcend two new swawns.
2022-03-23 23:32:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:32:55 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pffer.
2022-03-23 23:32:55 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:33:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all of its thoughts are on the track.
2022-03-23 23:33:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:33:07 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife, the number of wildlife grows up again, and this is a basis for conservation in namibia.
2022-03-23 23:33:07 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:33:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it if you move, because your movements are using your energy, and the superconductor's disorders.
2022-03-23 23:33:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:33:20 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the large constraints of the face, and we can then restore it through the very basic kind of information that pulls the entire porter structure and all the ffits into a fold.
2022-03-23 23:33:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:33:26 | INFO | fairseq.tasks.translation | example hypothesis: , one of the reasons that makes it very interesting and appropriate to me here at tedwomen is that -- well, when i was striking dinner, it was best summarized when someone said, "turn you to men in your table and tell them, 'if the revolution starts, then we support you.'" the truth, love women, we've already been supporting you for a long time in our spring. "
2022-03-23 23:33:26 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:33:28 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the need still is the mother of invention, and a large part of the design work that we're at our plane the most proud of our aircraft was a result that we had to solve the unique problems associated with it to operate on the ground -- everything from a continuous variable drivers and a cooling system of the refrigerating that allows us to use a flying machine in the go-and-traffic, and if you can see the propeller, you can either be able to be able to be able to be able to be able to be able to be able to be able to use the fabricate the fabric, if you're connected to the fabric.
2022-03-23 23:33:28 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:33:28 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.566 | ppl 5.92 | bleu 31.27 | wps 3250.6 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.39
2022-03-23 23:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-23 23:33:28 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 23:33:28 | INFO | train | epoch 034 | loss 2.313 | ppl 4.97 | wps 8108.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.642 | loss_scale 4 | train_wall 430 | gb_free 13.2 | wall 16640
2022-03-23 23:33:29 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 23:33:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:36:34 | INFO | train_inner | epoch 035:     67 / 157 loss=2.329, ppl=5.03, wps=7587.4, ups=0.3, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.651, loss_scale=4, train_wall=274, gb_free=14.2, wall=16826
2022-03-23 23:40:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:40:45 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepples in the clinic.
2022-03-23 23:40:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:40:50 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 23:40:50 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:40:56 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of displays that are going to translate two new pigs.
2022-03-23 23:40:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:41:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frogs are served with salz and pepper.
2022-03-23 23:41:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:41:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on its head and understand exactly what all his thoughts are on the track.
2022-03-23 23:41:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:41:14 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife, the number of wildwildlife grew again, and this has become a basis for conservation in namibia.
2022-03-23 23:41:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:41:20 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are trapped inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 23:41:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:41:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information coming from this reflection that comes from this reflection, we can start with a traditional facial can that restores the big configurations of the face and the basic shape, and through the theft of information that pulls the whole porting structure and all the functions.
2022-03-23 23:41:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:41:32 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it really interesting and appropriate for me to be here at tedwomen is that -- tyes, when you were striking dinner, it was best summarized when someone said, "turn you to men on your table and tell you, 'when the revolution starts to support you.'" the truth is that we've been supporting you for a long time. "
2022-03-23 23:41:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:41:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the need is still the mother of invention, and a lot of the design work that we're on our plane the staggering toe was a result that we had to solve the unique problems associated with operating it on the ground -- everything from a continuously variable drives and a cooling system of refrigeration that allows us to use an aircraft machine in traffic and go-to-a particular propelled thing when you can see that's connected to a promoting device, if you can use it in the air conditioning it in the air conditioning space, or whatever you can do it, if you can see it's in the air conditioning it's in the air conditional air conditioning it's in the air conditioning it's in the air conditioning it's in the air conditioning place, if you can do it's in the air conditioning it's in the air conditioning around the air conditioning it's in the ground,
2022-03-23 23:41:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:41:35 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.532 | ppl 5.78 | bleu 31.06 | wps 3286.2 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.39
2022-03-23 23:41:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-23 23:41:35 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 23:41:35 | INFO | train | epoch 035 | loss 2.255 | ppl 4.77 | wps 8120.8 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.601 | loss_scale 4 | train_wall 430 | gb_free 12.9 | wall 17126
2022-03-23 23:41:35 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 23:41:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 23:42:01 | INFO | train_inner | epoch 036:     10 / 157 loss=2.231, ppl=4.7, wps=7618, ups=0.31, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.585, loss_scale=4, train_wall=271, gb_free=14.2, wall=17153
2022-03-23 23:46:37 | INFO | train_inner | epoch 036:    110 / 157 loss=2.186, ppl=4.55, wps=9183.3, ups=0.36, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.588, loss_scale=4, train_wall=275, gb_free=14.2, wall=17428
2022-03-23 23:48:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 23:48:50 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppers in the clinic.
2022-03-23 23:48:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 23:48:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 23:48:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 23:49:02 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to be translated by two new pigs.
2022-03-23 23:49:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 23:49:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are served with salz and pepper.
2022-03-23 23:49:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 23:49:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just take some electrodes on its head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:49:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 23:49:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildwildlife grew up again, and that's become a basis for conservation in namibia.
2022-03-23 23:49:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 23:49:26 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if they move, because they use their movements, and so the superconduction.
2022-03-23 23:49:26 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 23:49:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big contextures of the face, and the basic form, and then will reconcile it through the theft of the information that pulls the entire porter structure and all the fits.
2022-03-23 23:49:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 23:49:39 | INFO | fairseq.tasks.translation | example hypothesis: one of the reasons that makes it very interesting and measured to me here at tedwomen, is that -- well, when constricted dinner was best summarized when someone said, "turn to men on your desk and tell them, 'when the revolution begins to be, then we'll support you.'" 'the truth is that we've already started supporting you at this topic for a long period of time. "
2022-03-23 23:49:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 23:49:41 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the need is still the mother of invention, and a big part of the design work that we're on our aircraft is a result that we had to solve the unique problems that were connected to operating on the ground -- everything, from a continuously variable drives, and a cooling system of refrigeration that allows us to use aircraft in the aircraft, to a particular gas station, or to a promoteness, to a propulsion system that is to be allowed to be reliable, to be reliable, or to be reliable to be reliable to the ground, or to be reliable to be reliable to be reliable to be reliable to be reliable to be reliance for a state of a state of a state of a state of a state of a fluctumb, so that we could be reliance, or a state of a state of a state of a state of a state of a fluctumb, so that we could be,
2022-03-23 23:49:41 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 23:49:41 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.528 | ppl 5.77 | bleu 31.34 | wps 3180.7 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.39
2022-03-23 23:49:41 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 23:49:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-23 23:49:41 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 23:49:41 | INFO | train | epoch 036 | loss 2.205 | ppl 4.61 | wps 8114.3 | ups 0.32 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.608 | loss_scale 4 | train_wall 429 | gb_free 13.4 | wall 17613
2022-03-23 23:49:41 | INFO | fairseq_cli.train | done training in 17612.4 seconds
