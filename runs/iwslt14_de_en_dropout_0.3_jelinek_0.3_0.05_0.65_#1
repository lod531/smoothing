Sender: LSF System <lsfadmin@eu-g3-054>
Subject: Job 210595938: <iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 11:40:18 2022
Job was executed on host(s) <eu-g3-054>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 11:40:29 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 11:40:29 2022
Terminated at Wed Mar 23 13:15:17 2022
Results reported at Wed Mar 23 13:15:17 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.3 --weight-decay 0.0001 --criterion jelinek_mercer_smoothing --jelinek-n 2 --alphas \(0.3,0.05,0.65\) --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5675.16 sec.
    Max Memory :                                 5678 MB
    Average Memory :                             4324.18 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               14322.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                15
    Run time :                                   5689 sec.
    Turnaround time :                            5699 sec.

The output (if any) follows:

2022-03-23 11:40:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, alphas='(0.3,0.05,0.65)', amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='jelinek_mercer_smoothing', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, jelinek_n=2, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'jelinek_mercer_smoothing', 'alphas': '(0.3,0.05,0.65)', 'jelinek_n': 2, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 11:40:36 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-23 11:40:36 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-23 11:40:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:40:37 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:40:37 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
Calculating frequency stats:
  0%|          | 0/160239 [00:00<?, ?it/s]  1%|          | 1128/160239 [00:00<00:14, 11268.06it/s]  2%|▏         | 2503/160239 [00:00<00:12, 12727.09it/s]  2%|▏         | 3903/160239 [00:00<00:11, 13300.15it/s]  3%|▎         | 5234/160239 [00:00<00:11, 13212.84it/s]  4%|▍         | 6588/160239 [00:00<00:11, 13329.82it/s]  5%|▍         | 7922/160239 [00:00<00:11, 13041.43it/s]  6%|▌         | 9228/160239 [00:00<00:11, 12914.49it/s]  7%|▋         | 10583/160239 [00:00<00:11, 13112.81it/s]  7%|▋         | 11896/160239 [00:00<00:11, 13111.58it/s]  8%|▊         | 13219/160239 [00:01<00:11, 13144.85it/s]  9%|▉         | 14534/160239 [00:01<00:11, 13083.94it/s] 10%|▉         | 15843/160239 [00:01<00:11, 12860.45it/s] 11%|█         | 17130/160239 [00:01<00:11, 12686.83it/s] 12%|█▏        | 18433/160239 [00:01<00:11, 12787.55it/s] 12%|█▏        | 19812/160239 [00:01<00:10, 13083.90it/s] 13%|█▎        | 21122/160239 [00:01<00:10, 13062.19it/s] 14%|█▍        | 22429/160239 [00:01<00:10, 12967.00it/s] 15%|█▍        | 23727/160239 [00:01<00:10, 12942.49it/s] 16%|█▌        | 25022/160239 [00:01<00:10, 12874.43it/s] 16%|█▋        | 26310/160239 [00:02<00:10, 12751.31it/s] 17%|█▋        | 27587/160239 [00:02<00:10, 12756.54it/s] 18%|█▊        | 28905/160239 [00:02<00:10, 12878.75it/s] 19%|█▉        | 30194/160239 [00:02<00:10, 12654.44it/s] 20%|█▉        | 31577/160239 [00:02<00:09, 13000.25it/s] 21%|██        | 32879/160239 [00:02<00:09, 12932.03it/s] 21%|██▏       | 34174/160239 [00:02<00:10, 12566.37it/s] 22%|██▏       | 35434/160239 [00:02<00:10, 12474.37it/s] 23%|██▎       | 36802/160239 [00:02<00:09, 12826.48it/s] 24%|██▍       | 38087/160239 [00:02<00:09, 12818.21it/s] 25%|██▍       | 39384/160239 [00:03<00:09, 12862.42it/s] 25%|██▌       | 40724/160239 [00:03<00:09, 13019.11it/s] 26%|██▌       | 42027/160239 [00:03<00:09, 12815.97it/s] 27%|██▋       | 43310/160239 [00:03<00:09, 12522.73it/s] 28%|██▊       | 44565/160239 [00:03<00:09, 12311.94it/s] 29%|██▊       | 45972/160239 [00:03<00:08, 12819.46it/s] 29%|██▉       | 47264/160239 [00:03<00:08, 12846.94it/s] 30%|███       | 48551/160239 [00:03<00:08, 12784.83it/s] 31%|███       | 49846/160239 [00:03<00:08, 12833.17it/s] 32%|███▏      | 51179/160239 [00:03<00:08, 12980.49it/s] 33%|███▎      | 52519/160239 [00:04<00:08, 13105.05it/s] 34%|███▎      | 53831/160239 [00:04<00:08, 12926.95it/s] 34%|███▍      | 55140/160239 [00:04<00:08, 12972.15it/s] 35%|███▌      | 56438/160239 [00:04<00:08, 12907.69it/s] 36%|███▌      | 57772/160239 [00:04<00:07, 13035.68it/s] 37%|███▋      | 59144/160239 [00:04<00:07, 13238.54it/s] 38%|███▊      | 60469/160239 [00:04<00:07, 13213.45it/s] 39%|███▊      | 61791/160239 [00:04<00:07, 12899.02it/s] 39%|███▉      | 63185/160239 [00:04<00:07, 13204.15it/s] 40%|████      | 64610/160239 [00:04<00:07, 13513.29it/s] 41%|████      | 66017/160239 [00:05<00:06, 13677.29it/s] 42%|████▏     | 67387/160239 [00:05<00:07, 13241.79it/s] 43%|████▎     | 68715/160239 [00:05<00:07, 12936.31it/s] 44%|████▎     | 70056/160239 [00:05<00:06, 13072.85it/s] 45%|████▍     | 71402/160239 [00:05<00:06, 13185.33it/s] 45%|████▌     | 72723/160239 [00:05<00:06, 12985.20it/s] 46%|████▌     | 74024/160239 [00:05<00:06, 12923.84it/s] 47%|████▋     | 75318/160239 [00:05<00:06, 12816.38it/s] 48%|████▊     | 76624/160239 [00:05<00:06, 12886.64it/s] 49%|████▊     | 78025/160239 [00:06<00:06, 13208.58it/s] 50%|████▉     | 79386/160239 [00:06<00:06, 13325.01it/s] 50%|█████     | 80793/160239 [00:06<00:05, 13546.67it/s] 51%|█████▏    | 82149/160239 [00:06<00:05, 13429.27it/s] 52%|█████▏    | 83509/160239 [00:06<00:05, 13479.28it/s] 53%|█████▎    | 84858/160239 [00:06<00:05, 13307.77it/s] 54%|█████▍    | 86286/160239 [00:06<00:05, 13592.09it/s] 55%|█████▍    | 87704/160239 [00:06<00:05, 13760.96it/s] 56%|█████▌    | 89081/160239 [00:06<00:05, 13514.68it/s] 56%|█████▋    | 90434/160239 [00:06<00:05, 13517.51it/s] 57%|█████▋    | 91787/160239 [00:07<00:05, 13296.93it/s] 58%|█████▊    | 93118/160239 [00:07<00:05, 13253.94it/s] 59%|█████▉    | 94445/160239 [00:07<00:05, 13017.10it/s] 60%|█████▉    | 95801/160239 [00:07<00:04, 13175.74it/s] 61%|██████    | 97120/160239 [00:07<00:04, 13143.40it/s] 61%|██████▏   | 98447/160239 [00:07<00:04, 13180.53it/s] 62%|██████▏   | 99766/160239 [00:07<00:04, 13162.34it/s] 63%|██████▎   | 101112/160239 [00:07<00:04, 13249.97it/s] 64%|██████▍   | 102438/160239 [00:07<00:04, 13236.52it/s] 65%|██████▍   | 103762/160239 [00:07<00:04, 12892.46it/s] 66%|██████▌   | 105189/160239 [00:08<00:04, 13296.45it/s] 66%|██████▋   | 106521/160239 [00:08<00:04, 13247.30it/s] 67%|██████▋   | 107848/160239 [00:08<00:04, 12918.78it/s] 68%|██████▊   | 109143/160239 [00:08<00:04, 12650.97it/s] 69%|██████▉   | 110431/160239 [00:08<00:03, 12716.53it/s] 70%|██████▉   | 111849/160239 [00:08<00:03, 13138.34it/s] 71%|███████   | 113166/160239 [00:08<00:03, 12958.97it/s] 71%|███████▏  | 114509/160239 [00:08<00:03, 13097.00it/s] 72%|███████▏  | 115826/160239 [00:08<00:03, 13116.11it/s] 73%|███████▎  | 117139/160239 [00:08<00:03, 12955.53it/s] 74%|███████▍  | 118451/160239 [00:09<00:03, 12999.42it/s] 75%|███████▍  | 119877/160239 [00:09<00:03, 13371.24it/s] 76%|███████▌  | 121216/160239 [00:09<00:02, 13119.14it/s] 77%|███████▋  | 122642/160239 [00:09<00:02, 13453.60it/s] 77%|███████▋  | 123990/160239 [00:09<00:02, 13259.29it/s] 78%|███████▊  | 125318/160239 [00:09<00:02, 12902.26it/s] 79%|███████▉  | 126640/160239 [00:09<00:02, 12993.58it/s] 80%|███████▉  | 128000/160239 [00:09<00:02, 13168.96it/s] 81%|████████  | 129319/160239 [00:09<00:02, 13117.20it/s] 82%|████████▏ | 130633/160239 [00:10<00:02, 12702.64it/s] 82%|████████▏ | 131926/160239 [00:10<00:02, 12767.98it/s] 83%|████████▎ | 133208/160239 [00:10<00:02, 12782.45it/s] 84%|████████▍ | 134489/160239 [00:10<00:02, 12681.11it/s] 85%|████████▍ | 135807/160239 [00:10<00:01, 12822.01it/s] 86%|████████▌ | 137148/160239 [00:10<00:01, 12991.41it/s] 86%|████████▋ | 138497/160239 [00:10<00:01, 13138.42it/s] 87%|████████▋ | 139868/160239 [00:10<00:01, 13308.36it/s] 88%|████████▊ | 141246/160239 [00:10<00:01, 13445.78it/s] 89%|████████▉ | 142592/160239 [00:10<00:01, 13054.92it/s] 90%|████████▉ | 143901/160239 [00:11<00:01, 13055.53it/s] 91%|█████████ | 145209/160239 [00:11<00:01, 12997.84it/s] 91%|█████████▏| 146511/160239 [00:11<00:01, 12812.32it/s] 92%|█████████▏| 147798/160239 [00:11<00:00, 12826.53it/s] 93%|█████████▎| 149082/160239 [00:11<00:00, 12476.90it/s] 94%|█████████▍| 150416/160239 [00:11<00:00, 12726.38it/s] 95%|█████████▍| 151750/160239 [00:11<00:00, 12905.17it/s] 96%|█████████▌| 153043/160239 [00:11<00:00, 12900.24it/s] 96%|█████████▋| 154364/160239 [00:11<00:00, 12990.02it/s] 97%|█████████▋| 155732/160239 [00:11<00:00, 13188.27it/s] 98%|█████████▊| 157084/160239 [00:12<00:00, 13286.79it/s] 99%|█████████▉| 158414/160239 [00:12<00:00, 12959.39it/s]100%|█████████▉| 159789/160239 [00:12<00:00, 13188.72it/s]100%|██████████| 160239/160239 [00:12<00:00, 13033.01it/s]

gathering stats for n=1
  0%|          | 0/160239 [00:00<?, ?it/s]  2%|▏         | 3687/160239 [00:00<00:04, 36865.46it/s]  5%|▍         | 7613/160239 [00:00<00:03, 38268.17it/s]  7%|▋         | 11562/160239 [00:00<00:03, 38825.07it/s] 10%|▉         | 15503/160239 [00:00<00:03, 39053.08it/s] 12%|█▏        | 19409/160239 [00:00<00:03, 38962.14it/s] 15%|█▍        | 23385/160239 [00:00<00:03, 39231.14it/s] 17%|█▋        | 27338/160239 [00:00<00:03, 39328.13it/s] 20%|█▉        | 31286/160239 [00:00<00:03, 39375.86it/s] 22%|██▏       | 35224/160239 [00:00<00:03, 39066.62it/s] 24%|██▍       | 39185/160239 [00:01<00:03, 39230.79it/s] 27%|██▋       | 43109/160239 [00:01<00:03, 38965.69it/s] 29%|██▉       | 47007/160239 [00:01<00:02, 38950.93it/s] 32%|███▏      | 50938/160239 [00:01<00:02, 39058.31it/s] 34%|███▍      | 54847/160239 [00:01<00:02, 39063.46it/s] 37%|███▋      | 58930/160239 [00:01<00:02, 39592.11it/s] 39%|███▉      | 62978/160239 [00:01<00:02, 39857.81it/s] 42%|████▏     | 67110/160239 [00:01<00:02, 40295.94it/s] 44%|████▍     | 71140/160239 [00:01<00:02, 39960.56it/s] 47%|████▋     | 75137/160239 [00:01<00:02, 39514.43it/s] 49%|████▉     | 79222/160239 [00:02<00:02, 39904.14it/s] 52%|█████▏    | 83331/160239 [00:02<00:01, 40252.15it/s] 55%|█████▍    | 87466/160239 [00:02<00:01, 40578.87it/s] 57%|█████▋    | 91526/160239 [00:02<00:01, 40413.32it/s] 60%|█████▉    | 95569/160239 [00:02<00:01, 40103.69it/s] 62%|██████▏   | 99581/160239 [00:02<00:01, 39990.70it/s] 65%|██████▍   | 103581/160239 [00:02<00:01, 39883.06it/s] 67%|██████▋   | 107570/160239 [00:02<00:01, 39822.41it/s] 70%|██████▉   | 111553/160239 [00:02<00:01, 39582.49it/s] 72%|███████▏  | 115574/160239 [00:02<00:01, 39764.83it/s] 75%|███████▍  | 119596/160239 [00:03<00:01, 39897.09it/s] 77%|███████▋  | 123656/160239 [00:03<00:00, 40104.90it/s] 80%|███████▉  | 127667/160239 [00:03<00:00, 39951.57it/s] 82%|████████▏ | 131663/160239 [00:03<00:00, 39592.66it/s] 85%|████████▍ | 135624/160239 [00:03<00:00, 39408.81it/s] 87%|████████▋ | 139702/160239 [00:03<00:00, 39814.67it/s] 90%|████████▉ | 143690/160239 [00:03<00:00, 39832.11it/s] 92%|█████████▏| 147674/160239 [00:03<00:00, 39393.46it/s] 95%|█████████▍| 151615/160239 [00:03<00:00, 39133.65it/s] 97%|█████████▋| 155677/160239 [00:03<00:00, 39572.39it/s]100%|█████████▉| 159649/160239 [00:04<00:00, 39611.49it/s]100%|██████████| 160239/160239 [00:04<00:00, 39584.23it/s]

transferring to GPU memory
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 2197.12it/s]2022-03-23 11:41:01 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-23 11:41:01 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-23 11:41:01 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-23 11:41:01 | INFO | fairseq_cli.train | criterion: JelinekMercerSmoothingCriterion
2022-03-23 11:41:01 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-23 11:41:01 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-23 11:41:01 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-23 11:41:01 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 11:41:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:41:01 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 11:41:01 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 11:41:01 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 11:41:01 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-23 11:41:01 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 11:41:01 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 11:41:01 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-23 11:41:01 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-23 11:41:01 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-23 11:41:02 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 11:41:02 | INFO | fairseq_cli.train | Start iterating over samples

2022-03-23 11:41:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 11:41:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 11:41:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 11:41:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 11:41:43 | INFO | train_inner | epoch 001:    104 / 157 loss=13.605, ppl=12457.4, wps=66708, ups=2.65, wpb=25146.2, bsz=969, num_updates=100, lr=1.25e-05, gnorm=2.544, loss_scale=8, train_wall=41, gb_free=12.1, wall=42
2022-03-23 11:42:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 11:42:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example hypothesis: ...
2022-03-23 11:42:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:42:12 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,.......
2022-03-23 11:42:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:42:15 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,
2022-03-23 11:42:15 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:42:19 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:19 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:42:23 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:23 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:42:29 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:42:34 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:42:41 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-23 11:42:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:42:44 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 13.731 | ppl 13600.8 | bleu 0.01 | wps 4363.3 | wpb 17862.2 | bsz 728.3 | num_updates 153
2022-03-23 11:42:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 153 updates
2022-03-23 11:42:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:42:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 1 @ 153 updates, score 0.01) (writing took 1.627730917010922 seconds)
2022-03-23 11:42:45 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 11:42:45 | INFO | train | epoch 001 | loss 13.262 | ppl 9822.3 | wps 38388.5 | ups 1.53 | wpb 25079.4 | bsz 998 | num_updates 153 | lr 1.9125e-05 | gnorm 2.003 | loss_scale 8 | train_wall 60 | gb_free 22.3 | wall 104
KL Stats: Epoch 1 Divergences: Uniform: 0.5078770778978284 Unigram: 1.4674023436185528
2022-03-23 11:42:46 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 11:42:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:43:03 | INFO | train_inner | epoch 002:     47 / 157 loss=12.319, ppl=5110.27, wps=31609, ups=1.25, wpb=25333.2, bsz=1104.8, num_updates=200, lr=2.5e-05, gnorm=0.91, loss_scale=8, train_wall=37, gb_free=12.9, wall=122
2022-03-23 11:43:41 | INFO | train_inner | epoch 002:    147 / 157 loss=12.008, ppl=4119.01, wps=66730.6, ups=2.65, wpb=25185, bsz=961.8, num_updates=300, lr=3.75e-05, gnorm=0.958, loss_scale=8, train_wall=37, gb_free=12.2, wall=160
2022-03-23 11:43:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:43:48 | INFO | fairseq.tasks.translation | example hypothesis: we we.
2022-03-23 11:43:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:43:51 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the.
2022-03-23 11:43:51 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:43:54 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the.
2022-03-23 11:43:54 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:43:58 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,.
2022-03-23 11:43:58 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:44:02 | INFO | fairseq.tasks.translation | example hypothesis: and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:44:02 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:44:06 | INFO | fairseq.tasks.translation | example hypothesis: and and and and and and the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-23 11:44:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:44:11 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:44:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:44:16 | INFO | fairseq.tasks.translation | example hypothesis: and and and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:44:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:44:21 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:44:21 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:44:22 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.
2022-03-23 11:44:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:44:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 13.164 | ppl 9175.46 | bleu 0.02 | wps 4736.8 | wpb 17862.2 | bsz 728.3 | num_updates 310 | best_bleu 0.02
2022-03-23 11:44:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 310 updates
2022-03-23 11:44:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:44:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:44:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 2 @ 310 updates, score 0.02) (writing took 1.6659891009912826 seconds)
2022-03-23 11:44:24 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 11:44:24 | INFO | train | epoch 002 | loss 12.019 | ppl 4151.47 | wps 40029.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 310 | lr 3.875e-05 | gnorm 0.934 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 203
KL Stats: Epoch 2 Divergences: Uniform: 0.5144803189077888 Unigram: 0.4700453520936403
2022-03-23 11:44:24 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 11:44:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:44:58 | INFO | train_inner | epoch 003:     90 / 157 loss=11.815, ppl=3603.35, wps=32090.6, ups=1.31, wpb=24585.2, bsz=969, num_updates=400, lr=5e-05, gnorm=0.987, loss_scale=8, train_wall=36, gb_free=11.8, wall=237
2022-03-23 11:45:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:45:26 | INFO | fairseq.tasks.translation | example hypothesis: and we we we we we.
2022-03-23 11:45:26 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example hypothesis: it's's the the the the the the the the the.
2022-03-23 11:45:30 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:45:34 | INFO | fairseq.tasks.translation | example hypothesis: and it's's a.
2022-03-23 11:45:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:45:39 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, it's's, it's's's.
2022-03-23 11:45:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:45:44 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, it's's, it's's's's, it's's, it's's's's, and it's's, it's's's's's's's's's.
2022-03-23 11:45:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:45:50 | INFO | fairseq.tasks.translation | example hypothesis: and and it's's's, and and and and and and and and and the's's's's's, and and and the the the the the the the the the the of the the of the of the, and and and and and and and and and and and and and and the
2022-03-23 11:45:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:45:56 | INFO | fairseq.tasks.translation | example hypothesis: and it's, it's, and it's's's, and it's, and it's's's, it's's, and it's's's's's, and it's's's, and it's's's's's, and it's's's's's's's's's's, and it's, and it's's's's
2022-03-23 11:45:56 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:46:02 | INFO | fairseq.tasks.translation | example hypothesis: and we, we, and we, and we, and we, and we, and we, and and we the the, and the the the the the, and the the the the, and and the the the, and and we the the the, and the the the the the, and the the the the the, and and the the the the, and and the the the the the, and and the the the the the the the, and and we
2022-03-23 11:46:02 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:46:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's's's, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:46:09 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:46:12 | INFO | fairseq.tasks.translation | example hypothesis: and it's's, it's's's, we's's's, and the, it's's's's, and the, and the, and we's's's's's's's's's's's's's's's's's's's's's's's's's's's, and the, and the, and the to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to,
2022-03-23 11:46:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:46:12 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13 | ppl 8192.4 | bleu 0.17 | wps 3603.2 | wpb 17862.2 | bsz 728.3 | num_updates 467 | best_bleu 0.17
2022-03-23 11:46:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 467 updates
2022-03-23 11:46:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 3 @ 467 updates, score 0.17) (writing took 1.8277723109931685 seconds)
2022-03-23 11:46:13 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 11:46:13 | INFO | train | epoch 003 | loss 11.704 | ppl 3336.16 | wps 36053 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 467 | lr 5.8375e-05 | gnorm 1.018 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 312
KL Stats: Epoch 3 Divergences: Uniform: 0.5906508478006589 Unigram: 0.47003712301191347
2022-03-23 11:46:14 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 11:46:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:46:27 | INFO | train_inner | epoch 004:     33 / 157 loss=11.592, ppl=3087.19, wps=28660, ups=1.13, wpb=25454.8, bsz=1088.2, num_updates=500, lr=6.25e-05, gnorm=1.029, loss_scale=8, train_wall=37, gb_free=12, wall=325
2022-03-23 11:47:04 | INFO | train_inner | epoch 004:    133 / 157 loss=11.465, ppl=2827.25, wps=66893.7, ups=2.65, wpb=25263.8, bsz=1024.8, num_updates=600, lr=7.5e-05, gnorm=1.079, loss_scale=8, train_wall=37, gb_free=10.8, wall=363
2022-03-23 11:47:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:47:17 | INFO | fairseq.tasks.translation | example hypothesis: we're the world.
2022-03-23 11:47:17 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:47:21 | INFO | fairseq.tasks.translation | example hypothesis: this is that's the world of the world.
2022-03-23 11:47:21 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:47:25 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world of the world.
2022-03-23 11:47:25 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:47:29 | INFO | fairseq.tasks.translation | example hypothesis: and it's a world, and it's a world, and it's a world.
2022-03-23 11:47:29 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:47:34 | INFO | fairseq.tasks.translation | example hypothesis: and it's that's the world, and it's not not not not not not not not not it's the world.
2022-03-23 11:47:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:47:39 | INFO | fairseq.tasks.translation | example hypothesis: and this is the world of the world, and this is the world, and the world of the world of the world of the world of the world of the world of the world of the world.
2022-03-23 11:47:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:47:44 | INFO | fairseq.tasks.translation | example hypothesis: but you can can can't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't't be
2022-03-23 11:47:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:47:50 | INFO | fairseq.tasks.translation | example hypothesis: and we can can can see the world of the world, and we're the world, and we're the world of the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can't't't't't't't't't't't't't't't't't't't't't't
2022-03-23 11:47:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:47:57 | INFO | fairseq.tasks.translation | example hypothesis: and "", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""
2022-03-23 11:47:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:48:00 | INFO | fairseq.tasks.translation | example hypothesis: so, we're the world of the world, and we're the world of the world, and it's the world, and we have the world, and we have the world, and we have to be be the world of the world, and it's the world of the world of the world of the world, and we're the world, and we can can can can can can can can can can can can can can can can can can can can can can can can can can can can can can be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be to be to be to be, and it, and it's the world, and it's the world, and it's the world, and we have to be be be be be be be to be be be be be be be be be be be be be be be be
2022-03-23 11:48:00 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:48:00 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.649 | ppl 6421.86 | bleu 1.08 | wps 3804.8 | wpb 17862.2 | bsz 728.3 | num_updates 624 | best_bleu 1.08
2022-03-23 11:48:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 624 updates
2022-03-23 11:48:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:48:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:48:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 4 @ 624 updates, score 1.08) (writing took 1.6906173509778455 seconds)
2022-03-23 11:48:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 11:48:01 | INFO | train | epoch 004 | loss 11.463 | ppl 2823.43 | wps 36621.1 | ups 1.46 | wpb 25153.6 | bsz 1020.6 | num_updates 624 | lr 7.8e-05 | gnorm 1.024 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 420
KL Stats: Epoch 4 Divergences: Uniform: 0.6074532376956236 Unigram: 0.7028846823222413
2022-03-23 11:48:02 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 11:48:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:48:30 | INFO | train_inner | epoch 005:     76 / 157 loss=11.387, ppl=2677.7, wps=28530.8, ups=1.16, wpb=24556.2, bsz=953.2, num_updates=700, lr=8.75e-05, gnorm=1.07, loss_scale=8, train_wall=36, gb_free=11.5, wall=449
2022-03-23 11:49:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:49:05 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be in the world we're going to be in the world.
2022-03-23 11:49:05 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:49:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the world of the world of the world is the world is the world.
2022-03-23 11:49:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:49:15 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the world of the world of the world.
2022-03-23 11:49:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:49:20 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and there's going to be a lot, and there's a lot of the world, and there's a lot of the world, and there's a lot of
2022-03-23 11:49:20 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:49:25 | INFO | fairseq.tasks.translation | example hypothesis: and it's not not not not that we're not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not
2022-03-23 11:49:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:49:31 | INFO | fairseq.tasks.translation | example hypothesis: and this is in the world of the world of the world, and the world, and the world, and the world is the world in the world in the world in the world in the world in the world, and the world in the world in the world of the world, and the world
2022-03-23 11:49:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:49:37 | INFO | fairseq.tasks.translation | example hypothesis: and they're going to be the world, and they're not not not not not not not not not not not not not not not not not not not not not not not the world, but they're the world, but they're the world, but they're the world, but they're going to be in the world, and they're going to be
2022-03-23 11:49:37 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:49:43 | INFO | fairseq.tasks.translation | example hypothesis: and so we're going to make the world, and we can see the world, and we're going to be the world, and we're going to make the world, and we're the world, and we're the world, and we're the world, and we're the world, and we're the world, and we're the world, and we're going to make the world, and we're going to be the world, and we're going to
2022-03-23 11:49:43 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:49:51 | INFO | fairseq.tasks.translation | example hypothesis: and this is, "this is," this is, "this is," this is the first, "this is," this is, "this is the first," this is the first, "" this is, "" this is, "this is," this is, "this is," this is, "this is," this is, "this is," this is, "this is the first," that we're the first, "" "" "" "" "" this is, "" "" this is, "this is," "this is," "" "" this is, "this is," "" "" "" "you," this is, "this is," this is, "this is," this is, "this is," this is, "" "" "" ""
2022-03-23 11:49:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:49:53 | INFO | fairseq.tasks.translation | example hypothesis: so, we're the world, and we're the world, and we're going to be the world, and that we're going to be the world, and that we're the world, and we're the world, and we're the world that we're the world that we're the world that we're the world that we're the world, and the world, and we have to be the world, and we're going to be the world, and we're the world, and we have to be the world that we're the world that we have to be the world that we're the world, and we have to be the world that we have to be the world that we have to be the world, and that we have to be the world that we have to have to be the world, and we have to be the world, and we're the world, and we have to be be be be the world, and we have to be the world, and the world, and we have to have to be the world, and the world,
2022-03-23 11:49:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:49:53 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.408 | ppl 5433.88 | bleu 1.23 | wps 3392 | wpb 17862.2 | bsz 728.3 | num_updates 781 | best_bleu 1.23
2022-03-23 11:49:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 781 updates
2022-03-23 11:49:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 5 @ 781 updates, score 1.23) (writing took 1.709506765997503 seconds)
2022-03-23 11:49:55 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 11:49:55 | INFO | train | epoch 005 | loss 11.193 | ppl 2340.83 | wps 34722.1 | ups 1.38 | wpb 25153.6 | bsz 1020.6 | num_updates 781 | lr 9.7625e-05 | gnorm 1.081 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 534
KL Stats: Epoch 5 Divergences: Uniform: 0.6447779075150459 Unigram: 0.9038044671161742
2022-03-23 11:49:55 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 11:49:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:50:02 | INFO | train_inner | epoch 006:     19 / 157 loss=11.036, ppl=2099.92, wps=27573.7, ups=1.09, wpb=25377, bsz=1038.3, num_updates=800, lr=0.0001, gnorm=1.11, loss_scale=8, train_wall=37, gb_free=12.7, wall=541
2022-03-23 11:50:40 | INFO | train_inner | epoch 006:    119 / 157 loss=10.979, ppl=2018.24, wps=67144.7, ups=2.65, wpb=25320.5, bsz=1021.9, num_updates=900, lr=0.0001125, gnorm=1.068, loss_scale=8, train_wall=37, gb_free=11.9, wall=579
2022-03-23 11:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:50:58 | INFO | fairseq.tasks.translation | example hypothesis: we're going to see in the world.
2022-03-23 11:50:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:51:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most of the world.
2022-03-23 11:51:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:51:06 | INFO | fairseq.tasks.translation | example hypothesis: we're going to be a lot of the world.
2022-03-23 11:51:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:51:11 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of there, there's a lot of the world.
2022-03-23 11:51:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:51:16 | INFO | fairseq.tasks.translation | example hypothesis: and it's not that we're going to do that we're going to do that we're going to do it's going to do it, and it's not not going to do it's not not not going to do it's not not
2022-03-23 11:51:16 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:51:21 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people in the world, and the world, and the world, and in the world, and the world, and the world, and the world is the world, and the world, and the world, and people in the world, and the world, and the
2022-03-23 11:51:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:51:27 | INFO | fairseq.tasks.translation | example hypothesis: but they're going to be a lot of the world, but they're not not not not not not a lot of the world, but they're going to be, but they're going to be a lot of the world.
2022-03-23 11:51:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:51:33 | INFO | fairseq.tasks.translation | example hypothesis: and if we're going to be a lot of the world, and we can see that we can see that we're going to be a lot of the world, and we're going to make the world, and we can see the world, and we're going to be a lot of the world, and then we can see the world, and we can see that we can see the world, and we're going to make the world, and we're going to
2022-03-23 11:51:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:51:41 | INFO | fairseq.tasks.translation | example hypothesis: and i said, "you know," you know, "you know," it's going to say, "you know," it's going to say, "it's going to say," it's going to say, "you know," you know, "it's going to say," you know, "it's going to say," it's going to say, "it's going to say," it's going to say, "it's a first first first of the first first first first first first first first first first first first first first," it's going to say, "it's going to say," it's going to say, "it's going to say," you know, "you know," it's a first first first first first first first first first first first first first first first first first first first first first first first first first
2022-03-23 11:51:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:51:43 | INFO | fairseq.tasks.translation | example hypothesis: i think that we've got that we're going to be a lot of the world, that we're going to be a lot of the world, that we're going to do that we're going to do that we're going to be a lot of the world, that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going to do that we're going
2022-03-23 11:51:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:51:43 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 12.218 | ppl 4765.52 | bleu 1.74 | wps 3639.3 | wpb 17862.2 | bsz 728.3 | num_updates 938 | best_bleu 1.74
2022-03-23 11:51:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 938 updates
2022-03-23 11:51:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:51:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 6 @ 938 updates, score 1.74) (writing took 1.7494661789969541 seconds)
2022-03-23 11:51:45 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 11:51:45 | INFO | train | epoch 006 | loss 10.995 | ppl 2041.59 | wps 35968.5 | ups 1.43 | wpb 25153.6 | bsz 1020.6 | num_updates 938 | lr 0.00011725 | gnorm 1.052 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 644
KL Stats: Epoch 6 Divergences: Uniform: 0.6809269863025383 Unigram: 1.028846371617534
2022-03-23 11:51:45 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 11:51:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:52:09 | INFO | train_inner | epoch 007:     62 / 157 loss=10.902, ppl=1913.72, wps=28518.3, ups=1.13, wpb=25195.5, bsz=1022.5, num_updates=1000, lr=0.000125, gnorm=0.933, loss_scale=8, train_wall=37, gb_free=11.6, wall=667
2022-03-23 11:52:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:52:48 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the world.
2022-03-23 11:52:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:52:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most of the most of the most of the most of the most of the most of the
2022-03-23 11:52:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:52:57 | INFO | fairseq.tasks.translation | example hypothesis: these are going to be able to be a new new new new new new new new new new new new new york.
2022-03-23 11:52:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:53:02 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the world, and it's a lot of the world.
2022-03-23 11:53:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example hypothesis: it's what we're going to do is that we're going to do, and it's going to do, and it's going to do that we're going to do that we're going to do that we're going to do it's
2022-03-23 11:53:07 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:53:13 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the people who are in the people in the world, and people who are in the people in the people in the people in the people in the world.
2022-03-23 11:53:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:53:18 | INFO | fairseq.tasks.translation | example hypothesis: now, you're going to see, but you're going to see, you're going to see, and they're going to see, and they're going to see, and they're going to get a lot of the world, and they're going to see it, and they're going to be a lot of the world.
2022-03-23 11:53:18 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take a lot of the world, and we can see the world, and we can see, and we can see, and we can see the world, and we can see it's going to be a lot of the world.
2022-03-23 11:53:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:53:32 | INFO | fairseq.tasks.translation | example hypothesis: so, if you're going to say, "you're going to say," you know, "we're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say," we're going to say, "you're going to say," you're going to say, "" "" "" "" "" "" "" "" "" "" "" "you're going to say," you're going to say, "it's going to say," you're going to say, "it's going to say," you know, "" "you're going to say," you're going to say, "you're going to say," we're going to say, "" "
2022-03-23 11:53:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:53:34 | INFO | fairseq.tasks.translation | example hypothesis: in fact, we're going to be a lot of the world, and we're going to be a lot of the world, which is that we're going to be able to be able to be able to be able to be able to be a lot of the world, which is a lot of the world, and we're going to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, and in the world, and we're going to be a lot of the world, and we're going to be a lot of the world, which is that we're going to be able to be able to be able to be able to be able to be able to be able to be a lot of the world, and in the world, which is that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 11:53:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:53:34 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 12.092 | ppl 4365.64 | bleu 2 | wps 3521.4 | wpb 17862.2 | bsz 728.3 | num_updates 1095 | best_bleu 2
2022-03-23 11:53:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1095 updates
2022-03-23 11:53:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:53:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 7 @ 1095 updates, score 2.0) (writing took 1.7179048720281571 seconds)
2022-03-23 11:53:36 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 11:53:36 | INFO | train | epoch 007 | loss 10.827 | ppl 1815.98 | wps 35506.3 | ups 1.41 | wpb 25153.6 | bsz 1020.6 | num_updates 1095 | lr 0.000136875 | gnorm 0.965 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 755
KL Stats: Epoch 7 Divergences: Uniform: 0.7107462361714113 Unigram: 1.1177934165113748
2022-03-23 11:53:37 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 11:53:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:53:38 | INFO | train_inner | epoch 008:      5 / 157 loss=10.829, ppl=1819.46, wps=27804.4, ups=1.11, wpb=25002.6, bsz=1042.3, num_updates=1100, lr=0.0001375, gnorm=0.962, loss_scale=8, train_wall=37, gb_free=12, wall=757
2022-03-23 11:54:16 | INFO | train_inner | epoch 008:    105 / 157 loss=10.642, ppl=1597.73, wps=67284, ups=2.68, wpb=25137.5, bsz=1075.3, num_updates=1200, lr=0.00015, gnorm=0.956, loss_scale=8, train_wall=37, gb_free=12.3, wall=795
2022-03-23 11:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:54:39 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in the world.
2022-03-23 11:54:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:54:44 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most most of the most most of the most of the most most most of the most of the most most of the most
2022-03-23 11:54:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:54:49 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-23 11:54:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:54:54 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, for example, for example, and there's a lot of example, and it's going to be a lot of the world.
2022-03-23 11:54:54 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:55:00 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're going to do that we're going to do it, and we're going to do what we're going to do is that we're going to do that's going to do it's not going to do.
2022-03-23 11:55:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:55:05 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the world, in the world, in the world, in the world, in the world, the world, for the people who are the people in the people in the people in the people in the world.
2022-03-23 11:55:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:55:11 | INFO | fairseq.tasks.translation | example hypothesis: now, some of some of these are not, but it's a lot of the same way, but it's not, but but it's a lot of you can't have to be, but but it's the same, but but it's not a lot of the same, but it's also also also, but but it's a lot of the
2022-03-23 11:55:11 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:55:17 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to take the brain, and we can see that we can see that we can see that we can see the world, and we can see the world, and we can see that we can see that we can see the world, and we can see that we can see that we can see that we can see the world, and we can see that we can see that we can see that we can see the world, and we can see the
2022-03-23 11:55:17 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:55:24 | INFO | fairseq.tasks.translation | example hypothesis: one: one: one: you know, "you know," it's a lot of the world, and it's going to say, "it's a lot of the world, and it's going to say," and it's a lot of the world, "and it's a lot of the world," and it's a lot of the world, "and it's going to say," it's going to say, "it's going to say," it's going to say, "it's going to say," and it's a lot of the world, "and it's a lot of the world," and it's a lot of you know, "and it's a lot of the world," and it's a lot of you know, "and it's a lot of you know," and it's a lot of the first first first first first
2022-03-23 11:55:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:55:27 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, if we're going to make a lot of the world, and we're going to do that we're going to make a lot of the world, and that we're going to be able to make the world, and we're going to make the world, and that we're going to be able to make the world, and that we're going to be able to make the world, and then we're going to be the world, and then we're going to be able to be a, and that we're going to be able to be a, and then we're going to be a lot of the world, and then we're going to be able to do that we're going to make the world, and then we're going to be a lot of the world, and then we're going to be able to make the world, and then we're going to be a lot of the world, and then we're going to make a lot of the world, and we're going to do that we're going to make the world
2022-03-23 11:55:27 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:55:27 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 11.934 | ppl 3913.5 | bleu 2.75 | wps 3460.1 | wpb 17862.2 | bsz 728.3 | num_updates 1252 | best_bleu 2.75
2022-03-23 11:55:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1252 updates
2022-03-23 11:55:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 8 @ 1252 updates, score 2.75) (writing took 1.704248809022829 seconds)
2022-03-23 11:55:28 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 11:55:28 | INFO | train | epoch 008 | loss 10.687 | ppl 1648.92 | wps 35176.6 | ups 1.4 | wpb 25153.6 | bsz 1020.6 | num_updates 1252 | lr 0.0001565 | gnorm 0.932 | loss_scale 8 | train_wall 58 | gb_free 11.7 | wall 867
KL Stats: Epoch 8 Divergences: Uniform: 0.7341546997732659 Unigram: 1.1792359168749846
2022-03-23 11:55:29 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 11:55:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:55:47 | INFO | train_inner | epoch 009:     48 / 157 loss=10.567, ppl=1516.71, wps=28163.6, ups=1.1, wpb=25702.9, bsz=1011, num_updates=1300, lr=0.0001625, gnorm=0.846, loss_scale=8, train_wall=37, gb_free=12.6, wall=886
2022-03-23 11:56:24 | INFO | train_inner | epoch 009:    148 / 157 loss=10.597, ppl=1549.15, wps=66385.7, ups=2.68, wpb=24780.2, bsz=958.6, num_updates=1400, lr=0.000175, gnorm=0.898, loss_scale=8, train_wall=37, gb_free=11.9, wall=923
2022-03-23 11:56:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:56:32 | INFO | fairseq.tasks.translation | example hypothesis: we've got this in this room.
2022-03-23 11:56:32 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:56:36 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most of the most of the most most of the most most of the most most of the most most most people.
2022-03-23 11:56:36 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:56:41 | INFO | fairseq.tasks.translation | example hypothesis: are new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new york.
2022-03-23 11:56:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:56:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a lot of life, where it's where you're going to go, where you're going to go with a, and it's where you're going to go.
2022-03-23 11:56:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:56:51 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just just just just just just just just just just just just just a few of what we're going to do.
2022-03-23 11:56:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:56:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the middle of people like the people like the people who had a lot of people in the people in the people, for the people who had a lot of people in the people, and the most people who had a lot of people.
2022-03-23 11:56:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of some of some of them, but if you're going to go, it's not, but it's not a lot of the same way, but it's not, but if you're going to go, you don't see it, it's not, but if you're going to go, but it's a lot of
2022-03-23 11:57:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:57:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to look at the world, we can see the world, we can see that we can see the world, and we can see that we can see the world, and we can see that we can get a lot of the world, and then we can see that we can see the brain.
2022-03-23 11:57:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:57:15 | INFO | fairseq.tasks.translation | example hypothesis: yeah: it's one of the world, "it's a lot of the world," "" and it's going to say, "" "" you know, "you're going to say," well, "well," you know, "you're going to say," well, "well," well, "we're going to say," you're going to say, "well," well, "well," well, "well," you're going to say, "" "you're going to say," well, "you're going to say," you're going to say, "well," well, "you're going to say," you're going to say, "well," you're going to do it's going to say, "" you know, "you're going to say it's going to say," "
2022-03-23 11:57:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:57:17 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's going to be a lot of the world, and if we're going to do that we're going to have a lot of the world, if we're going to have a lot of the world, if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be
2022-03-23 11:57:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:57:17 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 11.726 | ppl 3387.62 | bleu 4.2 | wps 3581.1 | wpb 17862.2 | bsz 728.3 | num_updates 1409 | best_bleu 4.2
2022-03-23 11:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1409 updates
2022-03-23 11:57:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:57:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 9 @ 1409 updates, score 4.2) (writing took 1.697541945031844 seconds)
2022-03-23 11:57:19 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 11:57:19 | INFO | train | epoch 009 | loss 10.532 | ppl 1480.19 | wps 35626.9 | ups 1.42 | wpb 25153.6 | bsz 1020.6 | num_updates 1409 | lr 0.000176125 | gnorm 0.863 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 978
KL Stats: Epoch 9 Divergences: Uniform: 0.7587496686271071 Unigram: 1.241353344488954
2022-03-23 11:57:20 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 11:57:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:57:54 | INFO | train_inner | epoch 010:     91 / 157 loss=10.473, ppl=1421.67, wps=27984.4, ups=1.11, wpb=25166.5, bsz=1026, num_updates=1500, lr=0.0001875, gnorm=0.804, loss_scale=8, train_wall=37, gb_free=12.6, wall=1013
2022-03-23 11:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 11:58:22 | INFO | fairseq.tasks.translation | example hypothesis: we did this in the way.
2022-03-23 11:58:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 11:58:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the most, most of the most most most most most most.
2022-03-23 11:58:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 11:58:30 | INFO | fairseq.tasks.translation | example hypothesis: these are going to new new new new new new new new new new new cells.
2022-03-23 11:58:30 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 11:58:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, it's where you're going to go, and where you're going to get up.
2022-03-23 11:58:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 11:58:38 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just just just a couple of your brain, and what's going on.
2022-03-23 11:58:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, how people for the people for the people for the people, and that's a lot of the people, and that's a lot of the people.
2022-03-23 11:58:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 11:58:47 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of you're going to go to the brain, but if you don't have to get it, if you don't have the energy, if you don't have to get the energy, you're going to get the energy, it, you're going to get the energy, and you're going to get the energy, it,
2022-03-23 11:58:47 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 11:58:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that we can use this, we can take a lot of the brain, and we can take a lot of the brain, and that's all of the brain, and all of the brain, and that's all of the brain, and all of the brain, and all of the brain, and that's all of the brain, and that's all of the brain.
2022-03-23 11:58:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 11:58:57 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the interesting thing, and it's very interesting for me, and it's going to say, "and then we're going to say," you know, if you're going to say, you're going to say, you're going to say, "you're going to get to get a lot of that's going to get to get to get to get a lot of the right for a lot of the first time, and then we're going to say, and then we're going to say, and then we're going to say," you're going to say, "you're going to say," you're going to say, you know, "you're going to say," you're going to say, "you're going to say," you're going to say, "you're going to say, you know, and then we're going to say,
2022-03-23 11:58:57 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 11:58:59 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's a lot of the first thing, and a lot of work, and if we're going to take a lot of the world, we're going to have to be able to get to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 11:58:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 11:59:00 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 11.513 | ppl 2921.67 | bleu 7.57 | wps 4404 | wpb 17862.2 | bsz 728.3 | num_updates 1566 | best_bleu 7.57
2022-03-23 11:59:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1566 updates
2022-03-23 11:59:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 11:59:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 10 @ 1566 updates, score 7.57) (writing took 1.7005683589959517 seconds)
2022-03-23 11:59:01 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 11:59:01 | INFO | train | epoch 010 | loss 10.356 | ppl 1310.25 | wps 38702.9 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 1566 | lr 0.00019575 | gnorm 0.816 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1080
KL Stats: Epoch 10 Divergences: Uniform: 0.7862312948283848 Unigram: 1.300959954821779
2022-03-23 11:59:02 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 11:59:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 11:59:14 | INFO | train_inner | epoch 011:     34 / 157 loss=10.302, ppl=1262.87, wps=31029.6, ups=1.25, wpb=24827.9, bsz=1010.3, num_updates=1600, lr=0.0002, gnorm=0.825, loss_scale=8, train_wall=36, gb_free=13.1, wall=1093
2022-03-23 11:59:52 | INFO | train_inner | epoch 011:    134 / 157 loss=10.06, ppl=1067.63, wps=67926.6, ups=2.66, wpb=25502, bsz=1063, num_updates=1700, lr=0.0002125, gnorm=0.824, loss_scale=8, train_wall=37, gb_free=12.6, wall=1131
2022-03-23 12:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:00:04 | INFO | fairseq.tasks.translation | example hypothesis: we had these pppm in the end of the house.
2022-03-23 12:00:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:00:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the fact that most of most of most most most most most most most most of you know here.
2022-03-23 12:00:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:00:13 | INFO | fairseq.tasks.translation | example hypothesis: these are new york york new new new new new new new new new york are going to be able to be able to be able.
2022-03-23 12:00:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:00:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's example, where the chinese, where they're going to come with the pppppm, and they're going to be able.
2022-03-23 12:00:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:00:21 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't just just just just a few feet on his head, and what's going to understand.
2022-03-23 12:00:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:00:26 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, people like the people who were used for the number of the number of the number, and that's a number of the number of the number.
2022-03-23 12:00:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:00:30 | INFO | fairseq.tasks.translation | example hypothesis: first of some of them are looking at the ocean, but if you don't need to use the energy, if you don't need your energy, you need the energy, and you need to need the energy.
2022-03-23 12:00:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:00:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can see this, we can create a structure, and we can see the structure of the structure of the structure, and that's all the structure.
2022-03-23 12:00:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:00:38 | INFO | fairseq.tasks.translation | example hypothesis: so, one of the reasons, and it's interesting for me for me, "you know," you know, "if you're going to say," you're going to say, "you know," well, "well," you know, "you know," well, "you know," well, "well," you're going to say, "well," you know, "you know," well, "well," you know, "well," well, "you know," well, "well," well, "well," you know, "well," well, "well," you know, "well," well, "you know," you know, "you know," well, "well," you know, "you know," you know, "you know," well, "well,"
2022-03-23 12:00:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:00:40 | INFO | fairseq.tasks.translation | example hypothesis: well, it's still still still still the mother, and we had a lot of work that we had to be able to be able to be able to be able to be able to be able to be able to be able.
2022-03-23 12:00:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:00:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 11.369 | ppl 2645.12 | bleu 9.67 | wps 4590.9 | wpb 17862.2 | bsz 728.3 | num_updates 1723 | best_bleu 9.67
2022-03-23 12:00:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1723 updates
2022-03-23 12:00:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:00:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 11 @ 1723 updates, score 9.67) (writing took 1.699719545955304 seconds)
2022-03-23 12:00:42 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 12:00:42 | INFO | train | epoch 011 | loss 10.195 | ppl 1172.13 | wps 39208.2 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 1723 | lr 0.000215375 | gnorm 0.812 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 1181
KL Stats: Epoch 11 Divergences: Uniform: 0.812266898377738 Unigram: 1.3537526979136778
2022-03-23 12:00:42 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 12:00:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:01:11 | INFO | train_inner | epoch 012:     77 / 157 loss=10.133, ppl=1122.86, wps=31445.1, ups=1.26, wpb=24985.4, bsz=970.8, num_updates=1800, lr=0.000225, gnorm=0.769, loss_scale=8, train_wall=37, gb_free=12.1, wall=1210
2022-03-23 12:01:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:01:45 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppm in the lab.
2022-03-23 12:01:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:01:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the cist, most of course, most of most of most of most of the most.
2022-03-23 12:01:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:01:53 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to be able to be able to create two new york.
2022-03-23 12:01:53 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:01:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese food, where they're going to get with the pppp.
2022-03-23 12:01:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:02:01 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just going to understand a few ways of his head, and what's going to understand his mind.
2022-03-23 12:02:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:02:06 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamacy of people who took the most important number of animals, and it's a number of animals in the fact, and it's a lot of the iiiiiiiiiiiiiiiiiiiiii
2022-03-23 12:02:06 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:02:10 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are a little bit of the dddle, but if you don't need to do it, if you don't need the energy, you need the energy, you need the energy, and you need to need the energy.
2022-03-23 12:02:10 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we're going to start with this kind of structure, we can start to start with a structure of the structure of the structure, and the structure of the structure of the structure, and all the structure of the structure, and all the structure of the structure of the structure of the structure, and all the structure of the structure, and all the structure, and all the structure of the structure of the structure of the structure of the information
2022-03-23 12:02:15 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:02:19 | INFO | fairseq.tasks.translation | example hypothesis: again, one of the reasons it's interesting, and it's interesting for me to be here for me, "well," well, "then we said," then we've got to say, "and then we said," you're going to say, "you're going to say," you know, "you're going to say," well, "well," you know, "you're going to say," you're going to say, "well," and then we're going to say, "well," well, "well," well, "well," well, "and then we're going to say," well, "well," well, "you're going to say," well, "well," well, "and then we've got it's a young young young young young young young young young young women," you have
2022-03-23 12:02:19 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example hypothesis: in fact, it's still still the mother, and a lot of work that we had to be a lot of the world, and if we had to see that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see
2022-03-23 12:02:22 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:02:22 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 11.147 | ppl 2267.5 | bleu 10.82 | wps 4458.5 | wpb 17862.2 | bsz 728.3 | num_updates 1880 | best_bleu 10.82
2022-03-23 12:02:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1880 updates
2022-03-23 12:02:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:02:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 12 @ 1880 updates, score 10.82) (writing took 1.6911069590132684 seconds)
2022-03-23 12:02:23 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 12:02:23 | INFO | train | epoch 012 | loss 10.003 | ppl 1026.24 | wps 38964.4 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 1880 | lr 0.000235 | gnorm 0.804 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 1282
KL Stats: Epoch 12 Divergences: Uniform: 0.8337815873509513 Unigram: 1.3832876129880947
2022-03-23 12:02:24 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 12:02:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:02:31 | INFO | train_inner | epoch 013:     20 / 157 loss=9.916, ppl=966.13, wps=31399.3, ups=1.25, wpb=25105.5, bsz=1045.6, num_updates=1900, lr=0.0002375, gnorm=0.864, loss_scale=8, train_wall=37, gb_free=12.3, wall=1290
2022-03-23 12:03:09 | INFO | train_inner | epoch 013:    120 / 157 loss=9.859, ppl=928.76, wps=67078, ups=2.65, wpb=25276.1, bsz=1044.4, num_updates=2000, lr=0.00025, gnorm=0.77, loss_scale=8, train_wall=37, gb_free=13.1, wall=1328
2022-03-23 12:03:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:03:27 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppppton in the clinic.
2022-03-23 12:03:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:03:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the car car of doha, most of most of most of the most most of the most of here.
2022-03-23 12:03:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:03:35 | INFO | fairseq.tasks.translation | example hypothesis: new stars are going to create new ororores of two new ways that are going to be going to be used.
2022-03-23 12:03:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:03:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's chinese chinese chinese chinese chinese food, where they're going to do with pppie.
2022-03-23 12:03:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:03:43 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we're not just just just a couple of electrodes on his head, and all of his mind.
2022-03-23 12:03:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:03:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamamamacy of people who had been working for animals, and this is a number of animals.
2022-03-23 12:03:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example hypothesis: first of some of those are some of the magic, but it doesn't have to be able to be able to move their energy, and if you need the energy, and you need the energy.
2022-03-23 12:03:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:03:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can start to be able to be able to start with this kind of design, we can start to start with a big structure of the structure of the structure of the structure, and the structure of the structure of the structure of the information, and all the information, and the structure of the structure of the structure of the structure of the information, and all the information, and the structure of the structure of the information that we can
2022-03-23 12:03:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:04:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting to be interesting, and i'm here to be here for women, "oh," well, "you know," you know, "you know," you know, "you know," the best time, "the best time," the best time, "and then we're going to say," and then we're going to say, "and then," the best time, "the best time," the best time, "the best time," the best time, "and then," the best time, "the best time," the best time, "the best time," the best time, "the best time," you're going to say, "the best time," the best time, "the best time," the best time, "the best time," and then we're going to
2022-03-23 12:04:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need to be still still the mother of the great work, and we've had to see that the airplane, and we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the top of the top of the ground.
2022-03-23 12:04:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:04:05 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 11.038 | ppl 2103.23 | bleu 11.94 | wps 4259 | wpb 17862.2 | bsz 728.3 | num_updates 2037 | best_bleu 11.94
2022-03-23 12:04:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2037 updates
2022-03-23 12:04:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:04:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 13 @ 2037 updates, score 11.94) (writing took 1.7480172970099375 seconds)
2022-03-23 12:04:07 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 12:04:07 | INFO | train | epoch 013 | loss 9.831 | ppl 910.51 | wps 38130.9 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 2037 | lr 0.000254625 | gnorm 0.794 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 1386
KL Stats: Epoch 13 Divergences: Uniform: 0.8587522512821496 Unigram: 1.4218579045539783
2022-03-23 12:04:07 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 12:04:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:04:31 | INFO | train_inner | epoch 014:     63 / 157 loss=9.76, ppl=867.22, wps=30467.9, ups=1.22, wpb=24981.2, bsz=975.8, num_updates=2100, lr=0.0002625, gnorm=0.752, loss_scale=8, train_wall=37, gb_free=12.8, wall=1410
2022-03-23 12:05:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:05:10 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppppin the clinic.
2022-03-23 12:05:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:05:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the top of doha, doha, most of most of the most most of the most of here.
2022-03-23 12:05:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:05:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create a new locks.
2022-03-23 12:05:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:05:23 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where the legs are happy, and they're going to be going to be able.
2022-03-23 12:05:23 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:05:27 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head on his head and understand what all of his mind are on the mind.
2022-03-23 12:05:27 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:05:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamaking people like the responsibility of the responsibility, the number of animals came back to the number of animals, and this has become a congress.
2022-03-23 12:05:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:05:35 | INFO | fairseq.tasks.translation | example hypothesis: first, you're a couple of maps from the color, but in the top of the lines, but if you don't need the energy, and you need the energy.
2022-03-23 12:05:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:05:39 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, we can use the reflection of this reflection, we can start to start with a traditional traditional form of the shape of the structure, and the whole structure of all the information.
2022-03-23 12:05:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:05:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to do with tedtedtedtedwomen, "well, you know," if you're going to tell you a long time. "
2022-03-23 12:05:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:05:44 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big design part of the work that we're going to see that if we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see the earth.
2022-03-23 12:05:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:05:44 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.879 | ppl 1882.75 | bleu 14.95 | wps 4892 | wpb 17862.2 | bsz 728.3 | num_updates 2194 | best_bleu 14.95
2022-03-23 12:05:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2194 updates
2022-03-23 12:05:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:05:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:05:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 14 @ 2194 updates, score 14.95) (writing took 1.7020640699774958 seconds)
2022-03-23 12:05:45 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 12:05:45 | INFO | train | epoch 014 | loss 9.647 | ppl 801.78 | wps 40073.8 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 2194 | lr 0.00027425 | gnorm 0.725 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1484
KL Stats: Epoch 14 Divergences: Uniform: 0.8888484199223111 Unigram: 1.4493316922654211
2022-03-23 12:05:46 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 12:05:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:05:49 | INFO | train_inner | epoch 015:      6 / 157 loss=9.5, ppl=724.26, wps=32957.9, ups=1.29, wpb=25546.6, bsz=1077.7, num_updates=2200, lr=0.000275, gnorm=0.696, loss_scale=8, train_wall=37, gb_free=12.2, wall=1487
2022-03-23 12:06:26 | INFO | train_inner | epoch 015:    106 / 157 loss=9.473, ppl=710.86, wps=67226.1, ups=2.67, wpb=25207.9, bsz=1066.4, num_updates=2300, lr=0.0002875, gnorm=0.754, loss_scale=8, train_wall=37, gb_free=12.8, wall=1525
2022-03-23 12:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:06:49 | INFO | fairseq.tasks.translation | example hypothesis: we made these ppills in the clinics.
2022-03-23 12:06:49 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:06:53 | INFO | fairseq.tasks.translation | example hypothesis: this is the line of doha, the most know here.
2022-03-23 12:06:53 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:06:57 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-23 12:06:57 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:07:01 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where the legs are happy, and they're going to do with pppie.
2022-03-23 12:07:01 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:07:05 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to make a few electrodes on his head and understand what all of his mind are on the mind.
2022-03-23 12:07:05 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:07:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamaking of how people took the responsibility for life, the number of animals, and this is a number of animals, and that has become a precisiiiiiiiiiiibia.
2022-03-23 12:07:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:07:14 | INFO | fairseq.tasks.translation | example hypothesis: first of course, some of the magic lines in the field, but it doesn't like to move, but if you don't need to move it, if you need your energy, it doesn't need your energy, and you need your energy.
2022-03-23 12:07:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can begin to start with a traditional face, and we can begin to start with a big shape of the shape of the shape of the information, and the information that's all the structure of the information.
2022-03-23 12:07:19 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:07:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here at tedtedwomen -- that's the best time, "yeah, when someone said," well, it was the best thing that we're going to tell you, "and then," if we've got a lot of you know, "and then we've got a long time for you know," well, "well," well, "well," well, "and then we've got a long time for you know," well, "well," well, "in this time," that the best time, "you know, we've got a long time."
2022-03-23 12:07:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:07:26 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the need is still the mother of the invention, and a big design part of our work on our airplane, that we had to solve is that we had to solve a unique idea that we had to solve the result of the problem of a unique source of the ground, or to use it.
2022-03-23 12:07:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:07:26 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.691 | ppl 1653.15 | bleu 16.52 | wps 4411 | wpb 17862.2 | bsz 728.3 | num_updates 2351 | best_bleu 16.52
2022-03-23 12:07:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2351 updates
2022-03-23 12:07:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:07:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 15 @ 2351 updates, score 16.52) (writing took 1.702478980005253 seconds)
2022-03-23 12:07:28 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 12:07:28 | INFO | train | epoch 015 | loss 9.501 | ppl 724.51 | wps 38649.5 | ups 1.54 | wpb 25153.6 | bsz 1020.6 | num_updates 2351 | lr 0.000293875 | gnorm 0.722 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 1586
KL Stats: Epoch 15 Divergences: Uniform: 0.9117031952062977 Unigram: 1.46413695317689
2022-03-23 12:07:28 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 12:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:07:47 | INFO | train_inner | epoch 016:     49 / 157 loss=9.408, ppl=679.52, wps=31465.5, ups=1.24, wpb=25434.7, bsz=926.5, num_updates=2400, lr=0.0003, gnorm=0.68, loss_scale=8, train_wall=37, gb_free=11.2, wall=1606
2022-03-23 12:08:24 | INFO | train_inner | epoch 016:    149 / 157 loss=9.415, ppl=682.72, wps=66529.9, ups=2.69, wpb=24694, bsz=1031.8, num_updates=2500, lr=0.0003125, gnorm=0.643, loss_scale=8, train_wall=37, gb_free=12.8, wall=1643
2022-03-23 12:08:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:08:31 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinics.
2022-03-23 12:08:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:08:35 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most know here.
2022-03-23 12:08:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:08:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new dines.
2022-03-23 12:08:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:08:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french food.
2022-03-23 12:08:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:08:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head and understand what all the thoughts are on the mind.
2022-03-23 12:08:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:08:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamammals like the responsibility of life, which grew up to the number of animals.
2022-03-23 12:08:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:08:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic lines are in the field, but the sulens don't like it, if you need their energy, you need their energy, and you need their energy.
2022-03-23 12:08:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:08:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information that comes from this reflection, we can start with a traditional face of the traditional face of the face of the face of the face of the face and the face of the shape of the shape of the shape of the information.
2022-03-23 12:08:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:09:01 | INFO | fairseq.tasks.translation | example hypothesis: th: one of you have interesting and measure me to be able to be here for tedwomen, "yes, is that when someone said," well, "well, it was the best thing that someone said," when we're going to support them, "and then we're going to support them."
2022-03-23 12:09:01 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:09:02 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still able to see the invention of the design, and a lot of design that we've got to see is that we had to solve a result of the airplane that we had to solve a unique result of it.
2022-03-23 12:09:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:09:02 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.633 | ppl 1587.82 | bleu 12.91 | wps 5301.2 | wpb 17862.2 | bsz 728.3 | num_updates 2508 | best_bleu 16.52
2022-03-23 12:09:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2508 updates
2022-03-23 12:09:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:09:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:09:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 16 @ 2508 updates, score 12.91) (writing took 0.7424967160332017 seconds)
2022-03-23 12:09:02 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 12:09:02 | INFO | train | epoch 016 | loss 9.334 | ppl 645.42 | wps 41672 | ups 1.66 | wpb 25153.6 | bsz 1020.6 | num_updates 2508 | lr 0.0003135 | gnorm 0.67 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 1681
KL Stats: Epoch 16 Divergences: Uniform: 0.9341173319148495 Unigram: 1.4935851660077133
2022-03-23 12:09:03 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 12:09:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:09:38 | INFO | train_inner | epoch 017:     92 / 157 loss=9.23, ppl=600.6, wps=34309.2, ups=1.36, wpb=25239.3, bsz=1052.8, num_updates=2600, lr=0.000325, gnorm=0.678, loss_scale=8, train_wall=37, gb_free=11.9, wall=1716
2022-03-23 12:10:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:10:06 | INFO | fairseq.tasks.translation | example hypothesis: we did these ppills in the clinic clinic clinic.
2022-03-23 12:10:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:10:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-23 12:10:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:10:14 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be able to create two new locations.
2022-03-23 12:10:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:10:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese chinese food food, where happy legs are and salt with sales.
2022-03-23 12:10:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:10:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just get a few electrodes on his head and understand what all of his thoughts are on the way.
2022-03-23 12:10:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:10:28 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility for the life, the number of animals, the number of animals grew up, and this is a foundation for conservation in the maibia.
2022-03-23 12:10:28 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:10:32 | INFO | fairseq.tasks.translation | example hypothesis: first of first, some of the magnetic field in the field, but the suck of the suick, if you don't need your energy, and you need a few energy, and you need to move out.
2022-03-23 12:10:32 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:10:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection reflection, we can start with a traditional face with a traditional face of the face and the information that we can start with all the information, and the whole structure of the structure of the structure of the structure, and the information that all the structure is going to be able to do.
2022-03-23 12:10:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:10:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting for me to be in tedwomen, "that it was the best thing that someone said," if you're going to say, "and then we've been working with you."
2022-03-23 12:10:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:10:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big design part of the design of the work that we have to solve is that we had to solve the unique problems that we had to solve with all the problems of the problems that we've been connected to the ground of the ground, and that if you're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, or see that it, or a particular, and we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, and see, and see, and see, and see that it, or a particular, and see that it, or a particular, if you're able to be able to be able to be able to be able to be able to
2022-03-23 12:10:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:10:45 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 10.504 | ppl 1451.72 | bleu 17.19 | wps 4180.5 | wpb 17862.2 | bsz 728.3 | num_updates 2665 | best_bleu 17.19
2022-03-23 12:10:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2665 updates
2022-03-23 12:10:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:10:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 17 @ 2665 updates, score 17.19) (writing took 1.6901080189854838 seconds)
2022-03-23 12:10:47 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 12:10:47 | INFO | train | epoch 017 | loss 9.217 | ppl 594.97 | wps 37848.2 | ups 1.5 | wpb 25153.6 | bsz 1020.6 | num_updates 2665 | lr 0.000333125 | gnorm 0.687 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1785
KL Stats: Epoch 17 Divergences: Uniform: 0.9560959605142054 Unigram: 1.5078730450840963
2022-03-23 12:10:47 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 12:10:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:11:00 | INFO | train_inner | epoch 018:     35 / 157 loss=9.112, ppl=553.23, wps=30478.2, ups=1.21, wpb=25247.6, bsz=1001.6, num_updates=2700, lr=0.0003375, gnorm=0.694, loss_scale=8, train_wall=37, gb_free=11.9, wall=1799
2022-03-23 12:11:38 | INFO | train_inner | epoch 018:    135 / 157 loss=9.157, ppl=570.89, wps=66327.4, ups=2.67, wpb=24835.3, bsz=1025.2, num_updates=2800, lr=0.00035, gnorm=0.609, loss_scale=8, train_wall=37, gb_free=11.7, wall=1837
2022-03-23 12:11:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:11:50 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:11:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:11:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most.
2022-03-23 12:11:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:11:58 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks.
2022-03-23 12:11:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:12:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food, where happy legs are being done with salsalz and feeding.
2022-03-23 12:12:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:12:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get a few electrodes on his head and understand what all his thoughts are on the way.
2022-03-23 12:12:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:12:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the masteribia, the people had grew up for the wild, grew up the number of animals, and this is a foundation for the natural protection.
2022-03-23 12:12:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:12:14 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the things of the magnetic field, but the susulal, it doesn't like that, if you're moving, you need your energy, you need the energy, and the sucks.
2022-03-23 12:12:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:12:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face that can start with a traditional facial facial of the face of the face, and the form of the information, and the information is the whole structure.
2022-03-23 12:12:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:12:23 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure it interesting, for me to be a long time, is that, "oh, when we're talking about it."
2022-03-23 12:12:23 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:12:25 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of the invention, and a big part of the design work that we're in our airplane, a result of it was that we had to solve the unique problems that we had to be connected to the ground -- it's all the ground, and that it's an interior system, and that if we're either using a specific machine, or a specific machine, or a specific machine that's a specific machine that we're going to be able to see that if we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see, or a very specific, or a very specific, or a specific, or a very specific, and to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to see,
2022-03-23 12:12:25 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:12:25 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 10.319 | ppl 1277.21 | bleu 20.68 | wps 4658 | wpb 17862.2 | bsz 728.3 | num_updates 2822 | best_bleu 20.68
2022-03-23 12:12:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2822 updates
2022-03-23 12:12:25 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:12:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:12:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 18 @ 2822 updates, score 20.68) (writing took 1.6864692140370607 seconds)
2022-03-23 12:12:27 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 12:12:27 | INFO | train | epoch 018 | loss 9.08 | ppl 541.22 | wps 39453.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 2822 | lr 0.00035275 | gnorm 0.604 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 1886
KL Stats: Epoch 18 Divergences: Uniform: 0.970134660523843 Unigram: 1.5242327545418297
2022-03-23 12:12:27 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 12:12:27 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:12:57 | INFO | train_inner | epoch 019:     78 / 157 loss=8.997, ppl=510.87, wps=32290.8, ups=1.26, wpb=25562.4, bsz=986.2, num_updates=2900, lr=0.0003625, gnorm=0.572, loss_scale=8, train_wall=37, gb_free=11.9, wall=1916
2022-03-23 12:13:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:13:30 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:13:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:13:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably know most of you here.
2022-03-23 12:13:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:13:38 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldies of the two new pigs that are going to be transformed.
2022-03-23 12:13:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food food, where happy legs are being served with salz and ppeppet.
2022-03-23 12:13:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a few electrodes on his head and understand exactly what all his thoughts are.
2022-03-23 12:13:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:13:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people responsibility for the wild, grew the number of animals again, and this is a foundation of conservation in namibia.
2022-03-23 12:13:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:13:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines, but the susulalal may not be moving when they need energy, and so the sucks.
2022-03-23 12:13:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:13:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, the big constructions of the face and the information through the whole structure of this structure, the whole structure, the whole structure of this reflection and the structure of this reflection.
2022-03-23 12:13:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:14:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measure, for me to be here at tedwomen, is that...
2022-03-23 12:14:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:14:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother's invention, and a big part of design work that we're going to use in our airplane, is that we had to solve the unique problems in the ground -- it's all the way that we had to be connected to a continent of a continent, and that it allows us to be a constructive system, and that it allows us to use the power of a concrete, or to see that we can use the aircraft, or to see that it's a mechanism, or to be a mechanism, or to see that we use it's a mechanism, or to see that if you can use it's a mechanism, or to see that we can use it's a mechanism, or to see that it's a mechanism, or to see that we can use the tragic system that we're either use it's a mechanism, or to see that we can use it's a mechanism, or to see that we use it's all the trajectory system that we
2022-03-23 12:14:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:14:05 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.283 | ppl 1246.24 | bleu 21.57 | wps 4688.9 | wpb 17862.2 | bsz 728.3 | num_updates 2979 | best_bleu 21.57
2022-03-23 12:14:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2979 updates
2022-03-23 12:14:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:14:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 19 @ 2979 updates, score 21.57) (writing took 1.702199004997965 seconds)
2022-03-23 12:14:06 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 12:14:06 | INFO | train | epoch 019 | loss 8.955 | ppl 496.4 | wps 39647.1 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 2979 | lr 0.000372375 | gnorm 0.58 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 1985
KL Stats: Epoch 19 Divergences: Uniform: 0.9845809328263979 Unigram: 1.5450765383048166
2022-03-23 12:14:07 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 12:14:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:14:15 | INFO | train_inner | epoch 020:     21 / 157 loss=8.899, ppl=477.47, wps=32001.9, ups=1.28, wpb=24910, bsz=1037.8, num_updates=3000, lr=0.000375, gnorm=0.568, loss_scale=8, train_wall=36, gb_free=11.6, wall=1994
2022-03-23 12:14:53 | INFO | train_inner | epoch 020:    121 / 157 loss=8.79, ppl=442.51, wps=67703.3, ups=2.63, wpb=25727.6, bsz=1003.9, num_updates=3100, lr=0.0003875, gnorm=0.505, loss_scale=8, train_wall=38, gb_free=12.8, wall=2032
2022-03-23 12:15:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:15:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these pills in the clinic.
2022-03-23 12:15:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:15:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:15:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:15:18 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to create the two new pigments.
2022-03-23 12:15:18 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:15:22 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food food, where happy legs are being served with salz and buppets.
2022-03-23 12:15:22 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:15:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to get a few electrodes on his head and understand exactly what all of the thoughts are on the way of the way.
2022-03-23 12:15:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:15:31 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people like the wild took responsibility for the wild, the number of the wild animals, and this is a foundation of natural protection in namibia.
2022-03-23 12:15:31 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:15:35 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bols of magnetic field lines are starting in the inside the inside of the inner field, but the sulalty may not be moving if they need to move their energy, and so the sulalty disorder.
2022-03-23 12:15:35 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:15:40 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from these reflection reflection reflection, we can start with a traditional facial facial, the big constructions of the face of the face and the basic form of information that comes through the whole structure of these reflection.
2022-03-23 12:15:40 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:15:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and measure it very interesting and measure it for me here at tedwomen, is that... in tedwomen, in the best way, when someone said, "when someone said," take you on a table and you say, "you know, if you're going to be able to be able to be able to be able to be here at a lot of the fact that we've been able to be here at tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen in tedwomen who have been here at tedwomen in tedwomen in tedwomen in tedwomen in tedwomen," oh, "oh," yeah, "yeah," oh oh oh oh oh yeah, we've
2022-03-23 12:15:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:15:48 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother is still the invention of invention, and a big part of the design work that we're going to be a result of the plane that we had to solve is that we had to solve unique problems that were connected to the unique problems that were connected to the ground -- everything from a continent, and a big part of the design of the design design work that we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:15:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:15:48 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 10.198 | ppl 1174.64 | bleu 22.42 | wps 4260 | wpb 17862.2 | bsz 728.3 | num_updates 3136 | best_bleu 22.42
2022-03-23 12:15:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3136 updates
2022-03-23 12:15:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:15:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:15:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 20 @ 3136 updates, score 22.42) (writing took 1.7286777520203032 seconds)
2022-03-23 12:15:50 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 12:15:50 | INFO | train | epoch 020 | loss 8.833 | ppl 456.16 | wps 38266.1 | ups 1.52 | wpb 25153.6 | bsz 1020.6 | num_updates 3136 | lr 0.000392 | gnorm 0.536 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 2088
KL Stats: Epoch 20 Divergences: Uniform: 0.9936191411515252 Unigram: 1.5562527778091246
2022-03-23 12:15:50 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 12:15:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:16:14 | INFO | train_inner | epoch 021:     64 / 157 loss=8.708, ppl=418.13, wps=30694.5, ups=1.23, wpb=24958.8, bsz=1113.8, num_updates=3200, lr=0.0004, gnorm=0.577, loss_scale=8, train_wall=36, gb_free=12, wall=2113
2022-03-23 12:16:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:16:53 | INFO | fairseq.tasks.translation | example hypothesis: we put these pills in the clinic of clinic.
2022-03-23 12:16:53 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:16:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 12:16:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:17:01 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be transformed by two new pigments.
2022-03-23 12:17:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:17:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frozen legs will be served with salz and pills.
2022-03-23 12:17:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:17:09 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just going to bring a few electrodes on his head and understand exactly what all of the thoughts are on the way.
2022-03-23 12:17:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:17:13 | INFO | fairseq.tasks.translation | example hypothesis: and this is a foundation of nature in namibia.
2022-03-23 12:17:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:17:17 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the super-disorder of magnetic fields in the inside, but the superconductors don't like it, because they need their movements, and so the susulalty disorder of the superdisorders.
2022-03-23 12:17:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:17:20 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information, which is a whole structure, and we can start with a traditional face.
2022-03-23 12:17:20 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:17:24 | INFO | fairseq.tasks.translation | example hypothesis: and one of the reasons, "if you're in a table revolution, you know, we have a long time with you, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, in this time, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, and you know, you know, you know, you know,
2022-03-23 12:17:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, we had to solve the unique problems on the ground -- everything of a variation, and it allows us to be a very specific machine, or to see that we're going to be able to use it on the ground, all the variation of us to be able to use a very specific machine, and that it allows us to be a very specific machine, to be a very specific machine, to be a very specific machine, or a very specific machine, to be able to use.
2022-03-23 12:17:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:17:26 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 10.175 | ppl 1155.74 | bleu 20.68 | wps 4847.2 | wpb 17862.2 | bsz 728.3 | num_updates 3293 | best_bleu 22.42
2022-03-23 12:17:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3293 updates
2022-03-23 12:17:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 21 @ 3293 updates, score 20.68) (writing took 0.753478713973891 seconds)
2022-03-23 12:17:27 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 12:17:27 | INFO | train | epoch 021 | loss 8.757 | ppl 432.77 | wps 40473 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 3293 | lr 0.000411625 | gnorm 0.551 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 2186
KL Stats: Epoch 21 Divergences: Uniform: 0.9964050638667767 Unigram: 1.5583308349740315
2022-03-23 12:17:28 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 12:17:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:17:30 | INFO | train_inner | epoch 022:      7 / 157 loss=8.876, ppl=469.82, wps=32521.1, ups=1.31, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.557, loss_scale=8, train_wall=37, gb_free=12.8, wall=2189
2022-03-23 12:18:08 | INFO | train_inner | epoch 022:    107 / 157 loss=8.816, ppl=450.64, wps=66050.3, ups=2.69, wpb=24592, bsz=996, num_updates=3400, lr=0.000425, gnorm=0.558, loss_scale=8, train_wall=37, gb_free=11.5, wall=2226
2022-03-23 12:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:18:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:18:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:18:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:18:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:18:38 | INFO | fairseq.tasks.translation | example hypothesis: stars become new goldicks.
2022-03-23 12:18:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:18:42 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and pbump.
2022-03-23 12:18:42 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:18:46 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the way.
2022-03-23 12:18:46 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:18:50 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people responsibility for the wild, the number of wild animals grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:18:50 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:18:54 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field in the inside, but the sulalegter doesn't like it when they're moving around, because their movements need energy to use.
2022-03-23 12:18:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:18:58 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big constructions of the face and the basic form of the shape of the information that gives him the information that comes from the information that comes from the whole portion of this reflection and a fold.
2022-03-23 12:18:58 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:19:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measure it for me at tedwomen, is that... "well, you know, you know, when you're going to get rid of the best," somebody said, "you're going to tell you about the men on your desperate," and then we're going to support you. "
2022-03-23 12:19:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:19:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design that we're on our plane, was a result of the unique problems that we had to solve with the unique problems that were connected to the ground to surgery, and it's all the way that we're going to be refrigergergered to be able to see, and that if you're going to be able to be able to be able to see the refrigergergerman, or the refrigergergerman in the aircraft.
2022-03-23 12:19:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:19:05 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 10.043 | ppl 1054.86 | bleu 25.06 | wps 4717.5 | wpb 17862.2 | bsz 728.3 | num_updates 3450 | best_bleu 25.06
2022-03-23 12:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3450 updates
2022-03-23 12:19:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:19:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 22 @ 3450 updates, score 25.06) (writing took 1.7111038350267336 seconds)
2022-03-23 12:19:06 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 12:19:06 | INFO | train | epoch 022 | loss 8.694 | ppl 414.2 | wps 39773 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 3450 | lr 0.00043125 | gnorm 0.524 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 2285
KL Stats: Epoch 22 Divergences: Uniform: 1.0074878935605571 Unigram: 1.5657696780176378
2022-03-23 12:19:07 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 12:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:19:26 | INFO | train_inner | epoch 023:     50 / 157 loss=8.614, ppl=391.87, wps=32639.8, ups=1.28, wpb=25549.5, bsz=963.1, num_updates=3500, lr=0.0004375, gnorm=0.436, loss_scale=8, train_wall=37, gb_free=11.8, wall=2305
2022-03-23 12:20:03 | INFO | train_inner | epoch 023:    150 / 157 loss=8.493, ppl=360.3, wps=67888, ups=2.68, wpb=25317.8, bsz=1082.4, num_updates=3600, lr=0.00045, gnorm=0.497, loss_scale=8, train_wall=37, gb_free=11.6, wall=2342
2022-03-23 12:20:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:20:10 | INFO | fairseq.tasks.translation | example hypothesis: we put these twet into the clinic.
2022-03-23 12:20:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:20:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:20:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:20:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create the two new pigs.
2022-03-23 12:20:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:20:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz.
2022-03-23 12:20:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:20:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:20:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:20:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people have responsibility for the wild, the number of wild animals grew again. and this is a foundation for conservation in namibia.
2022-03-23 12:20:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:20:34 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bands of magnetic field are caught in the inside, but the superconductor may not like the superconductor, because they're going to move their energy, and so the suicide disorder of magnetic field.
2022-03-23 12:20:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial, the big constructions of the face and the basic shape of the face, and the basic shape of the face, and through the information that comes out of the information that comes from the whole portion of this reflection.
2022-03-23 12:20:39 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that do it high-interesting and measure it for me to be here at tedwomen, is that... well, when you're going to get rid of it, it was the best thing when somebody said, "turn you to the men on a table and say," turn you to the men on a table, "if the revolution starts to tell you."
2022-03-23 12:20:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:20:46 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, the mother of the invention, and a big part of design work that we're on our plane, was a result of it, that we had to solve the unique problems that were connected to the ground, so that it was connected to surely problems that it was connected to the ground -- all the way we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do it.
2022-03-23 12:20:46 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:20:46 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 10.023 | ppl 1040.67 | bleu 25.18 | wps 4570.3 | wpb 17862.2 | bsz 728.3 | num_updates 3607 | best_bleu 25.18
2022-03-23 12:20:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3607 updates
2022-03-23 12:20:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:20:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 23 @ 3607 updates, score 25.18) (writing took 1.7058679690235294 seconds)
2022-03-23 12:20:47 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 12:20:47 | INFO | train | epoch 023 | loss 8.59 | ppl 385.38 | wps 39188.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 3607 | lr 0.000450875 | gnorm 0.48 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 2386
KL Stats: Epoch 23 Divergences: Uniform: 1.0085771949973128 Unigram: 1.5839508281758206
2022-03-23 12:20:48 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 12:20:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:21:23 | INFO | train_inner | epoch 024:     93 / 157 loss=8.602, ppl=388.63, wps=31356.9, ups=1.26, wpb=24933.4, bsz=1048.2, num_updates=3700, lr=0.0004625, gnorm=0.469, loss_scale=8, train_wall=37, gb_free=12.1, wall=2421
2022-03-23 12:21:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:21:50 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep into the clinic.
2022-03-23 12:21:50 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:21:54 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:21:54 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:21:58 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks that create two new pigs.
2022-03-23 12:21:58 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:22:02 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:22:02 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:22:06 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the road.
2022-03-23 12:22:06 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:22:10 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wild, grew up the number of wild animals, and that's a basis for conservation in namibia.
2022-03-23 12:22:10 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:22:14 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are caught in the inner, but the superconductor don't like when they move, because their movements are moving, and so the superconducting disorders.
2022-03-23 12:22:14 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the big constraints of the face and the basic shape, and through the information that will fold all the ports and fold it through.
2022-03-23 12:22:18 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:22:22 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and measured to me here at tedwomen is that... well, when they were distorted at the best when someone said, "turn to the men in your table and say,"] ["] ["] ["] ["]] ["] ["] ["] ["] ["] ["] ["] [[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[we
2022-03-23 12:22:22 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:22:24 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of the invention, and a big part of the design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continued to a continuum and refrigerator system that allows us to see in our aircraft, and that if you use it into the air, or if you use it to see the mechanism to a mechanism, or to a mechanism that we use it into a mechanism, to a mechanism, to the mechanism, to the trajectory system that we're either distorcted to the trajectory system that we can use it into the trajectively, to the air refriction of a mechanism, to the aircraft.
2022-03-23 12:22:24 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:22:24 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.91 | ppl 962.08 | bleu 27.22 | wps 4792.8 | wpb 17862.2 | bsz 728.3 | num_updates 3764 | best_bleu 27.22
2022-03-23 12:22:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3764 updates
2022-03-23 12:22:24 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:22:25 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:22:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 24 @ 3764 updates, score 27.22) (writing took 1.7032831570249982 seconds)
2022-03-23 12:22:26 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 12:22:26 | INFO | train | epoch 024 | loss 8.526 | ppl 368.65 | wps 39985 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 3764 | lr 0.0004705 | gnorm 0.447 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 2485
KL Stats: Epoch 24 Divergences: Uniform: 1.013347538763808 Unigram: 1.5900090711914805
2022-03-23 12:22:26 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 12:22:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:22:40 | INFO | train_inner | epoch 025:     36 / 157 loss=8.377, ppl=332.46, wps=33006.7, ups=1.29, wpb=25565.7, bsz=1063.5, num_updates=3800, lr=0.000475, gnorm=0.425, loss_scale=8, train_wall=37, gb_free=12.5, wall=2499
2022-03-23 12:23:18 | INFO | train_inner | epoch 025:    136 / 157 loss=8.549, ppl=374.66, wps=66628.6, ups=2.67, wpb=24971.5, bsz=968.1, num_updates=3900, lr=0.0004875, gnorm=0.485, loss_scale=8, train_wall=37, gb_free=12.6, wall=2536
2022-03-23 12:23:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:23:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:23:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:23:33 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:23:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:23:37 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new golden locks.
2022-03-23 12:23:37 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:23:41 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and psuitcase.
2022-03-23 12:23:41 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:23:45 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all your thoughts are on the track.
2022-03-23 12:23:45 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:23:49 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wild animals. and that's a basis for conservation in namibia.
2022-03-23 12:23:49 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:23:53 | INFO | fairseq.tasks.translation | example hypothesis: first, some bloody of magnetic field lines are caught inside, but the superconductor doesn't like it when you move, because your movements use your energy, and so the supersuperconductor disorder.
2022-03-23 12:23:53 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:23:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which is the big constraints of the face and the basic shape, and through the basic form, and the basic shape of the information, which includes the whole portion structure and a fold.
2022-03-23 12:23:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:24:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are high-interesting and measuring to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn you to the men on a table and tell you," if the revolution starts. "
2022-03-23 12:24:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:24:01 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a great part of design work that we're on our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation and a refrigeration system that allows us to use.
2022-03-23 12:24:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:24:01 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.944 | ppl 984.79 | bleu 25.48 | wps 5293.7 | wpb 17862.2 | bsz 728.3 | num_updates 3921 | best_bleu 27.22
2022-03-23 12:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3921 updates
2022-03-23 12:24:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:24:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:24:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 25 @ 3921 updates, score 25.48) (writing took 0.7736745340516791 seconds)
2022-03-23 12:24:01 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 12:24:01 | INFO | train | epoch 025 | loss 8.488 | ppl 359.15 | wps 41402.2 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 3921 | lr 0.000490125 | gnorm 0.464 | loss_scale 8 | train_wall 58 | gb_free 12.8 | wall 2580
KL Stats: Epoch 25 Divergences: Uniform: 1.0123064746789743 Unigram: 1.5940115020960497
2022-03-23 12:24:02 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 12:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:24:32 | INFO | train_inner | epoch 026:     79 / 157 loss=8.36, ppl=328.45, wps=34349.9, ups=1.35, wpb=25448.4, bsz=1017.2, num_updates=4000, lr=0.0005, gnorm=0.422, loss_scale=8, train_wall=37, gb_free=11.2, wall=2610
2022-03-23 12:25:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:25:04 | INFO | fairseq.tasks.translation | example hypothesis: we put these sheep in the clinic.
2022-03-23 12:25:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:25:08 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that most of you know here.
2022-03-23 12:25:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:25:12 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 12:25:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:25:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where frog legs are served with salz and psuitcase.
2022-03-23 12:25:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:25:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all the thoughts are on the track.
2022-03-23 12:25:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:25:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the case like the people responsibility for the wildlife, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 12:25:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured in the inside, but the superconductor may not like when they move, because their movements use, and so the superconductor disorders.
2022-03-23 12:25:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:25:33 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can start with the big constructions of the face and the basic form of information, which is the whole portion of information and all the fits.
2022-03-23 12:25:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:25:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured for me to be here at tedwomen is that... well, it's been put together the best when someone said, "turn you to the men on a table and tell you," if the revolution begins, "the truth is that we've been supporting you've already supporting you've already supported to you," we've been supported for you've already supporting you've already supporting you've been a long time with you've already supporting you've already been in this topic topic for a long time. "
2022-03-23 12:25:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:25:39 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of the invention is still the mother of the invention, and a big part of the design work that we're on our plane at the stumbling, was a result that we had to solve the unique problems that were connected to operations -- everything from a continuous variation system with a refrigerators and refrigeration system that allows us to be able to use in the aircraft that we're in the aircraft to be able to use, to use, to be specific or to be able to be able to use the most specific, if we're either the most specific, to be able to see the most specific, to be able to be able to be able to be able to be able to be able to be able to be able to see the most specific, to be able to be able to be able to be able to be able to be able to see the most specific, to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-23 12:25:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:25:39 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.804 | ppl 893.85 | bleu 29.04 | wps 4677.4 | wpb 17862.2 | bsz 728.3 | num_updates 4078 | best_bleu 29.04
2022-03-23 12:25:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4078 updates
2022-03-23 12:25:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:25:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 26 @ 4078 updates, score 29.04) (writing took 1.6945025650202297 seconds)
2022-03-23 12:25:41 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 12:25:41 | INFO | train | epoch 026 | loss 8.414 | ppl 341.1 | wps 39593.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4078 | lr 0.000495195 | gnorm 0.426 | loss_scale 8 | train_wall 58 | gb_free 12.4 | wall 2680
KL Stats: Epoch 26 Divergences: Uniform: 1.0150269966397332 Unigram: 1.6032811815927093
2022-03-23 12:25:41 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 12:25:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:25:50 | INFO | train_inner | epoch 027:     22 / 157 loss=8.431, ppl=345.07, wps=31899.6, ups=1.27, wpb=25035.3, bsz=1086.6, num_updates=4100, lr=0.000493865, gnorm=0.419, loss_scale=8, train_wall=37, gb_free=11.9, wall=2689
2022-03-23 12:26:27 | INFO | train_inner | epoch 027:    122 / 157 loss=8.391, ppl=335.61, wps=66835.2, ups=2.68, wpb=24941.2, bsz=964.6, num_updates=4200, lr=0.00048795, gnorm=0.421, loss_scale=8, train_wall=37, gb_free=12, wall=2726
2022-03-23 12:26:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:26:44 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:26:44 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-23 12:26:48 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:26:52 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks of the two new pigments.
2022-03-23 12:26:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:26:56 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and psuitcase.
2022-03-23 12:26:56 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:27:00 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like people's responsibility for the wildlife, the number of wildanimals grew up again, and that's a basis for conservation in namibia.
2022-03-23 12:27:04 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example hypothesis: first, some magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:27:08 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can begin to restore the big constraints of the face and the basic shape of this information that fits all the portion structure and all the fits.
2022-03-23 12:27:12 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn to the men on your table and tell you," if the revolution begins, "the truth is that we've been supporting you."
2022-03-23 12:27:16 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our airplane at the proud of the stack, was a result that we had to solve the unique problems that were connected to surgery -- everything from a continuous variation and a refrigerator system, that it allows us to use.
2022-03-23 12:27:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:27:17 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.798 | ppl 890.27 | bleu 29.19 | wps 5028.8 | wpb 17862.2 | bsz 728.3 | num_updates 4235 | best_bleu 29.19
2022-03-23 12:27:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4235 updates
2022-03-23 12:27:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:27:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 27 @ 4235 updates, score 29.19) (writing took 1.7368509779917076 seconds)
2022-03-23 12:27:19 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 12:27:19 | INFO | train | epoch 027 | loss 8.355 | ppl 327.36 | wps 40422.3 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 4235 | lr 0.00048593 | gnorm 0.405 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 2778
KL Stats: Epoch 27 Divergences: Uniform: 1.0187523276706518 Unigram: 1.6133993236064397
2022-03-23 12:27:19 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 12:27:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:27:44 | INFO | train_inner | epoch 028:     65 / 157 loss=8.361, ppl=328.83, wps=32775.9, ups=1.31, wpb=24983.4, bsz=1008.5, num_updates=4300, lr=0.000482243, gnorm=0.384, loss_scale=8, train_wall=37, gb_free=12.6, wall=2802
2022-03-23 12:28:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:28:22 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:28:22 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:28:26 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:28:26 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:28:29 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that make two new pigs.
2022-03-23 12:28:29 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:28:34 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:28:34 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:28:38 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all his thoughts are on the track.
2022-03-23 12:28:38 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:28:42 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wild animals grew back, and that's a basis for conservation in namibia.
2022-03-23 12:28:42 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:28:46 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:28:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:28:50 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial, which is the big constraints of the face and the basic shape, and through the one of the one that refers all the porn structure and all the fits a fold.
2022-03-23 12:28:50 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:28:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's really interesting and measured to me here at tedwomen is that... well, when the pride dinner, it was best summarized when someone said, "turn to the men in your table and tell them," if the revolution starts to support you. "the truth is that we've already been supporting you for a long time."
2022-03-23 12:28:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we are on our airplane at the proud of, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variation and a refrigeration system that allows us to use the aircraft to make us a refrigerator, or to use the aircraft, if we have to make a specific traffic, we have to use the soil, or the same as we've got to the same as you've got to the same as you've got to use the same as you've got to use the same as you've got to drive the same as you've got to drive, you've got to drive, you've got to use the same as you've got to drive, you've got to use the same as you've got to use it.
2022-03-23 12:28:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:28:56 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.748 | ppl 859.96 | bleu 30.04 | wps 4752 | wpb 17862.2 | bsz 728.3 | num_updates 4392 | best_bleu 30.04
2022-03-23 12:28:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4392 updates
2022-03-23 12:28:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:28:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:28:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 28 @ 4392 updates, score 30.04) (writing took 1.7437740580062382 seconds)
2022-03-23 12:28:58 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 12:28:58 | INFO | train | epoch 028 | loss 8.308 | ppl 316.97 | wps 39819.1 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4392 | lr 0.000477165 | gnorm 0.404 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 2877
KL Stats: Epoch 28 Divergences: Uniform: 1.0187131681580737 Unigram: 1.6172883725538227
2022-03-23 12:28:58 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 12:28:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:29:01 | INFO | train_inner | epoch 029:      8 / 157 loss=8.282, ppl=311.18, wps=32360.9, ups=1.29, wpb=25115.8, bsz=996.1, num_updates=4400, lr=0.000476731, gnorm=0.427, loss_scale=8, train_wall=37, gb_free=12.6, wall=2880
2022-03-23 12:29:39 | INFO | train_inner | epoch 029:    108 / 157 loss=8.294, ppl=313.87, wps=66855.8, ups=2.66, wpb=25124.7, bsz=1021.9, num_updates=4500, lr=0.000471405, gnorm=0.385, loss_scale=8, train_wall=37, gb_free=11.9, wall=2918
2022-03-23 12:29:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:30:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:30:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:30:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:30:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:30:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to translate two new pigs.
2022-03-23 12:30:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:30:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-23 12:30:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:30:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:30:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:30:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people were taking responsibility for the wild, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 12:30:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:30:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are captured inside, but the superconductor doesn't like when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:30:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:30:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constructions of the face and the basic shape of that information that refuses all the ports structure and all the fits.
2022-03-23 12:30:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:30:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it was highly interesting and measured to me here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts to support you. "
2022-03-23 12:30:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our aircraft on the proud of, was a result that we had to solve the unique problems that were connected to surveillance -- everything from a continuous variation and a refrigerator system that allows us to stop an aircraft, until a mechanism, or if you can see the power of a mechanism, or if you can use the air, or if you can use it to a mechanism, or if you're either if you can see the air, until you can use it, or if you can use it, or if you can use the air, or you can use it, or if you can use it, until you can use it, until you can use it, until you can use it, or if you can, or if you can, or you can use it, or you can use it, or you can, or you can use it, or you can use it, or you can
2022-03-23 12:30:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:30:36 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.704 | ppl 834 | bleu 30.41 | wps 4737.7 | wpb 17862.2 | bsz 728.3 | num_updates 4549 | best_bleu 30.41
2022-03-23 12:30:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4549 updates
2022-03-23 12:30:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:30:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 29 @ 4549 updates, score 30.41) (writing took 1.69593470194377 seconds)
2022-03-23 12:30:37 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 12:30:37 | INFO | train | epoch 029 | loss 8.265 | ppl 307.55 | wps 39770.4 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 4549 | lr 0.000468859 | gnorm 0.393 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 2976
KL Stats: Epoch 29 Divergences: Uniform: 1.0164554564717065 Unigram: 1.6192685324048421
2022-03-23 12:30:38 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 12:30:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:30:57 | INFO | train_inner | epoch 030:     51 / 157 loss=8.252, ppl=304.89, wps=32221.5, ups=1.28, wpb=25166.4, bsz=979.4, num_updates=4600, lr=0.000466252, gnorm=0.381, loss_scale=8, train_wall=37, gb_free=12.4, wall=2996
2022-03-23 12:31:34 | INFO | train_inner | epoch 030:    151 / 157 loss=8.192, ppl=292.41, wps=67759.4, ups=2.67, wpb=25347.5, bsz=1039.1, num_updates=4700, lr=0.000461266, gnorm=0.358, loss_scale=8, train_wall=37, gb_free=12.3, wall=3033
2022-03-23 12:31:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:31:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep up in the clinic.
2022-03-23 12:31:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:31:45 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most people here know.
2022-03-23 12:31:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:31:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that will create two new pigs.
2022-03-23 12:31:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:31:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pepper.
2022-03-23 12:31:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:31:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example hypothesis: and it's like people's responsibility for the wild, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-23 12:32:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:32:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:32:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:32:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeat the big constraints of the face and the basic shape of that information that refers the entire porting structure and all the fits fold.
2022-03-23 12:32:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:32:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to me here at tedwomen is that... well, when striking dinner, it was best summarized when someone said, "turn to the men to your table and tell them," 'the truth is we've already supported you for this time. "
2022-03-23 12:32:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane at the most stumbled, was a result that we had to solve the unique problems that were connected to operations on the ground -- everything from a continuous variation and a refrigeration system that allows us to use an aircraft in a specific way to a specialist, to either be able to use the ground if you can use it to make a specialist, until the one of the most specific solution to a mechanism, to a specific solution to a specialist, to the ground, to an aircraft that allows us to make it, to a specialist, to make it, to a specialist, to a specialist, to a specialist, to a specialist, to the ground, to a specific machine that is to make it, to make it.
2022-03-23 12:32:16 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:32:16 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.688 | ppl 824.61 | bleu 30.57 | wps 4699.7 | wpb 17862.2 | bsz 728.3 | num_updates 4706 | best_bleu 30.57
2022-03-23 12:32:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4706 updates
2022-03-23 12:32:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 30 @ 4706 updates, score 30.57) (writing took 1.728868160978891 seconds)
2022-03-23 12:32:17 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 12:32:17 | INFO | train | epoch 030 | loss 8.213 | ppl 296.73 | wps 39439 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4706 | lr 0.000460971 | gnorm 0.362 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 3076
KL Stats: Epoch 30 Divergences: Uniform: 1.017792373306981 Unigram: 1.629183214858352
2022-03-23 12:32:18 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 12:32:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:32:54 | INFO | train_inner | epoch 031:     94 / 157 loss=8.137, ppl=281.49, wps=32153.2, ups=1.26, wpb=25475, bsz=1043.1, num_updates=4800, lr=0.000456435, gnorm=0.381, loss_scale=8, train_wall=37, gb_free=12.3, wall=3112
2022-03-23 12:33:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:33:21 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:33:21 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:33:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 12:33:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:33:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs.
2022-03-23 12:33:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:33:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where happy legs are served with salz and pepper suitcase.
2022-03-23 12:33:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:33:37 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all his thoughts are on the track.
2022-03-23 12:33:37 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:33:41 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wild animals grew up again, and it's become a basis for conservation in namibia.
2022-03-23 12:33:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:33:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:33:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:33:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional face can start with a traditional face that restores the big constraints of the face and the basic shape of information that refers all the ports structure and all the fits through.
2022-03-23 12:33:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:33:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that are highly interesting and appropriate for me to be here at tedwomen is that... tyes, when dinner was the best summarized, when someone said, "turn to the men on your table and say," if the revolution begins to support you. "the truth is that we've already supported you for a long time."
2022-03-23 12:33:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane at the proud of was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything from a continuous variation and a refrigeration system that allows us to use a machine on our aircraft on the top of the top of a stack of aircraft to be a specific, or when you're going to see the most reliable, or if you're going to be able to be able to be able to be able to use the lowered by a mechanism, or if you're going to be able to use it, or if you're a mechanism, or if you're a mechanism, you're going to use it, you're a mechanism, you're going to use it, you're going to use it, or if you're going to be able to use it, you're going to be able to be able to be able to see the
2022-03-23 12:33:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:33:56 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.653 | ppl 804.95 | bleu 31.43 | wps 4643.2 | wpb 17862.2 | bsz 728.3 | num_updates 4863 | best_bleu 31.43
2022-03-23 12:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4863 updates
2022-03-23 12:33:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:33:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:33:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 31 @ 4863 updates, score 31.43) (writing took 1.694375088030938 seconds)
2022-03-23 12:33:58 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 12:33:58 | INFO | train | epoch 031 | loss 8.194 | ppl 292.83 | wps 39446.1 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 4863 | lr 0.000453469 | gnorm 0.378 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 3176
KL Stats: Epoch 31 Divergences: Uniform: 1.0174893540987349 Unigram: 1.630425081383916
2022-03-23 12:33:58 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 12:33:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:34:12 | INFO | train_inner | epoch 032:     37 / 157 loss=8.237, ppl=301.77, wps=31690, ups=1.27, wpb=24862.4, bsz=1037.8, num_updates=4900, lr=0.000451754, gnorm=0.354, loss_scale=8, train_wall=37, gb_free=11.5, wall=3191
2022-03-23 12:34:50 | INFO | train_inner | epoch 032:    137 / 157 loss=8.076, ppl=269.92, wps=67496, ups=2.66, wpb=25359.2, bsz=1036.4, num_updates=5000, lr=0.000447214, gnorm=0.385, loss_scale=8, train_wall=37, gb_free=12, wall=3228
2022-03-23 12:34:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:35:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these tweep in the clinic.
2022-03-23 12:35:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:35:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 12:35:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:35:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will make two new pigs.
2022-03-23 12:35:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:35:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salz and pepper.
2022-03-23 12:35:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:35:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:35:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:35:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number grew up again. and that's a basis for conservation in namibia.
2022-03-23 12:35:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:35:25 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:35:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:35:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional face can start with a traditional face that refers the big constraints of the face and the basic shape, and we recover it through the one that refers the whole porter structure and all the fits.
2022-03-23 12:35:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:35:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized, it's when somebody said, "turn to your table and tell you," if the revolution begins, we support you. "'" the truth, women, love, we've already supported you for this topic for a long time.
2022-03-23 12:35:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still, and a large part of the design work that we're on on our plane, was a result that we had to solve the unique problems that were connected to this -- everything, from a continuous variation and a refrigeration system that allows us to use an aircraft in the aircraft, until a refrigeration system that allows us to use a trajectory machine to a trajectory, or a refrigeration of a trajectory system that allows us to use of a trajectory system of a trajectory system of a tragic transport, until a trajectory system that is to use of a trajectory system of a trajectory, or a refrigeration, until the most specific prophearsal system that is, until a mechanism, until a mechanism, or if you see it, until the trajectory system.
2022-03-23 12:35:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:35:35 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.638 | ppl 796.78 | bleu 31.45 | wps 4701.7 | wpb 17862.2 | bsz 728.3 | num_updates 5020 | best_bleu 31.45
2022-03-23 12:35:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5020 updates
2022-03-23 12:35:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:35:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 32 @ 5020 updates, score 31.45) (writing took 1.7357894370215945 seconds)
2022-03-23 12:35:37 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 12:35:37 | INFO | train | epoch 032 | loss 8.151 | ppl 284.29 | wps 39649.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5020 | lr 0.000446322 | gnorm 0.367 | loss_scale 8 | train_wall 58 | gb_free 12.6 | wall 3276
KL Stats: Epoch 32 Divergences: Uniform: 1.0181547004540283 Unigram: 1.6363739103728114
2022-03-23 12:35:37 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 12:35:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:36:08 | INFO | train_inner | epoch 033:     80 / 157 loss=8.156, ppl=285.3, wps=32009.5, ups=1.28, wpb=24994, bsz=1108.6, num_updates=5100, lr=0.000442807, gnorm=0.352, loss_scale=8, train_wall=37, gb_free=11.7, wall=3307
2022-03-23 12:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:36:40 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic clinic.
2022-03-23 12:36:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:36:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:36:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:36:49 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinments that create two new pigs.
2022-03-23 12:36:49 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:36:53 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:36:53 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:36:57 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:36:57 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:37:01 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back again, and that's a basis for conservation in namibia.
2022-03-23 12:37:01 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:37:05 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:37:05 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:37:09 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restore the big constraints of the face and the basic shape, and recover it through the one of the information that refers the whole porter structure and all the fits.
2022-03-23 12:37:09 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:37:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and measured to be here at tedwomen is that... well, in the striking dinner, it was best summarized when someone said, "turn to the men on your table and tell them," if the revolution starts to support you. '"the truth is that we've already been supporting you for a long time."
2022-03-23 12:37:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:37:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we are on our aircraft on the proud of was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything, from a continuous variation and a refrigerator system that allows us to use an aircraft in the air until a specific vehicle, or when you see the aircraft.
2022-03-23 12:37:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:37:15 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.592 | ppl 771.84 | bleu 32.38 | wps 4747.6 | wpb 17862.2 | bsz 728.3 | num_updates 5177 | best_bleu 32.38
2022-03-23 12:37:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5177 updates
2022-03-23 12:37:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:37:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 33 @ 5177 updates, score 32.38) (writing took 1.708352807967458 seconds)
2022-03-23 12:37:16 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 12:37:16 | INFO | train | epoch 033 | loss 8.115 | ppl 277.33 | wps 39751.3 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5177 | lr 0.000439502 | gnorm 0.347 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 3375
KL Stats: Epoch 33 Divergences: Uniform: 1.0177196061500327 Unigram: 1.642327176035778
2022-03-23 12:37:17 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 12:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:37:26 | INFO | train_inner | epoch 034:     23 / 157 loss=8.134, ppl=280.86, wps=32165.2, ups=1.28, wpb=25153.7, bsz=930.1, num_updates=5200, lr=0.000438529, gnorm=0.35, loss_scale=8, train_wall=37, gb_free=12, wall=3385
2022-03-23 12:38:03 | INFO | train_inner | epoch 034:    123 / 157 loss=8.101, ppl=274.65, wps=67017.9, ups=2.67, wpb=25137.7, bsz=1040.6, num_updates=5300, lr=0.000434372, gnorm=0.359, loss_scale=8, train_wall=37, gb_free=12.6, wall=3422
2022-03-23 12:38:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:38:20 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppets in the clinic.
2022-03-23 12:38:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:38:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most of you know here.
2022-03-23 12:38:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:38:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks in the two new pigs.
2022-03-23 12:38:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:38:32 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:38:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:38:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just bringing some electrodes on his head and understanding exactly what all of its thoughts are on the track.
2022-03-23 12:38:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:38:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and this is a basis for conservation in namibia.
2022-03-23 12:38:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:38:45 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it if they move, because their movements are using energy, and so the superconducting disorder.
2022-03-23 12:38:45 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:38:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restored the big constraints of the face and refined the basic form of information that refers all the ports structure and all the fits.
2022-03-23 12:38:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:38:54 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that... well, when dinner was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, "we'll support you. '' '" the truth is that we've already been supporting you for a long time. "well, we've already been supporting you for this topic for a long time."' "'"' "'"' "'"' "'" by raw, "'" '"'" '"'" 'if you know, "'" 'if you know, "' if you know," '"'" '"'" '"' if you know," 'if you know, "well,'" '"'" '
2022-03-23 12:38:54 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:38:56 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our plane at the proud toes, was a result that we had to solve the unique problems that were connected to them on the ground -- everything, from a continuous variables and a refrigerator system that allows us to use an aircraft in the gossip until either one of us to use it, until you can use it to use it for a specially, until you can either, until you can use it, or if you can use it's a mechanism, until you can, until you can't use it's not until you can use it, until you can use it, until you can, until you can, until you can't use it's either, until you can use it's the wrong, until you can use it's a mechanism, until you can, until you can, until you can use it's a constant, until you can't use it, until you can't use it's a
2022-03-23 12:38:56 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:38:56 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 9.615 | ppl 784.31 | bleu 32.29 | wps 4553.3 | wpb 17862.2 | bsz 728.3 | num_updates 5334 | best_bleu 32.38
2022-03-23 12:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5334 updates
2022-03-23 12:38:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 34 @ 5334 updates, score 32.29) (writing took 0.7586085459915921 seconds)
2022-03-23 12:38:57 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 12:38:57 | INFO | train | epoch 034 | loss 8.094 | ppl 273.15 | wps 39327.4 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5334 | lr 0.000432986 | gnorm 0.369 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 3476
KL Stats: Epoch 34 Divergences: Uniform: 1.018325407190523 Unigram: 1.6446181396996167
2022-03-23 12:38:57 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 12:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:39:22 | INFO | train_inner | epoch 035:     66 / 157 loss=8.027, ppl=260.82, wps=31906.9, ups=1.27, wpb=25119, bsz=947.5, num_updates=5400, lr=0.000430331, gnorm=0.369, loss_scale=8, train_wall=37, gb_free=12.3, wall=3501
2022-03-23 12:39:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:40:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 12:40:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:40:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most here.
2022-03-23 12:40:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:40:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden dilocks that are going to overcome two new pigs.
2022-03-23 12:40:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:40:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and pepper.
2022-03-23 12:40:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:40:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on his head and understanding exactly what all of its thoughts are on the track.
2022-03-23 12:40:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:40:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildanimals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:40:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:40:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like moving because their movements use energy and so the superconductor disorder.
2022-03-23 12:40:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:40:29 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeat the big configurations of the face and the basic form, and enhance it through the one thing that refers the whole porting structure and all the fine folds.
2022-03-23 12:40:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:40:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to be here at tedwomen is that... well, when dinner was best summarized, when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. "'" the truth, women, we've already been supporting you for a long time. "
2022-03-23 12:40:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:40:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on our aircraft on the proud toes was a result that we had to solve the unique problems that were connected to surgery on the ground -- everything from a continuous variable and a refrigerator system with liquid fluid that allows us to use an aircraft in traffic to either appropriate or when you see the most specific problems that are connected to the ground, until you see it's all the wrong -- everything from a mechanism, all the right?
2022-03-23 12:40:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:40:35 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 9.573 | ppl 761.74 | bleu 32.31 | wps 4770.5 | wpb 17862.2 | bsz 728.3 | num_updates 5491 | best_bleu 32.38
2022-03-23 12:40:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5491 updates
2022-03-23 12:40:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:40:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:40:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 35 @ 5491 updates, score 32.31) (writing took 0.7568971200380474 seconds)
2022-03-23 12:40:36 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 12:40:36 | INFO | train | epoch 035 | loss 8.056 | ppl 266.13 | wps 39803.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 5491 | lr 0.000426751 | gnorm 0.329 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 3575
KL Stats: Epoch 35 Divergences: Uniform: 1.018801718707005 Unigram: 1.6535038812104979
2022-03-23 12:40:36 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 12:40:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:40:40 | INFO | train_inner | epoch 036:      9 / 157 loss=8.123, ppl=278.85, wps=32144.1, ups=1.28, wpb=25032.4, bsz=1069.2, num_updates=5500, lr=0.000426401, gnorm=0.317, loss_scale=8, train_wall=37, gb_free=12.4, wall=3579
2022-03-23 12:41:18 | INFO | train_inner | epoch 036:    109 / 157 loss=8.045, ppl=264.04, wps=66903, ups=2.66, wpb=25186, bsz=1026.7, num_updates=5600, lr=0.000422577, gnorm=0.336, loss_scale=8, train_wall=37, gb_free=12.8, wall=3616
2022-03-23 12:41:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:41:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beetles in the clinic.
2022-03-23 12:41:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:41:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha who probably know most of you here.
2022-03-23 12:41:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:41:47 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will create two new pigs.
2022-03-23 12:41:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:41:51 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:41:51 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:41:55 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:41:55 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:41:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for the wild, the number of wildanimals grew up again, and that's a basis for conservation in namibia.
2022-03-23 12:41:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it, if you move, because your movements use energy, and so the superconductor disorder.
2022-03-23 12:42:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:42:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the big constraints of the face and the basic form, and then refined it through the one that refers the entire porter structure and all the fits folds.
2022-03-23 12:42:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:42:13 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that, well, when a strict dinner, it was the best summarized when someone said, "turn to the men on your table and tell them," if the revolution begins, we'll support you. '"'" 'the truth, we love, we've already been supporting you for a long time. "
2022-03-23 12:42:13 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:42:15 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a big part of the design work that we're on our plane at the proud of, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable shrinkage and a refrigerator system that allows us to use on our aircraft on the top of the clothes to go, and it was an outdoorstep, and it would make sure that we had to make sure that we had to do it would be tilacked up until the progressed that we would be tilacked to make it would be tilacked, or if we would be till the wrong, or if you'd be connected to see it's going to be tilacked to do it's going to be till you'd be till you'd be able to see it's going to be able to do it's going to get rid of the
2022-03-23 12:42:15 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:42:15 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 9.583 | ppl 766.93 | bleu 32.72 | wps 4555 | wpb 17862.2 | bsz 728.3 | num_updates 5648 | best_bleu 32.72
2022-03-23 12:42:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5648 updates
2022-03-23 12:42:15 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:42:16 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:42:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 36 @ 5648 updates, score 32.72) (writing took 1.7143761449842714 seconds)
2022-03-23 12:42:17 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 12:42:17 | INFO | train | epoch 036 | loss 8.038 | ppl 262.76 | wps 39209.5 | ups 1.56 | wpb 25153.6 | bsz 1020.6 | num_updates 5648 | lr 0.000420778 | gnorm 0.352 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 3676
KL Stats: Epoch 36 Divergences: Uniform: 1.0199609792472368 Unigram: 1.6526477978222398
2022-03-23 12:42:17 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 12:42:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:42:37 | INFO | train_inner | epoch 037:     52 / 157 loss=7.865, ppl=233.05, wps=32364.2, ups=1.27, wpb=25580.8, bsz=1115.6, num_updates=5700, lr=0.000418854, gnorm=0.356, loss_scale=8, train_wall=37, gb_free=12.2, wall=3696
2022-03-23 12:43:14 | INFO | train_inner | epoch 037:    152 / 157 loss=8.162, ppl=286.45, wps=66121.6, ups=2.67, wpb=24729.4, bsz=902.1, num_updates=5800, lr=0.000415227, gnorm=0.342, loss_scale=8, train_wall=37, gb_free=11.8, wall=3733
2022-03-23 12:43:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:43:20 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 12:43:20 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:43:24 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that probably most people know here.
2022-03-23 12:43:24 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:43:28 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will overcome two new pigs.
2022-03-23 12:43:28 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:43:31 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:43:32 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:43:36 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all the thoughts are on the track.
2022-03-23 12:43:36 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:43:40 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew up again, and this is a basis for conservation in namibia.
2022-03-23 12:43:40 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:43:44 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic fields are captured inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconducting disorder.
2022-03-23 12:43:44 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:43:48 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that resembles the big constraints of the face and the basic form of information that refers the whole porter structure and fold all the fits.
2022-03-23 12:43:48 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:43:53 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate to be here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn to the men on your table and tell them," 'if the revolution starts to support you. "'" '"'" '"' the truth, women is that we've already been supporting you for a long time."
2022-03-23 12:43:53 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:43:55 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're most proud of at our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a refrigerator system with liquid fluid, that allows us to use an aircraft in the aircraft that allows us to use a aircraft in the closest place in our aircraft, until a specific transportation to use a specific traffic machine, until you see it, either when you see the propellum, or if you're in a mechanism, if you're in a mechanism, all the ground, all the wrong place that's going to see it's going to a mechanism, all the wrong system of a continuously variable.
2022-03-23 12:43:55 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:43:55 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 9.55 | ppl 749.55 | bleu 33.06 | wps 4629 | wpb 17862.2 | bsz 728.3 | num_updates 5805 | best_bleu 33.06
2022-03-23 12:43:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 5805 updates
2022-03-23 12:43:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:43:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 37 @ 5805 updates, score 33.06) (writing took 1.721305210958235 seconds)
2022-03-23 12:43:57 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 12:43:57 | INFO | train | epoch 037 | loss 8.018 | ppl 259.15 | wps 39455.6 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 5805 | lr 0.000415049 | gnorm 0.336 | loss_scale 8 | train_wall 58 | gb_free 12.3 | wall 3776
KL Stats: Epoch 37 Divergences: Uniform: 1.0203005551999977 Unigram: 1.65750054956314
2022-03-23 12:43:57 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 12:43:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:44:33 | INFO | train_inner | epoch 038:     95 / 157 loss=8.168, ppl=287.64, wps=31262.9, ups=1.27, wpb=24664.6, bsz=1009.5, num_updates=5900, lr=0.000411693, gnorm=0.325, loss_scale=8, train_wall=37, gb_free=12, wall=3812
2022-03-23 12:44:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:45:00 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:45:00 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:45:04 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-23 12:45:04 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:45:08 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will make two new pigs transfer.
2022-03-23 12:45:08 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:45:11 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:45:11 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:45:15 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:45:15 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:45:20 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wild animals grew up again, and this has become a basis for conservation in namibia.
2022-03-23 12:45:20 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:45:24 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements use their energy, and so the superconducting disorder.
2022-03-23 12:45:24 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:45:28 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the grows of the face and the basic form of information that refers the whole porch structure and all the folds.
2022-03-23 12:45:28 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:45:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen is that -- well, when dinner was best summarized, when someone said, "turn to the men down to your table and say," 'when the revolution begins, we support you.' the truth, women is that we've already been supporting you for a long time. "
2022-03-23 12:45:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our aircraft, was a result that we had to solve the unique problems that were connected to operations on the ground -- everything from a continuous variation and a refrigeration system with fluid, that allows us to use an aircraft in the aircraft to go to a special traffic until either passenger, or when you see the propeller in a mechanism of an aircraft, all the wrong floor of a mechanism of a mechanism, until you see the wrong system that drill a mechanism that drill a mechanism of an aircraft that drives you see it's going to a mechanism of a mechanism, until you see it's going to a mechanism, you see it's going to be drill you see it's flowing you can see it's flowing you're in a mechanism, all the wrong system that drill you can see the wrong
2022-03-23 12:45:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:45:35 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 9.538 | ppl 743.49 | bleu 32.74 | wps 4679.6 | wpb 17862.2 | bsz 728.3 | num_updates 5962 | best_bleu 33.06
2022-03-23 12:45:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 5962 updates
2022-03-23 12:45:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:45:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:45:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 38 @ 5962 updates, score 32.74) (writing took 0.7558282079990022 seconds)
2022-03-23 12:45:36 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 12:45:36 | INFO | train | epoch 038 | loss 7.997 | ppl 255.45 | wps 40032 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 5962 | lr 0.000409547 | gnorm 0.339 | loss_scale 8 | train_wall 58 | gb_free 13.1 | wall 3874
KL Stats: Epoch 38 Divergences: Uniform: 1.019823334810711 Unigram: 1.6612114748530609
2022-03-23 12:45:36 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 12:45:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:45:51 | INFO | train_inner | epoch 039:     38 / 157 loss=7.727, ppl=211.91, wps=33640.7, ups=1.29, wpb=26083.6, bsz=1155.6, num_updates=6000, lr=0.000408248, gnorm=0.328, loss_scale=8, train_wall=37, gb_free=12.9, wall=3889
2022-03-23 12:46:28 | INFO | train_inner | epoch 039:    138 / 157 loss=8.022, ppl=259.93, wps=66630.9, ups=2.68, wpb=24907.7, bsz=936.1, num_updates=6100, lr=0.000404888, gnorm=0.362, loss_scale=8, train_wall=37, gb_free=22.3, wall=3927
2022-03-23 12:46:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:46:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pieppets in the clinic.
2022-03-23 12:46:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:46:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which probably most people know here.
2022-03-23 12:46:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:46:46 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will create two new pigs.
2022-03-23 12:46:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:46:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:46:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:46:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of the thoughts are on the track.
2022-03-23 12:46:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:46:59 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for the wild, the number of wildlife grew back again, and that's a basis for conservation in namibia.
2022-03-23 12:46:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:47:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the magnetic field lines in the inside are trapped, but the superconductor doesn't like it when they move, because their movements use energy, and that's how the superconductor disorder.
2022-03-23 12:47:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:47:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can, which repeats the big constraints of facial and the basic form, and redeploy it through the one that refuses the entire porn structure and fold all the fits.
2022-03-23 12:47:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:47:11 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in the strict dinner, it was best summarized when someone said, "turn to the men on your table and say," well, if the revolution starts to support you. "
2022-03-23 12:47:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground, all from a continuous variable and cooling system, that allows us to use an aircraft in the stop and traffic to either operate, or when you're in the ground, to be able to be able to see the propelled by the propelled to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the soil, or when we're going to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-23 12:47:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:47:14 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 9.526 | ppl 737.35 | bleu 33.16 | wps 4680.1 | wpb 17862.2 | bsz 728.3 | num_updates 6119 | best_bleu 33.16
2022-03-23 12:47:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 6119 updates
2022-03-23 12:47:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:47:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:47:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 39 @ 6119 updates, score 33.16) (writing took 1.71669098502025 seconds)
2022-03-23 12:47:15 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 12:47:15 | INFO | train | epoch 039 | loss 7.974 | ppl 251.46 | wps 39587.5 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6119 | lr 0.000404259 | gnorm 0.336 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 3974
KL Stats: Epoch 39 Divergences: Uniform: 1.0199574302901202 Unigram: 1.6649359643231498
2022-03-23 12:47:16 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 12:47:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:47:46 | INFO | train_inner | epoch 040:     81 / 157 loss=8.076, ppl=269.82, wps=31512.2, ups=1.28, wpb=24674.4, bsz=984.6, num_updates=6200, lr=0.00040161, gnorm=0.307, loss_scale=8, train_wall=37, gb_free=12.1, wall=4005
2022-03-23 12:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:48:18 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep in the clinic.
2022-03-23 12:48:18 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:48:22 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people know here.
2022-03-23 12:48:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:48:26 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that create two new pigs overlap.
2022-03-23 12:48:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:48:30 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:48:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:48:34 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:48:34 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew back again, and this has become a foundation for conservation in namibia.
2022-03-23 12:48:39 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:48:43 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disturbs.
2022-03-23 12:48:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:48:47 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that resembles the big constraints of the face and the basic shape, and restore it through the information that refers the entire por-structure and folds all the fine.
2022-03-23 12:48:47 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:48:51 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it very interesting and appropriate for me here at tedwomen is that, well, when we stripped dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution starts to support you, then we support you. '"' the truth, women, we've already been supporting you about this topic for a long time."
2022-03-23 12:48:51 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:48:53 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our aircraft most proud was a result that we still had to solve the unique problems that were connected to surgery it on the ground -- everything, from a continuous variables and a refrigerator system that allows us to use an aircraft in the aircraft, to fit a specific vehicle, or if you're going to see the floor, you're going to see it all the way down to the air, you can see it all the way down to the way down to the way, you can see it, and you can see it all the way down to the way that you can see it, and see it's going to see it's going to see it, and see it, and see it, and see it's going to see it's going to see it, and see it in the way that you're going to see it, and see it, and see it, and see it, and see it's going to be
2022-03-23 12:48:53 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:48:53 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 9.526 | ppl 737.36 | bleu 33.27 | wps 4724.4 | wpb 17862.2 | bsz 728.3 | num_updates 6276 | best_bleu 33.27
2022-03-23 12:48:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 6276 updates
2022-03-23 12:48:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:48:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:48:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 40 @ 6276 updates, score 33.27) (writing took 1.7537749619805254 seconds)
2022-03-23 12:48:55 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 12:48:55 | INFO | train | epoch 040 | loss 7.949 | ppl 247.19 | wps 39650 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6276 | lr 0.000399171 | gnorm 0.317 | loss_scale 8 | train_wall 58 | gb_free 12.2 | wall 4074
KL Stats: Epoch 40 Divergences: Uniform: 1.0206540613935864 Unigram: 1.670644709856478
2022-03-23 12:48:55 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 12:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:49:04 | INFO | train_inner | epoch 041:     24 / 157 loss=7.902, ppl=239.17, wps=32620.5, ups=1.28, wpb=25482.3, bsz=1001.4, num_updates=6300, lr=0.00039841, gnorm=0.33, loss_scale=8, train_wall=37, gb_free=12.1, wall=4083
2022-03-23 12:49:42 | INFO | train_inner | epoch 041:    124 / 157 loss=7.956, ppl=248.32, wps=66398.1, ups=2.66, wpb=24945.4, bsz=1024.8, num_updates=6400, lr=0.000395285, gnorm=0.338, loss_scale=8, train_wall=37, gb_free=12.6, wall=4121
2022-03-23 12:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:49:58 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:49:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:50:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most people know here.
2022-03-23 12:50:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:50:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that produce two new pigs.
2022-03-23 12:50:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:50:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:50:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:50:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 12:50:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:50:18 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife grew back, and that's a foundation for conservation in namibia.
2022-03-23 12:50:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:50:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconduction disorder.
2022-03-23 12:50:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:50:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the big constructions of the face and the basic shape of the information that refers the whole pore structure and all the folds.
2022-03-23 12:50:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:50:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that -- well, in strictly dinner, it was best summarized when someone said, "turn to the men in your table and tell them," 'when the revolution begins, then we support you.' "'" the truth, women, we've already supported you for a long time. "at rachel silspring's future, to sandra, and then, to downstream."
2022-03-23 12:50:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're at our airplane at the most stumbling, was a result that we had to solve the unique problems that were connected to the ground -- everything, from a continuous variables and a refrigerator system that allows us to use an aircraft in the stop traffic until a specific vehicle that is either propelled, or propelled by a mechanism, to the ground, to be able to be able to be able to see the wrongside of a mechanism.
2022-03-23 12:50:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:50:33 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 9.491 | ppl 719.67 | bleu 33.66 | wps 4726.5 | wpb 17862.2 | bsz 728.3 | num_updates 6433 | best_bleu 33.66
2022-03-23 12:50:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 6433 updates
2022-03-23 12:50:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:50:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:50:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 41 @ 6433 updates, score 33.66) (writing took 1.7355521930148825 seconds)
2022-03-23 12:50:34 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 12:50:34 | INFO | train | epoch 041 | loss 7.938 | ppl 245.24 | wps 39693.7 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 6433 | lr 0.00039427 | gnorm 0.329 | loss_scale 8 | train_wall 58 | gb_free 11.7 | wall 4173
KL Stats: Epoch 41 Divergences: Uniform: 1.019639395596595 Unigram: 1.668963174885864
2022-03-23 12:50:35 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 12:50:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:51:01 | INFO | train_inner | epoch 042:     67 / 157 loss=7.882, ppl=235.86, wps=32284.4, ups=1.27, wpb=25376.6, bsz=1027.4, num_updates=6500, lr=0.000392232, gnorm=0.31, loss_scale=8, train_wall=37, gb_free=11.7, wall=4199
2022-03-23 12:51:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:51:38 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:51:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:51:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most people know here.
2022-03-23 12:51:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:51:46 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that produce two new pigs.
2022-03-23 12:51:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:51:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:51:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:51:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:51:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:51:58 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wild animals grew back again, and that's a foundation for conservation in namibia.
2022-03-23 12:51:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:52:02 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are caught inside, but the superconductor doesn't like it when they move, because their movements use energy, and so the superconductor disorder.
2022-03-23 12:52:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:52:06 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that repeats the big constraints of the face and the basic shape, and encode it through the information that refers the entire porter structure and all the fine folds.
2022-03-23 12:52:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:52:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. '"' the truth, women is that we've been supporting you for a long time." at carchel carspring, with silspring's future, and then our prior to sandra's, "
2022-03-23 12:52:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:52:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on our aircraft on the proud toe was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continual variables and a refrigerator system that allows us to use an aircraft in stop and transportation to a special vehicle that either drives the propeller, or when you see the aircraft, to the ground, until you can see a mechanism, until you can see the safety system, until you can see the same.
2022-03-23 12:52:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:52:12 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 9.517 | ppl 732.66 | bleu 33.31 | wps 4756.2 | wpb 17862.2 | bsz 728.3 | num_updates 6590 | best_bleu 33.66
2022-03-23 12:52:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 6590 updates
2022-03-23 12:52:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:52:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 42 @ 6590 updates, score 33.31) (writing took 0.7957275429507717 seconds)
2022-03-23 12:52:13 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 12:52:13 | INFO | train | epoch 042 | loss 7.913 | ppl 241.07 | wps 39950.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 6590 | lr 0.000389545 | gnorm 0.312 | loss_scale 8 | train_wall 59 | gb_free 12.8 | wall 4272
KL Stats: Epoch 42 Divergences: Uniform: 1.0212371412355166 Unigram: 1.6769582618175982
2022-03-23 12:52:14 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 12:52:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:52:18 | INFO | train_inner | epoch 043:     10 / 157 loss=7.884, ppl=236.3, wps=32770.1, ups=1.3, wpb=25255.4, bsz=1067.6, num_updates=6600, lr=0.000389249, gnorm=0.306, loss_scale=8, train_wall=37, gb_free=12.7, wall=4276
2022-03-23 12:52:55 | INFO | train_inner | epoch 043:    110 / 157 loss=7.944, ppl=246.31, wps=66642.2, ups=2.68, wpb=24888.3, bsz=924.1, num_updates=6700, lr=0.000386334, gnorm=0.339, loss_scale=8, train_wall=37, gb_free=13.1, wall=4314
2022-03-23 12:53:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:53:16 | INFO | fairseq.tasks.translation | example hypothesis: we set up these bleep in the clinic.
2022-03-23 12:53:16 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:53:20 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 12:53:20 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:53:24 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that generate two new pigs.
2022-03-23 12:53:24 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:53:28 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:53:28 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:53:32 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:53:32 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:53:36 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for wildlife, the number of wildlife grew back, and it's become a basis for conservation in namibia.
2022-03-23 12:53:36 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:53:40 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundles of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconductor is disturbing.
2022-03-23 12:53:40 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:53:45 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that resembles the big constraints of the face and the basic shape, and recovers it through the information that refers the whole pore structure and all the fine folds.
2022-03-23 12:53:45 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:53:49 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that make it interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men on your table and say to them," 'when the revolution starts to support you.' "'the truth, women, we've been supporting you with this topic for a long time. at carchel'spring's future," and then, to downstream our sandra. "
2022-03-23 12:53:49 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:53:52 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on on our airplane is the most stumbling, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable drive and a refrigerator system that allows us to use an aircraft in stop and go-traffic to a particular vehicle, either when you're driven, or you're on the ground, until you're going to see the wrong mechanism, all the way down the way down to a mechanism, until you're going to a mechanism, until you're going to the wrong mechanism.
2022-03-23 12:53:52 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:53:52 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 9.488 | ppl 718.17 | bleu 33.74 | wps 4638.7 | wpb 17862.2 | bsz 728.3 | num_updates 6747 | best_bleu 33.74
2022-03-23 12:53:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 6747 updates
2022-03-23 12:53:52 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:53:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:53:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 43 @ 6747 updates, score 33.74) (writing took 1.7413737410097383 seconds)
2022-03-23 12:53:53 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 12:53:53 | INFO | train | epoch 043 | loss 7.901 | ppl 238.96 | wps 39408.7 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 6747 | lr 0.000384986 | gnorm 0.32 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 4372
KL Stats: Epoch 43 Divergences: Uniform: 1.0206006199558304 Unigram: 1.6779026048215664
2022-03-23 12:53:54 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 12:53:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:54:14 | INFO | train_inner | epoch 044:     53 / 157 loss=7.94, ppl=245.62, wps=31625.4, ups=1.27, wpb=24948.6, bsz=1084.2, num_updates=6800, lr=0.000383482, gnorm=0.318, loss_scale=8, train_wall=37, gb_free=11.7, wall=4393
2022-03-23 12:54:51 | INFO | train_inner | epoch 044:    153 / 157 loss=7.823, ppl=226.47, wps=68351.2, ups=2.68, wpb=25486.8, bsz=1035.6, num_updates=6900, lr=0.000380693, gnorm=0.308, loss_scale=8, train_wall=37, gb_free=12.2, wall=4430
2022-03-23 12:54:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:54:56 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:54:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:55:00 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most people know here.
2022-03-23 12:55:00 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:55:04 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks within which two new pigs are going to cross.
2022-03-23 12:55:04 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:55:08 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 12:55:08 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:55:12 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 12:55:12 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:55:16 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back. and this has become a basis for conservation in namibia.
2022-03-23 12:55:16 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:55:20 | INFO | fairseq.tasks.translation | example hypothesis: first, a bunch of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because they use their movements, and so they disturb the superconduction.
2022-03-23 12:55:20 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:55:24 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which repeats the gross constraints of the face and the basic form, and reinvent it through the information that refers the whole porter structure and all the fine folds.
2022-03-23 12:55:24 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:55:29 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men on your table and tell them," when the revolution begins, we support you. "'" the truth, women, we've been supporting you for a long time. "
2022-03-23 12:55:29 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:55:31 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate on the ground -- everything from a continuous variation and a refrigerator system of fluid that allows us to use an aircraft in stop and go-traffic to a particular vehicle that either drives the propeller or when you're flowing it to the ground, if you're in the wrong space, to the wrong space, or to a mechanism.
2022-03-23 12:55:31 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:55:31 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 9.498 | ppl 723 | bleu 33.54 | wps 4776.2 | wpb 17862.2 | bsz 728.3 | num_updates 6904 | best_bleu 33.74
2022-03-23 12:55:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 6904 updates
2022-03-23 12:55:31 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:55:32 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:55:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 44 @ 6904 updates, score 33.54) (writing took 0.7588244279613718 seconds)
2022-03-23 12:55:32 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 12:55:32 | INFO | train | epoch 044 | loss 7.885 | ppl 236.37 | wps 40248.2 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 6904 | lr 0.000380583 | gnorm 0.322 | loss_scale 8 | train_wall 58 | gb_free 11.5 | wall 4470
KL Stats: Epoch 44 Divergences: Uniform: 1.0214282160484425 Unigram: 1.680587001476722
2022-03-23 12:55:33 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 12:55:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:56:09 | INFO | train_inner | epoch 045:     96 / 157 loss=7.746, ppl=214.7, wps=33020.2, ups=1.28, wpb=25718.1, bsz=1046.1, num_updates=7000, lr=0.000377964, gnorm=0.339, loss_scale=8, train_wall=37, gb_free=11.6, wall=4508
2022-03-23 12:56:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:56:35 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 12:56:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:56:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most of you know here.
2022-03-23 12:56:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:56:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will generate two new pigs.
2022-03-23 12:56:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:56:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:56:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:56:51 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:56:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:56:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for the wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-23 12:56:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:56:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field lines are captured inside, but the superconductor doesn't like it when they move, because their movements are consuming energy, and so the superconducting disorder.
2022-03-23 12:56:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:57:04 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection of reflection, we can start with a traditional facial can that restores the grows of the face and the basic form, and reinforces it through the information that refuses the whole por-structure and all the fine folds.
2022-03-23 12:57:04 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:57:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men at your table and tell them," when the revolution begins, then we support you. '"'" the truth, women, is that we've already supported you for a long time. "
2022-03-23 12:57:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:57:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're the most proud of on our airplane was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable drill and a refrigeration system that allows us to use a machine in the stop and go traffic to a particular drill, or if you're going to be able to see it in the ground for the wrong place -- all the way.
2022-03-23 12:57:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:57:09 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 9.474 | ppl 711.27 | bleu 33.96 | wps 4842 | wpb 17862.2 | bsz 728.3 | num_updates 7061 | best_bleu 33.96
2022-03-23 12:57:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 7061 updates
2022-03-23 12:57:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:57:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 12:57:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 45 @ 7061 updates, score 33.96) (writing took 1.7849771439796314 seconds)
2022-03-23 12:57:11 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 12:57:11 | INFO | train | epoch 045 | loss 7.878 | ppl 235.17 | wps 39767.8 | ups 1.58 | wpb 25153.6 | bsz 1020.6 | num_updates 7061 | lr 0.000376328 | gnorm 0.337 | loss_scale 8 | train_wall 58 | gb_free 13.2 | wall 4570
KL Stats: Epoch 45 Divergences: Uniform: 1.0206626291789727 Unigram: 1.6803705861569351
2022-03-23 12:57:11 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 12:57:11 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:57:26 | INFO | train_inner | epoch 046:     39 / 157 loss=8.061, ppl=267.13, wps=31607.8, ups=1.3, wpb=24298.5, bsz=960.8, num_updates=7100, lr=0.000375293, gnorm=0.327, loss_scale=8, train_wall=36, gb_free=12.2, wall=4585
2022-03-23 12:58:04 | INFO | train_inner | epoch 046:    139 / 157 loss=7.795, ppl=222.1, wps=67581.8, ups=2.66, wpb=25412.5, bsz=1023.3, num_updates=7200, lr=0.000372678, gnorm=0.305, loss_scale=8, train_wall=37, gb_free=11.8, wall=4622
2022-03-23 12:58:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:58:15 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep up at the clinic.
2022-03-23 12:58:15 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:58:19 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-23 12:58:19 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 12:58:22 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will generate two new pigs.
2022-03-23 12:58:22 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 12:58:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 12:58:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 12:58:30 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:58:30 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 12:58:34 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew back, and this has become a basis for conservation in namibia.
2022-03-23 12:58:34 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 12:58:38 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they're moving, because their movements are consuming energy, and so the superconduction is disturbing.
2022-03-23 12:58:38 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 12:58:42 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that resurrects the grows of the face and the basic form, and restore it through that information that refers all the pores structure and all the fine wrinkles.
2022-03-23 12:58:42 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 12:58:46 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me to be here at tedwomen is that -- well, in strictly dinner, it was best summarized when someone said, "turn you to the men at your table and say," when the revolution begins, we support you. '"the truth, women, love, is that we've already supported you about this topic for a long time."
2022-03-23 12:58:46 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 12:58:48 | INFO | fairseq.tasks.translation | example hypothesis: luckily, there's still a mother of invention, and a great part of the design work that we're on our airplane to stumbling, was a result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuously variable driver and a refrigeration system of liquid, that it allows us to use an aircraft in the aircraft in the stop and go-traffic to a particular vehicle that was either drifted, or when you're flowing the propelled to a mechanism.
2022-03-23 12:58:48 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 12:58:48 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 9.485 | ppl 716.58 | bleu 33.48 | wps 4927.4 | wpb 17862.2 | bsz 728.3 | num_updates 7218 | best_bleu 33.96
2022-03-23 12:58:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 7218 updates
2022-03-23 12:58:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:58:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 12:58:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 46 @ 7218 updates, score 33.48) (writing took 0.8104037650045939 seconds)
2022-03-23 12:58:49 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 12:58:49 | INFO | train | epoch 046 | loss 7.856 | ppl 231.61 | wps 40375.2 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 7218 | lr 0.000372213 | gnorm 0.317 | loss_scale 8 | train_wall 58 | gb_free 12.9 | wall 4667
KL Stats: Epoch 46 Divergences: Uniform: 1.021581654546958 Unigram: 1.6860902820870538
2022-03-23 12:58:49 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 12:58:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 12:59:20 | INFO | train_inner | epoch 047:     82 / 157 loss=7.862, ppl=232.57, wps=32700.8, ups=1.3, wpb=25087.6, bsz=1049.5, num_updates=7300, lr=0.000370117, gnorm=0.323, loss_scale=8, train_wall=37, gb_free=13, wall=4699
2022-03-23 12:59:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 12:59:52 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep beep in the clinic.
2022-03-23 12:59:52 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 12:59:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which i think most people know here.
2022-03-23 12:59:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:00:00 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinments that will exceed two new pigs.
2022-03-23 13:00:00 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:00:04 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:00:04 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:00:08 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:00:08 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:00:12 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wild animals grew back again, and this has become a basis for conservation in namibia.
2022-03-23 13:00:12 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:00:16 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use their energy, so the superconducting disorder.
2022-03-23 13:00:16 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:00:21 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this mirror reflection, we can start with a traditional facial can that will restore the size constraints of the face and the basic form, and restore it through the information that refers the whole porch structure and all the fine folds.
2022-03-23 13:00:21 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:00:24 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men at your desk and tell them, 'when the revolution begins, then we support you.'" the truth, love, is that we've already supported you about this topic for a long time. "
2022-03-23 13:00:24 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:00:26 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane is the most proud toe was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a cooling system of liquid, that it allows us to use an aircraft in the stop and go-traffic until a specific vehicle that we see in the ground.
2022-03-23 13:00:26 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:00:26 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 9.47 | ppl 708.95 | bleu 34.02 | wps 4878.8 | wpb 17862.2 | bsz 728.3 | num_updates 7375 | best_bleu 34.02
2022-03-23 13:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 7375 updates
2022-03-23 13:00:26 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:00:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:00:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 47 @ 7375 updates, score 34.02) (writing took 1.747117902035825 seconds)
2022-03-23 13:00:27 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 13:00:27 | INFO | train | epoch 047 | loss 7.844 | ppl 229.71 | wps 40060.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7375 | lr 0.00036823 | gnorm 0.317 | loss_scale 8 | train_wall 58 | gb_free 11.6 | wall 4766
KL Stats: Epoch 47 Divergences: Uniform: 1.0209493815644994 Unigram: 1.6884230766441675
2022-03-23 13:00:28 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 13:00:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:00:37 | INFO | train_inner | epoch 048:     25 / 157 loss=7.809, ppl=224.32, wps=32682.5, ups=1.3, wpb=25094.3, bsz=1038.8, num_updates=7400, lr=0.000367607, gnorm=0.333, loss_scale=8, train_wall=37, gb_free=12.1, wall=4776
2022-03-23 13:01:15 | INFO | train_inner | epoch 048:    125 / 157 loss=7.797, ppl=222.43, wps=67303, ups=2.62, wpb=25690.6, bsz=963.1, num_updates=7500, lr=0.000365148, gnorm=0.297, loss_scale=8, train_wall=38, gb_free=11.8, wall=4814
2022-03-23 13:01:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:01:30 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-23 13:01:30 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:01:34 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, probably most of you know here.
2022-03-23 13:01:34 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:01:38 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will generate two new pigs.
2022-03-23 13:01:38 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:01:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:01:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:01:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 13:01:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:01:51 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew back, and that has become a basis for conservation in namibia.
2022-03-23 13:01:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:01:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements consume energy, and so the superconductor disorder.
2022-03-23 13:01:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:01:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that refers the grows of the face and the basic shape, and restore it through the information that refers the entire porch structure and all the fine folds.
2022-03-23 13:01:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:02:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me to be here at tedwomen is that, well, we've been best summarized by dinner when someone said, "turn you to your table and tell them," when the revolution begins, then we support you. '"the truth, women, is that we've been supporting you this topic for a long time. at rachel carchel."
2022-03-23 13:02:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:02:05 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a large part of the design work that we're on our aircraft is the most stumbling, which is a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable engine and a refrigeration system of liquid that allows us to use an aircraft in stop and go-go-transportation to a particular vehicle that we have to do until you see that, either when you run the unique problems that you see that's going to fly in the ground.
2022-03-23 13:02:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:02:05 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 9.478 | ppl 712.87 | bleu 33.83 | wps 4688.6 | wpb 17862.2 | bsz 728.3 | num_updates 7532 | best_bleu 34.02
2022-03-23 13:02:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 7532 updates
2022-03-23 13:02:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:02:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 48 @ 7532 updates, score 33.83) (writing took 0.7744554529781453 seconds)
2022-03-23 13:02:06 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 13:02:06 | INFO | train | epoch 048 | loss 7.838 | ppl 228.77 | wps 39913.1 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7532 | lr 0.000364372 | gnorm 0.341 | loss_scale 8 | train_wall 58 | gb_free 11.9 | wall 4865
KL Stats: Epoch 48 Divergences: Uniform: 1.021187407757548 Unigram: 1.6875200397579
2022-03-23 13:02:07 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 13:02:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:02:32 | INFO | train_inner | epoch 049:     68 / 157 loss=7.961, ppl=249.14, wps=31797.1, ups=1.3, wpb=24476.3, bsz=1019.4, num_updates=7600, lr=0.000362738, gnorm=0.358, loss_scale=8, train_wall=36, gb_free=12.4, wall=4891
2022-03-23 13:03:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:03:09 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep at the clinic.
2022-03-23 13:03:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:03:13 | INFO | fairseq.tasks.translation | example hypothesis: that's the doha skyline that most of you probably know here.
2022-03-23 13:03:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:03:17 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks that will cross two new pigs.
2022-03-23 13:03:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:03:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:03:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:03:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on your head and understand exactly what all of your thoughts are on the track.
2022-03-23 13:03:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:03:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people took responsibility for wildlife, the number of wildlife grew back again, and this has become a foundation for conservation in namibia.
2022-03-23 13:03:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:03:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements of energy, and so the superconducting disorder.
2022-03-23 13:03:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:03:38 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflective reflection, we can start with a traditional facial can that will restore the size configurations of the face and the basic form, and add it through the information that refers the entire por-structure and all the fine wrinkles.
2022-03-23 13:03:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:03:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me here at tedwomen is that... well, when we had strict dinner, it was best summarized when someone said, "turn to the men at your desk and tell them, 'when the revolution begins, we support you.'" the truth, women, we've been supporting you for a long time. in rachel carson, silspring's future, "to downstream our primortal future."
2022-03-23 13:03:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:03:43 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're most proud of on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable gear and a cooling system of liquid, that it allows us to use an aircraft in stop and gotraffic to a specially appropriate vehicle that either when you're in the ground, or if you're in the air, you're in the same way.
2022-03-23 13:03:43 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:03:43 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 9.463 | ppl 705.59 | bleu 34.03 | wps 4833.4 | wpb 17862.2 | bsz 728.3 | num_updates 7689 | best_bleu 34.03
2022-03-23 13:03:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 7689 updates
2022-03-23 13:03:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:03:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:03:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 49 @ 7689 updates, score 34.03) (writing took 1.6990138329565525 seconds)
2022-03-23 13:03:45 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 13:03:45 | INFO | train | epoch 049 | loss 7.818 | ppl 225.59 | wps 40037.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 7689 | lr 0.000360633 | gnorm 0.306 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 4964
KL Stats: Epoch 49 Divergences: Uniform: 1.0220380420066297 Unigram: 1.693339809291978
2022-03-23 13:03:45 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 13:03:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:03:50 | INFO | train_inner | epoch 050:     11 / 157 loss=7.73, ppl=212.38, wps=33074.1, ups=1.29, wpb=25612.6, bsz=1037, num_updates=7700, lr=0.000360375, gnorm=0.303, loss_scale=8, train_wall=37, gb_free=12.7, wall=4968
2022-03-23 13:04:27 | INFO | train_inner | epoch 050:    111 / 157 loss=7.758, ppl=216.45, wps=67322.5, ups=2.66, wpb=25317.8, bsz=1089.3, num_updates=7800, lr=0.000358057, gnorm=0.315, loss_scale=8, train_wall=37, gb_free=12, wall=5006
2022-03-23 13:04:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:04:48 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 13:04:48 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:04:52 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline that most people know here.
2022-03-23 13:04:52 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:04:56 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks covering two new pigs.
2022-03-23 13:04:56 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:05:00 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:05:00 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:05:04 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:05:04 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:05:08 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife grew up again, and that's a foundation for conservation in namibia.
2022-03-23 13:05:08 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:05:12 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are disturbing the superconductor.
2022-03-23 13:05:12 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:05:16 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that refers the grows constraints of the face and the basic form, and add it through the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 13:05:16 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:05:20 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was the best summarized when someone said, "turn to the men on your desk and say to them, 'when the revolution begins, we support you.'" 'the truth, women, we've already been supporting you about this for a long time. in rachel carry borra's future to downstream. "
2022-03-23 13:05:20 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:05:21 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of the invention, and a lot of the design work that we're on our plane is a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variable gear and a refrigeration system of liquid, that it allows us to use an aircraft in stop and go-traffic to a specially appropriate vehicle, either when you're on the ground, or if you're in the wrong area, right?
2022-03-23 13:05:21 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:05:21 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 9.462 | ppl 705.04 | bleu 34.16 | wps 4960.4 | wpb 17862.2 | bsz 728.3 | num_updates 7846 | best_bleu 34.16
2022-03-23 13:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 7846 updates
2022-03-23 13:05:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:05:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 50 @ 7846 updates, score 34.16) (writing took 1.9597683650208637 seconds)
2022-03-23 13:05:23 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 13:05:23 | INFO | train | epoch 050 | loss 7.804 | ppl 223.52 | wps 40243.5 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 7846 | lr 0.000357006 | gnorm 0.31 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 5062
KL Stats: Epoch 50 Divergences: Uniform: 1.021375810050262 Unigram: 1.695239283563244
2022-03-23 13:05:24 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 13:05:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:05:45 | INFO | train_inner | epoch 051:     54 / 157 loss=7.859, ppl=232.16, wps=32340.1, ups=1.29, wpb=25044.8, bsz=987.4, num_updates=7900, lr=0.000355784, gnorm=0.301, loss_scale=8, train_wall=37, gb_free=12.2, wall=5083
2022-03-23 13:06:22 | INFO | train_inner | epoch 051:    154 / 157 loss=7.776, ppl=219.18, wps=67215.2, ups=2.69, wpb=25018.7, bsz=1005.7, num_updates=8000, lr=0.000353553, gnorm=0.312, loss_scale=8, train_wall=37, gb_free=19.6, wall=5121
2022-03-23 13:06:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:06:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep at the clinic.
2022-03-23 13:06:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:06:31 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, which probably most of you know here.
2022-03-23 13:06:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:06:35 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks codes that will generate two new pigs.
2022-03-23 13:06:35 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:06:39 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:06:39 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:06:43 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 13:06:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:06:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach of how people took responsibility for the wildlife, the number of wildlife grew back, and that's become a basis for conservation in namibia.
2022-03-23 13:06:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:06:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are captured inside, but the superconductor doesn't like it when they move, because their movements use their energy and disorder.
2022-03-23 13:06:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:06:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that will restore the size configurations of the face and the basic shape, and encode it through that information that refers the whole porter structure and all the fine wrinkles.
2022-03-23 13:06:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:06:59 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men on your desk and say to them, 'when the revolution begins, then we support you.' the truth, women is that we've been supporting you with this topic for a long time. we've been supporting rael carnel spring thera's future to downstream."
2022-03-23 13:06:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:07:01 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're most proud of on our aircraft was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variation and a cooling system of design that allows us to use an aircraft machine in stop and go-traffic to a special vehicle that either drives the propeller, or if you look at the soil, the mechanism until you see the tragic of a mechanism until you see the safety system.
2022-03-23 13:07:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:07:01 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 9.47 | ppl 709 | bleu 34.17 | wps 4817.9 | wpb 17862.2 | bsz 728.3 | num_updates 8003 | best_bleu 34.17
2022-03-23 13:07:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 8003 updates
2022-03-23 13:07:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:07:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:07:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 51 @ 8003 updates, score 34.17) (writing took 1.8328786499914713 seconds)
2022-03-23 13:07:03 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 13:07:03 | INFO | train | epoch 051 | loss 7.79 | ppl 221.32 | wps 39588.2 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 8003 | lr 0.000353487 | gnorm 0.307 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 5162
KL Stats: Epoch 51 Divergences: Uniform: 1.0232025124914157 Unigram: 1.6998957533206354
2022-03-23 13:07:03 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 13:07:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:07:40 | INFO | train_inner | epoch 052:     97 / 157 loss=7.762, ppl=217.14, wps=32259, ups=1.29, wpb=25059.6, bsz=1060.7, num_updates=8100, lr=0.000351364, gnorm=0.319, loss_scale=8, train_wall=37, gb_free=12.9, wall=5198
2022-03-23 13:08:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:08:06 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 13:08:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:08:10 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline, probably most of you here know.
2022-03-23 13:08:10 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:08:14 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks covering two new pigs.
2022-03-23 13:08:14 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:08:18 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:08:18 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:08:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:08:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:08:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of how people took responsibility for wildlife, the number of wildlife grew back up again, and that has become a basis for conservation in namibia.
2022-03-23 13:08:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:08:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements to use energy and disturb the superconduction.
2022-03-23 13:08:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:08:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial can that restores the grows of the face and the basic shape, and encounters it through the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 13:08:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:08:38 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that, well, when somebody said, "turn to the men in your desk and say to them," 'when the revolution begins, then we support you. "'" 'the truth, women, we've been supporting you about this topic for a long time. start with rachel, "
2022-03-23 13:08:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:08:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our plane is a pristine tower, was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable and a refrigerator system of liquid that allows us to use an aircraft in the stop and go traffic to a specific vehicle that either drives the propellers, or when you see the safety floor, the safety system to the safety system.
2022-03-23 13:08:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:08:40 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 9.443 | ppl 695.85 | bleu 34.2 | wps 4836.3 | wpb 17862.2 | bsz 728.3 | num_updates 8160 | best_bleu 34.2
2022-03-23 13:08:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 8160 updates
2022-03-23 13:08:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:08:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 52 @ 8160 updates, score 34.2) (writing took 1.7396697250078432 seconds)
2022-03-23 13:08:41 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 13:08:41 | INFO | train | epoch 052 | loss 7.786 | ppl 220.78 | wps 40001.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 8160 | lr 0.00035007 | gnorm 0.32 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 5260
KL Stats: Epoch 52 Divergences: Uniform: 1.021983097778389 Unigram: 1.6968687687435582
2022-03-23 13:08:42 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 13:08:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:08:57 | INFO | train_inner | epoch 053:     40 / 157 loss=7.79, ppl=221.33, wps=32636.6, ups=1.29, wpb=25222.2, bsz=988.6, num_updates=8200, lr=0.000349215, gnorm=0.318, loss_scale=8, train_wall=37, gb_free=12.1, wall=5276
2022-03-23 13:09:35 | INFO | train_inner | epoch 053:    140 / 157 loss=7.836, ppl=228.5, wps=66079.1, ups=2.65, wpb=24916.1, bsz=1025.7, num_updates=8300, lr=0.000347105, gnorm=0.313, loss_scale=8, train_wall=37, gb_free=12.3, wall=5313
2022-03-23 13:09:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:09:45 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 13:09:45 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:09:49 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that i think most of you know here.
2022-03-23 13:09:49 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:09:52 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks covering two new pigs.
2022-03-23 13:09:52 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:09:57 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:09:57 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:10:01 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-23 13:10:01 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:10:05 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach like people's responsibility for wildlife, the number of wildlife grew back. and it's become a basis for conservation in namibia.
2022-03-23 13:10:05 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:10:09 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements to use energy and disturb the superconduction.
2022-03-23 13:10:09 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:10:13 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which restores the grows of the face and the basic shape, and add it through the information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 13:10:13 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:10:17 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate for me to be here at tedwomen is that... well, in strictly dinner, it was best summarized when someone said, "turn to the men on your table and say," when the revolution begins, we support you. '"the truth, women, we've been supporting you about this topic for a long time. at rachel carson,"
2022-03-23 13:10:17 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:10:19 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a big part of the design work that we're most proud of on our airplane was a result that we had to solve the unique problems that were connected to operate it on the ground -- everything, from a continuous variables and a refrigerator system of liquid that allows us to use an aircraft in stop and go-traffic to a special passage that either drives the propeller, or if you're going to see the soil, to the wrong mechanism to the fall of a car storm.
2022-03-23 13:10:19 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:10:19 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 9.434 | ppl 691.67 | bleu 34.54 | wps 4815.6 | wpb 17862.2 | bsz 728.3 | num_updates 8317 | best_bleu 34.54
2022-03-23 13:10:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 8317 updates
2022-03-23 13:10:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:10:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt
2022-03-23 13:10:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_best.pt (epoch 53 @ 8317 updates, score 34.54) (writing took 1.7459166150074452 seconds)
2022-03-23 13:10:20 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 13:10:20 | INFO | train | epoch 053 | loss 7.772 | ppl 218.64 | wps 39911.9 | ups 1.59 | wpb 25153.6 | bsz 1020.6 | num_updates 8317 | lr 0.00034675 | gnorm 0.31 | loss_scale 8 | train_wall 58 | gb_free 12 | wall 5359
KL Stats: Epoch 53 Divergences: Uniform: 1.0225420124026396 Unigram: 1.7007308025685
2022-03-23 13:10:21 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 13:10:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:10:52 | INFO | train_inner | epoch 054:     83 / 157 loss=7.67, ppl=203.7, wps=32881.7, ups=1.29, wpb=25457, bsz=991.4, num_updates=8400, lr=0.000345033, gnorm=0.327, loss_scale=8, train_wall=37, gb_free=11.8, wall=5391
2022-03-23 13:11:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:11:24 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 13:11:24 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:11:27 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline that i think most people know here.
2022-03-23 13:11:27 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:11:31 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks inmates that will transcend two new pigs.
2022-03-23 13:11:31 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:11:35 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-23 13:11:35 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:11:39 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:11:39 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:11:43 | INFO | fairseq.tasks.translation | example hypothesis: and as people took responsibility for wildlife, the number of wildlife animals grew up again, and that has become a basis for conservation in namibia.
2022-03-23 13:11:43 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:11:48 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements and disturb the superconduction.
2022-03-23 13:11:48 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:11:52 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can that restores the grows of the face and the basic shape, and add it through that information, which refers the entire por-structure and all the fine wrinkles.
2022-03-23 13:11:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:11:56 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it very interesting and appropriate to be here at tedwomen is that... well, in strictly dinner, it was summed best when someone said, "turn to the men at your table and say," if the revolution starts to support you. '"' the truth, love, women is that we've been supporting you in this topic for a long time."
2022-03-23 13:11:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:11:57 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're using on our airplane the most stumbling toe was a result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuously variable gear and a cooling system of fluid, that allows us to use an aircraft machine in stop and go-traffic to either drives the propeller, or when you see the soil in the wrong place.
2022-03-23 13:11:57 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:11:57 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 9.457 | ppl 702.82 | bleu 34.06 | wps 4885 | wpb 17862.2 | bsz 728.3 | num_updates 8474 | best_bleu 34.54
2022-03-23 13:11:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 8474 updates
2022-03-23 13:11:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:11:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:11:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 54 @ 8474 updates, score 34.06) (writing took 0.83010771201225 seconds)
2022-03-23 13:11:58 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 13:11:58 | INFO | train | epoch 054 | loss 7.766 | ppl 217.67 | wps 40495.9 | ups 1.61 | wpb 25153.6 | bsz 1020.6 | num_updates 8474 | lr 0.000343523 | gnorm 0.323 | loss_scale 8 | train_wall 58 | gb_free 11.8 | wall 5457
KL Stats: Epoch 54 Divergences: Uniform: 1.023362190745546 Unigram: 1.7026525428192265
2022-03-23 13:11:58 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 13:11:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:12:09 | INFO | train_inner | epoch 055:     26 / 157 loss=7.792, ppl=221.59, wps=33044, ups=1.31, wpb=25277.4, bsz=1058.7, num_updates=8500, lr=0.000342997, gnorm=0.307, loss_scale=8, train_wall=37, gb_free=12.3, wall=5467
2022-03-23 13:12:46 | INFO | train_inner | epoch 055:    126 / 157 loss=7.732, ppl=212.6, wps=67256.6, ups=2.67, wpb=25144.5, bsz=953.9, num_updates=8600, lr=0.000340997, gnorm=0.332, loss_scale=8, train_wall=37, gb_free=11.9, wall=5505
2022-03-23 13:12:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:13:01 | INFO | fairseq.tasks.translation | example hypothesis: we set up these piepses in the clinic.
2022-03-23 13:13:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:13:05 | INFO | fairseq.tasks.translation | example hypothesis: this is the doha skyline that most people know here.
2022-03-23 13:13:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:13:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks within which two new pigs will cross.
2022-03-23 13:13:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:13:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:13:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:13:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:13:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:13:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of people taking responsibility for wildlife, the number of wildlife regrew, and that's a basis for conservation in namibia.
2022-03-23 13:13:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:13:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because their movements are using energy, and so the superconduction is disturbing.
2022-03-23 13:13:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:13:29 | INFO | fairseq.tasks.translation | example hypothesis: so when we use the information that comes from this reflection, we can start with a traditional facial can that restores the size of the face and gives it the basic shape, and enhances it through that information that involves the whole por-structure and all the fine wrinkles.
2022-03-23 13:13:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:13:33 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate to be here at tedwomen is that -- well, when we strict dinner, it was best summarized when someone said, "turn to the men in your table and tell them," when the revolution starts, we support you. '"the truth, women, love, is that we've been supporting you for a long time. in rachel carson with silson's spring's future," to download and to grave our sandra theaters to downstream. "
2022-03-23 13:13:33 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:13:35 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a large part of the design work that we're on our airplane is a pristine result that we had to solve the unique problems that were connected to operate on the ground -- everything, from a continuous variables and a cooling system with liquid, that it allows us to use a machine in stop and go-traffic to a particular passage that either drives the unique propeller or drives the propeller that's wrong to see in the ground -- all the way down to the way, to see in the way, to see in the way, to see, to the way, to the safety area, to the wrong area, to the way, to see, to the way, to the way, to the way, to see, to the trace, to the way, to the trace of one, to the trace, to the trace, to the trace, to the trace, to the ground, to the safety of a
2022-03-23 13:13:35 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:13:35 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 9.445 | ppl 697.02 | bleu 34.3 | wps 4790.6 | wpb 17862.2 | bsz 728.3 | num_updates 8631 | best_bleu 34.54
2022-03-23 13:13:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 8631 updates
2022-03-23 13:13:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:13:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:13:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 55 @ 8631 updates, score 34.3) (writing took 0.7887056850013323 seconds)
2022-03-23 13:13:36 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 13:13:36 | INFO | train | epoch 055 | loss 7.755 | ppl 216.02 | wps 40248.1 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8631 | lr 0.000340384 | gnorm 0.318 | loss_scale 8 | train_wall 58 | gb_free 12.5 | wall 5555
KL Stats: Epoch 55 Divergences: Uniform: 1.0245549396148381 Unigram: 1.7051985143547688
2022-03-23 13:13:36 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 13:13:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 13:14:03 | INFO | train_inner | epoch 056:     69 / 157 loss=7.916, ppl=241.44, wps=31746.2, ups=1.3, wpb=24341, bsz=994.7, num_updates=8700, lr=0.000339032, gnorm=0.312, loss_scale=8, train_wall=37, gb_free=10.8, wall=5581
2022-03-23 13:14:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 13:14:39 | INFO | fairseq.tasks.translation | example hypothesis: we set up these beep in the clinic.
2022-03-23 13:14:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-23 13:14:44 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha that i think most of you here know.
2022-03-23 13:14:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-23 13:14:48 | INFO | fairseq.tasks.translation | example hypothesis: stars will generate new goldilocks that will pass two new pigs.
2022-03-23 13:14:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-23 13:14:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs are served with salt and pepper.
2022-03-23 13:14:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-23 13:14:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:14:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-23 13:15:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the extent like people took responsibility for wildlife, the number of wildlife grew back. and that has become a basis for conservation in namibia.
2022-03-23 13:15:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-23 13:15:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move, because they use their movements, and they're disturbing the superconduction.
2022-03-23 13:15:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-23 13:15:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from that reflection, we can start with a traditional facial can that restore the grows of the face and the basic shape, and add it through that information that refers the whole por-structure and all the fine wrinkles.
2022-03-23 13:15:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-23 13:15:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it really interesting and appropriate for me here at tedwomen is that... well, when we were striking dinner, it was best summarized when someone said, "turn to the men on your table and say to them, 'when the revolution starts, we support you.'" the truth, women, we've been supporting you with this subject for a long time. "at rachel carson's future," to proud of sandra's "to downstream."
2022-03-23 13:15:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-23 13:15:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of invention, and a large part of the design work that we're on our airplane is the result that we had to solve the unique problems that were connected to operating it on the ground -- everything, from a continuous variable gear and a cooling system that allows us to use an aircraft in stop and gotraffic to a specially appropriate vehicle that either drives the propeller, or when you're on the ground, to see it in the case you're going to see it.
2022-03-23 13:15:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-23 13:15:14 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 9.445 | ppl 696.85 | bleu 34.21 | wps 4915.5 | wpb 17862.2 | bsz 728.3 | num_updates 8788 | best_bleu 34.54
2022-03-23 13:15:14 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 13:15:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 8788 updates
2022-03-23 13:15:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt
2022-03-23 13:15:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.3_jelinek_0.3_0.05_0.65_#1/checkpoint_last.pt (epoch 56 @ 8788 updates, score 34.21) (writing took 0.8512625970179215 seconds)
2022-03-23 13:15:14 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 13:15:14 | INFO | train | epoch 056 | loss 7.744 | ppl 214.31 | wps 40152.3 | ups 1.6 | wpb 25153.6 | bsz 1020.6 | num_updates 8788 | lr 0.00033733 | gnorm 0.312 | loss_scale 8 | train_wall 58 | gb_free 12.1 | wall 5653
2022-03-23 13:15:14 | INFO | fairseq_cli.train | done training in 5652.8 seconds
