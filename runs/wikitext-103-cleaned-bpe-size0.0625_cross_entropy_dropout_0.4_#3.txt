Sender: LSF System <lsfadmin@eu-g3-035>
Subject: Job 210480302: <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3> in cluster <euler> Done

Job <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3> was submitted from host <eu-login-43> by user <andriusb> in cluster <euler> at Tue Mar 22 19:44:06 2022
Job was executed on host(s) <eu-g3-035>, in queue <gpu.24h>, as user <andriusb> in cluster <euler> at Tue Mar 22 20:02:04 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Tue Mar 22 20:02:04 2022
Terminated at Tue Mar 22 22:32:24 2022
Results reported at Tue Mar 22 22:32:24 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.4 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 512 --update-freq 32 --seed 66575611 --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575613 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   8996.21 sec.
    Max Memory :                                 6088 MB
    Average Memory :                             4838.87 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               13912.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   9020 sec.
    Turnaround time :                            10098 sec.

The output (if any) follows:

2022-03-22 20:02:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575613, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.4, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575613, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-22 20:02:19 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-22 20:02:19 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-22 20:02:19 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-22 20:02:19 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-22 20:02:19 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-22 20:02:19 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-22 20:02:19 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-22 20:02:19 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-22 20:02:29 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-22 20:02:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-22 20:02:29 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = NVIDIA GeForce RTX 2080 Ti              
2022-03-22 20:02:29 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-22 20:02:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-22 20:02:29 | INFO | fairseq_cli.train | max tokens per device = 512 and max sentences per device = None
2022-03-22 20:02:29 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_last.pt
2022-03-22 20:02:29 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_last.pt
2022-03-22 20:02:29 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-22 20:02:29 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-22 20:02:29 | INFO | fairseq.trainer | begin training epoch 1
2022-03-22 20:02:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:02:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:02:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 20:03:32 | INFO | train_inner | epoch 001:    102 / 411 loss=14.484, ppl=22916.3, wps=27459.8, ups=1.68, wpb=16384, bsz=32, num_updates=100, lr=1.25975e-05, gnorm=2.924, loss_scale=32, train_wall=58, gb_free=9.7, wall=63
2022-03-22 20:04:31 | INFO | train_inner | epoch 001:    202 / 411 loss=12.633, ppl=6353.5, wps=27735.2, ups=1.69, wpb=16384, bsz=32, num_updates=200, lr=2.5095e-05, gnorm=1.247, loss_scale=32, train_wall=54, gb_free=9.7, wall=122
2022-03-22 20:05:30 | INFO | train_inner | epoch 001:    302 / 411 loss=11.411, ppl=2722.16, wps=27632.1, ups=1.69, wpb=16384, bsz=32, num_updates=300, lr=3.75925e-05, gnorm=0.881, loss_scale=32, train_wall=55, gb_free=9.7, wall=181
2022-03-22 20:06:29 | INFO | train_inner | epoch 001:    402 / 411 loss=10.67, ppl=1628.76, wps=27761.5, ups=1.69, wpb=16384, bsz=32, num_updates=400, lr=5.009e-05, gnorm=0.747, loss_scale=32, train_wall=54, gb_free=9.7, wall=240
2022-03-22 20:06:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:06:39 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 10.387 | ppl 1339.5 | wps 46335.3 | wpb 511.2 | bsz 1 | num_updates 409
2022-03-22 20:06:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 409 updates
2022-03-22 20:06:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:06:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:06:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 1 @ 409 updates, score 10.387) (writing took 1.0665485803037882 seconds)
2022-03-22 20:06:40 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-22 20:06:40 | INFO | train | epoch 001 | loss 12.261 | ppl 4907.98 | wps 26971.9 | ups 1.65 | wpb 16367.7 | bsz 32 | num_updates 409 | lr 5.12148e-05 | gnorm 1.433 | loss_scale 32 | train_wall 226 | gb_free 9.7 | wall 251
2022-03-22 20:06:40 | INFO | fairseq.trainer | begin training epoch 2
2022-03-22 20:06:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:07:34 | INFO | train_inner | epoch 002:     91 / 411 loss=10.383, ppl=1335.68, wps=25117.1, ups=1.54, wpb=16317.5, bsz=31.9, num_updates=500, lr=6.25875e-05, gnorm=0.676, loss_scale=32, train_wall=54, gb_free=9.7, wall=305
2022-03-22 20:08:33 | INFO | train_inner | epoch 002:    191 / 411 loss=10.226, ppl=1197.84, wps=27605.9, ups=1.68, wpb=16384, bsz=32, num_updates=600, lr=7.5085e-05, gnorm=0.661, loss_scale=64, train_wall=55, gb_free=9.7, wall=364
2022-03-22 20:09:33 | INFO | train_inner | epoch 002:    291 / 411 loss=10.053, ppl=1062.04, wps=27676, ups=1.69, wpb=16384, bsz=32, num_updates=700, lr=8.75825e-05, gnorm=0.669, loss_scale=64, train_wall=55, gb_free=9.7, wall=424
2022-03-22 20:10:32 | INFO | train_inner | epoch 002:    391 / 411 loss=9.893, ppl=950.63, wps=27651, ups=1.69, wpb=16378.9, bsz=32, num_updates=800, lr=0.00010008, gnorm=0.654, loss_scale=64, train_wall=55, gb_free=9.7, wall=483
2022-03-22 20:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:10:48 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 9.636 | ppl 795.89 | wps 49525.8 | wpb 511.2 | bsz 1 | num_updates 820 | best_loss 9.636
2022-03-22 20:10:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 820 updates
2022-03-22 20:10:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:10:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:10:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 2 @ 820 updates, score 9.636) (writing took 1.0355971977114677 seconds)
2022-03-22 20:10:49 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-22 20:10:49 | INFO | train | epoch 002 | loss 10.114 | ppl 1108.47 | wps 27027.3 | ups 1.65 | wpb 16367.8 | bsz 32 | num_updates 820 | lr 0.00010258 | gnorm 0.665 | loss_scale 64 | train_wall 224 | gb_free 9.7 | wall 500
2022-03-22 20:10:49 | INFO | fairseq.trainer | begin training epoch 3
2022-03-22 20:10:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:11:37 | INFO | train_inner | epoch 003:     80 / 411 loss=9.707, ppl=835.65, wps=25152.5, ups=1.54, wpb=16322.6, bsz=31.9, num_updates=900, lr=0.000112578, gnorm=0.655, loss_scale=64, train_wall=54, gb_free=9.7, wall=548
2022-03-22 20:12:36 | INFO | train_inner | epoch 003:    180 / 411 loss=9.542, ppl=745.28, wps=27651.5, ups=1.69, wpb=16378.9, bsz=32, num_updates=1000, lr=0.000125075, gnorm=0.651, loss_scale=64, train_wall=55, gb_free=9.7, wall=607
2022-03-22 20:13:35 | INFO | train_inner | epoch 003:    280 / 411 loss=9.388, ppl=669.78, wps=27640.5, ups=1.69, wpb=16384, bsz=32, num_updates=1100, lr=0.000137573, gnorm=0.694, loss_scale=128, train_wall=55, gb_free=9.7, wall=666
2022-03-22 20:14:35 | INFO | train_inner | epoch 003:    380 / 411 loss=9.258, ppl=612.43, wps=27643.8, ups=1.69, wpb=16384, bsz=32, num_updates=1200, lr=0.00015007, gnorm=0.691, loss_scale=128, train_wall=55, gb_free=9.7, wall=726
2022-03-22 20:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:14:58 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.968 | ppl 500.8 | wps 47322.5 | wpb 511.2 | bsz 1 | num_updates 1231 | best_loss 8.968
2022-03-22 20:14:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1231 updates
2022-03-22 20:14:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:14:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 3 @ 1231 updates, score 8.968) (writing took 1.093271130695939 seconds)
2022-03-22 20:14:59 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-22 20:14:59 | INFO | train | epoch 003 | loss 9.435 | ppl 692.41 | wps 26939.3 | ups 1.65 | wpb 16367.8 | bsz 32 | num_updates 1231 | lr 0.000153944 | gnorm 0.675 | loss_scale 128 | train_wall 224 | gb_free 9.7 | wall 750
2022-03-22 20:14:59 | INFO | fairseq.trainer | begin training epoch 4
2022-03-22 20:14:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:15:40 | INFO | train_inner | epoch 004:     69 / 411 loss=9.075, ppl=539.22, wps=24945.4, ups=1.53, wpb=16317.5, bsz=31.9, num_updates=1300, lr=0.000162568, gnorm=0.702, loss_scale=128, train_wall=55, gb_free=9.7, wall=791
2022-03-22 20:16:39 | INFO | train_inner | epoch 004:    169 / 411 loss=8.938, ppl=490.32, wps=27612.5, ups=1.69, wpb=16384, bsz=32, num_updates=1400, lr=0.000175065, gnorm=0.699, loss_scale=128, train_wall=55, gb_free=9.7, wall=850
2022-03-22 20:17:39 | INFO | train_inner | epoch 004:    269 / 411 loss=8.816, ppl=450.7, wps=27641, ups=1.69, wpb=16384, bsz=32, num_updates=1500, lr=0.000187563, gnorm=0.714, loss_scale=128, train_wall=55, gb_free=9.7, wall=910
2022-03-22 20:18:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2022-03-22 20:18:38 | INFO | train_inner | epoch 004:    370 / 411 loss=8.738, ppl=427.01, wps=27454.4, ups=1.68, wpb=16384, bsz=32, num_updates=1600, lr=0.00020006, gnorm=0.689, loss_scale=128, train_wall=55, gb_free=9.7, wall=969
2022-03-22 20:19:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:19:07 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 8.484 | ppl 358.06 | wps 45451.4 | wpb 511.2 | bsz 1 | num_updates 1641 | best_loss 8.484
2022-03-22 20:19:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 1641 updates
2022-03-22 20:19:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:19:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:19:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 4 @ 1641 updates, score 8.484) (writing took 0.9181076698005199 seconds)
2022-03-22 20:19:08 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-22 20:19:08 | INFO | train | epoch 004 | loss 8.847 | ppl 460.37 | wps 26898.6 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 1641 | lr 0.000205184 | gnorm 0.699 | loss_scale 128 | train_wall 224 | gb_free 9.7 | wall 999
2022-03-22 20:19:08 | INFO | fairseq.trainer | begin training epoch 5
2022-03-22 20:19:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:19:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:19:44 | INFO | train_inner | epoch 005:     60 / 411 loss=8.6, ppl=388.06, wps=24877.2, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=1700, lr=0.000212558, gnorm=0.689, loss_scale=64, train_wall=55, gb_free=9.7, wall=1035
2022-03-22 20:20:43 | INFO | train_inner | epoch 005:    160 / 411 loss=8.477, ppl=356.38, wps=27710, ups=1.69, wpb=16384, bsz=32, num_updates=1800, lr=0.000225055, gnorm=0.716, loss_scale=64, train_wall=54, gb_free=9.7, wall=1094
2022-03-22 20:21:42 | INFO | train_inner | epoch 005:    260 / 411 loss=8.412, ppl=340.5, wps=27627.3, ups=1.69, wpb=16384, bsz=32, num_updates=1900, lr=0.000237553, gnorm=0.696, loss_scale=64, train_wall=55, gb_free=9.7, wall=1153
2022-03-22 20:22:42 | INFO | train_inner | epoch 005:    360 / 411 loss=8.322, ppl=319.97, wps=27608.9, ups=1.69, wpb=16384, bsz=32, num_updates=2000, lr=0.00025005, gnorm=0.684, loss_scale=64, train_wall=55, gb_free=9.7, wall=1213
2022-03-22 20:23:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:23:17 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 8.128 | ppl 279.82 | wps 46301.1 | wpb 511.2 | bsz 1 | num_updates 2051 | best_loss 8.128
2022-03-22 20:23:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2051 updates
2022-03-22 20:23:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:23:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:23:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 5 @ 2051 updates, score 8.128) (writing took 0.9139815494418144 seconds)
2022-03-22 20:23:18 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-22 20:23:18 | INFO | train | epoch 005 | loss 8.412 | ppl 340.53 | wps 26897.7 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 2051 | lr 0.000256424 | gnorm 0.692 | loss_scale 64 | train_wall 224 | gb_free 9.7 | wall 1249
2022-03-22 20:23:18 | INFO | fairseq.trainer | begin training epoch 6
2022-03-22 20:23:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:23:47 | INFO | train_inner | epoch 006:     49 / 411 loss=8.221, ppl=298.39, wps=24940.3, ups=1.53, wpb=16312.3, bsz=31.9, num_updates=2100, lr=0.000262548, gnorm=0.684, loss_scale=64, train_wall=55, gb_free=9.7, wall=1278
2022-03-22 20:24:46 | INFO | train_inner | epoch 006:    149 / 411 loss=8.122, ppl=278.59, wps=27649.8, ups=1.69, wpb=16384, bsz=32, num_updates=2200, lr=0.000275045, gnorm=0.662, loss_scale=128, train_wall=54, gb_free=9.7, wall=1337
2022-03-22 20:25:46 | INFO | train_inner | epoch 006:    249 / 411 loss=8.066, ppl=267.93, wps=27608.4, ups=1.69, wpb=16384, bsz=32, num_updates=2300, lr=0.000287543, gnorm=0.681, loss_scale=128, train_wall=55, gb_free=9.7, wall=1397
2022-03-22 20:25:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:26:46 | INFO | train_inner | epoch 006:    350 / 411 loss=8.01, ppl=257.87, wps=27307.4, ups=1.67, wpb=16384, bsz=32, num_updates=2400, lr=0.00030004, gnorm=0.676, loss_scale=64, train_wall=55, gb_free=9.7, wall=1457
2022-03-22 20:27:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:27:27 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 7.839 | ppl 228.92 | wps 49703.4 | wpb 511.2 | bsz 1 | num_updates 2461 | best_loss 7.839
2022-03-22 20:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 2461 updates
2022-03-22 20:27:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:27:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 6 @ 2461 updates, score 7.839) (writing took 1.0853018686175346 seconds)
2022-03-22 20:27:28 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-22 20:27:28 | INFO | train | epoch 006 | loss 8.061 | ppl 267.02 | wps 26856.3 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 2461 | lr 0.000307663 | gnorm 0.677 | loss_scale 64 | train_wall 224 | gb_free 9.7 | wall 1499
2022-03-22 20:27:28 | INFO | fairseq.trainer | begin training epoch 7
2022-03-22 20:27:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:27:51 | INFO | train_inner | epoch 007:     39 / 411 loss=7.892, ppl=237.52, wps=24880.5, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=2500, lr=0.000312538, gnorm=0.68, loss_scale=64, train_wall=55, gb_free=9.7, wall=1522
2022-03-22 20:28:51 | INFO | train_inner | epoch 007:    139 / 411 loss=7.818, ppl=225.74, wps=27529, ups=1.68, wpb=16384, bsz=32, num_updates=2600, lr=0.000325035, gnorm=0.675, loss_scale=64, train_wall=55, gb_free=9.7, wall=1582
2022-03-22 20:29:50 | INFO | train_inner | epoch 007:    239 / 411 loss=7.735, ppl=213.08, wps=27462.7, ups=1.68, wpb=16384, bsz=32, num_updates=2700, lr=0.000337533, gnorm=0.681, loss_scale=64, train_wall=55, gb_free=9.7, wall=1641
2022-03-22 20:30:50 | INFO | train_inner | epoch 007:    339 / 411 loss=7.707, ppl=208.93, wps=27494.7, ups=1.68, wpb=16378.9, bsz=32, num_updates=2800, lr=0.00035003, gnorm=0.685, loss_scale=64, train_wall=55, gb_free=9.7, wall=1701
2022-03-22 20:31:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:31:38 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 7.568 | ppl 189.72 | wps 45946.8 | wpb 511.2 | bsz 1 | num_updates 2872 | best_loss 7.568
2022-03-22 20:31:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 2872 updates
2022-03-22 20:31:38 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:31:39 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:31:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 7 @ 2872 updates, score 7.568) (writing took 1.1167616043239832 seconds)
2022-03-22 20:31:39 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-22 20:31:39 | INFO | train | epoch 007 | loss 7.744 | ppl 214.33 | wps 26791.6 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 2872 | lr 0.000359028 | gnorm 0.678 | loss_scale 128 | train_wall 225 | gb_free 9.7 | wall 1750
2022-03-22 20:31:39 | INFO | fairseq.trainer | begin training epoch 8
2022-03-22 20:31:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:31:55 | INFO | train_inner | epoch 008:     28 / 411 loss=7.617, ppl=196.27, wps=24960.2, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=2900, lr=0.000362528, gnorm=0.656, loss_scale=128, train_wall=54, gb_free=9.7, wall=1766
2022-03-22 20:32:55 | INFO | train_inner | epoch 008:    128 / 411 loss=7.506, ppl=181.79, wps=27387.1, ups=1.67, wpb=16384, bsz=32, num_updates=3000, lr=0.000375025, gnorm=0.672, loss_scale=128, train_wall=55, gb_free=9.7, wall=1826
2022-03-22 20:33:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:33:56 | INFO | train_inner | epoch 008:    229 / 411 loss=7.474, ppl=177.82, wps=27100.8, ups=1.65, wpb=16384, bsz=32, num_updates=3100, lr=0.000387523, gnorm=0.669, loss_scale=64, train_wall=56, gb_free=9.7, wall=1887
2022-03-22 20:34:55 | INFO | train_inner | epoch 008:    329 / 411 loss=7.433, ppl=172.81, wps=27439.9, ups=1.67, wpb=16384, bsz=32, num_updates=3200, lr=0.00040002, gnorm=0.67, loss_scale=64, train_wall=55, gb_free=9.7, wall=1946
2022-03-22 20:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:35:49 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 7.349 | ppl 163.07 | wps 47499.7 | wpb 511.2 | bsz 1 | num_updates 3282 | best_loss 7.349
2022-03-22 20:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 3282 updates
2022-03-22 20:35:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 8 @ 3282 updates, score 7.349) (writing took 0.9432605262845755 seconds)
2022-03-22 20:35:50 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-22 20:35:50 | INFO | train | epoch 008 | loss 7.456 | ppl 175.53 | wps 26712.9 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 3282 | lr 0.000410268 | gnorm 0.667 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 2001
2022-03-22 20:35:50 | INFO | fairseq.trainer | begin training epoch 9
2022-03-22 20:35:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:36:01 | INFO | train_inner | epoch 009:     18 / 411 loss=7.358, ppl=164.02, wps=24920.4, ups=1.53, wpb=16317.5, bsz=31.9, num_updates=3300, lr=0.000412518, gnorm=0.659, loss_scale=64, train_wall=55, gb_free=9.7, wall=2012
2022-03-22 20:37:01 | INFO | train_inner | epoch 009:    118 / 411 loss=7.23, ppl=150.1, wps=27432.7, ups=1.67, wpb=16378.9, bsz=32, num_updates=3400, lr=0.000425015, gnorm=0.67, loss_scale=64, train_wall=55, gb_free=9.7, wall=2072
2022-03-22 20:38:00 | INFO | train_inner | epoch 009:    218 / 411 loss=7.218, ppl=148.86, wps=27457.1, ups=1.68, wpb=16384, bsz=32, num_updates=3500, lr=0.000437513, gnorm=0.67, loss_scale=64, train_wall=55, gb_free=9.7, wall=2131
2022-03-22 20:39:00 | INFO | train_inner | epoch 009:    318 / 411 loss=7.193, ppl=146.31, wps=27492.2, ups=1.68, wpb=16384, bsz=32, num_updates=3600, lr=0.00045001, gnorm=0.656, loss_scale=64, train_wall=55, gb_free=9.7, wall=2191
2022-03-22 20:39:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:40:00 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 7.182 | ppl 145.25 | wps 49530.9 | wpb 511.2 | bsz 1 | num_updates 3693 | best_loss 7.182
2022-03-22 20:40:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 3693 updates
2022-03-22 20:40:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:40:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:40:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 9 @ 3693 updates, score 7.182) (writing took 1.070036033168435 seconds)
2022-03-22 20:40:01 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-22 20:40:01 | INFO | train | epoch 009 | loss 7.199 | ppl 146.89 | wps 26797.8 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 3693 | lr 0.000461633 | gnorm 0.664 | loss_scale 128 | train_wall 226 | gb_free 9.7 | wall 2252
2022-03-22 20:40:01 | INFO | fairseq.trainer | begin training epoch 10
2022-03-22 20:40:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:40:06 | INFO | train_inner | epoch 010:      7 / 411 loss=7.137, ppl=140.76, wps=24837.5, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=3700, lr=0.000462508, gnorm=0.662, loss_scale=128, train_wall=55, gb_free=9.7, wall=2257
2022-03-22 20:41:05 | INFO | train_inner | epoch 010:    107 / 411 loss=6.99, ppl=127.11, wps=27503.6, ups=1.68, wpb=16384, bsz=32, num_updates=3800, lr=0.000475005, gnorm=0.665, loss_scale=128, train_wall=55, gb_free=9.7, wall=2316
2022-03-22 20:42:05 | INFO | train_inner | epoch 010:    207 / 411 loss=6.987, ppl=126.83, wps=27521.6, ups=1.68, wpb=16384, bsz=32, num_updates=3900, lr=0.000487503, gnorm=0.661, loss_scale=128, train_wall=55, gb_free=9.7, wall=2376
2022-03-22 20:43:04 | INFO | train_inner | epoch 010:    307 / 411 loss=6.959, ppl=124.43, wps=27445.2, ups=1.68, wpb=16384, bsz=32, num_updates=4000, lr=0.0005, gnorm=0.659, loss_scale=128, train_wall=55, gb_free=9.7, wall=2435
2022-03-22 20:43:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:44:05 | INFO | train_inner | epoch 010:    408 / 411 loss=6.936, ppl=122.42, wps=27193.3, ups=1.66, wpb=16378.9, bsz=32, num_updates=4100, lr=0.000493865, gnorm=0.662, loss_scale=64, train_wall=55, gb_free=9.7, wall=2496
2022-03-22 20:44:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:44:11 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 7.025 | ppl 130.2 | wps 45173 | wpb 511.2 | bsz 1 | num_updates 4103 | best_loss 7.025
2022-03-22 20:44:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 4103 updates
2022-03-22 20:44:11 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:44:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:44:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 10 @ 4103 updates, score 7.025) (writing took 0.9764779862016439 seconds)
2022-03-22 20:44:12 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-22 20:44:12 | INFO | train | epoch 010 | loss 6.968 | ppl 125.21 | wps 26712.1 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 4103 | lr 0.000493684 | gnorm 0.662 | loss_scale 64 | train_wall 225 | gb_free 9.7 | wall 2503
2022-03-22 20:44:12 | INFO | fairseq.trainer | begin training epoch 11
2022-03-22 20:44:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:45:10 | INFO | train_inner | epoch 011:     97 / 411 loss=6.758, ppl=108.27, wps=24833.1, ups=1.52, wpb=16317.5, bsz=31.9, num_updates=4200, lr=0.00048795, gnorm=0.649, loss_scale=64, train_wall=55, gb_free=9.7, wall=2561
2022-03-22 20:46:11 | INFO | train_inner | epoch 011:    197 / 411 loss=6.763, ppl=108.63, wps=26889.3, ups=1.64, wpb=16384, bsz=32, num_updates=4300, lr=0.000482243, gnorm=0.652, loss_scale=64, train_wall=56, gb_free=9.7, wall=2622
2022-03-22 20:47:11 | INFO | train_inner | epoch 011:    297 / 411 loss=6.719, ppl=105.37, wps=27515.6, ups=1.68, wpb=16384, bsz=32, num_updates=4400, lr=0.000476731, gnorm=0.652, loss_scale=64, train_wall=55, gb_free=9.7, wall=2682
2022-03-22 20:48:10 | INFO | train_inner | epoch 011:    397 / 411 loss=6.749, ppl=107.54, wps=27485.8, ups=1.68, wpb=16384, bsz=32, num_updates=4500, lr=0.000471405, gnorm=0.64, loss_scale=64, train_wall=55, gb_free=9.7, wall=2741
2022-03-22 20:48:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:48:23 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.906 | ppl 119.91 | wps 49090.9 | wpb 511.2 | bsz 1 | num_updates 4514 | best_loss 6.906
2022-03-22 20:48:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 4514 updates
2022-03-22 20:48:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:48:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:48:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 11 @ 4514 updates, score 6.906) (writing took 1.0061672274023294 seconds)
2022-03-22 20:48:24 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-22 20:48:24 | INFO | train | epoch 011 | loss 6.746 | ppl 107.37 | wps 26676.7 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 4514 | lr 0.000470673 | gnorm 0.649 | loss_scale 64 | train_wall 227 | gb_free 9.7 | wall 2756
2022-03-22 20:48:24 | INFO | fairseq.trainer | begin training epoch 12
2022-03-22 20:48:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:49:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:49:17 | INFO | train_inner | epoch 012:     87 / 411 loss=6.566, ppl=94.77, wps=24584.6, ups=1.51, wpb=16322.6, bsz=31.9, num_updates=4600, lr=0.000466252, gnorm=0.641, loss_scale=64, train_wall=56, gb_free=9.7, wall=2808
2022-03-22 20:50:17 | INFO | train_inner | epoch 012:    187 / 411 loss=6.551, ppl=93.8, wps=27369.3, ups=1.67, wpb=16384, bsz=32, num_updates=4700, lr=0.000461266, gnorm=0.646, loss_scale=64, train_wall=55, gb_free=9.7, wall=2868
2022-03-22 20:51:16 | INFO | train_inner | epoch 012:    287 / 411 loss=6.573, ppl=95.2, wps=27381.3, ups=1.67, wpb=16378.9, bsz=32, num_updates=4800, lr=0.000456435, gnorm=0.647, loss_scale=64, train_wall=55, gb_free=9.7, wall=2927
2022-03-22 20:52:16 | INFO | train_inner | epoch 012:    387 / 411 loss=6.558, ppl=94.21, wps=27448.9, ups=1.68, wpb=16384, bsz=32, num_updates=4900, lr=0.000451754, gnorm=0.648, loss_scale=64, train_wall=55, gb_free=9.7, wall=2987
2022-03-22 20:52:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:52:35 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.798 | ppl 111.28 | wps 47956.5 | wpb 511.2 | bsz 1 | num_updates 4924 | best_loss 6.798
2022-03-22 20:52:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 4924 updates
2022-03-22 20:52:35 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:52:36 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 12 @ 4924 updates, score 6.798) (writing took 1.1708190087229013 seconds)
2022-03-22 20:52:36 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-22 20:52:36 | INFO | train | epoch 012 | loss 6.553 | ppl 93.89 | wps 26654.3 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 4924 | lr 0.000450652 | gnorm 0.645 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 3007
2022-03-22 20:52:36 | INFO | fairseq.trainer | begin training epoch 13
2022-03-22 20:52:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:53:22 | INFO | train_inner | epoch 013:     76 / 411 loss=6.399, ppl=84.41, wps=24927.5, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=5000, lr=0.000447214, gnorm=0.643, loss_scale=64, train_wall=55, gb_free=9.7, wall=3053
2022-03-22 20:54:21 | INFO | train_inner | epoch 013:    176 / 411 loss=6.379, ppl=83.22, wps=27486.7, ups=1.68, wpb=16378.9, bsz=32, num_updates=5100, lr=0.000442807, gnorm=0.651, loss_scale=128, train_wall=55, gb_free=9.7, wall=3112
2022-03-22 20:54:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 20:55:21 | INFO | train_inner | epoch 013:    277 / 411 loss=6.425, ppl=85.9, wps=27236.2, ups=1.66, wpb=16384, bsz=32, num_updates=5200, lr=0.000438529, gnorm=0.654, loss_scale=64, train_wall=55, gb_free=9.7, wall=3172
2022-03-22 20:56:21 | INFO | train_inner | epoch 013:    377 / 411 loss=6.404, ppl=84.67, wps=27497.6, ups=1.68, wpb=16384, bsz=32, num_updates=5300, lr=0.000434372, gnorm=0.65, loss_scale=64, train_wall=55, gb_free=9.7, wall=3232
2022-03-22 20:56:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 20:56:46 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.715 | ppl 105.07 | wps 46577.3 | wpb 511.2 | bsz 1 | num_updates 5334 | best_loss 6.715
2022-03-22 20:56:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 5334 updates
2022-03-22 20:56:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:56:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 20:56:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 13 @ 5334 updates, score 6.715) (writing took 0.8995832167565823 seconds)
2022-03-22 20:56:47 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-22 20:56:47 | INFO | train | epoch 013 | loss 6.395 | ppl 84.16 | wps 26761.8 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 5334 | lr 0.000432986 | gnorm 0.651 | loss_scale 64 | train_wall 225 | gb_free 9.7 | wall 3258
2022-03-22 20:56:47 | INFO | fairseq.trainer | begin training epoch 14
2022-03-22 20:56:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 20:57:26 | INFO | train_inner | epoch 014:     66 / 411 loss=6.277, ppl=77.55, wps=24892.7, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=5400, lr=0.000430331, gnorm=0.653, loss_scale=64, train_wall=55, gb_free=9.7, wall=3298
2022-03-22 20:58:26 | INFO | train_inner | epoch 014:    166 / 411 loss=6.261, ppl=76.72, wps=27465.4, ups=1.68, wpb=16378.9, bsz=32, num_updates=5500, lr=0.000426401, gnorm=0.656, loss_scale=64, train_wall=55, gb_free=9.7, wall=3357
2022-03-22 20:59:26 | INFO | train_inner | epoch 014:    266 / 411 loss=6.265, ppl=76.92, wps=27485, ups=1.68, wpb=16384, bsz=32, num_updates=5600, lr=0.000422577, gnorm=0.659, loss_scale=64, train_wall=55, gb_free=9.7, wall=3417
2022-03-22 21:00:25 | INFO | train_inner | epoch 014:    366 / 411 loss=6.278, ppl=77.61, wps=27421.9, ups=1.67, wpb=16384, bsz=32, num_updates=5700, lr=0.000418854, gnorm=0.654, loss_scale=128, train_wall=55, gb_free=9.7, wall=3477
2022-03-22 21:00:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:00:57 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.668 | ppl 101.67 | wps 48989.8 | wpb 511.2 | bsz 1 | num_updates 5745 | best_loss 6.668
2022-03-22 21:00:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 5745 updates
2022-03-22 21:00:57 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:00:58 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:00:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 14 @ 5745 updates, score 6.668) (writing took 1.1045221742242575 seconds)
2022-03-22 21:00:58 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-22 21:00:58 | INFO | train | epoch 014 | loss 6.261 | ppl 76.68 | wps 26781.3 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 5745 | lr 0.00041721 | gnorm 0.655 | loss_scale 128 | train_wall 226 | gb_free 9.7 | wall 3509
2022-03-22 21:00:58 | INFO | fairseq.trainer | begin training epoch 15
2022-03-22 21:00:58 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:01:31 | INFO | train_inner | epoch 015:     55 / 411 loss=6.165, ppl=71.75, wps=24858.1, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=5800, lr=0.000415227, gnorm=0.653, loss_scale=128, train_wall=55, gb_free=9.7, wall=3542
2022-03-22 21:01:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:02:31 | INFO | train_inner | epoch 015:    156 / 411 loss=6.12, ppl=69.56, wps=27167.5, ups=1.66, wpb=16384, bsz=32, num_updates=5900, lr=0.000411693, gnorm=0.658, loss_scale=64, train_wall=55, gb_free=9.7, wall=3603
2022-03-22 21:03:31 | INFO | train_inner | epoch 015:    256 / 411 loss=6.157, ppl=71.36, wps=27434.1, ups=1.67, wpb=16378.9, bsz=32, num_updates=6000, lr=0.000408248, gnorm=0.66, loss_scale=64, train_wall=55, gb_free=9.7, wall=3662
2022-03-22 21:04:31 | INFO | train_inner | epoch 015:    356 / 411 loss=6.183, ppl=72.64, wps=27222.3, ups=1.66, wpb=16384, bsz=32, num_updates=6100, lr=0.000404888, gnorm=0.658, loss_scale=64, train_wall=55, gb_free=9.7, wall=3722
2022-03-22 21:05:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:05:09 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.618 | ppl 98.22 | wps 45286.5 | wpb 511.2 | bsz 1 | num_updates 6155 | best_loss 6.618
2022-03-22 21:05:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 6155 updates
2022-03-22 21:05:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:05:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:05:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 15 @ 6155 updates, score 6.618) (writing took 1.0691672079265118 seconds)
2022-03-22 21:05:10 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-22 21:05:10 | INFO | train | epoch 015 | loss 6.145 | ppl 70.78 | wps 26615.3 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 6155 | lr 0.000403075 | gnorm 0.658 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 3761
2022-03-22 21:05:10 | INFO | fairseq.trainer | begin training epoch 16
2022-03-22 21:05:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:05:37 | INFO | train_inner | epoch 016:     45 / 411 loss=6.093, ppl=68.27, wps=24807, ups=1.52, wpb=16317.5, bsz=31.9, num_updates=6200, lr=0.00040161, gnorm=0.662, loss_scale=64, train_wall=55, gb_free=9.7, wall=3788
2022-03-22 21:06:37 | INFO | train_inner | epoch 016:    145 / 411 loss=6.017, ppl=64.77, wps=27461.6, ups=1.68, wpb=16384, bsz=32, num_updates=6300, lr=0.00039841, gnorm=0.662, loss_scale=64, train_wall=55, gb_free=9.7, wall=3848
2022-03-22 21:07:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:07:37 | INFO | train_inner | epoch 016:    246 / 411 loss=6.046, ppl=66.08, wps=27198.9, ups=1.66, wpb=16384, bsz=32, num_updates=6400, lr=0.000395285, gnorm=0.664, loss_scale=64, train_wall=55, gb_free=9.7, wall=3908
2022-03-22 21:08:37 | INFO | train_inner | epoch 016:    346 / 411 loss=6.065, ppl=66.96, wps=27401.8, ups=1.67, wpb=16384, bsz=32, num_updates=6500, lr=0.000392232, gnorm=0.666, loss_scale=64, train_wall=55, gb_free=9.7, wall=3968
2022-03-22 21:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:09:20 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.586 | ppl 96.09 | wps 46418.8 | wpb 511.2 | bsz 1 | num_updates 6565 | best_loss 6.586
2022-03-22 21:09:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 6565 updates
2022-03-22 21:09:20 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:09:21 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:09:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 16 @ 6565 updates, score 6.586) (writing took 0.9311262648552656 seconds)
2022-03-22 21:09:21 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-22 21:09:21 | INFO | train | epoch 016 | loss 6.044 | ppl 65.99 | wps 26738.6 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 6565 | lr 0.000390286 | gnorm 0.663 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 4012
2022-03-22 21:09:21 | INFO | fairseq.trainer | begin training epoch 17
2022-03-22 21:09:21 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:09:42 | INFO | train_inner | epoch 017:     35 / 411 loss=6.012, ppl=64.53, wps=24893.4, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=6600, lr=0.000389249, gnorm=0.665, loss_scale=64, train_wall=55, gb_free=9.7, wall=4033
2022-03-22 21:10:42 | INFO | train_inner | epoch 017:    135 / 411 loss=5.921, ppl=60.58, wps=27429.2, ups=1.67, wpb=16378.9, bsz=32, num_updates=6700, lr=0.000386334, gnorm=0.667, loss_scale=64, train_wall=55, gb_free=9.7, wall=4093
2022-03-22 21:11:42 | INFO | train_inner | epoch 017:    235 / 411 loss=5.957, ppl=62.14, wps=27420.8, ups=1.67, wpb=16384, bsz=32, num_updates=6800, lr=0.000383482, gnorm=0.669, loss_scale=64, train_wall=55, gb_free=9.7, wall=4153
2022-03-22 21:12:42 | INFO | train_inner | epoch 017:    335 / 411 loss=5.995, ppl=63.79, wps=27371.6, ups=1.67, wpb=16384, bsz=32, num_updates=6900, lr=0.000380693, gnorm=0.668, loss_scale=128, train_wall=55, gb_free=9.7, wall=4213
2022-03-22 21:12:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:13:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:13:32 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.543 | ppl 93.23 | wps 47101.4 | wpb 511.2 | bsz 1 | num_updates 6975 | best_loss 6.543
2022-03-22 21:13:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 6975 updates
2022-03-22 21:13:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:13:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:13:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 17 @ 6975 updates, score 6.543) (writing took 1.0182498041540384 seconds)
2022-03-22 21:13:33 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-22 21:13:33 | INFO | train | epoch 017 | loss 5.954 | ppl 61.98 | wps 26646.4 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 6975 | lr 0.000378641 | gnorm 0.668 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 4264
2022-03-22 21:13:33 | INFO | fairseq.trainer | begin training epoch 18
2022-03-22 21:13:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:13:48 | INFO | train_inner | epoch 018:     25 / 411 loss=5.925, ppl=60.75, wps=24633.7, ups=1.51, wpb=16322.6, bsz=31.9, num_updates=7000, lr=0.000377964, gnorm=0.668, loss_scale=64, train_wall=55, gb_free=9.7, wall=4279
2022-03-22 21:14:48 | INFO | train_inner | epoch 018:    125 / 411 loss=5.854, ppl=57.83, wps=27359, ups=1.67, wpb=16378.9, bsz=32, num_updates=7100, lr=0.000375293, gnorm=0.669, loss_scale=64, train_wall=55, gb_free=9.7, wall=4339
2022-03-22 21:15:48 | INFO | train_inner | epoch 018:    225 / 411 loss=5.872, ppl=58.58, wps=27432.6, ups=1.67, wpb=16384, bsz=32, num_updates=7200, lr=0.000372678, gnorm=0.677, loss_scale=64, train_wall=55, gb_free=9.7, wall=4399
2022-03-22 21:16:47 | INFO | train_inner | epoch 018:    325 / 411 loss=5.888, ppl=59.22, wps=27376.4, ups=1.67, wpb=16384, bsz=32, num_updates=7300, lr=0.000370117, gnorm=0.676, loss_scale=64, train_wall=55, gb_free=9.7, wall=4458
2022-03-22 21:17:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:17:43 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 6.515 | ppl 91.43 | wps 48431.4 | wpb 511.2 | bsz 1 | num_updates 7386 | best_loss 6.515
2022-03-22 21:17:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 7386 updates
2022-03-22 21:17:43 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:17:44 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:17:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 18 @ 7386 updates, score 6.515) (writing took 0.9616240598261356 seconds)
2022-03-22 21:17:44 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-22 21:17:44 | INFO | train | epoch 018 | loss 5.873 | ppl 58.61 | wps 26769.6 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 7386 | lr 0.000367956 | gnorm 0.676 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 4515
2022-03-22 21:17:44 | INFO | fairseq.trainer | begin training epoch 19
2022-03-22 21:17:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:17:53 | INFO | train_inner | epoch 019:     14 / 411 loss=5.879, ppl=58.86, wps=24930.9, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=7400, lr=0.000367607, gnorm=0.683, loss_scale=64, train_wall=55, gb_free=9.7, wall=4524
2022-03-22 21:18:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:18:53 | INFO | train_inner | epoch 019:    115 / 411 loss=5.751, ppl=53.84, wps=27082.1, ups=1.65, wpb=16384, bsz=32, num_updates=7500, lr=0.000365148, gnorm=0.681, loss_scale=64, train_wall=56, gb_free=9.7, wall=4584
2022-03-22 21:19:54 | INFO | train_inner | epoch 019:    215 / 411 loss=5.805, ppl=55.91, wps=27247.5, ups=1.66, wpb=16384, bsz=32, num_updates=7600, lr=0.000362738, gnorm=0.686, loss_scale=64, train_wall=55, gb_free=9.7, wall=4645
2022-03-22 21:20:53 | INFO | train_inner | epoch 019:    315 / 411 loss=5.81, ppl=56.1, wps=27483.5, ups=1.68, wpb=16384, bsz=32, num_updates=7700, lr=0.000360375, gnorm=0.683, loss_scale=64, train_wall=55, gb_free=9.7, wall=4704
2022-03-22 21:21:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:21:55 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 6.492 | ppl 90.04 | wps 49140.1 | wpb 511.2 | bsz 1 | num_updates 7796 | best_loss 6.492
2022-03-22 21:21:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 7796 updates
2022-03-22 21:21:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:21:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:21:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 19 @ 7796 updates, score 6.492) (writing took 0.9385123252868652 seconds)
2022-03-22 21:21:56 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-22 21:21:56 | INFO | train | epoch 019 | loss 5.8 | ppl 55.7 | wps 26667.8 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 7796 | lr 0.000358149 | gnorm 0.684 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 4767
2022-03-22 21:21:56 | INFO | fairseq.trainer | begin training epoch 20
2022-03-22 21:21:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:21:59 | INFO | train_inner | epoch 020:      4 / 411 loss=5.841, ppl=57.31, wps=24836.6, ups=1.52, wpb=16317.5, bsz=31.9, num_updates=7800, lr=0.000358057, gnorm=0.685, loss_scale=64, train_wall=55, gb_free=9.7, wall=4770
2022-03-22 21:22:58 | INFO | train_inner | epoch 020:    104 / 411 loss=5.679, ppl=51.22, wps=27459.8, ups=1.68, wpb=16378.9, bsz=32, num_updates=7900, lr=0.000355784, gnorm=0.689, loss_scale=64, train_wall=55, gb_free=9.7, wall=4830
2022-03-22 21:23:41 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 21:23:59 | INFO | train_inner | epoch 020:    205 / 411 loss=5.705, ppl=52.17, wps=27189.3, ups=1.66, wpb=16384, bsz=32, num_updates=8000, lr=0.000353553, gnorm=0.691, loss_scale=32, train_wall=55, gb_free=9.7, wall=4890
2022-03-22 21:24:58 | INFO | train_inner | epoch 020:    305 / 411 loss=5.753, ppl=53.94, wps=27423.7, ups=1.67, wpb=16384, bsz=32, num_updates=8100, lr=0.000351364, gnorm=0.694, loss_scale=32, train_wall=55, gb_free=9.7, wall=4950
2022-03-22 21:25:58 | INFO | train_inner | epoch 020:    405 / 411 loss=5.793, ppl=55.44, wps=27500.6, ups=1.68, wpb=16384, bsz=32, num_updates=8200, lr=0.000349215, gnorm=0.689, loss_scale=32, train_wall=55, gb_free=9.7, wall=5009
2022-03-22 21:26:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:26:06 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 6.478 | ppl 89.12 | wps 45499.7 | wpb 511.2 | bsz 1 | num_updates 8206 | best_loss 6.478
2022-03-22 21:26:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 8206 updates
2022-03-22 21:26:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:26:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 20 @ 8206 updates, score 6.478) (writing took 0.9756728559732437 seconds)
2022-03-22 21:26:07 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-22 21:26:07 | INFO | train | epoch 020 | loss 5.733 | ppl 53.2 | wps 26695.9 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 8206 | lr 0.000349087 | gnorm 0.691 | loss_scale 32 | train_wall 225 | gb_free 9.7 | wall 5019
2022-03-22 21:26:07 | INFO | fairseq.trainer | begin training epoch 21
2022-03-22 21:26:07 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:27:04 | INFO | train_inner | epoch 021:     94 / 411 loss=5.624, ppl=49.32, wps=24842.6, ups=1.52, wpb=16317.5, bsz=31.9, num_updates=8300, lr=0.000347105, gnorm=0.694, loss_scale=32, train_wall=55, gb_free=9.7, wall=5075
2022-03-22 21:28:04 | INFO | train_inner | epoch 021:    194 / 411 loss=5.667, ppl=50.8, wps=27401.8, ups=1.67, wpb=16384, bsz=32, num_updates=8400, lr=0.000345033, gnorm=0.701, loss_scale=32, train_wall=55, gb_free=9.7, wall=5135
2022-03-22 21:29:03 | INFO | train_inner | epoch 021:    294 / 411 loss=5.683, ppl=51.37, wps=27414.5, ups=1.67, wpb=16384, bsz=32, num_updates=8500, lr=0.000342997, gnorm=0.698, loss_scale=64, train_wall=55, gb_free=9.7, wall=5194
2022-03-22 21:30:03 | INFO | train_inner | epoch 021:    394 / 411 loss=5.704, ppl=52.11, wps=27457.3, ups=1.68, wpb=16384, bsz=32, num_updates=8600, lr=0.000340997, gnorm=0.705, loss_scale=64, train_wall=55, gb_free=9.7, wall=5254
2022-03-22 21:30:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:30:18 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 6.465 | ppl 88.32 | wps 49274.5 | wpb 511.2 | bsz 1 | num_updates 8617 | best_loss 6.465
2022-03-22 21:30:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 8617 updates
2022-03-22 21:30:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:30:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:30:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 21 @ 8617 updates, score 6.465) (writing took 0.924064489081502 seconds)
2022-03-22 21:30:19 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-22 21:30:19 | INFO | train | epoch 021 | loss 5.672 | ppl 50.99 | wps 26785.6 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 8617 | lr 0.000340661 | gnorm 0.7 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 5270
2022-03-22 21:30:19 | INFO | fairseq.trainer | begin training epoch 22
2022-03-22 21:30:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:31:08 | INFO | train_inner | epoch 022:     83 / 411 loss=5.592, ppl=48.22, wps=24955.9, ups=1.53, wpb=16317.5, bsz=31.9, num_updates=8700, lr=0.000339032, gnorm=0.702, loss_scale=64, train_wall=55, gb_free=9.7, wall=5319
2022-03-22 21:32:08 | INFO | train_inner | epoch 022:    183 / 411 loss=5.577, ppl=47.74, wps=27456, ups=1.68, wpb=16384, bsz=32, num_updates=8800, lr=0.0003371, gnorm=0.709, loss_scale=64, train_wall=55, gb_free=9.7, wall=5379
2022-03-22 21:33:08 | INFO | train_inner | epoch 022:    283 / 411 loss=5.637, ppl=49.77, wps=27323.2, ups=1.67, wpb=16384, bsz=32, num_updates=8900, lr=0.000335201, gnorm=0.707, loss_scale=64, train_wall=55, gb_free=9.7, wall=5439
2022-03-22 21:34:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:34:09 | INFO | train_inner | epoch 022:    384 / 411 loss=5.659, ppl=50.53, wps=27030.2, ups=1.65, wpb=16384, bsz=32, num_updates=9000, lr=0.000333333, gnorm=0.711, loss_scale=64, train_wall=56, gb_free=9.7, wall=5500
2022-03-22 21:34:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:34:30 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 6.451 | ppl 87.49 | wps 46567.6 | wpb 511.2 | bsz 1 | num_updates 9027 | best_loss 6.451
2022-03-22 21:34:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 9027 updates
2022-03-22 21:34:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:34:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:34:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 22 @ 9027 updates, score 6.451) (writing took 0.9635300226509571 seconds)
2022-03-22 21:34:31 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-22 21:34:31 | INFO | train | epoch 022 | loss 5.615 | ppl 49 | wps 26631.8 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 9027 | lr 0.000332834 | gnorm 0.708 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 5522
2022-03-22 21:34:31 | INFO | fairseq.trainer | begin training epoch 23
2022-03-22 21:34:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:35:14 | INFO | train_inner | epoch 023:     73 / 411 loss=5.554, ppl=46.99, wps=24841.4, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=9100, lr=0.000331497, gnorm=0.71, loss_scale=64, train_wall=55, gb_free=9.7, wall=5565
2022-03-22 21:36:14 | INFO | train_inner | epoch 023:    173 / 411 loss=5.551, ppl=46.88, wps=27434.7, ups=1.67, wpb=16384, bsz=32, num_updates=9200, lr=0.00032969, gnorm=0.715, loss_scale=64, train_wall=55, gb_free=9.7, wall=5625
2022-03-22 21:37:14 | INFO | train_inner | epoch 023:    273 / 411 loss=5.577, ppl=47.75, wps=27416.1, ups=1.67, wpb=16384, bsz=32, num_updates=9300, lr=0.000327913, gnorm=0.716, loss_scale=64, train_wall=55, gb_free=9.7, wall=5685
2022-03-22 21:38:14 | INFO | train_inner | epoch 023:    373 / 411 loss=5.589, ppl=48.14, wps=27400.5, ups=1.67, wpb=16378.9, bsz=32, num_updates=9400, lr=0.000326164, gnorm=0.715, loss_scale=64, train_wall=55, gb_free=9.7, wall=5745
2022-03-22 21:38:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:38:41 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 6.437 | ppl 86.67 | wps 46511.8 | wpb 511.2 | bsz 1 | num_updates 9438 | best_loss 6.437
2022-03-22 21:38:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 9438 updates
2022-03-22 21:38:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:38:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:38:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 23 @ 9438 updates, score 6.437) (writing took 0.9398967530578375 seconds)
2022-03-22 21:38:42 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-22 21:38:42 | INFO | train | epoch 023 | loss 5.562 | ppl 47.25 | wps 26739.6 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 9438 | lr 0.000325507 | gnorm 0.715 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 5773
2022-03-22 21:38:42 | INFO | fairseq.trainer | begin training epoch 24
2022-03-22 21:38:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:39:19 | INFO | train_inner | epoch 024:     62 / 411 loss=5.51, ppl=45.58, wps=24806.5, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=9500, lr=0.000324443, gnorm=0.718, loss_scale=64, train_wall=55, gb_free=9.7, wall=5810
2022-03-22 21:40:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:40:20 | INFO | train_inner | epoch 024:    163 / 411 loss=5.466, ppl=44.2, wps=27179.7, ups=1.66, wpb=16384, bsz=32, num_updates=9600, lr=0.000322749, gnorm=0.719, loss_scale=64, train_wall=55, gb_free=9.7, wall=5871
2022-03-22 21:41:19 | INFO | train_inner | epoch 024:    263 / 411 loss=5.529, ppl=46.18, wps=27377.5, ups=1.67, wpb=16384, bsz=32, num_updates=9700, lr=0.000321081, gnorm=0.73, loss_scale=64, train_wall=55, gb_free=9.7, wall=5931
2022-03-22 21:42:19 | INFO | train_inner | epoch 024:    363 / 411 loss=5.56, ppl=47.17, wps=27358.1, ups=1.67, wpb=16378.9, bsz=32, num_updates=9800, lr=0.000319438, gnorm=0.722, loss_scale=64, train_wall=55, gb_free=9.7, wall=5990
2022-03-22 21:42:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:42:53 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 6.431 | ppl 86.29 | wps 48663.1 | wpb 511.2 | bsz 1 | num_updates 9848 | best_loss 6.431
2022-03-22 21:42:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 9848 updates
2022-03-22 21:42:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:42:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:42:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 24 @ 9848 updates, score 6.431) (writing took 0.8964451774954796 seconds)
2022-03-22 21:42:54 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-22 21:42:54 | INFO | train | epoch 024 | loss 5.515 | ppl 45.71 | wps 26677.9 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 9848 | lr 0.000318659 | gnorm 0.723 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 6025
2022-03-22 21:42:54 | INFO | fairseq.trainer | begin training epoch 25
2022-03-22 21:42:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:43:25 | INFO | train_inner | epoch 025:     52 / 411 loss=5.474, ppl=44.46, wps=24860, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=9900, lr=0.000317821, gnorm=0.724, loss_scale=64, train_wall=55, gb_free=9.7, wall=6056
2022-03-22 21:44:23 | INFO | train_inner | epoch 025:    152 / 411 loss=5.421, ppl=42.84, wps=28177.5, ups=1.72, wpb=16384, bsz=32, num_updates=10000, lr=0.000316228, gnorm=0.726, loss_scale=64, train_wall=54, gb_free=9.7, wall=6114
2022-03-22 21:45:18 | INFO | train_inner | epoch 025:    252 / 411 loss=5.47, ppl=44.34, wps=29970.6, ups=1.83, wpb=16378.9, bsz=32, num_updates=10100, lr=0.000314658, gnorm=0.729, loss_scale=128, train_wall=51, gb_free=9.7, wall=6169
2022-03-22 21:45:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:46:13 | INFO | train_inner | epoch 025:    353 / 411 loss=5.521, ppl=45.9, wps=29560.9, ups=1.8, wpb=16384, bsz=32, num_updates=10200, lr=0.000313112, gnorm=0.733, loss_scale=64, train_wall=51, gb_free=9.7, wall=6224
2022-03-22 21:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:46:49 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 6.412 | ppl 85.18 | wps 51155.4 | wpb 511.2 | bsz 1 | num_updates 10258 | best_loss 6.412
2022-03-22 21:46:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 10258 updates
2022-03-22 21:46:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:46:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 25 @ 10258 updates, score 6.412) (writing took 0.9640017133206129 seconds)
2022-03-22 21:46:50 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-22 21:46:50 | INFO | train | epoch 025 | loss 5.467 | ppl 44.23 | wps 28348.3 | ups 1.73 | wpb 16367.8 | bsz 32 | num_updates 10258 | lr 0.000312226 | gnorm 0.73 | loss_scale 64 | train_wall 213 | gb_free 9.7 | wall 6262
2022-03-22 21:46:50 | INFO | fairseq.trainer | begin training epoch 26
2022-03-22 21:46:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:47:14 | INFO | train_inner | epoch 026:     42 / 411 loss=5.45, ppl=43.73, wps=26941.1, ups=1.65, wpb=16322.6, bsz=31.9, num_updates=10300, lr=0.000311588, gnorm=0.735, loss_scale=64, train_wall=51, gb_free=9.7, wall=6285
2022-03-22 21:48:10 | INFO | train_inner | epoch 026:    142 / 411 loss=5.381, ppl=41.66, wps=29343, ups=1.79, wpb=16378.9, bsz=32, num_updates=10400, lr=0.000310087, gnorm=0.734, loss_scale=64, train_wall=52, gb_free=9.7, wall=6341
2022-03-22 21:49:06 | INFO | train_inner | epoch 026:    242 / 411 loss=5.423, ppl=42.91, wps=29097.8, ups=1.78, wpb=16384, bsz=32, num_updates=10500, lr=0.000308607, gnorm=0.744, loss_scale=64, train_wall=52, gb_free=9.7, wall=6397
2022-03-22 21:50:03 | INFO | train_inner | epoch 026:    342 / 411 loss=5.465, ppl=44.17, wps=28833.3, ups=1.76, wpb=16384, bsz=32, num_updates=10600, lr=0.000307148, gnorm=0.741, loss_scale=64, train_wall=53, gb_free=9.7, wall=6454
2022-03-22 21:50:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:50:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:50:46 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 6.406 | ppl 84.83 | wps 49851.4 | wpb 511.2 | bsz 1 | num_updates 10668 | best_loss 6.406
2022-03-22 21:50:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 10668 updates
2022-03-22 21:50:46 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:50:47 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:50:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 26 @ 10668 updates, score 6.406) (writing took 0.9885879196226597 seconds)
2022-03-22 21:50:47 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-22 21:50:47 | INFO | train | epoch 026 | loss 5.424 | ppl 42.93 | wps 28326.7 | ups 1.73 | wpb 16367.8 | bsz 32 | num_updates 10668 | lr 0.000306167 | gnorm 0.738 | loss_scale 64 | train_wall 214 | gb_free 9.7 | wall 6498
2022-03-22 21:50:47 | INFO | fairseq.trainer | begin training epoch 27
2022-03-22 21:50:47 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:51:06 | INFO | train_inner | epoch 027:     32 / 411 loss=5.418, ppl=42.76, wps=25997.9, ups=1.59, wpb=16322.6, bsz=31.9, num_updates=10700, lr=0.000305709, gnorm=0.736, loss_scale=64, train_wall=53, gb_free=9.7, wall=6517
2022-03-22 21:52:02 | INFO | train_inner | epoch 027:    132 / 411 loss=5.348, ppl=40.72, wps=28884.3, ups=1.76, wpb=16378.9, bsz=32, num_updates=10800, lr=0.00030429, gnorm=0.74, loss_scale=64, train_wall=52, gb_free=9.7, wall=6573
2022-03-22 21:52:59 | INFO | train_inner | epoch 027:    232 / 411 loss=5.373, ppl=41.45, wps=28917.7, ups=1.76, wpb=16384, bsz=32, num_updates=10900, lr=0.000302891, gnorm=0.742, loss_scale=64, train_wall=52, gb_free=9.7, wall=6630
2022-03-22 21:53:56 | INFO | train_inner | epoch 027:    332 / 411 loss=5.419, ppl=42.79, wps=28776.4, ups=1.76, wpb=16384, bsz=32, num_updates=11000, lr=0.000301511, gnorm=0.747, loss_scale=64, train_wall=53, gb_free=9.7, wall=6687
2022-03-22 21:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:54:45 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 6.403 | ppl 84.65 | wps 49894.6 | wpb 511.2 | bsz 1 | num_updates 11079 | best_loss 6.403
2022-03-22 21:54:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 11079 updates
2022-03-22 21:54:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:54:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:54:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 27 @ 11079 updates, score 6.403) (writing took 0.9489489831030369 seconds)
2022-03-22 21:54:46 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-22 21:54:46 | INFO | train | epoch 027 | loss 5.384 | ppl 41.75 | wps 28171.5 | ups 1.72 | wpb 16367.8 | bsz 32 | num_updates 11079 | lr 0.000300434 | gnorm 0.743 | loss_scale 64 | train_wall 216 | gb_free 9.7 | wall 6737
2022-03-22 21:54:46 | INFO | fairseq.trainer | begin training epoch 28
2022-03-22 21:54:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:54:58 | INFO | train_inner | epoch 028:     21 / 411 loss=5.395, ppl=42.06, wps=26253.5, ups=1.61, wpb=16322.6, bsz=31.9, num_updates=11100, lr=0.00030015, gnorm=0.746, loss_scale=64, train_wall=52, gb_free=9.7, wall=6749
2022-03-22 21:55:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 21:55:57 | INFO | train_inner | epoch 028:    122 / 411 loss=5.278, ppl=38.81, wps=27886.5, ups=1.7, wpb=16384, bsz=32, num_updates=11200, lr=0.000298807, gnorm=0.743, loss_scale=64, train_wall=54, gb_free=9.7, wall=6808
2022-03-22 21:56:57 | INFO | train_inner | epoch 028:    222 / 411 loss=5.347, ppl=40.71, wps=27377, ups=1.67, wpb=16378.9, bsz=32, num_updates=11300, lr=0.000297482, gnorm=0.75, loss_scale=64, train_wall=55, gb_free=9.7, wall=6868
2022-03-22 21:57:57 | INFO | train_inner | epoch 028:    322 / 411 loss=5.364, ppl=41.17, wps=27334, ups=1.67, wpb=16384, bsz=32, num_updates=11400, lr=0.000296174, gnorm=0.755, loss_scale=64, train_wall=55, gb_free=9.7, wall=6928
2022-03-22 21:58:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 21:58:54 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.393 | ppl 84.05 | wps 47166.1 | wpb 511.2 | bsz 1 | num_updates 11489 | best_loss 6.393
2022-03-22 21:58:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 11489 updates
2022-03-22 21:58:54 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:58:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 21:58:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 28 @ 11489 updates, score 6.393) (writing took 0.9843086898326874 seconds)
2022-03-22 21:58:55 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-22 21:58:55 | INFO | train | epoch 028 | loss 5.344 | ppl 40.63 | wps 26922.3 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 11489 | lr 0.000295025 | gnorm 0.751 | loss_scale 64 | train_wall 224 | gb_free 9.7 | wall 6986
2022-03-22 21:58:55 | INFO | fairseq.trainer | begin training epoch 29
2022-03-22 21:58:55 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 21:59:02 | INFO | train_inner | epoch 029:     11 / 411 loss=5.392, ppl=41.99, wps=24967.5, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=11500, lr=0.000294884, gnorm=0.758, loss_scale=64, train_wall=55, gb_free=9.7, wall=6993
2022-03-22 22:00:02 | INFO | train_inner | epoch 029:    111 / 411 loss=5.243, ppl=37.87, wps=27402.6, ups=1.67, wpb=16378.9, bsz=32, num_updates=11600, lr=0.00029361, gnorm=0.755, loss_scale=64, train_wall=55, gb_free=9.7, wall=7053
2022-03-22 22:01:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:01:02 | INFO | train_inner | epoch 029:    212 / 411 loss=5.303, ppl=39.47, wps=27136.5, ups=1.66, wpb=16384, bsz=32, num_updates=11700, lr=0.000292353, gnorm=0.756, loss_scale=64, train_wall=56, gb_free=9.7, wall=7113
2022-03-22 22:02:02 | INFO | train_inner | epoch 029:    312 / 411 loss=5.336, ppl=40.4, wps=27270.7, ups=1.66, wpb=16384, bsz=32, num_updates=11800, lr=0.000291111, gnorm=0.76, loss_scale=64, train_wall=55, gb_free=9.7, wall=7173
2022-03-22 22:03:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:03:07 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.388 | ppl 83.77 | wps 45783.6 | wpb 511.2 | bsz 1 | num_updates 11899 | best_loss 6.388
2022-03-22 22:03:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 11899 updates
2022-03-22 22:03:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 29 @ 11899 updates, score 6.388) (writing took 0.9621959198266268 seconds)
2022-03-22 22:03:08 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-22 22:03:08 | INFO | train | epoch 029 | loss 5.309 | ppl 39.65 | wps 26618.1 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 11899 | lr 0.000289898 | gnorm 0.758 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 7239
2022-03-22 22:03:08 | INFO | fairseq.trainer | begin training epoch 30
2022-03-22 22:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:03:08 | INFO | train_inner | epoch 030:      1 / 411 loss=5.364, ppl=41.18, wps=24740.1, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=11900, lr=0.000289886, gnorm=0.762, loss_scale=64, train_wall=55, gb_free=9.7, wall=7239
2022-03-22 22:04:08 | INFO | train_inner | epoch 030:    101 / 411 loss=5.206, ppl=36.91, wps=27461.6, ups=1.68, wpb=16384, bsz=32, num_updates=12000, lr=0.000288675, gnorm=0.757, loss_scale=64, train_wall=55, gb_free=9.7, wall=7299
2022-03-22 22:05:08 | INFO | train_inner | epoch 030:    201 / 411 loss=5.267, ppl=38.5, wps=27423.5, ups=1.67, wpb=16378.9, bsz=32, num_updates=12100, lr=0.00028748, gnorm=0.769, loss_scale=64, train_wall=55, gb_free=9.7, wall=7359
2022-03-22 22:06:07 | INFO | train_inner | epoch 030:    301 / 411 loss=5.299, ppl=39.37, wps=27412.3, ups=1.67, wpb=16384, bsz=32, num_updates=12200, lr=0.000286299, gnorm=0.769, loss_scale=64, train_wall=55, gb_free=9.7, wall=7418
2022-03-22 22:06:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:07:08 | INFO | train_inner | epoch 030:    402 / 411 loss=5.327, ppl=40.13, wps=27150.9, ups=1.66, wpb=16384, bsz=32, num_updates=12300, lr=0.000285133, gnorm=0.773, loss_scale=64, train_wall=55, gb_free=9.7, wall=7479
2022-03-22 22:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:07:18 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.39 | ppl 83.89 | wps 49576.4 | wpb 511.2 | bsz 1 | num_updates 12309 | best_loss 6.388
2022-03-22 22:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 12309 updates
2022-03-22 22:07:18 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-22 22:07:18 | INFO | train | epoch 030 | loss 5.275 | ppl 38.72 | wps 26814.1 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 12309 | lr 0.000285029 | gnorm 0.767 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 7489
2022-03-22 22:07:18 | INFO | fairseq.trainer | begin training epoch 31
2022-03-22 22:07:18 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:08:12 | INFO | train_inner | epoch 031:     91 / 411 loss=5.165, ppl=35.89, wps=25227.8, ups=1.55, wpb=16322.6, bsz=31.9, num_updates=12400, lr=0.000283981, gnorm=0.766, loss_scale=64, train_wall=55, gb_free=9.7, wall=7543
2022-03-22 22:09:12 | INFO | train_inner | epoch 031:    191 / 411 loss=5.225, ppl=37.4, wps=27459.2, ups=1.68, wpb=16384, bsz=32, num_updates=12500, lr=0.000282843, gnorm=0.771, loss_scale=64, train_wall=55, gb_free=9.7, wall=7603
2022-03-22 22:09:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 22:10:12 | INFO | train_inner | epoch 031:    292 / 411 loss=5.259, ppl=38.29, wps=27185, ups=1.66, wpb=16384, bsz=32, num_updates=12600, lr=0.000281718, gnorm=0.773, loss_scale=32, train_wall=55, gb_free=9.7, wall=7663
2022-03-22 22:11:12 | INFO | train_inner | epoch 031:    392 / 411 loss=5.302, ppl=39.46, wps=27473.1, ups=1.68, wpb=16378.9, bsz=32, num_updates=12700, lr=0.000280607, gnorm=0.776, loss_scale=32, train_wall=55, gb_free=9.7, wall=7723
2022-03-22 22:11:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:11:28 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.386 | ppl 83.63 | wps 48325.9 | wpb 511.2 | bsz 1 | num_updates 12719 | best_loss 6.386
2022-03-22 22:11:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 12719 updates
2022-03-22 22:11:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:11:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:11:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 31 @ 12719 updates, score 6.386) (writing took 1.0859008636325598 seconds)
2022-03-22 22:11:29 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-22 22:11:29 | INFO | train | epoch 031 | loss 5.241 | ppl 37.82 | wps 26719.1 | ups 1.63 | wpb 16367.8 | bsz 32 | num_updates 12719 | lr 0.000280397 | gnorm 0.772 | loss_scale 32 | train_wall 225 | gb_free 9.7 | wall 7740
2022-03-22 22:11:29 | INFO | fairseq.trainer | begin training epoch 32
2022-03-22 22:11:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:12:17 | INFO | train_inner | epoch 032:     81 / 411 loss=5.171, ppl=36.03, wps=24928.7, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=12800, lr=0.000279508, gnorm=0.774, loss_scale=32, train_wall=55, gb_free=9.7, wall=7788
2022-03-22 22:13:17 | INFO | train_inner | epoch 032:    181 / 411 loss=5.192, ppl=36.56, wps=27491.7, ups=1.68, wpb=16384, bsz=32, num_updates=12900, lr=0.000278423, gnorm=0.779, loss_scale=32, train_wall=55, gb_free=9.7, wall=7848
2022-03-22 22:14:17 | INFO | train_inner | epoch 032:    281 / 411 loss=5.221, ppl=37.3, wps=27406.8, ups=1.67, wpb=16378.9, bsz=32, num_updates=13000, lr=0.00027735, gnorm=0.783, loss_scale=32, train_wall=55, gb_free=9.7, wall=7908
2022-03-22 22:15:16 | INFO | train_inner | epoch 032:    381 / 411 loss=5.269, ppl=38.55, wps=27489.9, ups=1.68, wpb=16384, bsz=32, num_updates=13100, lr=0.000276289, gnorm=0.784, loss_scale=64, train_wall=55, gb_free=9.7, wall=7967
2022-03-22 22:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:15:39 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.384 | ppl 83.53 | wps 44826.2 | wpb 511.2 | bsz 1 | num_updates 13130 | best_loss 6.384
2022-03-22 22:15:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 13130 updates
2022-03-22 22:15:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:15:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 32 @ 13130 updates, score 6.384) (writing took 1.0028120316565037 seconds)
2022-03-22 22:15:40 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-22 22:15:40 | INFO | train | epoch 032 | loss 5.21 | ppl 37.03 | wps 26766.9 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 13130 | lr 0.000275974 | gnorm 0.78 | loss_scale 64 | train_wall 225 | gb_free 9.7 | wall 7991
2022-03-22 22:15:40 | INFO | fairseq.trainer | begin training epoch 33
2022-03-22 22:15:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:16:22 | INFO | train_inner | epoch 033:     70 / 411 loss=5.154, ppl=35.6, wps=24782.9, ups=1.52, wpb=16322.6, bsz=31.9, num_updates=13200, lr=0.000275241, gnorm=0.778, loss_scale=64, train_wall=55, gb_free=9.7, wall=8033
2022-03-22 22:17:22 | INFO | train_inner | epoch 033:    170 / 411 loss=5.158, ppl=35.71, wps=27312.5, ups=1.67, wpb=16384, bsz=32, num_updates=13300, lr=0.000274204, gnorm=0.784, loss_scale=64, train_wall=55, gb_free=9.7, wall=8093
2022-03-22 22:18:22 | INFO | train_inner | epoch 033:    270 / 411 loss=5.201, ppl=36.79, wps=27451.4, ups=1.68, wpb=16384, bsz=32, num_updates=13400, lr=0.000273179, gnorm=0.784, loss_scale=64, train_wall=55, gb_free=9.7, wall=8153
2022-03-22 22:19:21 | INFO | train_inner | epoch 033:    370 / 411 loss=5.216, ppl=37.16, wps=27519.4, ups=1.68, wpb=16378.9, bsz=32, num_updates=13500, lr=0.000272166, gnorm=0.791, loss_scale=64, train_wall=55, gb_free=9.7, wall=8212
2022-03-22 22:19:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:19:51 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.382 | ppl 83.39 | wps 45454.2 | wpb 511.2 | bsz 1 | num_updates 13541 | best_loss 6.382
2022-03-22 22:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 13541 updates
2022-03-22 22:19:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-22 22:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 33 @ 13541 updates, score 6.382) (writing took 0.944238469004631 seconds)
2022-03-22 22:19:52 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-22 22:19:52 | INFO | train | epoch 033 | loss 5.181 | ppl 36.27 | wps 26767.9 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 13541 | lr 0.000271753 | gnorm 0.786 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 8243
2022-03-22 22:19:52 | INFO | fairseq.trainer | begin training epoch 34
2022-03-22 22:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:20:27 | INFO | train_inner | epoch 034:     59 / 411 loss=5.126, ppl=34.92, wps=24982.9, ups=1.53, wpb=16322.6, bsz=31.9, num_updates=13600, lr=0.000271163, gnorm=0.788, loss_scale=128, train_wall=54, gb_free=9.7, wall=8278
2022-03-22 22:20:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-22 22:21:27 | INFO | train_inner | epoch 034:    160 / 411 loss=5.114, ppl=34.64, wps=27096, ups=1.65, wpb=16384, bsz=32, num_updates=13700, lr=0.000270172, gnorm=0.791, loss_scale=64, train_wall=56, gb_free=9.7, wall=8338
2022-03-22 22:22:27 | INFO | train_inner | epoch 034:    260 / 411 loss=5.151, ppl=35.54, wps=27385.3, ups=1.67, wpb=16378.9, bsz=32, num_updates=13800, lr=0.000269191, gnorm=0.793, loss_scale=64, train_wall=55, gb_free=9.7, wall=8398
2022-03-22 22:22:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-22 22:23:27 | INFO | train_inner | epoch 034:    361 / 411 loss=5.199, ppl=36.74, wps=27168.1, ups=1.66, wpb=16384, bsz=32, num_updates=13900, lr=0.000268221, gnorm=0.795, loss_scale=32, train_wall=56, gb_free=9.7, wall=8458
2022-03-22 22:23:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:24:02 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.388 | ppl 83.74 | wps 47817 | wpb 511.2 | bsz 1 | num_updates 13950 | best_loss 6.382
2022-03-22 22:24:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 13950 updates
2022-03-22 22:24:02 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-22 22:24:02 | INFO | train | epoch 034 | loss 5.152 | ppl 35.55 | wps 26755.5 | ups 1.63 | wpb 16367.7 | bsz 32 | num_updates 13950 | lr 0.00026774 | gnorm 0.792 | loss_scale 32 | train_wall 226 | gb_free 9.7 | wall 8493
2022-03-22 22:24:02 | INFO | fairseq.trainer | begin training epoch 35
2022-03-22 22:24:02 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:24:32 | INFO | train_inner | epoch 035:     50 / 411 loss=5.132, ppl=35.06, wps=25340.3, ups=1.55, wpb=16322.6, bsz=31.9, num_updates=14000, lr=0.000267261, gnorm=0.795, loss_scale=32, train_wall=55, gb_free=9.7, wall=8523
2022-03-22 22:25:31 | INFO | train_inner | epoch 035:    150 / 411 loss=5.088, ppl=34, wps=27507.4, ups=1.68, wpb=16384, bsz=32, num_updates=14100, lr=0.000266312, gnorm=0.793, loss_scale=32, train_wall=55, gb_free=9.7, wall=8582
2022-03-22 22:26:31 | INFO | train_inner | epoch 035:    250 / 411 loss=5.129, ppl=35, wps=27415.8, ups=1.67, wpb=16378.9, bsz=32, num_updates=14200, lr=0.000265372, gnorm=0.801, loss_scale=32, train_wall=55, gb_free=9.7, wall=8642
2022-03-22 22:27:31 | INFO | train_inner | epoch 035:    350 / 411 loss=5.173, ppl=36.07, wps=27459.1, ups=1.68, wpb=16384, bsz=32, num_updates=14300, lr=0.000264443, gnorm=0.803, loss_scale=32, train_wall=55, gb_free=9.7, wall=8702
2022-03-22 22:28:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:28:12 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.39 | ppl 83.87 | wps 49996.8 | wpb 511.2 | bsz 1 | num_updates 14361 | best_loss 6.382
2022-03-22 22:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 14361 updates
2022-03-22 22:28:12 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-22 22:28:12 | INFO | train | epoch 035 | loss 5.126 | ppl 34.92 | wps 26912.1 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 14361 | lr 0.000263881 | gnorm 0.8 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 8743
2022-03-22 22:28:12 | INFO | fairseq.trainer | begin training epoch 36
2022-03-22 22:28:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-22 22:28:35 | INFO | train_inner | epoch 036:     39 / 411 loss=5.119, ppl=34.75, wps=25315.2, ups=1.55, wpb=16322.6, bsz=31.9, num_updates=14400, lr=0.000263523, gnorm=0.801, loss_scale=64, train_wall=55, gb_free=9.7, wall=8766
2022-03-22 22:29:35 | INFO | train_inner | epoch 036:    139 / 411 loss=5.049, ppl=33.1, wps=27479.8, ups=1.68, wpb=16384, bsz=32, num_updates=14500, lr=0.000262613, gnorm=0.804, loss_scale=64, train_wall=55, gb_free=9.7, wall=8826
2022-03-22 22:30:35 | INFO | train_inner | epoch 036:    239 / 411 loss=5.091, ppl=34.08, wps=27392.2, ups=1.67, wpb=16384, bsz=32, num_updates=14600, lr=0.000261712, gnorm=0.806, loss_scale=64, train_wall=55, gb_free=9.7, wall=8886
2022-03-22 22:31:35 | INFO | train_inner | epoch 036:    339 / 411 loss=5.143, ppl=35.34, wps=27300.1, ups=1.67, wpb=16378.9, bsz=32, num_updates=14700, lr=0.00026082, gnorm=0.811, loss_scale=64, train_wall=55, gb_free=9.7, wall=8946
2022-03-22 22:32:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-22 22:32:23 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.386 | ppl 83.66 | wps 49123.2 | wpb 511.2 | bsz 1 | num_updates 14772 | best_loss 6.382
2022-03-22 22:32:23 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-22 22:32:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 14772 updates
2022-03-22 22:32:23 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-22 22:32:23 | INFO | train | epoch 036 | loss 5.099 | ppl 34.28 | wps 26827.2 | ups 1.64 | wpb 16367.8 | bsz 32 | num_updates 14772 | lr 0.000260184 | gnorm 0.806 | loss_scale 64 | train_wall 226 | gb_free 9.7 | wall 8994
2022-03-22 22:32:23 | INFO | fairseq_cli.train | done training in 8993.4 seconds
Sender: LSF System <lsfadmin@eu-g3-057>
Subject: Job 210566170: <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3> in cluster <euler> Done

Job <wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3> was submitted from host <eu-login-06> by user <andriusb> in cluster <euler> at Wed Mar 23 06:36:22 2022
Job was executed on host(s) <eu-g3-057>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Wed Mar 23 06:36:32 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Wed Mar 23 06:36:32 2022
Terminated at Wed Mar 23 08:01:24 2022
Results reported at Wed Mar 23 08:01:24 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train --task language_modeling data-bin/wikitext-103-cleaned-bpe-size0.0625 --save-dir /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3 --arch transformer_lm --share-decoder-input-output-embed --dropout 0.4 --criterion cross_entropy --optimizer adam --adam-betas "(0.9, 0.98)" --weight-decay 0.01 --clip-norm 0.0 --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 --tokens-per-sample 512 --sample-break-mode none --max-tokens 2048 --update-freq 32 --seed 66575611 --fp16 --no-epoch-checkpoints --no-last-checkpoints --patience 3 --seed 66575613 --max-update 50000
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5080.70 sec.
    Max Memory :                                 4289 MB
    Average Memory :                             3119.84 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15711.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   5092 sec.
    Turnaround time :                            5102 sec.

The output (if any) follows:

2022-03-23 06:36:39 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575613, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 2048, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2048, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 50000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm', 'activation_fn': 'relu', 'dropout': 0.4, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': False, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 1, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 512, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103-cleaned-bpe-size0.0625', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 66575613, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-23 06:36:39 | INFO | fairseq.tasks.language_modeling | dictionary: 39136 types
2022-03-23 06:36:40 | INFO | fairseq_cli.train | TransformerLanguageModel(
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(39136, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=39136, bias=False)
  )
)
2022-03-23 06:36:40 | INFO | fairseq_cli.train | task: LanguageModelingTask
2022-03-23 06:36:40 | INFO | fairseq_cli.train | model: TransformerLanguageModel
2022-03-23 06:36:40 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-23 06:36:40 | INFO | fairseq_cli.train | num. shared model params: 38,951,936 (num. trained: 38,951,936)
2022-03-23 06:36:40 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-23 06:36:40 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/valid
2022-03-23 06:36:43 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-23 06:36:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 06:36:43 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-23 06:36:43 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-23 06:36:43 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-23 06:36:43 | INFO | fairseq_cli.train | max tokens per device = 2048 and max sentences per device = None
2022-03-23 06:36:43 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_last.pt
2022-03-23 06:36:43 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_last.pt
2022-03-23 06:36:43 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-23 06:36:43 | INFO | fairseq.data.data_utils | loaded 112,584 examples from: data-bin/wikitext-103-cleaned-bpe-size0.0625/train
2022-03-23 06:36:43 | INFO | fairseq.trainer | begin training epoch 1
2022-03-23 06:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:36:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-23 06:36:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 06:36:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-23 06:36:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-23 06:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:38:13 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 12.95 | ppl 7912.73 | wps 166059 | wpb 2040.3 | bsz 4 | num_updates 99
2022-03-23 06:38:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 99 updates
2022-03-23 06:38:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:38:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:38:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 1 @ 99 updates, score 12.95) (writing took 0.9217544309794903 seconds)
2022-03-23 06:38:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-23 06:38:14 | INFO | train | epoch 001 | loss 14.468 | ppl 22657.9 | wps 79605.6 | ups 1.22 | wpb 65303.3 | bsz 127.6 | num_updates 99 | lr 1.24725e-05 | gnorm 2.852 | loss_scale 8 | train_wall 83 | gb_free 21.6 | wall 91
2022-03-23 06:38:14 | INFO | fairseq.trainer | begin training epoch 2
2022-03-23 06:38:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:38:15 | INFO | train_inner | epoch 002:      1 / 103 loss=14.455, ppl=22455, wps=79528.3, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=100, lr=1.25975e-05, gnorm=2.837, loss_scale=8, train_wall=84, gb_free=21.6, wall=92
2022-03-23 06:39:35 | INFO | train_inner | epoch 002:    101 / 103 loss=12.525, ppl=5892.4, wps=81936.7, ups=1.25, wpb=65530.9, bsz=128, num_updates=200, lr=2.5095e-05, gnorm=1.15, loss_scale=8, train_wall=75, gb_free=21.6, wall=172
2022-03-23 06:39:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:39:37 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 11.616 | ppl 3139.54 | wps 164988 | wpb 2040.3 | bsz 4 | num_updates 202 | best_loss 11.616
2022-03-23 06:39:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 202 updates
2022-03-23 06:39:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:39:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:39:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 2 @ 202 updates, score 11.616) (writing took 0.895488896407187 seconds)
2022-03-23 06:39:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-23 06:39:38 | INFO | train | epoch 002 | loss 12.52 | ppl 5872.73 | wps 79543.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 202 | lr 2.5345e-05 | gnorm 1.148 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 176
2022-03-23 06:39:38 | INFO | fairseq.trainer | begin training epoch 3
2022-03-23 06:39:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:40:57 | INFO | train_inner | epoch 003:     98 / 103 loss=11.215, ppl=2376.93, wps=79401.5, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=300, lr=3.75925e-05, gnorm=0.694, loss_scale=8, train_wall=75, gb_free=21.6, wall=254
2022-03-23 06:41:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:41:02 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 10.622 | ppl 1575.63 | wps 163326 | wpb 2040.3 | bsz 4 | num_updates 305 | best_loss 10.622
2022-03-23 06:41:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 305 updates
2022-03-23 06:41:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:41:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:41:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 3 @ 305 updates, score 10.622) (writing took 0.9032221422530711 seconds)
2022-03-23 06:41:03 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-23 06:41:03 | INFO | train | epoch 003 | loss 11.184 | ppl 2325.82 | wps 79447.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 305 | lr 3.82174e-05 | gnorm 0.684 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 260
2022-03-23 06:41:03 | INFO | fairseq.trainer | begin training epoch 4
2022-03-23 06:41:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:42:19 | INFO | train_inner | epoch 004:     95 / 103 loss=10.525, ppl=1472.98, wps=79501.5, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=400, lr=5.009e-05, gnorm=0.501, loss_scale=8, train_wall=75, gb_free=21.6, wall=336
2022-03-23 06:42:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:42:27 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 10.248 | ppl 1215.87 | wps 163543 | wpb 2040.3 | bsz 4 | num_updates 408 | best_loss 10.248
2022-03-23 06:42:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 408 updates
2022-03-23 06:42:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:42:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 4 @ 408 updates, score 10.248) (writing took 0.9064412899315357 seconds)
2022-03-23 06:42:28 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-23 06:42:28 | INFO | train | epoch 004 | loss 10.502 | ppl 1450.11 | wps 79566.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 408 | lr 5.10898e-05 | gnorm 0.496 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 345
2022-03-23 06:42:28 | INFO | fairseq.trainer | begin training epoch 5
2022-03-23 06:42:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:43:41 | INFO | train_inner | epoch 005:     92 / 103 loss=10.238, ppl=1207.97, wps=79402.4, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=500, lr=6.25875e-05, gnorm=0.458, loss_scale=8, train_wall=75, gb_free=21.6, wall=419
2022-03-23 06:43:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:43:51 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 9.979 | ppl 1008.9 | wps 163290 | wpb 2040.3 | bsz 4 | num_updates 511 | best_loss 9.979
2022-03-23 06:43:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 511 updates
2022-03-23 06:43:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:43:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:43:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 5 @ 511 updates, score 9.979) (writing took 0.916661913972348 seconds)
2022-03-23 06:43:52 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-23 06:43:52 | INFO | train | epoch 005 | loss 10.215 | ppl 1188.8 | wps 79451.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 511 | lr 6.39622e-05 | gnorm 0.454 | loss_scale 8 | train_wall 77 | gb_free 21.6 | wall 430
2022-03-23 06:43:52 | INFO | fairseq.trainer | begin training epoch 6
2022-03-23 06:43:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:45:04 | INFO | train_inner | epoch 006:     89 / 103 loss=9.99, ppl=1017.04, wps=79398.8, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=600, lr=7.5085e-05, gnorm=0.492, loss_scale=16, train_wall=75, gb_free=21.6, wall=501
2022-03-23 06:45:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:45:16 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 9.706 | ppl 835.31 | wps 166199 | wpb 2040.3 | bsz 4 | num_updates 614 | best_loss 9.706
2022-03-23 06:45:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 614 updates
2022-03-23 06:45:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:45:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 6 @ 614 updates, score 9.706) (writing took 0.8974597221240401 seconds)
2022-03-23 06:45:17 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-23 06:45:17 | INFO | train | epoch 006 | loss 9.962 | ppl 997.39 | wps 79490.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 614 | lr 7.68347e-05 | gnorm 0.501 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 514
2022-03-23 06:45:17 | INFO | fairseq.trainer | begin training epoch 7
2022-03-23 06:45:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:46:26 | INFO | train_inner | epoch 007:     86 / 103 loss=9.749, ppl=860.52, wps=79415.2, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=700, lr=8.75825e-05, gnorm=0.493, loss_scale=16, train_wall=75, gb_free=21.6, wall=583
2022-03-23 06:46:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:46:41 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 9.454 | ppl 701.54 | wps 168072 | wpb 2040.3 | bsz 4 | num_updates 717 | best_loss 9.454
2022-03-23 06:46:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 717 updates
2022-03-23 06:46:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:46:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:46:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 7 @ 717 updates, score 9.454) (writing took 0.9143164632841945 seconds)
2022-03-23 06:46:42 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-23 06:46:42 | INFO | train | epoch 007 | loss 9.714 | ppl 839.96 | wps 79477.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 717 | lr 8.97071e-05 | gnorm 0.493 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 599
2022-03-23 06:46:42 | INFO | fairseq.trainer | begin training epoch 8
2022-03-23 06:46:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:47:48 | INFO | train_inner | epoch 008:     83 / 103 loss=9.516, ppl=732.12, wps=79438.5, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=800, lr=0.00010008, gnorm=0.557, loss_scale=16, train_wall=75, gb_free=21.6, wall=665
2022-03-23 06:48:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:48:05 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 9.205 | ppl 590.22 | wps 167362 | wpb 2040.3 | bsz 4 | num_updates 820 | best_loss 9.205
2022-03-23 06:48:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 820 updates
2022-03-23 06:48:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:48:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:48:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 8 @ 820 updates, score 9.205) (writing took 0.9331601853482425 seconds)
2022-03-23 06:48:06 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-23 06:48:06 | INFO | train | epoch 008 | loss 9.471 | ppl 709.48 | wps 79478.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 820 | lr 0.00010258 | gnorm 0.571 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 683
2022-03-23 06:48:06 | INFO | fairseq.trainer | begin training epoch 9
2022-03-23 06:48:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:49:10 | INFO | train_inner | epoch 009:     80 / 103 loss=9.281, ppl=621.99, wps=79343.4, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=900, lr=0.000112578, gnorm=0.565, loss_scale=16, train_wall=75, gb_free=21.6, wall=748
2022-03-23 06:49:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:49:30 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 8.959 | ppl 497.48 | wps 168824 | wpb 2040.3 | bsz 4 | num_updates 923 | best_loss 8.959
2022-03-23 06:49:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 923 updates
2022-03-23 06:49:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:49:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:49:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 9 @ 923 updates, score 8.959) (writing took 0.9479941362515092 seconds)
2022-03-23 06:49:31 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-23 06:49:31 | INFO | train | epoch 009 | loss 9.227 | ppl 599.38 | wps 79428.5 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 923 | lr 0.000115452 | gnorm 0.586 | loss_scale 16 | train_wall 77 | gb_free 21.6 | wall 768
2022-03-23 06:49:31 | INFO | fairseq.trainer | begin training epoch 10
2022-03-23 06:49:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:50:33 | INFO | train_inner | epoch 010:     77 / 103 loss=9.045, ppl=528.12, wps=79365.9, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=1000, lr=0.000125075, gnorm=0.607, loss_scale=16, train_wall=75, gb_free=21.6, wall=830
2022-03-23 06:50:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:50:55 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 8.756 | ppl 432.37 | wps 167730 | wpb 2040.3 | bsz 4 | num_updates 1026 | best_loss 8.756
2022-03-23 06:50:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1026 updates
2022-03-23 06:50:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:50:55 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 10 @ 1026 updates, score 8.756) (writing took 0.9083133330568671 seconds)
2022-03-23 06:50:56 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-23 06:50:56 | INFO | train | epoch 010 | loss 8.996 | ppl 510.69 | wps 79455.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1026 | lr 0.000128324 | gnorm 0.58 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 853
2022-03-23 06:50:56 | INFO | fairseq.trainer | begin training epoch 11
2022-03-23 06:50:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:51:55 | INFO | train_inner | epoch 011:     74 / 103 loss=8.84, ppl=458.24, wps=79292.3, ups=1.21, wpb=65300.5, bsz=127.6, num_updates=1100, lr=0.000137573, gnorm=0.587, loss_scale=32, train_wall=75, gb_free=21.6, wall=912
2022-03-23 06:52:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:52:19 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 8.581 | ppl 382.85 | wps 168853 | wpb 2040.3 | bsz 4 | num_updates 1129 | best_loss 8.581
2022-03-23 06:52:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1129 updates
2022-03-23 06:52:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:52:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:52:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 11 @ 1129 updates, score 8.581) (writing took 0.9141145879402757 seconds)
2022-03-23 06:52:20 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-23 06:52:20 | INFO | train | epoch 011 | loss 8.793 | ppl 443.59 | wps 79349 | ups 1.21 | wpb 65312.3 | bsz 127.6 | num_updates 1129 | lr 0.000141197 | gnorm 0.607 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 938
2022-03-23 06:52:20 | INFO | fairseq.trainer | begin training epoch 12
2022-03-23 06:52:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:53:17 | INFO | train_inner | epoch 012:     71 / 103 loss=8.664, ppl=405.69, wps=79330.6, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=1200, lr=0.00015007, gnorm=0.609, loss_scale=32, train_wall=75, gb_free=21.6, wall=995
2022-03-23 06:53:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:53:44 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 8.432 | ppl 345.48 | wps 169920 | wpb 2040.3 | bsz 4 | num_updates 1232 | best_loss 8.432
2022-03-23 06:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1232 updates
2022-03-23 06:53:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:53:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:53:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 12 @ 1232 updates, score 8.432) (writing took 1.0287224631756544 seconds)
2022-03-23 06:53:45 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-23 06:53:45 | INFO | train | epoch 012 | loss 8.615 | ppl 392 | wps 79295.5 | ups 1.21 | wpb 65312.3 | bsz 127.6 | num_updates 1232 | lr 0.000154069 | gnorm 0.594 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1022
2022-03-23 06:53:45 | INFO | fairseq.trainer | begin training epoch 13
2022-03-23 06:53:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:54:40 | INFO | train_inner | epoch 013:     68 / 103 loss=8.508, ppl=364.03, wps=79233.2, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=1300, lr=0.000162568, gnorm=0.625, loss_scale=32, train_wall=75, gb_free=21.6, wall=1077
2022-03-23 06:55:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:55:09 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 8.3 | ppl 315.22 | wps 167761 | wpb 2040.3 | bsz 4 | num_updates 1335 | best_loss 8.3
2022-03-23 06:55:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 1335 updates
2022-03-23 06:55:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:55:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:55:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 13 @ 1335 updates, score 8.3) (writing took 0.9219870162196457 seconds)
2022-03-23 06:55:10 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-23 06:55:10 | INFO | train | epoch 013 | loss 8.458 | ppl 351.6 | wps 79411.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1335 | lr 0.000166942 | gnorm 0.642 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1107
2022-03-23 06:55:10 | INFO | fairseq.trainer | begin training epoch 14
2022-03-23 06:55:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:56:02 | INFO | train_inner | epoch 014:     65 / 103 loss=8.363, ppl=329.22, wps=79327.3, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=1400, lr=0.000175065, gnorm=0.636, loss_scale=32, train_wall=75, gb_free=21.6, wall=1159
2022-03-23 06:56:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:56:34 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 8.188 | ppl 291.64 | wps 168074 | wpb 2040.3 | bsz 4 | num_updates 1438 | best_loss 8.188
2022-03-23 06:56:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 1438 updates
2022-03-23 06:56:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:56:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:56:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 14 @ 1438 updates, score 8.188) (writing took 0.8978846156969666 seconds)
2022-03-23 06:56:35 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-23 06:56:35 | INFO | train | epoch 014 | loss 8.312 | ppl 317.83 | wps 79386.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1438 | lr 0.000179814 | gnorm 0.644 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1192
2022-03-23 06:56:35 | INFO | fairseq.trainer | begin training epoch 15
2022-03-23 06:56:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:57:24 | INFO | train_inner | epoch 015:     62 / 103 loss=8.225, ppl=299.2, wps=79328.9, ups=1.21, wpb=65310.7, bsz=127.6, num_updates=1500, lr=0.000187563, gnorm=0.662, loss_scale=32, train_wall=75, gb_free=21.6, wall=1242
2022-03-23 06:57:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:57:58 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 8.073 | ppl 269.2 | wps 168070 | wpb 2040.3 | bsz 4 | num_updates 1541 | best_loss 8.073
2022-03-23 06:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 1541 updates
2022-03-23 06:57:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:57:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:57:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 15 @ 1541 updates, score 8.073) (writing took 0.8908495930954814 seconds)
2022-03-23 06:57:59 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-23 06:57:59 | INFO | train | epoch 015 | loss 8.175 | ppl 288.95 | wps 79427.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1541 | lr 0.000192686 | gnorm 0.649 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 1277
2022-03-23 06:57:59 | INFO | fairseq.trainer | begin training epoch 16
2022-03-23 06:57:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 06:58:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 06:58:47 | INFO | train_inner | epoch 016:     60 / 103 loss=8.101, ppl=274.48, wps=78642, ups=1.2, wpb=65300.5, bsz=127.6, num_updates=1600, lr=0.00020006, gnorm=0.634, loss_scale=32, train_wall=76, gb_free=21.6, wall=1325
2022-03-23 06:59:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 06:59:23 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 7.953 | ppl 247.83 | wps 169156 | wpb 2040.3 | bsz 4 | num_updates 1643 | best_loss 7.953
2022-03-23 06:59:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 1643 updates
2022-03-23 06:59:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:59:24 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 06:59:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 16 @ 1643 updates, score 7.953) (writing took 0.9628609847277403 seconds)
2022-03-23 06:59:24 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-23 06:59:24 | INFO | train | epoch 016 | loss 8.045 | ppl 264.14 | wps 78682.1 | ups 1.2 | wpb 65310.1 | bsz 127.6 | num_updates 1643 | lr 0.000205434 | gnorm 0.647 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1361
2022-03-23 06:59:24 | INFO | fairseq.trainer | begin training epoch 17
2022-03-23 06:59:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:00:10 | INFO | train_inner | epoch 017:     57 / 103 loss=7.966, ppl=250.05, wps=79341.9, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=1700, lr=0.000212558, gnorm=0.639, loss_scale=32, train_wall=75, gb_free=21.6, wall=1407
2022-03-23 07:00:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:00:48 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 7.845 | ppl 229.86 | wps 169167 | wpb 2040.3 | bsz 4 | num_updates 1746 | best_loss 7.845
2022-03-23 07:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 1746 updates
2022-03-23 07:00:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:00:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:00:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 17 @ 1746 updates, score 7.845) (writing took 0.9131275503896177 seconds)
2022-03-23 07:00:49 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-23 07:00:49 | INFO | train | epoch 017 | loss 7.917 | ppl 241.63 | wps 79414.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1746 | lr 0.000218306 | gnorm 0.625 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1446
2022-03-23 07:00:49 | INFO | fairseq.trainer | begin training epoch 18
2022-03-23 07:00:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:01:32 | INFO | train_inner | epoch 018:     54 / 103 loss=7.845, ppl=229.97, wps=79304.3, ups=1.21, wpb=65310.7, bsz=127.6, num_updates=1800, lr=0.000225055, gnorm=0.651, loss_scale=32, train_wall=75, gb_free=21.6, wall=1489
2022-03-23 07:02:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:02:13 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 7.747 | ppl 214.84 | wps 168229 | wpb 2040.3 | bsz 4 | num_updates 1849 | best_loss 7.747
2022-03-23 07:02:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 1849 updates
2022-03-23 07:02:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:02:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 18 @ 1849 updates, score 7.747) (writing took 0.9161823228932917 seconds)
2022-03-23 07:02:13 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-23 07:02:13 | INFO | train | epoch 018 | loss 7.793 | ppl 221.77 | wps 79328.7 | ups 1.21 | wpb 65312.3 | bsz 127.6 | num_updates 1849 | lr 0.000231179 | gnorm 0.668 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1531
2022-03-23 07:02:13 | INFO | fairseq.trainer | begin training epoch 19
2022-03-23 07:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:02:54 | INFO | train_inner | epoch 019:     51 / 103 loss=7.735, ppl=212.98, wps=79297, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=1900, lr=0.000237553, gnorm=0.662, loss_scale=32, train_wall=75, gb_free=21.6, wall=1572
2022-03-23 07:03:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:03:37 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 7.659 | ppl 202.05 | wps 168409 | wpb 2040.3 | bsz 4 | num_updates 1952 | best_loss 7.659
2022-03-23 07:03:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 1952 updates
2022-03-23 07:03:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:03:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:03:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 19 @ 1952 updates, score 7.659) (writing took 0.9036081270314753 seconds)
2022-03-23 07:03:38 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-23 07:03:38 | INFO | train | epoch 019 | loss 7.67 | ppl 203.71 | wps 79401.4 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 1952 | lr 0.000244051 | gnorm 0.66 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1616
2022-03-23 07:03:38 | INFO | fairseq.trainer | begin training epoch 20
2022-03-23 07:03:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:04:17 | INFO | train_inner | epoch 020:     48 / 103 loss=7.608, ppl=195.1, wps=79366.2, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=2000, lr=0.00025005, gnorm=0.644, loss_scale=32, train_wall=75, gb_free=21.6, wall=1654
2022-03-23 07:05:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:05:02 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 7.558 | ppl 188.46 | wps 168597 | wpb 2040.3 | bsz 4 | num_updates 2055 | best_loss 7.558
2022-03-23 07:05:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 2055 updates
2022-03-23 07:05:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:05:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 20 @ 2055 updates, score 7.558) (writing took 0.9623751491308212 seconds)
2022-03-23 07:05:03 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-23 07:05:03 | INFO | train | epoch 020 | loss 7.55 | ppl 187.39 | wps 79459 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2055 | lr 0.000256924 | gnorm 0.641 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1700
2022-03-23 07:05:03 | INFO | fairseq.trainer | begin training epoch 21
2022-03-23 07:05:03 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:05:39 | INFO | train_inner | epoch 021:     45 / 103 loss=7.499, ppl=180.95, wps=79297.8, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=2100, lr=0.000262548, gnorm=0.643, loss_scale=64, train_wall=75, gb_free=21.6, wall=1736
2022-03-23 07:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:06:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:06:27 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 7.476 | ppl 178.01 | wps 169196 | wpb 2040.3 | bsz 4 | num_updates 2157 | best_loss 7.476
2022-03-23 07:06:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 2157 updates
2022-03-23 07:06:27 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:06:28 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:06:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 21 @ 2157 updates, score 7.476) (writing took 0.9154751179739833 seconds)
2022-03-23 07:06:28 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-23 07:06:28 | INFO | train | epoch 021 | loss 7.434 | ppl 172.91 | wps 78591.4 | ups 1.2 | wpb 65310.1 | bsz 127.6 | num_updates 2157 | lr 0.000269671 | gnorm 0.641 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1785
2022-03-23 07:06:28 | INFO | fairseq.trainer | begin training epoch 22
2022-03-23 07:06:28 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:07:02 | INFO | train_inner | epoch 022:     43 / 103 loss=7.38, ppl=166.57, wps=78580.2, ups=1.2, wpb=65310.7, bsz=127.6, num_updates=2200, lr=0.000275045, gnorm=0.649, loss_scale=32, train_wall=76, gb_free=21.6, wall=1819
2022-03-23 07:07:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:07:51 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 7.396 | ppl 168.42 | wps 169112 | wpb 2040.3 | bsz 4 | num_updates 2260 | best_loss 7.396
2022-03-23 07:07:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 2260 updates
2022-03-23 07:07:51 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:07:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 22 @ 2260 updates, score 7.396) (writing took 0.9420901630073786 seconds)
2022-03-23 07:07:52 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-23 07:07:52 | INFO | train | epoch 022 | loss 7.318 | ppl 159.53 | wps 79416.4 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2260 | lr 0.000282544 | gnorm 0.644 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1870
2022-03-23 07:07:52 | INFO | fairseq.trainer | begin training epoch 23
2022-03-23 07:07:52 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:08:24 | INFO | train_inner | epoch 023:     40 / 103 loss=7.271, ppl=154.48, wps=79349.1, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=2300, lr=0.000287543, gnorm=0.642, loss_scale=32, train_wall=75, gb_free=21.6, wall=1902
2022-03-23 07:09:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:09:16 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 7.302 | ppl 157.82 | wps 169172 | wpb 2040.3 | bsz 4 | num_updates 2363 | best_loss 7.302
2022-03-23 07:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 2363 updates
2022-03-23 07:09:16 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:09:17 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:09:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 23 @ 2363 updates, score 7.302) (writing took 0.9036582759581506 seconds)
2022-03-23 07:09:17 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-23 07:09:17 | INFO | train | epoch 023 | loss 7.206 | ppl 147.68 | wps 79449.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2363 | lr 0.000295416 | gnorm 0.633 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 1954
2022-03-23 07:09:17 | INFO | fairseq.trainer | begin training epoch 24
2022-03-23 07:09:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:09:47 | INFO | train_inner | epoch 024:     37 / 103 loss=7.165, ppl=143.52, wps=79385.6, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=2400, lr=0.00030004, gnorm=0.633, loss_scale=32, train_wall=75, gb_free=21.6, wall=1984
2022-03-23 07:10:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:10:41 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 7.236 | ppl 150.74 | wps 167572 | wpb 2040.3 | bsz 4 | num_updates 2466 | best_loss 7.236
2022-03-23 07:10:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 2466 updates
2022-03-23 07:10:41 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:10:42 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:10:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 24 @ 2466 updates, score 7.236) (writing took 0.9644076791591942 seconds)
2022-03-23 07:10:42 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-23 07:10:42 | INFO | train | epoch 024 | loss 7.099 | ppl 137.07 | wps 79408.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2466 | lr 0.000308288 | gnorm 0.638 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2039
2022-03-23 07:10:42 | INFO | fairseq.trainer | begin training epoch 25
2022-03-23 07:10:42 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:11:09 | INFO | train_inner | epoch 025:     34 / 103 loss=7.067, ppl=134.05, wps=79333.6, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=2500, lr=0.000312538, gnorm=0.637, loss_scale=32, train_wall=75, gb_free=21.6, wall=2066
2022-03-23 07:12:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:12:05 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 7.168 | ppl 143.77 | wps 169510 | wpb 2040.3 | bsz 4 | num_updates 2569 | best_loss 7.168
2022-03-23 07:12:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 2569 updates
2022-03-23 07:12:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:12:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:12:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 25 @ 2569 updates, score 7.168) (writing took 0.929738522041589 seconds)
2022-03-23 07:12:06 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-23 07:12:06 | INFO | train | epoch 025 | loss 6.995 | ppl 127.6 | wps 79462.7 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2569 | lr 0.000321161 | gnorm 0.642 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2124
2022-03-23 07:12:06 | INFO | fairseq.trainer | begin training epoch 26
2022-03-23 07:12:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:12:31 | INFO | train_inner | epoch 026:     31 / 103 loss=6.962, ppl=124.7, wps=79433.7, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=2600, lr=0.000325035, gnorm=0.641, loss_scale=32, train_wall=75, gb_free=21.6, wall=2149
2022-03-23 07:13:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:13:30 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 7.097 | ppl 136.95 | wps 168712 | wpb 2040.3 | bsz 4 | num_updates 2672 | best_loss 7.097
2022-03-23 07:13:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 2672 updates
2022-03-23 07:13:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:13:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:13:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 26 @ 2672 updates, score 7.097) (writing took 0.9068449549376965 seconds)
2022-03-23 07:13:31 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-23 07:13:31 | INFO | train | epoch 026 | loss 6.895 | ppl 119.01 | wps 79466 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2672 | lr 0.000334033 | gnorm 0.635 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 2208
2022-03-23 07:13:31 | INFO | fairseq.trainer | begin training epoch 27
2022-03-23 07:13:31 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:13:54 | INFO | train_inner | epoch 027:     28 / 103 loss=6.868, ppl=116.78, wps=79353.7, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=2700, lr=0.000337533, gnorm=0.622, loss_scale=64, train_wall=75, gb_free=21.6, wall=2231
2022-03-23 07:14:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:14:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:14:55 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 7.048 | ppl 132.29 | wps 169275 | wpb 2040.3 | bsz 4 | num_updates 2774 | best_loss 7.048
2022-03-23 07:14:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 2774 updates
2022-03-23 07:14:55 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:14:56 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:14:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 27 @ 2774 updates, score 7.048) (writing took 0.9080758569762111 seconds)
2022-03-23 07:14:56 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-23 07:14:56 | INFO | train | epoch 027 | loss 6.799 | ppl 111.38 | wps 78692.8 | ups 1.2 | wpb 65310.1 | bsz 127.6 | num_updates 2774 | lr 0.000346781 | gnorm 0.608 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2293
2022-03-23 07:14:56 | INFO | fairseq.trainer | begin training epoch 28
2022-03-23 07:14:56 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:15:17 | INFO | train_inner | epoch 028:     26 / 103 loss=6.775, ppl=109.5, wps=78639, ups=1.2, wpb=65310.7, bsz=127.6, num_updates=2800, lr=0.00035003, gnorm=0.619, loss_scale=32, train_wall=76, gb_free=21.6, wall=2314
2022-03-23 07:16:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:16:19 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 6.997 | ppl 127.7 | wps 168125 | wpb 2040.3 | bsz 4 | num_updates 2877 | best_loss 6.997
2022-03-23 07:16:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 2877 updates
2022-03-23 07:16:19 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:16:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 28 @ 2877 updates, score 6.997) (writing took 0.9446985106915236 seconds)
2022-03-23 07:16:20 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-23 07:16:20 | INFO | train | epoch 028 | loss 6.71 | ppl 104.66 | wps 79391.1 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2877 | lr 0.000359653 | gnorm 0.632 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2378
2022-03-23 07:16:20 | INFO | fairseq.trainer | begin training epoch 29
2022-03-23 07:16:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:16:39 | INFO | train_inner | epoch 029:     23 / 103 loss=6.688, ppl=103.11, wps=79315.8, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=2900, lr=0.000362528, gnorm=0.625, loss_scale=32, train_wall=75, gb_free=21.6, wall=2396
2022-03-23 07:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:17:44 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 6.953 | ppl 123.91 | wps 168106 | wpb 2040.3 | bsz 4 | num_updates 2980 | best_loss 6.953
2022-03-23 07:17:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 2980 updates
2022-03-23 07:17:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:17:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 29 @ 2980 updates, score 6.953) (writing took 0.898968196939677 seconds)
2022-03-23 07:17:45 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-23 07:17:45 | INFO | train | epoch 029 | loss 6.623 | ppl 98.57 | wps 79426.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 2980 | lr 0.000372526 | gnorm 0.614 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2462
2022-03-23 07:17:45 | INFO | fairseq.trainer | begin training epoch 30
2022-03-23 07:17:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:18:01 | INFO | train_inner | epoch 030:     20 / 103 loss=6.605, ppl=97.36, wps=79338.7, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=3000, lr=0.000375025, gnorm=0.61, loss_scale=32, train_wall=75, gb_free=21.6, wall=2479
2022-03-23 07:19:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:19:09 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 6.914 | ppl 120.59 | wps 168800 | wpb 2040.3 | bsz 4 | num_updates 3083 | best_loss 6.914
2022-03-23 07:19:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 3083 updates
2022-03-23 07:19:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:19:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:19:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 30 @ 3083 updates, score 6.914) (writing took 0.8999496903270483 seconds)
2022-03-23 07:19:10 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-23 07:19:10 | INFO | train | epoch 030 | loss 6.539 | ppl 93.01 | wps 79372.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3083 | lr 0.000385398 | gnorm 0.604 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2547
2022-03-23 07:19:10 | INFO | fairseq.trainer | begin training epoch 31
2022-03-23 07:19:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:19:24 | INFO | train_inner | epoch 031:     17 / 103 loss=6.521, ppl=91.85, wps=79319.1, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=3100, lr=0.000387523, gnorm=0.61, loss_scale=32, train_wall=75, gb_free=21.6, wall=2561
2022-03-23 07:20:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:20:34 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 6.872 | ppl 117.1 | wps 168507 | wpb 2040.3 | bsz 4 | num_updates 3186 | best_loss 6.872
2022-03-23 07:20:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 3186 updates
2022-03-23 07:20:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:20:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:20:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 31 @ 3186 updates, score 6.872) (writing took 0.9051124481484294 seconds)
2022-03-23 07:20:35 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-23 07:20:35 | INFO | train | epoch 031 | loss 6.46 | ppl 88.03 | wps 79474.3 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3186 | lr 0.00039827 | gnorm 0.599 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2632
2022-03-23 07:20:35 | INFO | fairseq.trainer | begin training epoch 32
2022-03-23 07:20:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:20:46 | INFO | train_inner | epoch 032:     14 / 103 loss=6.453, ppl=87.61, wps=79431.4, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3200, lr=0.00040002, gnorm=0.596, loss_scale=32, train_wall=75, gb_free=21.6, wall=2643
2022-03-23 07:21:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:21:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:21:58 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 6.835 | ppl 114.2 | wps 168982 | wpb 2040.3 | bsz 4 | num_updates 3288 | best_loss 6.835
2022-03-23 07:21:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 3288 updates
2022-03-23 07:21:58 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:21:59 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 32 @ 3288 updates, score 6.835) (writing took 0.9659651550464332 seconds)
2022-03-23 07:21:59 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-23 07:21:59 | INFO | train | epoch 032 | loss 6.387 | ppl 83.67 | wps 78619.9 | ups 1.2 | wpb 65310.1 | bsz 127.6 | num_updates 3288 | lr 0.000411018 | gnorm 0.587 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2717
2022-03-23 07:21:59 | INFO | fairseq.trainer | begin training epoch 33
2022-03-23 07:21:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:22:09 | INFO | train_inner | epoch 033:     12 / 103 loss=6.379, ppl=83.23, wps=78557.2, ups=1.2, wpb=65305.6, bsz=127.6, num_updates=3300, lr=0.000412518, gnorm=0.585, loss_scale=32, train_wall=76, gb_free=21.6, wall=2726
2022-03-23 07:23:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:23:23 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 6.801 | ppl 111.54 | wps 169131 | wpb 2040.3 | bsz 4 | num_updates 3391 | best_loss 6.801
2022-03-23 07:23:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 3391 updates
2022-03-23 07:23:23 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:23:26 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:23:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 33 @ 3391 updates, score 6.801) (writing took 2.696743723936379 seconds)
2022-03-23 07:23:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-23 07:23:26 | INFO | train | epoch 033 | loss 6.316 | ppl 79.68 | wps 77807.6 | ups 1.19 | wpb 65312.3 | bsz 127.6 | num_updates 3391 | lr 0.00042389 | gnorm 0.589 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2803
2022-03-23 07:23:26 | INFO | fairseq.trainer | begin training epoch 34
2022-03-23 07:23:26 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:23:33 | INFO | train_inner | epoch 034:      9 / 103 loss=6.309, ppl=79.29, wps=77686.7, ups=1.19, wpb=65305.6, bsz=127.6, num_updates=3400, lr=0.000425015, gnorm=0.587, loss_scale=32, train_wall=75, gb_free=21.6, wall=2810
2022-03-23 07:24:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:24:49 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 6.763 | ppl 108.6 | wps 168005 | wpb 2040.3 | bsz 4 | num_updates 3494 | best_loss 6.763
2022-03-23 07:24:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 3494 updates
2022-03-23 07:24:49 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:24:50 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:24:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 34 @ 3494 updates, score 6.763) (writing took 0.9174074348993599 seconds)
2022-03-23 07:24:50 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-23 07:24:50 | INFO | train | epoch 034 | loss 6.247 | ppl 75.93 | wps 79447.2 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3494 | lr 0.000436763 | gnorm 0.576 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2888
2022-03-23 07:24:50 | INFO | fairseq.trainer | begin training epoch 35
2022-03-23 07:24:50 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:24:55 | INFO | train_inner | epoch 035:      6 / 103 loss=6.245, ppl=75.84, wps=79366.9, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=3500, lr=0.000437513, gnorm=0.578, loss_scale=32, train_wall=75, gb_free=21.6, wall=2893
2022-03-23 07:26:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:26:14 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 6.751 | ppl 107.7 | wps 168496 | wpb 2040.3 | bsz 4 | num_updates 3597 | best_loss 6.751
2022-03-23 07:26:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 3597 updates
2022-03-23 07:26:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:26:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:26:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 35 @ 3597 updates, score 6.751) (writing took 0.9090540977194905 seconds)
2022-03-23 07:26:15 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-23 07:26:15 | INFO | train | epoch 035 | loss 6.182 | ppl 72.63 | wps 79392.5 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3597 | lr 0.000449635 | gnorm 0.581 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 2972
2022-03-23 07:26:15 | INFO | fairseq.trainer | begin training epoch 36
2022-03-23 07:26:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:26:18 | INFO | train_inner | epoch 036:      3 / 103 loss=6.183, ppl=72.65, wps=79332.2, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=3600, lr=0.00045001, gnorm=0.581, loss_scale=32, train_wall=75, gb_free=21.6, wall=2975
2022-03-23 07:27:37 | INFO | train_inner | epoch 036:    103 / 103 loss=6.119, ppl=69.52, wps=81841.6, ups=1.25, wpb=65305.6, bsz=127.6, num_updates=3700, lr=0.000462508, gnorm=0.566, loss_scale=32, train_wall=75, gb_free=21.6, wall=3055
2022-03-23 07:27:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:27:39 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 6.707 | ppl 104.5 | wps 167315 | wpb 2040.3 | bsz 4 | num_updates 3700 | best_loss 6.707
2022-03-23 07:27:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 3700 updates
2022-03-23 07:27:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:27:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:27:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 36 @ 3700 updates, score 6.707) (writing took 0.9381004376336932 seconds)
2022-03-23 07:27:40 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-23 07:27:40 | INFO | train | epoch 036 | loss 6.12 | ppl 69.53 | wps 79454.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3700 | lr 0.000462508 | gnorm 0.568 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3057
2022-03-23 07:27:40 | INFO | fairseq.trainer | begin training epoch 37
2022-03-23 07:27:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:29:00 | INFO | train_inner | epoch 037:    100 / 103 loss=6.059, ppl=66.68, wps=79388.7, ups=1.21, wpb=65530.9, bsz=128, num_updates=3800, lr=0.000475005, gnorm=0.572, loss_scale=64, train_wall=75, gb_free=21.6, wall=3137
2022-03-23 07:29:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:29:03 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 6.693 | ppl 103.47 | wps 169137 | wpb 2040.3 | bsz 4 | num_updates 3803 | best_loss 6.693
2022-03-23 07:29:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 3803 updates
2022-03-23 07:29:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:29:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 37 @ 3803 updates, score 6.693) (writing took 0.932273565325886 seconds)
2022-03-23 07:29:04 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2022-03-23 07:29:04 | INFO | train | epoch 037 | loss 6.06 | ppl 66.74 | wps 79455.7 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 3803 | lr 0.00047538 | gnorm 0.572 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 3142
2022-03-23 07:29:04 | INFO | fairseq.trainer | begin training epoch 38
2022-03-23 07:29:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:30:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:30:23 | INFO | train_inner | epoch 038:     98 / 103 loss=6.004, ppl=64.16, wps=78606.9, ups=1.2, wpb=65305.6, bsz=127.6, num_updates=3900, lr=0.000487503, gnorm=0.562, loss_scale=32, train_wall=76, gb_free=21.6, wall=3220
2022-03-23 07:30:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:30:28 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 6.675 | ppl 102.19 | wps 167943 | wpb 2040.3 | bsz 4 | num_updates 3905 | best_loss 6.675
2022-03-23 07:30:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 3905 updates
2022-03-23 07:30:28 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:30:29 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:30:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 38 @ 3905 updates, score 6.675) (writing took 0.9263180210255086 seconds)
2022-03-23 07:30:29 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2022-03-23 07:30:29 | INFO | train | epoch 038 | loss 6.001 | ppl 64.04 | wps 78656.8 | ups 1.2 | wpb 65310.1 | bsz 127.6 | num_updates 3905 | lr 0.000488127 | gnorm 0.561 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3226
2022-03-23 07:30:29 | INFO | fairseq.trainer | begin training epoch 39
2022-03-23 07:30:29 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:31:45 | INFO | train_inner | epoch 039:     95 / 103 loss=5.95, ppl=61.83, wps=79350.5, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4000, lr=0.0005, gnorm=0.569, loss_scale=32, train_wall=75, gb_free=21.6, wall=3303
2022-03-23 07:31:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:31:53 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 6.648 | ppl 100.31 | wps 168705 | wpb 2040.3 | bsz 4 | num_updates 4008 | best_loss 6.648
2022-03-23 07:31:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 4008 updates
2022-03-23 07:31:53 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:31:54 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:31:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 39 @ 4008 updates, score 6.648) (writing took 0.9206543047912419 seconds)
2022-03-23 07:31:54 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2022-03-23 07:31:54 | INFO | train | epoch 039 | loss 5.949 | ppl 61.8 | wps 79394.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4008 | lr 0.000499501 | gnorm 0.569 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3311
2022-03-23 07:31:54 | INFO | fairseq.trainer | begin training epoch 40
2022-03-23 07:31:54 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:33:08 | INFO | train_inner | epoch 040:     92 / 103 loss=5.896, ppl=59.54, wps=79326.3, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=4100, lr=0.000493865, gnorm=0.55, loss_scale=32, train_wall=75, gb_free=21.6, wall=3385
2022-03-23 07:33:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:33:18 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 6.629 | ppl 98.97 | wps 168717 | wpb 2040.3 | bsz 4 | num_updates 4111 | best_loss 6.629
2022-03-23 07:33:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 4111 updates
2022-03-23 07:33:18 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:33:19 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:33:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 40 @ 4111 updates, score 6.629) (writing took 0.9329292690381408 seconds)
2022-03-23 07:33:19 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2022-03-23 07:33:19 | INFO | train | epoch 040 | loss 5.893 | ppl 59.44 | wps 79420.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4111 | lr 0.000493204 | gnorm 0.55 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3396
2022-03-23 07:33:19 | INFO | fairseq.trainer | begin training epoch 41
2022-03-23 07:33:19 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:34:30 | INFO | train_inner | epoch 041:     89 / 103 loss=5.841, ppl=57.32, wps=79337, ups=1.21, wpb=65305.6, bsz=127.6, num_updates=4200, lr=0.00048795, gnorm=0.545, loss_scale=32, train_wall=75, gb_free=21.6, wall=3467
2022-03-23 07:34:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:34:42 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 6.607 | ppl 97.45 | wps 168551 | wpb 2040.3 | bsz 4 | num_updates 4214 | best_loss 6.607
2022-03-23 07:34:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 4214 updates
2022-03-23 07:34:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:34:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:34:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 41 @ 4214 updates, score 6.607) (writing took 0.9224034501239657 seconds)
2022-03-23 07:34:43 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2022-03-23 07:34:43 | INFO | train | epoch 041 | loss 5.836 | ppl 57.13 | wps 79435.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4214 | lr 0.000487139 | gnorm 0.547 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3481
2022-03-23 07:34:43 | INFO | fairseq.trainer | begin training epoch 42
2022-03-23 07:34:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:35:52 | INFO | train_inner | epoch 042:     86 / 103 loss=5.79, ppl=55.33, wps=79448.6, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4300, lr=0.000482243, gnorm=0.553, loss_scale=32, train_wall=75, gb_free=21.6, wall=3549
2022-03-23 07:36:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:36:07 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 6.586 | ppl 96.09 | wps 168204 | wpb 2040.3 | bsz 4 | num_updates 4317 | best_loss 6.586
2022-03-23 07:36:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 4317 updates
2022-03-23 07:36:07 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:36:08 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 42 @ 4317 updates, score 6.586) (writing took 0.9007988888770342 seconds)
2022-03-23 07:36:08 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2022-03-23 07:36:08 | INFO | train | epoch 042 | loss 5.785 | ppl 55.14 | wps 79497.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4317 | lr 0.000481292 | gnorm 0.551 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3565
2022-03-23 07:36:08 | INFO | fairseq.trainer | begin training epoch 43
2022-03-23 07:36:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:37:14 | INFO | train_inner | epoch 043:     83 / 103 loss=5.74, ppl=53.46, wps=79380.8, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=4400, lr=0.000476731, gnorm=0.542, loss_scale=64, train_wall=75, gb_free=21.6, wall=3632
2022-03-23 07:37:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:37:32 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 6.565 | ppl 94.7 | wps 168336 | wpb 2040.3 | bsz 4 | num_updates 4420 | best_loss 6.565
2022-03-23 07:37:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 4420 updates
2022-03-23 07:37:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:37:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:37:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 43 @ 4420 updates, score 6.565) (writing took 0.9001856441609561 seconds)
2022-03-23 07:37:33 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2022-03-23 07:37:33 | INFO | train | epoch 043 | loss 5.734 | ppl 53.22 | wps 79451.7 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4420 | lr 0.000475651 | gnorm 0.544 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 3650
2022-03-23 07:37:33 | INFO | fairseq.trainer | begin training epoch 44
2022-03-23 07:37:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:38:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:38:37 | INFO | train_inner | epoch 044:     81 / 103 loss=5.694, ppl=51.75, wps=78648, ups=1.2, wpb=65300.5, bsz=127.6, num_updates=4500, lr=0.000471405, gnorm=0.539, loss_scale=32, train_wall=76, gb_free=21.6, wall=3715
2022-03-23 07:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:38:56 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 6.561 | ppl 94.42 | wps 167816 | wpb 2040.3 | bsz 4 | num_updates 4522 | best_loss 6.561
2022-03-23 07:38:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 4522 updates
2022-03-23 07:38:56 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:38:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 44 @ 4522 updates, score 6.561) (writing took 0.9707218906842172 seconds)
2022-03-23 07:38:57 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2022-03-23 07:38:57 | INFO | train | epoch 044 | loss 5.685 | ppl 51.46 | wps 78629.8 | ups 1.2 | wpb 65310.1 | bsz 127.6 | num_updates 4522 | lr 0.000470256 | gnorm 0.539 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3735
2022-03-23 07:38:57 | INFO | fairseq.trainer | begin training epoch 45
2022-03-23 07:38:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:40:00 | INFO | train_inner | epoch 045:     78 / 103 loss=5.654, ppl=50.34, wps=79418, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4600, lr=0.000466252, gnorm=0.533, loss_scale=32, train_wall=75, gb_free=21.6, wall=3797
2022-03-23 07:40:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:40:21 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 6.549 | ppl 93.62 | wps 168235 | wpb 2040.3 | bsz 4 | num_updates 4625 | best_loss 6.549
2022-03-23 07:40:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 4625 updates
2022-03-23 07:40:21 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:40:22 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:40:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 45 @ 4625 updates, score 6.549) (writing took 0.8956178110092878 seconds)
2022-03-23 07:40:22 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2022-03-23 07:40:22 | INFO | train | epoch 045 | loss 5.64 | ppl 49.86 | wps 79588.4 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4625 | lr 0.000464991 | gnorm 0.528 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3819
2022-03-23 07:40:22 | INFO | fairseq.trainer | begin training epoch 46
2022-03-23 07:40:22 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:41:22 | INFO | train_inner | epoch 046:     75 / 103 loss=5.601, ppl=48.54, wps=79485.4, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4700, lr=0.000461266, gnorm=0.53, loss_scale=32, train_wall=75, gb_free=21.6, wall=3879
2022-03-23 07:41:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:41:45 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 6.534 | ppl 92.64 | wps 169403 | wpb 2040.3 | bsz 4 | num_updates 4728 | best_loss 6.534
2022-03-23 07:41:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 4728 updates
2022-03-23 07:41:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:41:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 46 @ 4728 updates, score 6.534) (writing took 0.9243253450840712 seconds)
2022-03-23 07:41:46 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2022-03-23 07:41:46 | INFO | train | epoch 046 | loss 5.599 | ppl 48.46 | wps 79537.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4728 | lr 0.000459898 | gnorm 0.533 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3904
2022-03-23 07:41:46 | INFO | fairseq.trainer | begin training epoch 47
2022-03-23 07:41:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:42:44 | INFO | train_inner | epoch 047:     72 / 103 loss=5.573, ppl=47.61, wps=79468.6, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=4800, lr=0.000456435, gnorm=0.534, loss_scale=32, train_wall=75, gb_free=21.6, wall=3961
2022-03-23 07:43:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:43:10 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 6.535 | ppl 92.71 | wps 167890 | wpb 2040.3 | bsz 4 | num_updates 4831 | best_loss 6.534
2022-03-23 07:43:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 4831 updates
2022-03-23 07:43:10 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2022-03-23 07:43:10 | INFO | train | epoch 047 | loss 5.557 | ppl 47.08 | wps 80375 | ups 1.23 | wpb 65312.3 | bsz 127.6 | num_updates 4831 | lr 0.000454969 | gnorm 0.534 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 3987
2022-03-23 07:43:10 | INFO | fairseq.trainer | begin training epoch 48
2022-03-23 07:43:10 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:44:05 | INFO | train_inner | epoch 048:     69 / 103 loss=5.53, ppl=46.2, wps=80263.5, ups=1.23, wpb=65305.6, bsz=127.6, num_updates=4900, lr=0.000451754, gnorm=0.529, loss_scale=32, train_wall=75, gb_free=21.6, wall=4043
2022-03-23 07:44:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:44:34 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 6.518 | ppl 91.67 | wps 168409 | wpb 2040.3 | bsz 4 | num_updates 4934 | best_loss 6.518
2022-03-23 07:44:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 4934 updates
2022-03-23 07:44:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:44:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:44:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 48 @ 4934 updates, score 6.518) (writing took 0.9594581266865134 seconds)
2022-03-23 07:44:35 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2022-03-23 07:44:35 | INFO | train | epoch 048 | loss 5.517 | ppl 45.79 | wps 79417.5 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 4934 | lr 0.000450195 | gnorm 0.525 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4072
2022-03-23 07:44:35 | INFO | fairseq.trainer | begin training epoch 49
2022-03-23 07:44:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:45:28 | INFO | train_inner | epoch 049:     66 / 103 loss=5.489, ppl=44.91, wps=79297.3, ups=1.21, wpb=65310.7, bsz=127.6, num_updates=5000, lr=0.000447214, gnorm=0.525, loss_scale=32, train_wall=75, gb_free=21.6, wall=4125
2022-03-23 07:45:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:45:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:45:59 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 6.523 | ppl 91.96 | wps 167126 | wpb 2040.3 | bsz 4 | num_updates 5036 | best_loss 6.518
2022-03-23 07:45:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 5036 updates
2022-03-23 07:45:59 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2022-03-23 07:45:59 | INFO | train | epoch 049 | loss 5.479 | ppl 44.61 | wps 79457.9 | ups 1.22 | wpb 65310.1 | bsz 127.6 | num_updates 5036 | lr 0.000445612 | gnorm 0.525 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4156
2022-03-23 07:45:59 | INFO | fairseq.trainer | begin training epoch 50
2022-03-23 07:45:59 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:46:50 | INFO | train_inner | epoch 050:     64 / 103 loss=5.452, ppl=43.79, wps=79504.4, ups=1.22, wpb=65300.5, bsz=127.6, num_updates=5100, lr=0.000442807, gnorm=0.527, loss_scale=32, train_wall=76, gb_free=21.6, wall=4207
2022-03-23 07:47:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:47:22 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 6.514 | ppl 91.39 | wps 168851 | wpb 2040.3 | bsz 4 | num_updates 5139 | best_loss 6.514
2022-03-23 07:47:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 5139 updates
2022-03-23 07:47:22 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:47:23 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:47:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 50 @ 5139 updates, score 6.514) (writing took 0.9125834689475596 seconds)
2022-03-23 07:47:23 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2022-03-23 07:47:23 | INFO | train | epoch 050 | loss 5.443 | ppl 43.51 | wps 79522.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5139 | lr 0.000441124 | gnorm 0.526 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4241
2022-03-23 07:47:23 | INFO | fairseq.trainer | begin training epoch 51
2022-03-23 07:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:48:12 | INFO | train_inner | epoch 051:     61 / 103 loss=5.424, ppl=42.94, wps=79408.4, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=5200, lr=0.000438529, gnorm=0.525, loss_scale=32, train_wall=75, gb_free=21.6, wall=4289
2022-03-23 07:48:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:48:47 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 6.51 | ppl 91.14 | wps 167231 | wpb 2040.3 | bsz 4 | num_updates 5242 | best_loss 6.51
2022-03-23 07:48:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 5242 updates
2022-03-23 07:48:47 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:48:48 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:48:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 51 @ 5242 updates, score 6.51) (writing took 0.9203550573438406 seconds)
2022-03-23 07:48:48 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2022-03-23 07:48:48 | INFO | train | epoch 051 | loss 5.41 | ppl 42.5 | wps 79444.6 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5242 | lr 0.000436769 | gnorm 0.527 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4325
2022-03-23 07:48:48 | INFO | fairseq.trainer | begin training epoch 52
2022-03-23 07:48:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:49:34 | INFO | train_inner | epoch 052:     58 / 103 loss=5.386, ppl=41.81, wps=79428.3, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=5300, lr=0.000434372, gnorm=0.527, loss_scale=32, train_wall=75, gb_free=21.6, wall=4372
2022-03-23 07:50:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:50:12 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 6.501 | ppl 90.58 | wps 168993 | wpb 2040.3 | bsz 4 | num_updates 5345 | best_loss 6.501
2022-03-23 07:50:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 5345 updates
2022-03-23 07:50:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:50:12 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:50:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 52 @ 5345 updates, score 6.501) (writing took 0.9292343896813691 seconds)
2022-03-23 07:50:12 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2022-03-23 07:50:12 | INFO | train | epoch 052 | loss 5.376 | ppl 41.52 | wps 79544.4 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5345 | lr 0.00043254 | gnorm 0.528 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4410
2022-03-23 07:50:12 | INFO | fairseq.trainer | begin training epoch 53
2022-03-23 07:50:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:50:57 | INFO | train_inner | epoch 053:     55 / 103 loss=5.363, ppl=41.16, wps=79467.7, ups=1.22, wpb=65310.7, bsz=127.6, num_updates=5400, lr=0.000430331, gnorm=0.527, loss_scale=32, train_wall=75, gb_free=21.6, wall=4454
2022-03-23 07:51:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:51:36 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 6.502 | ppl 90.62 | wps 168045 | wpb 2040.3 | bsz 4 | num_updates 5448 | best_loss 6.501
2022-03-23 07:51:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 5448 updates
2022-03-23 07:51:36 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2022-03-23 07:51:36 | INFO | train | epoch 053 | loss 5.343 | ppl 40.58 | wps 80382.1 | ups 1.23 | wpb 65312.3 | bsz 127.6 | num_updates 5448 | lr 0.000428432 | gnorm 0.526 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4493
2022-03-23 07:51:36 | INFO | fairseq.trainer | begin training epoch 54
2022-03-23 07:51:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:52:18 | INFO | train_inner | epoch 054:     52 / 103 loss=5.32, ppl=39.94, wps=80296, ups=1.23, wpb=65300.5, bsz=127.6, num_updates=5500, lr=0.000426401, gnorm=0.528, loss_scale=32, train_wall=75, gb_free=21.6, wall=4535
2022-03-23 07:52:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:53:00 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 6.495 | ppl 90.19 | wps 168597 | wpb 2040.3 | bsz 4 | num_updates 5551 | best_loss 6.495
2022-03-23 07:53:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 5551 updates
2022-03-23 07:53:00 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:53:01 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:53:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 54 @ 5551 updates, score 6.495) (writing took 0.920856932643801 seconds)
2022-03-23 07:53:01 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2022-03-23 07:53:01 | INFO | train | epoch 054 | loss 5.312 | ppl 39.74 | wps 79483.4 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5551 | lr 0.000424438 | gnorm 0.528 | loss_scale 64 | train_wall 77 | gb_free 21.6 | wall 4578
2022-03-23 07:53:01 | INFO | fairseq.trainer | begin training epoch 55
2022-03-23 07:53:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:53:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 07:53:41 | INFO | train_inner | epoch 055:     50 / 103 loss=5.302, ppl=39.44, wps=78648.7, ups=1.2, wpb=65305.6, bsz=127.6, num_updates=5600, lr=0.000422577, gnorm=0.529, loss_scale=32, train_wall=76, gb_free=21.6, wall=4618
2022-03-23 07:54:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:54:25 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 6.499 | ppl 90.44 | wps 167622 | wpb 2040.3 | bsz 4 | num_updates 5653 | best_loss 6.495
2022-03-23 07:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 5653 updates
2022-03-23 07:54:25 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2022-03-23 07:54:25 | INFO | train | epoch 055 | loss 5.283 | ppl 38.94 | wps 79537 | ups 1.22 | wpb 65310.1 | bsz 127.6 | num_updates 5653 | lr 0.000420592 | gnorm 0.533 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4662
2022-03-23 07:54:25 | INFO | fairseq.trainer | begin training epoch 56
2022-03-23 07:54:25 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:55:02 | INFO | train_inner | epoch 056:     47 / 103 loss=5.269, ppl=38.57, wps=80286, ups=1.23, wpb=65310.7, bsz=127.6, num_updates=5700, lr=0.000418854, gnorm=0.535, loss_scale=32, train_wall=75, gb_free=21.6, wall=4700
2022-03-23 07:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:55:48 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 6.493 | ppl 90.09 | wps 169006 | wpb 2040.3 | bsz 4 | num_updates 5756 | best_loss 6.493
2022-03-23 07:55:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 5756 updates
2022-03-23 07:55:48 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:55:49 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:55:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 56 @ 5756 updates, score 6.493) (writing took 0.9357878109440207 seconds)
2022-03-23 07:55:49 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2022-03-23 07:55:49 | INFO | train | epoch 056 | loss 5.254 | ppl 38.16 | wps 79498.9 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5756 | lr 0.000416811 | gnorm 0.537 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4746
2022-03-23 07:55:49 | INFO | fairseq.trainer | begin training epoch 57
2022-03-23 07:55:49 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:56:24 | INFO | train_inner | epoch 057:     44 / 103 loss=5.239, ppl=37.77, wps=79438.4, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=5800, lr=0.000415227, gnorm=0.531, loss_scale=32, train_wall=75, gb_free=21.6, wall=4782
2022-03-23 07:57:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:57:13 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 6.483 | ppl 89.47 | wps 168169 | wpb 2040.3 | bsz 4 | num_updates 5859 | best_loss 6.483
2022-03-23 07:57:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 5859 updates
2022-03-23 07:57:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:57:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt
2022-03-23 07:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/wikitext-103-cleaned-bpe-size0.0625_cross_entropy_dropout_0.4_#3/checkpoint_best.pt (epoch 57 @ 5859 updates, score 6.483) (writing took 0.911463089287281 seconds)
2022-03-23 07:57:14 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2022-03-23 07:57:14 | INFO | train | epoch 057 | loss 5.225 | ppl 37.39 | wps 79515.8 | ups 1.22 | wpb 65312.3 | bsz 127.6 | num_updates 5859 | lr 0.000413131 | gnorm 0.53 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4831
2022-03-23 07:57:14 | INFO | fairseq.trainer | begin training epoch 58
2022-03-23 07:57:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:57:47 | INFO | train_inner | epoch 058:     41 / 103 loss=5.216, ppl=37.18, wps=79447.9, ups=1.22, wpb=65305.6, bsz=127.6, num_updates=5900, lr=0.000411693, gnorm=0.535, loss_scale=32, train_wall=75, gb_free=21.6, wall=4864
2022-03-23 07:58:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 07:58:37 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 6.498 | ppl 90.39 | wps 172011 | wpb 2040.3 | bsz 4 | num_updates 5962 | best_loss 6.483
2022-03-23 07:58:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 5962 updates
2022-03-23 07:58:37 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2022-03-23 07:58:37 | INFO | train | epoch 058 | loss 5.2 | ppl 36.75 | wps 80511.4 | ups 1.23 | wpb 65312.3 | bsz 127.6 | num_updates 5962 | lr 0.000409547 | gnorm 0.532 | loss_scale 32 | train_wall 77 | gb_free 21.6 | wall 4915
2022-03-23 07:58:37 | INFO | fairseq.trainer | begin training epoch 59
2022-03-23 07:58:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 07:59:07 | INFO | train_inner | epoch 059:     38 / 103 loss=5.194, ppl=36.6, wps=80858.1, ups=1.24, wpb=65305.6, bsz=127.6, num_updates=6000, lr=0.000408248, gnorm=0.538, loss_scale=32, train_wall=74, gb_free=21.6, wall=4945
2022-03-23 07:59:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:00:00 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 6.498 | ppl 90.41 | wps 171929 | wpb 2040.3 | bsz 4 | num_updates 6065 | best_loss 6.483
2022-03-23 08:00:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 6065 updates
2022-03-23 08:00:00 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2022-03-23 08:00:00 | INFO | train | epoch 059 | loss 5.174 | ppl 36.1 | wps 81416.2 | ups 1.25 | wpb 65312.3 | bsz 127.6 | num_updates 6065 | lr 0.000406055 | gnorm 0.54 | loss_scale 32 | train_wall 76 | gb_free 21.6 | wall 4997
2022-03-23 08:00:00 | INFO | fairseq.trainer | begin training epoch 60
2022-03-23 08:00:00 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-23 08:00:28 | INFO | train_inner | epoch 060:     35 / 103 loss=5.161, ppl=35.77, wps=81285.2, ups=1.24, wpb=65305.6, bsz=127.6, num_updates=6100, lr=0.000404888, gnorm=0.532, loss_scale=64, train_wall=74, gb_free=21.6, wall=5025
2022-03-23 08:00:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-23 08:01:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-23 08:01:23 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 6.5 | ppl 90.53 | wps 171502 | wpb 2040.3 | bsz 4 | num_updates 6167 | best_loss 6.483
2022-03-23 08:01:23 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-23 08:01:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 6167 updates
2022-03-23 08:01:23 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2022-03-23 08:01:23 | INFO | train | epoch 060 | loss 5.146 | ppl 35.41 | wps 80531.1 | ups 1.23 | wpb 65310.1 | bsz 127.6 | num_updates 6167 | lr 0.000402683 | gnorm 0.535 | loss_scale 32 | train_wall 76 | gb_free 21.6 | wall 5080
2022-03-23 08:01:23 | INFO | fairseq_cli.train | done training in 5079.8 seconds
