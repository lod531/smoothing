Sender: LSF System <lsfadmin@eu-g3-061>
Subject: Job 208118116: <iwslt14_de_en_dropout_0.1> in cluster <euler> Done

Job <iwslt14_de_en_dropout_0.1> was submitted from host <eu-login-20> by user <andriusb> in cluster <euler> at Mon Mar 14 07:19:58 2022
Job was executed on host(s) <eu-g3-061>, in queue <gpuhe.4h>, as user <andriusb> in cluster <euler> at Mon Mar 14 07:20:06 2022
</cluster/home/andriusb> was used as the home directory.
</cluster/home/andriusb/fq/fairseq> was used as the working directory.
Started at Mon Mar 14 07:20:06 2022
Terminated at Mon Mar 14 08:15:07 2022
Results reported at Mon Mar 14 08:15:07 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin/iwslt14.tokenized.de-en --save-dir /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1 --arch transformer_iwslt_de_en --share-decoder-input-output-embed --optimizer adam --adam-betas "(0.9, 0.98)" --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.1 --weight-decay 0.0001 --criterion cross_entropy --max-tokens 32768 --eval-bleu --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' --eval-bleu-detok moses --eval-bleu-remove-bpe --eval-bleu-print-samples --fp16 --no-epoch-checkpoints --patience 3 --seed 66575611 --best-checkpoint-metric bleu --maximize-best-checkpoint-metric
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   3287.53 sec.
    Max Memory :                                 4402 MB
    Average Memory :                             3456.42 MB
    Total Requested Memory :                     20000.00 MB
    Delta Memory :                               15598.00 MB
    Max Swap :                                   126 MB
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   3316 sec.
    Turnaround time :                            3309 sec.

The output (if any) follows:

2022-03-14 07:20:16 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 66575611, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 32768, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 32768, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 3, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_iwslt_de_en', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_iwslt_de_en', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, cpu=False, cpu_offload=False, criterion='cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14.tokenized.de-en', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=True, eval_bleu_args='{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=32768, max_tokens_valid=32768, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=3, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1', save_interval=1, save_interval_updates=0, scoring='bleu', seed=66575611, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14.tokenized.de-en', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-03-14 07:20:16 | INFO | fairseq.tasks.translation | [de] dictionary: 8848 types
2022-03-14 07:20:16 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2022-03-14 07:20:17 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8848, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2022-03-14 07:20:17 | INFO | fairseq_cli.train | task: TranslationTask
2022-03-14 07:20:17 | INFO | fairseq_cli.train | model: TransformerModel
2022-03-14 07:20:17 | INFO | fairseq_cli.train | criterion: CrossEntropyCriterion
2022-03-14 07:20:17 | INFO | fairseq_cli.train | num. shared model params: 39,469,056 (num. trained: 39,469,056)
2022-03-14 07:20:17 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-03-14 07:20:17 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.de
2022-03-14 07:20:17 | INFO | fairseq.data.data_utils | loaded 7,283 examples from: data-bin/iwslt14.tokenized.de-en/valid.de-en.en
2022-03-14 07:20:17 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples
2022-03-14 07:20:24 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2022-03-14 07:20:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:20:24 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 23.653 GB ; name = Quadro RTX 6000                         
2022-03-14 07:20:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-03-14 07:20:24 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-03-14 07:20:24 | INFO | fairseq_cli.train | max tokens per device = 32768 and max sentences per device = None
2022-03-14 07:20:24 | INFO | fairseq.trainer | Preparing to load checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:20:24 | INFO | fairseq.trainer | No existing checkpoint found /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:20:24 | INFO | fairseq.trainer | loading train data for epoch 1
2022-03-14 07:20:24 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.de
2022-03-14 07:20:24 | INFO | fairseq.data.data_utils | loaded 160,239 examples from: data-bin/iwslt14.tokenized.de-en/train.de-en.en
2022-03-14 07:20:24 | INFO | fairseq.tasks.translation | data-bin/iwslt14.tokenized.de-en train de-en 160239 examples
2022-03-14 07:20:24 | INFO | fairseq.trainer | begin training epoch 1
2022-03-14 07:20:24 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:20:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-03-14 07:20:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-03-14 07:20:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2022-03-14 07:20:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-03-14 07:20:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-03-14 07:20:59 | INFO | train_inner | epoch 001:    105 / 157 loss=11.696, ppl=3318.28, wps=81047, ups=3.22, wpb=25186.5, bsz=962.7, num_updates=100, lr=1.25e-05, gnorm=4.193, loss_scale=4, train_wall=34, gb_free=14.3, wall=36
2022-03-14 07:21:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:21:19 | INFO | fairseq.tasks.translation | example hypothesis: ,,...
2022-03-14 07:21:19 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:21:22 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the.
2022-03-14 07:21:22 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:21:26 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-14 07:21:26 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:21:30 | INFO | fairseq.tasks.translation | example hypothesis: ,,,,,,,,,,,,,,,,,,,.................
2022-03-14 07:21:30 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:21:35 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:21:35 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:21:41 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2022-03-14 07:21:41 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:21:46 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:21:46 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:21:52 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:21:52 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:21:59 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:21:59 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:22:01 | INFO | fairseq.tasks.translation | example hypothesis: and and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:22:01 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:22:01 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.932 | ppl 976.7 | bleu 0.02 | wps 3878.2 | wpb 17862.2 | bsz 728.3 | num_updates 152
2022-03-14 07:22:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 152 updates
2022-03-14 07:22:01 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:22:02 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:22:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 1 @ 152 updates, score 0.02) (writing took 2.0870985940564424 seconds)
2022-03-14 07:22:03 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-03-14 07:22:03 | INFO | train | epoch 001 | loss 11.216 | ppl 2378.3 | wps 40067.8 | ups 1.6 | wpb 25082.4 | bsz 995.7 | num_updates 152 | lr 1.9e-05 | gnorm 3.356 | loss_scale 4 | train_wall 50 | gb_free 22.4 | wall 99
2022-03-14 07:22:04 | INFO | fairseq.trainer | begin training epoch 2
2022-03-14 07:22:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:22:19 | INFO | train_inner | epoch 002:     48 / 157 loss=9.993, ppl=1019.03, wps=31964.2, ups=1.26, wpb=25339.2, bsz=1116.9, num_updates=200, lr=2.5e-05, gnorm=2.216, loss_scale=4, train_wall=30, gb_free=14.6, wall=115
2022-03-14 07:22:50 | INFO | train_inner | epoch 002:    148 / 157 loss=9.222, ppl=597.18, wps=80407.2, ups=3.22, wpb=24962.3, bsz=943, num_updates=300, lr=3.75e-05, gnorm=1.71, loss_scale=4, train_wall=31, gb_free=20.2, wall=146
2022-03-14 07:22:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:22:56 | INFO | fairseq.tasks.translation | example hypothesis: we we we we.
2022-03-14 07:22:56 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:22:59 | INFO | fairseq.tasks.translation | example hypothesis: the the the the the the the the the the.
2022-03-14 07:22:59 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:23:02 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the.
2022-03-14 07:23:02 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:23:06 | INFO | fairseq.tasks.translation | example hypothesis: and it's's,,,,,,,,,,,.
2022-03-14 07:23:06 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:23:09 | INFO | fairseq.tasks.translation | example hypothesis: and it's's,,,,,,,,,,,,,.
2022-03-14 07:23:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:23:13 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the.
2022-03-14 07:23:13 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:23:17 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:17 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:23:22 | INFO | fairseq.tasks.translation | example hypothesis: and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the.
2022-03-14 07:23:22 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:23:28 | INFO | fairseq.tasks.translation | example hypothesis: and,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, "" "" "" "" "" "." "" ""
2022-03-14 07:23:28 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:23:30 | INFO | fairseq.tasks.translation | example hypothesis: and the the,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2022-03-14 07:23:30 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:23:30 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.852 | ppl 462.06 | bleu 0.03 | wps 4792.7 | wpb 17862.2 | bsz 728.3 | num_updates 309 | best_bleu 0.03
2022-03-14 07:23:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 309 updates
2022-03-14 07:23:30 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:23:31 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:23:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 2 @ 309 updates, score 0.03) (writing took 2.244434753898531 seconds)
2022-03-14 07:23:32 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-03-14 07:23:32 | INFO | train | epoch 002 | loss 9.353 | ppl 653.93 | wps 44343.8 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 309 | lr 3.8625e-05 | gnorm 2.032 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 188
2022-03-14 07:23:33 | INFO | fairseq.trainer | begin training epoch 3
2022-03-14 07:23:33 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:24:01 | INFO | train_inner | epoch 003:     91 / 157 loss=8.806, ppl=447.47, wps=34923.3, ups=1.41, wpb=24808.2, bsz=976.5, num_updates=400, lr=5e-05, gnorm=1.892, loss_scale=4, train_wall=30, gb_free=13.8, wall=217
2022-03-14 07:24:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:24:25 | INFO | fairseq.tasks.translation | example hypothesis: we have the the in in the in the in in the.
2022-03-14 07:24:25 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:24:29 | INFO | fairseq.tasks.translation | example hypothesis: this is the the of the of the of the of the.
2022-03-14 07:24:29 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:24:34 | INFO | fairseq.tasks.translation | example hypothesis: this is a of the of the.
2022-03-14 07:24:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:24:38 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, it's a of the a, and it's.
2022-03-14 07:24:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:24:43 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, and it's not not not not not not, and it's's a a of the.
2022-03-14 07:24:43 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:24:48 | INFO | fairseq.tasks.translation | example hypothesis: and and this is the of the of the of the of the of the of the of the of the of the of the of the of the of the.
2022-03-14 07:24:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example hypothesis: and it's, but it's a a to the the a, but it's, but it's a, but it's, but it's a of the are are are are are are are are, and it's a of the the of the.
2022-03-14 07:24:54 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:25:00 | INFO | fairseq.tasks.translation | example hypothesis: and we're the the to to the the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the, and the of the of the of the of the of the of the of the of the, and the of the of the of the, and the of the of the of the of the of the of the of the of the of the of the of the of the
2022-03-14 07:25:00 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:25:08 | INFO | fairseq.tasks.translation | example hypothesis: it's a, "" "" "", "" "" ",", "", ",", ",", "" "", "," "" ",", ",", ",", ",", "", ",", ",", "," "," "" "" "" "" "" "" "" "" ",", "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "," "" "" "" "" "" "" "" "" "", ",", ",", "" "" "" "" "", "," "" "" "" "" "" "" "" "" "
2022-03-14 07:25:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:25:10 | INFO | fairseq.tasks.translation | example hypothesis: and it's a, it's a a, the a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a a, it's a, it's a a, it's a, it's a a a a a a a a a a a a a a a, and the a a, and the a, and the a a, it's a a a, and the a a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a, it's a a a a, it's a, and the, and the a, and the, it's a, it's a, it's a a a a a a a a a a a a a a a a,
2022-03-14 07:25:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:25:10 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 8.343 | ppl 324.75 | bleu 0.27 | wps 3626.4 | wpb 17862.2 | bsz 728.3 | num_updates 466 | best_bleu 0.27
2022-03-14 07:25:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 466 updates
2022-03-14 07:25:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:25:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 3 @ 466 updates, score 0.27) (writing took 2.236884871032089 seconds)
2022-03-14 07:25:12 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-03-14 07:25:12 | INFO | train | epoch 003 | loss 8.66 | ppl 404.53 | wps 39392.3 | ups 1.57 | wpb 25153.6 | bsz 1020.6 | num_updates 466 | lr 5.825e-05 | gnorm 1.976 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 289
2022-03-14 07:25:13 | INFO | fairseq.trainer | begin training epoch 4
2022-03-14 07:25:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:25:24 | INFO | train_inner | epoch 004:     34 / 157 loss=8.403, ppl=338.46, wps=30647.5, ups=1.2, wpb=25464, bsz=1090.9, num_updates=500, lr=6.25e-05, gnorm=2.009, loss_scale=4, train_wall=30, gb_free=13.9, wall=300
2022-03-14 07:25:55 | INFO | train_inner | epoch 004:    134 / 157 loss=8.019, ppl=259.45, wps=80769.9, ups=3.2, wpb=25227.2, bsz=1021.3, num_updates=600, lr=7.5e-05, gnorm=2.178, loss_scale=4, train_wall=31, gb_free=14.6, wall=331
2022-03-14 07:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:26:06 | INFO | fairseq.tasks.translation | example hypothesis: we have to be this.
2022-03-14 07:26:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:26:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the most of the thing.
2022-03-14 07:26:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:26:13 | INFO | fairseq.tasks.translation | example hypothesis: now, you're two two two two.
2022-03-14 07:26:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:26:17 | INFO | fairseq.tasks.translation | example hypothesis: and there's a lot of the way, there's a lot.
2022-03-14 07:26:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:26:21 | INFO | fairseq.tasks.translation | example hypothesis: it's not not that we're going to be a lot of the world.
2022-03-14 07:26:21 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:26:25 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of people, in the world, in the world, in the world, in the world.
2022-03-14 07:26:25 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:26:29 | INFO | fairseq.tasks.translation | example hypothesis: now, it's a lot of the way, but they're not not not not not not not not not not not not not not not a lot of the way.
2022-03-14 07:26:29 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:26:33 | INFO | fairseq.tasks.translation | example hypothesis: so, we're a lot of the world, we have to be a lot of the world, and we have to be a lot of the world, and we have the world, and we have to be the way that we have a lot of the world.
2022-03-14 07:26:33 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:26:38 | INFO | fairseq.tasks.translation | example hypothesis: so, "this is a" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "
2022-03-14 07:26:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:26:40 | INFO | fairseq.tasks.translation | example hypothesis: now, if we're a lot of the world, we're a lot of the world, we're a lot of the world, which is a lot of the world, which is that we have a lot of the world, which is a lot of the world, which is that we have to be be be be a lot of the world, we're a lot of the world, which is a lot of the world, which is a lot of the world, which is that we're a lot of the way that we're a lot of the world, which is a lot of the world, which is that we have to be be be be be be be be be be able to be be be be be be be be be be be be be be be be be be be be be a lot of the way of the world, which is that we have to be be be be be be be be be be be be, which is a way, which is a lot of the world, which is a lot of the way of the way of the way
2022-03-14 07:26:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:26:40 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.635 | ppl 198.72 | bleu 1.92 | wps 4727.9 | wpb 17862.2 | bsz 728.3 | num_updates 623 | best_bleu 1.92
2022-03-14 07:26:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 623 updates
2022-03-14 07:26:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:26:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 4 @ 623 updates, score 1.92) (writing took 2.1321071148850024 seconds)
2022-03-14 07:26:42 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-03-14 07:26:42 | INFO | train | epoch 004 | loss 8.045 | ppl 264.14 | wps 43910.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 623 | lr 7.7875e-05 | gnorm 2.125 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 379
2022-03-14 07:26:43 | INFO | fairseq.trainer | begin training epoch 5
2022-03-14 07:26:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:27:07 | INFO | train_inner | epoch 005:     77 / 157 loss=7.68, ppl=205.13, wps=34040, ups=1.39, wpb=24464.6, bsz=968, num_updates=700, lr=8.75e-05, gnorm=2.332, loss_scale=4, train_wall=30, gb_free=15.5, wall=403
2022-03-14 07:27:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:27:36 | INFO | fairseq.tasks.translation | example hypothesis: we're going to go in the future.
2022-03-14 07:27:36 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:27:40 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most most most most of the most of the time.
2022-03-14 07:27:40 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:27:44 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-14 07:27:44 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:27:47 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a lot of the world, and there's going to be a lot of the world.
2022-03-14 07:27:47 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:27:52 | INFO | fairseq.tasks.translation | example hypothesis: it's what we're going to do that we're going to do that the world.
2022-03-14 07:27:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:27:56 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, in the people in the people, for the people in the people, and the people in the people in the people in the people in the people in the people in the people in the people, and the people in the people.
2022-03-14 07:27:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:28:02 | INFO | fairseq.tasks.translation | example hypothesis: but some of some of some of some of course, but there are a lot of a lot of course, but they're going to have a lot of a lot of the people, but they're going to have a lot of a lot of a lot of the lot of a lot of course, but they're going to have to have a lot of the
2022-03-14 07:28:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:28:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to have a lot of the world of the world, and we're going to have a lot of the world, and we're going to have a lot of the world of the world, and we have a lot of the world of the world, and then we have to have a lot of the world of the world of the world of the world of the world, and we're going to have a lot of the world of the world,
2022-03-14 07:28:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:28:15 | INFO | fairseq.tasks.translation | example hypothesis: and one of one of the world, "the world," the world, "this is one one one one one of the world, and then we have to say," and then we've been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been a good good good good good good good good good good good good good good good good, "" "" "" "" "" "" "" "" "" and then, "that that that," to me, "and then," "" "" "" "" "" "
2022-03-14 07:28:15 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:28:17 | INFO | fairseq.tasks.translation | example hypothesis: and this is a lot of fact that we had a lot of a lot of a lot of the world, which is that we have been been been been been been been been been been been been been a little little little little little little little little little little little little little little bit of the world, and that we have a lot of the world that we have to have to have to have to have a lot of the people to have a lot of the world of the world of the world, and that we have to have to have a lot of the world that we have been been been been been been been been been been been been been been been been been been been been been been been been been a little little little little little little little little little little little little little little little little little little little little little little little little little bit of the world, which is that that that we have to have to have to have to have to have to have to have been been been been been been been been been been been been been been been been been been been been been been
2022-03-14 07:28:17 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:28:17 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 7.093 | ppl 136.57 | bleu 2.59 | wps 3933.8 | wpb 17862.2 | bsz 728.3 | num_updates 780 | best_bleu 2.59
2022-03-14 07:28:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 780 updates
2022-03-14 07:28:17 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:28:18 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:28:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 5 @ 780 updates, score 2.59) (writing took 2.089697697898373 seconds)
2022-03-14 07:28:20 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-03-14 07:28:20 | INFO | train | epoch 005 | loss 7.447 | ppl 174.44 | wps 40664.6 | ups 1.62 | wpb 25153.6 | bsz 1020.6 | num_updates 780 | lr 9.75e-05 | gnorm 2.114 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 476
2022-03-14 07:28:20 | INFO | fairseq.trainer | begin training epoch 6
2022-03-14 07:28:20 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:28:26 | INFO | train_inner | epoch 006:     20 / 157 loss=7.302, ppl=157.85, wps=32068.9, ups=1.26, wpb=25435.1, bsz=1018.2, num_updates=800, lr=0.0001, gnorm=2.139, loss_scale=4, train_wall=30, gb_free=13, wall=483
2022-03-14 07:28:57 | INFO | train_inner | epoch 006:    120 / 157 loss=6.975, ppl=125.78, wps=81052.9, ups=3.2, wpb=25302.4, bsz=1024.5, num_updates=900, lr=0.0001125, gnorm=1.796, loss_scale=4, train_wall=31, gb_free=14.5, wall=514
2022-03-14 07:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:29:13 | INFO | fairseq.tasks.translation | example hypothesis: we've got this, in the future.
2022-03-14 07:29:13 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:29:17 | INFO | fairseq.tasks.translation | example hypothesis: this is the idea of the most most most most of the most most most most most of the most most most most most most.
2022-03-14 07:29:17 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:29:21 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new new
2022-03-14 07:29:21 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:29:26 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's a lot of example, where you're going to see, where it's going to be a lot of the world.
2022-03-14 07:29:26 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:29:31 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we don't know that we're going to do it, what we're going to do it's going to do that's going to do it's going to do that's a few few few few few few few of the
2022-03-14 07:29:31 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:29:37 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, as as as as people, for the people, for the people, for the people, for the people, for the people, for the people, for the people, the people, the people, the people, and the people, the people, the people, the people
2022-03-14 07:29:37 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:29:43 | INFO | fairseq.tasks.translation | example hypothesis: but some of some of some of some of some of some of some of some of the time, if you don't know, if you don't know, but it's not have the same time, if you don't know, if you don't know, it's not have the same time, if you don't know, if you don't go
2022-03-14 07:29:43 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:29:49 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to see the idea of the world that we're going to see that we can see that we can see the world, we can see that we can see the world, we can see that's a lot of a lot of the world, we can see that we can see the world, we can see that we can see that can see the world, and see that can see the world, we can see the world, we can see the
2022-03-14 07:29:49 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:29:56 | INFO | fairseq.tasks.translation | example hypothesis: : one of the time, and it's a lot of the time, and you know, "you know," you know, "you know," you know, "you know," you know, "you know," you know, and then, you know, you know, you know, you know, "you know, you know, you know, you know, you know, you know, you know, you know, you know," you know, you know, "you know, you know," you know, you know, you know, "you know, you know, you know, you know, you know, you know, you know," you know, you know, you know, you know, you know, you know, you know, "this is that is that is that is that is that is that is that is that is that,"
2022-03-14 07:29:56 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:29:59 | INFO | fairseq.tasks.translation | example hypothesis: so, this is a lot of the time, and the time, and we've got to be a lot of the time, if we've got a little little little bit of the time, and we've got to be a little little bit of the time that we've got a little little little bit of the time, if we have a little little little bit of the time that we've got a little little little little little little little little little bit of the time that we've got that we've got to have a little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little bit of the time that we've got that we're going to do that we've got to do that we've got to have to have to get to get to get to get to be a little little little little little little little little little bit,
2022-03-14 07:29:59 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:29:59 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.624 | ppl 98.62 | bleu 3.45 | wps 3566.3 | wpb 17862.2 | bsz 728.3 | num_updates 937 | best_bleu 3.45
2022-03-14 07:29:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 937 updates
2022-03-14 07:29:59 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:30:00 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:30:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 6 @ 937 updates, score 3.45) (writing took 2.185256317956373 seconds)
2022-03-14 07:30:01 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-03-14 07:30:01 | INFO | train | epoch 006 | loss 6.975 | ppl 125.79 | wps 38952.9 | ups 1.55 | wpb 25153.6 | bsz 1020.6 | num_updates 937 | lr 0.000117125 | gnorm 2.03 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 577
2022-03-14 07:30:01 | INFO | fairseq.trainer | begin training epoch 7
2022-03-14 07:30:01 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:30:21 | INFO | train_inner | epoch 007:     63 / 157 loss=6.661, ppl=101.21, wps=30108.5, ups=1.2, wpb=25148.3, bsz=1033.1, num_updates=1000, lr=0.000125, gnorm=1.872, loss_scale=4, train_wall=30, gb_free=15.3, wall=597
2022-03-14 07:30:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:30:54 | INFO | fairseq.tasks.translation | example hypothesis: we've got this.
2022-03-14 07:30:54 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:30:57 | INFO | fairseq.tasks.translation | example hypothesis: this is the fact of the fact.
2022-03-14 07:30:57 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:31:01 | INFO | fairseq.tasks.translation | example hypothesis: new new new new new york are two new new york.
2022-03-14 07:31:01 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:31:05 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's the chinese chinese, where you're going to get up, where you're going to get up up with your body.
2022-03-14 07:31:05 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:31:09 | INFO | fairseq.tasks.translation | example hypothesis: it's not that we're not just just a few few few of his life, and i'm going to understand what's going to do.
2022-03-14 07:31:09 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:31:14 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamamay, the people who are going to make a lot of people.
2022-03-14 07:31:14 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:31:19 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some kinds of the bottom of the same, but if you don't know, if you don't know, if you don't know, if you don't know, it's not have a lot of the energy, if you don't know, it's a lot of the energy, it's going to do it's going to go
2022-03-14 07:31:19 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:31:25 | INFO | fairseq.tasks.translation | example hypothesis: so if we're going to use the information of these things that we can create a lot of the world, we can see with a lot of the world, and we can make a lot of the world, and we can create a lot of the world, and make a lot of the world, and we can create a lot of the world, and we can make the world.
2022-03-14 07:31:25 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:31:32 | INFO | fairseq.tasks.translation | example hypothesis: yeah: one of the one of you know, and it's going to make me, "you know," you know, you know, "you know," you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to know, "and then, it's going to know, you know, you know, you know, it's going to say, you know, you know, you know, you know, you know, you know, it's going to know, you know, you know, if you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-14 07:31:32 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:31:34 | INFO | fairseq.tasks.translation | example hypothesis: and in fact, it's always always always to be a lot of the world, and if we've got a lot of the world, we've been able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to get
2022-03-14 07:31:34 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:31:34 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.211 | ppl 74.07 | bleu 5.82 | wps 4079.8 | wpb 17862.2 | bsz 728.3 | num_updates 1094 | best_bleu 5.82
2022-03-14 07:31:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 1094 updates
2022-03-14 07:31:34 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:31:35 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:31:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 7 @ 1094 updates, score 5.82) (writing took 2.112230374943465 seconds)
2022-03-14 07:31:36 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-03-14 07:31:36 | INFO | train | epoch 007 | loss 6.478 | ppl 89.16 | wps 41431.8 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 1094 | lr 0.00013675 | gnorm 1.77 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 672
2022-03-14 07:31:37 | INFO | fairseq.trainer | begin training epoch 8
2022-03-14 07:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:31:39 | INFO | train_inner | epoch 008:      6 / 157 loss=6.379, ppl=83.25, wps=32210.3, ups=1.29, wpb=25024, bsz=1033.8, num_updates=1100, lr=0.0001375, gnorm=1.811, loss_scale=4, train_wall=30, gb_free=14.8, wall=675
2022-03-14 07:32:10 | INFO | train_inner | epoch 008:    106 / 157 loss=6.02, ppl=64.91, wps=81483.4, ups=3.23, wpb=25229.1, bsz=1097.2, num_updates=1200, lr=0.00015, gnorm=1.9, loss_scale=4, train_wall=30, gb_free=15.1, wall=706
2022-03-14 07:32:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:32:29 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppped in the middle.
2022-03-14 07:32:29 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:32:33 | INFO | fairseq.tasks.translation | example hypothesis: that's the car.
2022-03-14 07:32:33 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:32:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new york.
2022-03-14 07:32:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:32:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, for example, there's the chinese chinese.
2022-03-14 07:32:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:32:44 | INFO | fairseq.tasks.translation | example hypothesis: it's not simple that we're not just just just a few few of his head, and what's going on his head.
2022-03-14 07:32:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:32:48 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamamay people like the most people, the number of the number of animals, and it's a few years.
2022-03-14 07:32:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:32:52 | INFO | fairseq.tasks.translation | example hypothesis: first of some of some of the bbbbbmmmmmme, but if you don't need to use the energy, if you need the energy, you need the energy, the energy, the energy, you need the energy and the energy, the energy, you need the energy, the energy, the energy, the energy
2022-03-14 07:32:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:32:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can use the information from this information, we can see a new structure of the world, and we can create a structure of the structure of the structure of the structure of the structure, and the structure of the structure, and the structure, which is all the structure of the structure of the structure, and the structure, which is all the structure.
2022-03-14 07:32:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:33:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to make me that you're going to be able to say that you know, "you know," you know, if you know, you know, you know, you know, you know, you know, you know, you know, you're going to know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to go to go to go to go to know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-14 07:33:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:33:05 | INFO | fairseq.tasks.translation | example hypothesis: and unfortunately, in fact, it's still still still a few years of the work, and the work that we had to be able to create a new system that we had to be able to create a new system that we were able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a little bit of the world, which is, which is that we had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to create a
2022-03-14 07:33:05 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:33:05 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.734 | ppl 53.24 | bleu 7.76 | wps 4556.5 | wpb 17862.2 | bsz 728.3 | num_updates 1251 | best_bleu 7.76
2022-03-14 07:33:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 1251 updates
2022-03-14 07:33:05 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:33:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 8 @ 1251 updates, score 7.76) (writing took 2.165089503163472 seconds)
2022-03-14 07:33:07 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-03-14 07:33:07 | INFO | train | epoch 008 | loss 6.061 | ppl 66.77 | wps 43357.9 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 1251 | lr 0.000156375 | gnorm 1.895 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 764
2022-03-14 07:33:08 | INFO | fairseq.trainer | begin training epoch 9
2022-03-14 07:33:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:33:23 | INFO | train_inner | epoch 009:     49 / 157 loss=5.898, ppl=59.64, wps=34913.8, ups=1.36, wpb=25665, bsz=991.6, num_updates=1300, lr=0.0001625, gnorm=1.919, loss_scale=4, train_wall=30, gb_free=15.3, wall=779
2022-03-14 07:33:54 | INFO | train_inner | epoch 009:    149 / 157 loss=5.659, ppl=50.52, wps=80339.5, ups=3.24, wpb=24819.9, bsz=982.3, num_updates=1400, lr=0.000175, gnorm=1.867, loss_scale=4, train_wall=31, gb_free=14.8, wall=810
2022-03-14 07:33:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:34:01 | INFO | fairseq.tasks.translation | example hypothesis: we did these pppppat the clinics.
2022-03-14 07:34:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:34:05 | INFO | fairseq.tasks.translation | example hypothesis: so this is the new ha ha, most of most most most most most of most most here.
2022-03-14 07:34:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:34:09 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new york.
2022-03-14 07:34:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:34:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese chinese chinese, where they're going to go up with the legs and pppppdy.
2022-03-14 07:34:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:34:18 | INFO | fairseq.tasks.translation | example hypothesis: it's not clear that we just just just just put a few of his head on his head, and his head are all of his head.
2022-03-14 07:34:18 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:34:22 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamay of people like the responsibility for the number of animals, the number of animals, and this is a number of animals, and this is a number of cocoviiiiiiibia.
2022-03-14 07:34:22 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:34:27 | INFO | fairseq.tasks.translation | example hypothesis: first of some of the bbbe in the bottom of the bottom, but if you don't know, it's not like the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, the energy, and the energy, the energy
2022-03-14 07:34:27 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:34:31 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information of these patterns, we can see with a little bit of a single single single single cell, and we can create a lot of the structure of the structure of the structure, which is all the structure of the structure of the structure of the structure of the structure, which is all the structure of the structure and the structure of the structure of the structure of the structure of the structure that we all the structure that are all the structure
2022-03-14 07:34:31 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:34:37 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons the reasons it was interesting for me, and i'm going to talk to be able to be here, "yes," yes, "oh, if you say, you know, you know, you know, you know, you know, you're going to say, the next time, we're going to say, we're talking about this is a lot of the next time."
2022-03-14 07:34:37 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:34:39 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, it's still still still the invention of the same time, and we had a little bit of our work that we had to create a little bit of the ground that we had had to create a new york system that we had to do it with a whole system that we had to create a new york system that we had to use of the world, or a new york system, which had had had to do it was a new york, or a new york, which is, which is to do it was a new york system that we had to use to use that we had to do it was a new york system that we had to use of the same system that we had to do it was a new york, or a new system, which had had had had had had to use, or a little bit of the same system that we had had to use that we had had had to use of the united states who had had had had had had to use to use that we had had to use to use to use to use of the
2022-03-14 07:34:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:34:39 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.298 | ppl 39.35 | bleu 10.99 | wps 4295.9 | wpb 17862.2 | bsz 728.3 | num_updates 1408 | best_bleu 10.99
2022-03-14 07:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 1408 updates
2022-03-14 07:34:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:34:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 9 @ 1408 updates, score 10.99) (writing took 2.1454619490541518 seconds)
2022-03-14 07:34:41 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-03-14 07:34:41 | INFO | train | epoch 009 | loss 5.656 | ppl 50.41 | wps 42167 | ups 1.68 | wpb 25153.6 | bsz 1020.6 | num_updates 1408 | lr 0.000176 | gnorm 1.898 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 857
2022-03-14 07:34:41 | INFO | fairseq.trainer | begin training epoch 10
2022-03-14 07:34:41 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:35:11 | INFO | train_inner | epoch 010:     92 / 157 loss=5.335, ppl=40.35, wps=32811.9, ups=1.31, wpb=25102.3, bsz=1000.6, num_updates=1500, lr=0.0001875, gnorm=1.76, loss_scale=4, train_wall=31, gb_free=14.7, wall=887
2022-03-14 07:35:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:35:34 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppppine in the clinics.
2022-03-14 07:35:34 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:35:39 | INFO | fairseq.tasks.translation | example hypothesis: that's the right line of doha, most of you know, most of you know.
2022-03-14 07:35:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:35:43 | INFO | fairseq.tasks.translation | example hypothesis: stars will be new dididididies, the new new new york will get two new way.
2022-03-14 07:35:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:35:46 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese, where it's going to eat with the legs.
2022-03-14 07:35:46 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:35:51 | INFO | fairseq.tasks.translation | example hypothesis: it's right, we don't just just just a few seconds on his head on his head, and what's going on.
2022-03-14 07:35:51 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:35:55 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamay of people like the responsibility for the responsibility, and the number of animals, and this is a number of animals in fact, and this is a viviviiiiiiibia.
2022-03-14 07:35:55 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:35:59 | INFO | fairseq.tasks.translation | example hypothesis: first, some of these are some of the cototes, but in the lines, but it doesn't have to move, if they need their energy, they need their energy, and they need their energy.
2022-03-14 07:35:59 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:36:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the information that comes from this reflection, we can go with a single single one of the traditional, and we can start with the one of the information, and there's a whole structure, and there's all the information, and there's all the structure, and there's a whole structure, and there's a whole structure, and we all the structure that are all the structure, and we all the information that are all the information
2022-03-14 07:36:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:36:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons and it's interesting, and it's interesting for me, for tedwomen, for tedwomen, "yes," yes, "yes," yes, "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "'' '' '' '' '' '' '' '' '' '' '" "" "" "
2022-03-14 07:36:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:36:14 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, in fact, the mother, and the invention of the invention, and a very much part of the design, we had a little bit of the ground, which is that we had to solve, and we had to solve, it, it, and it's a whole system that it had to be a whole system that it was to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use
2022-03-14 07:36:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:36:14 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.994 | ppl 31.86 | bleu 11.88 | wps 4131.1 | wpb 17862.2 | bsz 728.3 | num_updates 1565 | best_bleu 11.88
2022-03-14 07:36:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 1565 updates
2022-03-14 07:36:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:36:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 10 @ 1565 updates, score 11.88) (writing took 2.1803540841210634 seconds)
2022-03-14 07:36:16 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-03-14 07:36:16 | INFO | train | epoch 010 | loss 5.25 | ppl 38.05 | wps 41397.1 | ups 1.65 | wpb 25153.6 | bsz 1020.6 | num_updates 1565 | lr 0.000195625 | gnorm 1.833 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 953
2022-03-14 07:36:17 | INFO | fairseq.trainer | begin training epoch 11
2022-03-14 07:36:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:36:28 | INFO | train_inner | epoch 011:     35 / 157 loss=5.158, ppl=35.69, wps=32200, ups=1.3, wpb=24855.9, bsz=1006.2, num_updates=1600, lr=0.0002, gnorm=1.919, loss_scale=4, train_wall=30, gb_free=13.8, wall=964
2022-03-14 07:36:59 | INFO | train_inner | epoch 011:    135 / 157 loss=4.804, ppl=27.93, wps=81698, ups=3.2, wpb=25548.4, bsz=1066.4, num_updates=1700, lr=0.0002125, gnorm=1.762, loss_scale=4, train_wall=31, gb_free=13.7, wall=995
2022-03-14 07:37:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:37:10 | INFO | fairseq.tasks.translation | example hypothesis: we did this pppin the clinics.
2022-03-14 07:37:10 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:37:14 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most most of you know here.
2022-03-14 07:37:14 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:37:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-14 07:37:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:37:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french, where the legs are shake, and you're going to get it.
2022-03-14 07:37:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:37:26 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just understand a couple of electroelectrodes on his head and understand what all the thoughts are on the mind.
2022-03-14 07:37:26 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:37:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the mamamated people who grew up the responsibility for the number of animals, and this is a number of animals.
2022-03-14 07:37:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:37:34 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magic lines in the lines, but if you don't get it, it doesn't need their energy energy energy, and if you need the energy energy energy energy.
2022-03-14 07:37:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:37:38 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that we can come from this reflection, we can start with a traditional face of the face, and we start able to create a whole form of the information, which is all the structure of the structure, and all the information.
2022-03-14 07:37:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:37:43 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting to make me here for tedwomen, is that i'm going to be able to say, "yes, you know, when you know, the best revolution is, you know," you know, you know, you know, you know, you know, you know, the time, you know, you know, you know, you know, you know, you know, you know, you know, in this is that there's a candandandandy of a cccist, "in this is a cist, for a cl l l l l l," and a cccist, "for a cist, you know, you know, you know, you know, for a cist, for a cist," and you know, you know, you know, you know, you know, "
2022-03-14 07:37:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:37:45 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, if you're still still the mother, and a big part of our work, we had to solve the plane, that we had to solve a result of the problems that we had to solve it, and it was a unique system that it had to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to
2022-03-14 07:37:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:37:45 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.65 | ppl 25.1 | bleu 15.21 | wps 4575.4 | wpb 17862.2 | bsz 728.3 | num_updates 1722 | best_bleu 15.21
2022-03-14 07:37:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 1722 updates
2022-03-14 07:37:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:37:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:37:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 11 @ 1722 updates, score 15.21) (writing took 2.1581692930776626 seconds)
2022-03-14 07:37:48 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-03-14 07:37:48 | INFO | train | epoch 011 | loss 4.887 | ppl 29.6 | wps 43246.6 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 1722 | lr 0.00021525 | gnorm 1.78 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 1044
2022-03-14 07:37:48 | INFO | fairseq.trainer | begin training epoch 12
2022-03-14 07:37:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:38:13 | INFO | train_inner | epoch 012:     78 / 157 loss=4.701, ppl=26.01, wps=34025, ups=1.36, wpb=24994.5, bsz=978.4, num_updates=1800, lr=0.000225, gnorm=1.663, loss_scale=4, train_wall=30, gb_free=14.4, wall=1069
2022-03-14 07:38:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:38:40 | INFO | fairseq.tasks.translation | example hypothesis: we did this ppink in the clinic.
2022-03-14 07:38:40 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:38:44 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, most of the most.
2022-03-14 07:38:44 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:38:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new locks.
2022-03-14 07:38:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:38:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's a french chinese chinese food, where the legs are happy, and it's going to be degrace.
2022-03-14 07:38:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:38:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just get some electrodes on his head on his head, and understand what all the thoughts are on the mind.
2022-03-14 07:38:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:39:00 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility, the number of responsibility grew up to the number of animals, and this is a foundation for the priiibia.
2022-03-14 07:39:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:39:04 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic magnetic lines in the field, but it doesn't go to the conductor, if you don't need to move the energy, you need to move the energy, and you need to be able to be able to see the alaluminum.
2022-03-14 07:39:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:39:08 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of these reflection, we can start with a traditional facial face, we start able to begin with the face of the face of the information and the information that gives it all the information.
2022-03-14 07:39:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:39:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's interesting for me to be here for tedwomen -- yes, it's the best thing that it said, "yeah, you know, you know, if you're talking about the best men, you're going to support."
2022-03-14 07:39:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:39:13 | INFO | fairseq.tasks.translation | example hypothesis: unfortunately, if you're going to do the idea of the invention, and a lot of work on the airplane, we had to solve that the plane was a unique result that we had to solve that there were unique problems in the ground.
2022-03-14 07:39:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:39:13 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.376 | ppl 20.76 | bleu 14.74 | wps 4967.6 | wpb 17862.2 | bsz 728.3 | num_updates 1879 | best_bleu 15.21
2022-03-14 07:39:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 1879 updates
2022-03-14 07:39:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:39:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:39:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 12 @ 1879 updates, score 14.74) (writing took 1.0582098900340497 seconds)
2022-03-14 07:39:15 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-03-14 07:39:15 | INFO | train | epoch 012 | loss 4.568 | ppl 23.71 | wps 45470.7 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 1879 | lr 0.000234875 | gnorm 1.643 | loss_scale 4 | train_wall 48 | gb_free 14.5 | wall 1131
2022-03-14 07:39:15 | INFO | fairseq.trainer | begin training epoch 13
2022-03-14 07:39:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:39:21 | INFO | train_inner | epoch 013:     21 / 157 loss=4.427, ppl=21.52, wps=36403.2, ups=1.45, wpb=25100.1, bsz=1056.5, num_updates=1900, lr=0.0002375, gnorm=1.677, loss_scale=4, train_wall=30, gb_free=14.3, wall=1138
2022-03-14 07:39:53 | INFO | train_inner | epoch 013:    121 / 157 loss=4.302, ppl=19.73, wps=80707.6, ups=3.19, wpb=25287.4, bsz=1028.2, num_updates=2000, lr=0.00025, gnorm=1.476, loss_scale=4, train_wall=31, gb_free=14, wall=1169
2022-03-14 07:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:40:08 | INFO | fairseq.tasks.translation | example hypothesis: we put these ppink in the clinic.
2022-03-14 07:40:08 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:40:12 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of you know.
2022-03-14 07:40:12 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:40:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new gulf locks that will be two new reduced.
2022-03-14 07:40:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:40:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food, where frog salt and serving.
2022-03-14 07:40:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:40:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just a few electrodes on his head, and understand what all the thoughts are on the mind.
2022-03-14 07:40:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:40:27 | INFO | fairseq.tasks.translation | example hypothesis: and in the mammals like the responsibility of responsibility, grew up to the number of animals, and this is a number of conservation for conservatives.
2022-03-14 07:40:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:40:31 | INFO | fairseq.tasks.translation | example hypothesis: first of these are some of the magnetic magnetic lines in the field, but the superconductor wouldn't be able to move their energy movements, and so if you need your energy and the alaluminum.
2022-03-14 07:40:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:40:35 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use information, the reflection of this reflection, we can start able to begin with a traditional face of the face of the face, and through the shape of the information and the information, which gives you a whole structure of the information and the information that all the structure.
2022-03-14 07:40:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:40:39 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and it's for me to be here for tedwomen, that he said, "yeah, when someone's best," you know, "when the best men said," and the men starts to support you. "
2022-03-14 07:40:39 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:40:40 | INFO | fairseq.tasks.translation | example hypothesis: luckily, is still the mother of the invention, and a big design that we had to solve the plane on our airplane, so that we had to solve a unique result of these problems that had to solve all the ground -- and it was a unique source of a fluid.
2022-03-14 07:40:40 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:40:40 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.111 | ppl 17.28 | bleu 17.91 | wps 5036.4 | wpb 17862.2 | bsz 728.3 | num_updates 2036 | best_bleu 17.91
2022-03-14 07:40:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 2036 updates
2022-03-14 07:40:40 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:40:41 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:40:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 13 @ 2036 updates, score 17.91) (writing took 2.0118849920108914 seconds)
2022-03-14 07:40:42 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-03-14 07:40:42 | INFO | train | epoch 013 | loss 4.282 | ppl 19.45 | wps 44960 | ups 1.79 | wpb 25153.6 | bsz 1020.6 | num_updates 2036 | lr 0.0002545 | gnorm 1.549 | loss_scale 4 | train_wall 48 | gb_free 13.9 | wall 1219
2022-03-14 07:40:43 | INFO | fairseq.trainer | begin training epoch 14
2022-03-14 07:40:43 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:41:03 | INFO | train_inner | epoch 014:     64 / 157 loss=4.128, ppl=17.48, wps=35724.6, ups=1.43, wpb=24965.5, bsz=985.9, num_updates=2100, lr=0.0002625, gnorm=1.516, loss_scale=4, train_wall=30, gb_free=14.4, wall=1239
2022-03-14 07:41:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:41:35 | INFO | fairseq.tasks.translation | example hypothesis: we made this pink in the clinic.
2022-03-14 07:41:35 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:41:39 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, which most of the most familiar here.
2022-03-14 07:41:39 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:41:43 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that are going to be the two new picks.
2022-03-14 07:41:43 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:41:48 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french food food, where frog legs, where frog legs are going to be served.
2022-03-14 07:41:48 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:41:52 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a few electrodes on his head and understand what all the thoughts of the thoughts are.
2022-03-14 07:41:52 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:41:56 | INFO | fairseq.tasks.translation | example hypothesis: and in the mab of the people like responsibility for life, grew up to the number of wildlife, the number of animals, and this is a natural conservation for conservaibia.
2022-03-14 07:41:56 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:42:00 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some bols of the magnetic field of magnetic lines in the inner lines, but the superconductor may not move to the energy and the alty.
2022-03-14 07:42:00 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:42:03 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection is reflection, we can start to start with a traditional facial of the face of the information, and through the whole structure of the information and the whole structure.
2022-03-14 07:42:03 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:42:08 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting, and you know, and you know, for me, "you know, you know, when the best men said," you know, and when the men starts to tell you about the table, and when you know, when you start to support the table. "
2022-03-14 07:42:08 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:42:10 | INFO | fairseq.tasks.translation | example hypothesis: luckily, it's still the mother of the invention of the invention of design, and a big part of the work that we had to solve the unique problems that were connected to the ground -- everything was connected to the ground.
2022-03-14 07:42:10 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:42:10 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 3.973 | ppl 15.71 | bleu 20.11 | wps 4697.4 | wpb 17862.2 | bsz 728.3 | num_updates 2193 | best_bleu 20.11
2022-03-14 07:42:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 2193 updates
2022-03-14 07:42:10 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:42:11 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:42:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 14 @ 2193 updates, score 20.11) (writing took 2.1576596070080996 seconds)
2022-03-14 07:42:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-03-14 07:42:12 | INFO | train | epoch 014 | loss 3.973 | ppl 15.7 | wps 43874.4 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 2193 | lr 0.000274125 | gnorm 1.359 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1309
2022-03-14 07:42:13 | INFO | fairseq.trainer | begin training epoch 15
2022-03-14 07:42:13 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:42:15 | INFO | train_inner | epoch 015:      7 / 157 loss=3.88, ppl=14.73, wps=35229.3, ups=1.38, wpb=25541.8, bsz=1065.6, num_updates=2200, lr=0.000275, gnorm=1.276, loss_scale=4, train_wall=30, gb_free=14.3, wall=1311
2022-03-14 07:42:46 | INFO | train_inner | epoch 015:    107 / 157 loss=3.7, ppl=13, wps=81078.7, ups=3.22, wpb=25146.5, bsz=1064.7, num_updates=2300, lr=0.0002875, gnorm=1.342, loss_scale=4, train_wall=30, gb_free=14.3, wall=1343
2022-03-14 07:43:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:43:06 | INFO | fairseq.tasks.translation | example hypothesis: we made this tack in the clinic clinic.
2022-03-14 07:43:06 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:43:09 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline from doha, probably most of the most familiar here.
2022-03-14 07:43:09 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:43:13 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldidge dines of the two new pigs.
2022-03-14 07:43:13 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:43:17 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are being served with salce and pelevation.
2022-03-14 07:43:17 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:43:22 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just take some electrodes on his head, and understand exactly what all of the thoughts are on the way.
2022-03-14 07:43:22 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:43:26 | INFO | fairseq.tasks.translation | example hypothesis: and in the mab of the people like the responsibility for the wildlife, grew up the number of wildlife, and that's a basis for conservation for conservation in namibia.
2022-03-14 07:43:26 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:43:30 | INFO | fairseq.tasks.translation | example hypothesis: first, some bols of magnetic field, but the superconducting lines in the inner field, but the superconductor doesn't like it, if you need to move your energy, your energy, you need to move, and the super-conductor.
2022-03-14 07:43:30 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:43:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information to reflect the reflection of this reflection, we can start with a traditional facial, the big constructions of the face of the face of the face and repeat it's a whole structure that gives you all the structure, and all the structure of the structure.
2022-03-14 07:43:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:43:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting to measure it and measure it, for me, for tedwomen, is that... yes, when the best thing came up with the best day, somebody said, "if we're going to support them," and then we're going to support you know, that the next time we've been working with this is that we've been working with this is for women, "and then we've been working with this time," oh, we've got it's been working with this time for example, that we've been working with this time, that we've been working with these women who have a silent, that we've been working on this time. "
2022-03-14 07:43:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:43:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of the invention, and a big part of the design work that we're at at the plane, was a result that we had to solve is a unique result that we had to solve with a system that allows us to be able to be able to use, and it allows us to use it to use it to use it to use it to use the most of a reuse of the power, and that allows us to use that allows us to use, to use it to use it to use it to use the tral to use it, to use it to use the most expensive to use, to use it, to use it to use it to use it, to use it, if you can use it, if you can actually use it, to use it, to use it, or be able to be able to use it to use the tral, to use the tral, to use it to use it to use it, or be able to be able to use the tral, or
2022-03-14 07:43:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:43:42 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.635 | ppl 12.42 | bleu 22.15 | wps 4533.7 | wpb 17862.2 | bsz 728.3 | num_updates 2350 | best_bleu 22.15
2022-03-14 07:43:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 2350 updates
2022-03-14 07:43:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:43:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:43:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 15 @ 2350 updates, score 22.15) (writing took 2.210924383951351 seconds)
2022-03-14 07:43:44 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-03-14 07:43:44 | INFO | train | epoch 015 | loss 3.743 | ppl 13.39 | wps 43099.9 | ups 1.71 | wpb 25153.6 | bsz 1020.6 | num_updates 2350 | lr 0.00029375 | gnorm 1.355 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1400
2022-03-14 07:43:44 | INFO | fairseq.trainer | begin training epoch 16
2022-03-14 07:43:44 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:44:01 | INFO | train_inner | epoch 016:     50 / 157 loss=3.742, ppl=13.38, wps=34170, ups=1.34, wpb=25427.2, bsz=928.4, num_updates=2400, lr=0.0003, gnorm=1.373, loss_scale=4, train_wall=31, gb_free=14.7, wall=1417
2022-03-14 07:44:31 | INFO | train_inner | epoch 016:    150 / 157 loss=3.49, ppl=11.23, wps=80363.2, ups=3.26, wpb=24656.8, bsz=1032.6, num_updates=2500, lr=0.0003125, gnorm=1.206, loss_scale=4, train_wall=30, gb_free=14.9, wall=1448
2022-03-14 07:44:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:44:38 | INFO | fairseq.tasks.translation | example hypothesis: we made these little prieps in the clinic.
2022-03-14 07:44:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:44:42 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, the most familiar here.
2022-03-14 07:44:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:44:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that create two new pigs.
2022-03-14 07:44:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:44:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese chinese food food, where frog legs are served and fat.
2022-03-14 07:44:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:44:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all the thoughts on the way.
2022-03-14 07:44:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:44:57 | INFO | fairseq.tasks.translation | example hypothesis: and it's like people's responsibility for wildwildlife, who grew up the number of wildwildlife, and this is a foundation for conservation in namibia.
2022-03-14 07:44:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:45:01 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field of magnetic lines, but the superconductor doesn't like the superconductor, if you're moving, you don't use your energy movements, and the superconductor.
2022-03-14 07:45:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:45:05 | INFO | fairseq.tasks.translation | example hypothesis: so if we use information, the reflection of this reflection comes from this reflection, we can start with a traditional facial facial configuration of the face and the basic shape of the face and repeat it, which gives you the whole structure, and all the structure of the structure and all the structure.
2022-03-14 07:45:05 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:45:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured to be here for me in tedwomen, is that... "yes," yes, when you're talking about the best day, "as somebody said," and the men who say, "if you're talking about a table," and you know, if you're going to support you're going to be silent, "and you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-14 07:45:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:45:13 | INFO | fairseq.tasks.translation | example hypothesis: luckness is still the mother of invention, and a big part of design work on our plane, we had a result that we had to solve is a result that we had to solve the unique problems that we had to solve, all of the ground -- everything is connected to a continuous system, and it allows us to be able to be able to be able to use a dumpse, and we're able to use of a little bit of the surface, and we're able to use it to use it to use the aircraft, and we're able to use a little bit of a little bit of a little bit of a little bit of the surface, and we're able to see that we can use it to use it to use it in the air, and we're able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to use the surface,
2022-03-14 07:45:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:45:13 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.497 | ppl 11.29 | bleu 21.95 | wps 4730.6 | wpb 17862.2 | bsz 728.3 | num_updates 2507 | best_bleu 22.15
2022-03-14 07:45:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 2507 updates
2022-03-14 07:45:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:45:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:45:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 16 @ 2507 updates, score 21.95) (writing took 0.9657399060670286 seconds)
2022-03-14 07:45:13 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2022-03-14 07:45:13 | INFO | train | epoch 016 | loss 3.531 | ppl 11.56 | wps 44124.8 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 2507 | lr 0.000313375 | gnorm 1.264 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 1490
2022-03-14 07:45:14 | INFO | fairseq.trainer | begin training epoch 17
2022-03-14 07:45:14 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:45:43 | INFO | train_inner | epoch 017:     93 / 157 loss=3.322, ppl=10, wps=35289.2, ups=1.39, wpb=25300.9, bsz=1053.6, num_updates=2600, lr=0.000325, gnorm=1.142, loss_scale=4, train_wall=31, gb_free=15.3, wall=1519
2022-03-14 07:46:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:46:07 | INFO | fairseq.tasks.translation | example hypothesis: we made these little priepin the clinics on the clinic.
2022-03-14 07:46:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:46:11 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you know most of the people here.
2022-03-14 07:46:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:46:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new golden locks that produce two new pigs that are going to be headed.
2022-03-14 07:46:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:46:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are serving with salz and fat.
2022-03-14 07:46:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:46:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we just don't just bring a few electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:46:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:46:27 | INFO | fairseq.tasks.translation | example hypothesis: and in that case, as people like responsibility for wildwildlife, grew up, and that's a basis of wildlife in namibia.
2022-03-14 07:46:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:46:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of these are some of the magnetic lines in the inner lines, but the sulalty is not going to move into the energy, and so the superconduction of the alignment of magnetic field.
2022-03-14 07:46:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:46:36 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial, and the basic shape of the face of the face, and the basic shape of the information that gives you a whole structure of the information that comes from this reflection, and all the structure of these reflection, we can start with a shape of these reflection, we can start with a whole structure of these things that we can begin with
2022-03-14 07:46:36 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:46:41 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and measured for me to be here at tedwomen, and then, in fact, is, when somebody said, "oh, you know, you know, you know, you know, you know, if we're working on a table and you're working on this thing, you're working on the fact that the truth is that you've got to be silent truth, you have a long time, you're working on it's silent truth, you're working on it's silent, you're working on that you're working on it's silent truth, you're working on it's silent truth,"
2022-03-14 07:46:41 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:46:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we've had to solve in the plane, is a result that we had to solve the unique problems that we had to solve in the ground -- everything else has to be able to be able to use a high-tech system that allows us to use a refrifriction system, or a machine that allows us to use to use of aircraft.
2022-03-14 07:46:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:46:44 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.426 | ppl 10.75 | bleu 23.54 | wps 4436.3 | wpb 17862.2 | bsz 728.3 | num_updates 2664 | best_bleu 23.54
2022-03-14 07:46:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 2664 updates
2022-03-14 07:46:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:46:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:46:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 17 @ 2664 updates, score 23.54) (writing took 2.3196411170065403 seconds)
2022-03-14 07:46:46 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2022-03-14 07:46:46 | INFO | train | epoch 017 | loss 3.347 | ppl 10.18 | wps 42758.7 | ups 1.7 | wpb 25153.6 | bsz 1020.6 | num_updates 2664 | lr 0.000333 | gnorm 1.206 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 1582
2022-03-14 07:46:46 | INFO | fairseq.trainer | begin training epoch 18
2022-03-14 07:46:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:46:58 | INFO | train_inner | epoch 018:     36 / 157 loss=3.324, ppl=10.01, wps=33825.4, ups=1.34, wpb=25229.8, bsz=1000.4, num_updates=2700, lr=0.0003375, gnorm=1.243, loss_scale=4, train_wall=30, gb_free=14.7, wall=1594
2022-03-14 07:47:29 | INFO | train_inner | epoch 018:    136 / 157 loss=3.156, ppl=8.91, wps=80100.3, ups=3.23, wpb=24823.4, bsz=1023, num_updates=2800, lr=0.00035, gnorm=1.093, loss_scale=4, train_wall=31, gb_free=14.5, wall=1625
2022-03-14 07:47:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:47:39 | INFO | fairseq.tasks.translation | example hypothesis: we put this sheep in the clinic.
2022-03-14 07:47:39 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:47:43 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, the most familiar here.
2022-03-14 07:47:43 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:47:47 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks. the two new picks will be reviewed.
2022-03-14 07:47:47 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:47:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are being served with salz.
2022-03-14 07:47:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:47:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:47:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:47:58 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis for the people like the people's responsibility for the wildlife, the number of wildlife. and this is a foundation for conservation protection.
2022-03-14 07:47:58 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:48:02 | INFO | fairseq.tasks.translation | example hypothesis: first, some bust of magnetic fields are caught inside the inner, but the superconductor doesn't like it, if you're moving around, and so the superconductor.
2022-03-14 07:48:02 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:48:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial facial, which is the big configuration of the face of the face, and the basic shape of the information, and through it. and all the structure, and all the structure, and a structure.
2022-03-14 07:48:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:48:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me to be here at tedwomen, is that -- you know, you know, you know, you know, you know, you know, you know, you know, you know, "you know, you know, you know, you know, you know, and if you're talking to me, you know," you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know,
2022-03-14 07:48:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:48:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a great part of the design work that we're using on the plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from one continent, everything from one continent, everything from a continual variable, and it allows us to do with an aircraft, and it allows us to be able to do with a rift of the aircraft, to the air, and to do with a logic, and it to the most expensive, and the logic, to the logic, to the world, and it to the most powerful, and it, and it's an aircraft.
2022-03-14 07:48:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:48:14 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.195 | ppl 9.16 | bleu 25.2 | wps 4671 | wpb 17862.2 | bsz 728.3 | num_updates 2821 | best_bleu 25.2
2022-03-14 07:48:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 2821 updates
2022-03-14 07:48:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:48:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:48:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 18 @ 2821 updates, score 25.2) (writing took 2.290039960993454 seconds)
2022-03-14 07:48:16 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2022-03-14 07:48:16 | INFO | train | epoch 018 | loss 3.165 | ppl 8.97 | wps 43716.8 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 2821 | lr 0.000352625 | gnorm 1.07 | loss_scale 4 | train_wall 48 | gb_free 14 | wall 1672
2022-03-14 07:48:17 | INFO | fairseq.trainer | begin training epoch 19
2022-03-14 07:48:17 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:48:41 | INFO | train_inner | epoch 019:     79 / 157 loss=3.066, ppl=8.38, wps=35212.5, ups=1.37, wpb=25639, bsz=997.8, num_updates=2900, lr=0.0003625, gnorm=0.994, loss_scale=4, train_wall=31, gb_free=14.3, wall=1698
2022-03-14 07:49:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:49:09 | INFO | fairseq.tasks.translation | example hypothesis: we made this sweep in the clinic.
2022-03-14 07:49:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:49:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-14 07:49:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:49:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldicks, which are made two new pigs.
2022-03-14 07:49:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:49:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are being served with salt legs and ppet.
2022-03-14 07:49:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:49:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put a few electrodes on his head and understand exactly what his thoughts are on the track.
2022-03-14 07:49:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:49:29 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of humans took responsibility for wildwildlife, the number of wildwildwildwildwildwildlife has become a foundation for conservation in namibia.
2022-03-14 07:49:29 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:49:33 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field are caught in the inner inner field, but the superconductors don't like it, if they move their energy, and so the supersuperconduction of magnetic field.
2022-03-14 07:49:33 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:49:37 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information that comes from this reflection, we can start with a traditional facial face, which is the groundings of the face and the basic shape of the information, and all the structure of this reflection and all the structure.
2022-03-14 07:49:37 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:49:42 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and appropriate to be here for me to be here at tedwomen, is that, when he was best summarized when somebody said, "turn you on the men and say," if the revolution begins, "]]]]]," you know, we're already supporting you. "]]]]] ["]]]]] ["]]]]]]]]]] ["]]]]]]]]]]]]]]]]] then we've already, you guys, you guys, you guys, "] ["] ["] then we're going to be a lot of you guys,"] then you guys, "] ["]] ["] ["] ["] ["] then you guys who are already supporting you guys,
2022-03-14 07:49:42 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:49:44 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother is still the invention of invention, and a great part of the design work that we're using on our plane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variation, and a big part of a refrigeration with a refrigerator, and it allows us to make it a refrigergergergeration system of the most expensive, which is that they're going to the most expensive to the most expensive, to the most expensive, and it would be a little bit of the most expensive, to the high-high-high-level of the most expensive, and it would be a machine that we use it, to the most expensive to the most expensive, and it's a machine that it's a machine that it's a high-end up the degrace of the most expensive to the most expensive to the most expensive, to the most expensive to the high-end up the most expensive when you, and it, and it's a machine,
2022-03-14 07:49:44 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:49:44 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.199 | ppl 9.18 | bleu 24.96 | wps 4697 | wpb 17862.2 | bsz 728.3 | num_updates 2978 | best_bleu 25.2
2022-03-14 07:49:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 2978 updates
2022-03-14 07:49:44 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:49:45 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:49:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 19 @ 2978 updates, score 24.96) (writing took 1.0067090368829668 seconds)
2022-03-14 07:49:45 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2022-03-14 07:49:45 | INFO | train | epoch 019 | loss 3.019 | ppl 8.11 | wps 44501.8 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 2978 | lr 0.00037225 | gnorm 1.035 | loss_scale 4 | train_wall 48 | gb_free 14.2 | wall 1761
2022-03-14 07:49:46 | INFO | fairseq.trainer | begin training epoch 20
2022-03-14 07:49:46 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:49:53 | INFO | train_inner | epoch 020:     22 / 157 loss=2.959, ppl=7.78, wps=34793.4, ups=1.4, wpb=24793.5, bsz=1030.8, num_updates=3000, lr=0.000375, gnorm=1.035, loss_scale=4, train_wall=30, gb_free=15.1, wall=1769
2022-03-14 07:50:24 | INFO | train_inner | epoch 020:    122 / 157 loss=2.859, ppl=7.26, wps=81863.4, ups=3.16, wpb=25866.7, bsz=1014.2, num_updates=3100, lr=0.0003875, gnorm=0.867, loss_scale=4, train_wall=31, gb_free=14.1, wall=1801
2022-03-14 07:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:50:38 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters in the clinic.
2022-03-14 07:50:38 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:50:42 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here.
2022-03-14 07:50:42 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:50:46 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks.
2022-03-14 07:50:46 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:50:50 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are served with salz and pills.
2022-03-14 07:50:50 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:50:54 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:50:54 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:50:59 | INFO | fairseq.tasks.translation | example hypothesis: and this is a basis for conservation, as people who took responsibility for wildlife, who grew up with wildlife animals again, and that's a foundation for conservation in namibia.
2022-03-14 07:50:59 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:51:03 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are caught in the inner lines, but the superconductor doesn't like it if they're moving around, and that's how the supermovements need.
2022-03-14 07:51:03 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:51:07 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial, which is the groundings of the face of the face and the basic shape, and restoring it through that one information, which is the whole structure, and all the structure and a constructor structure and an infold.
2022-03-14 07:51:07 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:51:11 | INFO | fairseq.tasks.translation | example hypothesis: th one of the reasons that it's interesting and appropriate to be here for me to be here at tedwomen, is that... well, in the way, the best dinner was summarized as someone said, "turn on the men in a table, and tell you, if the revolution starts to support you, 'if the revolution,' if the revolution starts to support you. ''"
2022-03-14 07:51:11 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:51:14 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we have on our aircraft, was a result that we had to solve the unique problems that were connected to the ground -- everything from one continuing to a continuous variation, and a system of the refrigerator, and a system of the refrigerator of the fly system, which allows us to see that allows us to see in the aircraft, to see in the aircraft, or the fly, to see that allows us to see that allows us to see in the aircraft to see that we can be able to see in the aircraft, except except for the fly, to see in the fly, to see in the fly, to see in the fly, until the fly, to see in the fly, to see that allows us to see that allows us to see in the first time, to see that we can be able to see in the aircraft, to see that's a state of a state of a state of a
2022-03-14 07:51:14 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:51:14 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.045 | ppl 8.26 | bleu 27.03 | wps 4614.9 | wpb 17862.2 | bsz 728.3 | num_updates 3135 | best_bleu 27.03
2022-03-14 07:51:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 3135 updates
2022-03-14 07:51:14 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:51:15 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:51:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 20 @ 3135 updates, score 27.03) (writing took 2.151564555009827 seconds)
2022-03-14 07:51:16 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2022-03-14 07:51:16 | INFO | train | epoch 020 | loss 2.853 | ppl 7.23 | wps 43396.3 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 3135 | lr 0.000391875 | gnorm 0.92 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 1852
2022-03-14 07:51:16 | INFO | fairseq.trainer | begin training epoch 21
2022-03-14 07:51:16 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:51:37 | INFO | train_inner | epoch 021:     65 / 157 loss=2.801, ppl=6.97, wps=34426.1, ups=1.38, wpb=24883, bsz=1097.7, num_updates=3200, lr=0.0004, gnorm=1.081, loss_scale=4, train_wall=30, gb_free=14.3, wall=1873
2022-03-14 07:52:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:52:09 | INFO | fairseq.tasks.translation | example hypothesis: we made these piepsters in the clinic clinic.
2022-03-14 07:52:09 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:52:13 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, most of you know here.
2022-03-14 07:52:13 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:52:17 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to make new goldilocks to create the two new sponsors.
2022-03-14 07:52:17 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:52:21 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food, where frog legs are being served with salz and ppet.
2022-03-14 07:52:21 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:52:25 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what its thoughts are on the track.
2022-03-14 07:52:25 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:52:30 | INFO | fairseq.tasks.translation | example hypothesis: and in the case of the people like responsibility for wildwildlife, the number of wildwildwildwildlife animals have become a foundation for conservation protection in namibia.
2022-03-14 07:52:30 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:52:34 | INFO | fairseq.tasks.translation | example hypothesis: first, some bust of magnetic fields are caught inside, but the superconductors don't like it, if you move, you use your energy movements, and so the superconducting disorders.
2022-03-14 07:52:34 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:52:38 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection reflection, we can start with a traditional facial face, which is the groundly constructures of the face and the basic form of the face, and restoring it through that information, and put it through that one piece of the information that we can fold up all of it.
2022-03-14 07:52:38 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:52:43 | INFO | fairseq.tasks.translation | example hypothesis: th one of the reasons it's kind of interesting and appropriate to be here for me here at tedwomen, is that... yes, when the strikes dinner was summarized when someone said, "turning you to a table and say," you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're going to have a lot of old old old, you, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you know, you're
2022-03-14 07:52:43 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:52:45 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a great piece of design work that we have on our aircraft, one result that we had to solve the unique problems that were connected to it to operations -- everything from a continuous, and a refrigeration system that allows us to use the aircraft, or to make the carpet pet, to the most expensive, to the aircraft of the most strippy, to the most powerful, to the united states, or a state of one of which is a state of which we had to solve, that we had to solve the most unique problem that we had to solve the most unique problems that we had to solve the most unique problems that we had to solve the most unique problems that we had to solve the most unique problems that we had to solve the most unique problems that we had to solve the most unique problems that we had to solve the most unique problems that we had to solve.
2022-03-14 07:52:45 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:52:45 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.027 | ppl 8.15 | bleu 27.12 | wps 4587.3 | wpb 17862.2 | bsz 728.3 | num_updates 3292 | best_bleu 27.12
2022-03-14 07:52:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 3292 updates
2022-03-14 07:52:45 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:52:46 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:52:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 21 @ 3292 updates, score 27.12) (writing took 2.2705621120985597 seconds)
2022-03-14 07:52:47 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2022-03-14 07:52:47 | INFO | train | epoch 021 | loss 2.775 | ppl 6.85 | wps 43150.5 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 3292 | lr 0.0004115 | gnorm 0.983 | loss_scale 4 | train_wall 47 | gb_free 15.1 | wall 1944
2022-03-14 07:52:48 | INFO | fairseq.trainer | begin training epoch 22
2022-03-14 07:52:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:52:51 | INFO | train_inner | epoch 022:      8 / 157 loss=2.769, ppl=6.82, wps=33462.4, ups=1.35, wpb=24765.2, bsz=946.6, num_updates=3300, lr=0.0004125, gnorm=0.889, loss_scale=4, train_wall=30, gb_free=14.3, wall=1947
2022-03-14 07:53:22 | INFO | train_inner | epoch 022:    108 / 157 loss=2.688, ppl=6.45, wps=79734.2, ups=3.24, wpb=24641.4, bsz=1004.1, num_updates=3400, lr=0.000425, gnorm=1.007, loss_scale=4, train_wall=30, gb_free=14.2, wall=1978
2022-03-14 07:53:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:53:41 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsters in the clinic.
2022-03-14 07:53:41 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:53:45 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know.
2022-03-14 07:53:45 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:53:48 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks signs that are going to cross two new sponges.
2022-03-14 07:53:48 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:53:52 | INFO | fairseq.tasks.translation | example hypothesis: for example, there are french chinese food where frog legs are served with salz and psuitcase.
2022-03-14 07:53:52 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:53:56 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all his thoughts are on track.
2022-03-14 07:53:56 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:54:00 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife, the number of wildwildwildwildlife has become again. and that's a foundation for conservation.
2022-03-14 07:54:00 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:54:04 | INFO | fairseq.tasks.translation | example hypothesis: first, some bundle of magnetic field tracks are trapped inside, but the superconductor doesn't like it, when they move, they use their movements.
2022-03-14 07:54:04 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:54:08 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from this reflection, we can start with a traditional facial facial, which is the big congestion of the face and the basic shape, and refuse it through the tune of information, which refits the entire portical structure and fits its its its its its its its its its of information.
2022-03-14 07:54:08 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:54:12 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's interesting and appropriate for me to be here at tedwomen, is that     well, when you're going to put it together as somebody said, "turn you to the men in your table, and say," turn it out to the men in your desk, "and tell you," you, you know, you know, you know, you know, you're going to have a silent on. "
2022-03-14 07:54:12 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:54:13 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that allows us to use in our aircraft to solve the unique problems that were linked to the ground.
2022-03-14 07:54:13 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:54:13 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 2.934 | ppl 7.64 | bleu 26.13 | wps 4987.6 | wpb 17862.2 | bsz 728.3 | num_updates 3449 | best_bleu 27.12
2022-03-14 07:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 3449 updates
2022-03-14 07:54:13 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:54:14 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:54:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 22 @ 3449 updates, score 26.13) (writing took 1.0088052558712661 seconds)
2022-03-14 07:54:14 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2022-03-14 07:54:14 | INFO | train | epoch 022 | loss 2.665 | ppl 6.34 | wps 45371 | ups 1.8 | wpb 25153.6 | bsz 1020.6 | num_updates 3449 | lr 0.000431125 | gnorm 0.921 | loss_scale 4 | train_wall 48 | gb_free 14.8 | wall 2031
2022-03-14 07:54:15 | INFO | fairseq.trainer | begin training epoch 23
2022-03-14 07:54:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:54:31 | INFO | train_inner | epoch 023:     51 / 157 loss=2.58, ppl=5.98, wps=36809.7, ups=1.44, wpb=25503.2, bsz=954.5, num_updates=3500, lr=0.0004375, gnorm=0.748, loss_scale=4, train_wall=30, gb_free=14.2, wall=2047
2022-03-14 07:55:02 | INFO | train_inner | epoch 023:    151 / 157 loss=2.541, ppl=5.82, wps=82383.8, ups=3.24, wpb=25389.8, bsz=1103.3, num_updates=3600, lr=0.00045, gnorm=0.948, loss_scale=4, train_wall=30, gb_free=14.2, wall=2078
2022-03-14 07:55:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:55:07 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsters on the clinic.
2022-03-14 07:55:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:55:11 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you here.
2022-03-14 07:55:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:55:15 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks that are going to cross two emerging pigs.
2022-03-14 07:55:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:55:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salz and ppepper.
2022-03-14 07:55:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:55:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:55:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:55:27 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife's responsibility, the number of wildwildwildlife again has become a foundation for conservation in namibia.
2022-03-14 07:55:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:55:31 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the magnetic field lines are caught inside, but the superconductor doesn't like it, if they move around, because their movements need their energy movements, and so the superconducting disorder.
2022-03-14 07:55:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:55:35 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflective reflection, we can start with a traditional facial, which is the grows of the face of the face and the basic shape that restores the whole information that gives you all the porter of the information that gives you the entire portion of the tune and all of the fine information.
2022-03-14 07:55:35 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:55:40 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting to be very interesting and appropriate to me here at tedwomen, is that -- well, when strictly dinner was linked, when someone said, "turn it to men on a table and tell you," if the revolution starts to support you. "
2022-03-14 07:55:40 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:55:42 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're on on our plane, was a result that we had to solve the unique problems that were connected to it -- everything that's connected to the ground -- all of a continuous substitute system that allows us to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to do when the most specialized in the most specialized, to be a state of a state of a mechanism that we're used to be able to be able to solve in the streets, if we're used to solve in the streets, if we're actually actually actually be able to solve in a state of a state of a state of a mechanism, if we're actually be able to solve the most specialized, if you're in the most specialized, if you're actually actually actually actually actually actually actually, to solve the first place.
2022-03-14 07:55:42 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:55:42 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 2.944 | ppl 7.7 | bleu 27.22 | wps 4711.5 | wpb 17862.2 | bsz 728.3 | num_updates 3606 | best_bleu 27.22
2022-03-14 07:55:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 3606 updates
2022-03-14 07:55:42 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:55:43 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:55:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 23 @ 3606 updates, score 27.22) (writing took 2.273204955039546 seconds)
2022-03-14 07:55:44 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2022-03-14 07:55:44 | INFO | train | epoch 023 | loss 2.538 | ppl 5.81 | wps 43950.4 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 3606 | lr 0.00045075 | gnorm 0.873 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 2121
2022-03-14 07:55:45 | INFO | fairseq.trainer | begin training epoch 24
2022-03-14 07:55:45 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:56:14 | INFO | train_inner | epoch 024:     94 / 157 loss=2.441, ppl=5.43, wps=34474.4, ups=1.38, wpb=24931.7, bsz=1035.4, num_updates=3700, lr=0.0004625, gnorm=0.82, loss_scale=4, train_wall=30, gb_free=14.2, wall=2150
2022-03-14 07:56:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:56:37 | INFO | fairseq.tasks.translation | example hypothesis: we put these tweep in the clinic.
2022-03-14 07:56:37 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:56:41 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you.
2022-03-14 07:56:41 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:56:45 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks, the two new pigs.
2022-03-14 07:56:45 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:56:49 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and ppeg.
2022-03-14 07:56:49 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:56:53 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on track.
2022-03-14 07:56:53 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:56:57 | INFO | fairseq.tasks.translation | example hypothesis: and in the size of how people took responsibility for wildlife, the number of wildanimals grew up again. and that's a foundation for conservation in namibia.
2022-03-14 07:56:57 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:57:01 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field are trapped inside, but the superconductor doesn't like it, if you move around, movements are required, and so the superconducting disorders.
2022-03-14 07:57:01 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:57:06 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from that reflection, we can start with a traditional facial can, the main configurations of the face and the basic shape of the face, and restoring it through the information that pulls up all the pores structure and fits folds.
2022-03-14 07:57:06 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:57:10 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and measures, for me to be here at tedwomen, is that -- tyes, when i was summarized when someone said, "turn to men in a table and say," '"if the revolution starts to support you."' "'the truth is that we've been supporting you,"' "'" that the truth is that we've already started to share with you. "' em & gt;
2022-03-14 07:57:10 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:57:12 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of the design work that we're on on on our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variable variables and a system of the refrigerators that allows us to exploit or a refrigerators, that we're able to use the sound of a petrashing machine to use of what we could use when they're able to make it's more sophisticated, or more sophisticated, or to make it's a sense of a sense of the sound of the sound of what we had to be able to be able to make it's more sophisticated, to make it's going to make it's more sophisticated, to be able to be able to make it's more sophisticated, to use of what we had been able to make it's more sophisticated, to make it's more sophisticated, to make it's going to be able to be able to be able to
2022-03-14 07:57:12 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:57:12 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 2.831 | ppl 7.12 | bleu 28.66 | wps 4718.4 | wpb 17862.2 | bsz 728.3 | num_updates 3763 | best_bleu 28.66
2022-03-14 07:57:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 3763 updates
2022-03-14 07:57:12 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:57:13 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 07:57:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 24 @ 3763 updates, score 28.66) (writing took 2.1405687229707837 seconds)
2022-03-14 07:57:14 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2022-03-14 07:57:14 | INFO | train | epoch 024 | loss 2.452 | ppl 5.47 | wps 43835.7 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 3763 | lr 0.000470375 | gnorm 0.825 | loss_scale 4 | train_wall 48 | gb_free 14.7 | wall 2211
2022-03-14 07:57:15 | INFO | fairseq.trainer | begin training epoch 25
2022-03-14 07:57:15 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:57:27 | INFO | train_inner | epoch 025:     37 / 157 loss=2.388, ppl=5.23, wps=35061.3, ups=1.38, wpb=25486.7, bsz=1056.2, num_updates=3800, lr=0.000475, gnorm=0.774, loss_scale=4, train_wall=30, gb_free=14.4, wall=2223
2022-03-14 07:57:58 | INFO | train_inner | epoch 025:    137 / 157 loss=2.42, ppl=5.35, wps=80340, ups=3.21, wpb=25037.1, bsz=988.5, num_updates=3900, lr=0.0004875, gnorm=0.846, loss_scale=4, train_wall=31, gb_free=14.3, wall=2254
2022-03-14 07:58:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:58:07 | INFO | fairseq.tasks.translation | example hypothesis: we put these piesters in the clinic.
2022-03-14 07:58:07 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:58:11 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha probably most of you here.
2022-03-14 07:58:11 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:58:15 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks.
2022-03-14 07:58:15 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:58:19 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog legs will be served with salz and pepper.
2022-03-14 07:58:19 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:58:23 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all its thoughts are on track.
2022-03-14 07:58:23 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:58:27 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife has grown again, and this has become a basis for conservation in namibia.
2022-03-14 07:58:27 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:58:31 | INFO | fairseq.tasks.translation | example hypothesis: first, some of magnetic fields are trapped inside, but the superconductor doesn't like you move around, because your movements use, and so the superconducting disorders.
2022-03-14 07:58:31 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 07:58:34 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this mirror reflection, we can start with a traditional facial configurations that contains the face of the face and the basic shape, and refuse it through the information that includes all the fabric of it.
2022-03-14 07:58:34 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 07:58:38 | INFO | fairseq.tasks.translation | example hypothesis: th one of the reasons it's interesting and appropriate to me here at tedwomen, is that... well, when strikes dinner was best summarized as someone said, "turn forward to men on a table and say to them, 'if revolution begins to support you.'
2022-03-14 07:58:38 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 07:58:39 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of design work that we're proud of our airplane, was a result that we had to solve the unique problems that were connected to operations -- everything from continuing to a continuous variation and a system that allows us to use in the aircraft.
2022-03-14 07:58:39 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 07:58:39 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 2.868 | ppl 7.3 | bleu 27.09 | wps 5195.4 | wpb 17862.2 | bsz 728.3 | num_updates 3920 | best_bleu 28.66
2022-03-14 07:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 3920 updates
2022-03-14 07:58:39 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:58:40 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 07:58:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 25 @ 3920 updates, score 27.09) (writing took 1.0482959321234375 seconds)
2022-03-14 07:58:40 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2022-03-14 07:58:40 | INFO | train | epoch 025 | loss 2.37 | ppl 5.17 | wps 46075.8 | ups 1.83 | wpb 25153.6 | bsz 1020.6 | num_updates 3920 | lr 0.00049 | gnorm 0.795 | loss_scale 4 | train_wall 48 | gb_free 15.1 | wall 2296
2022-03-14 07:58:40 | INFO | fairseq.trainer | begin training epoch 26
2022-03-14 07:58:40 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 07:59:06 | INFO | train_inner | epoch 026:     80 / 157 loss=2.275, ppl=4.84, wps=37432.5, ups=1.47, wpb=25441.6, bsz=1009.2, num_updates=4000, lr=0.0005, gnorm=0.756, loss_scale=4, train_wall=30, gb_free=14.3, wall=2322
2022-03-14 07:59:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 07:59:33 | INFO | fairseq.tasks.translation | example hypothesis: we put these tank in the clinic.
2022-03-14 07:59:33 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 07:59:37 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha that most of you know here.
2022-03-14 07:59:37 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 07:59:41 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks dinners that are going to cross two new sponsors.
2022-03-14 07:59:41 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 07:59:45 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and ppepper.
2022-03-14 07:59:45 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 07:59:49 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 07:59:49 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 07:59:53 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as people took responsibility for wildlife, the number of wildlife wildlife wildlife conservation has become a foundation for conservation in namibia.
2022-03-14 07:59:53 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 07:59:57 | INFO | fairseq.tasks.translation | example hypothesis: first, some legs of magnetic field capabilities are caught inside, but the superconductor doesn't like it, if they move, they use their energy movements, and so the superconducting disorders.
2022-03-14 07:59:57 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:00:01 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information that comes from that reflection, we can start with a traditional facial can, which is the great constructures of the face and the basic shape, and refuse it through the tune of information that refuses up the entire portutoring structure, and refuse it.
2022-03-14 08:00:01 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:00:07 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that it's very interesting and appropriate for me to be here at tedwomen, is that... tyes, when the stridy dinner was best summarized when someone said, "turn the men on your table and say to you, 'if the revolution begins, then we support you."
2022-03-14 08:00:07 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:00:09 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're in our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables to operate -- to operate on the ground, from a continuous variables and a system of the refrigerators that allows us to be able to do with a refrigeration of the aircraft, to the operations that we can't use of the operations, to the table table table, to be able, to be able to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate, to operate in the table, to operate in the table, to operate -- to operate in the table, to operate
2022-03-14 08:00:09 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:00:09 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 2.778 | ppl 6.86 | bleu 29.82 | wps 4607.2 | wpb 17862.2 | bsz 728.3 | num_updates 4077 | best_bleu 29.82
2022-03-14 08:00:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 4077 updates
2022-03-14 08:00:09 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:00:10 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:00:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 26 @ 4077 updates, score 29.82) (writing took 2.1330571440048516 seconds)
2022-03-14 08:00:11 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2022-03-14 08:00:11 | INFO | train | epoch 026 | loss 2.283 | ppl 4.87 | wps 43347.5 | ups 1.72 | wpb 25153.6 | bsz 1020.6 | num_updates 4077 | lr 0.000495256 | gnorm 0.779 | loss_scale 4 | train_wall 48 | gb_free 14.6 | wall 2387
2022-03-14 08:00:12 | INFO | fairseq.trainer | begin training epoch 27
2022-03-14 08:00:12 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:00:19 | INFO | train_inner | epoch 027:     23 / 157 loss=2.24, ppl=4.72, wps=33986.8, ups=1.36, wpb=24953.1, bsz=1099.1, num_updates=4100, lr=0.000493865, gnorm=0.768, loss_scale=4, train_wall=30, gb_free=15.2, wall=2395
2022-03-14 08:00:50 | INFO | train_inner | epoch 027:    123 / 157 loss=2.221, ppl=4.66, wps=80516.4, ups=3.22, wpb=25041.4, bsz=943.9, num_updates=4200, lr=0.00048795, gnorm=0.761, loss_scale=4, train_wall=31, gb_free=14, wall=2427
2022-03-14 08:01:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:01:04 | INFO | fairseq.tasks.translation | example hypothesis: we set up these pietsters in the clinic.
2022-03-14 08:01:04 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:01:08 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-14 08:01:08 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:01:12 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks dinners that will transcend two new sponsors.
2022-03-14 08:01:12 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:01:16 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food where frog is going to be served with salt and pffer.
2022-03-14 08:01:16 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:01:20 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:01:20 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:01:24 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as human responsibility for wildlife has been growing again, and this has become a basis for conservation in namibia.
2022-03-14 08:01:24 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:01:28 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are captured inside, but the superconductor doesn't like it if they move because their energy use, and so the superconducting disorder.
2022-03-14 08:01:28 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:01:32 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial configuration that gives the larger contextures of the face and the basic shape, and refuse it through the information that comes in.
2022-03-14 08:01:32 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:01:36 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and reasonable for me to be here at tedwomen, is that... well, in the strikes dinner, it was best summarized as somebody said, "turn you to men on your table and say," well, if the revolution begins, let's support you. "
2022-03-14 08:01:36 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:01:37 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a large part of the design work that we're on on the aircraft, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and a system that allows us to look at aircraft, and we're going to be used to be able to use it, and we're going to use it in a regular car, and we're going to be able to see it.
2022-03-14 08:01:37 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:01:37 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 2.751 | ppl 6.73 | bleu 28.88 | wps 5036.8 | wpb 17862.2 | bsz 728.3 | num_updates 4234 | best_bleu 29.82
2022-03-14 08:01:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 4234 updates
2022-03-14 08:01:37 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:01:38 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:01:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 27 @ 4234 updates, score 28.88) (writing took 1.0133045541588217 seconds)
2022-03-14 08:01:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2022-03-14 08:01:38 | INFO | train | epoch 027 | loss 2.194 | ppl 4.58 | wps 45496.3 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 4234 | lr 0.000485987 | gnorm 0.745 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 2474
2022-03-14 08:01:38 | INFO | fairseq.trainer | begin training epoch 28
2022-03-14 08:01:38 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:01:59 | INFO | train_inner | epoch 028:     66 / 157 loss=2.096, ppl=4.28, wps=36199.1, ups=1.45, wpb=24892.1, bsz=1013.7, num_updates=4300, lr=0.000482243, gnorm=0.692, loss_scale=4, train_wall=30, gb_free=15.1, wall=2495
2022-03-14 08:02:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:02:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these piepsters on the clinic.
2022-03-14 08:02:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:02:35 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you know.
2022-03-14 08:02:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:02:39 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to cross new goldilocks.
2022-03-14 08:02:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:02:43 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog is being served with salt and pepper.
2022-03-14 08:02:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:02:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:02:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:02:51 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife, the number of wildwildlife has become again, and that's a basis for conservation in namibia.
2022-03-14 08:02:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:02:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductors don't like it if they move, they use their energy movements, and so the superconducting disorders.
2022-03-14 08:02:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:02:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the great configurations of the face and the basic shape, and replaced it through the dieest information that includes the entire por-structure and all the flooding.
2022-03-14 08:02:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:03:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and measurable for me to be here at tedwomen, is that -- well, when there was a strict dinner, it was best than somebody said, "turn you to men on a table and say to you, 'if the revolution begins, we will support you.'"
2022-03-14 08:03:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:03:06 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention still is the mother of invention, and a large part of the design work that allows us to use on our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables to a continuous variable variables, and a large part of the design system that allows us to use a machine to use the aircraft, or to use it in the air, or to be able to use the vehicle, or to be able to move around the vehicle.
2022-03-14 08:03:06 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:03:06 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 2.716 | ppl 6.57 | bleu 30.03 | wps 4730.5 | wpb 17862.2 | bsz 728.3 | num_updates 4391 | best_bleu 30.03
2022-03-14 08:03:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 4391 updates
2022-03-14 08:03:06 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:03:07 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:03:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 28 @ 4391 updates, score 30.03) (writing took 2.2428986991290003 seconds)
2022-03-14 08:03:08 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2022-03-14 08:03:08 | INFO | train | epoch 028 | loss 2.091 | ppl 4.26 | wps 43957.6 | ups 1.75 | wpb 25153.6 | bsz 1020.6 | num_updates 4391 | lr 0.00047722 | gnorm 0.706 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 2564
2022-03-14 08:03:08 | INFO | fairseq.trainer | begin training epoch 29
2022-03-14 08:03:08 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:03:11 | INFO | train_inner | epoch 029:      9 / 157 loss=2.137, ppl=4.4, wps=34984.5, ups=1.39, wpb=25193, bsz=990.5, num_updates=4400, lr=0.000476731, gnorm=0.77, loss_scale=4, train_wall=30, gb_free=14, wall=2567
2022-03-14 08:03:42 | INFO | train_inner | epoch 029:    109 / 157 loss=2.009, ppl=4.03, wps=80661.5, ups=3.21, wpb=25138.3, bsz=1028.2, num_updates=4500, lr=0.000471405, gnorm=0.719, loss_scale=4, train_wall=31, gb_free=14, wall=2598
2022-03-14 08:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:04:01 | INFO | fairseq.tasks.translation | example hypothesis: we put these pietsters up in the clinic.
2022-03-14 08:04:01 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:04:05 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you know.
2022-03-14 08:04:05 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:04:09 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks guards that are going to cross two new pierts.
2022-03-14 08:04:09 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:04:13 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog is served with salt and pepper.
2022-03-14 08:04:13 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:04:17 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring a couple electrodes on its head and understand exactly what all its thoughts are on track.
2022-03-14 08:04:17 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:04:21 | INFO | fairseq.tasks.translation | example hypothesis: and in the magician, as people took responsibility for wildlife, the number of wild animals are growing back up, and that's a basis for conservation in namibia.
2022-03-14 08:04:21 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:04:25 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it when they move around, because their energy use, and so the superconductors.
2022-03-14 08:04:25 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:04:29 | INFO | fairseq.tasks.translation | example hypothesis: so, if we take the information that comes from this reflection, we can start with a traditional facial can, which is the great, and the basic shape, and then refuse it through the temptation of the information that comes from the fabric structure and floods up a fold.
2022-03-14 08:04:29 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons that makes it interesting and reasonable, for me here at tedwomen, is that... tone, when he said, "turn to men on a table and said, 'if the revolution begins, then we'll support you.' the truth is that we've already got you on a long time of peace for boys."
2022-03-14 08:04:34 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:04:36 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a lot of design work that allows us to use on our airplane the most proud toe, or when you're in the case that we have to solve the unique problems that you have to operate on the ground -- all of a continuous variables and a system of liquid, that allows us to use a machine to use a stop-and-a-bridust, and if you're in a specialist, to the propelled, to the propelled, or when you're going to be able to see the propelled to the market.
2022-03-14 08:04:36 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:04:36 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 2.716 | ppl 6.57 | bleu 30.35 | wps 4725.9 | wpb 17862.2 | bsz 728.3 | num_updates 4548 | best_bleu 30.35
2022-03-14 08:04:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 4548 updates
2022-03-14 08:04:36 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:04:37 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:04:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 29 @ 4548 updates, score 30.35) (writing took 2.2590177678503096 seconds)
2022-03-14 08:04:38 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2022-03-14 08:04:38 | INFO | train | epoch 029 | loss 2.014 | ppl 4.04 | wps 43645.1 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4548 | lr 0.00046891 | gnorm 0.721 | loss_scale 4 | train_wall 48 | gb_free 13.7 | wall 2655
2022-03-14 08:04:39 | INFO | fairseq.trainer | begin training epoch 30
2022-03-14 08:04:39 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:04:55 | INFO | train_inner | epoch 030:     52 / 157 loss=1.96, ppl=3.89, wps=34415.7, ups=1.37, wpb=25075.3, bsz=967.8, num_updates=4600, lr=0.000466252, gnorm=0.679, loss_scale=4, train_wall=30, gb_free=14.3, wall=2671
2022-03-14 08:05:26 | INFO | train_inner | epoch 030:    152 / 157 loss=1.909, ppl=3.76, wps=81736.9, ups=3.23, wpb=25320.2, bsz=1072.2, num_updates=4700, lr=0.000461266, gnorm=0.629, loss_scale=4, train_wall=31, gb_free=15.1, wall=2702
2022-03-14 08:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:05:31 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep ep in the clinic.
2022-03-14 08:05:31 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:05:35 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, probably most of you here know.
2022-03-14 08:05:35 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:05:39 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks prayers that will transcend two new vibrands.
2022-03-14 08:05:39 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:05:43 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frogged with salt and pepper.
2022-03-14 08:05:43 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:05:47 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just put some electrodes on his head and understand exactly what all of its thoughts are on the track.
2022-03-14 08:05:47 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:05:51 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility to the wildlife population, the number of wild animals have become a foundations for conservation in namibia.
2022-03-14 08:05:51 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:05:55 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductors don't like it if they move, because their energy use, and so the superconducting disorder.
2022-03-14 08:05:55 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:05:59 | INFO | fairseq.tasks.translation | example hypothesis: so if we can use the information coming from this reflection, we can start with a traditional facial can, which is the larger configurations of the face and the basic shape, and empairing it through the tune of this information that refuses the entire porter structure and fits its its its its its its its its its its its its brain.
2022-03-14 08:05:59 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:06:03 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and reasonable to be here at tedwomen, is that... well, when strictly dinner was put it together, when someone said, "turn to men on your table and say to you, 'if the revolution starts to support you.'" 'the truth is that we have you guys guys guys with this long, carbonate ate ate ate ate ate ate ate ate ate ate ate ate ate ate ate ate ate ate ate, "and then you."
2022-03-14 08:06:03 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:06:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention still is the mother of invention, and a big part of the design work that we're on the plane crank was a result that we had to solve the unique problems that were connected to operations on the ground -- all of a continuous variables and a refrigeration system, that allows us to use a stop-to-fly machine to a special traffic and a constructive citizenship.
2022-03-14 08:06:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:06:04 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 2.709 | ppl 6.54 | bleu 30.33 | wps 4993 | wpb 17862.2 | bsz 728.3 | num_updates 4705 | best_bleu 30.35
2022-03-14 08:06:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 4705 updates
2022-03-14 08:06:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:06:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:06:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 30 @ 4705 updates, score 30.33) (writing took 0.9767252781894058 seconds)
2022-03-14 08:06:05 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2022-03-14 08:06:05 | INFO | train | epoch 030 | loss 1.904 | ppl 3.74 | wps 45426.7 | ups 1.81 | wpb 25153.6 | bsz 1020.6 | num_updates 4705 | lr 0.00046102 | gnorm 0.649 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2742
2022-03-14 08:06:06 | INFO | fairseq.trainer | begin training epoch 31
2022-03-14 08:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:06:36 | INFO | train_inner | epoch 031:     95 / 157 loss=1.853, ppl=3.61, wps=36682.8, ups=1.44, wpb=25536.1, bsz=1010.6, num_updates=4800, lr=0.000456435, gnorm=0.705, loss_scale=4, train_wall=31, gb_free=14, wall=2772
2022-03-14 08:06:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:06:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep in the clinic.
2022-03-14 08:06:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:07:02 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most people here know.
2022-03-14 08:07:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:07:06 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks facilities that will transcend the two new vows.
2022-03-14 08:07:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:07:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog legs are served with salt and pepper.
2022-03-14 08:07:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:07:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all his thoughts are on the track.
2022-03-14 08:07:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:07:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the measures of how people took responsibility for wildlife, the number of wildlife conservation has become a foundation for conservation in namibia.
2022-03-14 08:07:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:07:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductors don't like it if they're moving, there's your movements, and so the superconducting disorders.
2022-03-14 08:07:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:07:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial configuration that gives the larger configurations of the face and the basic shape, and then add it through the information that makes the whole porter structure and all the fits.
2022-03-14 08:07:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:07:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and appropriate for me to be here at tedwomen, is that... well, when it's been presumably nified when someone said, "turn to the men on your table and say to you," if the revolution begins, then we support you. "the truth is that we already have a long time for you."] ["] ["] [people '"] [are] [people] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] [are] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["] ["]
2022-03-14 08:07:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:07:33 | INFO | fairseq.tasks.translation | example hypothesis: fortunately, the mother of invention still is the mother of invention, and a great part of design work that we're the most proud of our airplane, was a result that we had to solve the unique problems that were connected to the ground -- everything from a continuous variables and refrigerated system with the refrigeration that allows us to use a machine in the airplane, and then we can use it in the vehicle of a static transport, or a promoting system of a trajectory until you're in the market market market market, and then you can see in the auto, and then you can see in the auto, and then you can see in the auto station in the trains that's a regular vehicle, timber.
2022-03-14 08:07:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:07:33 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 2.699 | ppl 6.49 | bleu 30.76 | wps 4696.4 | wpb 17862.2 | bsz 728.3 | num_updates 4862 | best_bleu 30.76
2022-03-14 08:07:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 4862 updates
2022-03-14 08:07:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:07:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:07:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 31 @ 4862 updates, score 30.76) (writing took 2.2249713900964707 seconds)
2022-03-14 08:07:35 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2022-03-14 08:07:35 | INFO | train | epoch 031 | loss 1.858 | ppl 3.62 | wps 43867.3 | ups 1.74 | wpb 25153.6 | bsz 1020.6 | num_updates 4862 | lr 0.000453516 | gnorm 0.693 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 2832
2022-03-14 08:07:36 | INFO | fairseq.trainer | begin training epoch 32
2022-03-14 08:07:36 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:07:48 | INFO | train_inner | epoch 032:     38 / 157 loss=1.788, ppl=3.45, wps=34540.2, ups=1.39, wpb=24912.5, bsz=1051, num_updates=4900, lr=0.000451754, gnorm=0.64, loss_scale=4, train_wall=30, gb_free=14.7, wall=2844
2022-03-14 08:08:19 | INFO | train_inner | epoch 032:    138 / 157 loss=1.81, ppl=3.51, wps=81163.2, ups=3.21, wpb=25273.6, bsz=1027.3, num_updates=5000, lr=0.000447214, gnorm=0.738, loss_scale=4, train_wall=31, gb_free=14.8, wall=2875
2022-03-14 08:08:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:08:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep on the clinic.
2022-03-14 08:08:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:08:32 | INFO | fairseq.tasks.translation | example hypothesis: this is the skyline of doha, probably most of you know here.
2022-03-14 08:08:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:08:36 | INFO | fairseq.tasks.translation | example hypothesis: stars will create new goldilocks conditions that will transcend two new vials.
2022-03-14 08:08:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:08:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogs are being served with salt and pepper.
2022-03-14 08:08:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:08:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just take some electrodes on his head and understand exactly what all of its thoughts are on track.
2022-03-14 08:08:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:08:48 | INFO | fairseq.tasks.translation | example hypothesis: and in this case, as people took responsibility for wildlife, the wildlife wildlife community grew back. and this is a basis for conservation.
2022-03-14 08:08:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:08:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if they move, because their energy use, and so the superconductors.
2022-03-14 08:08:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:08:56 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which is the big shapes of the face, and the basic shape, and give it through the tune of information that includes the entire porter structure and all the fits.
2022-03-14 08:08:56 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:09:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and measured for me here at tedwomen is that -- well, when he was striking dinner, it was best summarized when somebody said, "turn to men at your table, and they say, 'if the revolution begins, we will support you.' ''" the truth is that we already have you on this topic for me, you know, it's a long time, you know, you know, spelled by the way, you know, it's silly. "
2022-03-14 08:09:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:09:03 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a huge amount of design work that allows us to use on our plane trip, was a result that we had to solve the unique problems associated with it, to operate on the ground -- everything from a continuous variables and a system of refrigeration, that allows us to use a machine on the plane, the go-go-and-a-race race, to transport, to transport, to fly around you know, or to take the propelled the propelled it, or, the propelled it would be the propelled.
2022-03-14 08:09:03 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:09:03 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 2.749 | ppl 6.72 | bleu 29.84 | wps 4778.8 | wpb 17862.2 | bsz 728.3 | num_updates 5019 | best_bleu 30.76
2022-03-14 08:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 5019 updates
2022-03-14 08:09:03 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:09:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:09:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 32 @ 5019 updates, score 29.84) (writing took 0.9465883090160787 seconds)
2022-03-14 08:09:04 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2022-03-14 08:09:04 | INFO | train | epoch 032 | loss 1.777 | ppl 3.43 | wps 44778.2 | ups 1.78 | wpb 25153.6 | bsz 1020.6 | num_updates 5019 | lr 0.000446366 | gnorm 0.695 | loss_scale 4 | train_wall 48 | gb_free 14.9 | wall 2920
2022-03-14 08:09:04 | INFO | fairseq.trainer | begin training epoch 33
2022-03-14 08:09:04 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:09:30 | INFO | train_inner | epoch 033:     81 / 157 loss=1.675, ppl=3.19, wps=35430.9, ups=1.41, wpb=25080.4, bsz=1119.7, num_updates=5100, lr=0.000442807, gnorm=0.665, loss_scale=4, train_wall=30, gb_free=14.4, wall=2946
2022-03-14 08:09:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:09:57 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep psters up in the clinic.
2022-03-14 08:09:57 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:10:02 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, which i think most of you here know.
2022-03-14 08:10:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:10:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks conditions that are going to scend two new vibrations.
2022-03-14 08:10:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:10:10 | INFO | fairseq.tasks.translation | example hypothesis: for instance, there's french chinese food, where frog legs are being served with salt and pepper.
2022-03-14 08:10:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:10:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on top of its head and understand exactly what all his thoughts are on the track.
2022-03-14 08:10:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:10:18 | INFO | fairseq.tasks.translation | example hypothesis: and in the measures of how people took responsibility for wildlife, the number of wild animals grew up again, and that's a basis for conservation in namibia.
2022-03-14 08:10:18 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:10:22 | INFO | fairseq.tasks.translation | example hypothesis: first of all, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it, if they move, there's their movements, and so the superconductors are disrupting.
2022-03-14 08:10:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:10:26 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from this reflection, we can start with a traditional facial can, which will be the widespread edges of the face and readily remediate the basic shape, and refuse it through the one of the second information that refers the entire porter structure and fits it.
2022-03-14 08:10:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:10:31 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's very interesting and reasonable to be here at tedwomen, is that... well, when strikes dinner was put together, when someone said, "turn to men on your desk and say to them, 'if the revolution begins, then we will support you.' the truth is that we have, you know, women, that we have a long time to break down," and then, trigger, "and then," why, "and then," why, if the future breaks down.
2022-03-14 08:10:31 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:10:32 | INFO | fairseq.tasks.translation | example hypothesis: thankfully, the mother of invention still is the mother of invention, and a big part of the design work that we're on on our plane the proud toe was a result that we had to solve the unique problems that are linked to operate on the ground -- all of a continuously varied variables and a cooling system with refrigeration that allows us to take advantage of an airplane and use to the propelled, or when you can see the propelled.
2022-03-14 08:10:32 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:10:32 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 2.705 | ppl 6.52 | bleu 31.03 | wps 4790.7 | wpb 17862.2 | bsz 728.3 | num_updates 5176 | best_bleu 31.03
2022-03-14 08:10:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 5176 updates
2022-03-14 08:10:32 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:10:33 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt
2022-03-14 08:10:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_best.pt (epoch 33 @ 5176 updates, score 31.03) (writing took 2.158332376042381 seconds)
2022-03-14 08:10:34 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2022-03-14 08:10:34 | INFO | train | epoch 033 | loss 1.704 | ppl 3.26 | wps 43525.5 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5176 | lr 0.000439545 | gnorm 0.67 | loss_scale 4 | train_wall 48 | gb_free 14.4 | wall 3010
2022-03-14 08:10:35 | INFO | fairseq.trainer | begin training epoch 34
2022-03-14 08:10:35 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:10:43 | INFO | train_inner | epoch 034:     24 / 157 loss=1.719, ppl=3.29, wps=34450.7, ups=1.37, wpb=25148, bsz=918.9, num_updates=5200, lr=0.000438529, gnorm=0.681, loss_scale=4, train_wall=30, gb_free=14.2, wall=3019
2022-03-14 08:11:14 | INFO | train_inner | epoch 034:    124 / 157 loss=1.623, ppl=3.08, wps=80701.9, ups=3.21, wpb=25139.6, bsz=1054.5, num_updates=5300, lr=0.000434372, gnorm=0.677, loss_scale=4, train_wall=31, gb_free=14.1, wall=3050
2022-03-14 08:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:11:28 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep pans up in the clinic.
2022-03-14 08:11:28 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:11:32 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline from doha, most of you probably know here.
2022-03-14 08:11:32 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:11:36 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks conditions that will transcend two new gay people.
2022-03-14 08:11:36 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:11:40 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frosniff legs and salt pepper are served.
2022-03-14 08:11:40 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:11:44 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what his thoughts are on the track.
2022-03-14 08:11:44 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:11:48 | INFO | fairseq.tasks.translation | example hypothesis: and in that sense, as people took responsibility for wildlife, the wildlife wildlife kingdom grew again, and that's a basis for conservation in namibia.
2022-03-14 08:11:48 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:11:52 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move, then you use your energy movements, and so the superconductors.
2022-03-14 08:11:52 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:11:57 | INFO | fairseq.tasks.translation | example hypothesis: so if we use the information that comes from that reflection, we can start with a traditional facial can that will give the larger shapes of the face and the basic shape, and restraints it through the medium information that includes the entire porter structure, and all the trails.
2022-03-14 08:11:57 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:12:02 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting and appropriate for me to be here at tedwomen, is that -- well, when it was striking dinner, it was best summarized when someone said, "turn the men on your desk and say to you," if the revolution begins, we will support you. "'" the truth, "" "" "" "" "" "well, we have you guys on this for a long time."
2022-03-14 08:12:02 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:12:04 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still invention, and a big part of design work that we're at our plane pristine, was a result that we had to solve the unique problems associated with it, getting it to operations on the ground -- all of a varied variables, and a large part of the design of our design work, that allows us to use a stopgo-and flight system, all the way down to a point where we can use it, or when you get escaping the propelled, or when you get the propelled, or when you get in a bladder, and you get in the market, it all the first place, it all the way, it all the propelled, it all the resources, and we can see it all the way, all the time, all the time, all the time, all the way, all the way.
2022-03-14 08:12:04 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:12:04 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 2.746 | ppl 6.71 | bleu 31.01 | wps 4580.9 | wpb 17862.2 | bsz 728.3 | num_updates 5333 | best_bleu 31.03
2022-03-14 08:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 5333 updates
2022-03-14 08:12:04 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:12:05 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:12:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 34 @ 5333 updates, score 31.01) (writing took 0.915556135121733 seconds)
2022-03-14 08:12:05 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2022-03-14 08:12:05 | INFO | train | epoch 034 | loss 1.638 | ppl 3.11 | wps 43537.8 | ups 1.73 | wpb 25153.6 | bsz 1020.6 | num_updates 5333 | lr 0.000433026 | gnorm 0.69 | loss_scale 4 | train_wall 48 | gb_free 14.1 | wall 3101
2022-03-14 08:12:05 | INFO | fairseq.trainer | begin training epoch 35
2022-03-14 08:12:05 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:12:26 | INFO | train_inner | epoch 035:     67 / 157 loss=1.628, ppl=3.09, wps=34671.2, ups=1.38, wpb=25102.4, bsz=954, num_updates=5400, lr=0.000430331, gnorm=0.743, loss_scale=4, train_wall=30, gb_free=15.1, wall=3123
2022-03-14 08:12:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:12:58 | INFO | fairseq.tasks.translation | example hypothesis: we put these beep on the clinic.
2022-03-14 08:12:58 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:13:02 | INFO | fairseq.tasks.translation | example hypothesis: that's the skyline of doha, which i think most of you here know.
2022-03-14 08:13:02 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:13:06 | INFO | fairseq.tasks.translation | example hypothesis: stars are going to create new goldilocks conditions that will transcend two new pigs.
2022-03-14 08:13:06 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:13:10 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frogy legs are being served with salt and pepper.
2022-03-14 08:13:10 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:13:14 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we're not just putting some electrodes on its head and just understanding what's all his thoughts on the track.
2022-03-14 08:13:14 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:13:17 | INFO | fairseq.tasks.translation | example hypothesis: and in the stomach, as humans took responsibility for wildlife, the wildlife wildlife conservation has grown up. and that's a basis for conservation in namibia.
2022-03-14 08:13:17 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:13:22 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it, if you move around, there's their movements, and so the superconducting disorder.
2022-03-14 08:13:22 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:13:26 | INFO | fairseq.tasks.translation | example hypothesis: so, if we use the information coming from this reflection, we can start with a traditional facial can that will regenerate the larger facial configurations of the face and regenerate the basic shape, and recover it through the rest of the information, which includes the entire por-structure and all of the fits.
2022-03-14 08:13:26 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:13:30 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's really interesting and reasonable to do it here for me to be here at tedwomen, is that -- well, the strict dinner was put together as one said, "turn the men on your desk and saying to you, 'if the revolution begins, then we will support you.'" the truth is that we've already been supporting you with this long, carbond by charose. "
2022-03-14 08:13:30 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:13:33 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention, and a big part of design work that we're on our plane the most proud of it, was a result that we had to solve the unique problems that were connected to operations on the ground -- everything from a continuous variables of drives and refrigerators that allows us to use a vehicle in the aircraft, or if you're going to use the propeller ground, or if you're going to see the propelled for the propelled automation system, or when you're going to the propelled to the propellers, to the safety system.
2022-03-14 08:13:33 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:13:33 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 2.759 | ppl 6.77 | bleu 30.52 | wps 4722.3 | wpb 17862.2 | bsz 728.3 | num_updates 5490 | best_bleu 31.03
2022-03-14 08:13:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 5490 updates
2022-03-14 08:13:33 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:13:34 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:13:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 35 @ 5490 updates, score 30.52) (writing took 1.0324662909843028 seconds)
2022-03-14 08:13:34 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2022-03-14 08:13:34 | INFO | train | epoch 035 | loss 1.57 | ppl 2.97 | wps 44518.5 | ups 1.77 | wpb 25153.6 | bsz 1020.6 | num_updates 5490 | lr 0.00042679 | gnorm 0.688 | loss_scale 4 | train_wall 48 | gb_free 13.8 | wall 3190
2022-03-14 08:13:34 | INFO | fairseq.trainer | begin training epoch 36
2022-03-14 08:13:34 | INFO | fairseq_cli.train | Start iterating over samples
2022-03-14 08:13:37 | INFO | train_inner | epoch 036:     10 / 157 loss=1.552, ppl=2.93, wps=35106.3, ups=1.41, wpb=24921.2, bsz=1053.9, num_updates=5500, lr=0.000426401, gnorm=0.65, loss_scale=4, train_wall=30, gb_free=15.1, wall=3194
2022-03-14 08:14:09 | INFO | train_inner | epoch 036:    110 / 157 loss=1.492, ppl=2.81, wps=81052.1, ups=3.2, wpb=25297.2, bsz=1042, num_updates=5600, lr=0.000422577, gnorm=0.66, loss_scale=4, train_wall=31, gb_free=15.1, wall=3225
2022-03-14 08:14:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-03-14 08:14:27 | INFO | fairseq.tasks.translation | example hypothesis: we put these bleep on the clinic.
2022-03-14 08:14:27 | INFO | fairseq.tasks.translation | example reference: we put the beeper in the clinic.
2022-03-14 08:14:31 | INFO | fairseq.tasks.translation | example hypothesis: that's the doha skyline, which i think most people know here.
2022-03-14 08:14:31 | INFO | fairseq.tasks.translation | example reference: this is probably the skyline that most of you know about doha.
2022-03-14 08:14:34 | INFO | fairseq.tasks.translation | example hypothesis: stars will make new goldilocks conditions that will create these two new voirs.
2022-03-14 08:14:34 | INFO | fairseq.tasks.translation | example reference: stars will create the goldilocks conditions for crossing two new thresholds.
2022-03-14 08:14:38 | INFO | fairseq.tasks.translation | example hypothesis: for example, there's french chinese food, where frog with salt and pepper is served.
2022-03-14 08:14:38 | INFO | fairseq.tasks.translation | example reference: for example, there is french chinese food, where they serve salt and pepper frog legs.
2022-03-14 08:14:42 | INFO | fairseq.tasks.translation | example hypothesis: it's clear that we don't just bring some electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:14:42 | INFO | fairseq.tasks.translation | example reference: now, clearly we're not going to put a couple of electrodes on his head and understand exactly what all of his thoughts are on the track.
2022-03-14 08:14:47 | INFO | fairseq.tasks.translation | example hypothesis: and in the measures of how people took responsibility to the wildlife, the number of wildlife grew back. and that's a basis for conservation in namibia.
2022-03-14 08:14:47 | INFO | fairseq.tasks.translation | example reference: and thus, as people started feeling ownership over wildlife, wildlife numbers started coming back, and that's actually becoming a foundation for conservation in namibia.
2022-03-14 08:14:51 | INFO | fairseq.tasks.translation | example hypothesis: first, some of the strands of magnetic field are trapped inside, but the superconductor doesn't like it if they move, because their movements use, and so the superconductors.
2022-03-14 08:14:51 | INFO | fairseq.tasks.translation | example reference: well, first there are strands of magnetic field left inside, but now the superconductor doesn't like them moving around, because their movements dissipate energy, which breaks the superconductivity state.
2022-03-14 08:14:55 | INFO | fairseq.tasks.translation | example hypothesis: so if we take advantage of the information that comes from this reflection, we can start with a traditional facial can that will resemble the larger configurations of the face and add the basic shape, and refuse it through that single information that includes the entire portion structure and all the floods.
2022-03-14 08:14:55 | INFO | fairseq.tasks.translation | example reference: so, if we use information that comes off of this specular reflection, we can go from a traditional face scan that might have the gross contours of the face and the basic shape, and augment it with information that puts in all of that skin pore structure and fine wrinkles.
2022-03-14 08:15:00 | INFO | fairseq.tasks.translation | example hypothesis: th: one of the reasons it's interesting, and it's measurable to be here at tedwomen, is that -- well, when it's strided dinner it was best known as somebody said, "turn on men on your desk and say to you, 'if the revolution begins, we will support you.'" '"'" '"'" '"the truth,"' "'"' "'"' "'"' "'"' "'"' "] [" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'" '"'"]
2022-03-14 08:15:00 | INFO | fairseq.tasks.translation | example reference: th: one of this things that's exciting and appropriate for me to be here at tedwomen is that, well, i think it was summed up best last night at dinner when someone said, "turn to the man at your table and tell them, 'when the revolution starts, we've got your back.'" the truth is, women, you've had our back on this issue for a very long time, starting with rachel carson's "silent spring" to theo colborn's "our stolen future" to sandra steingraber's books "living downstream" and "having faith."
2022-03-14 08:15:02 | INFO | fairseq.tasks.translation | example hypothesis: luckily, the mother of invention is still the mother of invention, and a big part of the design work that we're on our airplane on the proud zealand was a result that we had to solve the unique problems associated with the ground -- all of a continuous variables, and a system of refrigeration, and that allows us to use a refrigeration of the aircraft system, and that allows us to use to stop the reliance of one of the forces and a pipeline, and the propelled to the aircraft system if you can be reliance, or if you can see on the propelled to the aircraft.
2022-03-14 08:15:02 | INFO | fairseq.tasks.translation | example reference: fortunately, necessity remains the mother of invention, and a lot of the design work that we're the most proud of with the aircraft came out of solving the unique problems of operating it on the ground -- everything from a continuously-variable transmission and liquid-based cooling system that allows us to use an aircraft engine in stop-and-go traffic, to a custom-designed gearbox that powers either the propeller when you're flying or the wheels on the ground, to the automated wing-folding mechanism that we'll see in a moment, to crash safety features.
2022-03-14 08:15:02 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 2.8 | ppl 6.97 | bleu 30.31 | wps 4644.2 | wpb 17862.2 | bsz 728.3 | num_updates 5647 | best_bleu 31.03
2022-03-14 08:15:02 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 3 runs
2022-03-14 08:15:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 5647 updates
2022-03-14 08:15:02 | INFO | fairseq.trainer | Saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:15:03 | INFO | fairseq.trainer | Finished saving checkpoint to /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt
2022-03-14 08:15:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /cluster/scratch/andriusb/checkpoints/iwslt14_de_en_dropout_0.1/checkpoint_last.pt (epoch 36 @ 5647 updates, score 30.31) (writing took 1.0413267619442195 seconds)
2022-03-14 08:15:03 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2022-03-14 08:15:03 | INFO | train | epoch 036 | loss 1.513 | ppl 2.85 | wps 44196.3 | ups 1.76 | wpb 25153.6 | bsz 1020.6 | num_updates 5647 | lr 0.000420815 | gnorm 0.675 | loss_scale 4 | train_wall 48 | gb_free 14.3 | wall 3279
2022-03-14 08:15:03 | INFO | fairseq_cli.train | done training in 3278.7 seconds
